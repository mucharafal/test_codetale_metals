[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "What is this app name? Please add to comments.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-29T21:07:50Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.net.InetAddress\n+import java.util.UUID\n+import org.apache.spark.Logging\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver.Receiver\n+import com.amazonaws.auth.DefaultAWSCredentialsProviderChain\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import java.nio.ByteBuffer\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Custom AWS Kinesis-specific implementation of Spark Streaming's Receiver.\n+ * This implementation relies on the Kinesis Client Library (KCL) Worker as described here:\n+ * https://github.com/awslabs/amazon-kinesis-client\n+ * This is a custom receiver used with StreamingContext.receiverStream(Receiver) as described here:\n+ * http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+ * Instances of this class will get shipped to the Spark Streaming Workers to run within a Spark Executor.\n+ *\n+ * @param app name"
  }, {
    "author": {
      "login": "cfregly"
    },
    "body": "updated\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T22:48:45Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.net.InetAddress\n+import java.util.UUID\n+import org.apache.spark.Logging\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver.Receiver\n+import com.amazonaws.auth.DefaultAWSCredentialsProviderChain\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import java.nio.ByteBuffer\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Custom AWS Kinesis-specific implementation of Spark Streaming's Receiver.\n+ * This implementation relies on the Kinesis Client Library (KCL) Worker as described here:\n+ * https://github.com/awslabs/amazon-kinesis-client\n+ * This is a custom receiver used with StreamingContext.receiverStream(Receiver) as described here:\n+ * http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+ * Instances of this class will get shipped to the Spark Streaming Workers to run within a Spark Executor.\n+ *\n+ * @param app name"
  }],
  "prId": 1434
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Formatting incorrect. 4 spaces necessary here. Please see the spark style guide\nhttps://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-29T21:09:21Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.net.InetAddress\n+import java.util.UUID\n+import org.apache.spark.Logging\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver.Receiver\n+import com.amazonaws.auth.DefaultAWSCredentialsProviderChain\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import java.nio.ByteBuffer\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Custom AWS Kinesis-specific implementation of Spark Streaming's Receiver.\n+ * This implementation relies on the Kinesis Client Library (KCL) Worker as described here:\n+ * https://github.com/awslabs/amazon-kinesis-client\n+ * This is a custom receiver used with StreamingContext.receiverStream(Receiver) as described here:\n+ * http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+ * Instances of this class will get shipped to the Spark Streaming Workers to run within a Spark Executor.\n+ *\n+ * @param app name\n+ * @param Kinesis stream name\n+ * @param endpoint url of Kinesis service\n+ * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+ *   See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+ * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+ *   The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+ *      or the tip of the stream using InitialPositionInStream.LATEST.\n+ * @param persistence strategy for RDDs and DStreams.\n+ */\n+private[streaming] class KinesisReceiver(\n+  app: String,"
  }, {
    "author": {
      "login": "cfregly"
    },
    "body": "good catch.  i went through and fixed another similar formatting mistake, as well. \n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-29T22:01:59Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.net.InetAddress\n+import java.util.UUID\n+import org.apache.spark.Logging\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver.Receiver\n+import com.amazonaws.auth.DefaultAWSCredentialsProviderChain\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import java.nio.ByteBuffer\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Custom AWS Kinesis-specific implementation of Spark Streaming's Receiver.\n+ * This implementation relies on the Kinesis Client Library (KCL) Worker as described here:\n+ * https://github.com/awslabs/amazon-kinesis-client\n+ * This is a custom receiver used with StreamingContext.receiverStream(Receiver) as described here:\n+ * http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+ * Instances of this class will get shipped to the Spark Streaming Workers to run within a Spark Executor.\n+ *\n+ * @param app name\n+ * @param Kinesis stream name\n+ * @param endpoint url of Kinesis service\n+ * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+ *   See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+ * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+ *   The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+ *      or the tip of the stream using InitialPositionInStream.LATEST.\n+ * @param persistence strategy for RDDs and DStreams.\n+ */\n+private[streaming] class KinesisReceiver(\n+  app: String,"
  }],
  "prId": 1434
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "If you are adding a random UUID to this, do you really need the workerId to be actually the IP of the worker?\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-29T21:12:54Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.net.InetAddress\n+import java.util.UUID\n+import org.apache.spark.Logging\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver.Receiver\n+import com.amazonaws.auth.DefaultAWSCredentialsProviderChain\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import java.nio.ByteBuffer\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Custom AWS Kinesis-specific implementation of Spark Streaming's Receiver.\n+ * This implementation relies on the Kinesis Client Library (KCL) Worker as described here:\n+ * https://github.com/awslabs/amazon-kinesis-client\n+ * This is a custom receiver used with StreamingContext.receiverStream(Receiver) as described here:\n+ * http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+ * Instances of this class will get shipped to the Spark Streaming Workers to run within a Spark Executor.\n+ *\n+ * @param app name\n+ * @param Kinesis stream name\n+ * @param endpoint url of Kinesis service\n+ * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+ *   See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+ * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+ *   The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+ *      or the tip of the stream using InitialPositionInStream.LATEST.\n+ * @param persistence strategy for RDDs and DStreams.\n+ */\n+private[streaming] class KinesisReceiver(\n+  app: String,\n+  stream: String,\n+  endpoint: String,\n+  checkpointIntervalMillis: Long,\n+  initialPositionInStream: InitialPositionInStream,\n+  storageLevel: StorageLevel)\n+  extends Receiver[Array[Byte]](storageLevel) with Logging { receiver =>\n+\n+  /**\n+   *  The lazy val's below will get instantiated in the remote Executor after the closure is shipped to the Spark Worker. \n+   *  These are all lazy because they're from third-party Amazon libraries and are not Serializable.\n+   *  If they're not marked lazy, they will cause NotSerializableExceptions when they're shipped to the Spark Worker.\n+   */\n+\n+  /**\n+   *  workerId is lazy because we want the address of the actual Worker where the code runs - not the Driver's ip address.\n+   *  This makes a difference when running in a cluster.\n+   */\n+  lazy val workerId = InetAddress.getLocalHost.getHostAddress() + \":\" + UUID.randomUUID()"
  }, {
    "author": {
      "login": "cfregly"
    },
    "body": "there can be multiple workers per host, so i can't just use the host address.  but to answer your question, i guess i don't really need the host address since i'm generating a random UUID.  \n\nhowever, i found it useful when reviewing logs for debugging purposes.  i'll keep for now unless you have a strong objection.\n\ngood catch.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-29T22:04:08Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.net.InetAddress\n+import java.util.UUID\n+import org.apache.spark.Logging\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver.Receiver\n+import com.amazonaws.auth.DefaultAWSCredentialsProviderChain\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import java.nio.ByteBuffer\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Custom AWS Kinesis-specific implementation of Spark Streaming's Receiver.\n+ * This implementation relies on the Kinesis Client Library (KCL) Worker as described here:\n+ * https://github.com/awslabs/amazon-kinesis-client\n+ * This is a custom receiver used with StreamingContext.receiverStream(Receiver) as described here:\n+ * http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+ * Instances of this class will get shipped to the Spark Streaming Workers to run within a Spark Executor.\n+ *\n+ * @param app name\n+ * @param Kinesis stream name\n+ * @param endpoint url of Kinesis service\n+ * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+ *   See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+ * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+ *   The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+ *      or the tip of the stream using InitialPositionInStream.LATEST.\n+ * @param persistence strategy for RDDs and DStreams.\n+ */\n+private[streaming] class KinesisReceiver(\n+  app: String,\n+  stream: String,\n+  endpoint: String,\n+  checkpointIntervalMillis: Long,\n+  initialPositionInStream: InitialPositionInStream,\n+  storageLevel: StorageLevel)\n+  extends Receiver[Array[Byte]](storageLevel) with Logging { receiver =>\n+\n+  /**\n+   *  The lazy val's below will get instantiated in the remote Executor after the closure is shipped to the Spark Worker. \n+   *  These are all lazy because they're from third-party Amazon libraries and are not Serializable.\n+   *  If they're not marked lazy, they will cause NotSerializableExceptions when they're shipped to the Spark Worker.\n+   */\n+\n+  /**\n+   *  workerId is lazy because we want the address of the actual Worker where the code runs - not the Driver's ip address.\n+   *  This makes a difference when running in a cluster.\n+   */\n+  lazy val workerId = InetAddress.getLocalHost.getHostAddress() + \":\" + UUID.randomUUID()"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Aah, that is a good point! Lets keep it then!\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-29T22:11:12Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.net.InetAddress\n+import java.util.UUID\n+import org.apache.spark.Logging\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver.Receiver\n+import com.amazonaws.auth.DefaultAWSCredentialsProviderChain\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import java.nio.ByteBuffer\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Custom AWS Kinesis-specific implementation of Spark Streaming's Receiver.\n+ * This implementation relies on the Kinesis Client Library (KCL) Worker as described here:\n+ * https://github.com/awslabs/amazon-kinesis-client\n+ * This is a custom receiver used with StreamingContext.receiverStream(Receiver) as described here:\n+ * http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+ * Instances of this class will get shipped to the Spark Streaming Workers to run within a Spark Executor.\n+ *\n+ * @param app name\n+ * @param Kinesis stream name\n+ * @param endpoint url of Kinesis service\n+ * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+ *   See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+ * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+ *   The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+ *      or the tip of the stream using InitialPositionInStream.LATEST.\n+ * @param persistence strategy for RDDs and DStreams.\n+ */\n+private[streaming] class KinesisReceiver(\n+  app: String,\n+  stream: String,\n+  endpoint: String,\n+  checkpointIntervalMillis: Long,\n+  initialPositionInStream: InitialPositionInStream,\n+  storageLevel: StorageLevel)\n+  extends Receiver[Array[Byte]](storageLevel) with Logging { receiver =>\n+\n+  /**\n+   *  The lazy val's below will get instantiated in the remote Executor after the closure is shipped to the Spark Worker. \n+   *  These are all lazy because they're from third-party Amazon libraries and are not Serializable.\n+   *  If they're not marked lazy, they will cause NotSerializableExceptions when they're shipped to the Spark Worker.\n+   */\n+\n+  /**\n+   *  workerId is lazy because we want the address of the actual Worker where the code runs - not the Driver's ip address.\n+   *  This makes a difference when running in a cluster.\n+   */\n+  lazy val workerId = InetAddress.getLocalHost.getHostAddress() + \":\" + UUID.randomUUID()"
  }],
  "prId": 1434
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Line longer than 100 characters.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T01:54:06Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.net.InetAddress\n+import java.util.UUID\n+import org.apache.spark.Logging\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver.Receiver\n+import com.amazonaws.auth.DefaultAWSCredentialsProviderChain\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import java.nio.ByteBuffer\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Custom AWS Kinesis-specific implementation of Spark Streaming's Receiver.\n+ * This implementation relies on the Kinesis Client Library (KCL) Worker as described here:\n+ * https://github.com/awslabs/amazon-kinesis-client\n+ * This is a custom receiver used with StreamingContext.receiverStream(Receiver) as described here:\n+ * http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+ * Instances of this class will get shipped to the Spark Streaming Workers to run within a Spark Executor.\n+ *\n+ * @param app name\n+ * @param Kinesis stream name\n+ * @param endpoint url of Kinesis service\n+ * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+ *   See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+ * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+ *   The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+ *      or the tip of the stream using InitialPositionInStream.LATEST.\n+ * @param persistence strategy for RDDs and DStreams.\n+ */\n+private[streaming] class KinesisReceiver(\n+  app: String,\n+  stream: String,\n+  endpoint: String,\n+  checkpointIntervalMillis: Long,\n+  initialPositionInStream: InitialPositionInStream,\n+  storageLevel: StorageLevel)\n+  extends Receiver[Array[Byte]](storageLevel) with Logging { receiver =>\n+\n+  /**\n+   *  The lazy val's below will get instantiated in the remote Executor after the closure is shipped to the Spark Worker. \n+   *  These are all lazy because they're from third-party Amazon libraries and are not Serializable.\n+   *  If they're not marked lazy, they will cause NotSerializableExceptions when they're shipped to the Spark Worker.\n+   */\n+\n+  /**\n+   *  workerId is lazy because we want the address of the actual Worker where the code runs - not the Driver's ip address.\n+   *  This makes a difference when running in a cluster.\n+   */\n+  lazy val workerId = InetAddress.getLocalHost.getHostAddress() + \":\" + UUID.randomUUID()\n+\n+  /**\n+   * This impl uses the DefaultAWSCredentialsProviderChain per the following url:\n+   *    http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/auth/DefaultAWSCredentialsProviderChain.html\n+   *  and searches for credentials in the following order of precedence:\n+   * Environment Variables - AWS_ACCESS_KEY_ID and AWS_SECRET_KEY\n+   * Java System Properties - aws.accessKeyId and aws.secretKey\n+   * Credential profiles file at the default location (~/.aws/credentials) shared by all AWS SDKs and the AWS CLI\n+   * Instance profile credentials delivered through the Amazon EC2 metadata service\n+   */\n+  lazy val credentialsProvider = new DefaultAWSCredentialsProviderChain()\n+\n+  /** Create a KCL config instance. */\n+  lazy val KinesisClientLibConfiguration = new KinesisClientLibConfiguration(app, stream, credentialsProvider, workerId)\n+    .withKinesisEndpoint(endpoint).withInitialPositionInStream(initialPositionInStream).withTaskBackoffTimeMillis(500)\n+\n+  /**\n+   *  RecordProcessorFactory creates impls of IRecordProcessor.\n+   *  IRecordProcessor adapts the KCL to our Spark KinesisReceiver via the IRecordProcessor.processRecords() method.\n+   *  We're using our custom KinesisRecordProcessor in this case.\n+   */\n+  lazy val recordProcessorFactory: IRecordProcessorFactory = new IRecordProcessorFactory {\n+    override def createProcessor: IRecordProcessor = new KinesisRecordProcessor(receiver, workerId, KinesisUtils.createCheckpointState(checkpointIntervalMillis))"
  }],
  "prId": 1434
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Hey, so this is probably not properly documented, but the receivers can be started and stopped multiple time (forexample, when receiver.restart(<Error>) is called). So creating all these vals once using lazy is not the right way, and then calling run/shutdown multiple times is not a good idea. Instead they should be created from scratch every time onStart() is called. \n\nSee the pattern followed by [FlumeReceiver](https://github.com/apache/spark/blob/master/external/flume/src/main/scala/org/apache/spark/streaming/flume/FlumeInputDStream.scala#L139). Should be simple to change.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T02:25:25Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.net.InetAddress\n+import java.util.UUID\n+import org.apache.spark.Logging\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver.Receiver\n+import com.amazonaws.auth.DefaultAWSCredentialsProviderChain\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import java.nio.ByteBuffer\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Custom AWS Kinesis-specific implementation of Spark Streaming's Receiver.\n+ * This implementation relies on the Kinesis Client Library (KCL) Worker as described here:\n+ * https://github.com/awslabs/amazon-kinesis-client\n+ * This is a custom receiver used with StreamingContext.receiverStream(Receiver) as described here:\n+ * http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+ * Instances of this class will get shipped to the Spark Streaming Workers to run within a Spark Executor.\n+ *\n+ * @param app name\n+ * @param Kinesis stream name\n+ * @param endpoint url of Kinesis service\n+ * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+ *   See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+ * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+ *   The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+ *      or the tip of the stream using InitialPositionInStream.LATEST.\n+ * @param persistence strategy for RDDs and DStreams.\n+ */\n+private[streaming] class KinesisReceiver(\n+  app: String,\n+  stream: String,\n+  endpoint: String,\n+  checkpointIntervalMillis: Long,\n+  initialPositionInStream: InitialPositionInStream,\n+  storageLevel: StorageLevel)\n+  extends Receiver[Array[Byte]](storageLevel) with Logging { receiver =>\n+\n+  /**\n+   *  The lazy val's below will get instantiated in the remote Executor after the closure is shipped to the Spark Worker. \n+   *  These are all lazy because they're from third-party Amazon libraries and are not Serializable.\n+   *  If they're not marked lazy, they will cause NotSerializableExceptions when they're shipped to the Spark Worker.\n+   */\n+\n+  /**\n+   *  workerId is lazy because we want the address of the actual Worker where the code runs - not the Driver's ip address.\n+   *  This makes a difference when running in a cluster.\n+   */\n+  lazy val workerId = InetAddress.getLocalHost.getHostAddress() + \":\" + UUID.randomUUID()\n+\n+  /**\n+   * This impl uses the DefaultAWSCredentialsProviderChain per the following url:\n+   *    http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/auth/DefaultAWSCredentialsProviderChain.html\n+   *  and searches for credentials in the following order of precedence:\n+   * Environment Variables - AWS_ACCESS_KEY_ID and AWS_SECRET_KEY\n+   * Java System Properties - aws.accessKeyId and aws.secretKey\n+   * Credential profiles file at the default location (~/.aws/credentials) shared by all AWS SDKs and the AWS CLI\n+   * Instance profile credentials delivered through the Amazon EC2 metadata service\n+   */\n+  lazy val credentialsProvider = new DefaultAWSCredentialsProviderChain()\n+\n+  /** Create a KCL config instance. */\n+  lazy val KinesisClientLibConfiguration = new KinesisClientLibConfiguration(app, stream, credentialsProvider, workerId)\n+    .withKinesisEndpoint(endpoint).withInitialPositionInStream(initialPositionInStream).withTaskBackoffTimeMillis(500)"
  }, {
    "author": {
      "login": "cfregly"
    },
    "body": "yeah, this is a little awkward.  the problem is that these Kinesis classes are not Serializable, so when they get shipped to the Spark Worker, i get the dreaded NotSerializableException.\n\nthis is why they need to be lazy.  if i create them each time onStart() is called, i'll lose the laziness.\n\nany suggestions for a workaround?\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T22:06:15Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.net.InetAddress\n+import java.util.UUID\n+import org.apache.spark.Logging\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver.Receiver\n+import com.amazonaws.auth.DefaultAWSCredentialsProviderChain\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import java.nio.ByteBuffer\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Custom AWS Kinesis-specific implementation of Spark Streaming's Receiver.\n+ * This implementation relies on the Kinesis Client Library (KCL) Worker as described here:\n+ * https://github.com/awslabs/amazon-kinesis-client\n+ * This is a custom receiver used with StreamingContext.receiverStream(Receiver) as described here:\n+ * http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+ * Instances of this class will get shipped to the Spark Streaming Workers to run within a Spark Executor.\n+ *\n+ * @param app name\n+ * @param Kinesis stream name\n+ * @param endpoint url of Kinesis service\n+ * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+ *   See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+ * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+ *   The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+ *      or the tip of the stream using InitialPositionInStream.LATEST.\n+ * @param persistence strategy for RDDs and DStreams.\n+ */\n+private[streaming] class KinesisReceiver(\n+  app: String,\n+  stream: String,\n+  endpoint: String,\n+  checkpointIntervalMillis: Long,\n+  initialPositionInStream: InitialPositionInStream,\n+  storageLevel: StorageLevel)\n+  extends Receiver[Array[Byte]](storageLevel) with Logging { receiver =>\n+\n+  /**\n+   *  The lazy val's below will get instantiated in the remote Executor after the closure is shipped to the Spark Worker. \n+   *  These are all lazy because they're from third-party Amazon libraries and are not Serializable.\n+   *  If they're not marked lazy, they will cause NotSerializableExceptions when they're shipped to the Spark Worker.\n+   */\n+\n+  /**\n+   *  workerId is lazy because we want the address of the actual Worker where the code runs - not the Driver's ip address.\n+   *  This makes a difference when running in a cluster.\n+   */\n+  lazy val workerId = InetAddress.getLocalHost.getHostAddress() + \":\" + UUID.randomUUID()\n+\n+  /**\n+   * This impl uses the DefaultAWSCredentialsProviderChain per the following url:\n+   *    http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/auth/DefaultAWSCredentialsProviderChain.html\n+   *  and searches for credentials in the following order of precedence:\n+   * Environment Variables - AWS_ACCESS_KEY_ID and AWS_SECRET_KEY\n+   * Java System Properties - aws.accessKeyId and aws.secretKey\n+   * Credential profiles file at the default location (~/.aws/credentials) shared by all AWS SDKs and the AWS CLI\n+   * Instance profile credentials delivered through the Amazon EC2 metadata service\n+   */\n+  lazy val credentialsProvider = new DefaultAWSCredentialsProviderChain()\n+\n+  /** Create a KCL config instance. */\n+  lazy val KinesisClientLibConfiguration = new KinesisClientLibConfiguration(app, stream, credentialsProvider, workerId)\n+    .withKinesisEndpoint(endpoint).withInitialPositionInStream(initialPositionInStream).withTaskBackoffTimeMillis(500)"
  }, {
    "author": {
      "login": "cfregly"
    },
    "body": "ah, i just looked at FlumeReceiver.  i see the workaround.  lemme code it up.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T22:16:35Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.net.InetAddress\n+import java.util.UUID\n+import org.apache.spark.Logging\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver.Receiver\n+import com.amazonaws.auth.DefaultAWSCredentialsProviderChain\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import java.nio.ByteBuffer\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Custom AWS Kinesis-specific implementation of Spark Streaming's Receiver.\n+ * This implementation relies on the Kinesis Client Library (KCL) Worker as described here:\n+ * https://github.com/awslabs/amazon-kinesis-client\n+ * This is a custom receiver used with StreamingContext.receiverStream(Receiver) as described here:\n+ * http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+ * Instances of this class will get shipped to the Spark Streaming Workers to run within a Spark Executor.\n+ *\n+ * @param app name\n+ * @param Kinesis stream name\n+ * @param endpoint url of Kinesis service\n+ * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+ *   See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+ * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+ *   The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+ *      or the tip of the stream using InitialPositionInStream.LATEST.\n+ * @param persistence strategy for RDDs and DStreams.\n+ */\n+private[streaming] class KinesisReceiver(\n+  app: String,\n+  stream: String,\n+  endpoint: String,\n+  checkpointIntervalMillis: Long,\n+  initialPositionInStream: InitialPositionInStream,\n+  storageLevel: StorageLevel)\n+  extends Receiver[Array[Byte]](storageLevel) with Logging { receiver =>\n+\n+  /**\n+   *  The lazy val's below will get instantiated in the remote Executor after the closure is shipped to the Spark Worker. \n+   *  These are all lazy because they're from third-party Amazon libraries and are not Serializable.\n+   *  If they're not marked lazy, they will cause NotSerializableExceptions when they're shipped to the Spark Worker.\n+   */\n+\n+  /**\n+   *  workerId is lazy because we want the address of the actual Worker where the code runs - not the Driver's ip address.\n+   *  This makes a difference when running in a cluster.\n+   */\n+  lazy val workerId = InetAddress.getLocalHost.getHostAddress() + \":\" + UUID.randomUUID()\n+\n+  /**\n+   * This impl uses the DefaultAWSCredentialsProviderChain per the following url:\n+   *    http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/auth/DefaultAWSCredentialsProviderChain.html\n+   *  and searches for credentials in the following order of precedence:\n+   * Environment Variables - AWS_ACCESS_KEY_ID and AWS_SECRET_KEY\n+   * Java System Properties - aws.accessKeyId and aws.secretKey\n+   * Credential profiles file at the default location (~/.aws/credentials) shared by all AWS SDKs and the AWS CLI\n+   * Instance profile credentials delivered through the Amazon EC2 metadata service\n+   */\n+  lazy val credentialsProvider = new DefaultAWSCredentialsProviderChain()\n+\n+  /** Create a KCL config instance. */\n+  lazy val KinesisClientLibConfiguration = new KinesisClientLibConfiguration(app, stream, credentialsProvider, workerId)\n+    .withKinesisEndpoint(endpoint).withInitialPositionInStream(initialPositionInStream).withTaskBackoffTimeMillis(500)"
  }],
  "prId": 1434
}]