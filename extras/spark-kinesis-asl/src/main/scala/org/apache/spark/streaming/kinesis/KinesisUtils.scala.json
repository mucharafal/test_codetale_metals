[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Can you mark this as Experimental API? It is a class annotation, search through spark for \"@ExperimentalAPI\" to see how its used. Basically we want to make sure that people understand that there is a small chance that the interfaces my changes in the future. \n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T00:17:06Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {"
  }, {
    "author": {
      "login": "cfregly"
    },
    "body": "done\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T22:49:13Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {"
  }],
  "prId": 1434
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "`@param initialPositionInStream` is incorrect in the docs.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T00:26:23Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return ReceiverInputDStream[Array[Byte]]\n+   */\n+  def createStream(\n+    ssc: StreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): ReceiverInputDStream[Array[Byte]] = {\n+\n+    ssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create a Java-friendly InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param JavaStreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream."
  }, {
    "author": {
      "login": "cfregly"
    },
    "body": "fixed\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T22:49:18Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return ReceiverInputDStream[Array[Byte]]\n+   */\n+  def createStream(\n+    ssc: StreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): ReceiverInputDStream[Array[Byte]] = {\n+\n+    ssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create a Java-friendly InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param JavaStreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream."
  }],
  "prId": 1434
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "`@param initialPositionInStream` is incorrect in the docs.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T00:26:58Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once."
  }, {
    "author": {
      "login": "cfregly"
    },
    "body": "fixed\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T22:49:25Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once."
  }],
  "prId": 1434
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Please follow the convention of other XYZUtils, where the Java ones are named as createStream as well. Keeps things consistent across Scala and Java.\n\nAlso, please add Java unit test to make sure that this function, along with its variations of default params, can be called from Java. See Flume Java units to understand how this is done by just instantiating streams and not actually running them.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T00:29:33Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return ReceiverInputDStream[Array[Byte]]\n+   */\n+  def createStream(\n+    ssc: StreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): ReceiverInputDStream[Array[Byte]] = {\n+\n+    ssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create a Java-friendly InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param JavaStreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return JavaReceiverInputDStream[Array[Byte]]\n+   */\n+  def createJavaStream("
  }, {
    "author": {
      "login": "cfregly"
    },
    "body": "created the junit test\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T23:08:11Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return ReceiverInputDStream[Array[Byte]]\n+   */\n+  def createStream(\n+    ssc: StreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): ReceiverInputDStream[Array[Byte]] = {\n+\n+    ssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create a Java-friendly InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param JavaStreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return JavaReceiverInputDStream[Array[Byte]]\n+   */\n+  def createJavaStream("
  }],
  "prId": 1434
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "What is the point of this function? Seems like this is only used in unit-tests? In which case shouldnt this be in the test classes only? Either way, if the user is not expected to use this function directly, this is should not be exposed. \n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T00:46:57Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return ReceiverInputDStream[Array[Byte]]\n+   */\n+  def createStream(\n+    ssc: StreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): ReceiverInputDStream[Array[Byte]] = {\n+\n+    ssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create a Java-friendly InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param JavaStreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return JavaReceiverInputDStream[Array[Byte]]\n+   */\n+  def createJavaStream(\n+    jssc: JavaStreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): JavaReceiverInputDStream[Array[Byte]] = {\n+\n+    jssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create checkpoint state using the existing system clock\n+   * @param checkpointIntervalMillis\n+   */\n+  def createCheckpointState(checkpointIntervalMillis: Long): CheckpointState = {\n+    new CheckpointState(checkpointIntervalMillis)\n+  }\n+\n+  /**\n+   * Retry the given amount of times with a random backoff time (millis) less than the given maxBackOffMillis\n+   *\n+   * @param expression expression to evalute\n+   * @param numRetriesLeft number of retries left\n+   * @param maxBackOffMillis: max millis between retries\n+   *\n+   * @return Evaluation of the given expression\n+   * @throws Unretryable exception, unexpected exception,\n+   *  or any exception that persists after numRetriesLeft reaches 0\n+   */\n+  @annotation.tailrec\n+  def retry[T](expression: => T, numRetriesLeft: Int, maxBackOffMillis: Int): T = {"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Actually, I correct myself. It is being used in the KinesisReceiver. However, this should not be exposed to the user. In fact, its better to keep this user facing class clean, and put this in the KinesisReceiver object, as that is the main user of retry.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T02:31:44Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return ReceiverInputDStream[Array[Byte]]\n+   */\n+  def createStream(\n+    ssc: StreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): ReceiverInputDStream[Array[Byte]] = {\n+\n+    ssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create a Java-friendly InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param JavaStreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return JavaReceiverInputDStream[Array[Byte]]\n+   */\n+  def createJavaStream(\n+    jssc: JavaStreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): JavaReceiverInputDStream[Array[Byte]] = {\n+\n+    jssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create checkpoint state using the existing system clock\n+   * @param checkpointIntervalMillis\n+   */\n+  def createCheckpointState(checkpointIntervalMillis: Long): CheckpointState = {\n+    new CheckpointState(checkpointIntervalMillis)\n+  }\n+\n+  /**\n+   * Retry the given amount of times with a random backoff time (millis) less than the given maxBackOffMillis\n+   *\n+   * @param expression expression to evalute\n+   * @param numRetriesLeft number of retries left\n+   * @param maxBackOffMillis: max millis between retries\n+   *\n+   * @return Evaluation of the given expression\n+   * @throws Unretryable exception, unexpected exception,\n+   *  or any exception that persists after numRetriesLeft reaches 0\n+   */\n+  @annotation.tailrec\n+  def retry[T](expression: => T, numRetriesLeft: Int, maxBackOffMillis: Int): T = {"
  }, {
    "author": {
      "login": "cfregly"
    },
    "body": "ok, i've moved this method to a private helper class.  it's a static method, so from a testability standpoint, it's awkward to have this part of a non-static class such as KinesisReceiver.  \n\notherwise, i would need to instantiate a KinesisReceiver with a bunch of mocks just to test this method.\n\nthis seems like a good compromise, but let me know if you feel otherwise.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-31T00:19:19Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return ReceiverInputDStream[Array[Byte]]\n+   */\n+  def createStream(\n+    ssc: StreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): ReceiverInputDStream[Array[Byte]] = {\n+\n+    ssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create a Java-friendly InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param JavaStreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return JavaReceiverInputDStream[Array[Byte]]\n+   */\n+  def createJavaStream(\n+    jssc: JavaStreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): JavaReceiverInputDStream[Array[Byte]] = {\n+\n+    jssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create checkpoint state using the existing system clock\n+   * @param checkpointIntervalMillis\n+   */\n+  def createCheckpointState(checkpointIntervalMillis: Long): CheckpointState = {\n+    new CheckpointState(checkpointIntervalMillis)\n+  }\n+\n+  /**\n+   * Retry the given amount of times with a random backoff time (millis) less than the given maxBackOffMillis\n+   *\n+   * @param expression expression to evalute\n+   * @param numRetriesLeft number of retries left\n+   * @param maxBackOffMillis: max millis between retries\n+   *\n+   * @return Evaluation of the given expression\n+   * @throws Unretryable exception, unexpected exception,\n+   *  or any exception that persists after numRetriesLeft reaches 0\n+   */\n+  @annotation.tailrec\n+  def retry[T](expression: => T, numRetriesLeft: Int, maxBackOffMillis: Int): T = {"
  }],
  "prId": 1434
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "What is the purpose of this? When does a checkpoint need to be created manually by the user.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T02:31:05Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return ReceiverInputDStream[Array[Byte]]\n+   */\n+  def createStream(\n+    ssc: StreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): ReceiverInputDStream[Array[Byte]] = {\n+\n+    ssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create a Java-friendly InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param JavaStreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return JavaReceiverInputDStream[Array[Byte]]\n+   */\n+  def createJavaStream(\n+    jssc: JavaStreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): JavaReceiverInputDStream[Array[Byte]] = {\n+\n+    jssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create checkpoint state using the existing system clock\n+   * @param checkpointIntervalMillis\n+   */\n+  def createCheckpointState(checkpointIntervalMillis: Long): CheckpointState = {\n+    new CheckpointState(checkpointIntervalMillis)"
  }, {
    "author": {
      "login": "cfregly"
    },
    "body": "i removed this helper method as it is only used in 1 place.  \n\nthis is passed in to KinesisRecordProcessor from the KinesisReceiver.  it's exposed for testability/mockability as demonstrated in the KinesisReceiverSuite of Scala tests. (ie. lines 81, 83, 86)\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T22:14:32Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return ReceiverInputDStream[Array[Byte]]\n+   */\n+  def createStream(\n+    ssc: StreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): ReceiverInputDStream[Array[Byte]] = {\n+\n+    ssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create a Java-friendly InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param JavaStreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return JavaReceiverInputDStream[Array[Byte]]\n+   */\n+  def createJavaStream(\n+    jssc: JavaStreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): JavaReceiverInputDStream[Array[Byte]] = {\n+\n+    jssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create checkpoint state using the existing system clock\n+   * @param checkpointIntervalMillis\n+   */\n+  def createCheckpointState(checkpointIntervalMillis: Long): CheckpointState = {\n+    new CheckpointState(checkpointIntervalMillis)"
  }],
  "prId": 1434
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Incorrect formatting.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T07:09:17Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return ReceiverInputDStream[Array[Byte]]\n+   */\n+  def createStream(\n+    ssc: StreamingContext,"
  }],
  "prId": 1434
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "incorrect formatting.\n",
    "commit": "47745816b21d7d2255a98283e3055a5a2a397a27",
    "createdAt": "2014-07-30T07:09:33Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.JavaReceiverInputDStream\n+import org.apache.spark.streaming.api.java.JavaStreamingContext\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.KinesisClientLibDependencyException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import org.apache.spark.Logging\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import scala.util.Random\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.util.ManualClock\n+import org.apache.spark.streaming.util.Clock\n+import org.apache.spark.streaming.util.SystemClock\n+\n+/**\n+ * Facade to create the Scala-based or Java-based streams.\n+ * Also, contains a reusable utility methods.\n+ */\n+object KinesisUtils extends Logging {\n+  /**\n+   * Create an InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param StreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return ReceiverInputDStream[Array[Byte]]\n+   */\n+  def createStream(\n+    ssc: StreamingContext,\n+    app: String,\n+    stream: String,\n+    endpoint: String,\n+    checkpointIntervalMillis: Long,\n+    initialPositionInStream: InitialPositionInStream = InitialPositionInStream.TRIM_HORIZON,\n+    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_2): ReceiverInputDStream[Array[Byte]] = {\n+\n+    ssc.receiverStream(new KinesisReceiver(app, stream, endpoint, checkpointIntervalMillis, initialPositionInStream, storageLevel))\n+  }\n+\n+  /**\n+   * Create a Java-friendly InputDStream that pulls messages from a Kinesis stream.\n+   *\n+   * @param JavaStreamingContext object\n+   * @param app name\n+   * @param stream name\n+   * @param endpoint\n+   * @param checkpoint interval (millis) for Kinesis checkpointing (not Spark checkpointing).\n+   * See the Kinesis Spark Streaming documentation for more details on the different types of checkpoints.\n+   * The default is TRIM_HORIZON to avoid potential data loss.  However, this presents the risk of processing records more than once.\n+   * @param in the absence of Kinesis checkpoint info, this is the worker's initial starting position in the stream.\n+   * The values are either the beginning of the stream per Kinesis' limit of 24 hours (InitialPositionInStream.TRIM_HORIZON)\n+   *       or the tip of the stream using InitialPositionInStream.LATEST.\n+   * The default is StorageLevel.MEMORY_AND_DISK_2 which replicates in-memory and on-disk to 2 nodes total (primary and secondary)\n+   *\n+   * @return JavaReceiverInputDStream[Array[Byte]]\n+   */\n+  def createJavaStream(\n+    jssc: JavaStreamingContext,\n+    app: String,"
  }],
  "prId": 1434
}]