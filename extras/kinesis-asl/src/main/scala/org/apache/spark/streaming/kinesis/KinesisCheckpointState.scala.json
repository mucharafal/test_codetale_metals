[{
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "This needs to be shutdown. Otherwise, it will leak a thread. BTW, it's better to add name and use daemon threads. You can use `ThreadUtils.newDaemonSingleThreadScheduledExecutor` to create a named one.\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-03T22:18:25Z",
    "diffHunk": "@@ -16,39 +16,77 @@\n  */\n package org.apache.spark.streaming.kinesis\n \n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n import org.apache.spark.Logging\n import org.apache.spark.streaming.Duration\n-import org.apache.spark.util.{Clock, ManualClock, SystemClock}\n \n /**\n- * This is a helper class for managing checkpoint clocks.\n+ * This is a helper class for managing Kinesis checkpointing.\n  *\n- * @param checkpointInterval\n- * @param currentClock.  Default to current SystemClock if none is passed in (mocking purposes)\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ * @param shardId The shard this worker was consuming data from\n  */\n-private[kinesis] class KinesisCheckpointState(\n+private[kinesis] class KinesisCheckpointState[T](\n+    receiver: KinesisReceiver[T],\n     checkpointInterval: Duration,\n-    currentClock: Clock = new SystemClock())\n-  extends Logging {\n+    workerId: String,\n+    shardId: String) extends Logging {\n \n-  /* Initialize the checkpoint clock using the given currentClock + checkpointInterval millis */\n-  val checkpointClock = new ManualClock()\n-  checkpointClock.setTime(currentClock.getTimeMillis() + checkpointInterval.milliseconds)\n+  private var _checkpointer: Option[IRecordProcessorCheckpointer] = None\n \n-  /**\n-   * Check if it's time to checkpoint based on the current time and the derived time\n-   *   for the next checkpoint\n-   *\n-   * @return true if it's time to checkpoint\n-   */\n-  def shouldCheckpoint(): Boolean = {\n-    new SystemClock().getTimeMillis() > checkpointClock.getTimeMillis()\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one. */\n+  def setCheckpointer(checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    _checkpointer = Option(checkpointer)\n+  }\n+\n+  /** Perform the checkpoint */\n+  private def checkpoint(checkpointer: Option[IRecordProcessorCheckpointer]): Unit = {\n+    // if this method throws an exception, then the scheduled task will not run again\n+    try {\n+      checkpointer.foreach { cp =>\n+        receiver.getLatestSeqNumToCheckpoint(shardId).foreach { latestSeqNum =>\n+          /* Perform the checkpoint */\n+          KinesisRecordProcessor.retryRandom(cp.checkpoint(latestSeqNum), 4, 100)\n+\n+          logDebug(s\"Checkpoint:  WorkerId $workerId completed checkpoint at sequence number\" +\n+            s\" $latestSeqNum for shardId $shardId\")\n+        }\n+      }\n+    } catch {\n+      case NonFatal(e) =>\n+        logError(\"Failed to checkpoint to DynamoDB.\", e)\n+    }\n+  }\n+\n+  /** Start the checkpointer thread with the given checkpoint duration. */\n+  private def startCheckpointerThread(): ScheduledFuture[_] = {\n+    val period = checkpointInterval.milliseconds\n+    val ex = new ScheduledThreadPoolExecutor(1)"
  }],
  "prId": 9421
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "What will happen if we use an old `IRecordProcessorCheckpointer` to checkpoint?\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-03T22:36:49Z",
    "diffHunk": "@@ -16,39 +16,77 @@\n  */\n package org.apache.spark.streaming.kinesis\n \n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n import org.apache.spark.Logging\n import org.apache.spark.streaming.Duration\n-import org.apache.spark.util.{Clock, ManualClock, SystemClock}\n \n /**\n- * This is a helper class for managing checkpoint clocks.\n+ * This is a helper class for managing Kinesis checkpointing.\n  *\n- * @param checkpointInterval\n- * @param currentClock.  Default to current SystemClock if none is passed in (mocking purposes)\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ * @param shardId The shard this worker was consuming data from\n  */\n-private[kinesis] class KinesisCheckpointState(\n+private[kinesis] class KinesisCheckpointState[T](\n+    receiver: KinesisReceiver[T],\n     checkpointInterval: Duration,\n-    currentClock: Clock = new SystemClock())\n-  extends Logging {\n+    workerId: String,\n+    shardId: String) extends Logging {\n \n-  /* Initialize the checkpoint clock using the given currentClock + checkpointInterval millis */\n-  val checkpointClock = new ManualClock()\n-  checkpointClock.setTime(currentClock.getTimeMillis() + checkpointInterval.milliseconds)\n+  private var _checkpointer: Option[IRecordProcessorCheckpointer] = None\n \n-  /**\n-   * Check if it's time to checkpoint based on the current time and the derived time\n-   *   for the next checkpoint\n-   *\n-   * @return true if it's time to checkpoint\n-   */\n-  def shouldCheckpoint(): Boolean = {\n-    new SystemClock().getTimeMillis() > checkpointClock.getTimeMillis()\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one. */\n+  def setCheckpointer(checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    _checkpointer = Option(checkpointer)\n+  }\n+\n+  /** Perform the checkpoint */\n+  private def checkpoint(checkpointer: Option[IRecordProcessorCheckpointer]): Unit = {\n+    // if this method throws an exception, then the scheduled task will not run again\n+    try {\n+      checkpointer.foreach { cp =>"
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "It should be okay\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-05T01:44:13Z",
    "diffHunk": "@@ -16,39 +16,77 @@\n  */\n package org.apache.spark.streaming.kinesis\n \n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n import org.apache.spark.Logging\n import org.apache.spark.streaming.Duration\n-import org.apache.spark.util.{Clock, ManualClock, SystemClock}\n \n /**\n- * This is a helper class for managing checkpoint clocks.\n+ * This is a helper class for managing Kinesis checkpointing.\n  *\n- * @param checkpointInterval\n- * @param currentClock.  Default to current SystemClock if none is passed in (mocking purposes)\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ * @param shardId The shard this worker was consuming data from\n  */\n-private[kinesis] class KinesisCheckpointState(\n+private[kinesis] class KinesisCheckpointState[T](\n+    receiver: KinesisReceiver[T],\n     checkpointInterval: Duration,\n-    currentClock: Clock = new SystemClock())\n-  extends Logging {\n+    workerId: String,\n+    shardId: String) extends Logging {\n \n-  /* Initialize the checkpoint clock using the given currentClock + checkpointInterval millis */\n-  val checkpointClock = new ManualClock()\n-  checkpointClock.setTime(currentClock.getTimeMillis() + checkpointInterval.milliseconds)\n+  private var _checkpointer: Option[IRecordProcessorCheckpointer] = None\n \n-  /**\n-   * Check if it's time to checkpoint based on the current time and the derived time\n-   *   for the next checkpoint\n-   *\n-   * @return true if it's time to checkpoint\n-   */\n-  def shouldCheckpoint(): Boolean = {\n-    new SystemClock().getTimeMillis() > checkpointClock.getTimeMillis()\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one. */\n+  def setCheckpointer(checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    _checkpointer = Option(checkpointer)\n+  }\n+\n+  /** Perform the checkpoint */\n+  private def checkpoint(checkpointer: Option[IRecordProcessorCheckpointer]): Unit = {\n+    // if this method throws an exception, then the scheduled task will not run again\n+    try {\n+      checkpointer.foreach { cp =>"
  }],
  "prId": 9421
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "This should be `volatile`\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-03T22:37:02Z",
    "diffHunk": "@@ -16,39 +16,77 @@\n  */\n package org.apache.spark.streaming.kinesis\n \n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n import org.apache.spark.Logging\n import org.apache.spark.streaming.Duration\n-import org.apache.spark.util.{Clock, ManualClock, SystemClock}\n \n /**\n- * This is a helper class for managing checkpoint clocks.\n+ * This is a helper class for managing Kinesis checkpointing.\n  *\n- * @param checkpointInterval\n- * @param currentClock.  Default to current SystemClock if none is passed in (mocking purposes)\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ * @param shardId The shard this worker was consuming data from\n  */\n-private[kinesis] class KinesisCheckpointState(\n+private[kinesis] class KinesisCheckpointState[T](\n+    receiver: KinesisReceiver[T],\n     checkpointInterval: Duration,\n-    currentClock: Clock = new SystemClock())\n-  extends Logging {\n+    workerId: String,\n+    shardId: String) extends Logging {\n \n-  /* Initialize the checkpoint clock using the given currentClock + checkpointInterval millis */\n-  val checkpointClock = new ManualClock()\n-  checkpointClock.setTime(currentClock.getTimeMillis() + checkpointInterval.milliseconds)\n+  private var _checkpointer: Option[IRecordProcessorCheckpointer] = None"
  }],
  "prId": 9421
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: extra line\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-04T09:20:51Z",
    "diffHunk": "@@ -16,39 +16,77 @@\n  */\n package org.apache.spark.streaming.kinesis\n \n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n import org.apache.spark.Logging\n import org.apache.spark.streaming.Duration\n-import org.apache.spark.util.{Clock, ManualClock, SystemClock}\n \n /**\n- * This is a helper class for managing checkpoint clocks.\n+ * This is a helper class for managing Kinesis checkpointing.\n  *\n- * @param checkpointInterval\n- * @param currentClock.  Default to current SystemClock if none is passed in (mocking purposes)\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ * @param shardId The shard this worker was consuming data from\n  */\n-private[kinesis] class KinesisCheckpointState(\n+private[kinesis] class KinesisCheckpointState[T](\n+    receiver: KinesisReceiver[T],\n     checkpointInterval: Duration,\n-    currentClock: Clock = new SystemClock())\n-  extends Logging {\n+    workerId: String,\n+    shardId: String) extends Logging {\n \n-  /* Initialize the checkpoint clock using the given currentClock + checkpointInterval millis */\n-  val checkpointClock = new ManualClock()\n-  checkpointClock.setTime(currentClock.getTimeMillis() + checkpointInterval.milliseconds)\n+  private var _checkpointer: Option[IRecordProcessorCheckpointer] = None\n \n-  /**\n-   * Check if it's time to checkpoint based on the current time and the derived time\n-   *   for the next checkpoint\n-   *\n-   * @return true if it's time to checkpoint\n-   */\n-  def shouldCheckpoint(): Boolean = {\n-    new SystemClock().getTimeMillis() > checkpointClock.getTimeMillis()\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one. */\n+  def setCheckpointer(checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    _checkpointer = Option(checkpointer)\n+  }\n+\n+  /** Perform the checkpoint */\n+  private def checkpoint(checkpointer: Option[IRecordProcessorCheckpointer]): Unit = {\n+    // if this method throws an exception, then the scheduled task will not run again\n+    try {\n+      checkpointer.foreach { cp =>\n+        receiver.getLatestSeqNumToCheckpoint(shardId).foreach { latestSeqNum =>\n+          /* Perform the checkpoint */\n+          KinesisRecordProcessor.retryRandom(cp.checkpoint(latestSeqNum), 4, 100)\n+"
  }],
  "prId": 9421
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "You dont need T in KinesisCheckpointState here. You can take reference to the receiver as KinesisReceiver[_]\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-04T09:25:21Z",
    "diffHunk": "@@ -16,39 +16,77 @@\n  */\n package org.apache.spark.streaming.kinesis\n \n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n import org.apache.spark.Logging\n import org.apache.spark.streaming.Duration\n-import org.apache.spark.util.{Clock, ManualClock, SystemClock}\n \n /**\n- * This is a helper class for managing checkpoint clocks.\n+ * This is a helper class for managing Kinesis checkpointing.\n  *\n- * @param checkpointInterval\n- * @param currentClock.  Default to current SystemClock if none is passed in (mocking purposes)\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ * @param shardId The shard this worker was consuming data from\n  */\n-private[kinesis] class KinesisCheckpointState(\n+private[kinesis] class KinesisCheckpointState[T](\n+    receiver: KinesisReceiver[T],"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Also could rename this to KinesisCheckpointer, to better reflect what this is doing.\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-04T09:26:09Z",
    "diffHunk": "@@ -16,39 +16,77 @@\n  */\n package org.apache.spark.streaming.kinesis\n \n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n import org.apache.spark.Logging\n import org.apache.spark.streaming.Duration\n-import org.apache.spark.util.{Clock, ManualClock, SystemClock}\n \n /**\n- * This is a helper class for managing checkpoint clocks.\n+ * This is a helper class for managing Kinesis checkpointing.\n  *\n- * @param checkpointInterval\n- * @param currentClock.  Default to current SystemClock if none is passed in (mocking purposes)\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ * @param shardId The shard this worker was consuming data from\n  */\n-private[kinesis] class KinesisCheckpointState(\n+private[kinesis] class KinesisCheckpointState[T](\n+    receiver: KinesisReceiver[T],"
  }],
  "prId": 9421
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Why pass the checkpoint as an option when the class already has reference to it in `_checkpointer`?\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-04T09:49:00Z",
    "diffHunk": "@@ -16,39 +16,77 @@\n  */\n package org.apache.spark.streaming.kinesis\n \n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n import org.apache.spark.Logging\n import org.apache.spark.streaming.Duration\n-import org.apache.spark.util.{Clock, ManualClock, SystemClock}\n \n /**\n- * This is a helper class for managing checkpoint clocks.\n+ * This is a helper class for managing Kinesis checkpointing.\n  *\n- * @param checkpointInterval\n- * @param currentClock.  Default to current SystemClock if none is passed in (mocking purposes)\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ * @param shardId The shard this worker was consuming data from\n  */\n-private[kinesis] class KinesisCheckpointState(\n+private[kinesis] class KinesisCheckpointState[T](\n+    receiver: KinesisReceiver[T],\n     checkpointInterval: Duration,\n-    currentClock: Clock = new SystemClock())\n-  extends Logging {\n+    workerId: String,\n+    shardId: String) extends Logging {\n \n-  /* Initialize the checkpoint clock using the given currentClock + checkpointInterval millis */\n-  val checkpointClock = new ManualClock()\n-  checkpointClock.setTime(currentClock.getTimeMillis() + checkpointInterval.milliseconds)\n+  private var _checkpointer: Option[IRecordProcessorCheckpointer] = None\n \n-  /**\n-   * Check if it's time to checkpoint based on the current time and the derived time\n-   *   for the next checkpoint\n-   *\n-   * @return true if it's time to checkpoint\n-   */\n-  def shouldCheckpoint(): Boolean = {\n-    new SystemClock().getTimeMillis() > checkpointClock.getTimeMillis()\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one. */\n+  def setCheckpointer(checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    _checkpointer = Option(checkpointer)\n+  }\n+\n+  /** Perform the checkpoint */\n+  private def checkpoint(checkpointer: Option[IRecordProcessorCheckpointer]): Unit = {"
  }],
  "prId": 9421
}]