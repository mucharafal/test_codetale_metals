[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Why do we need to do two different things. Unlike the usual checkpointing by usual IRecordProcessor implementations which checkpoint as soon as the data is received, we checkpoint stuff that has been received AND stored in Spark reliably. If some data has already been stored, then isnt it just strictly better to checkpoint corresponding offset to DynamoDB in any condition? \n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-05T22:59:44Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.Duration\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * This is a helper class for managing Kinesis checkpointing.\n+ *\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ */\n+private[kinesis] class KinesisCheckpointer(\n+    receiver: KinesisReceiver[_],\n+    checkpointInterval: Duration,\n+    workerId: String) extends Logging {\n+\n+  // a map from shardId's to checkpointers\n+  private val checkpointers = new ConcurrentHashMap[String, IRecordProcessorCheckpointer]()\n+\n+  private val lastCheckpointedSeqNums = new ConcurrentHashMap[String, String]()\n+\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one for the given shardId. */\n+  def setCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpointers.put(shardId, checkpointer)\n+  }\n+\n+  /**\n+   * Stop tracking the specified shardId.\n+   *\n+   * If a checkpointer is provided, e.g. on IRecordProcessor.shutdown [[ShutdownReason.TERMINATE]],",
    "line": 60
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "I'm worried that the IRecordProcessorCheckpointers may correspond to the wrong instances during, after resharding. Therefore I would like to use the latest possible checkpointer as much as possible\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-05T23:08:26Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.Duration\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * This is a helper class for managing Kinesis checkpointing.\n+ *\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ */\n+private[kinesis] class KinesisCheckpointer(\n+    receiver: KinesisReceiver[_],\n+    checkpointInterval: Duration,\n+    workerId: String) extends Logging {\n+\n+  // a map from shardId's to checkpointers\n+  private val checkpointers = new ConcurrentHashMap[String, IRecordProcessorCheckpointer]()\n+\n+  private val lastCheckpointedSeqNums = new ConcurrentHashMap[String, String]()\n+\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one for the given shardId. */\n+  def setCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpointers.put(shardId, checkpointer)\n+  }\n+\n+  /**\n+   * Stop tracking the specified shardId.\n+   *\n+   * If a checkpointer is provided, e.g. on IRecordProcessor.shutdown [[ShutdownReason.TERMINATE]],",
    "line": 60
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "This reasoning in the comment is not relevant any more. Please update\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-09T01:48:32Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.Duration\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * This is a helper class for managing Kinesis checkpointing.\n+ *\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ */\n+private[kinesis] class KinesisCheckpointer(\n+    receiver: KinesisReceiver[_],\n+    checkpointInterval: Duration,\n+    workerId: String) extends Logging {\n+\n+  // a map from shardId's to checkpointers\n+  private val checkpointers = new ConcurrentHashMap[String, IRecordProcessorCheckpointer]()\n+\n+  private val lastCheckpointedSeqNums = new ConcurrentHashMap[String, String]()\n+\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one for the given shardId. */\n+  def setCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpointers.put(shardId, checkpointer)\n+  }\n+\n+  /**\n+   * Stop tracking the specified shardId.\n+   *\n+   * If a checkpointer is provided, e.g. on IRecordProcessor.shutdown [[ShutdownReason.TERMINATE]],",
    "line": 60
  }],
  "prId": 9421
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Why pass the checkpointer if the `lastCheckpointedSeqNums` already has it?\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-05T23:02:39Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.Duration\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * This is a helper class for managing Kinesis checkpointing.\n+ *\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ */\n+private[kinesis] class KinesisCheckpointer(\n+    receiver: KinesisReceiver[_],\n+    checkpointInterval: Duration,\n+    workerId: String) extends Logging {\n+\n+  // a map from shardId's to checkpointers\n+  private val checkpointers = new ConcurrentHashMap[String, IRecordProcessorCheckpointer]()\n+\n+  private val lastCheckpointedSeqNums = new ConcurrentHashMap[String, String]()\n+\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one for the given shardId. */\n+  def setCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpointers.put(shardId, checkpointer)\n+  }\n+\n+  /**\n+   * Stop tracking the specified shardId.\n+   *\n+   * If a checkpointer is provided, e.g. on IRecordProcessor.shutdown [[ShutdownReason.TERMINATE]],\n+   * we will use that to make the final checkpoint. If `null` is provided, we will not make the\n+   * checkpoint, e.g. in case of [[ShutdownReason.ZOMBIE]].\n+   */\n+  def removeCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpoint(shardId, Option(checkpointer))\n+    checkpointers.remove(shardId)\n+  }\n+\n+  /** Perform the checkpoint. Exposed for tests. */\n+  private[kinesis] def checkpoint(\n+      shardId: String,\n+      checkpointer: Option[IRecordProcessorCheckpointer]): Unit = {"
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "You mean `checkpointers`? I want `checkpoint` to be called during the shutdown of a record processor called as well, independent from the checkpoint time. Otherwise we have to keep track of, Should I invalidate this checkpointer for shardId as well\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-05T23:49:27Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.Duration\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * This is a helper class for managing Kinesis checkpointing.\n+ *\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ */\n+private[kinesis] class KinesisCheckpointer(\n+    receiver: KinesisReceiver[_],\n+    checkpointInterval: Duration,\n+    workerId: String) extends Logging {\n+\n+  // a map from shardId's to checkpointers\n+  private val checkpointers = new ConcurrentHashMap[String, IRecordProcessorCheckpointer]()\n+\n+  private val lastCheckpointedSeqNums = new ConcurrentHashMap[String, String]()\n+\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one for the given shardId. */\n+  def setCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpointers.put(shardId, checkpointer)\n+  }\n+\n+  /**\n+   * Stop tracking the specified shardId.\n+   *\n+   * If a checkpointer is provided, e.g. on IRecordProcessor.shutdown [[ShutdownReason.TERMINATE]],\n+   * we will use that to make the final checkpoint. If `null` is provided, we will not make the\n+   * checkpoint, e.g. in case of [[ShutdownReason.ZOMBIE]].\n+   */\n+  def removeCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpoint(shardId, Option(checkpointer))\n+    checkpointers.remove(shardId)\n+  }\n+\n+  /** Perform the checkpoint. Exposed for tests. */\n+  private[kinesis] def checkpoint(\n+      shardId: String,\n+      checkpointer: Option[IRecordProcessorCheckpointer]): Unit = {"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "But for that a cleaner design is to update the checkpointer in the map, and then call `checkpoint(shardId)`. Its confusing code to take checkpointer when something else is already maintaining it. \n\nAlso, why have it as a `Option` and later test for cases where it is None?\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-06T00:28:56Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.Duration\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * This is a helper class for managing Kinesis checkpointing.\n+ *\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ */\n+private[kinesis] class KinesisCheckpointer(\n+    receiver: KinesisReceiver[_],\n+    checkpointInterval: Duration,\n+    workerId: String) extends Logging {\n+\n+  // a map from shardId's to checkpointers\n+  private val checkpointers = new ConcurrentHashMap[String, IRecordProcessorCheckpointer]()\n+\n+  private val lastCheckpointedSeqNums = new ConcurrentHashMap[String, String]()\n+\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one for the given shardId. */\n+  def setCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpointers.put(shardId, checkpointer)\n+  }\n+\n+  /**\n+   * Stop tracking the specified shardId.\n+   *\n+   * If a checkpointer is provided, e.g. on IRecordProcessor.shutdown [[ShutdownReason.TERMINATE]],\n+   * we will use that to make the final checkpoint. If `null` is provided, we will not make the\n+   * checkpoint, e.g. in case of [[ShutdownReason.ZOMBIE]].\n+   */\n+  def removeCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpoint(shardId, Option(checkpointer))\n+    checkpointers.remove(shardId)\n+  }\n+\n+  /** Perform the checkpoint. Exposed for tests. */\n+  private[kinesis] def checkpoint(\n+      shardId: String,\n+      checkpointer: Option[IRecordProcessorCheckpointer]): Unit = {"
  }],
  "prId": 9421
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This should be a logWarn. Its not a serious error as future attempts may succeed. Just like task failures are logged as warnings as they are going to reattempted, and only job failures are logged as errors.\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-05T23:08:10Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.Duration\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * This is a helper class for managing Kinesis checkpointing.\n+ *\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ */\n+private[kinesis] class KinesisCheckpointer(\n+    receiver: KinesisReceiver[_],\n+    checkpointInterval: Duration,\n+    workerId: String) extends Logging {\n+\n+  // a map from shardId's to checkpointers\n+  private val checkpointers = new ConcurrentHashMap[String, IRecordProcessorCheckpointer]()\n+\n+  private val lastCheckpointedSeqNums = new ConcurrentHashMap[String, String]()\n+\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one for the given shardId. */\n+  def setCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpointers.put(shardId, checkpointer)\n+  }\n+\n+  /**\n+   * Stop tracking the specified shardId.\n+   *\n+   * If a checkpointer is provided, e.g. on IRecordProcessor.shutdown [[ShutdownReason.TERMINATE]],\n+   * we will use that to make the final checkpoint. If `null` is provided, we will not make the\n+   * checkpoint, e.g. in case of [[ShutdownReason.ZOMBIE]].\n+   */\n+  def removeCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpoint(shardId, Option(checkpointer))\n+    checkpointers.remove(shardId)\n+  }\n+\n+  /** Perform the checkpoint. Exposed for tests. */\n+  private[kinesis] def checkpoint(\n+      shardId: String,\n+      checkpointer: Option[IRecordProcessorCheckpointer]): Unit = {\n+    // if this method throws an exception, then the scheduled task will not run again\n+    try {\n+      checkpointer.foreach { cp =>\n+        receiver.getLatestSeqNumToCheckpoint(shardId).foreach { latestSeqNum =>\n+          val lastSeqNum = lastCheckpointedSeqNums.get(shardId)\n+          // Kinesis sequence numbers are monotonically increasing strings, therefore we can do\n+          // safely do the string comparison\n+          if (lastSeqNum == null || latestSeqNum > lastSeqNum) {\n+            /* Perform the checkpoint */\n+            KinesisRecordProcessor.retryRandom(cp.checkpoint(latestSeqNum), 4, 100)\n+            logDebug(s\"Checkpoint:  WorkerId $workerId completed checkpoint at sequence number\" +\n+              s\" $latestSeqNum for shardId $shardId\")\n+            lastCheckpointedSeqNums.put(shardId, latestSeqNum)\n+          }\n+        }\n+      }\n+    } catch {\n+      case NonFatal(e) =>\n+        logError(\"Failed to checkpoint to DynamoDB.\", e)"
  }],
  "prId": 9421
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Dont you want to checkpoint one final time? \n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-05T23:08:22Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.Duration\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * This is a helper class for managing Kinesis checkpointing.\n+ *\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ */\n+private[kinesis] class KinesisCheckpointer(\n+    receiver: KinesisReceiver[_],\n+    checkpointInterval: Duration,\n+    workerId: String) extends Logging {\n+\n+  // a map from shardId's to checkpointers\n+  private val checkpointers = new ConcurrentHashMap[String, IRecordProcessorCheckpointer]()\n+\n+  private val lastCheckpointedSeqNums = new ConcurrentHashMap[String, String]()\n+\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one for the given shardId. */\n+  def setCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpointers.put(shardId, checkpointer)\n+  }\n+\n+  /**\n+   * Stop tracking the specified shardId.\n+   *\n+   * If a checkpointer is provided, e.g. on IRecordProcessor.shutdown [[ShutdownReason.TERMINATE]],\n+   * we will use that to make the final checkpoint. If `null` is provided, we will not make the\n+   * checkpoint, e.g. in case of [[ShutdownReason.ZOMBIE]].\n+   */\n+  def removeCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpoint(shardId, Option(checkpointer))\n+    checkpointers.remove(shardId)\n+  }\n+\n+  /** Perform the checkpoint. Exposed for tests. */\n+  private[kinesis] def checkpoint(\n+      shardId: String,\n+      checkpointer: Option[IRecordProcessorCheckpointer]): Unit = {\n+    // if this method throws an exception, then the scheduled task will not run again\n+    try {\n+      checkpointer.foreach { cp =>\n+        receiver.getLatestSeqNumToCheckpoint(shardId).foreach { latestSeqNum =>\n+          val lastSeqNum = lastCheckpointedSeqNums.get(shardId)\n+          // Kinesis sequence numbers are monotonically increasing strings, therefore we can do\n+          // safely do the string comparison\n+          if (lastSeqNum == null || latestSeqNum > lastSeqNum) {\n+            /* Perform the checkpoint */\n+            KinesisRecordProcessor.retryRandom(cp.checkpoint(latestSeqNum), 4, 100)\n+            logDebug(s\"Checkpoint:  WorkerId $workerId completed checkpoint at sequence number\" +\n+              s\" $latestSeqNum for shardId $shardId\")\n+            lastCheckpointedSeqNums.put(shardId, latestSeqNum)\n+          }\n+        }\n+      }\n+    } catch {\n+      case NonFatal(e) =>\n+        logError(\"Failed to checkpoint to DynamoDB.\", e)\n+    }\n+  }\n+\n+  /**\n+   * Start the checkpointer thread with the given checkpoint duration. Exposed for tests.\n+   */\n+  private[kinesis] def startCheckpointerThread(): ScheduledFuture[_] = {\n+    val period = checkpointInterval.milliseconds\n+    val ex =\n+      ThreadUtils.newDaemonSingleThreadScheduledExecutor(s\"Kinesis Checkpointer - Worker $workerId\")\n+    val task = new Runnable {\n+      def run() = {\n+        val shardIds = checkpointers.keys()\n+        while (shardIds.hasMoreElements) {\n+          val shardId = shardIds.nextElement()\n+          checkpoint(shardId, Option(checkpointers.get(shardId)))\n+        }\n+      }\n+    }\n+    ex.scheduleAtFixedRate(task, period, period, TimeUnit.MILLISECONDS)\n+  }\n+\n+  /**\n+   * Shutdown the checkpointer. Should be called on the onStop of the Receiver.\n+   */\n+  def shutdown(): Unit = {",
    "line": 126
  }],
  "prId": 9421
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "The whole thing is `private[kinesis]` already!\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-06T00:38:42Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.Duration\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * This is a helper class for managing Kinesis checkpointing.\n+ *\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ */\n+private[kinesis] class KinesisCheckpointer(\n+    receiver: KinesisReceiver[_],\n+    checkpointInterval: Duration,\n+    workerId: String) extends Logging {\n+\n+  // a map from shardId's to checkpointers\n+  private val checkpointers = new ConcurrentHashMap[String, IRecordProcessorCheckpointer]()\n+\n+  private val lastCheckpointedSeqNums = new ConcurrentHashMap[String, String]()\n+\n+  private val checkpointerThread = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one for the given shardId. */\n+  def setCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpointers.put(shardId, checkpointer)\n+  }\n+\n+  /**\n+   * Stop tracking the specified shardId.\n+   *\n+   * If a checkpointer is provided, e.g. on IRecordProcessor.shutdown [[ShutdownReason.TERMINATE]],\n+   * we will use that to make the final checkpoint. If `null` is provided, we will not make the\n+   * checkpoint, e.g. in case of [[ShutdownReason.ZOMBIE]].\n+   */\n+  def removeCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpoint(shardId, Option(checkpointer))\n+    checkpointers.remove(shardId)\n+  }\n+\n+  /** Perform the checkpoint. Exposed for tests. */\n+  private[kinesis] def checkpoint("
  }],
  "prId": 9421
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: Add braces around the method.\n",
    "commit": "63d2e5284034c899b5ae0ccdb6e3e1ac5c022f1c",
    "createdAt": "2015-11-09T01:47:51Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.Duration\n+import org.apache.spark.streaming.util.RecurringTimer\n+import org.apache.spark.util.{Clock, SystemClock, ThreadUtils}\n+\n+/**\n+ * This is a helper class for managing Kinesis checkpointing.\n+ *\n+ * @param receiver The receiver that keeps track of which sequence numbers we can checkpoint\n+ * @param checkpointInterval How frequently we will checkpoint to DynamoDB\n+ * @param workerId Worker Id of KCL worker for logging purposes\n+ * @param clock In order to use ManualClocks for the purpose of testing\n+ */\n+private[kinesis] class KinesisCheckpointer(\n+    receiver: KinesisReceiver[_],\n+    checkpointInterval: Duration,\n+    workerId: String,\n+    clock: Clock = new SystemClock) extends Logging {\n+\n+  // a map from shardId's to checkpointers\n+  private val checkpointers = new ConcurrentHashMap[String, IRecordProcessorCheckpointer]()\n+\n+  private val lastCheckpointedSeqNums = new ConcurrentHashMap[String, String]()\n+\n+  private val checkpointerThread: RecurringTimer = startCheckpointerThread()\n+\n+  /** Update the checkpointer instance to the most recent one for the given shardId. */\n+  def setCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit = {\n+    checkpointers.put(shardId, checkpointer)\n+  }\n+\n+  /**\n+   * Stop tracking the specified shardId.\n+   *\n+   * If a checkpointer is provided, e.g. on IRecordProcessor.shutdown [[ShutdownReason.TERMINATE]],\n+   * we will use that to make the final checkpoint. If `null` is provided, we will not make the\n+   * checkpoint, e.g. in case of [[ShutdownReason.ZOMBIE]].\n+   */\n+  def removeCheckpointer(shardId: String, checkpointer: IRecordProcessorCheckpointer): Unit ="
  }],
  "prId": 9421
}]