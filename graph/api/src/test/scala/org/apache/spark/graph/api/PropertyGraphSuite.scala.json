[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "nit. If possible, shorter is better.\r\n```scala\r\nval studentNF = NodeFrame.create(studentDF, \"id\", Set(\"Person\", \"Student\"))\r\nval teacherNF = NodeFrame.create(teacherDF, \"id\", Set(\"Person\", \"Teacher\"))\r\n```",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-12T15:56:35Z",
    "diffHunk": "@@ -0,0 +1,279 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import org.apache.spark.graph.api.CypherSession.{\n+  ID_COLUMN,\n+  LABEL_COLUMN_PREFIX,\n+  SOURCE_ID_COLUMN,\n+  TARGET_ID_COLUMN\n+}\n+import org.apache.spark.sql.{DataFrame, QueryTest}\n+import org.apache.spark.sql.test.SharedSparkSession\n+import org.scalatest.Matchers\n+\n+abstract class PropertyGraphSuite extends QueryTest with SharedSparkSession with Matchers {\n+\n+  // Override in spark-cypher\n+  type IdType = Long\n+  def convertId(inputId: Long): IdType\n+\n+  def cypherSession: CypherSession\n+\n+  test(\"create graph from NodeFrame\") {\n+    val nodeData = spark.createDataFrame(Seq(0L -> \"Alice\", 1L -> \"Bob\")).toDF(\"id\", \"name\")\n+    val nodeFrame = NodeFrame.create(nodeData, \"id\", Set(\"Person\"))\n+    val graph = cypherSession.createGraph(Seq(nodeFrame), Seq.empty)\n+\n+    val expectedDf = spark\n+      .createDataFrame(Seq((convertId(0L), true, \"Alice\"), (convertId(1L), true, \"Bob\")))\n+      .toDF(ID_COLUMN, label(\"Person\"), \"name\")\n+\n+    checkAnswer(graph.nodes, expectedDf)\n+  }\n+\n+  test(\"create graph from NodeFrame and RelationshipFrame\") {\n+    val nodeData = spark.createDataFrame(Seq(0L -> \"Alice\", 1L -> \"Bob\")).toDF(\"id\", \"name\")\n+    val nodeFrame = NodeFrame.create(nodeData, \"id\", Set(\"Person\"))\n+\n+    val relationshipData = spark\n+      .createDataFrame(Seq((0L, 0L, 1L, 1984)))\n+      .toDF(\"id\", \"source\", \"target\", \"since\")\n+    val relationshipFrame =\n+      RelationshipFrame.create(relationshipData, \"id\", \"source\", \"target\", \"KNOWS\")\n+\n+    val graph = cypherSession.createGraph(Seq(nodeFrame), Seq(relationshipFrame))\n+\n+    val expectedNodeDf = spark\n+      .createDataFrame(Seq((convertId(0L), true, \"Alice\"), (convertId(1L), true, \"Bob\")))\n+      .toDF(ID_COLUMN, label(\"Person\"), \"name\")\n+\n+    val expectedRelDf = spark\n+      .createDataFrame(Seq((convertId(0L), convertId(0L), convertId(1L), true, 1984)))\n+      .toDF(ID_COLUMN, SOURCE_ID_COLUMN, TARGET_ID_COLUMN, label(\"KNOWS\"), \"since\")\n+\n+    checkAnswer(graph.nodes, expectedNodeDf)\n+    checkAnswer(graph.relationships, expectedRelDf)\n+  }\n+\n+  test(\"create graph with multiple node and relationship types\") {\n+    val studentDF = spark\n+      .createDataFrame(Seq((0L, \"Alice\", 42), (1L, \"Bob\", 23)))\n+      .toDF(\"id\", \"name\", \"age\")\n+    val teacherDF = spark\n+      .createDataFrame(Seq((2L, \"Eve\", \"CS\")))\n+      .toDF(\"id\", \"name\", \"subject\")\n+\n+    val studentNF =\n+      NodeFrame.create(studentDF, \"id\", Set(\"Person\", \"Student\"))\n+    val teacherNF =\n+      NodeFrame.create(teacherDF, \"id\", Set(\"Person\", \"Teacher\"))"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "In Apache Spark project, this should be one-line `import`. We don't enforce maximum line length for `import`.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-12T20:29:16Z",
    "diffHunk": "@@ -0,0 +1,276 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import org.scalatest.Matchers\n+\n+import org.apache.spark.graph.api.CypherSession.{\n+  ID_COLUMN,\n+  LABEL_COLUMN_PREFIX,\n+  SOURCE_ID_COLUMN,\n+  TARGET_ID_COLUMN\n+}"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Let's move these `val nodes` and `val relationships` to the top of this test suite.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-10T06:25:13Z",
    "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import org.scalatest.Matchers\n+\n+import org.apache.spark.graph.api.CypherSession.{ID_COLUMN, LABEL_COLUMN_PREFIX, SOURCE_ID_COLUMN, TARGET_ID_COLUMN}\n+import org.apache.spark.sql.{DataFrame, QueryTest}\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+abstract class PropertyGraphSuite extends QueryTest with SharedSparkSession with Matchers {\n+\n+  // Override in spark-cypher\n+  type IdType = Long\n+  def convertId(inputId: Long): IdType\n+\n+  def cypherSession: CypherSession\n+\n+  test(\"create graph from NodeFrame\") {\n+    val nodeData = spark.createDataFrame(Seq(0L -> \"Alice\", 1L -> \"Bob\")).toDF(\"id\", \"name\")\n+    val nodeFrame = cypherSession.buildNodeFrame(nodeData)\n+      .idColumn(\"id\")\n+      .labelSet(Array(\"Person\"))\n+      .properties(Map(\"name\" -> \"name\"))\n+      .build()\n+    val graph = cypherSession.createGraph(Array(nodeFrame), Array.empty[RelationshipFrame])\n+\n+    val expectedDf = spark\n+      .createDataFrame(Seq((convertId(0L), true, \"Alice\"), (convertId(1L), true, \"Bob\")))\n+      .toDF(ID_COLUMN, label(\"Person\"), \"name\")\n+\n+    checkAnswer(graph.nodes, expectedDf)\n+  }\n+\n+  test(\"create graph from NodeFrame and RelationshipFrame\") {\n+    val nodeData = spark.createDataFrame(Seq(0L -> \"Alice\", 1L -> \"Bob\")).toDF(\"id\", \"name\")\n+    val nodeFrame = cypherSession.buildNodeFrame(nodeData)\n+      .idColumn(\"id\")\n+      .labelSet(Array(\"Person\"))\n+      .properties(Map(\"name\" -> \"name\"))\n+      .build()\n+    val relationshipData = spark\n+      .createDataFrame(Seq((0L, 0L, 1L, 1984)))\n+      .toDF(\"id\", \"source\", \"target\", \"since\")\n+    val relationshipFrame = cypherSession.buildRelationshipFrame(relationshipData)\n+      .idColumn(\"id\")\n+      .sourceIdColumn(\"source\")\n+      .targetIdColumn(\"target\")\n+      .relationshipType(\"KNOWS\")\n+      .properties(Map(\"since\" -> \"since\"))\n+      .build()\n+\n+    val graph = cypherSession.createGraph(Array(nodeFrame), Array(relationshipFrame))\n+\n+    val expectedNodeDf = spark\n+      .createDataFrame(Seq((convertId(0L), true, \"Alice\"), (convertId(1L), true, \"Bob\")))\n+      .toDF(ID_COLUMN, label(\"Person\"), \"name\")\n+\n+    val expectedRelDf = spark\n+      .createDataFrame(Seq((convertId(0L), convertId(0L), convertId(1L), true, 1984)))\n+      .toDF(ID_COLUMN, SOURCE_ID_COLUMN, TARGET_ID_COLUMN, label(\"KNOWS\"), \"since\")\n+\n+    checkAnswer(graph.nodes, expectedNodeDf)\n+    checkAnswer(graph.relationships, expectedRelDf)\n+  }\n+\n+  test(\"create graph with multiple node and relationship types\") {\n+    val studentDF = spark\n+      .createDataFrame(Seq((0L, \"Alice\", 42), (1L, \"Bob\", 23)))\n+      .toDF(\"id\", \"name\", \"age\")\n+    val teacherDF = spark\n+      .createDataFrame(Seq((2L, \"Eve\", \"CS\")))\n+      .toDF(\"id\", \"name\", \"subject\")\n+\n+    val studentNF = cypherSession.buildNodeFrame(studentDF)\n+        .idColumn(\"id\")\n+        .labelSet(Array(\"Person\", \"Student\"))\n+        .properties(Map(\"name\" -> \"name\", \"age\" -> \"age\"))\n+        .build()\n+\n+    val teacherNF = cypherSession.buildNodeFrame(teacherDF)\n+      .idColumn(\"id\")\n+      .labelSet(Array(\"Person\", \"Teacher\"))\n+      .properties(Map(\"name\" -> \"name\", \"subject\" -> \"subject\"))\n+      .build()\n+\n+    val knowsDF = spark\n+      .createDataFrame(Seq((0L, 0L, 1L, 1984)))\n+      .toDF(\"id\", \"source\", \"target\", \"since\")\n+    val teachesDF = spark\n+      .createDataFrame(Seq((1L, 2L, 1L)))\n+      .toDF(\"id\", \"source\", \"target\")\n+\n+    val knowsRF = cypherSession.buildRelationshipFrame(knowsDF)\n+      .idColumn(\"id\")\n+      .sourceIdColumn(\"source\")\n+      .targetIdColumn(\"target\")\n+      .relationshipType(\"KNOWS\")\n+      .properties(Map(\"since\" -> \"since\"))\n+      .build()\n+    val teachesRF = cypherSession.buildRelationshipFrame(teachesDF)\n+      .idColumn(\"id\")\n+      .sourceIdColumn(\"source\")\n+      .targetIdColumn(\"target\")\n+      .relationshipType(\"TEACHES\")\n+      .build()\n+\n+    val graph = cypherSession.createGraph(Array(studentNF, teacherNF), Array(knowsRF, teachesRF))\n+\n+    val expectedNodeDf = spark\n+      .createDataFrame(\n+        Seq(\n+          (convertId(0L), true, true, false, Some(42), Some(\"Alice\"), None),\n+          (convertId(1L), true, true, false, Some(23), Some(\"Bob\"), None),\n+          (convertId(2L), true, false, true, None, Some(\"Eve\"), Some(\"CS\"))))\n+      .toDF(\n+        ID_COLUMN,\n+        label(\"Person\"),\n+        label(\"Student\"),\n+        label(\"Teacher\"),\n+        \"age\",\n+        \"name\",\n+        \"subject\")\n+\n+    val expectedRelDf = spark\n+      .createDataFrame(\n+        Seq(\n+          (convertId(0L), convertId(0L), convertId(1L), true, false, Some(1984)),\n+          (convertId(1L), convertId(2L), convertId(1L), false, true, None)))\n+      .toDF(\n+        ID_COLUMN,\n+        SOURCE_ID_COLUMN,\n+        TARGET_ID_COLUMN,\n+        label(\"KNOWS\"),\n+        label(\"TEACHES\"),\n+        \"since\")\n+\n+    checkAnswer(graph.nodes, expectedNodeDf)\n+    checkAnswer(graph.relationships, expectedRelDf)\n+  }\n+\n+  test(\"create graph with explicit property-to-column mappings\") {\n+    val studentDF = spark\n+      .createDataFrame(Seq((0L, \"Alice\", 42), (1L, \"Bob\", 23)))\n+      .toDF(\"id\", \"col_name\", \"col_age\")\n+    val teacherDF = spark\n+      .createDataFrame(Seq((2L, \"Eve\", \"CS\")))\n+      .toDF(\"id\", \"col_name\", \"col_subject\")\n+\n+    val studentNF = NodeFrame(\n+      studentDF,\n+      \"id\",\n+      Set(\"Person\", \"Student\"),\n+      properties = Map(\"name\" -> \"col_name\", \"age\" -> \"col_age\"))\n+    val teacherNF = NodeFrame(\n+      teacherDF,\n+      \"id\",\n+      Set(\"Person\", \"Teacher\"),\n+      properties = Map(\"name\" -> \"col_name\", \"subject\" -> \"col_subject\"))\n+\n+    val knowsDF = spark\n+      .createDataFrame(Seq((0L, 0L, 1L, 1984)))\n+      .toDF(\"id\", \"source\", \"target\", \"col_since\")\n+    val teachesDF = spark.createDataFrame(Seq((1L, 2L, 1L))).toDF(\"id\", \"source\", \"target\")\n+\n+    val knowsRF = RelationshipFrame(\n+      knowsDF,\n+      \"id\",\n+      \"source\",\n+      \"target\",\n+      relationshipType = \"KNOWS\",\n+      properties = Map(\"since\" -> \"col_since\"))\n+    val teachesRF = RelationshipFrame(\n+      teachesDF,\n+      \"id\",\n+      \"source\",\n+      \"target\",\n+      \"TEACHES\",\n+      Map.empty)\n+\n+    val graph = cypherSession.createGraph(Array(studentNF, teacherNF), Array(knowsRF, teachesRF))\n+\n+    val expectedNodeDf = spark\n+      .createDataFrame(\n+        Seq(\n+          (convertId(0L), true, true, false, Some(42), Some(\"Alice\"), None),\n+          (convertId(1L), true, true, false, Some(23), Some(\"Bob\"), None),\n+          (convertId(2L), true, false, true, None, Some(\"Eve\"), Some(\"CS\"))))\n+      .toDF(\n+        ID_COLUMN,\n+        label(\"Person\"),\n+        label(\"Student\"),\n+        label(\"Teacher\"),\n+        \"age\",\n+        \"name\",\n+        \"subject\")\n+\n+    val expectedRelDf = spark\n+      .createDataFrame(\n+        Seq(\n+          (convertId(0L), convertId(0L), convertId(1L), true, false, Some(1984)),\n+          (convertId(1L), convertId(2L), convertId(1L), false, true, None)))\n+      .toDF(\n+        ID_COLUMN,\n+        SOURCE_ID_COLUMN,\n+        TARGET_ID_COLUMN,\n+        label(\"KNOWS\"),\n+        label(\"TEACHES\"),\n+        \"since\")\n+\n+    checkAnswer(graph.nodes, expectedNodeDf)\n+    checkAnswer(graph.relationships, expectedRelDf)\n+  }\n+\n+  lazy val nodes: DataFrame = spark"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "There is not much information about this. Could you explain about this a little bit more?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T03:25:12Z",
    "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import org.scalatest.Matchers\n+\n+import org.apache.spark.graph.api.CypherSession.{ID_COLUMN, LABEL_COLUMN_PREFIX, SOURCE_ID_COLUMN, TARGET_ID_COLUMN}\n+import org.apache.spark.sql.{DataFrame, QueryTest}\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+abstract class PropertyGraphSuite extends QueryTest with SharedSparkSession with Matchers {\n+\n+  // Override in spark-cypher",
    "line": 28
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "```scala\r\n-import org.apache.spark.sql.{DataFrame, QueryTest}\r\n+import org.apache.spark.sql.{Dataset, QueryTest, Row}\r\n```",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T03:40:57Z",
    "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import org.scalatest.Matchers\n+\n+import org.apache.spark.graph.api.CypherSession.{ID_COLUMN, LABEL_COLUMN_PREFIX, SOURCE_ID_COLUMN, TARGET_ID_COLUMN}\n+import org.apache.spark.sql.{DataFrame, QueryTest}"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "```scala\r\n-  lazy val nodes: DataFrame = spark\r\n+  lazy val nodes: Dataset[Row] = spark\r\n```",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T03:41:17Z",
    "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import org.scalatest.Matchers\n+\n+import org.apache.spark.graph.api.CypherSession.{ID_COLUMN, LABEL_COLUMN_PREFIX, SOURCE_ID_COLUMN, TARGET_ID_COLUMN}\n+import org.apache.spark.sql.{DataFrame, QueryTest}\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+abstract class PropertyGraphSuite extends QueryTest with SharedSparkSession with Matchers {\n+\n+  // Override in spark-cypher\n+  type IdType = Long\n+  def convertId(inputId: Long): IdType\n+\n+  def cypherSession: CypherSession\n+\n+  lazy val nodes: DataFrame = spark"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "```scala\r\n-  lazy val relationships: DataFrame = spark\r\n+  lazy val relationships: Dataset[Row] = spark\r\n```",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T03:41:41Z",
    "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import org.scalatest.Matchers\n+\n+import org.apache.spark.graph.api.CypherSession.{ID_COLUMN, LABEL_COLUMN_PREFIX, SOURCE_ID_COLUMN, TARGET_ID_COLUMN}\n+import org.apache.spark.sql.{DataFrame, QueryTest}\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+abstract class PropertyGraphSuite extends QueryTest with SharedSparkSession with Matchers {\n+\n+  // Override in spark-cypher\n+  type IdType = Long\n+  def convertId(inputId: Long): IdType\n+\n+  def cypherSession: CypherSession\n+\n+  lazy val nodes: DataFrame = spark\n+    .createDataFrame(\n+      Seq(\n+        (0L, true, true, false, false, Some(42), Some(\"Alice\"), None, None),\n+        (1L, true, true, false, false, Some(23), Some(\"Bob\"), None, None),\n+        (2L, true, false, true, false, Some(22), Some(\"Carol\"), Some(\"CS\"), None),\n+        (3L, true, true, false, false, Some(19), Some(\"Eve\"), None, None),\n+        (4L, false, false, false, true, None, None, None, Some(\"UC Berkeley\")),\n+        (5L, false, false, false, true, None, None, None, Some(\"Stanford\"))))\n+    .toDF(\n+      ID_COLUMN,\n+      label(\"Person\"),\n+      label(\"Student\"),\n+      label(\"Teacher\"),\n+      label(\"University\"),\n+      \"age\",\n+      \"name\",\n+      \"subject\",\n+      \"title\")\n+\n+  lazy val relationships: DataFrame = spark"
  }],
  "prId": 24851
}]