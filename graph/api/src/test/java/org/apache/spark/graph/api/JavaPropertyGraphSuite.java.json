[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Is this `abstract` test suite used?\r\n",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-12T16:02:33Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Sets;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.test.TestSparkSession;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+public abstract class JavaPropertyGraphSuite implements Serializable {",
    "line": 42
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "Both, the `PropertyGraphSuite` and `JavaPropertyGraphSuite` are supposed to be abstract and implemented in `spark-cypher` by the concrete implementation, providing a `CypherSession` instance. The idea is that multiple implementations of `spark-graph-api` can share the same tests.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-12T21:41:24Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Sets;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.test.TestSparkSession;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+public abstract class JavaPropertyGraphSuite implements Serializable {",
    "line": 42
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "We also need some feedback if this is the proper way to implement Java tests for a Scala API in Spark. That's why we just added one test for now.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-12T21:43:49Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Sets;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.test.TestSparkSession;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+public abstract class JavaPropertyGraphSuite implements Serializable {",
    "line": 42
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "FYI, Apache Spark uses 2-space indentation for Java code, too. Please fix this one and consider that in the next PRs.\r\n",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-12T16:06:35Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Sets;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.test.TestSparkSession;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+public abstract class JavaPropertyGraphSuite implements Serializable {\n+    private transient TestSparkSession spark;\n+    private transient CypherSession cypherSession = null;\n+\n+    @Before\n+    public void setUp() {\n+        spark = new TestSparkSession();\n+    }\n+\n+    @After\n+    public void tearDown() {\n+        spark.stop();\n+        spark = null;\n+    }\n+\n+    @Test\n+    public void testCreateFromNodeFrame() {\n+        StructType personSchema = createSchema(\n+                Lists.newArrayList(\"id\", \"name\"),\n+                Lists.newArrayList(DataTypes.LongType, DataTypes.StringType));\n+\n+        List<Row> personData = Arrays.asList(\n+                RowFactory.create(0L, \"Alice\"),\n+                RowFactory.create(1L, \"Bob\"));\n+\n+        StructType knowsSchema = createSchema(\n+                Lists.newArrayList(\"id\", \"source\", \"target\", \"since\"),\n+                Lists.newArrayList(DataTypes.LongType, DataTypes.LongType, DataTypes.LongType, DataTypes.IntegerType));\n+\n+        List<Row> knowsData = Collections.singletonList(RowFactory.create(0L, 0L, 1L, 1984));\n+\n+        Dataset<Row> personDf = spark.createDataFrame(personData, personSchema);\n+        NodeFrame personNodeFrame = NodeFrame.create(personDf, \"id\", Sets.newHashSet(\"Person\"));\n+\n+        Dataset<Row> knowsDf = spark.createDataFrame(knowsData, knowsSchema);\n+        RelationshipFrame knowsRelFrame = RelationshipFrame.create(knowsDf, \"id\", \"source\", \"target\", \"KNOWS\");\n+\n+        PropertyGraph graph = cypherSession.createGraph(Lists.newArrayList(personNodeFrame), Lists.newArrayList(knowsRelFrame));\n+        List<Row> result = graph.nodes().collectAsList();\n+        Assert.assertEquals(1, result.size());\n+    }\n+\n+    private StructType createSchema(List<String> fieldNames, List<DataType> dataTypes) {\n+        List<StructField> fields = new ArrayList<>();\n+        for (int i = 0; i < fieldNames.size(); i++) {\n+            fields.add(DataTypes.createStructField(fieldNames.get(i), dataTypes.get(i), true));\n+        }\n+        return DataTypes.createStructType(fields);\n+    }\n+}",
    "line": 113
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "nit: do we need this `import` line?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-09-27T08:59:17Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Sets;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.test.TestSparkSession;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.spark.sql.types.DataTypes.*;\n+import static org.apache.spark.sql.types.DataTypes.LongType;"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Indentation?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-10T06:13:34Z",
    "diffHunk": "@@ -74,9 +73,12 @@ public void testCreateFromNodeFrame() {\n \n     List<Row> knowsData = Collections.singletonList(RowFactory.create(0L, 0L, 1L, 1984));\n \n-    Dataset<Row> personDf = spark.createDataFrame(personData, personSchema);\n-    NodeFrame personNodeFrame = NodeFrame\n-        .create(personDf, \"id\", Sets.newHashSet(\"Person\"));\n+        Dataset<Row> personDf = spark.createDataFrame(personData, personSchema);"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "We use 2-space indentation in Java code. Please update all the other instances. You can reference the existing code, `Java8APISuite.java`.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T03:22:41Z",
    "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.test.TestSparkSession;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.apache.spark.sql.types.DataTypes.*;\n+\n+public abstract class JavaPropertyGraphSuite implements Serializable {\n+  private transient TestSparkSession spark;\n+  private transient CypherSession cypherSession;\n+\n+  abstract CypherSession getCypherSession(SparkSession sparkSession);\n+\n+  @Before\n+  public void setUp() {\n+    spark = new TestSparkSession();\n+    cypherSession = getCypherSession(spark);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    spark.stop();\n+    spark = null;\n+  }\n+\n+  @Test\n+  public void testCreateFromNodeFrame() {\n+    StructType personSchema = createSchema(\n+        Lists.newArrayList(\"id\", \"name\"),"
  }],
  "prId": 24851
}]