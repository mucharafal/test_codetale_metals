[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Could you remove this new line? The other license header seems to have the same issue.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-12T15:58:25Z",
    "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "```\r\n$ dev/scalastyle\r\n[error] /home/jenkins/workspace/SparkPullRequestBuilder/graph/api/src/main/scala/org/apache/spark/graph/api/CypherSession.scala:16: Header does not match expected text\r\n[error] /home/jenkins/workspace/SparkPullRequestBuilder/graph/api/src/main/scala/org/apache/spark/graph/api/PropertyGraph.scala:16: Header does not match expected text\r\n[error] /home/jenkins/workspace/SparkPullRequestBuilder/graph/api/src/main/scala/org/apache/spark/graph/api/GraphElementFrame.scala:16: Header does not match expected text\r\n[error] /home/jenkins/workspace/SparkPullRequestBuilder/graph/api/src/main/scala/org/apache/spark/graph/api/PropertyGraphType.scala:16: Header does not match expected text\r\n```",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-12T16:07:44Z",
    "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ *"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "Why not use `nodes.asScala`, `relationships.asScala` ?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-26T14:52:35Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "Why `+ Set.empty` ?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-26T14:59:36Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty"
  }, {
    "author": {
      "login": "WeichenXu123"
    },
    "body": "The `subset()` cause running time explosion.\r\nSuppose we have `N` labels, then it will generate `2^N` subsets,\r\nthen you will scan and filter the input `nodes` dataframe `2^N` times (the worst case the `nodes` dataframe is not cached).",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-26T15:13:15Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty"
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "Each of those sets represents a possible label combination (the empty set is the case where a node has no label). The input dataframe has no information about the possible label combinations. From looking at its schema, you can just derive which labels exist and we have to assume that any combination of those labels exists in the data. The alternative would be to look at the data, which we want to avoid.\r\n\r\nGenerally, this method is just for convenience. To avoid the combinatorical problem, one can use `NodeFrame` and `RelationshipFrame` for each possible label combination / relationship type.\r\n\r\nDo you see any other alternative? We could however, make that more clear in the documentation of that method. Wdyt?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-28T06:51:49Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty"
  }, {
    "author": {
      "login": "WeichenXu123"
    },
    "body": "Yes, logically we should do this, but we can still do some optimization, such as we do a `partitionBy` to shuffle data to different partitions, and then extract each partition to be a result dataframe, we could discuss them later when the optimization needed.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-28T09:12:14Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "* subsets() should include the empty subset already.\r\n* There should be an warning if the number of label columns is big (say 6) and an error if it is too big (say 10). We shouldn't call `subsets()` without those checks.\r\n* Could you create a follow-up JIRA for getting the distinct values instead of using `subsets`?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-16T19:08:27Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty"
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "I created https://issues.apache.org/jira/browse/SPARK-28513",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T10:24:52Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "Should we cache `nodes` and `relationships` dataframe first ?\r\nThe code here filter the two dataframes multiple times.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-26T15:01:41Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn) === trueLit\n+          case labelColumn => nodes.col(labelColumn) === falseLit\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn) === trueLit\n+\n+      RelationshipFrame(\n+        relationships.filter(predicate),\n+        idColumn,\n+        sourceIdColumn,\n+        targetIdColumn,\n+        relTypeColumn.substring(1),\n+        relProperties)\n+    }\n+\n+    createGraph(nodeFrames.toSeq, relFrames.toSeq)"
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "I think if we add some documentation about the combinatorial problem, the user can decide to cache `nodes` and `relationships` before entering that method. Otherwise, we would also cache for the case, where we just have a small set of label columns.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-28T06:54:09Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn) === trueLit\n+          case labelColumn => nodes.col(labelColumn) === falseLit\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn) === trueLit\n+\n+      RelationshipFrame(\n+        relationships.filter(predicate),\n+        idColumn,\n+        sourceIdColumn,\n+        targetIdColumn,\n+        relTypeColumn.substring(1),\n+        relProperties)\n+    }\n+\n+    createGraph(nodeFrames.toSeq, relFrames.toSeq)"
  }, {
    "author": {
      "login": "WeichenXu123"
    },
    "body": "I think cache won't hurt perf too much in any case. But no caching is risky. The input dataframe computation may consume massive time.\r\n@meng what do you think ?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-28T09:17:57Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn) === trueLit\n+          case labelColumn => nodes.col(labelColumn) === falseLit\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn) === trueLit\n+\n+      RelationshipFrame(\n+        relationships.filter(predicate),\n+        idColumn,\n+        sourceIdColumn,\n+        targetIdColumn,\n+        relTypeColumn.substring(1),\n+        relProperties)\n+    }\n+\n+    createGraph(nodeFrames.toSeq, relFrames.toSeq)"
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "You probably want to know what @mengxr thinks ;)",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-29T08:14:51Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn) === trueLit\n+          case labelColumn => nodes.col(labelColumn) === falseLit\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn) === trueLit\n+\n+      RelationshipFrame(\n+        relationships.filter(predicate),\n+        idColumn,\n+        sourceIdColumn,\n+        targetIdColumn,\n+        relTypeColumn.substring(1),\n+        relProperties)\n+    }\n+\n+    createGraph(nodeFrames.toSeq, relFrames.toSeq)"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Let's keep the current version but mention that user should cache the input data frame to tune performance.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-17T00:00:28Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn) === trueLit\n+          case labelColumn => nodes.col(labelColumn) === falseLit\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn) === trueLit\n+\n+      RelationshipFrame(\n+        relationships.filter(predicate),\n+        idColumn,\n+        sourceIdColumn,\n+        targetIdColumn,\n+        relTypeColumn.substring(1),\n+        relProperties)\n+    }\n+\n+    createGraph(nodeFrames.toSeq, relFrames.toSeq)"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "replace `expr == trueLit` with `expr`,\r\nreplace `expr == falseLit` with `!expr`.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-26T15:08:02Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn) === trueLit\n+          case labelColumn => nodes.col(labelColumn) === falseLit"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "ditto, replace `=== trueLit` ",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-06-26T15:13:52Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.sql.{functions, DataFrame, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(JavaConverters.asScalaBuffer(nodes), JavaConverters.asScalaBuffer(relationships))\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val trueLit = functions.lit(true)\n+    val falseLit = functions.lit(false)\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn) === trueLit\n+          case labelColumn => nodes.col(labelColumn) === falseLit\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn) === trueLit\n+"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "indentation.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-10T16:08:45Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Does it compile into a Java interface? Having `object` and `trait` of the same name, Scala compiler might create abstract class instead.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-16T18:07:52Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {",
    "line": 168
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Btw, do you think `GraphSession` is a better name here? Cypher is an implementation. `GraphSession.cypher` and `GraphSession.gql` (future extension) seem more nature than `CypherSession.gql`.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-18T23:35:25Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {",
    "line": 168
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "> Does it compile into a Java interface? Having `object` and `trait` of the same name, Scala compiler might create abstract class instead.\r\n\r\nI tested it on the PoC branch. Works fine so far: https://github.com/apache/spark/pull/24297/commits/4d3363802246ac3dde80910cc9cfea2510b6801b",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T11:39:17Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {",
    "line": 168
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "> Btw, do you think `GraphSession` is a better name here? Cypher is an implementation. `GraphSession.cypher` and `GraphSession.gql` (future extension) seem more nature than `CypherSession.gql`.\r\n\r\nIf we want to provide a session that offers `cypher` and `gql`, I would prefer extending the `CypherSession` trait to not enforce implementations to care about both. However, I think that question also depends on how we access the graph algorithms. If they are accessible via the session, renaming it to `GraphSession` sounds reasonable to me. I think we can postpone that decision and change it later if necessary.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T11:43:17Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {",
    "line": 168
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "> Does it compile into a Java interface? Having `object` and `trait` of the same name, Scala compiler might create abstract class instead.\r\n\r\nAlso, the constants are available in Java via e.g. `CypherSession.ID_COLUMN();`",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T11:50:40Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {",
    "line": 168
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "btw, I like `GraphSession`, too. I think the name would be better not to depend on implementations.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-25T06:56:59Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {",
    "line": 168
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Need ScalaDoc if this is intended to be public.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-16T18:08:11Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "The first line should describe what it does.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-16T18:08:47Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark."
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "We adapted the first line from `SparkSession` which is: `The entry point to programming Spark with the Dataset and DataFrame API.` I changed it to: `A CypherSession allows for creating, storing and loading [[PropertyGraph]] instances as well as executing Cypher queries on them.`",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T12:09:53Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark."
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Could you add a `seealso` link to Cypher definition?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-16T18:20:52Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0",
    "line": 177
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "I added `@see <a href=\"https://neo4j.com/docs/cypher-manual/current/\">` to all `cypher` methods.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T12:17:19Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0",
    "line": 177
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "What is it? Could you provide some examples?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-16T18:32:50Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query",
    "line": 202
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "Cypher queries can take a map of parameters as input, e.g. to avoid manual string building. I added `@see <a href=\"https://neo4j.com/docs/cypher-manual/current/syntax/parameters/\">` to each `cypher` method.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T12:20:20Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query",
    "line": 202
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Don't see the `@see` link.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-14T17:55:45Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query",
    "line": 202
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "The best way to avoid many method overloading is using builder pattern, like `DataFrameReader`.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-16T18:57:21Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {"
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "Agreed. However, I can't imagine any additional overloads and therefore would keep the methods as they are.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T12:35:19Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`Seq` -> `Array` for Java compatibility. Then we don't need a separate Java friendly method.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-16T18:58:31Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Note that if the trait has a default implementation, it won't be compiled into a Java interface.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-16T19:01:09Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)"
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "Interesting, especially since Java also supports `default` methods on interfaces. I removed that method, but we still have a default implementation for `createGraph(nodes: DataFrame, rels: DataFrame)`. Do you think we should remove the default implementation and implement it in spark-cypher?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T13:04:55Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Is this column optional for relationships?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-16T19:01:23Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)",
    "line": 259
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "No, relationships have their own identifier to allow for multiple edges between the same pair of nodes.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T13:07:25Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)",
    "line": 259
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "maybe easier to read with:\r\n\r\n~~~scala\r\nif (labelSet.contains(labelColumn)) {\r\n  ...\r\n} else {\r\n  ...\r\n}\r\n~~~",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-16T23:49:30Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn)"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Should mention the expected type here and verify the types in the implementation.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-18T23:04:41Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)",
    "line": 263
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "I added validation for the label columns. The DataType for id columns depends on the implementation.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T14:10:54Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)",
    "line": 263
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "This is different from DataFrameWriter pattern. `graph.write.mode(\"...\").save(path)`",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-18T23:06:00Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn)\n+          case labelColumn => !nodes.col(labelColumn)\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn)\n+\n+      RelationshipFrame(\n+        relationships.filter(predicate),\n+        idColumn,\n+        sourceIdColumn,\n+        targetIdColumn,\n+        relTypeColumn.substring(1),\n+        relProperties)\n+    }\n+\n+    createGraph(nodeFrames.toSeq, relFrames.toSeq)\n+  }\n+\n+  /**\n+   * Loads a [[PropertyGraph]] from the given location.\n+   *\n+   * @param path directory in which the graph is stored\n+   * @since 3.0.0\n+   */\n+  def load(path: String): PropertyGraph\n+\n+  /**\n+   * Saves a [[PropertyGraph]] to the given location.\n+   *\n+   * @param graph     [[PropertyGraph]] to be stored\n+   * @param path      directory in which the graph should be stored\n+   * @param saveMode  specifies what happens when the destination already exists\n+   * @since 3.0.0\n+   */\n+  def save(graph: PropertyGraph, path: String, saveMode: SaveMode): Unit"
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "Do we want to adapt to that pattern? Is this changing with DSv2 in Spark 3.0?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-25T14:11:59Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn)\n+          case labelColumn => !nodes.col(labelColumn)\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn)\n+\n+      RelationshipFrame(\n+        relationships.filter(predicate),\n+        idColumn,\n+        sourceIdColumn,\n+        targetIdColumn,\n+        relTypeColumn.substring(1),\n+        relProperties)\n+    }\n+\n+    createGraph(nodeFrames.toSeq, relFrames.toSeq)\n+  }\n+\n+  /**\n+   * Loads a [[PropertyGraph]] from the given location.\n+   *\n+   * @param path directory in which the graph is stored\n+   * @since 3.0.0\n+   */\n+  def load(path: String): PropertyGraph\n+\n+  /**\n+   * Saves a [[PropertyGraph]] to the given location.\n+   *\n+   * @param graph     [[PropertyGraph]] to be stored\n+   * @param path      directory in which the graph should be stored\n+   * @param saveMode  specifies what happens when the destination already exists\n+   * @since 3.0.0\n+   */\n+  def save(graph: PropertyGraph, path: String, saveMode: SaveMode): Unit"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Yep. For this one, @mengxr 's advice is the recent common development direction inside Apache Spark. Please follow @mengxr 's advice. This is orthogonal to `DSv2`.\r\n> Do we want to adapt to that pattern? Is this changing with DSv2 in Spark 3.0?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-05T22:36:48Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn)\n+          case labelColumn => !nodes.col(labelColumn)\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn)\n+\n+      RelationshipFrame(\n+        relationships.filter(predicate),\n+        idColumn,\n+        sourceIdColumn,\n+        targetIdColumn,\n+        relTypeColumn.substring(1),\n+        relProperties)\n+    }\n+\n+    createGraph(nodeFrames.toSeq, relFrames.toSeq)\n+  }\n+\n+  /**\n+   * Loads a [[PropertyGraph]] from the given location.\n+   *\n+   * @param path directory in which the graph is stored\n+   * @since 3.0.0\n+   */\n+  def load(path: String): PropertyGraph\n+\n+  /**\n+   * Saves a [[PropertyGraph]] to the given location.\n+   *\n+   * @param graph     [[PropertyGraph]] to be stored\n+   * @param path      directory in which the graph should be stored\n+   * @param saveMode  specifies what happens when the destination already exists\n+   * @since 3.0.0\n+   */\n+  def save(graph: PropertyGraph, path: String, saveMode: SaveMode): Unit"
  }, {
    "author": {
      "login": "Mats-SX"
    },
    "body": "We have now done this in c50b679",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-08T15:07:58Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val labelSets = labelColumns.subsets().toSet + Set.empty\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map {\n+          case labelColumn if labelSet.contains(labelColumn) => nodes.col(labelColumn)\n+          case labelColumn => !nodes.col(labelColumn)\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn)\n+\n+      RelationshipFrame(\n+        relationships.filter(predicate),\n+        idColumn,\n+        sourceIdColumn,\n+        targetIdColumn,\n+        relTypeColumn.substring(1),\n+        relProperties)\n+    }\n+\n+    createGraph(nodeFrames.toSeq, relFrames.toSeq)\n+  }\n+\n+  /**\n+   * Loads a [[PropertyGraph]] from the given location.\n+   *\n+   * @param path directory in which the graph is stored\n+   * @since 3.0.0\n+   */\n+  def load(path: String): PropertyGraph\n+\n+  /**\n+   * Saves a [[PropertyGraph]] to the given location.\n+   *\n+   * @param graph     [[PropertyGraph]] to be stored\n+   * @param path      directory in which the graph should be stored\n+   * @param saveMode  specifies what happens when the destination already exists\n+   * @since 3.0.0\n+   */\n+  def save(graph: PropertyGraph, path: String, saveMode: SaveMode): Unit"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We might need `Dataset[_]` instead of `DataFrame` to accept more input types.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-18T23:25:19Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {"
  }, {
    "author": {
      "login": "s1ck"
    },
    "body": "This is a big change. `spark-cypher` is designed to work with `DataFrame`. Why would we wanna change that? Isn't GraphFrames also working with `DataFrame`s?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-07-26T07:11:49Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "I understand the reasoning and the limitation, @s1ck .\r\n\r\nJust as a side-note for the reviewers, `GraphFrames` is not a part of Apache Spark. So, let's not refer to it in this PR. It's just one of the 3rd party libraries like `spark-cyber`. There is no reason for Apache Spark to follow `GraphFrames`.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-05T22:35:01Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "```scala\r\n-  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\r\n+  def createGraph(nodes: Dataset[Row], relationships: Dataset[Row]): PropertyGraph = {\r\n```",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T03:35:27Z",
    "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+\n+object CypherSession {\n+  val ID_COLUMN = \"$ID\"\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * The entry point for using property graphs in Spark.\n+ *\n+ * Provides factory methods for creating [[PropertyGraph]] instances.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph,\n+             query: String,\n+             parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Seq[NodeFrame], relationships: Seq[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(\n+      nodes: java.util.List[NodeFrame],\n+      relationships: java.util.List[RelationshipFrame]): PropertyGraph = {\n+    createGraph(nodes.asScala, relationships.asScala)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "@s1ck . Please remove `neo4j.com` reference.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-10T06:17:30Z",
    "diffHunk": "@@ -0,0 +1,263 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * A CypherSession allows for creating, storing and loading [[PropertyGraph]] instances as well as\n+ * executing Cypher queries on them.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession extends Logging {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @see <a href=\"https://neo4j.com/docs/cypher-manual/current/\">Cypher Manual</a>"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Let's remove these two lines.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-10T06:18:05Z",
    "diffHunk": "@@ -0,0 +1,263 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * A CypherSession allows for creating, storing and loading [[PropertyGraph]] instances as well as\n+ * executing Cypher queries on them.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession extends Logging {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @see <a href=\"https://neo4j.com/docs/cypher-manual/current/\">Cypher Manual</a>\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @see <a href=\"https://neo4j.com/docs/cypher-manual/current/\">Cypher Manual</a>\n+   * @see <a href=\"https://neo4j.com/docs/cypher-manual/current/syntax/parameters/\">Parameters</a>"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Let's remove these two lines.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-10T06:18:22Z",
    "diffHunk": "@@ -0,0 +1,263 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * A CypherSession allows for creating, storing and loading [[PropertyGraph]] instances as well as\n+ * executing Cypher queries on them.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession extends Logging {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @see <a href=\"https://neo4j.com/docs/cypher-manual/current/\">Cypher Manual</a>\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @see <a href=\"https://neo4j.com/docs/cypher-manual/current/\">Cypher Manual</a>\n+   * @see <a href=\"https://neo4j.com/docs/cypher-manual/current/syntax/parameters/\">Parameters</a>\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @see <a href=\"https://neo4j.com/docs/cypher-manual/current/\">Cypher Manual</a>\n+   * @see <a href=\"https://neo4j.com/docs/cypher-manual/current/syntax/parameters/\">Parameters</a>"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "```scala\r\n-import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\r\n+import org.apache.spark.sql.{DataFrame, SparkSession}\r\n```",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T03:09:26Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Actually, the following for the final update.\r\n```scala\r\n-import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\r\n+import org.apache.spark.sql.{Dataset, Row, SparkSession}\r\n```",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T03:34:54Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "```scala\r\n-  def buildNodeFrame(df: DataFrame): NodeFrameBuilder =\r\n+  def buildNodeFrame(df: Dataset[Row]): NodeFrameBuilder =\r\n```",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T03:35:45Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * A CypherSession allows for creating, storing and loading [[PropertyGraph]] instances as well as\n+ * executing Cypher queries on them.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession extends Logging {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(\n+      graph: PropertyGraph,\n+      query: String,\n+      parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Array[NodeFrame], relationships: Array[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @note It is recommended to cache the input DataFrames if they represent multiple label sets and\n+   *       relationship types.\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    def validateLabelColumns(schema: StructType, columns: Set[String]): Unit = {\n+      schema.fields.filter(f => columns.contains(f.name)).foreach(field => {\n+        if (field.dataType != BooleanType) {\n+          throw new IllegalArgumentException(s\"Column ${field.name} must be of type BooleanType.\")\n+        }\n+      })\n+    }\n+\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    validateLabelColumns(nodes.schema, labelColumns)\n+\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val labelCount = labelColumns.size\n+    if (labelCount > 5) {\n+      log.warn(\n+        s\"$labelCount label columns will result in ${Math.pow(labelCount, 2)} node frames.\")\n+      if (labelCount > 10) {\n+        throw new IllegalArgumentException(\n+          s\"Expected number of label columns to be less than or equal to 10, was $labelCount.\")\n+      }\n+    }\n+\n+    val labelSets = labelColumns.subsets().toSet\n+\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map { labelColumn =>\n+          if (labelSet.contains(labelColumn)) {\n+            nodes.col(labelColumn)\n+          } else {\n+            !nodes.col(labelColumn)\n+          }\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    validateLabelColumns(relationships.schema, relTypeColumns)\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn)\n+\n+      RelationshipFrame(\n+        relationships.filter(predicate),\n+        idColumn,\n+        sourceIdColumn,\n+        targetIdColumn,\n+        relTypeColumn.substring(1),\n+        relProperties)\n+    }\n+\n+    createGraph(nodeFrames.toArray, relFrames.toArray)\n+  }\n+\n+  /**\n+   * Returns a [[PropertyGraphReader]] that can be used to read data in as a `PropertyGraph`.\n+   *\n+   * @since 3.0.0\n+   */\n+  def read: PropertyGraphReader\n+\n+  /**\n+   * Returns a [[NodeFrameBuilder]] that can be used to construct a [[NodeFrame]].\n+   *\n+   * @param df DataFrame containing a single node in each row\n+   * @since 3.0.0\n+   */\n+  def buildNodeFrame(df: DataFrame): NodeFrameBuilder ="
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "```scala\r\n-  def buildRelationshipFrame(df: DataFrame): RelationshipFrameBuilder =\r\n+  def buildRelationshipFrame(df: Dataset[Row]): RelationshipFrameBuilder =\r\n```",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T03:35:55Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * A CypherSession allows for creating, storing and loading [[PropertyGraph]] instances as well as\n+ * executing Cypher queries on them.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession extends Logging {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(\n+      graph: PropertyGraph,\n+      query: String,\n+      parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Array[NodeFrame], relationships: Array[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given DataFrames need to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @note It is recommended to cache the input DataFrames if they represent multiple label sets and\n+   *       relationship types.\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node DataFrame\n+   * @param relationships relationship DataFrame\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: DataFrame, relationships: DataFrame): PropertyGraph = {\n+    def validateLabelColumns(schema: StructType, columns: Set[String]): Unit = {\n+      schema.fields.filter(f => columns.contains(f.name)).foreach(field => {\n+        if (field.dataType != BooleanType) {\n+          throw new IllegalArgumentException(s\"Column ${field.name} must be of type BooleanType.\")\n+        }\n+      })\n+    }\n+\n+    val idColumn = CypherSession.ID_COLUMN\n+    val sourceIdColumn = CypherSession.SOURCE_ID_COLUMN\n+    val targetIdColumn = CypherSession.TARGET_ID_COLUMN\n+\n+    val labelColumns = nodes.columns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX)).toSet\n+    validateLabelColumns(nodes.schema, labelColumns)\n+\n+    val nodeProperties = (nodes.columns.toSet - idColumn -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val labelCount = labelColumns.size\n+    if (labelCount > 5) {\n+      log.warn(\n+        s\"$labelCount label columns will result in ${Math.pow(labelCount, 2)} node frames.\")\n+      if (labelCount > 10) {\n+        throw new IllegalArgumentException(\n+          s\"Expected number of label columns to be less than or equal to 10, was $labelCount.\")\n+      }\n+    }\n+\n+    val labelSets = labelColumns.subsets().toSet\n+\n+    val nodeFrames = labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map { labelColumn =>\n+          if (labelSet.contains(labelColumn)) {\n+            nodes.col(labelColumn)\n+          } else {\n+            !nodes.col(labelColumn)\n+          }\n+        }\n+        .reduce(_ && _)\n+\n+      NodeFrame(nodes.filter(predicate), idColumn, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+\n+    val relColumns = relationships.columns.toSet\n+    val relTypeColumns = relColumns.filter(_.startsWith(CypherSession.LABEL_COLUMN_PREFIX))\n+    validateLabelColumns(relationships.schema, relTypeColumns)\n+    val propertyColumns = relColumns - idColumn - sourceIdColumn - targetIdColumn -- relTypeColumns\n+    val relProperties = propertyColumns.map(col => col -> col).toMap\n+    val relFrames = relTypeColumns.map { relTypeColumn =>\n+      val predicate = relationships.col(relTypeColumn)\n+\n+      RelationshipFrame(\n+        relationships.filter(predicate),\n+        idColumn,\n+        sourceIdColumn,\n+        targetIdColumn,\n+        relTypeColumn.substring(1),\n+        relProperties)\n+    }\n+\n+    createGraph(nodeFrames.toArray, relFrames.toArray)\n+  }\n+\n+  /**\n+   * Returns a [[PropertyGraphReader]] that can be used to read data in as a `PropertyGraph`.\n+   *\n+   * @since 3.0.0\n+   */\n+  def read: PropertyGraphReader\n+\n+  /**\n+   * Returns a [[NodeFrameBuilder]] that can be used to construct a [[NodeFrame]].\n+   *\n+   * @param df DataFrame containing a single node in each row\n+   * @since 3.0.0\n+   */\n+  def buildNodeFrame(df: DataFrame): NodeFrameBuilder =\n+    new NodeFrameBuilder(df)\n+\n+  /**\n+   * Returns a [[RelationshipFrameBuilder]] that can be used to construct a [[RelationshipFrame]].\n+   *\n+   * @param df DataFrame containing a single relationship in each row\n+   * @since 3.0.0\n+   */\n+  def buildRelationshipFrame(df: DataFrame): RelationshipFrameBuilder ="
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Let's move the most of function logic (line 168 ~229) to `object CyperSession` by making an explicit helper function.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T14:51:32Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{Dataset, Row, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * A CypherSession allows for creating, storing and loading [[PropertyGraph]] instances as well as\n+ * executing Cypher queries on them.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession extends Logging {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(\n+      graph: PropertyGraph,\n+      query: String,\n+      parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Array[NodeFrame], relationships: Array[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given dataset needs to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @note It is recommended to cache the input datasets if they represent multiple label sets and\n+   *       relationship types.\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node dataset\n+   * @param relationships relationship dataset\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Dataset[Row], relationships: Dataset[Row]): PropertyGraph = {",
    "line": 277
  }, {
    "author": {
      "login": "Mats-SX"
    },
    "body": "How do you propose we inject the `Logging` instance to still be able to log the warning?",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T16:01:07Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{Dataset, Row, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * A CypherSession allows for creating, storing and loading [[PropertyGraph]] instances as well as\n+ * executing Cypher queries on them.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession extends Logging {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(\n+      graph: PropertyGraph,\n+      query: String,\n+      parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Array[NodeFrame], relationships: Array[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given dataset needs to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @note It is recommended to cache the input datasets if they represent multiple label sets and\n+   *       relationship types.\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node dataset\n+   * @param relationships relationship dataset\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Dataset[Row], relationships: Dataset[Row]): PropertyGraph = {",
    "line": 277
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "That is not the main reason to ask this. The logic is really helper logic. We had better move that out to this `trait`.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T16:13:31Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{Dataset, Row, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * A CypherSession allows for creating, storing and loading [[PropertyGraph]] instances as well as\n+ * executing Cypher queries on them.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession extends Logging {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(\n+      graph: PropertyGraph,\n+      query: String,\n+      parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Array[NodeFrame], relationships: Array[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given dataset needs to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @note It is recommended to cache the input datasets if they represent multiple label sets and\n+   *       relationship types.\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node dataset\n+   * @param relationships relationship dataset\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Dataset[Row], relationships: Dataset[Row]): PropertyGraph = {",
    "line": 277
  }, {
    "author": {
      "login": "Mats-SX"
    },
    "body": "I agree.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-12T11:32:13Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{Dataset, Row, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * A CypherSession allows for creating, storing and loading [[PropertyGraph]] instances as well as\n+ * executing Cypher queries on them.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession extends Logging {\n+\n+  def sparkSession: SparkSession\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * @param graph [[PropertyGraph]] on which the query is executed\n+   * @param query Cypher query to execute\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(graph: PropertyGraph, query: String, parameters: Map[String, Any]): CypherResult\n+\n+  /**\n+   * Executes a Cypher query on the given input graph.\n+   *\n+   * Note that queries can take optional parameters:\n+   *\n+   * {{{\n+   *     Parameters:\n+   *\n+   *     {\n+   *        \"name\" : \"Alice\"\n+   *     }\n+   *\n+   *     Query:\n+   *\n+   *     MATCH (n:Person)\n+   *     WHERE n.name = $name\n+   *     RETURN n\n+   * }}}\n+   *\n+   * @param graph      [[PropertyGraph]] on which the query is executed\n+   * @param query      Cypher query to execute\n+   * @param parameters parameters used by the Cypher query\n+   * @since 3.0.0\n+   */\n+  def cypher(\n+      graph: PropertyGraph,\n+      query: String,\n+      parameters: java.util.Map[String, Object]): CypherResult = {\n+    cypher(graph, query, parameters.asScala.toMap)\n+  }\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from a sequence of [[NodeFrame]]s and [[RelationshipFrame]]s.\n+   * At least one [[NodeFrame]] has to be provided.\n+   *\n+   * For each label set and relationship type there can be at most one [[NodeFrame]] and at most one\n+   * [[RelationshipFrame]], respectively.\n+   *\n+   * @param nodes         NodeFrames that define the nodes in the graph\n+   * @param relationships RelationshipFrames that define the relationships in the graph\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Array[NodeFrame], relationships: Array[RelationshipFrame]): PropertyGraph\n+\n+  /**\n+   * Creates a [[PropertyGraph]] from nodes and relationships.\n+   *\n+   * The given dataset needs to adhere to the following column naming conventions:\n+   *\n+   * {{{\n+   *     Id column:        `$ID`            (nodes and relationships)\n+   *     SourceId column:  `$SOURCE_ID`     (relationships)\n+   *     TargetId column:  `$TARGET_ID`     (relationships)\n+   *\n+   *     Label columns:    `:{LABEL_NAME}`  (nodes)\n+   *     RelType columns:  `:{REL_TYPE}`    (relationships)\n+   *\n+   *     Property columns: `{Property_Key}` (nodes and relationships)\n+   * }}}\n+   *\n+   * @note It is recommended to cache the input datasets if they represent multiple label sets and\n+   *       relationship types.\n+   *\n+   * @see [[CypherSession]]\n+   * @param nodes         node dataset\n+   * @param relationships relationship dataset\n+   * @since 3.0.0\n+   */\n+  def createGraph(nodes: Dataset[Row], relationships: Dataset[Row]): PropertyGraph = {",
    "line": 277
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "After moving the [helper logic](https://github.com/apache/spark/pull/24851/files#r334031051), you can remove `extends Logging` here.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-11T14:55:30Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{Dataset, Row, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+}\n+\n+/**\n+ * A CypherSession allows for creating, storing and loading [[PropertyGraph]] instances as well as\n+ * executing Cypher queries on them.\n+ *\n+ * Wraps a [[org.apache.spark.sql.SparkSession]].\n+ *\n+ * @since 3.0.0\n+ */\n+trait CypherSession extends Logging {"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "+1 for your suggestion. `extractNodeDataset` -> `extractNodeDatasets`.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-14T16:42:27Z",
    "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.annotation.Evolving\n+import org.apache.spark.sql.{Dataset, Row, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+@Evolving\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+\n+  /**\n+   * Extracts [[NodeDataset]]s from a [[Dataset]] using column name conventions.\n+   *\n+   * For information about naming conventions, see [[CypherSession.createGraph]].\n+   *\n+   * @param nodes node dataset\n+   * @since 3.0.0\n+   */\n+  def extractNodeDataset(nodes: Dataset[Row]): Set[NodeDataset] = {"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "+1 for your suggestion, `extractRelationshipDataset` -> `extractRelationshipDatasets`.",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-14T16:42:44Z",
    "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.annotation.Evolving\n+import org.apache.spark.sql.{Dataset, Row, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+@Evolving\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+\n+  /**\n+   * Extracts [[NodeDataset]]s from a [[Dataset]] using column name conventions.\n+   *\n+   * For information about naming conventions, see [[CypherSession.createGraph]].\n+   *\n+   * @param nodes node dataset\n+   * @since 3.0.0\n+   */\n+  def extractNodeDataset(nodes: Dataset[Row]): Set[NodeDataset] = {\n+    val labelColumns = nodes.columns.filter(_.startsWith(LABEL_COLUMN_PREFIX)).toSet\n+    validateLabelColumns(nodes.schema, labelColumns)\n+\n+    val nodeProperties = (nodes.columns.toSet - ID_COLUMN -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val labelCount = labelColumns.size\n+    if (labelCount > 5) {\n+      LoggerFactory.getLogger(CypherSession.getClass).warn(\n+        s\"$labelCount label columns will result in ${Math.pow(labelCount, 2)} node frames.\")\n+      if (labelCount > 10) {\n+        throw new IllegalArgumentException(\n+          s\"Expected number of label columns to be less than or equal to 10, was $labelCount.\")\n+      }\n+    }\n+\n+    val labelSets = labelColumns.subsets().toSet\n+\n+    labelSets.map { labelSet =>\n+      val predicate = labelColumns\n+        .map { labelColumn =>\n+          if (labelSet.contains(labelColumn)) {\n+            nodes.col(labelColumn)\n+          } else {\n+            !nodes.col(labelColumn)\n+          }\n+        }\n+        .reduce(_ && _)\n+\n+      NodeDataset(nodes.filter(predicate), ID_COLUMN, labelSet.map(_.substring(1)), nodeProperties)\n+    }\n+  }\n+\n+  /**\n+   * Extracts [[RelationshipDataset]]s from a [[Dataset]] using column name conventions.\n+   *\n+   * For information about naming conventions, see [[CypherSession.createGraph]].\n+   *\n+   * @param relationships relationship dataset\n+   * @since 3.0.0\n+   */\n+  def extractRelationshipDataset(relationships: Dataset[Row]): Set[RelationshipDataset] = {"
  }],
  "prId": 24851
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "nit: `node datasets`",
    "commit": "44a955bdbe7f9ef88b69193635e1678668584ea3",
    "createdAt": "2019-10-14T17:46:46Z",
    "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graph.api\n+\n+import scala.collection.JavaConverters._\n+\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.annotation.Evolving\n+import org.apache.spark.sql.{Dataset, Row, SparkSession}\n+import org.apache.spark.sql.types.{BooleanType, StructType}\n+\n+/**\n+ * Contains constants used for convention based column naming.\n+ */\n+@Evolving\n+object CypherSession {\n+\n+  /**\n+   * Naming convention for identifier columns, both node and relationship identifiers.\n+   */\n+  val ID_COLUMN = \"$ID\"\n+\n+  /**\n+   * Naming convention for relationship source identifier.\n+   */\n+  val SOURCE_ID_COLUMN = \"$SOURCE_ID\"\n+\n+  /**\n+   * Naming convention for relationship target identifier.\n+   */\n+  val TARGET_ID_COLUMN = \"$TARGET_ID\"\n+\n+  /**\n+   * Naming convention both for node label and relationship type prefixes.\n+   */\n+  val LABEL_COLUMN_PREFIX = \":\"\n+\n+  /**\n+   * Extracts [[NodeDataset]]s from a [[Dataset]] using column name conventions.\n+   *\n+   * For information about naming conventions, see [[CypherSession.createGraph]].\n+   *\n+   * @param nodes node dataset\n+   * @since 3.0.0\n+   */\n+  def extractNodeDatasets(nodes: Dataset[Row]): Set[NodeDataset] = {\n+    val labelColumns = nodes.columns.filter(_.startsWith(LABEL_COLUMN_PREFIX)).toSet\n+    validateLabelColumns(nodes.schema, labelColumns)\n+\n+    val nodeProperties = (nodes.columns.toSet - ID_COLUMN -- labelColumns)\n+      .map(col => col -> col)\n+      .toMap\n+\n+    val labelCount = labelColumns.size\n+    if (labelCount > 5) {\n+      LoggerFactory.getLogger(CypherSession.getClass).warn(\n+        s\"$labelCount label columns will result in ${Math.pow(labelCount, 2)} node frames.\")"
  }],
  "prId": 24851
}]