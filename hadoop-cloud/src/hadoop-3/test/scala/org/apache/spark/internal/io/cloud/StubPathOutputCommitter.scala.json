[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Is this helpful? What's wrong with `classOf[StubPathOutputCommitterFactory].getName()`?",
    "commit": "ee247d9c473f665791da1bbc84e1f61b35ff8dc1",
    "createdAt": "2019-06-26T21:47:32Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.lib.output.{PathOutputCommitter, PathOutputCommitterFactory}\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+\n+/**\n+ * A local path output committer which tracks its state, for use in\n+ * tests.\n+ * @param outputPath final destination.\n+ * @param workPath work path\n+ * @param context task/job attempt.\n+ */\n+class StubPathOutputCommitter(\n+    outputPath: Path,\n+    workPath: Path,\n+    context: TaskAttemptContext) extends PathOutputCommitter(workPath, context) {\n+\n+  var jobSetup: Boolean = false\n+  var jobCommitted: Boolean = false\n+  var jobAborted: Boolean = false\n+\n+  var taskSetup: Boolean = false\n+  var taskCommitted: Boolean = false\n+  var taskAborted: Boolean = false\n+  var needsTaskCommit: Boolean = true\n+\n+  override def getOutputPath: Path = outputPath\n+\n+  override def getWorkPath: Path = {\n+    workPath\n+  }\n+\n+  override def setupTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskSetup = true\n+  }\n+\n+  override def abortTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskAborted = true\n+  }\n+\n+  override def commitTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskCommitted = true\n+  }\n+\n+  override def setupJob(jobContext: JobContext): Unit = {\n+    jobSetup = true\n+  }\n+\n+  override def commitJob(jobContext: JobContext): Unit = {\n+    jobCommitted = true\n+  }\n+\n+  override def abortJob(\n+      jobContext: JobContext,\n+      state: JobStatus.State): Unit = {\n+    jobAborted = true\n+  }\n+\n+  override def needsTaskCommit(taskAttemptContext: TaskAttemptContext): Boolean = {\n+    needsTaskCommit\n+  }\n+\n+  override def toString(): String  = s\"StubPathOutputCommitter(setup=$jobSetup,\" +\n+    s\" committed=$jobCommitted, aborted=$jobAborted)\"\n+}\n+\n+/**\n+ * Factory.\n+ */\n+class StubPathOutputCommitterFactory extends PathOutputCommitterFactory {\n+\n+  override def createOutputCommitter(\n+      outputPath: Path,\n+      context: TaskAttemptContext): PathOutputCommitter = {\n+    new StubPathOutputCommitter(outputPath, workPath(outputPath), context)\n+  }\n+\n+\n+  private def workPath(out: Path): Path = new Path(out, PathCommitterConstants.TEMP_DIR_NAME)\n+}\n+\n+object StubPathOutputCommitterFactory {\n+  val Name: String = \"org.apache.spark.internal.io.cloud.StubPathOutputCommitterFactory\""
  }],
  "prId": 24970
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Pretty obvious from the class name.",
    "commit": "ee247d9c473f665791da1bbc84e1f61b35ff8dc1",
    "createdAt": "2019-08-01T20:35:20Z",
    "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.output.{PathOutputCommitter, PathOutputCommitterFactory}\n+\n+/**\n+ * A local path output committer which tracks its state, for use in\n+ * tests.\n+ * @param outputPath final destination.\n+ * @param workPath work path\n+ * @param context task/job attempt.\n+ */\n+class StubPathOutputCommitter(\n+    outputPath: Path,\n+    workPath: Path,\n+    context: TaskAttemptContext) extends PathOutputCommitter(workPath, context) {\n+\n+  var jobSetup: Boolean = false\n+  var jobCommitted: Boolean = false\n+  var jobAborted: Boolean = false\n+\n+  var taskSetup: Boolean = false\n+  var taskCommitted: Boolean = false\n+  var taskAborted: Boolean = false\n+  var needsTaskCommit: Boolean = true\n+\n+  override def getOutputPath: Path = outputPath\n+\n+  override def getWorkPath: Path = {\n+    workPath\n+  }\n+\n+  override def setupTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskSetup = true\n+  }\n+\n+  override def abortTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskAborted = true\n+  }\n+\n+  override def commitTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskCommitted = true\n+  }\n+\n+  override def setupJob(jobContext: JobContext): Unit = {\n+    jobSetup = true\n+  }\n+\n+  override def commitJob(jobContext: JobContext): Unit = {\n+    jobCommitted = true\n+  }\n+\n+  override def abortJob(\n+      jobContext: JobContext,\n+      state: JobStatus.State): Unit = {\n+    jobAborted = true\n+  }\n+\n+  override def needsTaskCommit(taskAttemptContext: TaskAttemptContext): Boolean = {\n+    needsTaskCommit\n+  }\n+\n+  override def toString(): String = s\"StubPathOutputCommitter(setup=$jobSetup,\" +\n+    s\" committed=$jobCommitted, aborted=$jobAborted)\"\n+}\n+\n+/**\n+ * Factory."
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "cut",
    "commit": "ee247d9c473f665791da1bbc84e1f61b35ff8dc1",
    "createdAt": "2019-08-02T16:49:54Z",
    "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.output.{PathOutputCommitter, PathOutputCommitterFactory}\n+\n+/**\n+ * A local path output committer which tracks its state, for use in\n+ * tests.\n+ * @param outputPath final destination.\n+ * @param workPath work path\n+ * @param context task/job attempt.\n+ */\n+class StubPathOutputCommitter(\n+    outputPath: Path,\n+    workPath: Path,\n+    context: TaskAttemptContext) extends PathOutputCommitter(workPath, context) {\n+\n+  var jobSetup: Boolean = false\n+  var jobCommitted: Boolean = false\n+  var jobAborted: Boolean = false\n+\n+  var taskSetup: Boolean = false\n+  var taskCommitted: Boolean = false\n+  var taskAborted: Boolean = false\n+  var needsTaskCommit: Boolean = true\n+\n+  override def getOutputPath: Path = outputPath\n+\n+  override def getWorkPath: Path = {\n+    workPath\n+  }\n+\n+  override def setupTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskSetup = true\n+  }\n+\n+  override def abortTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskAborted = true\n+  }\n+\n+  override def commitTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskCommitted = true\n+  }\n+\n+  override def setupJob(jobContext: JobContext): Unit = {\n+    jobSetup = true\n+  }\n+\n+  override def commitJob(jobContext: JobContext): Unit = {\n+    jobCommitted = true\n+  }\n+\n+  override def abortJob(\n+      jobContext: JobContext,\n+      state: JobStatus.State): Unit = {\n+    jobAborted = true\n+  }\n+\n+  override def needsTaskCommit(taskAttemptContext: TaskAttemptContext): Boolean = {\n+    needsTaskCommit\n+  }\n+\n+  override def toString(): String = s\"StubPathOutputCommitter(setup=$jobSetup,\" +\n+    s\" committed=$jobCommitted, aborted=$jobAborted)\"\n+}\n+\n+/**\n+ * Factory."
  }],
  "prId": 24970
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: too many empty lines",
    "commit": "ee247d9c473f665791da1bbc84e1f61b35ff8dc1",
    "createdAt": "2019-08-01T20:35:44Z",
    "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.output.{PathOutputCommitter, PathOutputCommitterFactory}\n+\n+/**\n+ * A local path output committer which tracks its state, for use in\n+ * tests.\n+ * @param outputPath final destination.\n+ * @param workPath work path\n+ * @param context task/job attempt.\n+ */\n+class StubPathOutputCommitter(\n+    outputPath: Path,\n+    workPath: Path,\n+    context: TaskAttemptContext) extends PathOutputCommitter(workPath, context) {\n+\n+  var jobSetup: Boolean = false\n+  var jobCommitted: Boolean = false\n+  var jobAborted: Boolean = false\n+\n+  var taskSetup: Boolean = false\n+  var taskCommitted: Boolean = false\n+  var taskAborted: Boolean = false\n+  var needsTaskCommit: Boolean = true\n+\n+  override def getOutputPath: Path = outputPath\n+\n+  override def getWorkPath: Path = {\n+    workPath\n+  }\n+\n+  override def setupTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskSetup = true\n+  }\n+\n+  override def abortTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskAborted = true\n+  }\n+\n+  override def commitTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskCommitted = true\n+  }\n+\n+  override def setupJob(jobContext: JobContext): Unit = {\n+    jobSetup = true\n+  }\n+\n+  override def commitJob(jobContext: JobContext): Unit = {\n+    jobCommitted = true\n+  }\n+\n+  override def abortJob(\n+      jobContext: JobContext,\n+      state: JobStatus.State): Unit = {\n+    jobAborted = true\n+  }\n+\n+  override def needsTaskCommit(taskAttemptContext: TaskAttemptContext): Boolean = {\n+    needsTaskCommit\n+  }\n+\n+  override def toString(): String = s\"StubPathOutputCommitter(setup=$jobSetup,\" +\n+    s\" committed=$jobCommitted, aborted=$jobAborted)\"\n+}\n+\n+/**\n+ * Factory.\n+ */\n+class StubPathOutputCommitterFactory extends PathOutputCommitterFactory {\n+\n+  override def createOutputCommitter(\n+      outputPath: Path,\n+      context: TaskAttemptContext): PathOutputCommitter = {\n+    new StubPathOutputCommitter(outputPath, workPath(outputPath), context)\n+  }\n+\n+\n+  private def workPath(out: Path): Path = new Path(out,\n+    StubPathOutputCommitterFactory.TEMP_DIR_NAME)\n+}\n+\n+object StubPathOutputCommitterFactory {\n+\n+  /**\n+   * This is the \"Pending\" directory of the FileOutputCommitter;\n+   * data written here is, in that algorithm, renamed into place.\n+   */\n+  val TEMP_DIR_NAME = \"_temporary\"\n+\n+  /**\n+   * Scheme prefix for per-filesystem scheme committers.\n+   */\n+  val OUTPUTCOMMITTER_FACTORY_SCHEME = \"mapreduce.outputcommitter.factory.scheme\"\n+\n+  /**\n+   * Given a hadoop configuration, set up the factory binding for the scheme.\n+   * @param conf config to patch\n+   * @param scheme filesystem scheme.\n+   */\n+  def bind(conf: Configuration, scheme: String): Unit = {\n+    val key = OUTPUTCOMMITTER_FACTORY_SCHEME + \".\" + scheme\n+    conf.set(key, classOf[StubPathOutputCommitterFactory].getName())\n+  }\n+",
    "line": 119
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "fixed",
    "commit": "ee247d9c473f665791da1bbc84e1f61b35ff8dc1",
    "createdAt": "2019-08-02T16:50:40Z",
    "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.output.{PathOutputCommitter, PathOutputCommitterFactory}\n+\n+/**\n+ * A local path output committer which tracks its state, for use in\n+ * tests.\n+ * @param outputPath final destination.\n+ * @param workPath work path\n+ * @param context task/job attempt.\n+ */\n+class StubPathOutputCommitter(\n+    outputPath: Path,\n+    workPath: Path,\n+    context: TaskAttemptContext) extends PathOutputCommitter(workPath, context) {\n+\n+  var jobSetup: Boolean = false\n+  var jobCommitted: Boolean = false\n+  var jobAborted: Boolean = false\n+\n+  var taskSetup: Boolean = false\n+  var taskCommitted: Boolean = false\n+  var taskAborted: Boolean = false\n+  var needsTaskCommit: Boolean = true\n+\n+  override def getOutputPath: Path = outputPath\n+\n+  override def getWorkPath: Path = {\n+    workPath\n+  }\n+\n+  override def setupTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskSetup = true\n+  }\n+\n+  override def abortTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskAborted = true\n+  }\n+\n+  override def commitTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    taskCommitted = true\n+  }\n+\n+  override def setupJob(jobContext: JobContext): Unit = {\n+    jobSetup = true\n+  }\n+\n+  override def commitJob(jobContext: JobContext): Unit = {\n+    jobCommitted = true\n+  }\n+\n+  override def abortJob(\n+      jobContext: JobContext,\n+      state: JobStatus.State): Unit = {\n+    jobAborted = true\n+  }\n+\n+  override def needsTaskCommit(taskAttemptContext: TaskAttemptContext): Boolean = {\n+    needsTaskCommit\n+  }\n+\n+  override def toString(): String = s\"StubPathOutputCommitter(setup=$jobSetup,\" +\n+    s\" committed=$jobCommitted, aborted=$jobAborted)\"\n+}\n+\n+/**\n+ * Factory.\n+ */\n+class StubPathOutputCommitterFactory extends PathOutputCommitterFactory {\n+\n+  override def createOutputCommitter(\n+      outputPath: Path,\n+      context: TaskAttemptContext): PathOutputCommitter = {\n+    new StubPathOutputCommitter(outputPath, workPath(outputPath), context)\n+  }\n+\n+\n+  private def workPath(out: Path): Path = new Path(out,\n+    StubPathOutputCommitterFactory.TEMP_DIR_NAME)\n+}\n+\n+object StubPathOutputCommitterFactory {\n+\n+  /**\n+   * This is the \"Pending\" directory of the FileOutputCommitter;\n+   * data written here is, in that algorithm, renamed into place.\n+   */\n+  val TEMP_DIR_NAME = \"_temporary\"\n+\n+  /**\n+   * Scheme prefix for per-filesystem scheme committers.\n+   */\n+  val OUTPUTCOMMITTER_FACTORY_SCHEME = \"mapreduce.outputcommitter.factory.scheme\"\n+\n+  /**\n+   * Given a hadoop configuration, set up the factory binding for the scheme.\n+   * @param conf config to patch\n+   * @param scheme filesystem scheme.\n+   */\n+  def bind(conf: Configuration, scheme: String): Unit = {\n+    val key = OUTPUTCOMMITTER_FACTORY_SCHEME + \".\" + scheme\n+    conf.set(key, classOf[StubPathOutputCommitterFactory].getName())\n+  }\n+",
    "line": 119
  }],
  "prId": 24970
}]