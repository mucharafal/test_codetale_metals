[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: nuke empty line",
    "commit": "cb46f89aa6615d2b28edce6142c951300710c439",
    "createdAt": "2018-04-25T22:17:34Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import java.io.IOException\n+\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.lib.output.{BindingPathOutputCommitter, PathOutputCommitter}\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+import org.apache.parquet.hadoop.ParquetOutputCommitter\n+\n+import org.apache.spark.internal.Logging\n+\n+\n+/**\n+ * This dynamically binds to the factory-configured\n+ * output committer, and is intended to allow callers to use any [[PathOutputCommitter]],\n+ * even if not a subclass of [[ParquetOutputCommitter]].\n+ *\n+ * The Parquet \"parquet.enable.summary-metadata\" option will only be supported\n+ * if the instantiated committer itself supports it.\n+ */\n+"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "done",
    "commit": "cb46f89aa6615d2b28edce6142c951300710c439",
    "createdAt": "2018-05-07T16:08:10Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import java.io.IOException\n+\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.lib.output.{BindingPathOutputCommitter, PathOutputCommitter}\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+import org.apache.parquet.hadoop.ParquetOutputCommitter\n+\n+import org.apache.spark.internal.Logging\n+\n+\n+/**\n+ * This dynamically binds to the factory-configured\n+ * output committer, and is intended to allow callers to use any [[PathOutputCommitter]],\n+ * even if not a subclass of [[ParquetOutputCommitter]].\n+ *\n+ * The Parquet \"parquet.enable.summary-metadata\" option will only be supported\n+ * if the instantiated committer itself supports it.\n+ */\n+"
  }],
  "prId": 21066
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "What is \"this\"?",
    "commit": "cb46f89aa6615d2b28edce6142c951300710c439",
    "createdAt": "2018-04-25T22:17:41Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import java.io.IOException\n+\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.lib.output.{BindingPathOutputCommitter, PathOutputCommitter}\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+import org.apache.parquet.hadoop.ParquetOutputCommitter\n+\n+import org.apache.spark.internal.Logging\n+\n+\n+/**\n+ * This dynamically binds to the factory-configured"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "\"Parquet Committer subclass \"",
    "commit": "cb46f89aa6615d2b28edce6142c951300710c439",
    "createdAt": "2018-05-07T16:07:59Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import java.io.IOException\n+\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.lib.output.{BindingPathOutputCommitter, PathOutputCommitter}\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+import org.apache.parquet.hadoop.ParquetOutputCommitter\n+\n+import org.apache.spark.internal.Logging\n+\n+\n+/**\n+ * This dynamically binds to the factory-configured"
  }],
  "prId": 21066
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`private`?",
    "commit": "cb46f89aa6615d2b28edce6142c951300710c439",
    "createdAt": "2018-04-25T22:19:35Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import java.io.IOException\n+\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.lib.output.{BindingPathOutputCommitter, PathOutputCommitter}\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+import org.apache.parquet.hadoop.ParquetOutputCommitter\n+\n+import org.apache.spark.internal.Logging\n+\n+\n+/**\n+ * This dynamically binds to the factory-configured\n+ * output committer, and is intended to allow callers to use any [[PathOutputCommitter]],\n+ * even if not a subclass of [[ParquetOutputCommitter]].\n+ *\n+ * The Parquet \"parquet.enable.summary-metadata\" option will only be supported\n+ * if the instantiated committer itself supports it.\n+ */\n+\n+class BindingParquetOutputCommitter(\n+    path: Path,\n+    context: TaskAttemptContext)\n+  extends ParquetOutputCommitter(path, context) with Logging {\n+\n+  logInfo(s\"${this.getClass.getName} binding to configured PathOutputCommitter and dest $path\")\n+\n+  val committer = new BindingPathOutputCommitter(path, context)",
    "line": 45
  }],
  "prId": 21066
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Why not just let it propagate?",
    "commit": "cb46f89aa6615d2b28edce6142c951300710c439",
    "createdAt": "2018-04-25T22:21:31Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import java.io.IOException\n+\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.lib.output.{BindingPathOutputCommitter, PathOutputCommitter}\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+import org.apache.parquet.hadoop.ParquetOutputCommitter\n+\n+import org.apache.spark.internal.Logging\n+\n+\n+/**\n+ * This dynamically binds to the factory-configured\n+ * output committer, and is intended to allow callers to use any [[PathOutputCommitter]],\n+ * even if not a subclass of [[ParquetOutputCommitter]].\n+ *\n+ * The Parquet \"parquet.enable.summary-metadata\" option will only be supported\n+ * if the instantiated committer itself supports it.\n+ */\n+\n+class BindingParquetOutputCommitter(\n+    path: Path,\n+    context: TaskAttemptContext)\n+  extends ParquetOutputCommitter(path, context) with Logging {\n+\n+  logInfo(s\"${this.getClass.getName} binding to configured PathOutputCommitter and dest $path\")\n+\n+  val committer = new BindingPathOutputCommitter(path, context)\n+\n+  /**\n+   * This is the committer ultimately bound to.\n+   * @return the committer instantiated by the factory.\n+   */\n+  def boundCommitter(): PathOutputCommitter = {\n+    committer.getCommitter()\n+  }\n+\n+  override def getWorkPath: Path = {\n+    committer.getWorkPath()\n+  }\n+\n+  override def setupTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    committer.setupTask(taskAttemptContext)\n+  }\n+\n+  override def commitTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    committer.commitTask(taskAttemptContext)\n+  }\n+\n+  override def abortTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    committer.abortTask(taskAttemptContext)\n+  }\n+\n+  override def setupJob(jobContext: JobContext): Unit = {\n+    committer.setupJob(jobContext)\n+  }\n+\n+  override def needsTaskCommit(taskAttemptContext: TaskAttemptContext): Boolean = {\n+    committer.needsTaskCommit(taskAttemptContext)\n+  }\n+\n+  override def cleanupJob(jobContext: JobContext): Unit = {\n+    committer.cleanupJob(jobContext)\n+  }\n+\n+  override def isCommitJobRepeatable(jobContext: JobContext): Boolean = {\n+    committer.isCommitJobRepeatable(jobContext)\n+  }\n+\n+  override def commitJob(jobContext: JobContext): Unit = {\n+    committer.commitJob(jobContext)\n+  }\n+\n+  override def recoverTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    committer.recoverTask(taskAttemptContext)\n+  }\n+\n+  /**\n+   * Abort the job; log and ignore any IO exception thrown.\n+   *\n+   * @param jobContext job context\n+   * @param state final state of the job\n+   */\n+  override def abortJob(\n+      jobContext: JobContext,\n+      state: JobStatus.State): Unit = {\n+    try {\n+      committer.abortJob(jobContext, state)\n+    } catch {\n+      case e: IOException =>",
    "line": 109
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "That's exactly the question @mridulm asked, which is why the next commit to this PR will mention in comments. Essentially: this abort operation is regularly used in exception handling code, and this code tends to assume that the abort() routine doesn't fail. If it does, then it can get rethrown and so hide the underlying failure which triggered the abort. \r\n\r\nThere's  an underlying question \"what do you do when the abort operation itself fails\", which lurks. \r\nFor HDFS &c, with the FS used as the dest, then `rm  -rf $dest` does that cleanup For S3, uncommitted uploads still incur charges, so you need to define a maximum lifespan of outstanding requests , e.g. 24h, and/or run the new hadoop cli calls to list/abort MPUs under a path. for a database, well, it's up to the DB I guess.\r\n\r\nWhat is important, though it's never explicitly called out is: *the uncommitted work of a previous job attempt must never form part of the final output of a successor*. The error handling here doesn't do anything to help or hinder that.",
    "commit": "cb46f89aa6615d2b28edce6142c951300710c439",
    "createdAt": "2018-05-07T15:55:00Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.io.cloud\n+\n+import java.io.IOException\n+\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.mapreduce.lib.output.{BindingPathOutputCommitter, PathOutputCommitter}\n+import org.apache.hadoop.mapreduce.{JobContext, JobStatus, TaskAttemptContext}\n+import org.apache.parquet.hadoop.ParquetOutputCommitter\n+\n+import org.apache.spark.internal.Logging\n+\n+\n+/**\n+ * This dynamically binds to the factory-configured\n+ * output committer, and is intended to allow callers to use any [[PathOutputCommitter]],\n+ * even if not a subclass of [[ParquetOutputCommitter]].\n+ *\n+ * The Parquet \"parquet.enable.summary-metadata\" option will only be supported\n+ * if the instantiated committer itself supports it.\n+ */\n+\n+class BindingParquetOutputCommitter(\n+    path: Path,\n+    context: TaskAttemptContext)\n+  extends ParquetOutputCommitter(path, context) with Logging {\n+\n+  logInfo(s\"${this.getClass.getName} binding to configured PathOutputCommitter and dest $path\")\n+\n+  val committer = new BindingPathOutputCommitter(path, context)\n+\n+  /**\n+   * This is the committer ultimately bound to.\n+   * @return the committer instantiated by the factory.\n+   */\n+  def boundCommitter(): PathOutputCommitter = {\n+    committer.getCommitter()\n+  }\n+\n+  override def getWorkPath: Path = {\n+    committer.getWorkPath()\n+  }\n+\n+  override def setupTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    committer.setupTask(taskAttemptContext)\n+  }\n+\n+  override def commitTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    committer.commitTask(taskAttemptContext)\n+  }\n+\n+  override def abortTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    committer.abortTask(taskAttemptContext)\n+  }\n+\n+  override def setupJob(jobContext: JobContext): Unit = {\n+    committer.setupJob(jobContext)\n+  }\n+\n+  override def needsTaskCommit(taskAttemptContext: TaskAttemptContext): Boolean = {\n+    committer.needsTaskCommit(taskAttemptContext)\n+  }\n+\n+  override def cleanupJob(jobContext: JobContext): Unit = {\n+    committer.cleanupJob(jobContext)\n+  }\n+\n+  override def isCommitJobRepeatable(jobContext: JobContext): Boolean = {\n+    committer.isCommitJobRepeatable(jobContext)\n+  }\n+\n+  override def commitJob(jobContext: JobContext): Unit = {\n+    committer.commitJob(jobContext)\n+  }\n+\n+  override def recoverTask(taskAttemptContext: TaskAttemptContext): Unit = {\n+    committer.recoverTask(taskAttemptContext)\n+  }\n+\n+  /**\n+   * Abort the job; log and ignore any IO exception thrown.\n+   *\n+   * @param jobContext job context\n+   * @param state final state of the job\n+   */\n+  override def abortJob(\n+      jobContext: JobContext,\n+      state: JobStatus.State): Unit = {\n+    try {\n+      committer.abortJob(jobContext, state)\n+    } catch {\n+      case e: IOException =>",
    "line": 109
  }],
  "prId": 21066
}]