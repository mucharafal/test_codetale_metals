[{
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "Can we deprecate this instead of removing it?  I think its fairly common for people to use this for their own unit tests.\n",
    "commit": "821ea67c303ddba92e2df908b422f1c54eb66e6a",
    "createdAt": "2015-08-12T23:21:41Z",
    "diffHunk": "@@ -37,39 +38,36 @@ import org.apache.spark.sql.execution.CacheTableCommand\n import org.apache.spark.sql.hive._\n import org.apache.spark.sql.hive.execution.HiveNativeCommand\n import org.apache.spark.util.Utils\n-import org.apache.spark.{SparkConf, SparkContext}\n \n /* Implicit conversions */\n import scala.collection.JavaConversions._\n \n-// SPARK-3729: Test key required to check for initialization errors with config.\n-object TestHive"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "do you mean outside of Spark? The point is to never use this in Spark tests, since even referencing it will destabilize the tests because it leaves two overlapping `SparkContext`s in the same JVM\n",
    "commit": "821ea67c303ddba92e2df908b422f1c54eb66e6a",
    "createdAt": "2015-08-12T23:28:21Z",
    "diffHunk": "@@ -37,39 +38,36 @@ import org.apache.spark.sql.execution.CacheTableCommand\n import org.apache.spark.sql.hive._\n import org.apache.spark.sql.hive.execution.HiveNativeCommand\n import org.apache.spark.util.Utils\n-import org.apache.spark.{SparkConf, SparkContext}\n \n /* Implicit conversions */\n import scala.collection.JavaConversions._\n \n-// SPARK-3729: Test key required to check for initialization errors with config.\n-object TestHive"
  }, {
    "author": {
      "login": "marmbrus"
    },
    "body": "Yes, we can avoid it in our own tests, but I know for a fact that it is used externally.\n",
    "commit": "821ea67c303ddba92e2df908b422f1c54eb66e6a",
    "createdAt": "2015-08-12T23:34:08Z",
    "diffHunk": "@@ -37,39 +38,36 @@ import org.apache.spark.sql.execution.CacheTableCommand\n import org.apache.spark.sql.hive._\n import org.apache.spark.sql.hive.execution.HiveNativeCommand\n import org.apache.spark.util.Utils\n-import org.apache.spark.{SparkConf, SparkContext}\n \n /* Implicit conversions */\n import scala.collection.JavaConversions._\n \n-// SPARK-3729: Test key required to check for initialization errors with config.\n-object TestHive"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "OK, I've added these back with a deprecation warning in the latest commit.\n",
    "commit": "821ea67c303ddba92e2df908b422f1c54eb66e6a",
    "createdAt": "2015-08-13T00:17:59Z",
    "diffHunk": "@@ -37,39 +38,36 @@ import org.apache.spark.sql.execution.CacheTableCommand\n import org.apache.spark.sql.hive._\n import org.apache.spark.sql.hive.execution.HiveNativeCommand\n import org.apache.spark.util.Utils\n-import org.apache.spark.{SparkConf, SparkContext}\n \n /* Implicit conversions */\n import scala.collection.JavaConversions._\n \n-// SPARK-3729: Test key required to check for initialization errors with config.\n-object TestHive"
  }],
  "prId": 8111
}]