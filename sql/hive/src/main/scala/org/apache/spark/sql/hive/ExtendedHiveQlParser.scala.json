[{
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Leave only 1 newline here.\n",
    "commit": "5a8a0df37728b7858647a06c8b41a6d0f81d267e",
    "createdAt": "2015-06-10T13:34:22Z",
    "diffHunk": "@@ -34,7 +34,12 @@ private[hive] class ExtendedHiveQlParser extends AbstractSparkSQLParser {\n   protected val FILE = Keyword(\"FILE\")\n   protected val JAR = Keyword(\"JAR\")\n \n-  protected lazy val start: Parser[LogicalPlan] = dfs | addJar | addFile | hiveQl\n+  protected val IN      = Keyword(\"IN\")\n+  protected val SHOW    = Keyword(\"SHOW\")\n+  protected val TABLES  = Keyword(\"TABLES\")\n+\n+"
  }],
  "prId": 6745
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Please avoid doing vertical aligning.\n",
    "commit": "5a8a0df37728b7858647a06c8b41a6d0f81d267e",
    "createdAt": "2015-06-10T13:34:53Z",
    "diffHunk": "@@ -34,7 +34,12 @@ private[hive] class ExtendedHiveQlParser extends AbstractSparkSQLParser {\n   protected val FILE = Keyword(\"FILE\")\n   protected val JAR = Keyword(\"JAR\")\n \n-  protected lazy val start: Parser[LogicalPlan] = dfs | addJar | addFile | hiveQl\n+  protected val IN      = Keyword(\"IN\")\n+  protected val SHOW    = Keyword(\"SHOW\")\n+  protected val TABLES  = Keyword(\"TABLES\")"
  }],
  "prId": 6745
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Remove this newline.\n",
    "commit": "5a8a0df37728b7858647a06c8b41a6d0f81d267e",
    "createdAt": "2015-06-10T13:34:58Z",
    "diffHunk": "@@ -34,7 +34,12 @@ private[hive] class ExtendedHiveQlParser extends AbstractSparkSQLParser {\n   protected val FILE = Keyword(\"FILE\")\n   protected val JAR = Keyword(\"JAR\")\n "
  }],
  "prId": 6745
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Nit: Please rename `reg`  to `regexPattern`.\n",
    "commit": "5a8a0df37728b7858647a06c8b41a6d0f81d267e",
    "createdAt": "2015-06-10T13:44:37Z",
    "diffHunk": "@@ -55,4 +60,9 @@ private[hive] class ExtendedHiveQlParser extends AbstractSparkSQLParser {\n     ADD ~ JAR ~> restInput ^^ {\n       case input => AddJar(input.trim)\n     }\n+\n+  private lazy val showInHive: Parser[LogicalPlan] =\n+    SHOW ~ TABLES ~> (IN ~> ident).? ~ opt(stringLit) ^^ {\n+      case dbName ~ reg => ShowTablesCommand(dbName, reg)"
  }],
  "prId": 6745
}]