[{
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "I probably shouldn't reimplement this one via reflection, as it can be performance sensitive.\n",
    "commit": "cb2edfb4abd70aac289abbb9d713cbe51da821c2",
    "createdAt": "2015-01-20T06:56:18Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import java.math.{BigDecimal => JBigDecimal}\n+import java.util.{Properties, Set => JSet}\n+\n+import scala.collection.JavaConversions._\n+import scala.language.{existentials, implicitConversions}\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.Path\n+import org.apache.hadoop.hive.common.`type`.HiveDecimal\n+import org.apache.hadoop.hive.conf.HiveConf\n+import org.apache.hadoop.hive.ql.metadata.{Hive, Partition, Table}\n+import org.apache.hadoop.hive.ql.plan.{FileSinkDesc, TableDesc}\n+import org.apache.hadoop.hive.ql.processors.{CommandProcessor, CommandProcessorFactory}\n+import org.apache.hadoop.hive.serde2.{ColumnProjectionUtils, Deserializer}\n+import org.apache.hadoop.mapred.InputFormat\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * A utility object used to cope with Hive compatibility issues.\n+ */\n+object HiveCompat {\n+  def createDefaultDBIfNeeded(context: HiveContext) = {\n+    context.runSqlHive(\"CREATE DATABASE IF NOT EXISTS default\")\n+    context.runSqlHive(\"USE default\")\n+  }\n+\n+  def newTableDesc(\n+      serdeClass: Class[_ <: Deserializer],\n+      inputFormatClass: Class[_ <: InputFormat[_, _]],\n+      outputFormatClass: Class[_],\n+      properties: Properties) = callWithAlternatives(\n+    // For Hive 0.13.1\n+    Construct(classOf[TableDesc],\n+      classOf[Class[_ <: InputFormat[_, _]]] -> inputFormatClass,\n+      classOf[Class[_]] -> outputFormatClass,\n+      classOf[Properties] -> properties),\n+\n+    // For Hive 0.12.0\n+    Construct(classOf[TableDesc],\n+      classOf[Class[_ <: Deserializer]] -> serdeClass,\n+      classOf[Class[_ <: InputFormat[_, _]]] -> inputFormatClass,\n+      classOf[Class[_]] -> outputFormatClass,\n+      classOf[Properties] -> properties))\n+\n+  def getCommandProcessor(cmd: Array[String], conf: HiveConf) = {\n+    callWithAlternatives[CommandProcessor](\n+      // For Hive 0.13.1\n+      InvokeStatic[CommandProcessor](classOf[CommandProcessorFactory], \"get\",\n+        classOf[Array[String]] -> cmd,\n+        classOf[HiveConf] -> conf),\n+\n+      // For Hive 0.12.0\n+      InvokeStatic[CommandProcessor](classOf[CommandProcessorFactory], \"get\",\n+        classOf[String] -> cmd(0),\n+        classOf[HiveConf] -> conf))\n+  }\n+\n+  def getAllPartitionsOf(client: Hive, tbl: Table) = callWithAlternatives[JSet[Partition]](\n+    // For Hive 0.13.1\n+    Invoke[JSet[Partition]](classOf[Hive], client, \"getAllPartitionsOf\",\n+      classOf[Table] -> tbl),\n+\n+    // For Hive 0.12.0\n+    Invoke[JSet[Partition]](classOf[Hive], client, \"getAllPartitionsForPruner\",\n+      classOf[Table] -> tbl)\n+  )\n+\n+  def newHiveDecimal(bd: JBigDecimal) = callWithAlternatives("
  }],
  "prId": 4107
}]