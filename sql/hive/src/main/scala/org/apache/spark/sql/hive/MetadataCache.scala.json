[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "The load function is being revised by another PR: https://github.com/apache/spark/pull/14155. Thus, after that PR is merged, this function will be reduced a lot. For details, see https://github.com/cloud-fan/spark/blob/9b08ccac0bda5e29e98966fd87d12fb948de881a/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala#L69-L86\n",
    "commit": "ebdfad1b575650dd5bedc3ab97c5cf1e97fa3072",
    "createdAt": "2016-08-12T07:11:35Z",
    "diffHunk": "@@ -0,0 +1,174 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{AnalysisException, SparkSession}\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.catalog._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.execution.command.CreateDataSourceTableUtils._\n+import org.apache.spark.sql.execution.datasources.{Partition => _, _}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * Metadata cache is a key-value cache built on Google Guava Cache to speed up building logical plan\n+ * nodes (LogicalRelation) for data source tables. The cache key is a unique identifier of a table.\n+ * Here, the identifier is the fully qualified table name, including the database in which it\n+ * resides. The value is the corresponding LogicalRelation that represents a specific data source\n+ * table.\n+ */\n+private[hive] class MetadataCache(spark: SparkSession) extends Logging {\n+  /** A fully qualified identifier for a table (i.e., database.tableName) */\n+  case class QualifiedTableName(database: String, name: String)\n+\n+  private def getQualifiedTableName(tableIdent: TableIdentifier): QualifiedTableName = {\n+    QualifiedTableName(\n+      tableIdent.database.getOrElse(spark.sessionState.catalog.getCurrentDatabase).toLowerCase,\n+      tableIdent.table.toLowerCase)\n+  }\n+\n+  /** A cache of Spark SQL data source tables that have been accessed. */\n+  private val cachedDataSourceTables: LoadingCache[QualifiedTableName, LogicalPlan] = {\n+    val cacheLoader = new CacheLoader[QualifiedTableName, LogicalPlan]() {\n+      override def load(in: QualifiedTableName): LogicalPlan = {"
  }],
  "prId": 14618
}]