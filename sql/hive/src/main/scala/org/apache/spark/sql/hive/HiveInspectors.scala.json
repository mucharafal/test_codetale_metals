[{
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Indentation is off.\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-14T02:14:12Z",
    "diffHunk": "@@ -95,9 +96,12 @@ private[hive] trait HiveInspectors {\n     }\n     case t: hiveIo.TimestampWritable => t.getTimestamp\n     case b: hiveIo.HiveDecimalWritable => BigDecimal(b.getHiveDecimal().bigDecimalValue())\n-    case list: java.util.List[_] => list.map(unwrap)\n     case map: java.util.Map[_,_] => map.map { case (k, v) => (unwrap(k), unwrap(v)) }.toMap\n-    case array: Array[_] => array.map(unwrap).toSeq\n+    // StandardStructObjectInspector expects the data as either Object Array or java.util.List\n+    case array: Array[_] => Row(array.map(unwrap): _*)\n+    case array: java.util.List[_] => Row(array.toArray.map(unwrap): _*)\n+    // TODO how about the ListObjectInspector\n+//    case list: java.util.List[_] => list.map(unwrap)"
  }],
  "prId": 2762
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Remove duplicated `def`.\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-14T10:30:14Z",
    "diffHunk": "@@ -135,26 +139,66 @@ private[hive] trait HiveInspectors {\n           unwrapData(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n   }\n \n-  /** Converts native catalyst types to the types expected by Hive */\n-  def wrap(a: Any): AnyRef = a match {\n-    case s: String => s: java.lang.String\n-    case i: Int => i: java.lang.Integer\n-    case b: Boolean => b: java.lang.Boolean\n-    case f: Float => f: java.lang.Float\n-    case d: Double => d: java.lang.Double\n-    case l: Long => l: java.lang.Long\n-    case l: Short => l: java.lang.Short\n-    case l: Byte => l: java.lang.Byte\n-    case b: BigDecimal => new HiveDecimal(b.underlying())\n-    case b: Array[Byte] => b\n-    case t: java.sql.Timestamp => t\n-    case s: Seq[_] => seqAsJavaList(s.map(wrap))\n-    case m: Map[_,_] =>\n-      // Some UDFs seem to assume we pass in a HashMap.\n-      val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n-      hashMap.putAll(m.map { case (k, v) => wrap(k) -> wrap(v) })\n-      hashMap\n-    case null => null\n+  /**\n+   * Converts native catalyst types to the types expected by Hive\n+   * @param a the value to be wrapped\n+   * @param oi the destination ObjectInspector, which supposed to be the ObjectInspector enumerated\n+   *           in functions:\n+   *           def toInspector(dataType: DataType)\n+   *           def def toInspector(expr: Expression)"
  }],
  "prId": 2762
}, {
  "comments": [{
    "author": {
      "login": "gvramana"
    },
    "body": "Hive supports few complicated types constant. List, Map\nStandardConstantListObjectInspector.java\nStandardConstantMapObjectInspector.java\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-15T07:23:54Z",
    "diffHunk": "@@ -186,6 +230,51 @@ private[hive] trait HiveInspectors {\n         fields.map(f => f.name), fields.map(f => toInspector(f.dataType)))\n   }\n \n+  def toInspector(expr: Expression): ObjectInspector = expr match {\n+    case Literal(value: String, StringType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.STRING, new hadoopIo.Text(value))\n+    case Literal(value: Int, IntegerType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.INT, new hadoopIo.IntWritable(value))\n+    case Literal(value: Double, DoubleType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.DOUBLE, new hiveIo.DoubleWritable(value))\n+    case Literal(value: Boolean, BooleanType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.BOOLEAN, new hadoopIo.BooleanWritable(value))\n+    case Literal(value: Long, LongType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.LONG, new hadoopIo.LongWritable(value))\n+    case Literal(value: Float, FloatType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.FLOAT, new hadoopIo.FloatWritable(value))\n+    case Literal(value: Short, ShortType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.SHORT, new hiveIo.ShortWritable(value))\n+    case Literal(value: Byte, ByteType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.BYTE, new hiveIo.ByteWritable(value))\n+    case Literal(value: Array[Byte], BinaryType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.BINARY, new hadoopIo.BytesWritable(value))\n+    case Literal(value: java.sql.Date, DateType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.DATE, new hiveIo.DateWritable(value))\n+    case Literal(value: java.sql.Timestamp, TimestampType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.TIMESTAMP, new hiveIo.TimestampWritable(value))\n+    case Literal(value: BigDecimal, DecimalType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.DECIMAL,\n+        new hiveIo.HiveDecimalWritable(new HiveDecimal(value.underlying())))\n+    case Literal(_, NullType) =>\n+      PrimitiveObjectInspectorFactory.getPrimitiveWritableConstantObjectInspector(\n+        PrimitiveCategory.VOID, null)\n+    case Literal(_, _) => sys.error(\"Hive doesn't support the constant complicated type.\")"
  }],
  "prId": 2762
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Can we do something like this for each case below:\n\n``` scala\ncase s: String => if (x.preferWritable) new Text(s) else s: java.lang.String\n```\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-23T02:10:19Z",
    "diffHunk": "@@ -123,43 +93,88 @@ private[hive] trait HiveInspectors {\n     case pi: PrimitiveObjectInspector => pi.getPrimitiveJavaObject(data)\n     case li: ListObjectInspector =>\n       Option(li.getList(data))\n-        .map(_.map(unwrapData(_, li.getListElementObjectInspector)).toSeq)\n+        .map(_.map(unwrap(_, li.getListElementObjectInspector)).toSeq)\n         .orNull\n     case mi: MapObjectInspector =>\n       Option(mi.getMap(data)).map(\n         _.map {\n           case (k,v) =>\n-            (unwrapData(k, mi.getMapKeyObjectInspector),\n-              unwrapData(v, mi.getMapValueObjectInspector))\n+            (unwrap(k, mi.getMapKeyObjectInspector),\n+              unwrap(v, mi.getMapValueObjectInspector))\n         }.toMap).orNull\n     case si: StructObjectInspector =>\n       val allRefs = si.getAllStructFieldRefs\n       new GenericRow(\n         allRefs.map(r =>\n-          unwrapData(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n+          unwrap(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n   }\n \n-  /** Converts native catalyst types to the types expected by Hive */\n-  def wrap(a: Any): AnyRef = a match {\n-    case s: String => s: java.lang.String\n-    case i: Int => i: java.lang.Integer\n-    case b: Boolean => b: java.lang.Boolean\n-    case f: Float => f: java.lang.Float\n-    case d: Double => d: java.lang.Double\n-    case l: Long => l: java.lang.Long\n-    case l: Short => l: java.lang.Short\n-    case l: Byte => l: java.lang.Byte\n-    case b: BigDecimal => new HiveDecimal(b.underlying())\n-    case b: Array[Byte] => b\n-    case d: java.sql.Date => d\n-    case t: java.sql.Timestamp => t\n-    case s: Seq[_] => seqAsJavaList(s.map(wrap))\n-    case m: Map[_,_] =>\n-      // Some UDFs seem to assume we pass in a HashMap.\n-      val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n-      hashMap.putAll(m.map { case (k, v) => wrap(k) -> wrap(v) })\n-      hashMap\n-    case null => null\n+  /**\n+   * Converts native catalyst types to the types expected by Hive\n+   * @param a the value to be wrapped\n+   * @param oi wrapped object used by this ObjectInspector, which supposed to be\n+   *           the ObjectInspector enumerated in functions:\n+   *           def toInspector(dataType: DataType)\n+   *           def toInspector(expr: Expression)\n+   */\n+  def wrap(a: Any, oi: ObjectInspector): AnyRef = if (a == null) {\n+    null\n+  } else {\n+    oi match {\n+      case x: ConstantObjectInspector => x.getWritableConstantValue\n+      case x: PrimitiveObjectInspector => a match {\n+        // TODO what if x.preferWritable() == true?"
  }, {
    "author": {
      "login": "chenghao-intel"
    },
    "body": "Currently the `ObjectInspector` passed should not be `preferWriteable`, because the function `def toInspector(DataType)` will never returns that. I would like to keep it for further improvement (https://issues.apache.org/jira/browse/SPARK-4093), which probably pass in the `WritableObjectInspector`.\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-27T05:44:18Z",
    "diffHunk": "@@ -123,43 +93,88 @@ private[hive] trait HiveInspectors {\n     case pi: PrimitiveObjectInspector => pi.getPrimitiveJavaObject(data)\n     case li: ListObjectInspector =>\n       Option(li.getList(data))\n-        .map(_.map(unwrapData(_, li.getListElementObjectInspector)).toSeq)\n+        .map(_.map(unwrap(_, li.getListElementObjectInspector)).toSeq)\n         .orNull\n     case mi: MapObjectInspector =>\n       Option(mi.getMap(data)).map(\n         _.map {\n           case (k,v) =>\n-            (unwrapData(k, mi.getMapKeyObjectInspector),\n-              unwrapData(v, mi.getMapValueObjectInspector))\n+            (unwrap(k, mi.getMapKeyObjectInspector),\n+              unwrap(v, mi.getMapValueObjectInspector))\n         }.toMap).orNull\n     case si: StructObjectInspector =>\n       val allRefs = si.getAllStructFieldRefs\n       new GenericRow(\n         allRefs.map(r =>\n-          unwrapData(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n+          unwrap(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n   }\n \n-  /** Converts native catalyst types to the types expected by Hive */\n-  def wrap(a: Any): AnyRef = a match {\n-    case s: String => s: java.lang.String\n-    case i: Int => i: java.lang.Integer\n-    case b: Boolean => b: java.lang.Boolean\n-    case f: Float => f: java.lang.Float\n-    case d: Double => d: java.lang.Double\n-    case l: Long => l: java.lang.Long\n-    case l: Short => l: java.lang.Short\n-    case l: Byte => l: java.lang.Byte\n-    case b: BigDecimal => new HiveDecimal(b.underlying())\n-    case b: Array[Byte] => b\n-    case d: java.sql.Date => d\n-    case t: java.sql.Timestamp => t\n-    case s: Seq[_] => seqAsJavaList(s.map(wrap))\n-    case m: Map[_,_] =>\n-      // Some UDFs seem to assume we pass in a HashMap.\n-      val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n-      hashMap.putAll(m.map { case (k, v) => wrap(k) -> wrap(v) })\n-      hashMap\n-    case null => null\n+  /**\n+   * Converts native catalyst types to the types expected by Hive\n+   * @param a the value to be wrapped\n+   * @param oi wrapped object used by this ObjectInspector, which supposed to be\n+   *           the ObjectInspector enumerated in functions:\n+   *           def toInspector(dataType: DataType)\n+   *           def toInspector(expr: Expression)\n+   */\n+  def wrap(a: Any, oi: ObjectInspector): AnyRef = if (a == null) {\n+    null\n+  } else {\n+    oi match {\n+      case x: ConstantObjectInspector => x.getWritableConstantValue\n+      case x: PrimitiveObjectInspector => a match {\n+        // TODO what if x.preferWritable() == true?"
  }],
  "prId": 2762
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Nit: redundant braces here.\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-23T03:42:42Z",
    "diffHunk": "@@ -123,43 +93,88 @@ private[hive] trait HiveInspectors {\n     case pi: PrimitiveObjectInspector => pi.getPrimitiveJavaObject(data)\n     case li: ListObjectInspector =>\n       Option(li.getList(data))\n-        .map(_.map(unwrapData(_, li.getListElementObjectInspector)).toSeq)\n+        .map(_.map(unwrap(_, li.getListElementObjectInspector)).toSeq)\n         .orNull\n     case mi: MapObjectInspector =>\n       Option(mi.getMap(data)).map(\n         _.map {\n           case (k,v) =>\n-            (unwrapData(k, mi.getMapKeyObjectInspector),\n-              unwrapData(v, mi.getMapValueObjectInspector))\n+            (unwrap(k, mi.getMapKeyObjectInspector),\n+              unwrap(v, mi.getMapValueObjectInspector))\n         }.toMap).orNull\n     case si: StructObjectInspector =>\n       val allRefs = si.getAllStructFieldRefs\n       new GenericRow(\n         allRefs.map(r =>\n-          unwrapData(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n+          unwrap(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n   }\n \n-  /** Converts native catalyst types to the types expected by Hive */\n-  def wrap(a: Any): AnyRef = a match {\n-    case s: String => s: java.lang.String\n-    case i: Int => i: java.lang.Integer\n-    case b: Boolean => b: java.lang.Boolean\n-    case f: Float => f: java.lang.Float\n-    case d: Double => d: java.lang.Double\n-    case l: Long => l: java.lang.Long\n-    case l: Short => l: java.lang.Short\n-    case l: Byte => l: java.lang.Byte\n-    case b: BigDecimal => new HiveDecimal(b.underlying())\n-    case b: Array[Byte] => b\n-    case d: java.sql.Date => d\n-    case t: java.sql.Timestamp => t\n-    case s: Seq[_] => seqAsJavaList(s.map(wrap))\n-    case m: Map[_,_] =>\n-      // Some UDFs seem to assume we pass in a HashMap.\n-      val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n-      hashMap.putAll(m.map { case (k, v) => wrap(k) -> wrap(v) })\n-      hashMap\n-    case null => null\n+  /**\n+   * Converts native catalyst types to the types expected by Hive\n+   * @param a the value to be wrapped\n+   * @param oi wrapped object used by this ObjectInspector, which supposed to be\n+   *           the ObjectInspector enumerated in functions:\n+   *           def toInspector(dataType: DataType)\n+   *           def toInspector(expr: Expression)\n+   */\n+  def wrap(a: Any, oi: ObjectInspector): AnyRef = if (a == null) {\n+    null\n+  } else {\n+    oi match {\n+      case x: ConstantObjectInspector => x.getWritableConstantValue\n+      case x: PrimitiveObjectInspector => a match {\n+        // TODO what if x.preferWritable() == true?\n+        case s: String => s: java.lang.String\n+        case i: Int => i: java.lang.Integer\n+        case b: Boolean => b: java.lang.Boolean\n+        case f: Float => f: java.lang.Float\n+        case d: Double => d: java.lang.Double\n+        case l: Long => l: java.lang.Long\n+        case l: Short => l: java.lang.Short\n+        case l: Byte => l: java.lang.Byte\n+        case b: BigDecimal => new HiveDecimal(b.underlying())\n+        case b: Array[Byte] => b\n+        case d: java.sql.Date => d \n+        case t: java.sql.Timestamp => t\n+      }\n+      case x: StructObjectInspector => {"
  }],
  "prId": 2762
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Space before `(`\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-23T03:45:49Z",
    "diffHunk": "@@ -123,43 +93,88 @@ private[hive] trait HiveInspectors {\n     case pi: PrimitiveObjectInspector => pi.getPrimitiveJavaObject(data)\n     case li: ListObjectInspector =>\n       Option(li.getList(data))\n-        .map(_.map(unwrapData(_, li.getListElementObjectInspector)).toSeq)\n+        .map(_.map(unwrap(_, li.getListElementObjectInspector)).toSeq)\n         .orNull\n     case mi: MapObjectInspector =>\n       Option(mi.getMap(data)).map(\n         _.map {\n           case (k,v) =>\n-            (unwrapData(k, mi.getMapKeyObjectInspector),\n-              unwrapData(v, mi.getMapValueObjectInspector))\n+            (unwrap(k, mi.getMapKeyObjectInspector),\n+              unwrap(v, mi.getMapValueObjectInspector))\n         }.toMap).orNull\n     case si: StructObjectInspector =>\n       val allRefs = si.getAllStructFieldRefs\n       new GenericRow(\n         allRefs.map(r =>\n-          unwrapData(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n+          unwrap(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n   }\n \n-  /** Converts native catalyst types to the types expected by Hive */\n-  def wrap(a: Any): AnyRef = a match {\n-    case s: String => s: java.lang.String\n-    case i: Int => i: java.lang.Integer\n-    case b: Boolean => b: java.lang.Boolean\n-    case f: Float => f: java.lang.Float\n-    case d: Double => d: java.lang.Double\n-    case l: Long => l: java.lang.Long\n-    case l: Short => l: java.lang.Short\n-    case l: Byte => l: java.lang.Byte\n-    case b: BigDecimal => new HiveDecimal(b.underlying())\n-    case b: Array[Byte] => b\n-    case d: java.sql.Date => d\n-    case t: java.sql.Timestamp => t\n-    case s: Seq[_] => seqAsJavaList(s.map(wrap))\n-    case m: Map[_,_] =>\n-      // Some UDFs seem to assume we pass in a HashMap.\n-      val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n-      hashMap.putAll(m.map { case (k, v) => wrap(k) -> wrap(v) })\n-      hashMap\n-    case null => null\n+  /**\n+   * Converts native catalyst types to the types expected by Hive\n+   * @param a the value to be wrapped\n+   * @param oi wrapped object used by this ObjectInspector, which supposed to be\n+   *           the ObjectInspector enumerated in functions:\n+   *           def toInspector(dataType: DataType)\n+   *           def toInspector(expr: Expression)\n+   */\n+  def wrap(a: Any, oi: ObjectInspector): AnyRef = if (a == null) {\n+    null\n+  } else {\n+    oi match {\n+      case x: ConstantObjectInspector => x.getWritableConstantValue\n+      case x: PrimitiveObjectInspector => a match {\n+        // TODO what if x.preferWritable() == true?\n+        case s: String => s: java.lang.String\n+        case i: Int => i: java.lang.Integer\n+        case b: Boolean => b: java.lang.Boolean\n+        case f: Float => f: java.lang.Float\n+        case d: Double => d: java.lang.Double\n+        case l: Long => l: java.lang.Long\n+        case l: Short => l: java.lang.Short\n+        case l: Byte => l: java.lang.Byte\n+        case b: BigDecimal => new HiveDecimal(b.underlying())\n+        case b: Array[Byte] => b\n+        case d: java.sql.Date => d \n+        case t: java.sql.Timestamp => t\n+      }\n+      case x: StructObjectInspector => {\n+        val fieldRefs = x.getAllStructFieldRefs\n+        val row = a.asInstanceOf[Seq[_]]\n+        val result = new java.util.ArrayList[AnyRef](fieldRefs.length)\n+        var i = 0\n+        while(i < fieldRefs.length) {"
  }],
  "prId": 2762
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Need some rewording here:\n\n> The `ObjectInspector` used to wrap value `a`. The `ObjectInspector` type should be consistent with those returned by `toInspector: DataType => ObjectInspector` and `toInspector: Expression => ObjectInspector`.\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-23T03:57:53Z",
    "diffHunk": "@@ -123,43 +93,88 @@ private[hive] trait HiveInspectors {\n     case pi: PrimitiveObjectInspector => pi.getPrimitiveJavaObject(data)\n     case li: ListObjectInspector =>\n       Option(li.getList(data))\n-        .map(_.map(unwrapData(_, li.getListElementObjectInspector)).toSeq)\n+        .map(_.map(unwrap(_, li.getListElementObjectInspector)).toSeq)\n         .orNull\n     case mi: MapObjectInspector =>\n       Option(mi.getMap(data)).map(\n         _.map {\n           case (k,v) =>\n-            (unwrapData(k, mi.getMapKeyObjectInspector),\n-              unwrapData(v, mi.getMapValueObjectInspector))\n+            (unwrap(k, mi.getMapKeyObjectInspector),\n+              unwrap(v, mi.getMapValueObjectInspector))\n         }.toMap).orNull\n     case si: StructObjectInspector =>\n       val allRefs = si.getAllStructFieldRefs\n       new GenericRow(\n         allRefs.map(r =>\n-          unwrapData(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n+          unwrap(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n   }\n \n-  /** Converts native catalyst types to the types expected by Hive */\n-  def wrap(a: Any): AnyRef = a match {\n-    case s: String => s: java.lang.String\n-    case i: Int => i: java.lang.Integer\n-    case b: Boolean => b: java.lang.Boolean\n-    case f: Float => f: java.lang.Float\n-    case d: Double => d: java.lang.Double\n-    case l: Long => l: java.lang.Long\n-    case l: Short => l: java.lang.Short\n-    case l: Byte => l: java.lang.Byte\n-    case b: BigDecimal => new HiveDecimal(b.underlying())\n-    case b: Array[Byte] => b\n-    case d: java.sql.Date => d\n-    case t: java.sql.Timestamp => t\n-    case s: Seq[_] => seqAsJavaList(s.map(wrap))\n-    case m: Map[_,_] =>\n-      // Some UDFs seem to assume we pass in a HashMap.\n-      val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n-      hashMap.putAll(m.map { case (k, v) => wrap(k) -> wrap(v) })\n-      hashMap\n-    case null => null\n+  /**\n+   * Converts native catalyst types to the types expected by Hive\n+   * @param a the value to be wrapped\n+   * @param oi wrapped object used by this ObjectInspector, which supposed to be\n+   *           the ObjectInspector enumerated in functions:\n+   *           def toInspector(dataType: DataType)\n+   *           def toInspector(expr: Expression)"
  }],
  "prId": 2762
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "``` scala\ndef wrap(\n    row: Seq[Any],\n    inspectors: Seq[ObjectInspectlr],\n    cache: Array[AnyRef]): Array[AnyRef] = {\n  ...\n}\n```\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-23T04:23:27Z",
    "diffHunk": "@@ -123,43 +93,88 @@ private[hive] trait HiveInspectors {\n     case pi: PrimitiveObjectInspector => pi.getPrimitiveJavaObject(data)\n     case li: ListObjectInspector =>\n       Option(li.getList(data))\n-        .map(_.map(unwrapData(_, li.getListElementObjectInspector)).toSeq)\n+        .map(_.map(unwrap(_, li.getListElementObjectInspector)).toSeq)\n         .orNull\n     case mi: MapObjectInspector =>\n       Option(mi.getMap(data)).map(\n         _.map {\n           case (k,v) =>\n-            (unwrapData(k, mi.getMapKeyObjectInspector),\n-              unwrapData(v, mi.getMapValueObjectInspector))\n+            (unwrap(k, mi.getMapKeyObjectInspector),\n+              unwrap(v, mi.getMapValueObjectInspector))\n         }.toMap).orNull\n     case si: StructObjectInspector =>\n       val allRefs = si.getAllStructFieldRefs\n       new GenericRow(\n         allRefs.map(r =>\n-          unwrapData(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n+          unwrap(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n   }\n \n-  /** Converts native catalyst types to the types expected by Hive */\n-  def wrap(a: Any): AnyRef = a match {\n-    case s: String => s: java.lang.String\n-    case i: Int => i: java.lang.Integer\n-    case b: Boolean => b: java.lang.Boolean\n-    case f: Float => f: java.lang.Float\n-    case d: Double => d: java.lang.Double\n-    case l: Long => l: java.lang.Long\n-    case l: Short => l: java.lang.Short\n-    case l: Byte => l: java.lang.Byte\n-    case b: BigDecimal => new HiveDecimal(b.underlying())\n-    case b: Array[Byte] => b\n-    case d: java.sql.Date => d\n-    case t: java.sql.Timestamp => t\n-    case s: Seq[_] => seqAsJavaList(s.map(wrap))\n-    case m: Map[_,_] =>\n-      // Some UDFs seem to assume we pass in a HashMap.\n-      val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n-      hashMap.putAll(m.map { case (k, v) => wrap(k) -> wrap(v) })\n-      hashMap\n-    case null => null\n+  /**\n+   * Converts native catalyst types to the types expected by Hive\n+   * @param a the value to be wrapped\n+   * @param oi wrapped object used by this ObjectInspector, which supposed to be\n+   *           the ObjectInspector enumerated in functions:\n+   *           def toInspector(dataType: DataType)\n+   *           def toInspector(expr: Expression)\n+   */\n+  def wrap(a: Any, oi: ObjectInspector): AnyRef = if (a == null) {\n+    null\n+  } else {\n+    oi match {\n+      case x: ConstantObjectInspector => x.getWritableConstantValue\n+      case x: PrimitiveObjectInspector => a match {\n+        // TODO what if x.preferWritable() == true?\n+        case s: String => s: java.lang.String\n+        case i: Int => i: java.lang.Integer\n+        case b: Boolean => b: java.lang.Boolean\n+        case f: Float => f: java.lang.Float\n+        case d: Double => d: java.lang.Double\n+        case l: Long => l: java.lang.Long\n+        case l: Short => l: java.lang.Short\n+        case l: Byte => l: java.lang.Byte\n+        case b: BigDecimal => new HiveDecimal(b.underlying())\n+        case b: Array[Byte] => b\n+        case d: java.sql.Date => d \n+        case t: java.sql.Timestamp => t\n+      }\n+      case x: StructObjectInspector => {\n+        val fieldRefs = x.getAllStructFieldRefs\n+        val row = a.asInstanceOf[Seq[_]]\n+        val result = new java.util.ArrayList[AnyRef](fieldRefs.length)\n+        var i = 0\n+        while(i < fieldRefs.length) {\n+          result.add(wrap(row(i), fieldRefs.get(i).getFieldObjectInspector))\n+          i += 1\n+        }\n+\n+        result\n+      }\n+      case x: ListObjectInspector =>\n+        val list = new java.util.ArrayList[Object]\n+        a.asInstanceOf[Seq[_]].foreach {\n+          v => list.add(wrap(v, x.getListElementObjectInspector))\n+        }\n+        list\n+      case x: MapObjectInspector =>\n+        // Some UDFs seem to assume we pass in a HashMap.\n+        val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n+        hashMap.putAll(a.asInstanceOf[Map[_, _]].map {\n+          case (k, v) =>\n+            wrap(k, x.getMapKeyObjectInspector) -> wrap(v, x.getMapValueObjectInspector)\n+        })\n+\n+        hashMap\n+    }\n+  }\n+\n+  def wrap(row: Seq[Any], inspectors: Seq[ObjectInspector], cache: Array[AnyRef])\n+  : Array[AnyRef] = {"
  }],
  "prId": 2762
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Space before `(`\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-23T04:23:37Z",
    "diffHunk": "@@ -123,43 +93,88 @@ private[hive] trait HiveInspectors {\n     case pi: PrimitiveObjectInspector => pi.getPrimitiveJavaObject(data)\n     case li: ListObjectInspector =>\n       Option(li.getList(data))\n-        .map(_.map(unwrapData(_, li.getListElementObjectInspector)).toSeq)\n+        .map(_.map(unwrap(_, li.getListElementObjectInspector)).toSeq)\n         .orNull\n     case mi: MapObjectInspector =>\n       Option(mi.getMap(data)).map(\n         _.map {\n           case (k,v) =>\n-            (unwrapData(k, mi.getMapKeyObjectInspector),\n-              unwrapData(v, mi.getMapValueObjectInspector))\n+            (unwrap(k, mi.getMapKeyObjectInspector),\n+              unwrap(v, mi.getMapValueObjectInspector))\n         }.toMap).orNull\n     case si: StructObjectInspector =>\n       val allRefs = si.getAllStructFieldRefs\n       new GenericRow(\n         allRefs.map(r =>\n-          unwrapData(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n+          unwrap(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n   }\n \n-  /** Converts native catalyst types to the types expected by Hive */\n-  def wrap(a: Any): AnyRef = a match {\n-    case s: String => s: java.lang.String\n-    case i: Int => i: java.lang.Integer\n-    case b: Boolean => b: java.lang.Boolean\n-    case f: Float => f: java.lang.Float\n-    case d: Double => d: java.lang.Double\n-    case l: Long => l: java.lang.Long\n-    case l: Short => l: java.lang.Short\n-    case l: Byte => l: java.lang.Byte\n-    case b: BigDecimal => new HiveDecimal(b.underlying())\n-    case b: Array[Byte] => b\n-    case d: java.sql.Date => d\n-    case t: java.sql.Timestamp => t\n-    case s: Seq[_] => seqAsJavaList(s.map(wrap))\n-    case m: Map[_,_] =>\n-      // Some UDFs seem to assume we pass in a HashMap.\n-      val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n-      hashMap.putAll(m.map { case (k, v) => wrap(k) -> wrap(v) })\n-      hashMap\n-    case null => null\n+  /**\n+   * Converts native catalyst types to the types expected by Hive\n+   * @param a the value to be wrapped\n+   * @param oi wrapped object used by this ObjectInspector, which supposed to be\n+   *           the ObjectInspector enumerated in functions:\n+   *           def toInspector(dataType: DataType)\n+   *           def toInspector(expr: Expression)\n+   */\n+  def wrap(a: Any, oi: ObjectInspector): AnyRef = if (a == null) {\n+    null\n+  } else {\n+    oi match {\n+      case x: ConstantObjectInspector => x.getWritableConstantValue\n+      case x: PrimitiveObjectInspector => a match {\n+        // TODO what if x.preferWritable() == true?\n+        case s: String => s: java.lang.String\n+        case i: Int => i: java.lang.Integer\n+        case b: Boolean => b: java.lang.Boolean\n+        case f: Float => f: java.lang.Float\n+        case d: Double => d: java.lang.Double\n+        case l: Long => l: java.lang.Long\n+        case l: Short => l: java.lang.Short\n+        case l: Byte => l: java.lang.Byte\n+        case b: BigDecimal => new HiveDecimal(b.underlying())\n+        case b: Array[Byte] => b\n+        case d: java.sql.Date => d \n+        case t: java.sql.Timestamp => t\n+      }\n+      case x: StructObjectInspector => {\n+        val fieldRefs = x.getAllStructFieldRefs\n+        val row = a.asInstanceOf[Seq[_]]\n+        val result = new java.util.ArrayList[AnyRef](fieldRefs.length)\n+        var i = 0\n+        while(i < fieldRefs.length) {\n+          result.add(wrap(row(i), fieldRefs.get(i).getFieldObjectInspector))\n+          i += 1\n+        }\n+\n+        result\n+      }\n+      case x: ListObjectInspector =>\n+        val list = new java.util.ArrayList[Object]\n+        a.asInstanceOf[Seq[_]].foreach {\n+          v => list.add(wrap(v, x.getListElementObjectInspector))\n+        }\n+        list\n+      case x: MapObjectInspector =>\n+        // Some UDFs seem to assume we pass in a HashMap.\n+        val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n+        hashMap.putAll(a.asInstanceOf[Map[_, _]].map {\n+          case (k, v) =>\n+            wrap(k, x.getMapKeyObjectInspector) -> wrap(v, x.getMapValueObjectInspector)\n+        })\n+\n+        hashMap\n+    }\n+  }\n+\n+  def wrap(row: Seq[Any], inspectors: Seq[ObjectInspector], cache: Array[AnyRef])\n+  : Array[AnyRef] = {\n+    var i = 0\n+    while(i < inspectors.length) {"
  }],
  "prId": 2762
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Seems that the `Writable` related code was reverted after rebase?\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-29T00:51:19Z",
    "diffHunk": "@@ -123,43 +94,89 @@ private[hive] trait HiveInspectors {\n     case pi: PrimitiveObjectInspector => pi.getPrimitiveJavaObject(data)\n     case li: ListObjectInspector =>\n       Option(li.getList(data))\n-        .map(_.map(unwrapData(_, li.getListElementObjectInspector)).toSeq)\n+        .map(_.map(unwrap(_, li.getListElementObjectInspector)).toSeq)\n         .orNull\n     case mi: MapObjectInspector =>\n       Option(mi.getMap(data)).map(\n         _.map {\n           case (k,v) =>\n-            (unwrapData(k, mi.getMapKeyObjectInspector),\n-              unwrapData(v, mi.getMapValueObjectInspector))\n+            (unwrap(k, mi.getMapKeyObjectInspector),\n+              unwrap(v, mi.getMapValueObjectInspector))\n         }.toMap).orNull\n     case si: StructObjectInspector =>\n       val allRefs = si.getAllStructFieldRefs\n       new GenericRow(\n         allRefs.map(r =>\n-          unwrapData(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n+          unwrap(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n   }\n \n-  /** Converts native catalyst types to the types expected by Hive */\n-  def wrap(a: Any): AnyRef = a match {\n-    case s: String => s: java.lang.String\n-    case i: Int => i: java.lang.Integer\n-    case b: Boolean => b: java.lang.Boolean\n-    case f: Float => f: java.lang.Float\n-    case d: Double => d: java.lang.Double\n-    case l: Long => l: java.lang.Long\n-    case l: Short => l: java.lang.Short\n-    case l: Byte => l: java.lang.Byte\n-    case b: BigDecimal => HiveShim.createDecimal(b.underlying())\n-    case b: Array[Byte] => b\n-    case d: java.sql.Date => d\n-    case t: java.sql.Timestamp => t\n-    case s: Seq[_] => seqAsJavaList(s.map(wrap))\n-    case m: Map[_,_] =>\n-      // Some UDFs seem to assume we pass in a HashMap.\n-      val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n-      hashMap.putAll(m.map { case (k, v) => wrap(k) -> wrap(v) })\n-      hashMap\n-    case null => null\n+  /**\n+   * Converts native catalyst types to the types expected by Hive\n+   * @param a the value to be wrapped\n+   * @param oi This ObjectInspector associated with the value returned by this function, and\n+   *           the ObjectInspector should also be consistent with those returned from\n+   *           toInspector: DataType => ObjectInspector and\n+   *           toInspector: Expression => ObjectInspector\n+   */\n+  def wrap(a: Any, oi: ObjectInspector): AnyRef = if (a == null) {\n+    null\n+  } else {\n+    oi match {\n+      case x: ConstantObjectInspector => x.getWritableConstantValue\n+      case x: PrimitiveObjectInspector => a match {\n+        // TODO what if x.preferWritable() == true? reuse the writable?",
    "line": 121
  }, {
    "author": {
      "login": "chenghao-intel"
    },
    "body": "Yes, currently the `oi` is should not be \"preferWritable\" as `toInspector` doesn't return that. Even if we return an new instance of `Writable` here, it's the same as the `preferWritable` `ObjectInspector` does internally.\nAs you suggested we don't want to dynamically check the `oi` type, I will keep that for future improvement, and to reuse the writable object.\n",
    "commit": "bcacfd7e6e97f78e7f1e782a8787a53592e70127",
    "createdAt": "2014-10-29T01:05:49Z",
    "diffHunk": "@@ -123,43 +94,89 @@ private[hive] trait HiveInspectors {\n     case pi: PrimitiveObjectInspector => pi.getPrimitiveJavaObject(data)\n     case li: ListObjectInspector =>\n       Option(li.getList(data))\n-        .map(_.map(unwrapData(_, li.getListElementObjectInspector)).toSeq)\n+        .map(_.map(unwrap(_, li.getListElementObjectInspector)).toSeq)\n         .orNull\n     case mi: MapObjectInspector =>\n       Option(mi.getMap(data)).map(\n         _.map {\n           case (k,v) =>\n-            (unwrapData(k, mi.getMapKeyObjectInspector),\n-              unwrapData(v, mi.getMapValueObjectInspector))\n+            (unwrap(k, mi.getMapKeyObjectInspector),\n+              unwrap(v, mi.getMapValueObjectInspector))\n         }.toMap).orNull\n     case si: StructObjectInspector =>\n       val allRefs = si.getAllStructFieldRefs\n       new GenericRow(\n         allRefs.map(r =>\n-          unwrapData(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n+          unwrap(si.getStructFieldData(data,r), r.getFieldObjectInspector)).toArray)\n   }\n \n-  /** Converts native catalyst types to the types expected by Hive */\n-  def wrap(a: Any): AnyRef = a match {\n-    case s: String => s: java.lang.String\n-    case i: Int => i: java.lang.Integer\n-    case b: Boolean => b: java.lang.Boolean\n-    case f: Float => f: java.lang.Float\n-    case d: Double => d: java.lang.Double\n-    case l: Long => l: java.lang.Long\n-    case l: Short => l: java.lang.Short\n-    case l: Byte => l: java.lang.Byte\n-    case b: BigDecimal => HiveShim.createDecimal(b.underlying())\n-    case b: Array[Byte] => b\n-    case d: java.sql.Date => d\n-    case t: java.sql.Timestamp => t\n-    case s: Seq[_] => seqAsJavaList(s.map(wrap))\n-    case m: Map[_,_] =>\n-      // Some UDFs seem to assume we pass in a HashMap.\n-      val hashMap = new java.util.HashMap[AnyRef, AnyRef]()\n-      hashMap.putAll(m.map { case (k, v) => wrap(k) -> wrap(v) })\n-      hashMap\n-    case null => null\n+  /**\n+   * Converts native catalyst types to the types expected by Hive\n+   * @param a the value to be wrapped\n+   * @param oi This ObjectInspector associated with the value returned by this function, and\n+   *           the ObjectInspector should also be consistent with those returned from\n+   *           toInspector: DataType => ObjectInspector and\n+   *           toInspector: Expression => ObjectInspector\n+   */\n+  def wrap(a: Any, oi: ObjectInspector): AnyRef = if (a == null) {\n+    null\n+  } else {\n+    oi match {\n+      case x: ConstantObjectInspector => x.getWritableConstantValue\n+      case x: PrimitiveObjectInspector => a match {\n+        // TODO what if x.preferWritable() == true? reuse the writable?",
    "line": 121
  }],
  "prId": 2762
}]