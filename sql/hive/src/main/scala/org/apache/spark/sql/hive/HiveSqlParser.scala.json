[{
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Since this class takes over all HiveQL parsing work (although it delegates to an underlying Hive parser), it's not accurate to call it a \"pre parser\", maybe this:\n\n> A parser that recognizes all HiveQL constructs together with several Spark SQL specific extensions like `CACHE TABLE` and `UNCACHE TABLE`.\n",
    "commit": "bbca7dd626dcfb79230d4fa954ee3e0dee5c68e9",
    "createdAt": "2014-09-30T06:07:17Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.language.implicitConversions\n+import scala.util.parsing.combinator.syntactical.StandardTokenParsers\n+import scala.util.parsing.combinator.PackratParsers\n+import scala.util.parsing.input.CharArrayReader.EofCh\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.SqlLexical\n+import scala.util.parsing.combinator.lexical.StdLexical\n+\n+/**\n+ * A simple Hive SQL pre parser. It parses the commands like cache,uncache etc and \n+ * remaining actual query will be parsed by HiveQl.parseSql \n+ */"
  }, {
    "author": {
      "login": "ravipesala"
    },
    "body": "Looks good. I updated as per your comment\n",
    "commit": "bbca7dd626dcfb79230d4fa954ee3e0dee5c68e9",
    "createdAt": "2014-09-30T11:23:33Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.language.implicitConversions\n+import scala.util.parsing.combinator.syntactical.StandardTokenParsers\n+import scala.util.parsing.combinator.PackratParsers\n+import scala.util.parsing.input.CharArrayReader.EofCh\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.SqlLexical\n+import scala.util.parsing.combinator.lexical.StdLexical\n+\n+/**\n+ * A simple Hive SQL pre parser. It parses the commands like cache,uncache etc and \n+ * remaining actual query will be parsed by HiveQl.parseSql \n+ */"
  }],
  "prId": 2590
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Maybe `ExtendedHiveQLParser` is a better name? Since HiveQL is the definitive name and we're adding extensions to it in Spark SQL.\n",
    "commit": "bbca7dd626dcfb79230d4fa954ee3e0dee5c68e9",
    "createdAt": "2014-09-30T06:07:52Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.language.implicitConversions\n+import scala.util.parsing.combinator.syntactical.StandardTokenParsers\n+import scala.util.parsing.combinator.PackratParsers\n+import scala.util.parsing.input.CharArrayReader.EofCh\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.SqlLexical\n+import scala.util.parsing.combinator.lexical.StdLexical\n+\n+/**\n+ * A simple Hive SQL pre parser. It parses the commands like cache,uncache etc and \n+ * remaining actual query will be parsed by HiveQl.parseSql \n+ */\n+class HiveSqlParser extends StandardTokenParsers with PackratParsers {  "
  }, {
    "author": {
      "login": "ravipesala"
    },
    "body": "OK. Changed the file name.\n",
    "commit": "bbca7dd626dcfb79230d4fa954ee3e0dee5c68e9",
    "createdAt": "2014-09-30T11:23:59Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.language.implicitConversions\n+import scala.util.parsing.combinator.syntactical.StandardTokenParsers\n+import scala.util.parsing.combinator.PackratParsers\n+import scala.util.parsing.input.CharArrayReader.EofCh\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.SqlLexical\n+import scala.util.parsing.combinator.lexical.StdLexical\n+\n+/**\n+ * A simple Hive SQL pre parser. It parses the commands like cache,uncache etc and \n+ * remaining actual query will be parsed by HiveQl.parseSql \n+ */\n+class HiveSqlParser extends StandardTokenParsers with PackratParsers {  "
  }],
  "prId": 2590
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "I'd like to handle `SET` in parser combinator too, but we can leave this to another PR.\n",
    "commit": "bbca7dd626dcfb79230d4fa954ee3e0dee5c68e9",
    "createdAt": "2014-09-30T06:08:15Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.language.implicitConversions\n+import scala.util.parsing.combinator.syntactical.StandardTokenParsers\n+import scala.util.parsing.combinator.PackratParsers\n+import scala.util.parsing.input.CharArrayReader.EofCh\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.SqlLexical\n+import scala.util.parsing.combinator.lexical.StdLexical\n+\n+/**\n+ * A simple Hive SQL pre parser. It parses the commands like cache,uncache etc and \n+ * remaining actual query will be parsed by HiveQl.parseSql \n+ */\n+class HiveSqlParser extends StandardTokenParsers with PackratParsers {  \n+  \n+   def apply(input: String): LogicalPlan = {\n+    // Special-case out set commands since the value fields can be\n+    // complex to handle without RegexParsers. Also this approach\n+    // is clearer for the several possible cases of set commands.\n+    if (input.trim.toLowerCase.startsWith(\"set\")) {"
  }, {
    "author": {
      "login": "ravipesala"
    },
    "body": "OK.\n",
    "commit": "bbca7dd626dcfb79230d4fa954ee3e0dee5c68e9",
    "createdAt": "2014-09-30T11:24:28Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.language.implicitConversions\n+import scala.util.parsing.combinator.syntactical.StandardTokenParsers\n+import scala.util.parsing.combinator.PackratParsers\n+import scala.util.parsing.input.CharArrayReader.EofCh\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.SqlLexical\n+import scala.util.parsing.combinator.lexical.StdLexical\n+\n+/**\n+ * A simple Hive SQL pre parser. It parses the commands like cache,uncache etc and \n+ * remaining actual query will be parsed by HiveQl.parseSql \n+ */\n+class HiveSqlParser extends StandardTokenParsers with PackratParsers {  \n+  \n+   def apply(input: String): LogicalPlan = {\n+    // Special-case out set commands since the value fields can be\n+    // complex to handle without RegexParsers. Also this approach\n+    // is clearer for the several possible cases of set commands.\n+    if (input.trim.toLowerCase.startsWith(\"set\")) {"
  }],
  "prId": 2590
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Nit: I'd prefer `uncache` to `unCache`.\n",
    "commit": "bbca7dd626dcfb79230d4fa954ee3e0dee5c68e9",
    "createdAt": "2014-09-30T06:14:22Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.language.implicitConversions\n+import scala.util.parsing.combinator.syntactical.StandardTokenParsers\n+import scala.util.parsing.combinator.PackratParsers\n+import scala.util.parsing.input.CharArrayReader.EofCh\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.SqlLexical\n+import scala.util.parsing.combinator.lexical.StdLexical\n+\n+/**\n+ * A simple Hive SQL pre parser. It parses the commands like cache,uncache etc and \n+ * remaining actual query will be parsed by HiveQl.parseSql \n+ */\n+class HiveSqlParser extends StandardTokenParsers with PackratParsers {  \n+  \n+   def apply(input: String): LogicalPlan = {\n+    // Special-case out set commands since the value fields can be\n+    // complex to handle without RegexParsers. Also this approach\n+    // is clearer for the several possible cases of set commands.\n+    if (input.trim.toLowerCase.startsWith(\"set\")) {\n+      input.trim.drop(3).split(\"=\", 2).map(_.trim) match {\n+        case Array(\"\") => // \"set\"\n+          SetCommand(None, None)\n+        case Array(key) => // \"set key\"\n+          SetCommand(Some(key), None)\n+        case Array(key, value) => // \"set key=value\"\n+          SetCommand(Some(key), Some(value))\n+      }\n+    } else if (input.trim.startsWith(\"!\")) {\n+      ShellCommand(input.drop(1))      \n+    } else {\n+      phrase(query)(new lexical.Scanner(input)) match {\n+        case Success(r, x) => r\n+        case x => sys.error(x.toString)\n+      }\n+    }\n+  }\n+   \n+  protected case class Keyword(str: String)\n+  \n+  protected val CACHE = Keyword(\"CACHE\")\n+  protected val SET = Keyword(\"SET\")\n+  protected val ADD = Keyword(\"ADD\")\n+  protected val JAR = Keyword(\"JAR\")\n+  protected val TABLE = Keyword(\"TABLE\")\n+  protected val AS = Keyword(\"AS\")\n+  protected val UNCACHE = Keyword(\"UNCACHE\")\n+  protected val FILE = Keyword(\"FILE\")\n+  protected val DFS = Keyword(\"DFS\")\n+  protected val SOURCE = Keyword(\"SOURCE\")\n+  \n+  protected implicit def asParser(k: Keyword): Parser[String] =\n+    lexical.allCaseVersions(k.str).map(x => x : Parser[String]).reduce(_ | _)\n+    \n+  protected def allCaseConverse(k: String): Parser[String] =\n+    lexical.allCaseVersions(k).map(x => x : Parser[String]).reduce(_ | _)   \n+  \n+  protected val reservedWords =\n+    this.getClass\n+      .getMethods\n+      .filter(_.getReturnType == classOf[Keyword])\n+      .map(_.invoke(this).asInstanceOf[Keyword].str)\n+\n+  override val lexical = new SqlLexical(reservedWords)\n+  \n+  protected lazy val query: Parser[LogicalPlan] = (\n+    cache | unCache | addJar | addFile | dfs | source | hiveQl"
  }, {
    "author": {
      "login": "ravipesala"
    },
    "body": "updated\n",
    "commit": "bbca7dd626dcfb79230d4fa954ee3e0dee5c68e9",
    "createdAt": "2014-09-30T11:25:10Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.language.implicitConversions\n+import scala.util.parsing.combinator.syntactical.StandardTokenParsers\n+import scala.util.parsing.combinator.PackratParsers\n+import scala.util.parsing.input.CharArrayReader.EofCh\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.SqlLexical\n+import scala.util.parsing.combinator.lexical.StdLexical\n+\n+/**\n+ * A simple Hive SQL pre parser. It parses the commands like cache,uncache etc and \n+ * remaining actual query will be parsed by HiveQl.parseSql \n+ */\n+class HiveSqlParser extends StandardTokenParsers with PackratParsers {  \n+  \n+   def apply(input: String): LogicalPlan = {\n+    // Special-case out set commands since the value fields can be\n+    // complex to handle without RegexParsers. Also this approach\n+    // is clearer for the several possible cases of set commands.\n+    if (input.trim.toLowerCase.startsWith(\"set\")) {\n+      input.trim.drop(3).split(\"=\", 2).map(_.trim) match {\n+        case Array(\"\") => // \"set\"\n+          SetCommand(None, None)\n+        case Array(key) => // \"set key\"\n+          SetCommand(Some(key), None)\n+        case Array(key, value) => // \"set key=value\"\n+          SetCommand(Some(key), Some(value))\n+      }\n+    } else if (input.trim.startsWith(\"!\")) {\n+      ShellCommand(input.drop(1))      \n+    } else {\n+      phrase(query)(new lexical.Scanner(input)) match {\n+        case Success(r, x) => r\n+        case x => sys.error(x.toString)\n+      }\n+    }\n+  }\n+   \n+  protected case class Keyword(str: String)\n+  \n+  protected val CACHE = Keyword(\"CACHE\")\n+  protected val SET = Keyword(\"SET\")\n+  protected val ADD = Keyword(\"ADD\")\n+  protected val JAR = Keyword(\"JAR\")\n+  protected val TABLE = Keyword(\"TABLE\")\n+  protected val AS = Keyword(\"AS\")\n+  protected val UNCACHE = Keyword(\"UNCACHE\")\n+  protected val FILE = Keyword(\"FILE\")\n+  protected val DFS = Keyword(\"DFS\")\n+  protected val SOURCE = Keyword(\"SOURCE\")\n+  \n+  protected implicit def asParser(k: Keyword): Parser[String] =\n+    lexical.allCaseVersions(k.str).map(x => x : Parser[String]).reduce(_ | _)\n+    \n+  protected def allCaseConverse(k: String): Parser[String] =\n+    lexical.allCaseVersions(k).map(x => x : Parser[String]).reduce(_ | _)   \n+  \n+  protected val reservedWords =\n+    this.getClass\n+      .getMethods\n+      .filter(_.getReturnType == classOf[Keyword])\n+      .map(_.invoke(this).asInstanceOf[Keyword].str)\n+\n+  override val lexical = new SqlLexical(reservedWords)\n+  \n+  protected lazy val query: Parser[LogicalPlan] = (\n+    cache | unCache | addJar | addFile | dfs | source | hiveQl"
  }],
  "prId": 2590
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Nit: space after `:`\n",
    "commit": "bbca7dd626dcfb79230d4fa954ee3e0dee5c68e9",
    "createdAt": "2014-09-30T06:21:24Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.language.implicitConversions\n+import scala.util.parsing.combinator.syntactical.StandardTokenParsers\n+import scala.util.parsing.combinator.PackratParsers\n+import scala.util.parsing.input.CharArrayReader.EofCh\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.SqlLexical\n+import scala.util.parsing.combinator.lexical.StdLexical\n+\n+/**\n+ * A simple Hive SQL pre parser. It parses the commands like cache,uncache etc and \n+ * remaining actual query will be parsed by HiveQl.parseSql \n+ */\n+class HiveSqlParser extends StandardTokenParsers with PackratParsers {  \n+  \n+   def apply(input: String): LogicalPlan = {\n+    // Special-case out set commands since the value fields can be\n+    // complex to handle without RegexParsers. Also this approach\n+    // is clearer for the several possible cases of set commands.\n+    if (input.trim.toLowerCase.startsWith(\"set\")) {\n+      input.trim.drop(3).split(\"=\", 2).map(_.trim) match {\n+        case Array(\"\") => // \"set\"\n+          SetCommand(None, None)\n+        case Array(key) => // \"set key\"\n+          SetCommand(Some(key), None)\n+        case Array(key, value) => // \"set key=value\"\n+          SetCommand(Some(key), Some(value))\n+      }\n+    } else if (input.trim.startsWith(\"!\")) {\n+      ShellCommand(input.drop(1))      \n+    } else {\n+      phrase(query)(new lexical.Scanner(input)) match {\n+        case Success(r, x) => r\n+        case x => sys.error(x.toString)\n+      }\n+    }\n+  }\n+   \n+  protected case class Keyword(str: String)\n+  \n+  protected val CACHE = Keyword(\"CACHE\")\n+  protected val SET = Keyword(\"SET\")\n+  protected val ADD = Keyword(\"ADD\")\n+  protected val JAR = Keyword(\"JAR\")\n+  protected val TABLE = Keyword(\"TABLE\")\n+  protected val AS = Keyword(\"AS\")\n+  protected val UNCACHE = Keyword(\"UNCACHE\")\n+  protected val FILE = Keyword(\"FILE\")\n+  protected val DFS = Keyword(\"DFS\")\n+  protected val SOURCE = Keyword(\"SOURCE\")\n+  \n+  protected implicit def asParser(k: Keyword): Parser[String] =\n+    lexical.allCaseVersions(k.str).map(x => x : Parser[String]).reduce(_ | _)\n+    \n+  protected def allCaseConverse(k: String): Parser[String] =\n+    lexical.allCaseVersions(k).map(x => x : Parser[String]).reduce(_ | _)   \n+  \n+  protected val reservedWords =\n+    this.getClass\n+      .getMethods\n+      .filter(_.getReturnType == classOf[Keyword])\n+      .map(_.invoke(this).asInstanceOf[Keyword].str)\n+\n+  override val lexical = new SqlLexical(reservedWords)\n+  \n+  protected lazy val query: Parser[LogicalPlan] = (\n+    cache | unCache | addJar | addFile | dfs | source | hiveQl\n+  )  \n+  \n+  protected lazy val hiveQl: Parser[LogicalPlan] =\n+    remainingQuery ^^ { \n+      case r => HiveQl.parseSql(r.trim()) \n+    }\n+  \n+  /** It returns all remaining query */\n+  protected lazy val remainingQuery: Parser[String] = new Parser[String] {\n+    def apply(in:Input) = Success(in.source.subSequence(in.offset, in.source.length).toString,"
  }, {
    "author": {
      "login": "ravipesala"
    },
    "body": "Updated\n",
    "commit": "bbca7dd626dcfb79230d4fa954ee3e0dee5c68e9",
    "createdAt": "2014-09-30T11:25:26Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.language.implicitConversions\n+import scala.util.parsing.combinator.syntactical.StandardTokenParsers\n+import scala.util.parsing.combinator.PackratParsers\n+import scala.util.parsing.input.CharArrayReader.EofCh\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.SqlLexical\n+import scala.util.parsing.combinator.lexical.StdLexical\n+\n+/**\n+ * A simple Hive SQL pre parser. It parses the commands like cache,uncache etc and \n+ * remaining actual query will be parsed by HiveQl.parseSql \n+ */\n+class HiveSqlParser extends StandardTokenParsers with PackratParsers {  \n+  \n+   def apply(input: String): LogicalPlan = {\n+    // Special-case out set commands since the value fields can be\n+    // complex to handle without RegexParsers. Also this approach\n+    // is clearer for the several possible cases of set commands.\n+    if (input.trim.toLowerCase.startsWith(\"set\")) {\n+      input.trim.drop(3).split(\"=\", 2).map(_.trim) match {\n+        case Array(\"\") => // \"set\"\n+          SetCommand(None, None)\n+        case Array(key) => // \"set key\"\n+          SetCommand(Some(key), None)\n+        case Array(key, value) => // \"set key=value\"\n+          SetCommand(Some(key), Some(value))\n+      }\n+    } else if (input.trim.startsWith(\"!\")) {\n+      ShellCommand(input.drop(1))      \n+    } else {\n+      phrase(query)(new lexical.Scanner(input)) match {\n+        case Success(r, x) => r\n+        case x => sys.error(x.toString)\n+      }\n+    }\n+  }\n+   \n+  protected case class Keyword(str: String)\n+  \n+  protected val CACHE = Keyword(\"CACHE\")\n+  protected val SET = Keyword(\"SET\")\n+  protected val ADD = Keyword(\"ADD\")\n+  protected val JAR = Keyword(\"JAR\")\n+  protected val TABLE = Keyword(\"TABLE\")\n+  protected val AS = Keyword(\"AS\")\n+  protected val UNCACHE = Keyword(\"UNCACHE\")\n+  protected val FILE = Keyword(\"FILE\")\n+  protected val DFS = Keyword(\"DFS\")\n+  protected val SOURCE = Keyword(\"SOURCE\")\n+  \n+  protected implicit def asParser(k: Keyword): Parser[String] =\n+    lexical.allCaseVersions(k.str).map(x => x : Parser[String]).reduce(_ | _)\n+    \n+  protected def allCaseConverse(k: String): Parser[String] =\n+    lexical.allCaseVersions(k).map(x => x : Parser[String]).reduce(_ | _)   \n+  \n+  protected val reservedWords =\n+    this.getClass\n+      .getMethods\n+      .filter(_.getReturnType == classOf[Keyword])\n+      .map(_.invoke(this).asInstanceOf[Keyword].str)\n+\n+  override val lexical = new SqlLexical(reservedWords)\n+  \n+  protected lazy val query: Parser[LogicalPlan] = (\n+    cache | unCache | addJar | addFile | dfs | source | hiveQl\n+  )  \n+  \n+  protected lazy val hiveQl: Parser[LogicalPlan] =\n+    remainingQuery ^^ { \n+      case r => HiveQl.parseSql(r.trim()) \n+    }\n+  \n+  /** It returns all remaining query */\n+  protected lazy val remainingQuery: Parser[String] = new Parser[String] {\n+    def apply(in:Input) = Success(in.source.subSequence(in.offset, in.source.length).toString,"
  }],
  "prId": 2590
}]