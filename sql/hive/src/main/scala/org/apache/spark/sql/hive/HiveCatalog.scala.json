[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "cc @andrewor14 why does this one need to be synchronized? \n",
    "commit": "6703aa5af0c5bcb428bd0789aedbbec68f4257d0",
    "createdAt": "2016-02-22T04:43:09Z",
    "diffHunk": "@@ -0,0 +1,293 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.hive.ql.metadata.HiveException\n+import org.apache.thrift.TException\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.analysis.NoSuchItemException\n+import org.apache.spark.sql.catalyst.catalog._\n+import org.apache.spark.sql.hive.client.HiveClient\n+\n+\n+/**\n+ * A persistent implementation of the system catalog using Hive.\n+ * All public methods must be synchronized for thread-safety.\n+ */\n+private[spark] class HiveCatalog(client: HiveClient) extends Catalog with Logging {\n+  import Catalog._\n+\n+  // Exceptions thrown by the hive client that we would like to wrap\n+  private val clientExceptions = Set(\n+    classOf[HiveException].getCanonicalName,\n+    classOf[TException].getCanonicalName)\n+\n+  /**\n+   * Whether this is an exception thrown by the hive client that should be wrapped.\n+   *\n+   * Due to classloader isolation issues, pattern matching won't work here so we need\n+   * to compare the canonical names of the exceptions, which we assume to be stable.\n+   */\n+  private def isClientException(e: Throwable): Boolean = {\n+    var temp: Class[_] = e.getClass\n+    var found = false\n+    while (temp != null && !found) {\n+      found = clientExceptions.contains(temp.getCanonicalName)\n+      temp = temp.getSuperclass\n+    }\n+    found\n+  }\n+\n+  /**\n+   * Run some code involving `client` in a [[synchronized]] block and wrap certain\n+   * exceptions thrown in the process in [[AnalysisException]].\n+   */\n+  private def withClient[T](body: => T): T = synchronized {",
    "line": 64
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "shouldn't all methods of the catalog be synchronized?\n",
    "commit": "6703aa5af0c5bcb428bd0789aedbbec68f4257d0",
    "createdAt": "2016-02-22T18:49:38Z",
    "diffHunk": "@@ -0,0 +1,293 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.hive.ql.metadata.HiveException\n+import org.apache.thrift.TException\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.analysis.NoSuchItemException\n+import org.apache.spark.sql.catalyst.catalog._\n+import org.apache.spark.sql.hive.client.HiveClient\n+\n+\n+/**\n+ * A persistent implementation of the system catalog using Hive.\n+ * All public methods must be synchronized for thread-safety.\n+ */\n+private[spark] class HiveCatalog(client: HiveClient) extends Catalog with Logging {\n+  import Catalog._\n+\n+  // Exceptions thrown by the hive client that we would like to wrap\n+  private val clientExceptions = Set(\n+    classOf[HiveException].getCanonicalName,\n+    classOf[TException].getCanonicalName)\n+\n+  /**\n+   * Whether this is an exception thrown by the hive client that should be wrapped.\n+   *\n+   * Due to classloader isolation issues, pattern matching won't work here so we need\n+   * to compare the canonical names of the exceptions, which we assume to be stable.\n+   */\n+  private def isClientException(e: Throwable): Boolean = {\n+    var temp: Class[_] = e.getClass\n+    var found = false\n+    while (temp != null && !found) {\n+      found = clientExceptions.contains(temp.getCanonicalName)\n+      temp = temp.getSuperclass\n+    }\n+    found\n+  }\n+\n+  /**\n+   * Run some code involving `client` in a [[synchronized]] block and wrap certain\n+   * exceptions thrown in the process in [[AnalysisException]].\n+   */\n+  private def withClient[T](body: => T): T = synchronized {",
    "line": 64
  }],
  "prId": 11293
}]