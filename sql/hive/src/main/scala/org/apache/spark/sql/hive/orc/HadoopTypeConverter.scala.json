[{
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Maybe use `SettableStructObjectInspector` instead?\n",
    "commit": "4dbea6ee3feafd549938aebf7bba4181b5a097ae",
    "createdAt": "2015-05-14T02:53:17Z",
    "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.orc\n+\n+import org.apache.hadoop.hive.common.`type`.HiveVarchar\n+import org.apache.spark.sql.hive.{HiveInspectors, HiveShim}\n+import org.apache.hadoop.hive.serde2.objectinspector._\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive._\n+import org.apache.spark.sql.catalyst.expressions.{Row, MutableRow}\n+\n+import scala.collection.JavaConversions._\n+\n+/**\n+ * We can consolidate TableReader.unwrappers and HiveInspectors.wrapperFor to use\n+ * this class.\n+ *\n+ */\n+private[hive] object HadoopTypeConverter extends HiveInspectors {\n+  /**\n+   * Builds specific unwrappers ahead of time according to object inspector\n+   * types to avoid pattern matching and branching costs per row.\n+   */\n+  def unwrappers(fieldRefs: Seq[StructField]): Seq[(Any, MutableRow, Int) => Unit] = fieldRefs.map {\n+    _.getFieldObjectInspector match {\n+      case oi: BooleanObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setBoolean(ordinal, oi.get(value))\n+      case oi: ByteObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setByte(ordinal, oi.get(value))\n+      case oi: ShortObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setShort(ordinal, oi.get(value))\n+      case oi: IntObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setInt(ordinal, oi.get(value))\n+      case oi: LongObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setLong(ordinal, oi.get(value))\n+      case oi: FloatObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setFloat(ordinal, oi.get(value))\n+      case oi: DoubleObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setDouble(ordinal, oi.get(value))\n+      case oi =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row(ordinal) = unwrap(value, oi)\n+    }\n+  }\n+\n+  /**\n+   * Wraps with Hive types based on object inspector.\n+   */\n+  def wrappers(oi: ObjectInspector): Any => Any = oi match {\n+    case _: JavaHiveVarcharObjectInspector =>\n+      (o: Any) => new HiveVarchar(o.asInstanceOf[String], o.asInstanceOf[String].size)\n+\n+    case _: JavaHiveDecimalObjectInspector =>\n+      (o: Any) => HiveShim.createDecimal(o.asInstanceOf[BigDecimal].underlying())\n+\n+    case soi: StandardStructObjectInspector =>"
  }, {
    "author": {
      "login": "zhzhan"
    },
    "body": "Will reuse wrapperFor directly in the next push to remove this part of code totally.\n",
    "commit": "4dbea6ee3feafd549938aebf7bba4181b5a097ae",
    "createdAt": "2015-05-14T03:37:48Z",
    "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.orc\n+\n+import org.apache.hadoop.hive.common.`type`.HiveVarchar\n+import org.apache.spark.sql.hive.{HiveInspectors, HiveShim}\n+import org.apache.hadoop.hive.serde2.objectinspector._\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive._\n+import org.apache.spark.sql.catalyst.expressions.{Row, MutableRow}\n+\n+import scala.collection.JavaConversions._\n+\n+/**\n+ * We can consolidate TableReader.unwrappers and HiveInspectors.wrapperFor to use\n+ * this class.\n+ *\n+ */\n+private[hive] object HadoopTypeConverter extends HiveInspectors {\n+  /**\n+   * Builds specific unwrappers ahead of time according to object inspector\n+   * types to avoid pattern matching and branching costs per row.\n+   */\n+  def unwrappers(fieldRefs: Seq[StructField]): Seq[(Any, MutableRow, Int) => Unit] = fieldRefs.map {\n+    _.getFieldObjectInspector match {\n+      case oi: BooleanObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setBoolean(ordinal, oi.get(value))\n+      case oi: ByteObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setByte(ordinal, oi.get(value))\n+      case oi: ShortObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setShort(ordinal, oi.get(value))\n+      case oi: IntObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setInt(ordinal, oi.get(value))\n+      case oi: LongObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setLong(ordinal, oi.get(value))\n+      case oi: FloatObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setFloat(ordinal, oi.get(value))\n+      case oi: DoubleObjectInspector =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row.setDouble(ordinal, oi.get(value))\n+      case oi =>\n+        (value: Any, row: MutableRow, ordinal: Int) => row(ordinal) = unwrap(value, oi)\n+    }\n+  }\n+\n+  /**\n+   * Wraps with Hive types based on object inspector.\n+   */\n+  def wrappers(oi: ObjectInspector): Any => Any = oi match {\n+    case _: JavaHiveVarcharObjectInspector =>\n+      (o: Any) => new HiveVarchar(o.asInstanceOf[String], o.asInstanceOf[String].size)\n+\n+    case _: JavaHiveDecimalObjectInspector =>\n+      (o: Any) => HiveShim.createDecimal(o.asInstanceOf[BigDecimal].underlying())\n+\n+    case soi: StandardStructObjectInspector =>"
  }],
  "prId": 6135
}, {
  "comments": [{
    "author": {
      "login": "zhzhan"
    },
    "body": "Change TableReader.unwrapper method to remove this duplicated code?\n",
    "commit": "4dbea6ee3feafd549938aebf7bba4181b5a097ae",
    "createdAt": "2015-05-14T03:37:09Z",
    "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.orc\n+\n+import org.apache.hadoop.hive.common.`type`.HiveVarchar\n+import org.apache.spark.sql.hive.{HiveInspectors, HiveShim}\n+import org.apache.hadoop.hive.serde2.objectinspector._\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive._\n+import org.apache.spark.sql.catalyst.expressions.{Row, MutableRow}\n+\n+import scala.collection.JavaConversions._\n+\n+/**\n+ * We can consolidate TableReader.unwrappers and HiveInspectors.wrapperFor to use\n+ * this class.\n+ *\n+ */\n+private[hive] object HadoopTypeConverter extends HiveInspectors {\n+  /**\n+   * Builds specific unwrappers ahead of time according to object inspector\n+   * types to avoid pattern matching and branching costs per row.\n+   */\n+  def unwrappers(fieldRefs: Seq[StructField]): Seq[(Any, MutableRow, Int) => Unit] = fieldRefs.map {",
    "line": 37
  }],
  "prId": 6135
}]