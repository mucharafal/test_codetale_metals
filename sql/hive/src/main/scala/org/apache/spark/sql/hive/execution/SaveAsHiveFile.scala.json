[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "```Scala\r\nprivate def getCompressionByPriority(\r\n    fileSinkConf: FileSinkDesc,\r\n    compressionConf: String,\r\n    default: String): String = {\r\n```",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-10-03T23:43:42Z",
    "diffHunk": "@@ -86,6 +106,14 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n       options = Map.empty)\n   }\n \n+  private def getCompressionByPriority(fileSinkConf: FileSinkDesc,\n+    compressionConf: String, default: String): String = {"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Could you add the description to explain the priority sequences?",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-10-03T23:45:37Z",
    "diffHunk": "@@ -86,6 +106,14 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n       options = Map.empty)\n   }\n \n+  private def getCompressionByPriority(fileSinkConf: FileSinkDesc,\n+    compressionConf: String, default: String): String = {"
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Is it case sensitive? Should we convert it to lower case and upper case for string comparison?",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-10-03T23:46:28Z",
    "diffHunk": "@@ -68,6 +68,26 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.endsWith(\"ParquetOutputFormat\") =>"
  }, {
    "author": {
      "login": "fjh100456"
    },
    "body": "Sounds good idea.",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-10-10T03:41:43Z",
    "diffHunk": "@@ -68,6 +68,26 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.endsWith(\"ParquetOutputFormat\") =>"
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "```Scala\r\n val compressionCodec = getCompressionByPriority(\r\n    fileSinkConf, \r\n    compressionConf = \"parquet.compression\",\r\n    default = sparkSession.sessionState.conf.parquetCompressionCodec) match {\r\n```",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-10-03T23:49:38Z",
    "diffHunk": "@@ -68,6 +68,26 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.endsWith(\"ParquetOutputFormat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(fileSinkConf, compressionConf,\n+          sparkSession.sessionState.conf.parquetCompressionCodec) match {"
  }, {
    "author": {
      "login": "fjh100456"
    },
    "body": "`compressionConf` will be used below, I've adjusted the format, thanks.",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-10-10T03:42:03Z",
    "diffHunk": "@@ -68,6 +68,26 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.endsWith(\"ParquetOutputFormat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(fileSinkConf, compressionConf,\n+          sparkSession.sessionState.conf.parquetCompressionCodec) match {"
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "`case x => x`?",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-10-03T23:50:30Z",
    "diffHunk": "@@ -68,6 +68,26 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.endsWith(\"ParquetOutputFormat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(fileSinkConf, compressionConf,\n+          sparkSession.sessionState.conf.parquetCompressionCodec) match {\n+          case \"NONE\" => \"UNCOMPRESSED\"\n+          case _@x => x\n+        }\n+        hadoopConf.set(compressionConf, compressionCodec)\n+      case formatName if formatName.endsWith(\"OrcOutputFormat\") =>\n+        val compressionConf = \"orc.compress\"\n+        val compressionCodec = getCompressionByPriority(fileSinkConf, compressionConf,\n+          sparkSession.sessionState.conf.orcCompressionCodec) match {\n+          case \"UNCOMPRESSED\" => \"NONE\"\n+          case _@x => x"
  }, {
    "author": {
      "login": "fjh100456"
    },
    "body": "In fact, the following process will check the correctness of this value, and because \"orcoptions\" is not accessable here, I have to add the \"uncompressed\" => \"NONE\" conversion.\r\nDo you have any good advice?",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-10-10T03:42:11Z",
    "diffHunk": "@@ -68,6 +68,26 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.endsWith(\"ParquetOutputFormat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(fileSinkConf, compressionConf,\n+          sparkSession.sessionState.conf.parquetCompressionCodec) match {\n+          case \"NONE\" => \"UNCOMPRESSED\"\n+          case _@x => x\n+        }\n+        hadoopConf.set(compressionConf, compressionCodec)\n+      case formatName if formatName.endsWith(\"OrcOutputFormat\") =>\n+        val compressionConf = \"orc.compress\"\n+        val compressionCodec = getCompressionByPriority(fileSinkConf, compressionConf,\n+          sparkSession.sessionState.conf.orcCompressionCodec) match {\n+          case \"UNCOMPRESSED\" => \"NONE\"\n+          case _@x => x"
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Why ORC and Parquet are different?",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-10-03T23:51:29Z",
    "diffHunk": "@@ -68,6 +68,26 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.endsWith(\"ParquetOutputFormat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(fileSinkConf, compressionConf,\n+          sparkSession.sessionState.conf.parquetCompressionCodec) match {\n+          case \"NONE\" => \"UNCOMPRESSED\"\n+          case _@x => x\n+        }\n+        hadoopConf.set(compressionConf, compressionCodec)\n+      case formatName if formatName.endsWith(\"OrcOutputFormat\") =>\n+        val compressionConf = \"orc.compress\"\n+        val compressionCodec = getCompressionByPriority(fileSinkConf, compressionConf,\n+          sparkSession.sessionState.conf.orcCompressionCodec) match {\n+          case \"UNCOMPRESSED\" => \"NONE\""
  }, {
    "author": {
      "login": "fjh100456"
    },
    "body": "Yes, they are different, the style of parameter names and parameter values are all different, and should be parquet and orc problems.",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-10-10T03:42:20Z",
    "diffHunk": "@@ -68,6 +68,26 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.endsWith(\"ParquetOutputFormat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(fileSinkConf, compressionConf,\n+          sparkSession.sessionState.conf.parquetCompressionCodec) match {\n+          case \"NONE\" => \"UNCOMPRESSED\"\n+          case _@x => x\n+        }\n+        hadoopConf.set(compressionConf, compressionCodec)\n+      case formatName if formatName.endsWith(\"OrcOutputFormat\") =>\n+        val compressionConf = \"orc.compress\"\n+        val compressionCodec = getCompressionByPriority(fileSinkConf, compressionConf,\n+          sparkSession.sessionState.conf.orcCompressionCodec) match {\n+          case \"UNCOMPRESSED\" => \"NONE\""
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "` \"parquet.compression\"` -> `ParquetOutputFormat.COMPRESSION`",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-12-02T23:10:22Z",
    "diffHunk": "@@ -68,6 +68,30 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.toLowerCase.endsWith(\"parquetoutputformat\") =>\n+        val compressionConf = \"parquet.compression\""
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "-> `OrcRelation.ORC_COMPRESSION`",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-12-02T23:10:36Z",
    "diffHunk": "@@ -68,6 +68,30 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.toLowerCase.endsWith(\"parquetoutputformat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(\n+          fileSinkConf,\n+          compressionConf,\n+          default = sparkSession.sessionState.conf.parquetCompressionCodec) match {\n+          case \"NONE\" => \"UNCOMPRESSED\"\n+          case _@x => x\n+        }\n+        hadoopConf.set(compressionConf, compressionCodec)\n+      case formatName if formatName.endsWith(\"OrcOutputFormat\") =>\n+        val compressionConf = \"orc.compress\""
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Move the whole determination logics to `object HiveOptions`. You can call it in  `SaveAsHiveFile.scala`",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-12-02T23:13:46Z",
    "diffHunk": "@@ -68,6 +68,30 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.toLowerCase.endsWith(\"parquetoutputformat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(\n+          fileSinkConf,\n+          compressionConf,\n+          default = sparkSession.sessionState.conf.parquetCompressionCodec) match {\n+          case \"NONE\" => \"UNCOMPRESSED\"\n+          case _@x => x\n+        }\n+        hadoopConf.set(compressionConf, compressionCodec)\n+      case formatName if formatName.endsWith(\"OrcOutputFormat\") =>\n+        val compressionConf = \"orc.compress\"\n+        val compressionCodec = getCompressionByPriority(\n+          fileSinkConf,\n+          compressionConf,\n+          default = sparkSession.sessionState.conf.orcCompressionCodec) match {\n+          case \"UNCOMPRESSED\" => \"NONE\"\n+          case _@x => x\n+        }"
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "`case o => o`",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-12-02T23:14:28Z",
    "diffHunk": "@@ -68,6 +68,30 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.toLowerCase.endsWith(\"parquetoutputformat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(\n+          fileSinkConf,\n+          compressionConf,\n+          default = sparkSession.sessionState.conf.parquetCompressionCodec) match {\n+          case \"NONE\" => \"UNCOMPRESSED\"\n+          case _@x => x\n+        }\n+        hadoopConf.set(compressionConf, compressionCodec)\n+      case formatName if formatName.endsWith(\"OrcOutputFormat\") =>\n+        val compressionConf = \"orc.compress\"\n+        val compressionCodec = getCompressionByPriority(\n+          fileSinkConf,\n+          compressionConf,\n+          default = sparkSession.sessionState.conf.orcCompressionCodec) match {\n+          case \"UNCOMPRESSED\" => \"NONE\"\n+          case _@x => x"
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Why always making it upper case? This looks buggy.",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-12-02T23:15:18Z",
    "diffHunk": "@@ -68,6 +68,30 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.toLowerCase.endsWith(\"parquetoutputformat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(\n+          fileSinkConf,\n+          compressionConf,\n+          default = sparkSession.sessionState.conf.parquetCompressionCodec) match {\n+          case \"NONE\" => \"UNCOMPRESSED\"\n+          case _@x => x\n+        }\n+        hadoopConf.set(compressionConf, compressionCodec)\n+      case formatName if formatName.endsWith(\"OrcOutputFormat\") =>\n+        val compressionConf = \"orc.compress\"\n+        val compressionCodec = getCompressionByPriority(\n+          fileSinkConf,\n+          compressionConf,\n+          default = sparkSession.sessionState.conf.orcCompressionCodec) match {\n+          case \"UNCOMPRESSED\" => \"NONE\""
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "The same here.",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-12-02T23:15:28Z",
    "diffHunk": "@@ -68,6 +68,30 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.toLowerCase.endsWith(\"parquetoutputformat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(\n+          fileSinkConf,\n+          compressionConf,\n+          default = sparkSession.sessionState.conf.parquetCompressionCodec) match {\n+          case \"NONE\" => \"UNCOMPRESSED\"\n+          case _@x => x"
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "I suggest to add a normalization logics for both ORC and Parquet. \r\n\r\nCheck the `ParquetOptions`.`shortParquetCompressionCodecNames` ",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-12-02T23:18:38Z",
    "diffHunk": "@@ -68,6 +68,30 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.toLowerCase.endsWith(\"parquetoutputformat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(\n+          fileSinkConf,\n+          compressionConf,\n+          default = sparkSession.sessionState.conf.parquetCompressionCodec) match {\n+          case \"NONE\" => \"UNCOMPRESSED\"\n+          case _@x => x\n+        }\n+        hadoopConf.set(compressionConf, compressionCodec)\n+      case formatName if formatName.endsWith(\"OrcOutputFormat\") =>\n+        val compressionConf = \"orc.compress\"\n+        val compressionCodec = getCompressionByPriority(\n+          fileSinkConf,\n+          compressionConf,\n+          default = sparkSession.sessionState.conf.orcCompressionCodec) match {"
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Is it okay to leave this priority in the spark document or somewhere? https://spark.apache.org/docs/latest/sql-programming-guide.html#configuration",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-12-18T13:06:11Z",
    "diffHunk": "@@ -86,6 +110,19 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n       options = Map.empty)\n   }\n \n+  // Because compression configurations can come in a variety of ways,\n+  // we choose the compression configuration in this order:\n+  // For parquet: `compression` > `parquet.compression` > `spark.sql.parquet.compression.codec`\n+  // For orc: `compression` > `orc.compress` > `spark.sql.orc.compression.codec`"
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "`case formatName if formatName.toLowerCase.endsWith(\"orcoutputformat\") =>`?\r\nOr, you write `fileSinkConf.tableInfo.getOutputFileFormatClassName.toLowerCase match {`, then each match does not convert lower-case conversion?",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-12-18T13:17:24Z",
    "diffHunk": "@@ -68,6 +68,30 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    fileSinkConf.tableInfo.getOutputFileFormatClassName match {\n+      case formatName if formatName.toLowerCase.endsWith(\"parquetoutputformat\") =>\n+        val compressionConf = \"parquet.compression\"\n+        val compressionCodec = getCompressionByPriority(\n+          fileSinkConf,\n+          compressionConf,\n+          default = sparkSession.sessionState.conf.parquetCompressionCodec) match {\n+          case \"NONE\" => \"UNCOMPRESSED\"\n+          case _@x => x\n+        }\n+        hadoopConf.set(compressionConf, compressionCodec)\n+      case formatName if formatName.endsWith(\"OrcOutputFormat\") =>"
  }],
  "prId": 19218
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "```\r\n.foreach { case (compression, codec) => hadoopConf.set(compression, codec) }\r\n```",
    "commit": "52cdd75f7845d35aca41562f670c98384fb015b2",
    "createdAt": "2017-12-22T08:08:28Z",
    "diffHunk": "@@ -68,6 +68,12 @@ private[hive] trait SaveAsHiveFile extends DataWritingCommand {\n         .get(\"mapreduce.output.fileoutputformat.compress.type\"))\n     }\n \n+    // Set compression by priority\n+    HiveOptions.getHiveWriteCompression(fileSinkConf.getTableInfo, sparkSession.sessionState.conf)\n+      .foreach{ case (compression, codec) =>\n+        hadoopConf.set(compression, codec)\n+      }"
  }],
  "prId": 19218
}]