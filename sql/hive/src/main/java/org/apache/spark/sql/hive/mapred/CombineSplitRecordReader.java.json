[{
  "comments": [{
    "author": {
      "login": "chenghao-intel"
    },
    "body": "Since the progress granularity is split length, can we simply use the `idx / split.getSplitNum()`?\n",
    "commit": "085ce5feca2294f81f9ec7a5660635be13c70a4a",
    "createdAt": "2015-10-16T01:14:36Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.mapred;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.mapred.InputFormat;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.hadoop.mapred.RecordReader;\n+import org.apache.hadoop.mapred.Reporter;\n+\n+/**\n+ * A generic RecordReader that can hand out different recordReaders\n+ * for each split in a {@link org.apache.spark.sql.hive.mapred.CombineSplit}.\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Stable\n+public class CombineSplitRecordReader<K, V> implements RecordReader<K, V> {\n+  protected CombineSplit split;\n+  protected JobConf jc;\n+  protected FileSystem fs;\n+\n+  protected int idx;\n+  protected long progress;\n+  protected RecordReader<K, V> curReader;\n+\n+  @Override\n+  public boolean next(K key, V value) throws IOException {\n+    while ((curReader == null) || !curReader.next(key, value)) {\n+      if (!initNextRecordReader()) {\n+        return false;\n+      }\n+    }\n+    return true;\n+  }\n+\n+  public K createKey() {\n+    return curReader.createKey();\n+  }\n+\n+  public V createValue() {\n+    return curReader.createValue();\n+  }\n+\n+  /**\n+   * return the amount of data processed\n+   */\n+  public long getPos() throws IOException {\n+    return progress;\n+  }\n+\n+  public void close() throws IOException {\n+    if (curReader != null) {\n+      curReader.close();\n+      curReader = null;\n+    }\n+  }\n+\n+  /**\n+   * return progress based on the amount of data processed so far.\n+   */\n+  public float getProgress() throws IOException {\n+    return Math.min(1.0f,  progress/(float)(split.getLength()));"
  }, {
    "author": {
      "login": "zhichao-li"
    },
    "body": "I think the current one can give a more fine-grained metric. i.e. combinedSplit(split1-10M, split2-10M, split3-80M), let's say we've consumed split1 and split2 if we only calc by index then the progress is (2/3), but it would be (20%) otherwise.  Maybe I need to rename `split` -> `combinedSplit` to make name more readable.\n",
    "commit": "085ce5feca2294f81f9ec7a5660635be13c70a4a",
    "createdAt": "2015-10-16T01:34:42Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.mapred;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.mapred.InputFormat;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.hadoop.mapred.RecordReader;\n+import org.apache.hadoop.mapred.Reporter;\n+\n+/**\n+ * A generic RecordReader that can hand out different recordReaders\n+ * for each split in a {@link org.apache.spark.sql.hive.mapred.CombineSplit}.\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Stable\n+public class CombineSplitRecordReader<K, V> implements RecordReader<K, V> {\n+  protected CombineSplit split;\n+  protected JobConf jc;\n+  protected FileSystem fs;\n+\n+  protected int idx;\n+  protected long progress;\n+  protected RecordReader<K, V> curReader;\n+\n+  @Override\n+  public boolean next(K key, V value) throws IOException {\n+    while ((curReader == null) || !curReader.next(key, value)) {\n+      if (!initNextRecordReader()) {\n+        return false;\n+      }\n+    }\n+    return true;\n+  }\n+\n+  public K createKey() {\n+    return curReader.createKey();\n+  }\n+\n+  public V createValue() {\n+    return curReader.createValue();\n+  }\n+\n+  /**\n+   * return the amount of data processed\n+   */\n+  public long getPos() throws IOException {\n+    return progress;\n+  }\n+\n+  public void close() throws IOException {\n+    if (curReader != null) {\n+      curReader.close();\n+      curReader = null;\n+    }\n+  }\n+\n+  /**\n+   * return progress based on the amount of data processed so far.\n+   */\n+  public float getProgress() throws IOException {\n+    return Math.min(1.0f,  progress/(float)(split.getLength()));"
  }, {
    "author": {
      "login": "chenghao-intel"
    },
    "body": "OK, I see, maybe we can rename \"progress\" to something else as well.\n",
    "commit": "085ce5feca2294f81f9ec7a5660635be13c70a4a",
    "createdAt": "2015-10-16T04:25:40Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.mapred;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.mapred.InputFormat;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.hadoop.mapred.RecordReader;\n+import org.apache.hadoop.mapred.Reporter;\n+\n+/**\n+ * A generic RecordReader that can hand out different recordReaders\n+ * for each split in a {@link org.apache.spark.sql.hive.mapred.CombineSplit}.\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Stable\n+public class CombineSplitRecordReader<K, V> implements RecordReader<K, V> {\n+  protected CombineSplit split;\n+  protected JobConf jc;\n+  protected FileSystem fs;\n+\n+  protected int idx;\n+  protected long progress;\n+  protected RecordReader<K, V> curReader;\n+\n+  @Override\n+  public boolean next(K key, V value) throws IOException {\n+    while ((curReader == null) || !curReader.next(key, value)) {\n+      if (!initNextRecordReader()) {\n+        return false;\n+      }\n+    }\n+    return true;\n+  }\n+\n+  public K createKey() {\n+    return curReader.createKey();\n+  }\n+\n+  public V createValue() {\n+    return curReader.createValue();\n+  }\n+\n+  /**\n+   * return the amount of data processed\n+   */\n+  public long getPos() throws IOException {\n+    return progress;\n+  }\n+\n+  public void close() throws IOException {\n+    if (curReader != null) {\n+      curReader.close();\n+      curReader = null;\n+    }\n+  }\n+\n+  /**\n+   * return progress based on the amount of data processed so far.\n+   */\n+  public float getProgress() throws IOException {\n+    return Math.min(1.0f,  progress/(float)(split.getLength()));"
  }],
  "prId": 9097
}, {
  "comments": [{
    "author": {
      "login": "chenghao-intel"
    },
    "body": "`progress + curReader.getPos()`?\n",
    "commit": "085ce5feca2294f81f9ec7a5660635be13c70a4a",
    "createdAt": "2015-10-16T01:15:57Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.mapred;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.mapred.InputFormat;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.hadoop.mapred.RecordReader;\n+import org.apache.hadoop.mapred.Reporter;\n+\n+/**\n+ * A generic RecordReader that can hand out different recordReaders\n+ * for each split in a {@link org.apache.spark.sql.hive.mapred.CombineSplit}.\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Stable\n+public class CombineSplitRecordReader<K, V> implements RecordReader<K, V> {\n+  protected CombineSplit split;\n+  protected JobConf jc;\n+  protected FileSystem fs;\n+\n+  protected int idx;\n+  protected long progress;\n+  protected RecordReader<K, V> curReader;\n+\n+  @Override\n+  public boolean next(K key, V value) throws IOException {\n+    while ((curReader == null) || !curReader.next(key, value)) {\n+      if (!initNextRecordReader()) {\n+        return false;\n+      }\n+    }\n+    return true;\n+  }\n+\n+  public K createKey() {\n+    return curReader.createKey();\n+  }\n+\n+  public V createValue() {\n+    return curReader.createValue();\n+  }\n+\n+  /**\n+   * return the amount of data processed\n+   */\n+  public long getPos() throws IOException {"
  }],
  "prId": 9097
}, {
  "comments": [{
    "author": {
      "login": "chenghao-intel"
    },
    "body": "Nit: Move this ahead? Put all of the class members together?\n",
    "commit": "085ce5feca2294f81f9ec7a5660635be13c70a4a",
    "createdAt": "2015-10-16T01:17:48Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.mapred;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.mapred.InputFormat;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.hadoop.mapred.RecordReader;\n+import org.apache.hadoop.mapred.Reporter;\n+\n+/**\n+ * A generic RecordReader that can hand out different recordReaders\n+ * for each split in a {@link org.apache.spark.sql.hive.mapred.CombineSplit}.\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Stable\n+public class CombineSplitRecordReader<K, V> implements RecordReader<K, V> {\n+  protected CombineSplit split;\n+  protected JobConf jc;\n+  protected FileSystem fs;\n+\n+  protected int idx;\n+  protected long progress;\n+  protected RecordReader<K, V> curReader;\n+\n+  @Override\n+  public boolean next(K key, V value) throws IOException {\n+    while ((curReader == null) || !curReader.next(key, value)) {\n+      if (!initNextRecordReader()) {\n+        return false;\n+      }\n+    }\n+    return true;\n+  }\n+\n+  public K createKey() {\n+    return curReader.createKey();\n+  }\n+\n+  public V createValue() {\n+    return curReader.createValue();\n+  }\n+\n+  /**\n+   * return the amount of data processed\n+   */\n+  public long getPos() throws IOException {\n+    return progress;\n+  }\n+\n+  public void close() throws IOException {\n+    if (curReader != null) {\n+      curReader.close();\n+      curReader = null;\n+    }\n+  }\n+\n+  /**\n+   * return progress based on the amount of data processed so far.\n+   */\n+  public float getProgress() throws IOException {\n+    return Math.min(1.0f,  progress/(float)(split.getLength()));\n+  }\n+  private InputFormat<K, V> inputFormat;"
  }],
  "prId": 9097
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Remove these two annotations since they are not true in the scope of Spark.\n",
    "commit": "085ce5feca2294f81f9ec7a5660635be13c70a4a",
    "createdAt": "2016-02-02T00:16:41Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.mapred;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.mapred.InputFormat;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.hadoop.mapred.RecordReader;\n+import org.apache.hadoop.mapred.Reporter;\n+\n+/**\n+ * A generic RecordReader that can hand out different recordReaders\n+ * for each split in a {@link org.apache.spark.sql.hive.mapred.CombineSplit}.\n+ */\n+@InterfaceAudience.Public\n+@InterfaceStability.Stable"
  }],
  "prId": 9097
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Please add a comment here to point out which version of Hive/Hadoop this implementation is based on.\n",
    "commit": "085ce5feca2294f81f9ec7a5660635be13c70a4a",
    "createdAt": "2016-02-02T00:16:51Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.mapred;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.mapred.InputFormat;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.hadoop.mapred.RecordReader;\n+import org.apache.hadoop.mapred.Reporter;\n+\n+/**\n+ * A generic RecordReader that can hand out different recordReaders\n+ * for each split in a {@link org.apache.spark.sql.hive.mapred.CombineSplit}.\n+ */"
  }],
  "prId": 9097
}]