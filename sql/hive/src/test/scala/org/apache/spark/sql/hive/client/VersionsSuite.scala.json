[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Is there a reason to have this in `VersionSuite`?",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-20T17:46:51Z",
    "diffHunk": "@@ -841,6 +841,76 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: Insert into/overwrite external avro table\") {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Could you add `SPARK-19878` in a test case name?",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-20T17:54:13Z",
    "diffHunk": "@@ -841,6 +841,76 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: Insert into/overwrite external avro table\") {"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "I am fine to keep it in `VersionSuite`, since it is related to Hive. ",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-21T07:54:43Z",
    "diffHunk": "@@ -841,6 +841,76 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: Insert into/overwrite external avro table\") {"
  }],
  "prId": 19779
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "nit.\r\n```\r\nINSERT OVERWRITE TABLE $destTableName SELECT * FROM $srcTableName\r\n```",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-20T17:56:03Z",
    "diffHunk": "@@ -841,6 +841,76 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: Insert into/overwrite external avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaurl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        new java.io.PrintWriter(schemaurl) { write(avroSchema); close() }\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          val destLocation = s\"\"\"$path${File.separator}destTableLocation\"\"\"\n+          new File(destLocation).mkdir()\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$destLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          versionSpark.sql(\n+            s\"\"\"insert overwrite table $destTableName select * from $srcTableName\"\"\".stripMargin)"
  }, {
    "author": {
      "login": "vinodkc"
    },
    "body": "Thank you for your review comments, I'll fix all your comments ",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-20T18:06:26Z",
    "diffHunk": "@@ -841,6 +841,76 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: Insert into/overwrite external avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaurl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        new java.io.PrintWriter(schemaurl) { write(avroSchema); close() }\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          val destLocation = s\"\"\"$path${File.separator}destTableLocation\"\"\"\n+          new File(destLocation).mkdir()\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$destLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          versionSpark.sql(\n+            s\"\"\"insert overwrite table $destTableName select * from $srcTableName\"\"\".stripMargin)"
  }],
  "prId": 19779
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "ditto.",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-20T17:56:11Z",
    "diffHunk": "@@ -841,6 +841,76 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: Insert into/overwrite external avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaurl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        new java.io.PrintWriter(schemaurl) { write(avroSchema); close() }\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          val destLocation = s\"\"\"$path${File.separator}destTableLocation\"\"\"\n+          new File(destLocation).mkdir()\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$destLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          versionSpark.sql(\n+            s\"\"\"insert overwrite table $destTableName select * from $srcTableName\"\"\".stripMargin)\n+          assert(versionSpark.table(destTableName).count() ===\n+            versionSpark.table(srcTableName).count())\n+          versionSpark.sql(\n+            s\"\"\"insert into table $destTableName select * from $srcTableName\"\"\".stripMargin)"
  }],
  "prId": 19779
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "If possible, can we check values instead of count?",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-20T17:58:13Z",
    "diffHunk": "@@ -841,6 +841,76 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: Insert into/overwrite external avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaurl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        new java.io.PrintWriter(schemaurl) { write(avroSchema); close() }\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          val destLocation = s\"\"\"$path${File.separator}destTableLocation\"\"\"\n+          new File(destLocation).mkdir()\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$destLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          versionSpark.sql(\n+            s\"\"\"insert overwrite table $destTableName select * from $srcTableName\"\"\".stripMargin)\n+          assert(versionSpark.table(destTableName).count() ===\n+            versionSpark.table(srcTableName).count())\n+          versionSpark.sql(\n+            s\"\"\"insert into table $destTableName select * from $srcTableName\"\"\".stripMargin)\n+          assert(versionSpark.table(destTableName).count()/2 ===\n+            versionSpark.table(srcTableName).count())"
  }],
  "prId": 19779
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "do you mean SPARK-17920 is already fixed because this test passes?",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-21T12:28:06Z",
    "diffHunk": "@@ -800,7 +800,7 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n-    test(s\"$version: read avro file containing decimal\") {\n+    test(s\"$version: SPARK-17920: read avro file containing decimal\") {"
  }, {
    "author": {
      "login": "vinodkc"
    },
    "body": "@cloud-fan , Sorry, wrong test case updated,I'll change it",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-21T14:14:41Z",
    "diffHunk": "@@ -800,7 +800,7 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n-    test(s\"$version: read avro file containing decimal\") {\n+    test(s\"$version: SPARK-17920: read avro file containing decimal\") {"
  }],
  "prId": 19779
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit:\r\n```\r\nval schemaFile = new File(dir, \"avroDecimal.avsc\")\r\nval writer = new PrintWriter(schemaFile)\r\nwriter.write(avroSchema)\r\nwriter.close()\r\n...\r\n```",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-21T16:48:23Z",
    "diffHunk": "@@ -841,6 +841,75 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: SPARK-17920: Insert into/overwrite external avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\""
  }],
  "prId": 19779
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "do we have to provide a location for an empty table?",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-21T16:51:04Z",
    "diffHunk": "@@ -841,6 +841,75 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: SPARK-17920: Insert into/overwrite external avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaurl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        new java.io.PrintWriter(schemaurl) { write(avroSchema); close() }\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          val destLocation = s\"\"\"$path${File.separator}destTableLocation\"\"\"\n+          new File(destLocation).mkdir()\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$destLocation'"
  }, {
    "author": {
      "login": "vinodkc"
    },
    "body": "Will change to 'CREATE EXTERNAL TABLE'",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-21T17:37:07Z",
    "diffHunk": "@@ -841,6 +841,75 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: SPARK-17920: Insert into/overwrite external avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaurl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        new java.io.PrintWriter(schemaurl) { write(avroSchema); close() }\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          val destLocation = s\"\"\"$path${File.separator}destTableLocation\"\"\"\n+          new File(destLocation).mkdir()\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$destLocation'"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "This bug is for external table only? how about managed table?",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-21T19:52:16Z",
    "diffHunk": "@@ -841,6 +841,75 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: SPARK-17920: Insert into/overwrite external avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaurl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        new java.io.PrintWriter(schemaurl) { write(avroSchema); close() }\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          val destLocation = s\"\"\"$path${File.separator}destTableLocation\"\"\"\n+          new File(destLocation).mkdir()\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$destLocation'"
  }, {
    "author": {
      "login": "vinodkc"
    },
    "body": "@cloud-fan , This bug is for both external and managed tables.\r\n I've added a new test case for managed table too. However, to avoid code duplication, should I include both tests inside same test method?. Please suggest.",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-22T01:13:57Z",
    "diffHunk": "@@ -841,6 +841,75 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: SPARK-17920: Insert into/overwrite external avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaurl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        new java.io.PrintWriter(schemaurl) { write(avroSchema); close() }\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          val destLocation = s\"\"\"$path${File.separator}destTableLocation\"\"\"\n+          new File(destLocation).mkdir()\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$destLocation'"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "we can just test the managed table, to avoid creating a temp directory for external table.",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-22T01:32:09Z",
    "diffHunk": "@@ -841,6 +841,75 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: SPARK-17920: Insert into/overwrite external avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaurl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        new java.io.PrintWriter(schemaurl) { write(avroSchema); close() }\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          val destLocation = s\"\"\"$path${File.separator}destTableLocation\"\"\"\n+          new File(destLocation).mkdir()\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$destLocation'"
  }, {
    "author": {
      "login": "vinodkc"
    },
    "body": "Thanks, I've updated the test case to test only managed tables and avoided creating a temp directory.",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-22T03:52:02Z",
    "diffHunk": "@@ -841,6 +841,75 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: SPARK-17920: Insert into/overwrite external avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaurl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        new java.io.PrintWriter(schemaurl) { write(avroSchema); close() }\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaurl')\n+           \"\"\".stripMargin\n+          )\n+          val destLocation = s\"\"\"$path${File.separator}destTableLocation\"\"\"\n+          new File(destLocation).mkdir()\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$destLocation'"
  }],
  "prId": 19779
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "`stripMargin ` is useless ",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-22T04:07:54Z",
    "diffHunk": "@@ -841,6 +841,76 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: SPARK-17920: Insert into/overwrite avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaUrl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        val schemaFile = new File(schemaPath, \"avroDecimal.avsc\")\n+        val writer = new PrintWriter(schemaFile)\n+        writer.write(avroSchema)\n+        writer.close()\n+\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE EXTERNAL TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaUrl')\n+           \"\"\".stripMargin\n+          )\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaUrl')\n+           \"\"\".stripMargin\n+          )\n+          versionSpark.sql(\n+            s\"\"\"INSERT OVERWRITE TABLE $destTableName SELECT * FROM $srcTableName\"\"\".stripMargin)"
  }, {
    "author": {
      "login": "vinodkc"
    },
    "body": "Sure, I'll update it",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-22T05:43:19Z",
    "diffHunk": "@@ -841,6 +841,76 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: SPARK-17920: Insert into/overwrite avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaUrl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        val schemaFile = new File(schemaPath, \"avroDecimal.avsc\")\n+        val writer = new PrintWriter(schemaFile)\n+        writer.write(avroSchema)\n+        writer.close()\n+\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE EXTERNAL TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaUrl')\n+           \"\"\".stripMargin\n+          )\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaUrl')\n+           \"\"\".stripMargin\n+          )\n+          versionSpark.sql(\n+            s\"\"\"INSERT OVERWRITE TABLE $destTableName SELECT * FROM $srcTableName\"\"\".stripMargin)"
  }],
  "prId": 19779
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "The same here.",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-22T04:08:01Z",
    "diffHunk": "@@ -841,6 +841,76 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: SPARK-17920: Insert into/overwrite avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaUrl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        val schemaFile = new File(schemaPath, \"avroDecimal.avsc\")\n+        val writer = new PrintWriter(schemaFile)\n+        writer.write(avroSchema)\n+        writer.close()\n+\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE EXTERNAL TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaUrl')\n+           \"\"\".stripMargin\n+          )\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaUrl')\n+           \"\"\".stripMargin\n+          )\n+          versionSpark.sql(\n+            s\"\"\"INSERT OVERWRITE TABLE $destTableName SELECT * FROM $srcTableName\"\"\".stripMargin)\n+          val result = versionSpark.table(srcTableName).collect()\n+          assert(versionSpark.table(destTableName).collect() === result)\n+          versionSpark.sql(\n+            s\"\"\"INSERT INTO TABLE $destTableName SELECT * FROM $srcTableName\"\"\".stripMargin)"
  }, {
    "author": {
      "login": "vinodkc"
    },
    "body": "Updated",
    "commit": "e3651ef06d3ac3232b447df5d450632d8fde8ce2",
    "createdAt": "2017-11-22T05:50:35Z",
    "diffHunk": "@@ -841,6 +841,76 @@ class VersionsSuite extends SparkFunSuite with Logging {\n       }\n     }\n \n+    test(s\"$version: SPARK-17920: Insert into/overwrite avro table\") {\n+      withTempDir { dir =>\n+        val path = dir.getAbsolutePath\n+        val schemaPath = s\"\"\"$path${File.separator}avroschemadir\"\"\"\n+\n+        new File(schemaPath).mkdir()\n+        val avroSchema =\n+          \"\"\"{\n+            |  \"name\": \"test_record\",\n+            |  \"type\": \"record\",\n+            |  \"fields\": [ {\n+            |    \"name\": \"f0\",\n+            |    \"type\": [\n+            |      \"null\",\n+            |      {\n+            |        \"precision\": 38,\n+            |        \"scale\": 2,\n+            |        \"type\": \"bytes\",\n+            |        \"logicalType\": \"decimal\"\n+            |      }\n+            |    ]\n+            |  } ]\n+            |}\n+          \"\"\".stripMargin\n+        val schemaUrl = s\"\"\"$schemaPath${File.separator}avroDecimal.avsc\"\"\"\n+        val schemaFile = new File(schemaPath, \"avroDecimal.avsc\")\n+        val writer = new PrintWriter(schemaFile)\n+        writer.write(avroSchema)\n+        writer.close()\n+\n+        val url = Thread.currentThread().getContextClassLoader.getResource(\"avroDecimal\")\n+        val srcLocation = new File(url.getFile)\n+        val destTableName = \"tab1\"\n+        val srcTableName = \"tab2\"\n+\n+        withTable(srcTableName, destTableName) {\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE EXTERNAL TABLE $srcTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |LOCATION '$srcLocation'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaUrl')\n+           \"\"\".stripMargin\n+          )\n+\n+          versionSpark.sql(\n+            s\"\"\"\n+               |CREATE TABLE $destTableName\n+               |ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n+               |WITH SERDEPROPERTIES ('respectSparkSchema' = 'true')\n+               |STORED AS\n+               |  INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n+               |  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\n+               |TBLPROPERTIES ('avro.schema.url' = '$schemaUrl')\n+           \"\"\".stripMargin\n+          )\n+          versionSpark.sql(\n+            s\"\"\"INSERT OVERWRITE TABLE $destTableName SELECT * FROM $srcTableName\"\"\".stripMargin)\n+          val result = versionSpark.table(srcTableName).collect()\n+          assert(versionSpark.table(destTableName).collect() === result)\n+          versionSpark.sql(\n+            s\"\"\"INSERT INTO TABLE $destTableName SELECT * FROM $srcTableName\"\"\".stripMargin)"
  }],
  "prId": 19779
}]