[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "do you mean we will have table stats anyway as hive metastore stores it?",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-28T03:27:15Z",
    "diffHunk": "@@ -448,6 +433,145 @@ class StatisticsSuite extends StatisticsCollectionTestBase with TestHiveSingleto\n       \"ALTER TABLE unset_prop_table UNSET TBLPROPERTIES ('prop1')\")\n   }\n \n+  /**\n+   * To see if stats exist, we need to check spark's stats properties instead of catalog\n+   * statistics, because hive would change stats in metastore and thus change catalog statistics."
  }, {
    "author": {
      "login": "wzhfy"
    },
    "body": "Hive updates stats for some formats, e.g. in the test `test statistics of LogicalRelation converted from Hive serde tables`, hive updates stats for orc table but not parquet table.\r\nI think it's tricky and fussy to relay on hive's stats, we should rely on spark's stats. Here I just eliminate hive's influence for checking. As in `CatalogStatistics` we first fill in hive's stats and then override it using spark's stats, we can't tell where the stats is from if we check `CatalogStatistics`.",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-28T05:47:45Z",
    "diffHunk": "@@ -448,6 +433,145 @@ class StatisticsSuite extends StatisticsCollectionTestBase with TestHiveSingleto\n       \"ALTER TABLE unset_prop_table UNSET TBLPROPERTIES ('prop1')\")\n   }\n \n+  /**\n+   * To see if stats exist, we need to check spark's stats properties instead of catalog\n+   * statistics, because hive would change stats in metastore and thus change catalog statistics."
  }],
  "prId": 18334
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "can we put these tests in the parent class? so we don't need to duplicate the code for hvie and data source tables.",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-28T03:28:50Z",
    "diffHunk": "@@ -448,6 +433,145 @@ class StatisticsSuite extends StatisticsCollectionTestBase with TestHiveSingleto\n       \"ALTER TABLE unset_prop_table UNSET TBLPROPERTIES ('prop1')\")\n   }\n \n+  /**\n+   * To see if stats exist, we need to check spark's stats properties instead of catalog\n+   * statistics, because hive would change stats in metastore and thus change catalog statistics.\n+   */\n+  private def getStatsProperties(tableName: String): Map[String, String] = {\n+    val hTable = hiveClient.getTable(spark.sessionState.catalog.getCurrentDatabase, tableName)\n+    hTable.properties.filterKeys(_.startsWith(STATISTICS_PREFIX))\n+  }\n+\n+  test(\"change stats after insert command for hive table\") {\n+    val table = s\"change_stats_insert_hive_table\"\n+    Seq(false, true).foreach { autoUpdate =>\n+      withSQLConf(SQLConf.AUTO_UPDATE_SIZE.key -> autoUpdate.toString) {\n+        withTable(table) {\n+          sql(s\"CREATE TABLE $table (i int, j string)\")\n+          // analyze to get initial stats\n+          sql(s\"ANALYZE TABLE $table COMPUTE STATISTICS FOR COLUMNS i, j\")\n+          val fetched1 = checkTableStats(table, hasSizeInBytes = true, expectedRowCounts = Some(0))\n+          assert(fetched1.get.sizeInBytes == 0)\n+          assert(fetched1.get.colStats.size == 2)\n+\n+          // insert into command\n+          sql(s\"INSERT INTO TABLE $table SELECT 1, 'abc'\")\n+          if (autoUpdate) {\n+            val fetched2 = checkTableStats(table, hasSizeInBytes = true, expectedRowCounts = None)\n+            assert(fetched2.get.sizeInBytes > 0)\n+            assert(fetched2.get.colStats.isEmpty)\n+            val statsProp = getStatsProperties(table)\n+            assert(statsProp(STATISTICS_TOTAL_SIZE).toLong == fetched2.get.sizeInBytes)\n+          } else {\n+            assert(getStatsProperties(table).isEmpty)\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  test(\"change stats after load data command\") {\n+    val table = \"change_stats_load_table\"\n+    Seq(false, true).foreach { autoUpdate =>\n+      withSQLConf(SQLConf.AUTO_UPDATE_SIZE.key -> autoUpdate.toString) {\n+        withTable(table) {\n+          sql(s\"CREATE TABLE $table (i INT, j STRING) STORED AS PARQUET\")\n+          // analyze to get initial stats\n+          sql(s\"ANALYZE TABLE $table COMPUTE STATISTICS FOR COLUMNS i, j\")\n+          val fetched1 = checkTableStats(table, hasSizeInBytes = true, expectedRowCounts = Some(0))\n+          assert(fetched1.get.sizeInBytes == 0)\n+          assert(fetched1.get.colStats.size == 2)\n+\n+          withTempDir { loadPath =>\n+            // load data command\n+            val file = new File(loadPath + \"/data\")\n+            val writer = new PrintWriter(file)\n+            writer.write(\"2,xyz\")\n+            writer.close()\n+            sql(s\"LOAD DATA INPATH '${loadPath.toURI.toString}' INTO TABLE $table\")\n+            if (autoUpdate) {\n+              val fetched2 = checkTableStats(table, hasSizeInBytes = true, expectedRowCounts = None)\n+              assert(fetched2.get.sizeInBytes > 0)\n+              assert(fetched2.get.colStats.isEmpty)\n+              val statsProp = getStatsProperties(table)\n+              assert(statsProp(STATISTICS_TOTAL_SIZE).toLong == fetched2.get.sizeInBytes)\n+            } else {\n+              assert(getStatsProperties(table).isEmpty)\n+            }\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  test(\"change stats after add/drop partition command\") {"
  }, {
    "author": {
      "login": "wzhfy"
    },
    "body": "we can't get table properties through hiveClient in the parent class.",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-28T07:27:52Z",
    "diffHunk": "@@ -448,6 +433,145 @@ class StatisticsSuite extends StatisticsCollectionTestBase with TestHiveSingleto\n       \"ALTER TABLE unset_prop_table UNSET TBLPROPERTIES ('prop1')\")\n   }\n \n+  /**\n+   * To see if stats exist, we need to check spark's stats properties instead of catalog\n+   * statistics, because hive would change stats in metastore and thus change catalog statistics.\n+   */\n+  private def getStatsProperties(tableName: String): Map[String, String] = {\n+    val hTable = hiveClient.getTable(spark.sessionState.catalog.getCurrentDatabase, tableName)\n+    hTable.properties.filterKeys(_.startsWith(STATISTICS_PREFIX))\n+  }\n+\n+  test(\"change stats after insert command for hive table\") {\n+    val table = s\"change_stats_insert_hive_table\"\n+    Seq(false, true).foreach { autoUpdate =>\n+      withSQLConf(SQLConf.AUTO_UPDATE_SIZE.key -> autoUpdate.toString) {\n+        withTable(table) {\n+          sql(s\"CREATE TABLE $table (i int, j string)\")\n+          // analyze to get initial stats\n+          sql(s\"ANALYZE TABLE $table COMPUTE STATISTICS FOR COLUMNS i, j\")\n+          val fetched1 = checkTableStats(table, hasSizeInBytes = true, expectedRowCounts = Some(0))\n+          assert(fetched1.get.sizeInBytes == 0)\n+          assert(fetched1.get.colStats.size == 2)\n+\n+          // insert into command\n+          sql(s\"INSERT INTO TABLE $table SELECT 1, 'abc'\")\n+          if (autoUpdate) {\n+            val fetched2 = checkTableStats(table, hasSizeInBytes = true, expectedRowCounts = None)\n+            assert(fetched2.get.sizeInBytes > 0)\n+            assert(fetched2.get.colStats.isEmpty)\n+            val statsProp = getStatsProperties(table)\n+            assert(statsProp(STATISTICS_TOTAL_SIZE).toLong == fetched2.get.sizeInBytes)\n+          } else {\n+            assert(getStatsProperties(table).isEmpty)\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  test(\"change stats after load data command\") {\n+    val table = \"change_stats_load_table\"\n+    Seq(false, true).foreach { autoUpdate =>\n+      withSQLConf(SQLConf.AUTO_UPDATE_SIZE.key -> autoUpdate.toString) {\n+        withTable(table) {\n+          sql(s\"CREATE TABLE $table (i INT, j STRING) STORED AS PARQUET\")\n+          // analyze to get initial stats\n+          sql(s\"ANALYZE TABLE $table COMPUTE STATISTICS FOR COLUMNS i, j\")\n+          val fetched1 = checkTableStats(table, hasSizeInBytes = true, expectedRowCounts = Some(0))\n+          assert(fetched1.get.sizeInBytes == 0)\n+          assert(fetched1.get.colStats.size == 2)\n+\n+          withTempDir { loadPath =>\n+            // load data command\n+            val file = new File(loadPath + \"/data\")\n+            val writer = new PrintWriter(file)\n+            writer.write(\"2,xyz\")\n+            writer.close()\n+            sql(s\"LOAD DATA INPATH '${loadPath.toURI.toString}' INTO TABLE $table\")\n+            if (autoUpdate) {\n+              val fetched2 = checkTableStats(table, hasSizeInBytes = true, expectedRowCounts = None)\n+              assert(fetched2.get.sizeInBytes > 0)\n+              assert(fetched2.get.colStats.isEmpty)\n+              val statsProp = getStatsProperties(table)\n+              assert(statsProp(STATISTICS_TOTAL_SIZE).toLong == fetched2.get.sizeInBytes)\n+            } else {\n+              assert(getStatsProperties(table).isEmpty)\n+            }\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  test(\"change stats after add/drop partition command\") {"
  }],
  "prId": 18334
}]