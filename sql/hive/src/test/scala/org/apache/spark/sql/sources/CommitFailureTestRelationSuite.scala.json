[{
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "This is deleted because it's flaky? Or because it does not work with new APIs?\n",
    "commit": "3e5c7b72c184f0e37d65fad94cf6f21fbd6400da",
    "createdAt": "2016-03-04T18:23:30Z",
    "diffHunk": "@@ -1,104 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.spark.sql.sources\n-\n-import org.apache.hadoop.fs.Path\n-\n-import org.apache.spark.SparkException\n-import org.apache.spark.deploy.SparkHadoopUtil\n-import org.apache.spark.sql.functions._\n-import org.apache.spark.sql.hive.test.TestHiveSingleton\n-import org.apache.spark.sql.test.SQLTestUtils\n-\n-class CommitFailureTestRelationSuite extends SQLTestUtils with TestHiveSingleton  {\n-\n-  // When committing a task, `CommitFailureTestSource` throws an exception for testing purpose.\n-  val dataSourceName: String = classOf[CommitFailureTestSource].getCanonicalName\n-\n-  test(\"SPARK-7684: commitTask() failure should fallback to abortTask()\") {\n-    SimpleTextRelation.failCommitter = true\n-    withTempPath { file =>\n-      // Here we coalesce partition number to 1 to ensure that only a single task is issued.  This\n-      // prevents race condition happened when FileOutputCommitter tries to remove the `_temporary`\n-      // directory while committing/aborting the job.  See SPARK-8513 for more details.\n-      val df = sqlContext.range(0, 10).coalesce(1)\n-      intercept[SparkException] {\n-        df.write.format(dataSourceName).save(file.getCanonicalPath)\n-      }\n-\n-      val fs = new Path(file.getCanonicalPath).getFileSystem(SparkHadoopUtil.get.conf)\n-      assert(!fs.exists(new Path(file.getCanonicalPath, \"_temporary\")))\n-    }\n-  }\n-\n-  test(\"call failure callbacks before close writer - default\") {",
    "line": 49
  }, {
    "author": {
      "login": "marmbrus"
    },
    "body": "This needs to be rewritten to work against the new API. Filed [SPARK-13681](https://issues.apache.org/jira/browse/SPARK-13681)\n",
    "commit": "3e5c7b72c184f0e37d65fad94cf6f21fbd6400da",
    "createdAt": "2016-03-04T19:20:49Z",
    "diffHunk": "@@ -1,104 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.spark.sql.sources\n-\n-import org.apache.hadoop.fs.Path\n-\n-import org.apache.spark.SparkException\n-import org.apache.spark.deploy.SparkHadoopUtil\n-import org.apache.spark.sql.functions._\n-import org.apache.spark.sql.hive.test.TestHiveSingleton\n-import org.apache.spark.sql.test.SQLTestUtils\n-\n-class CommitFailureTestRelationSuite extends SQLTestUtils with TestHiveSingleton  {\n-\n-  // When committing a task, `CommitFailureTestSource` throws an exception for testing purpose.\n-  val dataSourceName: String = classOf[CommitFailureTestSource].getCanonicalName\n-\n-  test(\"SPARK-7684: commitTask() failure should fallback to abortTask()\") {\n-    SimpleTextRelation.failCommitter = true\n-    withTempPath { file =>\n-      // Here we coalesce partition number to 1 to ensure that only a single task is issued.  This\n-      // prevents race condition happened when FileOutputCommitter tries to remove the `_temporary`\n-      // directory while committing/aborting the job.  See SPARK-8513 for more details.\n-      val df = sqlContext.range(0, 10).coalesce(1)\n-      intercept[SparkException] {\n-        df.write.format(dataSourceName).save(file.getCanonicalPath)\n-      }\n-\n-      val fs = new Path(file.getCanonicalPath).getFileSystem(SparkHadoopUtil.get.conf)\n-      assert(!fs.exists(new Path(file.getCanonicalPath, \"_temporary\")))\n-    }\n-  }\n-\n-  test(\"call failure callbacks before close writer - default\") {",
    "line": 49
  }],
  "prId": 11509
}]