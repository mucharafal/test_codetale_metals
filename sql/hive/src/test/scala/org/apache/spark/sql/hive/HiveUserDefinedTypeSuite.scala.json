[{
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Remove this?",
    "commit": "d1ba290f01c843fba6648f97274ec2004d2ddff0",
    "createdAt": "2019-10-29T01:23:53Z",
    "diffHunk": "@@ -18,26 +18,28 @@\n package org.apache.spark.sql.hive\n \n import scala.collection.JavaConverters._\n+import scala.util.Random\n \n import org.apache.hadoop.hive.ql.udf.generic.GenericUDF\n import org.apache.hadoop.hive.serde2.objectinspector.{ObjectInspector, StandardListObjectInspector}\n import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory\n \n-import org.apache.spark.sql.{QueryTest, RandomDataGenerator, Row}\n+import org.apache.spark.sql.{QueryTest, Row}\n import org.apache.spark.sql.catalyst.FunctionIdentifier\n import org.apache.spark.sql.hive.test.TestHiveSingleton\n import org.apache.spark.sql.test.{ExamplePoint, ExamplePointUDT}\n import org.apache.spark.sql.types.StructType\n \n+"
  }],
  "prId": 26287
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I think you can just pick two numbers for `ExamplePoint` but don't bother with randomeness. It doesn't look unlikely this test case matters with the randomeness.",
    "commit": "d1ba290f01c843fba6648f97274ec2004d2ddff0",
    "createdAt": "2019-10-29T01:24:45Z",
    "diffHunk": "@@ -18,26 +18,28 @@\n package org.apache.spark.sql.hive\n \n import scala.collection.JavaConverters._\n+import scala.util.Random\n \n import org.apache.hadoop.hive.ql.udf.generic.GenericUDF\n import org.apache.hadoop.hive.serde2.objectinspector.{ObjectInspector, StandardListObjectInspector}\n import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory\n \n-import org.apache.spark.sql.{QueryTest, RandomDataGenerator, Row}\n+import org.apache.spark.sql.{QueryTest, Row}\n import org.apache.spark.sql.catalyst.FunctionIdentifier\n import org.apache.spark.sql.hive.test.TestHiveSingleton\n import org.apache.spark.sql.test.{ExamplePoint, ExamplePointUDT}\n import org.apache.spark.sql.types.StructType\n \n+\n class HiveUserDefinedTypeSuite extends QueryTest with TestHiveSingleton {\n   private val functionClass = classOf[org.apache.spark.sql.hive.TestUDF].getCanonicalName\n \n   test(\"Support UDT in Hive UDF\") {\n+    val rand = new Random\n     val functionName = \"get_point_x\"\n     try {\n-      val schema = new StructType().add(\"point\", new ExamplePointUDT)\n-      val inputGenerator = RandomDataGenerator.forType(schema, nullable = false).get\n-      val input = inputGenerator.apply().asInstanceOf[Row]\n+      val schema = new StructType().add(\"point\", new ExamplePointUDT, nullable = false)\n+      val input = Row.fromSeq(Seq(new ExamplePoint(rand.nextDouble(), rand.nextDouble())))"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Yea, better to remove the randomness...",
    "commit": "d1ba290f01c843fba6648f97274ec2004d2ddff0",
    "createdAt": "2019-10-29T01:26:25Z",
    "diffHunk": "@@ -18,26 +18,28 @@\n package org.apache.spark.sql.hive\n \n import scala.collection.JavaConverters._\n+import scala.util.Random\n \n import org.apache.hadoop.hive.ql.udf.generic.GenericUDF\n import org.apache.hadoop.hive.serde2.objectinspector.{ObjectInspector, StandardListObjectInspector}\n import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory\n \n-import org.apache.spark.sql.{QueryTest, RandomDataGenerator, Row}\n+import org.apache.spark.sql.{QueryTest, Row}\n import org.apache.spark.sql.catalyst.FunctionIdentifier\n import org.apache.spark.sql.hive.test.TestHiveSingleton\n import org.apache.spark.sql.test.{ExamplePoint, ExamplePointUDT}\n import org.apache.spark.sql.types.StructType\n \n+\n class HiveUserDefinedTypeSuite extends QueryTest with TestHiveSingleton {\n   private val functionClass = classOf[org.apache.spark.sql.hive.TestUDF].getCanonicalName\n \n   test(\"Support UDT in Hive UDF\") {\n+    val rand = new Random\n     val functionName = \"get_point_x\"\n     try {\n-      val schema = new StructType().add(\"point\", new ExamplePointUDT)\n-      val inputGenerator = RandomDataGenerator.forType(schema, nullable = false).get\n-      val input = inputGenerator.apply().asInstanceOf[Row]\n+      val schema = new StructType().add(\"point\", new ExamplePointUDT, nullable = false)\n+      val input = Row.fromSeq(Seq(new ExamplePoint(rand.nextDouble(), rand.nextDouble())))"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Yeah I've just tried to follow origin intention as it was trying to provide randomness. Looks like the test doesn't really deal with randomness. Will just pick any numbers.",
    "commit": "d1ba290f01c843fba6648f97274ec2004d2ddff0",
    "createdAt": "2019-10-29T01:28:21Z",
    "diffHunk": "@@ -18,26 +18,28 @@\n package org.apache.spark.sql.hive\n \n import scala.collection.JavaConverters._\n+import scala.util.Random\n \n import org.apache.hadoop.hive.ql.udf.generic.GenericUDF\n import org.apache.hadoop.hive.serde2.objectinspector.{ObjectInspector, StandardListObjectInspector}\n import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory\n \n-import org.apache.spark.sql.{QueryTest, RandomDataGenerator, Row}\n+import org.apache.spark.sql.{QueryTest, Row}\n import org.apache.spark.sql.catalyst.FunctionIdentifier\n import org.apache.spark.sql.hive.test.TestHiveSingleton\n import org.apache.spark.sql.test.{ExamplePoint, ExamplePointUDT}\n import org.apache.spark.sql.types.StructType\n \n+\n class HiveUserDefinedTypeSuite extends QueryTest with TestHiveSingleton {\n   private val functionClass = classOf[org.apache.spark.sql.hive.TestUDF].getCanonicalName\n \n   test(\"Support UDT in Hive UDF\") {\n+    val rand = new Random\n     val functionName = \"get_point_x\"\n     try {\n-      val schema = new StructType().add(\"point\", new ExamplePointUDT)\n-      val inputGenerator = RandomDataGenerator.forType(schema, nullable = false).get\n-      val input = inputGenerator.apply().asInstanceOf[Row]\n+      val schema = new StructType().add(\"point\", new ExamplePointUDT, nullable = false)\n+      val input = Row.fromSeq(Seq(new ExamplePoint(rand.nextDouble(), rand.nextDouble())))"
  }],
  "prId": 26287
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "We could remove this back while pushing some more changes.",
    "commit": "d1ba290f01c843fba6648f97274ec2004d2ddff0",
    "createdAt": "2019-10-29T01:25:46Z",
    "diffHunk": "@@ -18,26 +18,28 @@\n package org.apache.spark.sql.hive\n \n import scala.collection.JavaConverters._\n+import scala.util.Random\n \n import org.apache.hadoop.hive.ql.udf.generic.GenericUDF\n import org.apache.hadoop.hive.serde2.objectinspector.{ObjectInspector, StandardListObjectInspector}\n import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory\n \n-import org.apache.spark.sql.{QueryTest, RandomDataGenerator, Row}\n+import org.apache.spark.sql.{QueryTest, Row}\n import org.apache.spark.sql.catalyst.FunctionIdentifier\n import org.apache.spark.sql.hive.test.TestHiveSingleton\n import org.apache.spark.sql.test.{ExamplePoint, ExamplePointUDT}\n import org.apache.spark.sql.types.StructType\n \n+"
  }],
  "prId": 26287
}]