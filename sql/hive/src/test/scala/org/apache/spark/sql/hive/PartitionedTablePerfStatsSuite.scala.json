[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "This comment is not accurate. The extra counts are from the save API call in `setupPartitionedHiveTable`. ",
    "commit": "111025f1d39b55db08896c35f46149dcacf9b3b3",
    "createdAt": "2017-01-06T00:08:30Z",
    "diffHunk": "@@ -416,12 +405,8 @@ class PartitionedTablePerfStatsSuite\n           })\n           executorPool.shutdown()\n           executorPool.awaitTermination(30, TimeUnit.SECONDS)\n-          // check the cache hit, we use the metric of METRIC_FILES_DISCOVERED and\n-          // METRIC_PARALLEL_LISTING_JOB_COUNT to check this, while the lock take effect,\n-          // only one thread can really do the build, so the listing job count is 2, the other\n-          // one is cache.load func. Also METRIC_FILES_DISCOVERED is $partition_num * 2",
    "line": 66
  }],
  "prId": 16481
}, {
  "comments": [{
    "author": {
      "login": "ericl"
    },
    "body": "Nice.",
    "commit": "111025f1d39b55db08896c35f46149dcacf9b3b3",
    "createdAt": "2017-01-06T01:17:42Z",
    "diffHunk": "@@ -88,17 +83,12 @@ class PartitionedTablePerfStatsSuite\n   }\n \n   private def setupPartitionedDatasourceTable(\n-      tableName: String, dir: File, scale: Int,\n-      clearMetricsBeforeCreate: Boolean = false, repair: Boolean = true): Unit = {\n+      tableName: String, dir: File, scale: Int, repair: Boolean = true): Unit = {\n     spark.range(scale).selectExpr(\"id as fieldOne\", \"id as partCol1\", \"id as partCol2\").write\n       .partitionBy(\"partCol1\", \"partCol2\")\n       .mode(\"overwrite\")\n       .parquet(dir.getAbsolutePath)\n \n-    if (clearMetricsBeforeCreate) {",
    "line": 12
  }],
  "prId": 16481
}]