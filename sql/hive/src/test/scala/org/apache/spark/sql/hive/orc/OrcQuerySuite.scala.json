[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "nit: `i` => `orcImpl`",
    "commit": "7fac88f3a25122d4445f2491dcfc3ebc34749186",
    "createdAt": "2017-12-05T09:11:10Z",
    "diffHunk": "@@ -621,4 +621,21 @@ class OrcQuerySuite extends QueryTest with BeforeAndAfterAll with OrcTest {\n      makeOrcFile((1 to 10).map(Tuple1.apply), path2)\n      assertResult(20)(read.orc(path1.getCanonicalPath, path2.getCanonicalPath).count())\n    }\n+\n+  test(\"SPARK-20728 Make ORCFileFormat configurable between sql/hive and sql/core\") {\n+    Seq(\n+      (\"native\", classOf[org.apache.spark.sql.execution.datasources.orc.OrcFileFormat]),\n+      (\"hive\", classOf[org.apache.spark.sql.hive.orc.OrcFileFormat])).foreach { case (i, format) =>",
    "line": 17
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "For this one, I will update https://github.com/apache/spark/pull/19882 .\r\nI updated in my local and am running some tests.",
    "commit": "7fac88f3a25122d4445f2491dcfc3ebc34749186",
    "createdAt": "2017-12-06T02:53:01Z",
    "diffHunk": "@@ -621,4 +621,21 @@ class OrcQuerySuite extends QueryTest with BeforeAndAfterAll with OrcTest {\n      makeOrcFile((1 to 10).map(Tuple1.apply), path2)\n      assertResult(20)(read.orc(path1.getCanonicalPath, path2.getCanonicalPath).count())\n    }\n+\n+  test(\"SPARK-20728 Make ORCFileFormat configurable between sql/hive and sql/core\") {\n+    Seq(\n+      (\"native\", classOf[org.apache.spark.sql.execution.datasources.orc.OrcFileFormat]),\n+      (\"hive\", classOf[org.apache.spark.sql.hive.orc.OrcFileFormat])).foreach { case (i, format) =>",
    "line": 17
  }],
  "prId": 19871
}]