[{
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Let's also have a test using both partitioning and bucketing.",
    "commit": "08ec4a7e0d4d25da2e5c40fbf497ce7d067a82c5",
    "createdAt": "2017-01-05T01:27:13Z",
    "diffHunk": "@@ -592,4 +597,77 @@ class HiveDDLCommandSuite extends PlanTest with SQLTestUtils with TestHiveSingle\n     val hiveClient = spark.sharedState.externalCatalog.asInstanceOf[HiveExternalCatalog].client\n     assert(hiveClient.getConf(\"hive.in.test\", \"\") == \"true\")\n   }\n+\n+  test(\"create hive serde table with new syntax - basic\") {\n+    val sql =\n+      \"\"\"\n+        |CREATE TABLE t\n+        |(id int, name string COMMENT 'blabla')\n+        |USING hive\n+        |OPTIONS (format 'parquet', my_prop 1)\n+        |LOCATION '/tmp/file'\n+        |COMMENT 'BLABLA'\n+      \"\"\".stripMargin\n+\n+    val table = analyzeCreateTable(sql)\n+    assert(table.schema == new StructType()\n+      .add(\"id\", \"int\")\n+      .add(\"name\", \"string\", nullable = true, comment = \"blabla\"))\n+    assert(table.provider == Some(DDLUtils.HIVE_PROVIDER))\n+    assert(table.storage.locationUri == Some(\"/tmp/file\"))\n+    assert(table.storage.properties == Map(\"my_prop\" -> \"1\"))\n+    assert(table.comment == Some(\"BLABLA\"))\n+\n+    assert(table.storage.inputFormat ==\n+      Some(\"org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat\"))\n+    assert(table.storage.outputFormat ==\n+      Some(\"org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat\"))\n+    assert(table.storage.serde ==\n+      Some(\"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\"))\n+  }\n+\n+  test(\"create hive serde table with new syntax - with partition and bucketing\") {\n+    val v1 = \"CREATE TABLE t (c1 int, c2 int) USING hive PARTITIONED BY (c2)\"\n+    val table = analyzeCreateTable(v1)\n+    assert(table.schema == new StructType().add(\"c1\", \"int\").add(\"c2\", \"int\"))\n+    assert(table.partitionColumnNames == Seq(\"c2\"))\n+    // check the default formats\n+    assert(table.storage.serde == Some(\"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\"))\n+    assert(table.storage.inputFormat == Some(\"org.apache.hadoop.mapred.TextInputFormat\"))\n+    assert(table.storage.outputFormat ==\n+      Some(\"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\"))\n+\n+    val v2 = \"CREATE TABLE t (c1 int, c2 int) USING hive CLUSTERED BY (c2) INTO 4 BUCKETS\"\n+    val e = intercept[AnalysisException](analyzeCreateTable(v2))\n+    assert(e.message.contains(\"Cannot create bucketed Hive serde table\"))"
  }],
  "prId": 16296
}]