[{
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "How about we format it like \n\n```\nval window =\n  Window\n    .partitionBy($\"category\")\n    .orderBy($\"revenue\".desc)\n    .rangeBetween(-2000L, 1000L)\ncheckAnswer(\n  df.select($\"id\", avg($\"revenue\").over(window).cast(\"int\")),\n  ...\n```\n",
    "commit": "3bfdc491a3c1cad3cf07585388cc448b04bacd98",
    "createdAt": "2015-07-16T22:58:47Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.execution\n+\n+import org.apache.spark.sql.{Row, QueryTest}\n+import org.apache.spark.sql.expressions.Window\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.hive.test.TestHive.implicits._\n+\n+/**\n+ * Window expressions are tested extensively by the following test suites:\n+ * [[org.apache.spark.sql.hive.HiveDataFrameWindowSuite]]\n+ * [[org.apache.spark.sql.hive.execution.HiveWindowFunctionQueryWithoutCodeGenSuite]]\n+ * [[org.apache.spark.sql.hive.execution.HiveWindowFunctionQueryFileWithoutCodeGenSuite]]\n+ * However these suites do not cover all possible (i.e. more exotic) settings. This suite fill\n+ * this gap.\n+ *\n+ * TODO Move this class to the sql/core project when we move to Native Spark UDAFs.\n+ */\n+class WindowSuite extends QueryTest {\n+\n+  test(\"reverse sliding range frame\") {\n+    val df = Seq(\n+      (1, \"Thin\", \"Cell Phone\", 6000),\n+      (2, \"Normal\", \"Tablet\", 1500),\n+      (3, \"Mini\", \"Tablet\", 5500),\n+      (4, \"Ultra thin\", \"Cell Phone\", 5500),\n+      (5, \"Very thin\", \"Cell Phone\", 6000),\n+      (6, \"Big\", \"Tablet\", 2500),\n+      (7, \"Bendable\", \"Cell Phone\", 3000),\n+      (8, \"Foldable\", \"Cell Phone\", 3000),\n+      (9, \"Pro\", \"Tablet\", 4500),\n+      (10, \"Pro2\", \"Tablet\", 6500)).\n+      toDF(\"id\", \"product\", \"category\", \"revenue\")\n+    checkAnswer(\n+      df.select(\n+        $\"id\",\n+        avg($\"revenue\").over(Window.\n+          partitionBy($\"category\").\n+          orderBy($\"revenue\".desc).\n+          rangeBetween(-2000L, 1000L)).\n+          cast(\"int\")),"
  }],
  "prId": 7057
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Actually, this result seems not correct. For example, when we process `(10, \"Pro2\", \"Tablet\", 6500)`. The range of revenue for the frame will be [5500, 8500]. Since the ordering direction is `desc`, `2000 preceding` means `8500` and `1000 following` means `5500`. So, the avg value will be `6000`.\n\nThe result I got with Spark 1.4 and Hive is.\n\n```\n+--+----------+----------+-------+----+\n|id|   product|  category|revenue| avg|\n+--+----------+----------+-------+----+\n|10|      Pro2|    Tablet|   6500|6000|\n| 3|      Mini|    Tablet|   5500|5500|\n| 9|       Pro|    Tablet|   4500|5500|\n| 6|       Big|    Tablet|   2500|2833|\n| 2|    Normal|    Tablet|   1500|2000|\n| 1|      Thin|Cell Phone|   6000|5833|\n| 5| Very thin|Cell Phone|   6000|5833|\n| 4|Ultra thin|Cell Phone|   5500|5833|\n| 7|  Bendable|Cell Phone|   3000|3000|\n| 8|  Foldable|Cell Phone|   3000|3000|\n+--+----------+----------+-------+----+\n```\n",
    "commit": "3bfdc491a3c1cad3cf07585388cc448b04bacd98",
    "createdAt": "2015-07-16T23:15:58Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.execution\n+\n+import org.apache.spark.sql.{Row, QueryTest}\n+import org.apache.spark.sql.expressions.Window\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.hive.test.TestHive.implicits._\n+\n+/**\n+ * Window expressions are tested extensively by the following test suites:\n+ * [[org.apache.spark.sql.hive.HiveDataFrameWindowSuite]]\n+ * [[org.apache.spark.sql.hive.execution.HiveWindowFunctionQueryWithoutCodeGenSuite]]\n+ * [[org.apache.spark.sql.hive.execution.HiveWindowFunctionQueryFileWithoutCodeGenSuite]]\n+ * However these suites do not cover all possible (i.e. more exotic) settings. This suite fill\n+ * this gap.\n+ *\n+ * TODO Move this class to the sql/core project when we move to Native Spark UDAFs.\n+ */\n+class WindowSuite extends QueryTest {\n+\n+  test(\"reverse sliding range frame\") {\n+    val df = Seq(\n+      (1, \"Thin\", \"Cell Phone\", 6000),\n+      (2, \"Normal\", \"Tablet\", 1500),\n+      (3, \"Mini\", \"Tablet\", 5500),\n+      (4, \"Ultra thin\", \"Cell Phone\", 5500),\n+      (5, \"Very thin\", \"Cell Phone\", 6000),\n+      (6, \"Big\", \"Tablet\", 2500),\n+      (7, \"Bendable\", \"Cell Phone\", 3000),\n+      (8, \"Foldable\", \"Cell Phone\", 3000),\n+      (9, \"Pro\", \"Tablet\", 4500),\n+      (10, \"Pro2\", \"Tablet\", 6500)).\n+      toDF(\"id\", \"product\", \"category\", \"revenue\")\n+    checkAnswer(\n+      df.select(\n+        $\"id\",\n+        avg($\"revenue\").over(Window.\n+          partitionBy($\"category\").\n+          orderBy($\"revenue\".desc).\n+          rangeBetween(-2000L, 1000L)).\n+          cast(\"int\")),\n+    Row(1, 5833) :: Row(2, 2000) :: Row(3, 5500) ::\n+      Row(4, 5833) :: Row(5, 5833) :: Row(6, 2000) ::\n+      Row(7, 3000) :: Row(8, 3000) :: Row(9, 4166) ::\n+      Row(10, 5500) :: Nil)"
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "Yeah that was a mistake on my behalf. I didn't realise that offsets should be flipped on when the order is descending (I swapped the high and low offsets).\n\nI pushed a fix.\n",
    "commit": "3bfdc491a3c1cad3cf07585388cc448b04bacd98",
    "createdAt": "2015-07-17T02:19:19Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.execution\n+\n+import org.apache.spark.sql.{Row, QueryTest}\n+import org.apache.spark.sql.expressions.Window\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.hive.test.TestHive.implicits._\n+\n+/**\n+ * Window expressions are tested extensively by the following test suites:\n+ * [[org.apache.spark.sql.hive.HiveDataFrameWindowSuite]]\n+ * [[org.apache.spark.sql.hive.execution.HiveWindowFunctionQueryWithoutCodeGenSuite]]\n+ * [[org.apache.spark.sql.hive.execution.HiveWindowFunctionQueryFileWithoutCodeGenSuite]]\n+ * However these suites do not cover all possible (i.e. more exotic) settings. This suite fill\n+ * this gap.\n+ *\n+ * TODO Move this class to the sql/core project when we move to Native Spark UDAFs.\n+ */\n+class WindowSuite extends QueryTest {\n+\n+  test(\"reverse sliding range frame\") {\n+    val df = Seq(\n+      (1, \"Thin\", \"Cell Phone\", 6000),\n+      (2, \"Normal\", \"Tablet\", 1500),\n+      (3, \"Mini\", \"Tablet\", 5500),\n+      (4, \"Ultra thin\", \"Cell Phone\", 5500),\n+      (5, \"Very thin\", \"Cell Phone\", 6000),\n+      (6, \"Big\", \"Tablet\", 2500),\n+      (7, \"Bendable\", \"Cell Phone\", 3000),\n+      (8, \"Foldable\", \"Cell Phone\", 3000),\n+      (9, \"Pro\", \"Tablet\", 4500),\n+      (10, \"Pro2\", \"Tablet\", 6500)).\n+      toDF(\"id\", \"product\", \"category\", \"revenue\")\n+    checkAnswer(\n+      df.select(\n+        $\"id\",\n+        avg($\"revenue\").over(Window.\n+          partitionBy($\"category\").\n+          orderBy($\"revenue\".desc).\n+          rangeBetween(-2000L, 1000L)).\n+          cast(\"int\")),\n+    Row(1, 5833) :: Row(2, 2000) :: Row(3, 5500) ::\n+      Row(4, 5833) :: Row(5, 5833) :: Row(6, 2000) ::\n+      Row(7, 3000) :: Row(8, 3000) :: Row(9, 4166) ::\n+      Row(10, 5500) :: Nil)"
  }],
  "prId": 7057
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Seems we do not need to create a new suite, right? We can just use `HiveDataFrameWindowSuite`.\n",
    "commit": "3bfdc491a3c1cad3cf07585388cc448b04bacd98",
    "createdAt": "2015-07-19T06:46:54Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.execution\n+\n+import org.apache.spark.sql.{Row, QueryTest}\n+import org.apache.spark.sql.expressions.Window\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.hive.test.TestHive.implicits._\n+\n+/**\n+ * Window expressions are tested extensively by the following test suites:\n+ * [[org.apache.spark.sql.hive.HiveDataFrameWindowSuite]]\n+ * [[org.apache.spark.sql.hive.execution.HiveWindowFunctionQueryWithoutCodeGenSuite]]\n+ * [[org.apache.spark.sql.hive.execution.HiveWindowFunctionQueryFileWithoutCodeGenSuite]]\n+ * However these suites do not cover all possible (i.e. more exotic) settings. This suite fill\n+ * this gap.\n+ *\n+ * TODO Move this class to the sql/core project when we move to Native Spark UDAFs.\n+ */\n+class WindowSuite extends QueryTest {",
    "line": 35
  }],
  "prId": 7057
}]