[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "For this API, previously we will fail with message `Failed to find data source: hive` right? Should we change it?\n",
    "commit": "ef174c1fde3b872a2374d8b47b5a28eeb8a13321",
    "createdAt": "2016-09-15T03:45:00Z",
    "diffHunk": "@@ -1151,6 +1152,56 @@ class MetastoreDataSourcesSuite extends QueryTest with SQLTestUtils with TestHiv\n     }\n   }\n \n+  test(\"save API - format hive\") {",
    "line": 12
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Sure, change all of them to the message `Failed to find data source: hive`\n",
    "commit": "ef174c1fde3b872a2374d8b47b5a28eeb8a13321",
    "createdAt": "2016-09-16T03:36:11Z",
    "diffHunk": "@@ -1151,6 +1152,56 @@ class MetastoreDataSourcesSuite extends QueryTest with SQLTestUtils with TestHiv\n     }\n   }\n \n+  test(\"save API - format hive\") {",
    "line": 12
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "Oh sorry I missed this one, what I was asking is, we should only check the provider in `saveAsTable`, so that the `save` API is totally untouched.\n",
    "commit": "ef174c1fde3b872a2374d8b47b5a28eeb8a13321",
    "createdAt": "2016-09-16T08:02:42Z",
    "diffHunk": "@@ -1151,6 +1152,56 @@ class MetastoreDataSourcesSuite extends QueryTest with SQLTestUtils with TestHiv\n     }\n   }\n \n+  test(\"save API - format hive\") {",
    "line": 12
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "uh... I see. \n",
    "commit": "ef174c1fde3b872a2374d8b47b5a28eeb8a13321",
    "createdAt": "2016-09-17T04:14:22Z",
    "diffHunk": "@@ -1151,6 +1152,56 @@ class MetastoreDataSourcesSuite extends QueryTest with SQLTestUtils with TestHiv\n     }\n   }\n \n+  test(\"save API - format hive\") {",
    "line": 12
  }],
  "prId": 15073
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "after we address https://github.com/apache/spark/pull/15073/files#r79122288, we should follow https://github.com/apache/spark/pull/15073/files#diff-463cb1b0f60d87ada075a820f18e1104R262 to generate error message for this case\n",
    "commit": "ef174c1fde3b872a2374d8b47b5a28eeb8a13321",
    "createdAt": "2016-09-16T08:03:47Z",
    "diffHunk": "@@ -1151,6 +1152,56 @@ class MetastoreDataSourcesSuite extends QueryTest with SQLTestUtils with TestHiv\n     }\n   }\n \n+  test(\"save API - format hive\") {\n+    withTempDir { dir =>\n+      val path = dir.getCanonicalPath\n+      val e = intercept[AnalysisException] {\n+        spark.range(10).write.format(\"hive\").mode(SaveMode.Ignore).save(path)\n+      }.getMessage\n+      assert(e.contains(\"Failed to find data source: hive\"))\n+    }\n+  }\n+\n+  test(\"saveAsTable API - format hive\") {\n+    val tableName = \"tab1\"\n+    withTable(tableName) {\n+      val e = intercept[AnalysisException] {\n+        spark.range(10).write.format(\"hive\").mode(SaveMode.Overwrite).saveAsTable(tableName)\n+      }.getMessage\n+      assert(e.contains(\"Failed to find data source: hive\"))"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Done.\n",
    "commit": "ef174c1fde3b872a2374d8b47b5a28eeb8a13321",
    "createdAt": "2016-09-17T04:17:48Z",
    "diffHunk": "@@ -1151,6 +1152,56 @@ class MetastoreDataSourcesSuite extends QueryTest with SQLTestUtils with TestHiv\n     }\n   }\n \n+  test(\"save API - format hive\") {\n+    withTempDir { dir =>\n+      val path = dir.getCanonicalPath\n+      val e = intercept[AnalysisException] {\n+        spark.range(10).write.format(\"hive\").mode(SaveMode.Ignore).save(path)\n+      }.getMessage\n+      assert(e.contains(\"Failed to find data source: hive\"))\n+    }\n+  }\n+\n+  test(\"saveAsTable API - format hive\") {\n+    val tableName = \"tab1\"\n+    withTable(tableName) {\n+      val e = intercept[AnalysisException] {\n+        spark.range(10).write.format(\"hive\").mode(SaveMode.Overwrite).saveAsTable(tableName)\n+      }.getMessage\n+      assert(e.contains(\"Failed to find data source: hive\"))"
  }],
  "prId": 15073
}]