[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This test seems wrong for that the bug is about. `proxyUgi.getUserName` will return `proxyprincipal@EXAMPLE.COM`, and isn't the bug about it needing to be only `proxyprincipal` to match Hive's behavior?",
    "commit": "ef220efecf44a4b569de9e5a8a8147170692954f",
    "createdAt": "2019-09-16T18:16:43Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.client\n+\n+import java.security.PrivilegedExceptionAction\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.scalatest.{BeforeAndAfterAll, PrivateMethodTester}\n+\n+import org.apache.spark.util.Utils\n+\n+class HiveClientUserNameSuite(version: String)\n+    extends HiveVersionSuite(version) with BeforeAndAfterAll {\n+\n+  test(\"username of HiveClient - no UGI\") {\n+    // Assuming we're not faking System username\n+    assert(System.getProperty(\"user.name\") === getUserNameFromHiveClient)\n+  }\n+\n+  test(\"username of HiveClient - UGI\") {\n+    val ugi = UserGroupInformation.createUserForTesting(\n+      \"fakeprincipal@EXAMPLE.COM\", Array.empty)\n+    ugi.doAs(new PrivilegedExceptionAction[Unit]() {\n+      override def run(): Unit = {\n+        assert(ugi.getUserName === getUserNameFromHiveClient)\n+      }\n+    })\n+  }\n+\n+  test(\"username of HiveClient - Proxy user\") {\n+    val ugi = UserGroupInformation.createUserForTesting(\n+      \"fakeprincipal@EXAMPLE.COM\", Array.empty)\n+    val proxyUgi = UserGroupInformation.createProxyUserForTesting(\n+      \"proxyprincipal@EXAMPLE.COM\", ugi, Array.empty)\n+    proxyUgi.doAs(new PrivilegedExceptionAction[Unit]() {\n+      override def run(): Unit = {\n+        assert(proxyUgi.getUserName === getUserNameFromHiveClient)"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Before SPARK-26929 it was \"proxyprincipal@EXAMPLE.COM\" - as test passed. So setting HADOOP_USER_NAME and proxy user being set provided different results. I couldn't add test for HADOOP_USER_NAME as artificially setting system env. is hard. \r\n\r\nAnyway SPARK-26929 removes the case and makes tests here failing (intended). I'll reflect the change.",
    "commit": "ef220efecf44a4b569de9e5a8a8147170692954f",
    "createdAt": "2019-09-16T19:11:13Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.client\n+\n+import java.security.PrivilegedExceptionAction\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.scalatest.{BeforeAndAfterAll, PrivateMethodTester}\n+\n+import org.apache.spark.util.Utils\n+\n+class HiveClientUserNameSuite(version: String)\n+    extends HiveVersionSuite(version) with BeforeAndAfterAll {\n+\n+  test(\"username of HiveClient - no UGI\") {\n+    // Assuming we're not faking System username\n+    assert(System.getProperty(\"user.name\") === getUserNameFromHiveClient)\n+  }\n+\n+  test(\"username of HiveClient - UGI\") {\n+    val ugi = UserGroupInformation.createUserForTesting(\n+      \"fakeprincipal@EXAMPLE.COM\", Array.empty)\n+    ugi.doAs(new PrivilegedExceptionAction[Unit]() {\n+      override def run(): Unit = {\n+        assert(ugi.getUserName === getUserNameFromHiveClient)\n+      }\n+    })\n+  }\n+\n+  test(\"username of HiveClient - Proxy user\") {\n+    val ugi = UserGroupInformation.createUserForTesting(\n+      \"fakeprincipal@EXAMPLE.COM\", Array.empty)\n+    val proxyUgi = UserGroupInformation.createProxyUserForTesting(\n+      \"proxyprincipal@EXAMPLE.COM\", ugi, Array.empty)\n+    proxyUgi.doAs(new PrivilegedExceptionAction[Unit]() {\n+      override def run(): Unit = {\n+        assert(proxyUgi.getUserName === getUserNameFromHiveClient)"
  }],
  "prId": 25696
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "`BeforeAndAfterAll` is not used",
    "commit": "ef220efecf44a4b569de9e5a8a8147170692954f",
    "createdAt": "2019-09-17T02:25:29Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.client\n+\n+import java.security.PrivilegedExceptionAction\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.scalatest.{BeforeAndAfterAll, PrivateMethodTester}\n+\n+import org.apache.spark.util.Utils\n+\n+class HiveClientUserNameSuite(version: String)\n+    extends HiveVersionSuite(version) with BeforeAndAfterAll {"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Nice finding! Updated.",
    "commit": "ef220efecf44a4b569de9e5a8a8147170692954f",
    "createdAt": "2019-09-17T02:30:45Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.client\n+\n+import java.security.PrivilegedExceptionAction\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.scalatest.{BeforeAndAfterAll, PrivateMethodTester}\n+\n+import org.apache.spark.util.Utils\n+\n+class HiveClientUserNameSuite(version: String)\n+    extends HiveVersionSuite(version) with BeforeAndAfterAll {"
  }],
  "prId": 25696
}]