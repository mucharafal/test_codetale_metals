[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Why not just mix in `SQLTestUtils` then implement/override its `sqlContext` method to return `TestHive`?\n",
    "commit": "d0d8dc7ab2071dc665606f0bad9ad01cdbddc1b1",
    "createdAt": "2015-08-01T17:49:31Z",
    "diffHunk": "@@ -62,6 +62,20 @@ class MyDialect extends DefaultParserDialect\n  * valid, but Hive currently cannot execute it.\n  */\n class SQLQuerySuite extends QueryTest {\n+\n+  /**\n+   * Drops table `tableName` after calling `f`.\n+   * This is the `SQLTestUtils` function without\n+   * an explicit sql context",
    "line": 8
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "there was a reason for that â€”I just forget what. Let me look at it & do it as a mixin\n",
    "commit": "d0d8dc7ab2071dc665606f0bad9ad01cdbddc1b1",
    "createdAt": "2015-09-10T11:01:43Z",
    "diffHunk": "@@ -62,6 +62,20 @@ class MyDialect extends DefaultParserDialect\n  * valid, but Hive currently cannot execute it.\n  */\n class SQLQuerySuite extends QueryTest {\n+\n+  /**\n+   * Drops table `tableName` after calling `f`.\n+   * This is the `SQLTestUtils` function without\n+   * an explicit sql context",
    "line": 8
  }],
  "prId": 7188
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "If you're going to change this code anyways, I guess that you might as well use `SQLTestUtils.withConf` here as well.\n",
    "commit": "d0d8dc7ab2071dc665606f0bad9ad01cdbddc1b1",
    "createdAt": "2015-08-01T17:49:55Z",
    "diffHunk": "@@ -603,37 +630,41 @@ class SQLQuerySuite extends QueryTest {\n     // is not in a valid state (cannot be executed). Because of this bug, the analysis rule of\n     // PreInsertionCasts will actually start to work before ImplicitGenerate and then\n     // generates an invalid query plan.\n-    val rdd = sparkContext.makeRDD((1 to 5).map(i => s\"\"\"{\"a\":[$i, ${i + 1}]}\"\"\"))\n-    read.json(rdd).registerTempTable(\"data\")\n-    val originalConf = convertCTAS\n-    setConf(HiveContext.CONVERT_CTAS, false)\n-\n-    sql(\"CREATE TABLE explodeTest (key bigInt)\")\n-    table(\"explodeTest\").queryExecution.analyzed match {\n-      case metastoreRelation: MetastoreRelation => // OK\n-      case _ =>\n-        fail(\"To correctly test the fix of SPARK-5875, explodeTest should be a MetastoreRelation\")\n-    }\n+    withTable(\"explodeTest\") {\n+      val rdd = sparkContext.makeRDD((1 to 5).map(i => s\"\"\"{\"a\":[$i, ${i + 1}]}\"\"\"))\n+      read.json(rdd).registerTempTable(\"data\")\n+      val originalConf = convertCTAS\n+      setConf(HiveContext.CONVERT_CTAS, false)\n+\n+      sql(\"CREATE TABLE explodeTest (key bigInt)\")\n+      table(\"explodeTest\").queryExecution.analyzed match {\n+        case metastoreRelation: MetastoreRelation => // OK\n+        case _ =>\n+          fail(\"To correctly test the fix of SPARK-5875, explodeTest should be a MetastoreRelation\")\n+      }\n \n-    sql(s\"INSERT OVERWRITE TABLE explodeTest SELECT explode(a) AS val FROM data\")\n-    checkAnswer(\n-      sql(\"SELECT key from explodeTest\"),\n-      (1 to 5).flatMap(i => Row(i) :: Row(i + 1) :: Nil)\n-    )\n+      sql(s\"INSERT OVERWRITE TABLE explodeTest SELECT explode(a) AS val FROM data\")\n+      checkAnswer(\n+        sql(\"SELECT key from explodeTest\"),\n+        (1 to 5).flatMap(i => Row(i) :: Row(i + 1) :: Nil)\n+      )\n \n-    sql(\"DROP TABLE explodeTest\")\n-    dropTempTable(\"data\")\n-    setConf(HiveContext.CONVERT_CTAS, originalConf)\n+      dropTempTable(\"data\")\n+      setConf(HiveContext.CONVERT_CTAS, originalConf)",
    "line": 483
  }],
  "prId": 7188
}]