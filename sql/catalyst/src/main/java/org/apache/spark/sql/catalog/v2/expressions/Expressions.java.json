[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "you need to define what T is here. ",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-03-29T18:40:41Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {",
    "line": 68
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "The Javadoc states: \"the JVM type of the value\". Is that not clear?",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-03-29T20:49:54Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {",
    "line": 68
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "I think @rxin was asking for the mapping between the JVM type and data type. Since this is a public API, the users need to know this mapping.",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-03-29T20:56:14Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {",
    "line": 68
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "`T` is a type parameter though.\r\n\r\n@rxin, are you asking for javadoc for the type parameter, or more documentation on the mapping from java types to data types? I would assume that the relationship between java types and data types is documented elsewhere and would just need a reference from here?",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-03-29T21:33:39Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {",
    "line": 68
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "replied in the other comment.",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-04-02T00:41:07Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {",
    "line": 68
  }],
  "prId": 24117
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "this combo seems pretty weird. i think a better way to do it is to support multiple partition levels, or use a struct to allow arbitrary composition.\r\n",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-04-02T00:40:24Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {\n+    return LogicalExpressions.literal(value);\n+  }\n+\n+  /**\n+   * Create a bucket transform for one or more columns.\n+   * <p>\n+   * This transform represents a logical mapping from a value to a bucket id in [0, numBuckets)\n+   * based on a hash of the value.\n+   *\n+   * @param numBuckets the number of output buckets\n+   * @param columns input columns for the bucket transform\n+   * @return a logical bucket transform\n+   */\n+  public Transform bucket(int numBuckets, String... columns) {\n+    return LogicalExpressions.bucket(numBuckets, columns);\n+  }\n+\n+  /**\n+   * Create an identity transform for a column.\n+   * <p>\n+   * This transform represents a logical mapping from a value to itself.\n+   *\n+   * @param column an input column\n+   * @return a logical identity transform\n+   */\n+  public Transform identity(String column) {\n+    return LogicalExpressions.identity(column);\n+  }\n+\n+  /**\n+   * Create a year transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a year, such as 2018.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical year transform\n+   */\n+  public Transform year(String column) {\n+    return LogicalExpressions.year(column);\n+  }\n+\n+  /**\n+   * Create a month transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a month, such as\n+   * 2018-05.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical month transform\n+   */\n+  public Transform month(String column) {\n+    return LogicalExpressions.month(column);\n+  }\n+\n+  /**\n+   * Create a date transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a date, such as\n+   * 2018-05-13.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical date transform\n+   */\n+  public Transform date(String column) {\n+    return LogicalExpressions.date(column);\n+  }\n+\n+  /**\n+   * Create a date and hour transform for a timestamp column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp to an hour, such as 2018-05-13,\n+   * hour 11.\n+   *\n+   * @param column an input timestamp column\n+   * @return a logical date and hour transform\n+   */\n+  public Transform dateHour(String column) {"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "This is an hour ordinal that doesn't reset at the start of every day. With partition transforms, it makes no sense to partition by both date and hour-of-day. That just makes the implementation more complex.\r\n\r\nI think the confusion here is in the name. What if these were named `years`, `months`, `days`, and `hours` instead?",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-04-02T15:50:45Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {\n+    return LogicalExpressions.literal(value);\n+  }\n+\n+  /**\n+   * Create a bucket transform for one or more columns.\n+   * <p>\n+   * This transform represents a logical mapping from a value to a bucket id in [0, numBuckets)\n+   * based on a hash of the value.\n+   *\n+   * @param numBuckets the number of output buckets\n+   * @param columns input columns for the bucket transform\n+   * @return a logical bucket transform\n+   */\n+  public Transform bucket(int numBuckets, String... columns) {\n+    return LogicalExpressions.bucket(numBuckets, columns);\n+  }\n+\n+  /**\n+   * Create an identity transform for a column.\n+   * <p>\n+   * This transform represents a logical mapping from a value to itself.\n+   *\n+   * @param column an input column\n+   * @return a logical identity transform\n+   */\n+  public Transform identity(String column) {\n+    return LogicalExpressions.identity(column);\n+  }\n+\n+  /**\n+   * Create a year transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a year, such as 2018.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical year transform\n+   */\n+  public Transform year(String column) {\n+    return LogicalExpressions.year(column);\n+  }\n+\n+  /**\n+   * Create a month transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a month, such as\n+   * 2018-05.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical month transform\n+   */\n+  public Transform month(String column) {\n+    return LogicalExpressions.month(column);\n+  }\n+\n+  /**\n+   * Create a date transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a date, such as\n+   * 2018-05-13.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical date transform\n+   */\n+  public Transform date(String column) {\n+    return LogicalExpressions.date(column);\n+  }\n+\n+  /**\n+   * Create a date and hour transform for a timestamp column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp to an hour, such as 2018-05-13,\n+   * hour 11.\n+   *\n+   * @param column an input timestamp column\n+   * @return a logical date and hour transform\n+   */\n+  public Transform dateHour(String column) {"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "I don't know if I was confused earlier or am confused now. Let's say for timestamp 2019-04-02 10:11:12, what should dateHour return?\r\n\r\n",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-04-02T21:49:45Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {\n+    return LogicalExpressions.literal(value);\n+  }\n+\n+  /**\n+   * Create a bucket transform for one or more columns.\n+   * <p>\n+   * This transform represents a logical mapping from a value to a bucket id in [0, numBuckets)\n+   * based on a hash of the value.\n+   *\n+   * @param numBuckets the number of output buckets\n+   * @param columns input columns for the bucket transform\n+   * @return a logical bucket transform\n+   */\n+  public Transform bucket(int numBuckets, String... columns) {\n+    return LogicalExpressions.bucket(numBuckets, columns);\n+  }\n+\n+  /**\n+   * Create an identity transform for a column.\n+   * <p>\n+   * This transform represents a logical mapping from a value to itself.\n+   *\n+   * @param column an input column\n+   * @return a logical identity transform\n+   */\n+  public Transform identity(String column) {\n+    return LogicalExpressions.identity(column);\n+  }\n+\n+  /**\n+   * Create a year transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a year, such as 2018.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical year transform\n+   */\n+  public Transform year(String column) {\n+    return LogicalExpressions.year(column);\n+  }\n+\n+  /**\n+   * Create a month transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a month, such as\n+   * 2018-05.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical month transform\n+   */\n+  public Transform month(String column) {\n+    return LogicalExpressions.month(column);\n+  }\n+\n+  /**\n+   * Create a date transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a date, such as\n+   * 2018-05-13.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical date transform\n+   */\n+  public Transform date(String column) {\n+    return LogicalExpressions.date(column);\n+  }\n+\n+  /**\n+   * Create a date and hour transform for a timestamp column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp to an hour, such as 2018-05-13,\n+   * hour 11.\n+   *\n+   * @param column an input timestamp column\n+   * @return a logical date and hour transform\n+   */\n+  public Transform dateHour(String column) {"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "`dateHour` doesn't return anything, it is not a concrete transformation. Instead, it is the granularity of a time partition. There are many concrete transformations that implement hourly partitioning.\r\n\r\nWhether the storage implementation uses `{date=2019-04-02, hour=10}` or `hour=2019-04-02-10` doesn't matter. Iceberg defines this function as \"Extract a timestamp hour, as hours from 1970-01-01 00:00:00\", and uses an hour ordinal stored as an int.\r\n\r\nThat's why I think this may be more clear if we updated the transform names. `PARTITION BY (category, hours(ts))` is more clear that this is not a concrete transform.\r\n\r\nEventually, we will need to communicate what the concrete implementation of this function is. A table may report it is partitioned by `days(ts)` and Spark will need to produce those values for dataframe partitioning and write optimization. In that case, Spark should use the table's catalog to look up the function.",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-04-03T17:55:25Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {\n+    return LogicalExpressions.literal(value);\n+  }\n+\n+  /**\n+   * Create a bucket transform for one or more columns.\n+   * <p>\n+   * This transform represents a logical mapping from a value to a bucket id in [0, numBuckets)\n+   * based on a hash of the value.\n+   *\n+   * @param numBuckets the number of output buckets\n+   * @param columns input columns for the bucket transform\n+   * @return a logical bucket transform\n+   */\n+  public Transform bucket(int numBuckets, String... columns) {\n+    return LogicalExpressions.bucket(numBuckets, columns);\n+  }\n+\n+  /**\n+   * Create an identity transform for a column.\n+   * <p>\n+   * This transform represents a logical mapping from a value to itself.\n+   *\n+   * @param column an input column\n+   * @return a logical identity transform\n+   */\n+  public Transform identity(String column) {\n+    return LogicalExpressions.identity(column);\n+  }\n+\n+  /**\n+   * Create a year transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a year, such as 2018.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical year transform\n+   */\n+  public Transform year(String column) {\n+    return LogicalExpressions.year(column);\n+  }\n+\n+  /**\n+   * Create a month transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a month, such as\n+   * 2018-05.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical month transform\n+   */\n+  public Transform month(String column) {\n+    return LogicalExpressions.month(column);\n+  }\n+\n+  /**\n+   * Create a date transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a date, such as\n+   * 2018-05-13.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical date transform\n+   */\n+  public Transform date(String column) {\n+    return LogicalExpressions.date(column);\n+  }\n+\n+  /**\n+   * Create a date and hour transform for a timestamp column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp to an hour, such as 2018-05-13,\n+   * hour 11.\n+   *\n+   * @param column an input timestamp column\n+   * @return a logical date and hour transform\n+   */\n+  public Transform dateHour(String column) {"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "We discussed this in the sync last night. There were to conclusions. First, the approach makes sense, and second, the names should be improved. We came up with `perHour`, `hourly`, and `hours`. I think `hours` makes the most sense when reading SQL so I'll update these to use plural names.",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-04-04T16:34:49Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {\n+    return LogicalExpressions.literal(value);\n+  }\n+\n+  /**\n+   * Create a bucket transform for one or more columns.\n+   * <p>\n+   * This transform represents a logical mapping from a value to a bucket id in [0, numBuckets)\n+   * based on a hash of the value.\n+   *\n+   * @param numBuckets the number of output buckets\n+   * @param columns input columns for the bucket transform\n+   * @return a logical bucket transform\n+   */\n+  public Transform bucket(int numBuckets, String... columns) {\n+    return LogicalExpressions.bucket(numBuckets, columns);\n+  }\n+\n+  /**\n+   * Create an identity transform for a column.\n+   * <p>\n+   * This transform represents a logical mapping from a value to itself.\n+   *\n+   * @param column an input column\n+   * @return a logical identity transform\n+   */\n+  public Transform identity(String column) {\n+    return LogicalExpressions.identity(column);\n+  }\n+\n+  /**\n+   * Create a year transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a year, such as 2018.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical year transform\n+   */\n+  public Transform year(String column) {\n+    return LogicalExpressions.year(column);\n+  }\n+\n+  /**\n+   * Create a month transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a month, such as\n+   * 2018-05.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical month transform\n+   */\n+  public Transform month(String column) {\n+    return LogicalExpressions.month(column);\n+  }\n+\n+  /**\n+   * Create a date transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a date, such as\n+   * 2018-05-13.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical date transform\n+   */\n+  public Transform date(String column) {\n+    return LogicalExpressions.date(column);\n+  }\n+\n+  /**\n+   * Create a date and hour transform for a timestamp column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp to an hour, such as 2018-05-13,\n+   * hour 11.\n+   *\n+   * @param column an input timestamp column\n+   * @return a logical date and hour transform\n+   */\n+  public Transform dateHour(String column) {"
  }],
  "prId": 24117
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "what are the timezone semantics for all of these datetime functions?",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-04-02T00:45:20Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {\n+    return LogicalExpressions.literal(value);\n+  }\n+\n+  /**\n+   * Create a bucket transform for one or more columns.\n+   * <p>\n+   * This transform represents a logical mapping from a value to a bucket id in [0, numBuckets)\n+   * based on a hash of the value.\n+   *\n+   * @param numBuckets the number of output buckets\n+   * @param columns input columns for the bucket transform\n+   * @return a logical bucket transform\n+   */\n+  public Transform bucket(int numBuckets, String... columns) {\n+    return LogicalExpressions.bucket(numBuckets, columns);\n+  }\n+\n+  /**\n+   * Create an identity transform for a column.\n+   * <p>\n+   * This transform represents a logical mapping from a value to itself.\n+   *\n+   * @param column an input column\n+   * @return a logical identity transform\n+   */\n+  public Transform identity(String column) {\n+    return LogicalExpressions.identity(column);\n+  }\n+\n+  /**\n+   * Create a year transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a year, such as 2018.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical year transform\n+   */\n+  public Transform year(String column) {\n+    return LogicalExpressions.year(column);\n+  }\n+\n+  /**\n+   * Create a month transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a month, such as\n+   * 2018-05.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical month transform\n+   */\n+  public Transform month(String column) {\n+    return LogicalExpressions.month(column);\n+  }\n+\n+  /**\n+   * Create a date transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a date, such as\n+   * 2018-05-13.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical date transform\n+   */\n+  public Transform date(String column) {"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "If this is used to pass dates to Spark, then values must be the date in UTC. This corresponds to the UTC value passed to the data source when writing. The exact semantics here will be documented when we support passing values to Spark, which is a future extension.\r\n\r\nWhen this is used as a hidden transform and values are not passed to Spark, it doesn't matter. The current use simply tells the data source to break the data into daily partitions (or yearly, or monthly, or hourly). As long as those are regular intervals and the source knows how to prune them, it can use whatever representation it chooses to.",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-04-02T16:24:57Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {\n+    return LogicalExpressions.literal(value);\n+  }\n+\n+  /**\n+   * Create a bucket transform for one or more columns.\n+   * <p>\n+   * This transform represents a logical mapping from a value to a bucket id in [0, numBuckets)\n+   * based on a hash of the value.\n+   *\n+   * @param numBuckets the number of output buckets\n+   * @param columns input columns for the bucket transform\n+   * @return a logical bucket transform\n+   */\n+  public Transform bucket(int numBuckets, String... columns) {\n+    return LogicalExpressions.bucket(numBuckets, columns);\n+  }\n+\n+  /**\n+   * Create an identity transform for a column.\n+   * <p>\n+   * This transform represents a logical mapping from a value to itself.\n+   *\n+   * @param column an input column\n+   * @return a logical identity transform\n+   */\n+  public Transform identity(String column) {\n+    return LogicalExpressions.identity(column);\n+  }\n+\n+  /**\n+   * Create a year transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a year, such as 2018.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical year transform\n+   */\n+  public Transform year(String column) {\n+    return LogicalExpressions.year(column);\n+  }\n+\n+  /**\n+   * Create a month transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a month, such as\n+   * 2018-05.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical month transform\n+   */\n+  public Transform month(String column) {\n+    return LogicalExpressions.month(column);\n+  }\n+\n+  /**\n+   * Create a date transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a date, such as\n+   * 2018-05-13.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical date transform\n+   */\n+  public Transform date(String column) {"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "I should also note the suggestion I made above for using transforms to pass data back to Spark. I think we should pass back `builtin.date` as the transform so that Spark knows the date is in its internal format.",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-04-02T16:28:35Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name, args);\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {\n+    return LogicalExpressions.literal(value);\n+  }\n+\n+  /**\n+   * Create a bucket transform for one or more columns.\n+   * <p>\n+   * This transform represents a logical mapping from a value to a bucket id in [0, numBuckets)\n+   * based on a hash of the value.\n+   *\n+   * @param numBuckets the number of output buckets\n+   * @param columns input columns for the bucket transform\n+   * @return a logical bucket transform\n+   */\n+  public Transform bucket(int numBuckets, String... columns) {\n+    return LogicalExpressions.bucket(numBuckets, columns);\n+  }\n+\n+  /**\n+   * Create an identity transform for a column.\n+   * <p>\n+   * This transform represents a logical mapping from a value to itself.\n+   *\n+   * @param column an input column\n+   * @return a logical identity transform\n+   */\n+  public Transform identity(String column) {\n+    return LogicalExpressions.identity(column);\n+  }\n+\n+  /**\n+   * Create a year transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a year, such as 2018.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical year transform\n+   */\n+  public Transform year(String column) {\n+    return LogicalExpressions.year(column);\n+  }\n+\n+  /**\n+   * Create a month transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a month, such as\n+   * 2018-05.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical month transform\n+   */\n+  public Transform month(String column) {\n+    return LogicalExpressions.month(column);\n+  }\n+\n+  /**\n+   * Create a date transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a date, such as\n+   * 2018-05-13.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical date transform\n+   */\n+  public Transform date(String column) {"
  }],
  "prId": 24117
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "Since the developers can't access the internal `Transform` implementations, and they can only know if a `Transform` instance is a specific one by checking `Transform.name` and arguments, shall we document the name they should match? For example, the year transform uses the name \"years\", the dateHour transform uses the name \"hours\".\r\n\r\nOr, we can just expose these builtin `Transform` implementations.",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-04-04T17:49:18Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+import org.apache.spark.sql.types.DataType;\n+import scala.collection.JavaConverters;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name,\n+        JavaConverters.asScalaBuffer(Arrays.asList(args)).toSeq());\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   * <p>\n+   * The JVM type of the value held by a literal must be the type used by Spark's InternalRow API\n+   * for the literal's {@link DataType SQL data type}.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {\n+    return LogicalExpressions.literal(value);\n+  }\n+\n+  /**\n+   * Create a bucket transform for one or more columns.\n+   * <p>\n+   * This transform represents a logical mapping from a value to a bucket id in [0, numBuckets)\n+   * based on a hash of the value.\n+   *\n+   * @param numBuckets the number of output buckets\n+   * @param columns input columns for the bucket transform\n+   * @return a logical bucket transform\n+   */\n+  public Transform bucket(int numBuckets, String... columns) {\n+    return LogicalExpressions.bucket(numBuckets,\n+        JavaConverters.asScalaBuffer(Arrays.asList(columns)).toSeq());\n+  }\n+\n+  /**\n+   * Create an identity transform for a column.\n+   * <p>\n+   * This transform represents a logical mapping from a value to itself.\n+   *\n+   * @param column an input column\n+   * @return a logical identity transform\n+   */\n+  public Transform identity(String column) {\n+    return LogicalExpressions.identity(column);\n+  }\n+\n+  /**\n+   * Create a year transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a year, such as 2018.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical year transform\n+   */\n+  public Transform year(String column) {"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "I've updated the docs to specifically state the name used for each transform.\r\n\r\nMore documentation for how the TableCatalog API uses transforms is definitely a good idea, but I don't think it should block this commit. We should include it in a DSv2 guide for source authors.",
    "commit": "a4a87ac7582688e883e42980d95126dd05166c64",
    "createdAt": "2019-04-08T16:54:18Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2.expressions;\n+\n+import org.apache.spark.annotation.Experimental;\n+import org.apache.spark.sql.types.DataType;\n+import scala.collection.JavaConverters;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * Helper methods to create logical transforms to pass into Spark.\n+ */\n+@Experimental\n+public class Expressions {\n+  private Expressions() {\n+  }\n+\n+  /**\n+   * Create a logical transform for applying a named transform.\n+   * <p>\n+   * This transform can represent applying any named transform.\n+   *\n+   * @param name the transform name\n+   * @param args expression arguments to the transform\n+   * @return a logical transform\n+   */\n+  public Transform apply(String name, Expression... args) {\n+    return LogicalExpressions.apply(name,\n+        JavaConverters.asScalaBuffer(Arrays.asList(args)).toSeq());\n+  }\n+\n+  /**\n+   * Create a named reference expression for a column.\n+   *\n+   * @param name a column name\n+   * @return a named reference for the column\n+   */\n+  public NamedReference column(String name) {\n+    return LogicalExpressions.reference(name);\n+  }\n+\n+  /**\n+   * Create a literal from a value.\n+   * <p>\n+   * The JVM type of the value held by a literal must be the type used by Spark's InternalRow API\n+   * for the literal's {@link DataType SQL data type}.\n+   *\n+   * @param value a value\n+   * @param <T> the JVM type of the value\n+   * @return a literal expression for the value\n+   */\n+  public <T> Literal<T> literal(T value) {\n+    return LogicalExpressions.literal(value);\n+  }\n+\n+  /**\n+   * Create a bucket transform for one or more columns.\n+   * <p>\n+   * This transform represents a logical mapping from a value to a bucket id in [0, numBuckets)\n+   * based on a hash of the value.\n+   *\n+   * @param numBuckets the number of output buckets\n+   * @param columns input columns for the bucket transform\n+   * @return a logical bucket transform\n+   */\n+  public Transform bucket(int numBuckets, String... columns) {\n+    return LogicalExpressions.bucket(numBuckets,\n+        JavaConverters.asScalaBuffer(Arrays.asList(columns)).toSeq());\n+  }\n+\n+  /**\n+   * Create an identity transform for a column.\n+   * <p>\n+   * This transform represents a logical mapping from a value to itself.\n+   *\n+   * @param column an input column\n+   * @return a logical identity transform\n+   */\n+  public Transform identity(String column) {\n+    return LogicalExpressions.identity(column);\n+  }\n+\n+  /**\n+   * Create a year transform for a timestamp or date column.\n+   * <p>\n+   * This transform represents a logical mapping from a timestamp or date to a year, such as 2018.\n+   *\n+   * @param column an input timestamp or date column\n+   * @return a logical year transform\n+   */\n+  public Transform year(String column) {"
  }],
  "prId": 24117
}]