[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "A UDF doesn't take an entire row as it's input, but some columns. e.g. `SELECT substring(strCol, 3)`.",
    "commit": "21a5f074e3b564a353da28901c8d6cb107ec04c2",
    "createdAt": "2019-05-09T03:27:21Z",
    "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2;\n+\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.types.DataType;\n+\n+/**\n+ * Interface for a function that produces a result value for each input row.\n+ * <p>\n+ * The JVM type of result values produced by this function must be the type used by Spark's\n+ * InternalRow API for the {@link DataType SQL data type} returned by {@link #resultType()}.\n+ *\n+ * @param <R> the JVM type of result values\n+ */\n+public interface ScalarFunction<R> extends BoundFunction {\n+\n+  /**\n+   * Applies the function to an input row to produce a value.\n+   *\n+   * @param input an input row\n+   * @return a result value\n+   */\n+  R produceResult(InternalRow input);",
    "line": 39
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "This assumes that Spark will create an `InternalRow` to pass to the function. That's the easiest way to pass an arbitrary number of arguments that correspond to a struct schema.\r\n\r\nNote that this doesn't need to be expensive. We can build an `InternalRow` that exposes a projection of another and that can be reused for all of the UDF calls.",
    "commit": "21a5f074e3b564a353da28901c8d6cb107ec04c2",
    "createdAt": "2019-05-09T16:12:49Z",
    "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2;\n+\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.types.DataType;\n+\n+/**\n+ * Interface for a function that produces a result value for each input row.\n+ * <p>\n+ * The JVM type of result values produced by this function must be the type used by Spark's\n+ * InternalRow API for the {@link DataType SQL data type} returned by {@link #resultType()}.\n+ *\n+ * @param <R> the JVM type of result values\n+ */\n+public interface ScalarFunction<R> extends BoundFunction {\n+\n+  /**\n+   * Applies the function to an input row to produce a value.\n+   *\n+   * @param input an input row\n+   * @return a result value\n+   */\n+  R produceResult(InternalRow input);",
    "line": 39
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "Think about a UDF that adds 2 ints.\r\n```\r\nval row = InternalRow(i, j)\r\nudf.call(row)\r\n// inside udf.call\r\nreturn row.getInt(0) + row.getInt(1)\r\n```\r\nis much slower than\r\n```\r\nudf.call(i, j)\r\n// inside udf.call\r\nreturn i + j\r\n```\r\n\r\nWe need to think about the tradeoffs and pick between perf and ease-of-use.",
    "commit": "21a5f074e3b564a353da28901c8d6cb107ec04c2",
    "createdAt": "2019-05-09T18:15:39Z",
    "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2;\n+\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.types.DataType;\n+\n+/**\n+ * Interface for a function that produces a result value for each input row.\n+ * <p>\n+ * The JVM type of result values produced by this function must be the type used by Spark's\n+ * InternalRow API for the {@link DataType SQL data type} returned by {@link #resultType()}.\n+ *\n+ * @param <R> the JVM type of result values\n+ */\n+public interface ScalarFunction<R> extends BoundFunction {\n+\n+  /**\n+   * Applies the function to an input row to produce a value.\n+   *\n+   * @param input an input row\n+   * @return a result value\n+   */\n+  R produceResult(InternalRow input);",
    "line": 39
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "I don't think that's a relevant comparison. Clearly, it's a bad idea to copy data into a new `InternalRow` to pass it into a UDF. But `InternalRow` is an interface so we can change how it works. We have an `InternalRow` that exposes data from a `ColumnarBatch` and one that joins partition values, we could similarly have an `InternalRow` that wraps another `InternalRow` for this access.\r\n\r\n```scala\r\nclass ProjectingRow(wrappedPositions: Array[Int]) extends InternalRow {\r\n  var wrapped = null\r\n  def set(row: InternalRow): Unit = this.wrapped = row\r\n  def getInt(pos: Int): Int = wrapped.getInt(wrappedPositions(pos))\r\n  ...\r\n}\r\n```\r\n\r\nThen each UDF call becomes:\r\n```java\r\nudfRow.set(inputRow)\r\nval result = udf.call(udfRow)\r\n```\r\n\r\nAnd `call` could be implemented as you'd expect:\r\n\r\n```java\r\npublic int call(InternalRow row) {\r\n  return row.getInt(0) + row.getInt(1)\r\n}\r\n```\r\n\r\nI think that the overhead of `set` is much better than using reflection or object inspectors like Hive.",
    "commit": "21a5f074e3b564a353da28901c8d6cb107ec04c2",
    "createdAt": "2019-05-13T19:53:40Z",
    "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2;\n+\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.types.DataType;\n+\n+/**\n+ * Interface for a function that produces a result value for each input row.\n+ * <p>\n+ * The JVM type of result values produced by this function must be the type used by Spark's\n+ * InternalRow API for the {@link DataType SQL data type} returned by {@link #resultType()}.\n+ *\n+ * @param <R> the JVM type of result values\n+ */\n+public interface ScalarFunction<R> extends BoundFunction {\n+\n+  /**\n+   * Applies the function to an input row to produce a value.\n+   *\n+   * @param input an input row\n+   * @return a result value\n+   */\n+  R produceResult(InternalRow input);",
    "line": 39
  }],
  "prId": 24559
}]