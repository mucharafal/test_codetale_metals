[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This has a good intention, but there was an argument, too. According to `SPARK-16813 Remove private[sql] and private[spark] from catalyst package`, shall we not to use `private[sql]`?\r\ncc @HyukjinKwon ",
    "commit": "4169a8760d6e358914071460c91f381d4ae89b0b",
    "createdAt": "2019-06-05T22:25:50Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2\n+\n+import java.util\n+import java.util.Collections\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.catalog.v2.TableChange.{AddColumn, DeleteColumn, RemoveProperty, RenameColumn, SetProperty, UpdateColumnComment, UpdateColumnType}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+private[sql] object CatalogV2Util {"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "Sounds reasonable to me. Where should I move this to so that it doesn't show up in the API?",
    "commit": "4169a8760d6e358914071460c91f381d4ae89b0b",
    "createdAt": "2019-06-05T22:30:59Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2\n+\n+import java.util\n+import java.util.Collections\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.catalog.v2.TableChange.{AddColumn, DeleteColumn, RemoveProperty, RenameColumn, SetProperty, UpdateColumnComment, UpdateColumnType}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+private[sql] object CatalogV2Util {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "For that, shall we create `o.a.s.sql.catalog.v2.util` package and add that package to `ignoreUndocumentedPackages` of `SparkBuild.scala`?\r\n\r\nBTW, this is a simple move from `object TestTableCatalog` (in `test` source). Could you make a separate PR for this, please?",
    "commit": "4169a8760d6e358914071460c91f381d4ae89b0b",
    "createdAt": "2019-06-05T23:05:22Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2\n+\n+import java.util\n+import java.util.Collections\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.catalog.v2.TableChange.{AddColumn, DeleteColumn, RemoveProperty, RenameColumn, SetProperty, UpdateColumnComment, UpdateColumnType}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+private[sql] object CatalogV2Util {"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "In the past, I've been told that PRs that add utilities without using them are discouraged. Is this a different case? I'm happy to do it either here or in a different PR, but this conflicts with what I've been told by other committers.",
    "commit": "4169a8760d6e358914071460c91f381d4ae89b0b",
    "createdAt": "2019-06-05T23:32:23Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2\n+\n+import java.util\n+import java.util.Collections\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.catalog.v2.TableChange.{AddColumn, DeleteColumn, RemoveProperty, RenameColumn, SetProperty, UpdateColumnComment, UpdateColumnType}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+private[sql] object CatalogV2Util {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "First of all, refactoring from `TestTableCatalog` to `CatalogV2Util` is not the case you mentioned. I believe this one should be done before this.\r\n\r\nFor `transformer`, yes, I agree. It's on the edge. But, Apache Spark community also does the similar thing to split big PRs.",
    "commit": "4169a8760d6e358914071460c91f381d4ae89b0b",
    "createdAt": "2019-06-05T23:36:45Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2\n+\n+import java.util\n+import java.util.Collections\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.catalog.v2.TableChange.{AddColumn, DeleteColumn, RemoveProperty, RenameColumn, SetProperty, UpdateColumnComment, UpdateColumnType}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+private[sql] object CatalogV2Util {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Since I understand your concerns, cc @cloud-fan , @gatorsmile , @jiangxb1987 , @rxin .",
    "commit": "4169a8760d6e358914071460c91f381d4ae89b0b",
    "createdAt": "2019-06-05T23:38:27Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2\n+\n+import java.util\n+import java.util.Collections\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.catalog.v2.TableChange.{AddColumn, DeleteColumn, RemoveProperty, RenameColumn, SetProperty, UpdateColumnComment, UpdateColumnType}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+private[sql] object CatalogV2Util {"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "Opened https://github.com/apache/spark/pull/24813",
    "commit": "4169a8760d6e358914071460c91f381d4ae89b0b",
    "createdAt": "2019-06-05T23:58:47Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2\n+\n+import java.util\n+import java.util.Collections\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.catalog.v2.TableChange.{AddColumn, DeleteColumn, RemoveProperty, RenameColumn, SetProperty, UpdateColumnComment, UpdateColumnType}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+private[sql] object CatalogV2Util {"
  }],
  "prId": 24768
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Can we use `fieldNames` instead of `path`?",
    "commit": "4169a8760d6e358914071460c91f381d4ae89b0b",
    "createdAt": "2019-06-05T22:48:58Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2\n+\n+import java.util\n+import java.util.Collections\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.catalog.v2.TableChange.{AddColumn, DeleteColumn, RemoveProperty, RenameColumn, SetProperty, UpdateColumnComment, UpdateColumnType}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+private[sql] object CatalogV2Util {\n+  /**\n+   * Apply properties changes to a map and return the result.\n+   */\n+  def applyPropertiesChanges(\n+      properties: Map[String, String],\n+      changes: Seq[TableChange]): Map[String, String] = {\n+    applyPropertiesChanges(properties.asJava, changes).asScala.toMap\n+  }\n+\n+  /**\n+   * Apply properties changes to a Java map and return the result.\n+   */\n+  def applyPropertiesChanges(\n+      properties: util.Map[String, String],\n+      changes: Seq[TableChange]): util.Map[String, String] = {\n+    val newProperties = new util.HashMap[String, String](properties)\n+\n+    changes.foreach {\n+      case set: SetProperty =>\n+        newProperties.put(set.property, set.value)\n+\n+      case unset: RemoveProperty =>\n+        newProperties.remove(unset.property)\n+\n+      case _ =>\n+      // ignore non-property changes\n+    }\n+\n+    Collections.unmodifiableMap(newProperties)\n+  }\n+\n+  /**\n+   * Apply schema changes to a schema and return the result.\n+   */\n+  def applySchemaChanges(schema: StructType, changes: Seq[TableChange]): StructType = {\n+    changes.foldLeft(schema) { (schema, change) =>\n+      change match {\n+        case add: AddColumn =>\n+          add.fieldNames match {\n+            case Array(name) =>\n+              val newField = StructField(name, add.dataType, nullable = add.isNullable)\n+              Option(add.comment) match {\n+                case Some(comment) =>\n+                  schema.add(newField.withComment(comment))\n+                case _ =>\n+                  schema.add(newField)\n+              }\n+\n+            case names =>\n+              replace(schema, names.init, parent => parent.dataType match {\n+                case parentType: StructType =>\n+                  val field = StructField(names.last, add.dataType, nullable = add.isNullable)\n+                  val newParentType = Option(add.comment) match {\n+                    case Some(comment) =>\n+                      parentType.add(field.withComment(comment))\n+                    case None =>\n+                      parentType.add(field)\n+                  }\n+\n+                  Some(StructField(parent.name, newParentType, parent.nullable, parent.metadata))\n+\n+                case _ =>\n+                  throw new IllegalArgumentException(s\"Not a struct: ${names.init.last}\")\n+              })\n+          }\n+\n+        case rename: RenameColumn =>\n+          replace(schema, rename.fieldNames, field =>\n+            Some(StructField(rename.newName, field.dataType, field.nullable, field.metadata)))\n+\n+        case update: UpdateColumnType =>\n+          replace(schema, update.fieldNames, field => {\n+            if (!update.isNullable && field.nullable) {\n+              throw new IllegalArgumentException(\n+                s\"Cannot change optional column to required: $field.name\")\n+            }\n+            Some(StructField(field.name, update.newDataType, update.isNullable, field.metadata))\n+          })\n+\n+        case update: UpdateColumnComment =>\n+          replace(schema, update.fieldNames, field =>\n+            Some(field.withComment(update.newComment)))\n+\n+        case delete: DeleteColumn =>\n+          replace(schema, delete.fieldNames, _ => None)\n+\n+        case _ =>\n+          // ignore non-schema changes\n+          schema\n+      }\n+    }\n+  }\n+\n+  private def replace(\n+      struct: StructType,\n+      path: Seq[String],"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "I made this change in the other PR.",
    "commit": "4169a8760d6e358914071460c91f381d4ae89b0b",
    "createdAt": "2019-06-06T00:02:24Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalog.v2\n+\n+import java.util\n+import java.util.Collections\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.sql.catalog.v2.TableChange.{AddColumn, DeleteColumn, RemoveProperty, RenameColumn, SetProperty, UpdateColumnComment, UpdateColumnType}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+private[sql] object CatalogV2Util {\n+  /**\n+   * Apply properties changes to a map and return the result.\n+   */\n+  def applyPropertiesChanges(\n+      properties: Map[String, String],\n+      changes: Seq[TableChange]): Map[String, String] = {\n+    applyPropertiesChanges(properties.asJava, changes).asScala.toMap\n+  }\n+\n+  /**\n+   * Apply properties changes to a Java map and return the result.\n+   */\n+  def applyPropertiesChanges(\n+      properties: util.Map[String, String],\n+      changes: Seq[TableChange]): util.Map[String, String] = {\n+    val newProperties = new util.HashMap[String, String](properties)\n+\n+    changes.foreach {\n+      case set: SetProperty =>\n+        newProperties.put(set.property, set.value)\n+\n+      case unset: RemoveProperty =>\n+        newProperties.remove(unset.property)\n+\n+      case _ =>\n+      // ignore non-property changes\n+    }\n+\n+    Collections.unmodifiableMap(newProperties)\n+  }\n+\n+  /**\n+   * Apply schema changes to a schema and return the result.\n+   */\n+  def applySchemaChanges(schema: StructType, changes: Seq[TableChange]): StructType = {\n+    changes.foldLeft(schema) { (schema, change) =>\n+      change match {\n+        case add: AddColumn =>\n+          add.fieldNames match {\n+            case Array(name) =>\n+              val newField = StructField(name, add.dataType, nullable = add.isNullable)\n+              Option(add.comment) match {\n+                case Some(comment) =>\n+                  schema.add(newField.withComment(comment))\n+                case _ =>\n+                  schema.add(newField)\n+              }\n+\n+            case names =>\n+              replace(schema, names.init, parent => parent.dataType match {\n+                case parentType: StructType =>\n+                  val field = StructField(names.last, add.dataType, nullable = add.isNullable)\n+                  val newParentType = Option(add.comment) match {\n+                    case Some(comment) =>\n+                      parentType.add(field.withComment(comment))\n+                    case None =>\n+                      parentType.add(field)\n+                  }\n+\n+                  Some(StructField(parent.name, newParentType, parent.nullable, parent.metadata))\n+\n+                case _ =>\n+                  throw new IllegalArgumentException(s\"Not a struct: ${names.init.last}\")\n+              })\n+          }\n+\n+        case rename: RenameColumn =>\n+          replace(schema, rename.fieldNames, field =>\n+            Some(StructField(rename.newName, field.dataType, field.nullable, field.metadata)))\n+\n+        case update: UpdateColumnType =>\n+          replace(schema, update.fieldNames, field => {\n+            if (!update.isNullable && field.nullable) {\n+              throw new IllegalArgumentException(\n+                s\"Cannot change optional column to required: $field.name\")\n+            }\n+            Some(StructField(field.name, update.newDataType, update.isNullable, field.metadata))\n+          })\n+\n+        case update: UpdateColumnComment =>\n+          replace(schema, update.fieldNames, field =>\n+            Some(field.withComment(update.newComment)))\n+\n+        case delete: DeleteColumn =>\n+          replace(schema, delete.fieldNames, _ => None)\n+\n+        case _ =>\n+          // ignore non-schema changes\n+          schema\n+      }\n+    }\n+  }\n+\n+  private def replace(\n+      struct: StructType,\n+      path: Seq[String],"
  }],
  "prId": 24768
}]