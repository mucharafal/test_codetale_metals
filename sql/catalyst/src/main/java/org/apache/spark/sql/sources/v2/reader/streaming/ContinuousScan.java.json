[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "Hi @jose-torres , can you double-check if my explanation is correct?",
    "commit": "a7d0c55677d519843086f54ef9502e5482ea2765",
    "createdAt": "2019-08-06T12:27:27Z",
    "diffHunk": "@@ -19,21 +19,36 @@\n \n import org.apache.spark.annotation.Evolving;\n import org.apache.spark.sql.sources.v2.reader.InputPartition;\n-import org.apache.spark.sql.sources.v2.reader.Scan;\n \n /**\n- * A {@link SparkDataStream} for streaming queries with continuous mode.\n+ * An interface that defines how to scan the data from data source for continuous streaming\n+ * processing.\n+ *\n+ * The scanning procedure is:",
    "line": 11
  }],
  "prId": 25180
}]