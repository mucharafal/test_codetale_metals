[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "High-level question: why not wrap / re-use BytesToBytesMap instead of duplicating most of its code here?\n",
    "commit": "e6516838b46bff38a7bc07e2ee9e82a235bbf29e",
    "createdAt": "2015-07-15T17:51:13Z",
    "diffHunk": "@@ -0,0 +1,516 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution;\n+\n+import java.util.Comparator;\n+import java.util.Iterator;\n+\n+import scala.math.Ordering;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRowLocation;\n+import org.apache.spark.sql.catalyst.util.ObjectPool;\n+import org.apache.spark.unsafe.array.ByteArrayMethods;\n+import org.apache.spark.unsafe.bitset.BitSet;\n+import org.apache.spark.unsafe.hash.Murmur3_x86_32;\n+import org.apache.spark.unsafe.map.HashMapGrowthStrategy;\n+import org.apache.spark.unsafe.memory.MemoryBlock;\n+import org.apache.spark.unsafe.memory.MemoryLocation;\n+import org.apache.spark.unsafe.memory.TaskMemoryManager;\n+import org.apache.spark.util.collection.SortDataFormat;\n+import org.apache.spark.util.collection.Sorter;\n+\n+/**\n+ * An append-only hash map where keys and values are contiguous regions of bytes.\n+ * <p>\n+ * This is backed by a power-of-2-sized hash table, using quadratic probing with triangular numbers,\n+ * which is guaranteed to exhaust the space.\n+ * <p>\n+ * The map can support up to 2^29 keys. If the key cardinality is higher than this, you should\n+ * probably be using sorting instead of hashing for better cache locality.\n+ * <p>\n+ * This class is not thread safe.\n+ */\n+public class UnsafeAppendOnlyMap {",
    "line": 52
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "What are the key differences between this class and BytesToBytesMap?\n",
    "commit": "e6516838b46bff38a7bc07e2ee9e82a235bbf29e",
    "createdAt": "2015-07-15T17:51:27Z",
    "diffHunk": "@@ -0,0 +1,516 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution;\n+\n+import java.util.Comparator;\n+import java.util.Iterator;\n+\n+import scala.math.Ordering;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRowLocation;\n+import org.apache.spark.sql.catalyst.util.ObjectPool;\n+import org.apache.spark.unsafe.array.ByteArrayMethods;\n+import org.apache.spark.unsafe.bitset.BitSet;\n+import org.apache.spark.unsafe.hash.Murmur3_x86_32;\n+import org.apache.spark.unsafe.map.HashMapGrowthStrategy;\n+import org.apache.spark.unsafe.memory.MemoryBlock;\n+import org.apache.spark.unsafe.memory.MemoryLocation;\n+import org.apache.spark.unsafe.memory.TaskMemoryManager;\n+import org.apache.spark.util.collection.SortDataFormat;\n+import org.apache.spark.util.collection.Sorter;\n+\n+/**\n+ * An append-only hash map where keys and values are contiguous regions of bytes.\n+ * <p>\n+ * This is backed by a power-of-2-sized hash table, using quadratic probing with triangular numbers,\n+ * which is guaranteed to exhaust the space.\n+ * <p>\n+ * The map can support up to 2^29 keys. If the key cardinality is higher than this, you should\n+ * probably be using sorting instead of hashing for better cache locality.\n+ * <p>\n+ * This class is not thread safe.\n+ */\n+public class UnsafeAppendOnlyMap {",
    "line": 52
  }, {
    "author": {
      "login": "lianhuiwang"
    },
    "body": "because BytesToBytesMap has more complex, it did memory allocation's works.\nit's differences between their are UnsafeAppendOnlyMap split memory allocation and RowLocation from BytesToBytesMap.\nif based on BytesToBytesMap, UnsafeFixedWidthAggregationMap should change many. if it is necessary, i can did re-use BytesToBytesMap but it need to change some code of UnsafeFixedWidthAggregationMap.\nmoreover, i think UnsafeExternalAggregation could replace with UnsafeFixedWidthAggregationMap.\n",
    "commit": "e6516838b46bff38a7bc07e2ee9e82a235bbf29e",
    "createdAt": "2015-07-16T01:27:06Z",
    "diffHunk": "@@ -0,0 +1,516 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution;\n+\n+import java.util.Comparator;\n+import java.util.Iterator;\n+\n+import scala.math.Ordering;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRowLocation;\n+import org.apache.spark.sql.catalyst.util.ObjectPool;\n+import org.apache.spark.unsafe.array.ByteArrayMethods;\n+import org.apache.spark.unsafe.bitset.BitSet;\n+import org.apache.spark.unsafe.hash.Murmur3_x86_32;\n+import org.apache.spark.unsafe.map.HashMapGrowthStrategy;\n+import org.apache.spark.unsafe.memory.MemoryBlock;\n+import org.apache.spark.unsafe.memory.MemoryLocation;\n+import org.apache.spark.unsafe.memory.TaskMemoryManager;\n+import org.apache.spark.util.collection.SortDataFormat;\n+import org.apache.spark.util.collection.Sorter;\n+\n+/**\n+ * An append-only hash map where keys and values are contiguous regions of bytes.\n+ * <p>\n+ * This is backed by a power-of-2-sized hash table, using quadratic probing with triangular numbers,\n+ * which is guaranteed to exhaust the space.\n+ * <p>\n+ * The map can support up to 2^29 keys. If the key cardinality is higher than this, you should\n+ * probably be using sorting instead of hashing for better cache locality.\n+ * <p>\n+ * This class is not thread safe.\n+ */\n+public class UnsafeAppendOnlyMap {",
    "line": 52
  }, {
    "author": {
      "login": "lianhuiwang"
    },
    "body": "another point is we can remove UnsafeFixedWidthAggregationMap and BytesToBytesMap now, and just use UnsafeExternalAggregation. when it donot support Object schema, it do not did spills that is same as UnsafeFixedWidthAggregationMap.\ni think it is better than do some changes on BytesToBytesMap and UnsafeFixedWidthAggregationMap. if it is ok, i think i can did.\n@davies i think you have some opinions about it. thanks.\n",
    "commit": "e6516838b46bff38a7bc07e2ee9e82a235bbf29e",
    "createdAt": "2015-07-16T01:36:18Z",
    "diffHunk": "@@ -0,0 +1,516 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution;\n+\n+import java.util.Comparator;\n+import java.util.Iterator;\n+\n+import scala.math.Ordering;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRowLocation;\n+import org.apache.spark.sql.catalyst.util.ObjectPool;\n+import org.apache.spark.unsafe.array.ByteArrayMethods;\n+import org.apache.spark.unsafe.bitset.BitSet;\n+import org.apache.spark.unsafe.hash.Murmur3_x86_32;\n+import org.apache.spark.unsafe.map.HashMapGrowthStrategy;\n+import org.apache.spark.unsafe.memory.MemoryBlock;\n+import org.apache.spark.unsafe.memory.MemoryLocation;\n+import org.apache.spark.unsafe.memory.TaskMemoryManager;\n+import org.apache.spark.util.collection.SortDataFormat;\n+import org.apache.spark.util.collection.Sorter;\n+\n+/**\n+ * An append-only hash map where keys and values are contiguous regions of bytes.\n+ * <p>\n+ * This is backed by a power-of-2-sized hash table, using quadratic probing with triangular numbers,\n+ * which is guaranteed to exhaust the space.\n+ * <p>\n+ * The map can support up to 2^29 keys. If the key cardinality is higher than this, you should\n+ * probably be using sorting instead of hashing for better cache locality.\n+ * <p>\n+ * This class is not thread safe.\n+ */\n+public class UnsafeAppendOnlyMap {",
    "line": 52
  }],
  "prId": 7423
}]