[{
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "This needs to be more clear. What is the key of `sets`? I think it is clear what the expression and filters are used for, but all behavior should be clearly stated as requirements, not implied.",
    "commit": "3732a18e3012e0dccc28663f9a37ca570e8b13d1",
    "createdAt": "2019-09-04T21:08:16Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import java.util.Map;\n+\n+import org.apache.spark.sql.catalog.v2.expressions.Expression;\n+import org.apache.spark.sql.sources.Filter;\n+\n+/**\n+ * A mix-in interface for {@link Table} update support. Data sources can implement this\n+ * interface to provide the ability to update data that matches filter expressions\n+ * with the given sets.\n+ */\n+public interface SupportsUpdate {\n+\n+  /**\n+   * Update data that matches filter expressions with the given sets for a data source table.\n+   * <p>\n+   * Rows will be updated with the given values iff all of the filter expressions match.\n+   * That is, the expressions must be interpreted as a set of filters that are ANDed together.\n+   * <p>\n+   * Implementations may reject a update operation if the update isn't possible without significant\n+   * effort or it cannot deal with the sets expression. For example, partitioned data sources may\n+   * reject updates that do not filter by partition columns because the filter may require\n+   * rewriting files. The update may also be rejected if the update requires a complex computation\n+   * that the data source does not support.\n+   * To reject a delete implementations should throw {@link IllegalArgumentException} with a clear\n+   * error message that identifies which expression was rejected.\n+   *\n+   * @param sets the updated values for fields. The value can be a literal, or a simple expression\n+   *             like {{{ originalValue + 1 }}}.\n+   * @param filters filter expressions, used to select rows to delete when all expressions match\n+   * @throws IllegalArgumentException If the update is rejected due to required effort\n+   *                                  or unsupported update expression\n+   */\n+  void updateWhere(Map<String, Expression> sets, Filter[] filters);"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Thank you @rdblue . I'll add more doc to state it clearly.",
    "commit": "3732a18e3012e0dccc28663f9a37ca570e8b13d1",
    "createdAt": "2019-09-05T02:45:09Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import java.util.Map;\n+\n+import org.apache.spark.sql.catalog.v2.expressions.Expression;\n+import org.apache.spark.sql.sources.Filter;\n+\n+/**\n+ * A mix-in interface for {@link Table} update support. Data sources can implement this\n+ * interface to provide the ability to update data that matches filter expressions\n+ * with the given sets.\n+ */\n+public interface SupportsUpdate {\n+\n+  /**\n+   * Update data that matches filter expressions with the given sets for a data source table.\n+   * <p>\n+   * Rows will be updated with the given values iff all of the filter expressions match.\n+   * That is, the expressions must be interpreted as a set of filters that are ANDed together.\n+   * <p>\n+   * Implementations may reject a update operation if the update isn't possible without significant\n+   * effort or it cannot deal with the sets expression. For example, partitioned data sources may\n+   * reject updates that do not filter by partition columns because the filter may require\n+   * rewriting files. The update may also be rejected if the update requires a complex computation\n+   * that the data source does not support.\n+   * To reject a delete implementations should throw {@link IllegalArgumentException} with a clear\n+   * error message that identifies which expression was rejected.\n+   *\n+   * @param sets the updated values for fields. The value can be a literal, or a simple expression\n+   *             like {{{ originalValue + 1 }}}.\n+   * @param filters filter expressions, used to select rows to delete when all expressions match\n+   * @throws IllegalArgumentException If the update is rejected due to required effort\n+   *                                  or unsupported update expression\n+   */\n+  void updateWhere(Map<String, Expression> sets, Filter[] filters);"
  }],
  "prId": 25626
}, {
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "This should be marked experimental.",
    "commit": "3732a18e3012e0dccc28663f9a37ca570e8b13d1",
    "createdAt": "2019-09-04T21:20:56Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import java.util.Map;\n+\n+import org.apache.spark.sql.catalog.v2.expressions.Expression;\n+import org.apache.spark.sql.sources.Filter;\n+\n+/**\n+ * A mix-in interface for {@link Table} update support. Data sources can implement this\n+ * interface to provide the ability to update data that matches filter expressions\n+ * with the given sets.\n+ */\n+public interface SupportsUpdate {"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Done.",
    "commit": "3732a18e3012e0dccc28663f9a37ca570e8b13d1",
    "createdAt": "2019-09-05T03:24:37Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import java.util.Map;\n+\n+import org.apache.spark.sql.catalog.v2.expressions.Expression;\n+import org.apache.spark.sql.sources.Filter;\n+\n+/**\n+ * A mix-in interface for {@link Table} update support. Data sources can implement this\n+ * interface to provide the ability to update data that matches filter expressions\n+ * with the given sets.\n+ */\n+public interface SupportsUpdate {"
  }],
  "prId": 25626
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "`select rows to delete` -> `select rows to update`",
    "commit": "3732a18e3012e0dccc28663f9a37ca570e8b13d1",
    "createdAt": "2019-09-11T07:27:28Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import java.util.Map;\n+\n+import org.apache.spark.annotation.Experimental;\n+import org.apache.spark.sql.catalog.v2.expressions.Expression;\n+import org.apache.spark.sql.sources.Filter;\n+\n+/**\n+ * A mix-in interface for {@link Table} update support. Data sources can implement this\n+ * interface to provide the ability to update data that matches filter expressions\n+ * with the given sets.\n+ */\n+@Experimental\n+public interface SupportsUpdate {\n+\n+  /**\n+   * Update data that matches filter expressions with the given sets for a data source table.\n+   * <p>\n+   * Rows will be updated with the given values iff all of the filter expressions match.\n+   * That is, the expressions must be interpreted as a set of filters that are ANDed together.\n+   * <p>\n+   * Implementations may reject a update operation if the update isn't possible without significant\n+   * effort or it cannot deal with the sets expression. For example, partitioned data sources may\n+   * reject updates that do not filter by partition columns because the filter may require\n+   * rewriting files. The update may also be rejected if the update requires a complex computation\n+   * that the data source does not support.\n+   * To reject a delete implementations should throw {@link IllegalArgumentException} with a clear\n+   * error message that identifies which expression was rejected.\n+   *\n+   * @param sets the fields to be updated and the corresponding updated values in form of\n+   *             key-value pairs in a map. The value can be a literal, or a simple expression\n+   *             like {{{ originalValue + 1 }}}.\n+   * @param filters filter expressions, used to select rows to delete when all expressions match"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Fixed.",
    "commit": "3732a18e3012e0dccc28663f9a37ca570e8b13d1",
    "createdAt": "2019-09-11T07:32:22Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import java.util.Map;\n+\n+import org.apache.spark.annotation.Experimental;\n+import org.apache.spark.sql.catalog.v2.expressions.Expression;\n+import org.apache.spark.sql.sources.Filter;\n+\n+/**\n+ * A mix-in interface for {@link Table} update support. Data sources can implement this\n+ * interface to provide the ability to update data that matches filter expressions\n+ * with the given sets.\n+ */\n+@Experimental\n+public interface SupportsUpdate {\n+\n+  /**\n+   * Update data that matches filter expressions with the given sets for a data source table.\n+   * <p>\n+   * Rows will be updated with the given values iff all of the filter expressions match.\n+   * That is, the expressions must be interpreted as a set of filters that are ANDed together.\n+   * <p>\n+   * Implementations may reject a update operation if the update isn't possible without significant\n+   * effort or it cannot deal with the sets expression. For example, partitioned data sources may\n+   * reject updates that do not filter by partition columns because the filter may require\n+   * rewriting files. The update may also be rejected if the update requires a complex computation\n+   * that the data source does not support.\n+   * To reject a delete implementations should throw {@link IllegalArgumentException} with a clear\n+   * error message that identifies which expression was rejected.\n+   *\n+   * @param sets the fields to be updated and the corresponding updated values in form of\n+   *             key-value pairs in a map. The value can be a literal, or a simple expression\n+   *             like {{{ originalValue + 1 }}}.\n+   * @param filters filter expressions, used to select rows to delete when all expressions match"
  }],
  "prId": 25626
}]