[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Hm, actually, do we need to count `null` as distinct value? It's not counted as a distinct value in SQL (`F.countDistinct` or `count(DISTINCT col)`) and Pandas (`unique()` by default) at least.",
    "commit": "50ae5cfb3ef29aaf44dc2891c21207ff0cc5f9bc",
    "createdAt": "2019-05-23T18:10:16Z",
    "diffHunk": "@@ -42,8 +42,8 @@ object AggregateEstimation {\n         (res, expr) => {\n           val columnStat = childStats.attributeStats(expr.asInstanceOf[Attribute])\n           val distinctCount = columnStat.distinctCount.get\n-          val distinctValue: BigInt = if (distinctCount == 0 && columnStat.nullCount.get > 0) {\n-            1\n+          val distinctValue: BigInt = if (columnStat.nullCount.get > 0) {\n+            distinctCount + 1",
    "line": 7
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Looking into the current impl, seems we ignore `null` as distinct values:\r\n\r\nhttps://github.com/apache/spark/blob/239082d9667a4fa4198bd9524d63c739df147e0e/sql/core/src/main/scala/org/apache/spark/sql/execution/command/CommandUtils.scala#L270\r\nhttps://github.com/apache/spark/blob/b1857a4d7dfe17663f8adccd7825d890ae70d2a1/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/statsEstimation/EstimationUtils.scala#L50-L51\r\n",
    "commit": "50ae5cfb3ef29aaf44dc2891c21207ff0cc5f9bc",
    "createdAt": "2019-05-23T18:11:37Z",
    "diffHunk": "@@ -42,8 +42,8 @@ object AggregateEstimation {\n         (res, expr) => {\n           val columnStat = childStats.attributeStats(expr.asInstanceOf[Attribute])\n           val distinctCount = columnStat.distinctCount.get\n-          val distinctValue: BigInt = if (distinctCount == 0 && columnStat.nullCount.get > 0) {\n-            1\n+          val distinctValue: BigInt = if (columnStat.nullCount.get > 0) {\n+            distinctCount + 1",
    "line": 7
  }],
  "prId": 24436
}]