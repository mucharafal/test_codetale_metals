[{
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "We need this check even after the resolution batch?",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2018-12-28T05:40:25Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeMap}\n+import org.apache.spark.sql.catalyst.plans.logical.{LeafNode, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * Updates nullability of Attributes in a resolved LogicalPlan by using the nullability of\n+ * corresponding Attributes of its children output Attributes. This step is needed because\n+ * users can use a resolved AttributeReference in the Dataset API and outer joins\n+ * can change the nullability of an AttribtueReference. Without this rule, a nullable column's\n+ * nullable field can be actually set as non-nullable, which cause illegal optimization\n+ * (e.g., NULL propagation) and wrong answers.\n+ * See SPARK-13484 and SPARK-13801 for the concrete queries of this case.\n+ *\n+ * This rule should be executed again at the end of optimization phase, as optimizer may change\n+ * some expressions and their nullabilities as well. See SPARK-21351 for more details.\n+ */\n+object UpdateAttributeNullability extends Rule[LogicalPlan] {\n+\n+  def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperatorsUp {\n+    // Skip unresolved nodes.\n+    case p if !p.resolved => p",
    "line": 40
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "no we don't. But it has no harm, and help us to merge these 2 rules.",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2018-12-28T13:46:58Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeMap}\n+import org.apache.spark.sql.catalyst.plans.logical.{LeafNode, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * Updates nullability of Attributes in a resolved LogicalPlan by using the nullability of\n+ * corresponding Attributes of its children output Attributes. This step is needed because\n+ * users can use a resolved AttributeReference in the Dataset API and outer joins\n+ * can change the nullability of an AttribtueReference. Without this rule, a nullable column's\n+ * nullable field can be actually set as non-nullable, which cause illegal optimization\n+ * (e.g., NULL propagation) and wrong answers.\n+ * See SPARK-13484 and SPARK-13801 for the concrete queries of this case.\n+ *\n+ * This rule should be executed again at the end of optimization phase, as optimizer may change\n+ * some expressions and their nullabilities as well. See SPARK-21351 for more details.\n+ */\n+object UpdateAttributeNullability extends Rule[LogicalPlan] {\n+\n+  def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperatorsUp {\n+    // Skip unresolved nodes.\n+    case p if !p.resolved => p",
    "line": 40
  }],
  "prId": 23390
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "It still looks weird to me if we call an analyzer rule in the optimizer. Our codegen impl depends on the correctness of nullability fields. I am wondering which rule could break it? join reordering? \r\n\r\nI think our existing test cases might already have such a case. Could you throw an exception if this rule changes the nullability in the optimizer stage? I want to know the exact case why we need to run this in the optimizer stage. ",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2018-12-28T05:54:39Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis",
    "line": 18
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "The original PR #18576 explains it, and the test case is https://github.com/apache/spark/pull/23390/files#diff-099c363f75cfc9011d9e08f5a8067038R29",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2018-12-28T13:48:15Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis",
    "line": 18
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "In the future, if we introduce fixed-size array type, then `CreateArray` returns fixed-size array, and `GetArrayItem` can define the `nullable` smarter if the input is fixed-size array.",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2018-12-28T13:56:30Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis",
    "line": 18
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "@maropu do you have more use cases? If it's the only use case, maybe we can simply remove this optimization as its use case is rare. And we can optimize it in a better way in the future. ",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2018-12-28T13:58:24Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis",
    "line": 18
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Yes, we need to understand which cases are improved and then update the nullable at the right place. ",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2018-12-30T19:39:49Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis",
    "line": 18
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "@cloud-fan Removing it from the optimizer looks ok to me, but I remember the rule seems to be related to the existing tests? See: https://github.com/apache/spark/pull/18576#issuecomment-376762560",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2019-01-03T13:13:40Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis",
    "line": 18
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "How about we accept this patch and think about removing this optimization later?",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2019-01-04T13:12:08Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis",
    "line": 18
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "yea, that sounds good to me. Thanks!",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2019-01-04T23:44:49Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis",
    "line": 18
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "When removing it in a following pr, could you reopen the jira, too? https://issues.apache.org/jira/browse/SPARK-21351",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2019-01-04T23:53:00Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis",
    "line": 18
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "sure, feel free to merge this PR if you think it's ready to go. thanks!",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2019-01-07T07:54:29Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis",
    "line": 18
  }],
  "prId": 23390
}, {
  "comments": [{
    "author": {
      "login": "mgaido91"
    },
    "body": "can't we just have a map `exprId` -> `nullable` here and use this map is the `transformExpressions` below?",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2018-12-28T11:14:16Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeMap}\n+import org.apache.spark.sql.catalyst.plans.logical.{LeafNode, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * Updates nullability of Attributes in a resolved LogicalPlan by using the nullability of\n+ * corresponding Attributes of its children output Attributes. This step is needed because\n+ * users can use a resolved AttributeReference in the Dataset API and outer joins\n+ * can change the nullability of an AttribtueReference. Without this rule, a nullable column's\n+ * nullable field can be actually set as non-nullable, which cause illegal optimization\n+ * (e.g., NULL propagation) and wrong answers.\n+ * See SPARK-13484 and SPARK-13801 for the concrete queries of this case.\n+ *\n+ * This rule should be executed again at the end of optimization phase, as optimizer may change\n+ * some expressions and their nullabilities as well. See SPARK-21351 for more details.\n+ */\n+object UpdateAttributeNullability extends Rule[LogicalPlan] {\n+\n+  def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperatorsUp {\n+    // Skip unresolved nodes.\n+    case p if !p.resolved => p\n+    // Skip leaf node, as it has no child and no need to update nullability.\n+    case p: LeafNode => p\n+    case p: LogicalPlan =>\n+      val childrenOutput = p.children.flatMap(c => c.output).groupBy(_.exprId).flatMap {\n+        case (exprId, attributes) =>\n+          // If there are multiple Attributes having the same ExprId, we need to resolve\n+          // the conflict of nullable field. We do not really expect this happen.\n+          val nullable = attributes.exists(_.nullable)\n+          attributes.map(attr => attr.withNullability(nullable))"
  }],
  "prId": 23390
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "It sounds weird that in optimization phase we make correct nullability to wrong again. Can we have other way to solve it?",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2019-01-03T14:25:41Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeMap}\n+import org.apache.spark.sql.catalyst.plans.logical.{LeafNode, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * Updates nullability of Attributes in a resolved LogicalPlan by using the nullability of\n+ * corresponding Attributes of its children output Attributes. This step is needed because\n+ * users can use a resolved AttributeReference in the Dataset API and outer joins\n+ * can change the nullability of an AttribtueReference. Without this rule, a nullable column's\n+ * nullable field can be actually set as non-nullable, which cause illegal optimization\n+ * (e.g., NULL propagation) and wrong answers.\n+ * See SPARK-13484 and SPARK-13801 for the concrete queries of this case.\n+ *\n+ * This rule should be executed again at the end of optimization phase, as optimizer may change",
    "line": 33
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "it's not about wrong nullability, it's an optimization. see https://github.com/apache/spark/pull/23390/files#r244326583",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2019-01-04T13:06:02Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeMap}\n+import org.apache.spark.sql.catalyst.plans.logical.{LeafNode, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * Updates nullability of Attributes in a resolved LogicalPlan by using the nullability of\n+ * corresponding Attributes of its children output Attributes. This step is needed because\n+ * users can use a resolved AttributeReference in the Dataset API and outer joins\n+ * can change the nullability of an AttribtueReference. Without this rule, a nullable column's\n+ * nullable field can be actually set as non-nullable, which cause illegal optimization\n+ * (e.g., NULL propagation) and wrong answers.\n+ * See SPARK-13484 and SPARK-13801 for the concrete queries of this case.\n+ *\n+ * This rule should be executed again at the end of optimization phase, as optimizer may change",
    "line": 33
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "ah, I see. Then sounds like removing this optimization (https://github.com/apache/spark/pull/23390/files#r244326906) is ok.",
    "commit": "bcb56670c4d35df880ff7b4dbe1d29d1359e7791",
    "createdAt": "2019-01-04T16:17:20Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeMap}\n+import org.apache.spark.sql.catalyst.plans.logical.{LeafNode, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * Updates nullability of Attributes in a resolved LogicalPlan by using the nullability of\n+ * corresponding Attributes of its children output Attributes. This step is needed because\n+ * users can use a resolved AttributeReference in the Dataset API and outer joins\n+ * can change the nullability of an AttribtueReference. Without this rule, a nullable column's\n+ * nullable field can be actually set as non-nullable, which cause illegal optimization\n+ * (e.g., NULL propagation) and wrong answers.\n+ * See SPARK-13484 and SPARK-13801 for the concrete queries of this case.\n+ *\n+ * This rule should be executed again at the end of optimization phase, as optimizer may change",
    "line": 33
  }],
  "prId": 23390
}]