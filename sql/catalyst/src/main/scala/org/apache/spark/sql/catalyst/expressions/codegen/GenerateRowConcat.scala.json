[{
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "JoinUnsafeRow ?\n",
    "commit": "8717f3543e35908144598eb3eecd6b00a9fd8b09",
    "createdAt": "2015-07-31T23:05:14Z",
    "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.codegen\n+\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeRow, Attribute}\n+import org.apache.spark.sql.types.StructType\n+import org.apache.spark.unsafe.PlatformDependent\n+\n+\n+abstract class UnsafeRowConcat {"
  }],
  "prId": 7821
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "Should we move this into above section?\n",
    "commit": "8717f3543e35908144598eb3eecd6b00a9fd8b09",
    "createdAt": "2015-08-01T00:41:00Z",
    "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.codegen\n+\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeRow, Attribute}\n+import org.apache.spark.sql.types.StructType\n+import org.apache.spark.unsafe.PlatformDependent\n+\n+\n+abstract class UnsafeRowConcat {\n+  def concat(row1: UnsafeRow, row2: UnsafeRow): UnsafeRow\n+}\n+\n+\n+/**\n+ * A code generator for concatenating two [[UnsafeRow]]s into a single [[UnsafeRow]].\n+ *\n+ * The high level algorithm is:\n+ *\n+ * 1. Concatenate the two bitsets together into a single one, taking padding into account.\n+ * 2. Move fixed-length data.\n+ * 3. Move variable-length data.\n+ * 4. Update the offset position (i.e. the upper 32 bits in the fixed length part) for all\n+ *    variable-length data.\n+ */\n+object GenerateRowConcat extends CodeGenerator[(StructType, StructType), UnsafeRowConcat] {\n+\n+  def dump(word: Long): String = {\n+    Seq.tabulate(64) { i => if ((word >> i) % 2 == 0) \"0\" else \"1\" }.reverse.mkString\n+  }\n+\n+  override protected def create(in: (StructType, StructType)): UnsafeRowConcat = {\n+    create(in._1, in._2)\n+  }\n+\n+  override protected def canonicalize(in: (StructType, StructType)): (StructType, StructType) = in\n+\n+  override protected def bind(in: (StructType, StructType), inputSchema: Seq[Attribute])\n+    : (StructType, StructType) = {\n+    in\n+  }\n+\n+  def create(schema1: StructType, schema2: StructType): UnsafeRowConcat = {\n+    val ctx = newCodeGenContext()\n+    val offset = PlatformDependent.BYTE_ARRAY_OFFSET\n+\n+    val bitset1Words = (schema1.size + 63) / 64\n+    val bitset2Words = (schema2.size + 63) / 64\n+    val outputBitsetWords = (schema1.size + schema2.size + 63) / 64\n+    val bitset1Remainder = schema1.size % 64\n+    val bitset2Remainder = schema2.size % 64\n+\n+    // The number of words we can reduce when we concat two rows together.\n+    // The only reduction comes from merging the bitset portion of the two rows, saving 1 word.\n+    val sizeReduction = bitset1Words + bitset2Words - outputBitsetWords\n+\n+    // --------------------- copy bitset from row 1 ----------------------- //\n+    val copyBitset1 = Seq.tabulate(bitset1Words) { i =>\n+      s\"\"\"\n+         |PlatformDependent.UNSAFE.putLong(buf, ${offset + i * 8},\n+         |  PlatformDependent.UNSAFE.getLong(obj1, ${offset + i * 8}));\n+       \"\"\".stripMargin\n+    }.mkString\n+\n+\n+    // --------------------- copy bitset from row 2 ----------------------- //\n+    var copyBitset2 = \"\"\n+    if (bitset1Remainder == 0) {\n+      copyBitset2 += Seq.tabulate(bitset2Words) { i =>\n+        s\"\"\"\n+           |PlatformDependent.UNSAFE.putLong(buf, ${offset + (bitset1Words + i) * 8},\n+           |  PlatformDependent.UNSAFE.getLong(obj2, ${offset + i * 8}));\n+         \"\"\".stripMargin\n+      }.mkString\n+    } else {\n+      copyBitset2 = Seq.tabulate(bitset2Words) { i =>\n+        s\"\"\"\n+           |long bs2w$i = PlatformDependent.UNSAFE.getLong(obj2, ${offset + i * 8});\n+           |long bs2w${i}p1 = (bs2w$i << $bitset1Remainder) & ~((1L << $bitset1Remainder) - 1);\n+           |long bs2w${i}p2 = (bs2w$i >>> ${64 - bitset1Remainder});\n+         \"\"\".stripMargin\n+      }.mkString\n+\n+      copyBitset2 += Seq.tabulate(bitset2Words) { i =>\n+        val currentOffset = offset + (bitset1Words + i - 1) * 8\n+        if (i == 0) {\n+          if (bitset1Words > 0) {\n+            s\"\"\"\n+               |PlatformDependent.UNSAFE.putLong(buf, $currentOffset,\n+               |  bs2w${i}p1 | PlatformDependent.UNSAFE.getLong(obj1, $currentOffset));\n+            \"\"\".stripMargin\n+          } else {\n+            s\"\"\"\n+               |PlatformDependent.UNSAFE.putLong(buf, $currentOffset + 8, bs2w${i}p1);\n+            \"\"\".stripMargin\n+          }\n+        } else {\n+          s\"\"\"\n+             |PlatformDependent.UNSAFE.putLong(buf, $currentOffset, bs2w${i}p1 | bs2w${i - 1}p2);\n+          \"\"\".stripMargin\n+        }\n+      }.mkString(\"\\n\")\n+\n+      if (bitset2Words > 0 &&\n+        (bitset2Remainder == 0 || bitset2Remainder > (64 - bitset1Remainder))) {\n+        val lastWord = bitset2Words - 1\n+        copyBitset2 +=\n+          s\"\"\"\n+             |PlatformDependent.UNSAFE.putLong(buf, ${offset + (outputBitsetWords - 1) * 8},\n+             |  bs2w${lastWord}p2);\n+          \"\"\".stripMargin\n+      }\n+    }\n+\n+    // --------------------- copy fixed length portion from row 1 ----------------------- //\n+    var cursor = offset + outputBitsetWords * 8\n+    val copyFixedLengthRow1 = s\"\"\"\n+       |// Copy fixed length data for row1\n+       |PlatformDependent.copyMemory(\n+       |  obj1, offset1 + ${bitset1Words * 8},\n+       |  buf, $cursor,\n+       |  ${schema1.size * 8});\n+     \"\"\".stripMargin\n+\n+    // --------------------- copy fixed length portion from row 2 ----------------------- //\n+    cursor += schema1.size * 8"
  }],
  "prId": 7821
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "We could skip the copy if no variable length\n",
    "commit": "8717f3543e35908144598eb3eecd6b00a9fd8b09",
    "createdAt": "2015-08-01T00:49:15Z",
    "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.codegen\n+\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeRow, Attribute}\n+import org.apache.spark.sql.types.StructType\n+import org.apache.spark.unsafe.PlatformDependent\n+\n+\n+abstract class UnsafeRowConcat {\n+  def concat(row1: UnsafeRow, row2: UnsafeRow): UnsafeRow\n+}\n+\n+\n+/**\n+ * A code generator for concatenating two [[UnsafeRow]]s into a single [[UnsafeRow]].\n+ *\n+ * The high level algorithm is:\n+ *\n+ * 1. Concatenate the two bitsets together into a single one, taking padding into account.\n+ * 2. Move fixed-length data.\n+ * 3. Move variable-length data.\n+ * 4. Update the offset position (i.e. the upper 32 bits in the fixed length part) for all\n+ *    variable-length data.\n+ */\n+object GenerateRowConcat extends CodeGenerator[(StructType, StructType), UnsafeRowConcat] {\n+\n+  def dump(word: Long): String = {\n+    Seq.tabulate(64) { i => if ((word >> i) % 2 == 0) \"0\" else \"1\" }.reverse.mkString\n+  }\n+\n+  override protected def create(in: (StructType, StructType)): UnsafeRowConcat = {\n+    create(in._1, in._2)\n+  }\n+\n+  override protected def canonicalize(in: (StructType, StructType)): (StructType, StructType) = in\n+\n+  override protected def bind(in: (StructType, StructType), inputSchema: Seq[Attribute])\n+    : (StructType, StructType) = {\n+    in\n+  }\n+\n+  def create(schema1: StructType, schema2: StructType): UnsafeRowConcat = {\n+    val ctx = newCodeGenContext()\n+    val offset = PlatformDependent.BYTE_ARRAY_OFFSET\n+\n+    val bitset1Words = (schema1.size + 63) / 64\n+    val bitset2Words = (schema2.size + 63) / 64\n+    val outputBitsetWords = (schema1.size + schema2.size + 63) / 64\n+    val bitset1Remainder = schema1.size % 64\n+    val bitset2Remainder = schema2.size % 64\n+\n+    // The number of words we can reduce when we concat two rows together.\n+    // The only reduction comes from merging the bitset portion of the two rows, saving 1 word.\n+    val sizeReduction = bitset1Words + bitset2Words - outputBitsetWords\n+\n+    // --------------------- copy bitset from row 1 ----------------------- //\n+    val copyBitset1 = Seq.tabulate(bitset1Words) { i =>\n+      s\"\"\"\n+         |PlatformDependent.UNSAFE.putLong(buf, ${offset + i * 8},\n+         |  PlatformDependent.UNSAFE.getLong(obj1, ${offset + i * 8}));\n+       \"\"\".stripMargin\n+    }.mkString\n+\n+\n+    // --------------------- copy bitset from row 2 ----------------------- //\n+    var copyBitset2 = \"\"\n+    if (bitset1Remainder == 0) {\n+      copyBitset2 += Seq.tabulate(bitset2Words) { i =>\n+        s\"\"\"\n+           |PlatformDependent.UNSAFE.putLong(buf, ${offset + (bitset1Words + i) * 8},\n+           |  PlatformDependent.UNSAFE.getLong(obj2, ${offset + i * 8}));\n+         \"\"\".stripMargin\n+      }.mkString\n+    } else {\n+      copyBitset2 = Seq.tabulate(bitset2Words) { i =>\n+        s\"\"\"\n+           |long bs2w$i = PlatformDependent.UNSAFE.getLong(obj2, ${offset + i * 8});\n+           |long bs2w${i}p1 = (bs2w$i << $bitset1Remainder) & ~((1L << $bitset1Remainder) - 1);\n+           |long bs2w${i}p2 = (bs2w$i >>> ${64 - bitset1Remainder});\n+         \"\"\".stripMargin\n+      }.mkString\n+\n+      copyBitset2 += Seq.tabulate(bitset2Words) { i =>\n+        val currentOffset = offset + (bitset1Words + i - 1) * 8\n+        if (i == 0) {\n+          if (bitset1Words > 0) {\n+            s\"\"\"\n+               |PlatformDependent.UNSAFE.putLong(buf, $currentOffset,\n+               |  bs2w${i}p1 | PlatformDependent.UNSAFE.getLong(obj1, $currentOffset));\n+            \"\"\".stripMargin\n+          } else {\n+            s\"\"\"\n+               |PlatformDependent.UNSAFE.putLong(buf, $currentOffset + 8, bs2w${i}p1);\n+            \"\"\".stripMargin\n+          }\n+        } else {\n+          s\"\"\"\n+             |PlatformDependent.UNSAFE.putLong(buf, $currentOffset, bs2w${i}p1 | bs2w${i - 1}p2);\n+          \"\"\".stripMargin\n+        }\n+      }.mkString(\"\\n\")\n+\n+      if (bitset2Words > 0 &&\n+        (bitset2Remainder == 0 || bitset2Remainder > (64 - bitset1Remainder))) {\n+        val lastWord = bitset2Words - 1\n+        copyBitset2 +=\n+          s\"\"\"\n+             |PlatformDependent.UNSAFE.putLong(buf, ${offset + (outputBitsetWords - 1) * 8},\n+             |  bs2w${lastWord}p2);\n+          \"\"\".stripMargin\n+      }\n+    }\n+\n+    // --------------------- copy fixed length portion from row 1 ----------------------- //\n+    var cursor = offset + outputBitsetWords * 8\n+    val copyFixedLengthRow1 = s\"\"\"\n+       |// Copy fixed length data for row1\n+       |PlatformDependent.copyMemory(\n+       |  obj1, offset1 + ${bitset1Words * 8},\n+       |  buf, $cursor,\n+       |  ${schema1.size * 8});\n+     \"\"\".stripMargin\n+\n+    // --------------------- copy fixed length portion from row 2 ----------------------- //\n+    cursor += schema1.size * 8\n+    val copyFixedLengthRow2 = s\"\"\"\n+       |// Copy fixed length data for row2\n+       |PlatformDependent.copyMemory(\n+       |  obj2, offset2 + ${bitset2Words * 8},\n+       |  buf, $cursor,\n+       |  ${schema2.size * 8});\n+     \"\"\".stripMargin\n+\n+    // --------------------- copy variable length portion from row 1 ----------------------- //\n+    cursor += schema2.size * 8\n+    val copyVariableLengthRow1 = s\"\"\"\n+       |// Copy variable length data for row1\n+       |long numBytesBitsetAndFixedRow1 = ${(bitset1Words + schema1.size) * 8};\n+       |long numBytesVariableRow1 = row1.getSizeInBytes() - numBytesBitsetAndFixedRow1;\n+       |PlatformDependent.copyMemory(\n+       |  obj1, offset1 + ${(bitset1Words + schema1.size) * 8},\n+       |  buf, $cursor,\n+       |  numBytesVariableRow1);\n+     \"\"\".stripMargin\n+\n+    // --------------------- copy variable length portion from row 2 ----------------------- //\n+    val copyVariableLengthRow2 = s\"\"\"\n+       |// Copy variable length data for row2\n+       |long numBytesBitsetAndFixedRow2 = ${(bitset2Words + schema2.size) * 8};\n+       |long numBytesVariableRow2 = row2.getSizeInBytes() - numBytesBitsetAndFixedRow2;\n+       |PlatformDependent.copyMemory("
  }],
  "prId": 7821
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "We could do something like this\n\n```\nSeq.tabulate(outputBitsetWords) { i => \n  val bitset = if (i< bitset1Words) {\n    getLong(obj1, i * 8)\n  } else if (i == bitset1Words && bitset1Remainder > 0) {\n    getLong(obj1, i* 8) | getLong(obj2, 0) >>> bitset1Remainder\n  } else {\n    getLong(obj2, i - bitset1Words) <<< bitset1Remainder | getLong(obj2 i - bitset1Words + 1) >>> bitset1Remainder\n  }\n  putLong(buf, i * 8, bitset)\n}\n```\n",
    "commit": "8717f3543e35908144598eb3eecd6b00a9fd8b09",
    "createdAt": "2015-08-01T00:56:55Z",
    "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.codegen\n+\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeRow, Attribute}\n+import org.apache.spark.sql.types.StructType\n+import org.apache.spark.unsafe.PlatformDependent\n+\n+\n+abstract class UnsafeRowConcat {\n+  def concat(row1: UnsafeRow, row2: UnsafeRow): UnsafeRow\n+}\n+\n+\n+/**\n+ * A code generator for concatenating two [[UnsafeRow]]s into a single [[UnsafeRow]].\n+ *\n+ * The high level algorithm is:\n+ *\n+ * 1. Concatenate the two bitsets together into a single one, taking padding into account.\n+ * 2. Move fixed-length data.\n+ * 3. Move variable-length data.\n+ * 4. Update the offset position (i.e. the upper 32 bits in the fixed length part) for all\n+ *    variable-length data.\n+ */\n+object GenerateRowConcat extends CodeGenerator[(StructType, StructType), UnsafeRowConcat] {\n+\n+  def dump(word: Long): String = {\n+    Seq.tabulate(64) { i => if ((word >> i) % 2 == 0) \"0\" else \"1\" }.reverse.mkString\n+  }\n+\n+  override protected def create(in: (StructType, StructType)): UnsafeRowConcat = {\n+    create(in._1, in._2)\n+  }\n+\n+  override protected def canonicalize(in: (StructType, StructType)): (StructType, StructType) = in\n+\n+  override protected def bind(in: (StructType, StructType), inputSchema: Seq[Attribute])\n+    : (StructType, StructType) = {\n+    in\n+  }\n+\n+  def create(schema1: StructType, schema2: StructType): UnsafeRowConcat = {\n+    val ctx = newCodeGenContext()\n+    val offset = PlatformDependent.BYTE_ARRAY_OFFSET\n+\n+    val bitset1Words = (schema1.size + 63) / 64\n+    val bitset2Words = (schema2.size + 63) / 64\n+    val outputBitsetWords = (schema1.size + schema2.size + 63) / 64\n+    val bitset1Remainder = schema1.size % 64\n+    val bitset2Remainder = schema2.size % 64\n+\n+    // The number of words we can reduce when we concat two rows together.\n+    // The only reduction comes from merging the bitset portion of the two rows, saving 1 word.\n+    val sizeReduction = bitset1Words + bitset2Words - outputBitsetWords\n+\n+    // --------------------- copy bitset from row 1 ----------------------- //\n+    val copyBitset1 = Seq.tabulate(bitset1Words) { i =>\n+      s\"\"\"\n+         |PlatformDependent.UNSAFE.putLong(buf, ${offset + i * 8},\n+         |  PlatformDependent.UNSAFE.getLong(obj1, ${offset + i * 8}));\n+       \"\"\".stripMargin\n+    }.mkString\n+\n+\n+    // --------------------- copy bitset from row 2 ----------------------- //"
  }],
  "prId": 7821
}]