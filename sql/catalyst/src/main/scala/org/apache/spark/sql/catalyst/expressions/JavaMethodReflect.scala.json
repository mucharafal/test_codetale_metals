[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "is it similar to `StaticInvoke`?\n",
    "commit": "d24ca97a0ac85b54ea64b017343fe9eb51ecc02e",
    "createdAt": "2016-06-29T09:24:46Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import java.lang.reflect.Method\n+\n+import scala.util.Try\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * An expression that invokes a method on a class via reflection.\n+ *\n+ * @param children the first element should be a literal string for the class name,\n+ *                 and the second element should be a literal string for the method name,\n+ *                 and the remaining are input arguments to the Java method.\n+ */\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(class,method[,arg1[,arg2..]]) calls method with reflection\",\n+  extended = \"> SELECT _FUNC_('java.util.UUID', 'randomUUID');\\nc33fb387-8500-4bfa-81d2-6e0e3e930df2\")\n+// scalastyle:on line.size.limit\n+case class JavaMethodReflect(children: Seq[Expression])"
  }, {
    "author": {
      "login": "petermaxlee"
    },
    "body": "Thanks for pointing out. It looks similar, but has some subtle differences:\n1. This one can invoke non-static methods.\n2. This one does type conversion, and as a result is more user facing. StaticInvoke seems to be used in internal implementations?\n3. This is a SQL function - why was StaticInvoke a \"nonSQL\" function?\n4. This one supports non-codegen.\n\nPerhaps we can push this in, and I can look into whether it'd make sense to consolidate the two?\n",
    "commit": "d24ca97a0ac85b54ea64b017343fe9eb51ecc02e",
    "createdAt": "2016-06-29T18:59:17Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import java.lang.reflect.Method\n+\n+import scala.util.Try\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * An expression that invokes a method on a class via reflection.\n+ *\n+ * @param children the first element should be a literal string for the class name,\n+ *                 and the second element should be a literal string for the method name,\n+ *                 and the remaining are input arguments to the Java method.\n+ */\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(class,method[,arg1[,arg2..]]) calls method with reflection\",\n+  extended = \"> SELECT _FUNC_('java.util.UUID', 'randomUUID');\\nc33fb387-8500-4bfa-81d2-6e0e3e930df2\")\n+// scalastyle:on line.size.limit\n+case class JavaMethodReflect(children: Seq[Expression])"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "this one can invoke non-static methods? How do we pass in the object reference?\n\nI'm ok to leave them separated as this is one is userfacing and `StaticInvoke` is used internally.\n",
    "commit": "d24ca97a0ac85b54ea64b017343fe9eb51ecc02e",
    "createdAt": "2016-06-30T01:33:28Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import java.lang.reflect.Method\n+\n+import scala.util.Try\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * An expression that invokes a method on a class via reflection.\n+ *\n+ * @param children the first element should be a literal string for the class name,\n+ *                 and the second element should be a literal string for the method name,\n+ *                 and the remaining are input arguments to the Java method.\n+ */\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(class,method[,arg1[,arg2..]]) calls method with reflection\",\n+  extended = \"> SELECT _FUNC_('java.util.UUID', 'randomUUID');\\nc33fb387-8500-4bfa-81d2-6e0e3e930df2\")\n+// scalastyle:on line.size.limit\n+case class JavaMethodReflect(children: Seq[Expression])"
  }, {
    "author": {
      "login": "petermaxlee"
    },
    "body": "It assumes there is a no-arg constructor and creates an instance of the class automatically. That's what reflect does in Hive.\n",
    "commit": "d24ca97a0ac85b54ea64b017343fe9eb51ecc02e",
    "createdAt": "2016-06-30T01:46:38Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import java.lang.reflect.Method\n+\n+import scala.util.Try\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * An expression that invokes a method on a class via reflection.\n+ *\n+ * @param children the first element should be a literal string for the class name,\n+ *                 and the second element should be a literal string for the method name,\n+ *                 and the remaining are input arguments to the Java method.\n+ */\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(class,method[,arg1[,arg2..]]) calls method with reflection\",\n+  extended = \"> SELECT _FUNC_('java.util.UUID', 'randomUUID');\\nc33fb387-8500-4bfa-81d2-6e0e3e930df2\")\n+// scalastyle:on line.size.limit\n+case class JavaMethodReflect(children: Seq[Expression])"
  }],
  "prId": 13969
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "What's hive's rule? This looks reasonable but I wanna make sure we don't miss anything.\n",
    "commit": "d24ca97a0ac85b54ea64b017343fe9eb51ecc02e",
    "createdAt": "2016-06-30T14:51:38Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import java.lang.reflect.Method\n+\n+import scala.util.Try\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * An expression that invokes a method on a class via reflection.\n+ *\n+ * @param children the first element should be a literal string for the class name,\n+ *                 and the second element should be a literal string for the method name,\n+ *                 and the remaining are input arguments to the Java method.\n+ */\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(class,method[,arg1[,arg2..]]) calls method with reflection\",\n+  extended = \"> SELECT _FUNC_('java.util.UUID', 'randomUUID');\\nc33fb387-8500-4bfa-81d2-6e0e3e930df2\")\n+// scalastyle:on line.size.limit\n+case class JavaMethodReflect(children: Seq[Expression])\n+  extends Expression with CodegenFallback {\n+  import JavaMethodReflect._\n+\n+  override def prettyName: String = \"reflect\"\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    if (children.size < 2) {\n+      TypeCheckFailure(\"requires at least two arguments\")\n+    } else if (!children.take(2).forall(e => e.dataType == StringType && e.foldable)) {\n+      // The first two arguments must be string type.\n+      TypeCheckFailure(\"first two arguments should be string literals\")\n+    } else if (method == null) {\n+      TypeCheckFailure(\"cannot find a method that matches the argument types\")\n+    } else {\n+      TypeCheckSuccess\n+    }\n+  }\n+\n+  override def deterministic: Boolean = false\n+  override def nullable: Boolean = true\n+  override val dataType: DataType = StringType\n+\n+  override def eval(input: InternalRow): Any = {\n+    var i = 0\n+    while (i < argExprs.length) {\n+      buffer(i) = argExprs(i).eval(input).asInstanceOf[Object]\n+      // Convert if necessary. Based on the types defined in typeMapping, string is the only\n+      // type that needs conversion.\n+      if (buffer(i).isInstanceOf[UTF8String]) {\n+        buffer(i) = buffer(i).toString\n+      }\n+      i += 1\n+    }\n+    UTF8String.fromString(String.valueOf(method.invoke(obj, buffer : _*)))\n+  }\n+\n+  @transient private lazy val argExprs: Array[Expression] = children.drop(2).toArray\n+\n+  /** Name of the class -- this has to be called after we verify children has at least two exprs. */\n+  @transient private lazy val className = children(0).eval(null).asInstanceOf[UTF8String].toString\n+\n+  /** The reflection method. */\n+  @transient lazy val method: Method = {\n+    val methodName = children(1).eval(null).asInstanceOf[UTF8String].toString\n+    findMethod(className, methodName, argExprs.map(_.dataType)).orNull\n+  }\n+\n+  /** If the class has a no-arg ctor, instantiate the object. Otherwise, obj is null. */\n+  @transient private lazy val obj: Object = instantiate(className).orNull.asInstanceOf[Object]\n+\n+  /** A temporary buffer used to hold intermediate results returned by children. */\n+  @transient private lazy val buffer = new Array[Object](argExprs.length)\n+}\n+\n+object JavaMethodReflect {\n+  /** Mapping from Spark's type to acceptable JVM types. */\n+  val typeMapping = Map[DataType, Seq[Class[_]]]("
  }, {
    "author": {
      "login": "petermaxlee"
    },
    "body": "Hive follows the same thing for the subset we are supporting here. Hive however also supports timestamps, decimals, etc, that this one is not supporting yet.\n",
    "commit": "d24ca97a0ac85b54ea64b017343fe9eb51ecc02e",
    "createdAt": "2016-06-30T19:05:07Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import java.lang.reflect.Method\n+\n+import scala.util.Try\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * An expression that invokes a method on a class via reflection.\n+ *\n+ * @param children the first element should be a literal string for the class name,\n+ *                 and the second element should be a literal string for the method name,\n+ *                 and the remaining are input arguments to the Java method.\n+ */\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(class,method[,arg1[,arg2..]]) calls method with reflection\",\n+  extended = \"> SELECT _FUNC_('java.util.UUID', 'randomUUID');\\nc33fb387-8500-4bfa-81d2-6e0e3e930df2\")\n+// scalastyle:on line.size.limit\n+case class JavaMethodReflect(children: Seq[Expression])\n+  extends Expression with CodegenFallback {\n+  import JavaMethodReflect._\n+\n+  override def prettyName: String = \"reflect\"\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    if (children.size < 2) {\n+      TypeCheckFailure(\"requires at least two arguments\")\n+    } else if (!children.take(2).forall(e => e.dataType == StringType && e.foldable)) {\n+      // The first two arguments must be string type.\n+      TypeCheckFailure(\"first two arguments should be string literals\")\n+    } else if (method == null) {\n+      TypeCheckFailure(\"cannot find a method that matches the argument types\")\n+    } else {\n+      TypeCheckSuccess\n+    }\n+  }\n+\n+  override def deterministic: Boolean = false\n+  override def nullable: Boolean = true\n+  override val dataType: DataType = StringType\n+\n+  override def eval(input: InternalRow): Any = {\n+    var i = 0\n+    while (i < argExprs.length) {\n+      buffer(i) = argExprs(i).eval(input).asInstanceOf[Object]\n+      // Convert if necessary. Based on the types defined in typeMapping, string is the only\n+      // type that needs conversion.\n+      if (buffer(i).isInstanceOf[UTF8String]) {\n+        buffer(i) = buffer(i).toString\n+      }\n+      i += 1\n+    }\n+    UTF8String.fromString(String.valueOf(method.invoke(obj, buffer : _*)))\n+  }\n+\n+  @transient private lazy val argExprs: Array[Expression] = children.drop(2).toArray\n+\n+  /** Name of the class -- this has to be called after we verify children has at least two exprs. */\n+  @transient private lazy val className = children(0).eval(null).asInstanceOf[UTF8String].toString\n+\n+  /** The reflection method. */\n+  @transient lazy val method: Method = {\n+    val methodName = children(1).eval(null).asInstanceOf[UTF8String].toString\n+    findMethod(className, methodName, argExprs.map(_.dataType)).orNull\n+  }\n+\n+  /** If the class has a no-arg ctor, instantiate the object. Otherwise, obj is null. */\n+  @transient private lazy val obj: Object = instantiate(className).orNull.asInstanceOf[Object]\n+\n+  /** A temporary buffer used to hold intermediate results returned by children. */\n+  @transient private lazy val buffer = new Array[Object](argExprs.length)\n+}\n+\n+object JavaMethodReflect {\n+  /** Mapping from Spark's type to acceptable JVM types. */\n+  val typeMapping = Map[DataType, Seq[Class[_]]]("
  }],
  "prId": 13969
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "You can use `eval()` instead of `eval(null)`.\n",
    "commit": "d24ca97a0ac85b54ea64b017343fe9eb51ecc02e",
    "createdAt": "2016-07-06T09:36:51Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import java.lang.reflect.Method\n+\n+import scala.util.Try\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * An expression that invokes a method on a class via reflection.\n+ *\n+ * @param children the first element should be a literal string for the class name,\n+ *                 and the second element should be a literal string for the method name,\n+ *                 and the remaining are input arguments to the Java method.\n+ */\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(class,method[,arg1[,arg2..]]) calls method with reflection\",\n+  extended = \"> SELECT _FUNC_('java.util.UUID', 'randomUUID');\\nc33fb387-8500-4bfa-81d2-6e0e3e930df2\")\n+// scalastyle:on line.size.limit\n+case class JavaMethodReflect(children: Seq[Expression])\n+  extends Expression with CodegenFallback {\n+  import JavaMethodReflect._\n+\n+  override def prettyName: String = \"reflect\"\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    if (children.size < 2) {\n+      TypeCheckFailure(\"requires at least two arguments\")\n+    } else if (!children.take(2).forall(e => e.dataType == StringType && e.foldable)) {\n+      // The first two arguments must be string type.\n+      TypeCheckFailure(\"first two arguments should be string literals\")\n+    } else if (method == null) {\n+      TypeCheckFailure(\"cannot find a method that matches the argument types\")\n+    } else {\n+      TypeCheckSuccess\n+    }\n+  }\n+\n+  override def deterministic: Boolean = false\n+  override def nullable: Boolean = true\n+  override val dataType: DataType = StringType\n+\n+  override def eval(input: InternalRow): Any = {\n+    var i = 0\n+    while (i < argExprs.length) {\n+      buffer(i) = argExprs(i).eval(input).asInstanceOf[Object]\n+      // Convert if necessary. Based on the types defined in typeMapping, string is the only\n+      // type that needs conversion.\n+      if (buffer(i).isInstanceOf[UTF8String]) {\n+        buffer(i) = buffer(i).toString\n+      }\n+      i += 1\n+    }\n+    UTF8String.fromString(String.valueOf(method.invoke(obj, buffer : _*)))\n+  }\n+\n+  @transient private lazy val argExprs: Array[Expression] = children.drop(2).toArray\n+\n+  /** Name of the class -- this has to be called after we verify children has at least two exprs. */\n+  @transient private lazy val className = children(0).eval(null).asInstanceOf[UTF8String].toString"
  }],
  "prId": 13969
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This will throws `ClassNotFoundException`. We had better catch that and throw `AnalysisException`.\n",
    "commit": "d24ca97a0ac85b54ea64b017343fe9eb51ecc02e",
    "createdAt": "2016-07-06T10:16:44Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import java.lang.reflect.Method\n+\n+import scala.util.Try\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * An expression that invokes a method on a class via reflection.\n+ *\n+ * @param children the first element should be a literal string for the class name,\n+ *                 and the second element should be a literal string for the method name,\n+ *                 and the remaining are input arguments to the Java method.\n+ */\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(class,method[,arg1[,arg2..]]) calls method with reflection\",\n+  extended = \"> SELECT _FUNC_('java.util.UUID', 'randomUUID');\\nc33fb387-8500-4bfa-81d2-6e0e3e930df2\")\n+// scalastyle:on line.size.limit\n+case class JavaMethodReflect(children: Seq[Expression])\n+  extends Expression with CodegenFallback {\n+  import JavaMethodReflect._\n+\n+  override def prettyName: String = \"reflect\"\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    if (children.size < 2) {\n+      TypeCheckFailure(\"requires at least two arguments\")\n+    } else if (!children.take(2).forall(e => e.dataType == StringType && e.foldable)) {\n+      // The first two arguments must be string type.\n+      TypeCheckFailure(\"first two arguments should be string literals\")\n+    } else if (method == null) {\n+      TypeCheckFailure(\"cannot find a method that matches the argument types\")\n+    } else {\n+      TypeCheckSuccess\n+    }\n+  }\n+\n+  override def deterministic: Boolean = false\n+  override def nullable: Boolean = true\n+  override val dataType: DataType = StringType\n+\n+  override def eval(input: InternalRow): Any = {\n+    var i = 0\n+    while (i < argExprs.length) {\n+      buffer(i) = argExprs(i).eval(input).asInstanceOf[Object]\n+      // Convert if necessary. Based on the types defined in typeMapping, string is the only\n+      // type that needs conversion.\n+      if (buffer(i).isInstanceOf[UTF8String]) {\n+        buffer(i) = buffer(i).toString\n+      }\n+      i += 1\n+    }\n+    UTF8String.fromString(String.valueOf(method.invoke(obj, buffer : _*)))\n+  }\n+\n+  @transient private lazy val argExprs: Array[Expression] = children.drop(2).toArray\n+\n+  /** Name of the class -- this has to be called after we verify children has at least two exprs. */\n+  @transient private lazy val className = children(0).eval(null).asInstanceOf[UTF8String].toString\n+\n+  /** The reflection method. */\n+  @transient lazy val method: Method = {\n+    val methodName = children(1).eval(null).asInstanceOf[UTF8String].toString\n+    findMethod(className, methodName, argExprs.map(_.dataType)).orNull\n+  }\n+\n+  /** If the class has a no-arg ctor, instantiate the object. Otherwise, obj is null. */\n+  @transient private lazy val obj: Object = instantiate(className).orNull.asInstanceOf[Object]\n+\n+  /** A temporary buffer used to hold intermediate results returned by children. */\n+  @transient private lazy val buffer = new Array[Object](argExprs.length)\n+}\n+\n+object JavaMethodReflect {\n+  /** Mapping from Spark's type to acceptable JVM types. */\n+  val typeMapping = Map[DataType, Seq[Class[_]]](\n+    BooleanType -> Seq(classOf[java.lang.Boolean], classOf[Boolean]),\n+    ByteType -> Seq(classOf[java.lang.Byte], classOf[Byte]),\n+    ShortType -> Seq(classOf[java.lang.Short], classOf[Short]),\n+    IntegerType -> Seq(classOf[java.lang.Integer], classOf[Int]),\n+    LongType -> Seq(classOf[java.lang.Long], classOf[Long]),\n+    FloatType -> Seq(classOf[java.lang.Float], classOf[Float]),\n+    DoubleType -> Seq(classOf[java.lang.Double], classOf[Double]),\n+    StringType -> Seq(classOf[String])\n+  )\n+\n+  /**\n+   * Finds a Java method using reflection that matches the given argument types,\n+   * and whose return type is string.\n+   *\n+   * The types sequence must be the valid types defined in [[typeMapping]].\n+   *\n+   * This is made public for unit testing.\n+   */\n+  def findMethod(className: String, methodName: String, argTypes: Seq[DataType]): Option[Method] = {\n+    val clazz: Class[_] = Utils.classForName(className)"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Otherwise, None?\n",
    "commit": "d24ca97a0ac85b54ea64b017343fe9eb51ecc02e",
    "createdAt": "2016-07-06T10:18:48Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import java.lang.reflect.Method\n+\n+import scala.util.Try\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * An expression that invokes a method on a class via reflection.\n+ *\n+ * @param children the first element should be a literal string for the class name,\n+ *                 and the second element should be a literal string for the method name,\n+ *                 and the remaining are input arguments to the Java method.\n+ */\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(class,method[,arg1[,arg2..]]) calls method with reflection\",\n+  extended = \"> SELECT _FUNC_('java.util.UUID', 'randomUUID');\\nc33fb387-8500-4bfa-81d2-6e0e3e930df2\")\n+// scalastyle:on line.size.limit\n+case class JavaMethodReflect(children: Seq[Expression])\n+  extends Expression with CodegenFallback {\n+  import JavaMethodReflect._\n+\n+  override def prettyName: String = \"reflect\"\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    if (children.size < 2) {\n+      TypeCheckFailure(\"requires at least two arguments\")\n+    } else if (!children.take(2).forall(e => e.dataType == StringType && e.foldable)) {\n+      // The first two arguments must be string type.\n+      TypeCheckFailure(\"first two arguments should be string literals\")\n+    } else if (method == null) {\n+      TypeCheckFailure(\"cannot find a method that matches the argument types\")\n+    } else {\n+      TypeCheckSuccess\n+    }\n+  }\n+\n+  override def deterministic: Boolean = false\n+  override def nullable: Boolean = true\n+  override val dataType: DataType = StringType\n+\n+  override def eval(input: InternalRow): Any = {\n+    var i = 0\n+    while (i < argExprs.length) {\n+      buffer(i) = argExprs(i).eval(input).asInstanceOf[Object]\n+      // Convert if necessary. Based on the types defined in typeMapping, string is the only\n+      // type that needs conversion.\n+      if (buffer(i).isInstanceOf[UTF8String]) {\n+        buffer(i) = buffer(i).toString\n+      }\n+      i += 1\n+    }\n+    UTF8String.fromString(String.valueOf(method.invoke(obj, buffer : _*)))\n+  }\n+\n+  @transient private lazy val argExprs: Array[Expression] = children.drop(2).toArray\n+\n+  /** Name of the class -- this has to be called after we verify children has at least two exprs. */\n+  @transient private lazy val className = children(0).eval(null).asInstanceOf[UTF8String].toString\n+\n+  /** The reflection method. */\n+  @transient lazy val method: Method = {\n+    val methodName = children(1).eval(null).asInstanceOf[UTF8String].toString\n+    findMethod(className, methodName, argExprs.map(_.dataType)).orNull\n+  }\n+\n+  /** If the class has a no-arg ctor, instantiate the object. Otherwise, obj is null. */\n+  @transient private lazy val obj: Object = instantiate(className).orNull.asInstanceOf[Object]\n+\n+  /** A temporary buffer used to hold intermediate results returned by children. */\n+  @transient private lazy val buffer = new Array[Object](argExprs.length)\n+}\n+\n+object JavaMethodReflect {\n+  /** Mapping from Spark's type to acceptable JVM types. */\n+  val typeMapping = Map[DataType, Seq[Class[_]]](\n+    BooleanType -> Seq(classOf[java.lang.Boolean], classOf[Boolean]),\n+    ByteType -> Seq(classOf[java.lang.Byte], classOf[Byte]),\n+    ShortType -> Seq(classOf[java.lang.Short], classOf[Short]),\n+    IntegerType -> Seq(classOf[java.lang.Integer], classOf[Int]),\n+    LongType -> Seq(classOf[java.lang.Long], classOf[Long]),\n+    FloatType -> Seq(classOf[java.lang.Float], classOf[Float]),\n+    DoubleType -> Seq(classOf[java.lang.Double], classOf[Double]),\n+    StringType -> Seq(classOf[String])\n+  )\n+\n+  /**\n+   * Finds a Java method using reflection that matches the given argument types,\n+   * and whose return type is string.\n+   *\n+   * The types sequence must be the valid types defined in [[typeMapping]].\n+   *\n+   * This is made public for unit testing.\n+   */\n+  def findMethod(className: String, methodName: String, argTypes: Seq[DataType]): Option[Method] = {\n+    val clazz: Class[_] = Utils.classForName(className)"
  }, {
    "author": {
      "login": "petermaxlee"
    },
    "body": "that's a good point - I'm going to improve the error message.\n",
    "commit": "d24ca97a0ac85b54ea64b017343fe9eb51ecc02e",
    "createdAt": "2016-07-07T06:35:29Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import java.lang.reflect.Method\n+\n+import scala.util.Try\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.codegen.CodegenFallback\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * An expression that invokes a method on a class via reflection.\n+ *\n+ * @param children the first element should be a literal string for the class name,\n+ *                 and the second element should be a literal string for the method name,\n+ *                 and the remaining are input arguments to the Java method.\n+ */\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(class,method[,arg1[,arg2..]]) calls method with reflection\",\n+  extended = \"> SELECT _FUNC_('java.util.UUID', 'randomUUID');\\nc33fb387-8500-4bfa-81d2-6e0e3e930df2\")\n+// scalastyle:on line.size.limit\n+case class JavaMethodReflect(children: Seq[Expression])\n+  extends Expression with CodegenFallback {\n+  import JavaMethodReflect._\n+\n+  override def prettyName: String = \"reflect\"\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    if (children.size < 2) {\n+      TypeCheckFailure(\"requires at least two arguments\")\n+    } else if (!children.take(2).forall(e => e.dataType == StringType && e.foldable)) {\n+      // The first two arguments must be string type.\n+      TypeCheckFailure(\"first two arguments should be string literals\")\n+    } else if (method == null) {\n+      TypeCheckFailure(\"cannot find a method that matches the argument types\")\n+    } else {\n+      TypeCheckSuccess\n+    }\n+  }\n+\n+  override def deterministic: Boolean = false\n+  override def nullable: Boolean = true\n+  override val dataType: DataType = StringType\n+\n+  override def eval(input: InternalRow): Any = {\n+    var i = 0\n+    while (i < argExprs.length) {\n+      buffer(i) = argExprs(i).eval(input).asInstanceOf[Object]\n+      // Convert if necessary. Based on the types defined in typeMapping, string is the only\n+      // type that needs conversion.\n+      if (buffer(i).isInstanceOf[UTF8String]) {\n+        buffer(i) = buffer(i).toString\n+      }\n+      i += 1\n+    }\n+    UTF8String.fromString(String.valueOf(method.invoke(obj, buffer : _*)))\n+  }\n+\n+  @transient private lazy val argExprs: Array[Expression] = children.drop(2).toArray\n+\n+  /** Name of the class -- this has to be called after we verify children has at least two exprs. */\n+  @transient private lazy val className = children(0).eval(null).asInstanceOf[UTF8String].toString\n+\n+  /** The reflection method. */\n+  @transient lazy val method: Method = {\n+    val methodName = children(1).eval(null).asInstanceOf[UTF8String].toString\n+    findMethod(className, methodName, argExprs.map(_.dataType)).orNull\n+  }\n+\n+  /** If the class has a no-arg ctor, instantiate the object. Otherwise, obj is null. */\n+  @transient private lazy val obj: Object = instantiate(className).orNull.asInstanceOf[Object]\n+\n+  /** A temporary buffer used to hold intermediate results returned by children. */\n+  @transient private lazy val buffer = new Array[Object](argExprs.length)\n+}\n+\n+object JavaMethodReflect {\n+  /** Mapping from Spark's type to acceptable JVM types. */\n+  val typeMapping = Map[DataType, Seq[Class[_]]](\n+    BooleanType -> Seq(classOf[java.lang.Boolean], classOf[Boolean]),\n+    ByteType -> Seq(classOf[java.lang.Byte], classOf[Byte]),\n+    ShortType -> Seq(classOf[java.lang.Short], classOf[Short]),\n+    IntegerType -> Seq(classOf[java.lang.Integer], classOf[Int]),\n+    LongType -> Seq(classOf[java.lang.Long], classOf[Long]),\n+    FloatType -> Seq(classOf[java.lang.Float], classOf[Float]),\n+    DoubleType -> Seq(classOf[java.lang.Double], classOf[Double]),\n+    StringType -> Seq(classOf[String])\n+  )\n+\n+  /**\n+   * Finds a Java method using reflection that matches the given argument types,\n+   * and whose return type is string.\n+   *\n+   * The types sequence must be the valid types defined in [[typeMapping]].\n+   *\n+   * This is made public for unit testing.\n+   */\n+  def findMethod(className: String, methodName: String, argTypes: Seq[DataType]): Option[Method] = {\n+    val clazz: Class[_] = Utils.classForName(className)"
  }],
  "prId": 13969
}]