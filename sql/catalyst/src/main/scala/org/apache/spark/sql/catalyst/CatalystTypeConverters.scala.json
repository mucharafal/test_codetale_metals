[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "should we support both java and scala big integer?\n",
    "commit": "3b4e3608b2c4eb69940ceb1a4949b97814534b51",
    "createdAt": "2015-12-15T02:02:02Z",
    "diffHunk": "@@ -326,6 +326,7 @@ object CatalystTypeConverters {\n       val decimal = scalaValue match {\n         case d: BigDecimal => Decimal(d)\n         case d: JavaBigDecimal => Decimal(d)\n+        case d: BigInteger => Decimal(d)"
  }, {
    "author": {
      "login": "kevinyu98"
    },
    "body": "Hi Wenchen: Sure, I will add that.\n",
    "commit": "3b4e3608b2c4eb69940ceb1a4949b97814534b51",
    "createdAt": "2015-12-17T03:56:21Z",
    "diffHunk": "@@ -326,6 +326,7 @@ object CatalystTypeConverters {\n       val decimal = scalaValue match {\n         case d: BigDecimal => Decimal(d)\n         case d: JavaBigDecimal => Decimal(d)\n+        case d: BigInteger => Decimal(d)"
  }],
  "prId": 10125
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "Why change this file? I think we should use encoders most of the time.\n",
    "commit": "3b4e3608b2c4eb69940ceb1a4949b97814534b51",
    "createdAt": "2016-05-14T13:38:43Z",
    "diffHunk": "@@ -321,11 +323,13 @@ object CatalystTypeConverters {\n   }\n \n   private class DecimalConverter(dataType: DecimalType)\n-    extends CatalystTypeConverter[Any, JavaBigDecimal, Decimal] {\n+  extends CatalystTypeConverter[Any, JavaBigDecimal, Decimal] {"
  }, {
    "author": {
      "login": "kevinyu98"
    },
    "body": "sure, I will take this out. Thanks.\n",
    "commit": "3b4e3608b2c4eb69940ceb1a4949b97814534b51",
    "createdAt": "2016-05-17T21:33:10Z",
    "diffHunk": "@@ -321,11 +323,13 @@ object CatalystTypeConverters {\n   }\n \n   private class DecimalConverter(dataType: DecimalType)\n-    extends CatalystTypeConverter[Any, JavaBigDecimal, Decimal] {\n+  extends CatalystTypeConverter[Any, JavaBigDecimal, Decimal] {"
  }, {
    "author": {
      "login": "kevinyu98"
    },
    "body": "Hello Wenchen: I have to keep case d: JavaBigInteger => Decimal(d) there, otherwise, this testcase will fail with the java.math.BigInteger.\n\n@Test\n  public void testCreateDataFrameFromLocalJavaBeans() {\n    Bean bean = new Bean();\n    List<Bean> data = Arrays.asList(bean);\n    Dataset<Row> df = spark.createDataFrame(data, Bean.class);\n    validateDataFrameWithBeans(bean, df);\n  }\nhere is the trace\n\nscala.MatchError: 1234567 (of class java.math.BigInteger)\n    at org.apache.spark.sql.catalyst.CatalystTypeConverters$DecimalConverter.toCatalystImpl(CatalystTypeConverters.scala:326)\n    at org.apache.spark.sql.catalyst.CatalystTypeConverters$DecimalConverter.toCatalystImpl(CatalystTypeConverters.scala:323)\n    at org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)\n    at org.apache.spark.sql.catalyst.CatalystTypeConverters$$anonfun$createToCatalystConverter$2.apply(CatalystTypeConverters.scala:401)\n    at org.apache.spark.sql.SQLContext$$anonfun$beansToRows$1$$anonfun$apply$1.apply(SQLContext.scala:892)\n    at org.apache.spark.sql.SQLContext$$anonfun$beansToRows$1$$anonfun$apply$1.apply(SQLContext.scala:892)\n    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n    at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n    at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n    at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n    at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)\n    at org.apache.spark.sql.SQLContext$$anonfun$beansToRows$1.apply(SQLContext.scala:892)\n    at org.apache.spark.sql.SQLContext$$anonfun$beansToRows$1.apply(SQLContext.scala:890)\n    at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n    at scala.collection.Iterator$class.toStream(Iterator.scala:1322)\n    at scala.collection.AbstractIterator.toStream(Iterator.scala:1336)\n    at scala.collection.TraversableOnce$class.toSeq(TraversableOnce.scala:298)\n    at scala.collection.AbstractIterator.toSeq(Iterator.scala:1336)\n    at org.apache.spark.sql.SparkSession.createDataFrame(SparkSession.scala:373)\n    at test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromLocalJavaBeans(JavaDataFrameSuite.java:200)\n",
    "commit": "3b4e3608b2c4eb69940ceb1a4949b97814534b51",
    "createdAt": "2016-05-18T07:13:57Z",
    "diffHunk": "@@ -321,11 +323,13 @@ object CatalystTypeConverters {\n   }\n \n   private class DecimalConverter(dataType: DecimalType)\n-    extends CatalystTypeConverter[Any, JavaBigDecimal, Decimal] {\n+  extends CatalystTypeConverter[Any, JavaBigDecimal, Decimal] {"
  }],
  "prId": 10125
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "Can you hold on until https://github.com/apache/spark/pull/13008? Then we can revert this change as `CatalystTypeConverter` is not used when creating DataFrame.\n",
    "commit": "3b4e3608b2c4eb69940ceb1a4949b97814534b51",
    "createdAt": "2016-05-18T14:22:34Z",
    "diffHunk": "@@ -326,6 +327,7 @@ object CatalystTypeConverters {\n       val decimal = scalaValue match {\n         case d: BigDecimal => Decimal(d)\n         case d: JavaBigDecimal => Decimal(d)\n+        case d: JavaBigInteger => Decimal(d)",
    "line": 12
  }],
  "prId": 10125
}]