[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "`$leftName` -> `'$leftName'`",
    "commit": "f4892c95673cfb64459fbf7535d0ad1cf24bfb48",
    "createdAt": "2017-06-13T06:26:20Z",
    "diffHunk": "@@ -469,9 +469,16 @@ object StructType extends AbstractDataType {\n           case leftField @ StructField(leftName, leftType, leftNullable, _) =>\n             rightMapped.get(leftName)\n               .map { case rightField @ StructField(_, rightType, rightNullable, _) =>\n-                leftField.copy(\n-                  dataType = merge(leftType, rightType),\n-                  nullable = leftNullable || rightNullable)\n+                Try {\n+                  merge(leftType, rightType)\n+                } match {\n+                  case Success(dataType) =>\n+                    leftField.copy(\n+                      dataType = dataType,\n+                      nullable = leftNullable || rightNullable)\n+                  case Failure(e) =>\n+                    throw new SparkException(s\"Failed to merge field $leftName: \" + e.getMessage)"
  }],
  "prId": 16365
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Could we use the JAVA style `try` and `catch`? See the https://github.com/databricks/scala-style-guide#exception-handling-try-vs-try\r\n\r\n",
    "commit": "f4892c95673cfb64459fbf7535d0ad1cf24bfb48",
    "createdAt": "2017-07-31T02:05:56Z",
    "diffHunk": "@@ -469,9 +469,16 @@ object StructType extends AbstractDataType {\n           case leftField @ StructField(leftName, leftType, leftNullable, _) =>\n             rightMapped.get(leftName)\n               .map { case rightField @ StructField(_, rightType, rightNullable, _) =>\n-                leftField.copy(\n-                  dataType = merge(leftType, rightType),\n-                  nullable = leftNullable || rightNullable)\n+                Try {"
  }],
  "prId": 16365
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Could we throw an `AnalysisException` with both sides, `left` and `right`? Thanks!",
    "commit": "f4892c95673cfb64459fbf7535d0ad1cf24bfb48",
    "createdAt": "2017-07-31T02:07:08Z",
    "diffHunk": "@@ -469,9 +469,16 @@ object StructType extends AbstractDataType {\n           case leftField @ StructField(leftName, leftType, leftNullable, _) =>\n             rightMapped.get(leftName)\n               .map { case rightField @ StructField(_, rightType, rightNullable, _) =>\n-                leftField.copy(\n-                  dataType = merge(leftType, rightType),\n-                  nullable = leftNullable || rightNullable)\n+                Try {\n+                  merge(leftType, rightType)\n+                } match {\n+                  case Success(dataType) =>\n+                    leftField.copy(\n+                      dataType = dataType,\n+                      nullable = leftNullable || rightNullable)\n+                  case Failure(e) =>\n+                    throw new SparkException(s\"Failed to merge field '$leftName': \" + e.getMessage)"
  }, {
    "author": {
      "login": "jiayue-zhang"
    },
    "body": "Other exceptions in this class are also SparkException, for example the precision conflicts. Should we keep it as SparkException?\r\nFor \"with both sides, `left` and `right`\", do you mean just to modify the message a bit to include both left and right names(though they are the same)?\r\n@gatorsmile your other comments are resolved.",
    "commit": "f4892c95673cfb64459fbf7535d0ad1cf24bfb48",
    "createdAt": "2017-07-31T19:01:06Z",
    "diffHunk": "@@ -469,9 +469,16 @@ object StructType extends AbstractDataType {\n           case leftField @ StructField(leftName, leftType, leftNullable, _) =>\n             rightMapped.get(leftName)\n               .map { case rightField @ StructField(_, rightType, rightNullable, _) =>\n-                leftField.copy(\n-                  dataType = merge(leftType, rightType),\n-                  nullable = leftNullable || rightNullable)\n+                Try {\n+                  merge(leftType, rightType)\n+                } match {\n+                  case Success(dataType) =>\n+                    leftField.copy(\n+                      dataType = dataType,\n+                      nullable = leftNullable || rightNullable)\n+                  case Failure(e) =>\n+                    throw new SparkException(s\"Failed to merge field '$leftName': \" + e.getMessage)"
  }],
  "prId": 16365
}]