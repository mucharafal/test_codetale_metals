[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "order the imports \n",
    "commit": "227e89ef5b5c523a3a99e098ab5dec407f10e377",
    "createdAt": "2014-06-07T06:21:51Z",
    "diffHunk": "@@ -17,8 +17,56 @@\n \n package org.apache.spark.sql.catalyst\n \n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.types.{StructField, DataType, ArrayType, StructType}"
  }],
  "prId": 999
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "put attribute on the previous line to reduce indenting, i.e.\n\n``` scala\nschema.foreach { attribute =>\n\n}\n```\n\n(also reduced one level of curly braces)\n",
    "commit": "227e89ef5b5c523a3a99e098ab5dec407f10e377",
    "createdAt": "2014-06-07T06:22:40Z",
    "diffHunk": "@@ -17,8 +17,56 @@\n \n package org.apache.spark.sql.catalyst\n \n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.types.{StructField, DataType, ArrayType, StructType}\n+\n /**\n  * A a collection of common abstractions for query plans as well as\n  * a base logical plan representation.\n  */\n-package object plans\n+package object plans {\n+  def generateSchemaTreeString(schema: Seq[Attribute]): String = {\n+    val builder = new StringBuilder\n+    builder.append(\"root\\n\")\n+    val prefix = \" |\"\n+    schema.foreach {\n+      attribute => {"
  }],
  "prId": 999
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "mark this private?\n",
    "commit": "227e89ef5b5c523a3a99e098ab5dec407f10e377",
    "createdAt": "2014-06-07T06:23:22Z",
    "diffHunk": "@@ -17,8 +17,56 @@\n \n package org.apache.spark.sql.catalyst\n \n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.types.{StructField, DataType, ArrayType, StructType}\n+\n /**\n  * A a collection of common abstractions for query plans as well as\n  * a base logical plan representation.\n  */\n-package object plans\n+package object plans {\n+  def generateSchemaTreeString(schema: Seq[Attribute]): String = {\n+    val builder = new StringBuilder\n+    builder.append(\"root\\n\")\n+    val prefix = \" |\"\n+    schema.foreach {\n+      attribute => {\n+        val name = attribute.name\n+        val dataType = attribute.dataType\n+        dataType match {\n+          case fields: StructType =>\n+            builder.append(s\"$prefix-- $name: $StructType\\n\")\n+            generateSchemaTreeString(fields, s\"$prefix    |\", builder)\n+          case ArrayType(fields: StructType) =>\n+            builder.append(s\"$prefix-- $name: $ArrayType[$StructType]\\n\")\n+            generateSchemaTreeString(fields, s\"$prefix    |\", builder)\n+          case ArrayType(elementType: DataType) =>\n+            builder.append(s\"$prefix-- $name: $ArrayType[$elementType]\\n\")\n+          case _ => builder.append(s\"$prefix-- $name: $dataType\\n\")\n+        }\n+      }\n+    }\n+\n+    builder.toString()\n+  }\n+\n+  def generateSchemaTreeString("
  }],
  "prId": 999
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "mark this as private[sql]? or private[spark]\n",
    "commit": "227e89ef5b5c523a3a99e098ab5dec407f10e377",
    "createdAt": "2014-06-07T06:23:41Z",
    "diffHunk": "@@ -17,8 +17,56 @@\n \n package org.apache.spark.sql.catalyst\n \n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.types.{StructField, DataType, ArrayType, StructType}\n+\n /**\n  * A a collection of common abstractions for query plans as well as\n  * a base logical plan representation.\n  */\n-package object plans\n+package object plans {\n+  def generateSchemaTreeString(schema: Seq[Attribute]): String = {"
  }, {
    "author": {
      "login": "marmbrus"
    },
    "body": "We don't mark any of catalyst as private.  We just don't include any of the scala doc in the default spark distribution.\n",
    "commit": "227e89ef5b5c523a3a99e098ab5dec407f10e377",
    "createdAt": "2014-06-07T17:13:37Z",
    "diffHunk": "@@ -17,8 +17,56 @@\n \n package org.apache.spark.sql.catalyst\n \n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.types.{StructField, DataType, ArrayType, StructType}\n+\n /**\n  * A a collection of common abstractions for query plans as well as\n  * a base logical plan representation.\n  */\n-package object plans\n+package object plans {\n+  def generateSchemaTreeString(schema: Seq[Attribute]): String = {"
  }],
  "prId": 999
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "is this only used in QueryPlan?  If so, maybe is should just live there as a protected method.\n",
    "commit": "227e89ef5b5c523a3a99e098ab5dec407f10e377",
    "createdAt": "2014-06-16T20:27:58Z",
    "diffHunk": "@@ -17,8 +17,55 @@\n \n package org.apache.spark.sql.catalyst\n \n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.types.{ArrayType, DataType, StructField, StructType}\n+\n /**\n  * A a collection of common abstractions for query plans as well as\n  * a base logical plan representation.\n  */\n-package object plans\n+package object plans {\n+\n+  def generateSchemaTreeString(schema: Seq[Attribute]): String = {"
  }],
  "prId": 999
}]