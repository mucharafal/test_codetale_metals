[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Can we use `def ignoreSchemaMatch: Boolean = false` because we have only one instance and it's negative form.\r\n```scala\r\n- !table.requireSchemaMatch || {\r\n+ table.ignoreSchemaMatch || {\r\n```\r\n\r\n\r\n",
    "commit": "15a02f6549c2cbd786d4a8c38a77cc030881da11",
    "createdAt": "2019-04-30T04:12:16Z",
    "diffHunk": "@@ -21,4 +21,7 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n \n trait NamedRelation extends LogicalPlan {\n   def name: String\n+\n+  // When true, the schema of input data must match the schema of this relation, during write.\n+  def requireSchemaMatch: Boolean = true"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "`ignoreSchemaMatch` sounds a little weird. I don't have a strong opinion about negative form vs positive form, but the naming must be precise here.",
    "commit": "15a02f6549c2cbd786d4a8c38a77cc030881da11",
    "createdAt": "2019-04-30T12:38:22Z",
    "diffHunk": "@@ -21,4 +21,7 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n \n trait NamedRelation extends LogicalPlan {\n   def name: String\n+\n+  // When true, the schema of input data must match the schema of this relation, during write.\n+  def requireSchemaMatch: Boolean = true"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "I agree that the \"ignore\" form is better.\r\n\r\nI don't think that the term \"schema match\" is clear though, because it is not obvious what \"match\" means. What about `skipSchemaResolution` or `skipSchemaValidation`?",
    "commit": "15a02f6549c2cbd786d4a8c38a77cc030881da11",
    "createdAt": "2019-05-01T16:11:25Z",
    "diffHunk": "@@ -21,4 +21,7 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n \n trait NamedRelation extends LogicalPlan {\n   def name: String\n+\n+  // When true, the schema of input data must match the schema of this relation, during write.\n+  def requireSchemaMatch: Boolean = true"
  }],
  "prId": 24469
}, {
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "Separate from the discussion about the method name, I don't think it makes sense for this to be in `NamedRelation`.\r\n\r\n`NamedRelation` exists to help create better error messages from the generic rules that apply across any relation. This addition doesn't fit with that purpose. I think the reason why this was added to `NamedRelation` is because the v2 relation class is not available to catalyst, but this rule is in catalyst. If that's the case, then this depends on moving v2 into catalyst and I think it makes sense to do that first.",
    "commit": "15a02f6549c2cbd786d4a8c38a77cc030881da11",
    "createdAt": "2019-05-01T16:24:47Z",
    "diffHunk": "@@ -21,4 +21,7 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n \n trait NamedRelation extends LogicalPlan {\n   def name: String\n+\n+  // When true, the schema of input data must match the schema of this relation, during write.\n+  def requireSchemaMatch: Boolean = true"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "Moving DS v2 to catalyst module should be done soon, we can wait for it. BTW do we still need `NamedRelation` after that? It looks to me that `NamedRelation` is mostly for testing. Currently only the v2 relation class extends it.",
    "commit": "15a02f6549c2cbd786d4a8c38a77cc030881da11",
    "createdAt": "2019-05-06T07:41:59Z",
    "diffHunk": "@@ -21,4 +21,7 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n \n trait NamedRelation extends LogicalPlan {\n   def name: String\n+\n+  // When true, the schema of input data must match the schema of this relation, during write.\n+  def requireSchemaMatch: Boolean = true"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "We probably don't need it any more.",
    "commit": "15a02f6549c2cbd786d4a8c38a77cc030881da11",
    "createdAt": "2019-05-06T20:42:31Z",
    "diffHunk": "@@ -21,4 +21,7 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n \n trait NamedRelation extends LogicalPlan {\n   def name: String\n+\n+  // When true, the schema of input data must match the schema of this relation, during write.\n+  def requireSchemaMatch: Boolean = true"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "@cloud-fan, we may want to keep `NamedRelation` to be able to use `UnresolvedRelation` in v2 plans. If we updated `AppendData` (for example) to use `DataSourceV2Relation`, then we would not be able to create it with an `UnresolvedRelation` and delegate resolving the table to the analyzer.",
    "commit": "15a02f6549c2cbd786d4a8c38a77cc030881da11",
    "createdAt": "2019-05-15T23:48:52Z",
    "diffHunk": "@@ -21,4 +21,7 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n \n trait NamedRelation extends LogicalPlan {\n   def name: String\n+\n+  // When true, the schema of input data must match the schema of this relation, during write.\n+  def requireSchemaMatch: Boolean = true"
  }],
  "prId": 24469
}]