[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "`DefaultRange` -> `DefaultValueInterval `",
    "commit": "b51ab80a68f2d528911d82a244b6ba5e9169b29c",
    "createdAt": "2017-07-06T04:56:28Z",
    "diffHunk": "@@ -38,46 +38,49 @@ case class NumericRange(min: Decimal, max: Decimal) extends Range {\n  * This version of Spark does not have min/max for binary/string types, we define their default\n  * behaviors by this class.\n  */\n-class DefaultRange extends Range {\n+class DefaultValueInterval extends ValueInterval {\n   override def contains(l: Literal): Boolean = true\n }\n \n /** This is for columns with only null values. */\n-class NullRange extends Range {\n+class NullValueInterval extends ValueInterval {\n   override def contains(l: Literal): Boolean = false\n }\n \n-object Range {\n-  def apply(min: Option[Any], max: Option[Any], dataType: DataType): Range = dataType match {\n-    case StringType | BinaryType => new DefaultRange()\n-    case _ if min.isEmpty || max.isEmpty => new NullRange()\n+object ValueInterval {\n+  def apply(\n+      min: Option[Any],\n+      max: Option[Any],\n+      dataType: DataType): ValueInterval = dataType match {\n+    case StringType | BinaryType => new DefaultValueInterval()\n+    case _ if min.isEmpty || max.isEmpty => new NullValueInterval()\n     case _ =>\n-      NumericRange(\n+      NumericValueInterval(\n         min = EstimationUtils.toDecimal(min.get, dataType),\n         max = EstimationUtils.toDecimal(max.get, dataType))\n   }\n \n-  def isIntersected(r1: Range, r2: Range): Boolean = (r1, r2) match {\n-    case (_, _: DefaultRange) | (_: DefaultRange, _) =>\n+  def isIntersected(r1: ValueInterval, r2: ValueInterval): Boolean = (r1, r2) match {\n+    case (_, _: DefaultValueInterval) | (_: DefaultValueInterval, _) =>\n       // The DefaultRange represents string/binary types which do not have max/min stats,"
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "Thanks, I have fixed it",
    "commit": "b51ab80a68f2d528911d82a244b6ba5e9169b29c",
    "createdAt": "2017-07-06T05:02:19Z",
    "diffHunk": "@@ -38,46 +38,49 @@ case class NumericRange(min: Decimal, max: Decimal) extends Range {\n  * This version of Spark does not have min/max for binary/string types, we define their default\n  * behaviors by this class.\n  */\n-class DefaultRange extends Range {\n+class DefaultValueInterval extends ValueInterval {\n   override def contains(l: Literal): Boolean = true\n }\n \n /** This is for columns with only null values. */\n-class NullRange extends Range {\n+class NullValueInterval extends ValueInterval {\n   override def contains(l: Literal): Boolean = false\n }\n \n-object Range {\n-  def apply(min: Option[Any], max: Option[Any], dataType: DataType): Range = dataType match {\n-    case StringType | BinaryType => new DefaultRange()\n-    case _ if min.isEmpty || max.isEmpty => new NullRange()\n+object ValueInterval {\n+  def apply(\n+      min: Option[Any],\n+      max: Option[Any],\n+      dataType: DataType): ValueInterval = dataType match {\n+    case StringType | BinaryType => new DefaultValueInterval()\n+    case _ if min.isEmpty || max.isEmpty => new NullValueInterval()\n     case _ =>\n-      NumericRange(\n+      NumericValueInterval(\n         min = EstimationUtils.toDecimal(min.get, dataType),\n         max = EstimationUtils.toDecimal(max.get, dataType))\n   }\n \n-  def isIntersected(r1: Range, r2: Range): Boolean = (r1, r2) match {\n-    case (_, _: DefaultRange) | (_: DefaultRange, _) =>\n+  def isIntersected(r1: ValueInterval, r2: ValueInterval): Boolean = (r1, r2) match {\n+    case (_, _: DefaultValueInterval) | (_: DefaultValueInterval, _) =>\n       // The DefaultRange represents string/binary types which do not have max/min stats,"
  }],
  "prId": 18549
}]