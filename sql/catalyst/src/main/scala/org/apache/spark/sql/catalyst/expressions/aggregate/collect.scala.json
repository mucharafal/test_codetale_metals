[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Is `collect_set` non deterministic? It is backed by a `HashSet`, and the way elements are iterated over does not rely on the input order. \n",
    "commit": "00451281622226dc09d02f6ea454b29e6a7b5999",
    "createdAt": "2016-08-22T15:28:59Z",
    "diffHunk": "@@ -54,6 +54,10 @@ abstract class Collect extends ImperativeAggregate {\n \n   override def inputAggBufferAttributes: Seq[AttributeReference] = Nil\n \n+  // Both `CollectList` and `CollectSet` are non-deterministic since their results depend on the\n+  // actual order of input rows.\n+  override def deterministic: Boolean = false",
    "line": 6
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "NVM. Actually iteration over a set is non-deterministic for values in the same hash bucket.\n",
    "commit": "00451281622226dc09d02f6ea454b29e6a7b5999",
    "createdAt": "2016-08-22T21:59:58Z",
    "diffHunk": "@@ -54,6 +54,10 @@ abstract class Collect extends ImperativeAggregate {\n \n   override def inputAggBufferAttributes: Seq[AttributeReference] = Nil\n \n+  // Both `CollectList` and `CollectSet` are non-deterministic since their results depend on the\n+  // actual order of input rows.\n+  override def deterministic: Boolean = false",
    "line": 6
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "Yea. Also, there's no set type in Spark SQL, thus the result set is actually just a list without duplicated elements.\n",
    "commit": "00451281622226dc09d02f6ea454b29e6a7b5999",
    "createdAt": "2016-08-23T00:17:34Z",
    "diffHunk": "@@ -54,6 +54,10 @@ abstract class Collect extends ImperativeAggregate {\n \n   override def inputAggBufferAttributes: Seq[AttributeReference] = Nil\n \n+  // Both `CollectList` and `CollectSet` are non-deterministic since their results depend on the\n+  // actual order of input rows.\n+  override def deterministic: Boolean = false",
    "line": 6
  }],
  "prId": 14749
}]