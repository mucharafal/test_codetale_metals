[{
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "The extractors allow you to use `FieldReference` instead of `Ref`. The extractor will use `Ref` to match any `NamedReference`, even if it isn't already a `FieldReference`. So no need to make `Ref` public.",
    "commit": "b7a5ac549c26153a3aa8bf3e73bd415929a78a1f",
    "createdAt": "2019-07-31T22:55:59Z",
    "diffHunk": "@@ -88,4 +91,147 @@ private[spark] object SchemaUtils {\n         s\"Found duplicate column(s) $colType: ${duplicateColumns.mkString(\", \")}\")\n     }\n   }\n+\n+  /**\n+   * Returns all column names in this schema as a flat list. For example, a schema like:\n+   *   | - a\n+   *   | | - 1\n+   *   | | - 2\n+   *   | - b\n+   *   | - c\n+   *   | | - nest\n+   *   |   | - 3\n+   *   will get flattened to: \"a\", \"a.1\", \"a.2\", \"b\", \"c\", \"c.nest\", \"c.nest.3\"\n+   */\n+  def explodeNestedFieldNames(schema: StructType): Seq[String] = {\n+    def explode(schema: StructType): Seq[Seq[String]] = {\n+      def recurseIntoComplexTypes(complexType: DataType): Seq[Seq[String]] = {\n+        complexType match {\n+          case s: StructType => explode(s)\n+          case a: ArrayType => recurseIntoComplexTypes(a.elementType)\n+          case m: MapType =>\n+            recurseIntoComplexTypes(m.keyType).map(Seq(\"key\") ++ _) ++\n+              recurseIntoComplexTypes(m.valueType).map(Seq(\"value\") ++ _)\n+          case _ => Nil\n+        }\n+      }\n+\n+      schema.flatMap {\n+        case StructField(name, s: StructType, _, _) =>\n+          Seq(Seq(name)) ++ explode(s).map(nested => Seq(name) ++ nested)\n+        case StructField(name, a: ArrayType, _, _) =>\n+          Seq(Seq(name)) ++ recurseIntoComplexTypes(a).map(nested => Seq(name) ++ nested)\n+        case StructField(name, m: MapType, _, _) =>\n+          Seq(Seq(name)) ++ recurseIntoComplexTypes(m).map(nested => Seq(name) ++ nested)\n+        case f => Seq(f.name) :: Nil\n+      }\n+    }\n+\n+    explode(schema).map(UnresolvedAttribute.apply(_).name)\n+  }\n+\n+  /**\n+   * Checks if input column names have duplicate identifiers even in if they are nested. This\n+   * throws an exception if the duplication exists.\n+   *\n+   * @param schema the schema to check for duplicates\n+   * @param checkType contextual information around the check, used in an exception message\n+   * @param isCaseSensitive Whether to be case sensitive when comparing column names\n+   */\n+  def checkV2ColumnNameDuplication(\n+      schema: StructType,\n+      checkType: String,\n+      isCaseSensitive: Boolean): Unit = {\n+    val columnNames = explodeNestedFieldNames(schema)\n+    checkColumnNameDuplication(columnNames, checkType, isCaseSensitive)\n+  }\n+\n+  /**\n+   * Checks if the partitioning transforms are being duplicated or not. Throws an exception if\n+   * duplication exists.\n+   *\n+   * @param transforms the schema to check for duplicates\n+   * @param checkType contextual information around the check, used in an exception message\n+   * @param isCaseSensitive Whether to be case sensitive when comparing column names\n+   */\n+  def checkTransformDuplication(\n+      transforms: Seq[Transform],\n+      checkType: String,\n+      isCaseSensitive: Boolean): Unit = {\n+    val extractedTransforms = transforms.map {\n+      case b: BucketTransform =>\n+        val colNames = b.columns.map(c => UnresolvedAttribute(c.fieldNames()).name)\n+        // We need to check that we're not duplicating columns within our bucketing transform\n+        checkColumnNameDuplication(colNames, checkType, isCaseSensitive)\n+        b.name -> colNames\n+      case NamedTransform(transformName, refs) =>\n+        val fieldNameParts = refs.collect { case Ref(parts) => UnresolvedAttribute(parts).name }"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "See the tests here: https://github.com/apache/spark/blob/master/sql/catalyst/src/test/scala/org/apache/spark/sql/catalog/v2/expressions/TransformExtractorSuite.scala#L101-L106",
    "commit": "b7a5ac549c26153a3aa8bf3e73bd415929a78a1f",
    "createdAt": "2019-07-31T22:56:32Z",
    "diffHunk": "@@ -88,4 +91,147 @@ private[spark] object SchemaUtils {\n         s\"Found duplicate column(s) $colType: ${duplicateColumns.mkString(\", \")}\")\n     }\n   }\n+\n+  /**\n+   * Returns all column names in this schema as a flat list. For example, a schema like:\n+   *   | - a\n+   *   | | - 1\n+   *   | | - 2\n+   *   | - b\n+   *   | - c\n+   *   | | - nest\n+   *   |   | - 3\n+   *   will get flattened to: \"a\", \"a.1\", \"a.2\", \"b\", \"c\", \"c.nest\", \"c.nest.3\"\n+   */\n+  def explodeNestedFieldNames(schema: StructType): Seq[String] = {\n+    def explode(schema: StructType): Seq[Seq[String]] = {\n+      def recurseIntoComplexTypes(complexType: DataType): Seq[Seq[String]] = {\n+        complexType match {\n+          case s: StructType => explode(s)\n+          case a: ArrayType => recurseIntoComplexTypes(a.elementType)\n+          case m: MapType =>\n+            recurseIntoComplexTypes(m.keyType).map(Seq(\"key\") ++ _) ++\n+              recurseIntoComplexTypes(m.valueType).map(Seq(\"value\") ++ _)\n+          case _ => Nil\n+        }\n+      }\n+\n+      schema.flatMap {\n+        case StructField(name, s: StructType, _, _) =>\n+          Seq(Seq(name)) ++ explode(s).map(nested => Seq(name) ++ nested)\n+        case StructField(name, a: ArrayType, _, _) =>\n+          Seq(Seq(name)) ++ recurseIntoComplexTypes(a).map(nested => Seq(name) ++ nested)\n+        case StructField(name, m: MapType, _, _) =>\n+          Seq(Seq(name)) ++ recurseIntoComplexTypes(m).map(nested => Seq(name) ++ nested)\n+        case f => Seq(f.name) :: Nil\n+      }\n+    }\n+\n+    explode(schema).map(UnresolvedAttribute.apply(_).name)\n+  }\n+\n+  /**\n+   * Checks if input column names have duplicate identifiers even in if they are nested. This\n+   * throws an exception if the duplication exists.\n+   *\n+   * @param schema the schema to check for duplicates\n+   * @param checkType contextual information around the check, used in an exception message\n+   * @param isCaseSensitive Whether to be case sensitive when comparing column names\n+   */\n+  def checkV2ColumnNameDuplication(\n+      schema: StructType,\n+      checkType: String,\n+      isCaseSensitive: Boolean): Unit = {\n+    val columnNames = explodeNestedFieldNames(schema)\n+    checkColumnNameDuplication(columnNames, checkType, isCaseSensitive)\n+  }\n+\n+  /**\n+   * Checks if the partitioning transforms are being duplicated or not. Throws an exception if\n+   * duplication exists.\n+   *\n+   * @param transforms the schema to check for duplicates\n+   * @param checkType contextual information around the check, used in an exception message\n+   * @param isCaseSensitive Whether to be case sensitive when comparing column names\n+   */\n+  def checkTransformDuplication(\n+      transforms: Seq[Transform],\n+      checkType: String,\n+      isCaseSensitive: Boolean): Unit = {\n+    val extractedTransforms = transforms.map {\n+      case b: BucketTransform =>\n+        val colNames = b.columns.map(c => UnresolvedAttribute(c.fieldNames()).name)\n+        // We need to check that we're not duplicating columns within our bucketing transform\n+        checkColumnNameDuplication(colNames, checkType, isCaseSensitive)\n+        b.name -> colNames\n+      case NamedTransform(transformName, refs) =>\n+        val fieldNameParts = refs.collect { case Ref(parts) => UnresolvedAttribute(parts).name }"
  }],
  "prId": 25305
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit: in other places of the code base we always use `toLowerCase(Locale.ROOT)`",
    "commit": "b7a5ac549c26153a3aa8bf3e73bd415929a78a1f",
    "createdAt": "2019-08-07T07:55:47Z",
    "diffHunk": "@@ -88,4 +91,170 @@ private[spark] object SchemaUtils {\n         s\"Found duplicate column(s) $colType: ${duplicateColumns.mkString(\", \")}\")\n     }\n   }\n+\n+  /**\n+   * Returns all column names in this schema as a flat list. For example, a schema like:\n+   *   | - a\n+   *   | | - 1\n+   *   | | - 2\n+   *   | - b\n+   *   | - c\n+   *   | | - nest\n+   *   |   | - 3\n+   *   will get flattened to: \"a\", \"a.1\", \"a.2\", \"b\", \"c\", \"c.nest\", \"c.nest.3\"\n+   */\n+  def explodeNestedFieldNames(schema: StructType): Seq[String] = {\n+    def explode(schema: StructType): Seq[Seq[String]] = {\n+      def recurseIntoComplexTypes(complexType: DataType): Seq[Seq[String]] = {\n+        complexType match {\n+          case s: StructType => explode(s)\n+          case a: ArrayType => recurseIntoComplexTypes(a.elementType)\n+          case m: MapType =>\n+            recurseIntoComplexTypes(m.keyType).map(Seq(\"key\") ++ _) ++\n+              recurseIntoComplexTypes(m.valueType).map(Seq(\"value\") ++ _)\n+          case _ => Nil\n+        }\n+      }\n+\n+      schema.flatMap {\n+        case StructField(name, s: StructType, _, _) =>\n+          Seq(Seq(name)) ++ explode(s).map(nested => Seq(name) ++ nested)\n+        case StructField(name, a: ArrayType, _, _) =>\n+          Seq(Seq(name)) ++ recurseIntoComplexTypes(a).map(nested => Seq(name) ++ nested)\n+        case StructField(name, m: MapType, _, _) =>\n+          Seq(Seq(name)) ++ recurseIntoComplexTypes(m).map(nested => Seq(name) ++ nested)\n+        case f => Seq(f.name) :: Nil\n+      }\n+    }\n+\n+    explode(schema).map(UnresolvedAttribute.apply(_).name)\n+  }\n+\n+  /**\n+   * Checks if input column names have duplicate identifiers even in if they are nested. This\n+   * throws an exception if the duplication exists.\n+   *\n+   * @param schema the schema to check for duplicates\n+   * @param checkType contextual information around the check, used in an exception message\n+   * @param isCaseSensitive Whether to be case sensitive when comparing column names\n+   */\n+  def checkV2ColumnNameDuplication(\n+      schema: StructType,\n+      checkType: String,\n+      isCaseSensitive: Boolean): Unit = {\n+    val columnNames = explodeNestedFieldNames(schema)\n+    checkColumnNameDuplication(columnNames, checkType, isCaseSensitive)\n+  }\n+\n+  /**\n+   * Checks if the partitioning transforms are being duplicated or not. Throws an exception if\n+   * duplication exists.\n+   *\n+   * @param transforms the schema to check for duplicates\n+   * @param checkType contextual information around the check, used in an exception message\n+   * @param isCaseSensitive Whether to be case sensitive when comparing column names\n+   */\n+  def checkTransformDuplication(\n+      transforms: Seq[Transform],\n+      checkType: String,\n+      isCaseSensitive: Boolean): Unit = {\n+    val extractedTransforms = transforms.map {\n+      case b: BucketTransform =>\n+        val colNames = b.columns.map(c => UnresolvedAttribute(c.fieldNames()).name)\n+        // We need to check that we're not duplicating columns within our bucketing transform\n+        checkColumnNameDuplication(colNames, \"in the bucket definition\", isCaseSensitive)\n+        b.name -> colNames\n+      case NamedTransform(transformName, refs) =>\n+        val fieldNameParts =\n+          refs.collect { case FieldReference(parts) => UnresolvedAttribute(parts).name }\n+        // We could also check that we're not duplicating column names here as well if\n+        // fieldNameParts.length > 1, but we're specifically not, because certain transforms can\n+        // be defined where this is a legitimate use case.\n+        transformName -> fieldNameParts\n+    }\n+    val normalizedTransforms = if (isCaseSensitive) {\n+      extractedTransforms\n+    } else {\n+      extractedTransforms.map(t => t._1 -> t._2.map(_.toLowerCase(Locale.getDefault)))"
  }],
  "prId": 25305
}, {
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "Nit: wildcard types cause git conflicts and import conflicts because packages are imported, not just classes.",
    "commit": "b7a5ac549c26153a3aa8bf3e73bd415929a78a1f",
    "createdAt": "2019-08-07T23:58:09Z",
    "diffHunk": "@@ -17,9 +17,12 @@\n \n package org.apache.spark.sql.util\n \n+import java.util.Locale\n+\n import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalog.v2.expressions._\n import org.apache.spark.sql.catalyst.analysis._\n-import org.apache.spark.sql.types.StructType\n+import org.apache.spark.sql.types._"
  }],
  "prId": 25305
}]