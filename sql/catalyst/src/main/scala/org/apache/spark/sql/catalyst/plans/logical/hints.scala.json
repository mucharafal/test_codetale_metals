[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "shall we use `Expression` as type?",
    "commit": "7776ae66781961724bbc10a10162bf21d5330d12",
    "createdAt": "2017-05-25T11:33:08Z",
    "diffHunk": "@@ -25,7 +25,7 @@ import org.apache.spark.sql.internal.SQLConf\n  * should be removed This node will be eliminated post analysis.\n  * A pair of (name, parameters).\n  */\n-case class UnresolvedHint(name: String, parameters: Seq[String], child: LogicalPlan)\n+case class UnresolvedHint(name: String, parameters: Seq[Any], child: LogicalPlan)"
  }, {
    "author": {
      "login": "bogdanrdc"
    },
    "body": "If we use Expression then either:\r\n* Dataset.hint parameters should be Expression too, in which case you can't do `df.hint(\"hint\", 1, 2, \"c\")` you'd have to do `df.hint(\"hint\", Literal(1), Literal(2), Literal(\"c\"))` or a shortcut if there is\r\n* Dataset.hint accepts Any but then has to convert Any to Expressions. One problem here is that Seq(1,2,3) can't be converted to Literal. So you have to use `df.hint(\"hint\", Array(1,2,3))`\r\n\r\nThe disadvantage of have Any in UnresolvedHint is that to resolve the hint you have to check both for String and Literal(String) but the API is easier to use.\r\n",
    "commit": "7776ae66781961724bbc10a10162bf21d5330d12",
    "createdAt": "2017-05-26T09:00:53Z",
    "diffHunk": "@@ -25,7 +25,7 @@ import org.apache.spark.sql.internal.SQLConf\n  * should be removed This node will be eliminated post analysis.\n  * A pair of (name, parameters).\n  */\n-case class UnresolvedHint(name: String, parameters: Seq[String], child: LogicalPlan)\n+case class UnresolvedHint(name: String, parameters: Seq[Any], child: LogicalPlan)"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "we can keep `Any` in the API(`df.hint(xxx)`), but use `Expression` in `UnresolvedHint`, what do you think?",
    "commit": "7776ae66781961724bbc10a10162bf21d5330d12",
    "createdAt": "2017-05-26T13:27:06Z",
    "diffHunk": "@@ -25,7 +25,7 @@ import org.apache.spark.sql.internal.SQLConf\n  * should be removed This node will be eliminated post analysis.\n  * A pair of (name, parameters).\n  */\n-case class UnresolvedHint(name: String, parameters: Seq[String], child: LogicalPlan)\n+case class UnresolvedHint(name: String, parameters: Seq[Any], child: LogicalPlan)"
  }, {
    "author": {
      "login": "bogdanrdc"
    },
    "body": "One useful hint parameter is a list of columns.\r\nSomething like `df.hint(\"hint\", $\"table\", Seq($\"col1\", $\"col2\", $\"col3\"))`\r\n\r\nIn this case UnresolvedHint could be called like this:\r\n```UnresolvedHint(name: String, parameters: Seq(Expression, Seq[Expression]), child)```\r\n\r\nBut if `UnresolvedHint.parameters` is `Seq[Expression]` then it's not possible to have this kind of hint.",
    "commit": "7776ae66781961724bbc10a10162bf21d5330d12",
    "createdAt": "2017-05-29T13:47:36Z",
    "diffHunk": "@@ -25,7 +25,7 @@ import org.apache.spark.sql.internal.SQLConf\n  * should be removed This node will be eliminated post analysis.\n  * A pair of (name, parameters).\n  */\n-case class UnresolvedHint(name: String, parameters: Seq[String], child: LogicalPlan)\n+case class UnresolvedHint(name: String, parameters: Seq[Any], child: LogicalPlan)"
  }],
  "prId": 18086
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "This needs an update.",
    "commit": "7776ae66781961724bbc10a10162bf21d5330d12",
    "createdAt": "2017-05-28T03:41:07Z",
    "diffHunk": "@@ -25,7 +25,7 @@ import org.apache.spark.sql.internal.SQLConf\n  * should be removed This node will be eliminated post analysis.\n  * A pair of (name, parameters)."
  }],
  "prId": 18086
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "To support multiple parameters in `hint`, does it make sense to do it like `df.hint(\"hint\", \"1, 2, c\")`? We can use our Parser to parse this parameter string. ",
    "commit": "7776ae66781961724bbc10a10162bf21d5330d12",
    "createdAt": "2017-05-28T03:53:53Z",
    "diffHunk": "@@ -25,7 +25,7 @@ import org.apache.spark.sql.internal.SQLConf\n  * should be removed This node will be eliminated post analysis.\n  * A pair of (name, parameters).\n  */\n-case class UnresolvedHint(name: String, parameters: Seq[String], child: LogicalPlan)\n+case class UnresolvedHint(name: String, parameters: Seq[Any], child: LogicalPlan)"
  }, {
    "author": {
      "login": "bogdanrdc"
    },
    "body": "I think that could be something extra. The DF API should accept scala expressions too: function calls (df.hint(\"hint\", getInterestingValues()))",
    "commit": "7776ae66781961724bbc10a10162bf21d5330d12",
    "createdAt": "2017-05-30T12:32:04Z",
    "diffHunk": "@@ -25,7 +25,7 @@ import org.apache.spark.sql.internal.SQLConf\n  * should be removed This node will be eliminated post analysis.\n  * A pair of (name, parameters).\n  */\n-case class UnresolvedHint(name: String, parameters: Seq[String], child: LogicalPlan)\n+case class UnresolvedHint(name: String, parameters: Seq[Any], child: LogicalPlan)"
  }],
  "prId": 18086
}]