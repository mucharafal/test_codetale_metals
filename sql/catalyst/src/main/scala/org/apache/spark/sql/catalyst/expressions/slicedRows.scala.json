[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "SlicedMutableRow -> SlicedInternalRow?\n",
    "commit": "5c8f324a9fdc58ef2bb145c842bdff74febd99bb",
    "createdAt": "2016-08-09T12:55:11Z",
    "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.util.{ArrayData, MapData}\n+import org.apache.spark.sql.types.{DataType, Decimal}\n+import org.apache.spark.unsafe.types.{CalendarInterval, UTF8String}\n+\n+/**\n+ * A sliced row provides a view of the underlying row, and forwards all read/write requests to the\n+ * underlying row, after shifting the index by offset.\n+ *\n+ * Note that, the underlying row field in this class is mutable, so that we can reuse the same\n+ * instance of this class while processing many rows.\n+ */\n+trait BaseSlicedInternalRow extends InternalRow {\n+  def baseRow: InternalRow\n+  def offset: Int\n+\n+  protected def toBaseIndex(index: Int): Int = {\n+    assert(index >= 0, \"index (\" + index + \") should >= 0\")\n+    assert(index < numFields, \"index (\" + index + \") should < \" + numFields)\n+    index + offset\n+  }\n+\n+  override def isNullAt(i: Int): Boolean = baseRow.isNullAt(toBaseIndex(i))\n+  override def getBoolean(i: Int): Boolean = baseRow.getBoolean(toBaseIndex(i))\n+  override def getByte(i: Int): Byte = baseRow.getByte(toBaseIndex(i))\n+  override def getShort(i: Int): Short = baseRow.getShort(toBaseIndex(i))\n+  override def getInt(i: Int): Int = baseRow.getInt(toBaseIndex(i))\n+  override def getLong(i: Int): Long = baseRow.getLong(toBaseIndex(i))\n+  override def getFloat(i: Int): Float = baseRow.getFloat(toBaseIndex(i))\n+  override def getDouble(i: Int): Double = baseRow.getDouble(toBaseIndex((i)))\n+  override def getDecimal(i: Int, precision: Int, scale: Int): Decimal =\n+    baseRow.getDecimal(toBaseIndex(i), precision, scale)\n+  override def getUTF8String(i: Int): UTF8String = baseRow.getUTF8String(toBaseIndex(i))\n+  override def getBinary(i: Int): Array[Byte] = baseRow.getBinary(toBaseIndex(i))\n+  override def getInterval(i: Int): CalendarInterval = baseRow.getInterval(toBaseIndex(i))\n+  override def getStruct(i: Int, numFields: Int): InternalRow =\n+    baseRow.getStruct(toBaseIndex(i), numFields)\n+  override def getArray(i: Int): ArrayData = baseRow.getArray(toBaseIndex(i))\n+  override def getMap(i: Int): MapData = baseRow.getMap(toBaseIndex(i))\n+  override def get(i: Int, dataType: DataType): AnyRef = baseRow.get(toBaseIndex(i), dataType)\n+\n+  override def anyNull: Boolean = {\n+    val len = offset + numFields\n+    var i = offset\n+    while (i < len) {\n+      if (isNullAt(i)) { return true }\n+      i += 1\n+    }\n+    false\n+  }\n+\n+  override def copy(): InternalRow = {\n+    throw new UnsupportedOperationException(\"Cannot copy a SlicedMutableRow\")"
  }],
  "prId": 14562
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "does this need to be a case class?\n",
    "commit": "5c8f324a9fdc58ef2bb145c842bdff74febd99bb",
    "createdAt": "2016-08-10T04:03:35Z",
    "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.util.{ArrayData, MapData}\n+import org.apache.spark.sql.types.{DataType, Decimal}\n+import org.apache.spark.unsafe.types.{CalendarInterval, UTF8String}\n+\n+/**\n+ * A sliced row provides a view of the underlying row, and forwards all read/write requests to the\n+ * underlying row, after shifting the index by offset.\n+ *\n+ * Note that, the underlying row field in this class is mutable, so that we can reuse the same\n+ * instance of this class while processing many rows.\n+ */\n+trait BaseSlicedInternalRow extends InternalRow {\n+  def baseRow: InternalRow\n+  def offset: Int\n+\n+  protected def toBaseIndex(index: Int): Int = {\n+    assert(index >= 0, \"index (\" + index + \") should >= 0\")\n+    assert(index < numFields, \"index (\" + index + \") should < \" + numFields)\n+    index + offset\n+  }\n+\n+  override def isNullAt(i: Int): Boolean = baseRow.isNullAt(toBaseIndex(i))\n+  override def getBoolean(i: Int): Boolean = baseRow.getBoolean(toBaseIndex(i))\n+  override def getByte(i: Int): Byte = baseRow.getByte(toBaseIndex(i))\n+  override def getShort(i: Int): Short = baseRow.getShort(toBaseIndex(i))\n+  override def getInt(i: Int): Int = baseRow.getInt(toBaseIndex(i))\n+  override def getLong(i: Int): Long = baseRow.getLong(toBaseIndex(i))\n+  override def getFloat(i: Int): Float = baseRow.getFloat(toBaseIndex(i))\n+  override def getDouble(i: Int): Double = baseRow.getDouble(toBaseIndex((i)))\n+  override def getDecimal(i: Int, precision: Int, scale: Int): Decimal =\n+    baseRow.getDecimal(toBaseIndex(i), precision, scale)\n+  override def getUTF8String(i: Int): UTF8String = baseRow.getUTF8String(toBaseIndex(i))\n+  override def getBinary(i: Int): Array[Byte] = baseRow.getBinary(toBaseIndex(i))\n+  override def getInterval(i: Int): CalendarInterval = baseRow.getInterval(toBaseIndex(i))\n+  override def getStruct(i: Int, numFields: Int): InternalRow =\n+    baseRow.getStruct(toBaseIndex(i), numFields)\n+  override def getArray(i: Int): ArrayData = baseRow.getArray(toBaseIndex(i))\n+  override def getMap(i: Int): MapData = baseRow.getMap(toBaseIndex(i))\n+  override def get(i: Int, dataType: DataType): AnyRef = baseRow.get(toBaseIndex(i), dataType)\n+\n+  override def anyNull: Boolean = {\n+    val len = offset + numFields\n+    var i = offset\n+    while (i < len) {\n+      if (isNullAt(i)) { return true }\n+      i += 1\n+    }\n+    false\n+  }\n+\n+  override def copy(): InternalRow = {\n+    throw new UnsupportedOperationException(\"Cannot copy a SlicedMutableRow\")\n+  }\n+}\n+\n+case class SlicedInternalRow(offset: Int, numFields: Int) extends BaseSlicedInternalRow {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "hmmm, does case class has performance penalty? It doesn't need to be though.\n",
    "commit": "5c8f324a9fdc58ef2bb145c842bdff74febd99bb",
    "createdAt": "2016-08-10T05:20:24Z",
    "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.util.{ArrayData, MapData}\n+import org.apache.spark.sql.types.{DataType, Decimal}\n+import org.apache.spark.unsafe.types.{CalendarInterval, UTF8String}\n+\n+/**\n+ * A sliced row provides a view of the underlying row, and forwards all read/write requests to the\n+ * underlying row, after shifting the index by offset.\n+ *\n+ * Note that, the underlying row field in this class is mutable, so that we can reuse the same\n+ * instance of this class while processing many rows.\n+ */\n+trait BaseSlicedInternalRow extends InternalRow {\n+  def baseRow: InternalRow\n+  def offset: Int\n+\n+  protected def toBaseIndex(index: Int): Int = {\n+    assert(index >= 0, \"index (\" + index + \") should >= 0\")\n+    assert(index < numFields, \"index (\" + index + \") should < \" + numFields)\n+    index + offset\n+  }\n+\n+  override def isNullAt(i: Int): Boolean = baseRow.isNullAt(toBaseIndex(i))\n+  override def getBoolean(i: Int): Boolean = baseRow.getBoolean(toBaseIndex(i))\n+  override def getByte(i: Int): Byte = baseRow.getByte(toBaseIndex(i))\n+  override def getShort(i: Int): Short = baseRow.getShort(toBaseIndex(i))\n+  override def getInt(i: Int): Int = baseRow.getInt(toBaseIndex(i))\n+  override def getLong(i: Int): Long = baseRow.getLong(toBaseIndex(i))\n+  override def getFloat(i: Int): Float = baseRow.getFloat(toBaseIndex(i))\n+  override def getDouble(i: Int): Double = baseRow.getDouble(toBaseIndex((i)))\n+  override def getDecimal(i: Int, precision: Int, scale: Int): Decimal =\n+    baseRow.getDecimal(toBaseIndex(i), precision, scale)\n+  override def getUTF8String(i: Int): UTF8String = baseRow.getUTF8String(toBaseIndex(i))\n+  override def getBinary(i: Int): Array[Byte] = baseRow.getBinary(toBaseIndex(i))\n+  override def getInterval(i: Int): CalendarInterval = baseRow.getInterval(toBaseIndex(i))\n+  override def getStruct(i: Int, numFields: Int): InternalRow =\n+    baseRow.getStruct(toBaseIndex(i), numFields)\n+  override def getArray(i: Int): ArrayData = baseRow.getArray(toBaseIndex(i))\n+  override def getMap(i: Int): MapData = baseRow.getMap(toBaseIndex(i))\n+  override def get(i: Int, dataType: DataType): AnyRef = baseRow.get(toBaseIndex(i), dataType)\n+\n+  override def anyNull: Boolean = {\n+    val len = offset + numFields\n+    var i = offset\n+    while (i < len) {\n+      if (isNullAt(i)) { return true }\n+      i += 1\n+    }\n+    false\n+  }\n+\n+  override def copy(): InternalRow = {\n+    throw new UnsupportedOperationException(\"Cannot copy a SlicedMutableRow\")\n+  }\n+}\n+\n+case class SlicedInternalRow(offset: Int, numFields: Int) extends BaseSlicedInternalRow {"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "It generates a lot of crap in bytecode, so would be good to not generate them unless they are useful.\n",
    "commit": "5c8f324a9fdc58ef2bb145c842bdff74febd99bb",
    "createdAt": "2016-08-10T05:30:26Z",
    "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.util.{ArrayData, MapData}\n+import org.apache.spark.sql.types.{DataType, Decimal}\n+import org.apache.spark.unsafe.types.{CalendarInterval, UTF8String}\n+\n+/**\n+ * A sliced row provides a view of the underlying row, and forwards all read/write requests to the\n+ * underlying row, after shifting the index by offset.\n+ *\n+ * Note that, the underlying row field in this class is mutable, so that we can reuse the same\n+ * instance of this class while processing many rows.\n+ */\n+trait BaseSlicedInternalRow extends InternalRow {\n+  def baseRow: InternalRow\n+  def offset: Int\n+\n+  protected def toBaseIndex(index: Int): Int = {\n+    assert(index >= 0, \"index (\" + index + \") should >= 0\")\n+    assert(index < numFields, \"index (\" + index + \") should < \" + numFields)\n+    index + offset\n+  }\n+\n+  override def isNullAt(i: Int): Boolean = baseRow.isNullAt(toBaseIndex(i))\n+  override def getBoolean(i: Int): Boolean = baseRow.getBoolean(toBaseIndex(i))\n+  override def getByte(i: Int): Byte = baseRow.getByte(toBaseIndex(i))\n+  override def getShort(i: Int): Short = baseRow.getShort(toBaseIndex(i))\n+  override def getInt(i: Int): Int = baseRow.getInt(toBaseIndex(i))\n+  override def getLong(i: Int): Long = baseRow.getLong(toBaseIndex(i))\n+  override def getFloat(i: Int): Float = baseRow.getFloat(toBaseIndex(i))\n+  override def getDouble(i: Int): Double = baseRow.getDouble(toBaseIndex((i)))\n+  override def getDecimal(i: Int, precision: Int, scale: Int): Decimal =\n+    baseRow.getDecimal(toBaseIndex(i), precision, scale)\n+  override def getUTF8String(i: Int): UTF8String = baseRow.getUTF8String(toBaseIndex(i))\n+  override def getBinary(i: Int): Array[Byte] = baseRow.getBinary(toBaseIndex(i))\n+  override def getInterval(i: Int): CalendarInterval = baseRow.getInterval(toBaseIndex(i))\n+  override def getStruct(i: Int, numFields: Int): InternalRow =\n+    baseRow.getStruct(toBaseIndex(i), numFields)\n+  override def getArray(i: Int): ArrayData = baseRow.getArray(toBaseIndex(i))\n+  override def getMap(i: Int): MapData = baseRow.getMap(toBaseIndex(i))\n+  override def get(i: Int, dataType: DataType): AnyRef = baseRow.get(toBaseIndex(i), dataType)\n+\n+  override def anyNull: Boolean = {\n+    val len = offset + numFields\n+    var i = offset\n+    while (i < len) {\n+      if (isNullAt(i)) { return true }\n+      i += 1\n+    }\n+    false\n+  }\n+\n+  override def copy(): InternalRow = {\n+    throw new UnsupportedOperationException(\"Cannot copy a SlicedMutableRow\")\n+  }\n+}\n+\n+case class SlicedInternalRow(offset: Int, numFields: Int) extends BaseSlicedInternalRow {"
  }],
  "prId": 14562
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "does this need to be a case class?\n",
    "commit": "5c8f324a9fdc58ef2bb145c842bdff74febd99bb",
    "createdAt": "2016-08-10T04:03:38Z",
    "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.util.{ArrayData, MapData}\n+import org.apache.spark.sql.types.{DataType, Decimal}\n+import org.apache.spark.unsafe.types.{CalendarInterval, UTF8String}\n+\n+/**\n+ * A sliced row provides a view of the underlying row, and forwards all read/write requests to the\n+ * underlying row, after shifting the index by offset.\n+ *\n+ * Note that, the underlying row field in this class is mutable, so that we can reuse the same\n+ * instance of this class while processing many rows.\n+ */\n+trait BaseSlicedInternalRow extends InternalRow {\n+  def baseRow: InternalRow\n+  def offset: Int\n+\n+  protected def toBaseIndex(index: Int): Int = {\n+    assert(index >= 0, \"index (\" + index + \") should >= 0\")\n+    assert(index < numFields, \"index (\" + index + \") should < \" + numFields)\n+    index + offset\n+  }\n+\n+  override def isNullAt(i: Int): Boolean = baseRow.isNullAt(toBaseIndex(i))\n+  override def getBoolean(i: Int): Boolean = baseRow.getBoolean(toBaseIndex(i))\n+  override def getByte(i: Int): Byte = baseRow.getByte(toBaseIndex(i))\n+  override def getShort(i: Int): Short = baseRow.getShort(toBaseIndex(i))\n+  override def getInt(i: Int): Int = baseRow.getInt(toBaseIndex(i))\n+  override def getLong(i: Int): Long = baseRow.getLong(toBaseIndex(i))\n+  override def getFloat(i: Int): Float = baseRow.getFloat(toBaseIndex(i))\n+  override def getDouble(i: Int): Double = baseRow.getDouble(toBaseIndex((i)))\n+  override def getDecimal(i: Int, precision: Int, scale: Int): Decimal =\n+    baseRow.getDecimal(toBaseIndex(i), precision, scale)\n+  override def getUTF8String(i: Int): UTF8String = baseRow.getUTF8String(toBaseIndex(i))\n+  override def getBinary(i: Int): Array[Byte] = baseRow.getBinary(toBaseIndex(i))\n+  override def getInterval(i: Int): CalendarInterval = baseRow.getInterval(toBaseIndex(i))\n+  override def getStruct(i: Int, numFields: Int): InternalRow =\n+    baseRow.getStruct(toBaseIndex(i), numFields)\n+  override def getArray(i: Int): ArrayData = baseRow.getArray(toBaseIndex(i))\n+  override def getMap(i: Int): MapData = baseRow.getMap(toBaseIndex(i))\n+  override def get(i: Int, dataType: DataType): AnyRef = baseRow.get(toBaseIndex(i), dataType)\n+\n+  override def anyNull: Boolean = {\n+    val len = offset + numFields\n+    var i = offset\n+    while (i < len) {\n+      if (isNullAt(i)) { return true }\n+      i += 1\n+    }\n+    false\n+  }\n+\n+  override def copy(): InternalRow = {\n+    throw new UnsupportedOperationException(\"Cannot copy a SlicedMutableRow\")\n+  }\n+}\n+\n+case class SlicedInternalRow(offset: Int, numFields: Int) extends BaseSlicedInternalRow {\n+  private var _baseRow: InternalRow = _\n+  def target(row: InternalRow): SlicedInternalRow = {\n+    _baseRow = row\n+    this\n+  }\n+\n+  def baseRow: InternalRow = _baseRow\n+}\n+\n+case class SlicedMutableRow(offset: Int, numFields: Int)"
  }],
  "prId": 14562
}, {
  "comments": [{
    "author": {
      "login": "clockfly"
    },
    "body": "Rename to `baseIndexOf`?\n",
    "commit": "5c8f324a9fdc58ef2bb145c842bdff74febd99bb",
    "createdAt": "2016-08-16T23:26:26Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.util.{ArrayData, MapData}\n+import org.apache.spark.sql.types.{DataType, Decimal}\n+import org.apache.spark.unsafe.types.{CalendarInterval, UTF8String}\n+\n+/**\n+ * A sliced row provides a view of the underlying row, and forwards all read/write requests to the\n+ * underlying row, after shifting the index by offset.\n+ *\n+ * Note that, the underlying row field in this class is mutable, so that we can reuse the same\n+ * instance of this class while processing many rows.\n+ */\n+trait BaseSlicedInternalRow extends InternalRow {\n+  protected def baseRow: InternalRow\n+  protected def offset: Int\n+\n+  protected def toBaseIndex(index: Int): Int = {"
  }, {
    "author": {
      "login": "clockfly"
    },
    "body": "Or rawIndexOf?\n",
    "commit": "5c8f324a9fdc58ef2bb145c842bdff74febd99bb",
    "createdAt": "2016-08-16T23:27:10Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.util.{ArrayData, MapData}\n+import org.apache.spark.sql.types.{DataType, Decimal}\n+import org.apache.spark.unsafe.types.{CalendarInterval, UTF8String}\n+\n+/**\n+ * A sliced row provides a view of the underlying row, and forwards all read/write requests to the\n+ * underlying row, after shifting the index by offset.\n+ *\n+ * Note that, the underlying row field in this class is mutable, so that we can reuse the same\n+ * instance of this class while processing many rows.\n+ */\n+trait BaseSlicedInternalRow extends InternalRow {\n+  protected def baseRow: InternalRow\n+  protected def offset: Int\n+\n+  protected def toBaseIndex(index: Int): Int = {"
  }],
  "prId": 14562
}, {
  "comments": [{
    "author": {
      "login": "clockfly"
    },
    "body": "Maybe rawRow better? \n",
    "commit": "5c8f324a9fdc58ef2bb145c842bdff74febd99bb",
    "createdAt": "2016-08-16T23:28:02Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.util.{ArrayData, MapData}\n+import org.apache.spark.sql.types.{DataType, Decimal}\n+import org.apache.spark.unsafe.types.{CalendarInterval, UTF8String}\n+\n+/**\n+ * A sliced row provides a view of the underlying row, and forwards all read/write requests to the\n+ * underlying row, after shifting the index by offset.\n+ *\n+ * Note that, the underlying row field in this class is mutable, so that we can reuse the same\n+ * instance of this class while processing many rows.\n+ */\n+trait BaseSlicedInternalRow extends InternalRow {\n+  protected def baseRow: InternalRow"
  }],
  "prId": 14562
}]