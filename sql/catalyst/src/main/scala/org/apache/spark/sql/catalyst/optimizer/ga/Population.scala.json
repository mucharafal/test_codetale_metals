[{
  "comments": [{
    "author": {
      "login": "yeshengm"
    },
    "body": "Add one-line comment here for each concept as in the design doc?",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-07-30T20:52:19Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome("
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Fixed.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-08-01T12:50:40Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome("
  }],
  "prId": 24983
}, {
  "comments": [{
    "author": {
      "login": "yeshengm"
    },
    "body": "Use the scala-way.\r\n`val chromos = Seq.fill(determinPopSize(conf, itemsMap.size) {\r\n  Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\r\n}`",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-07-30T21:18:59Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Fixed.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-08-01T12:50:49Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()"
  }],
  "prId": 24983
}, {
  "comments": [{
    "author": {
      "login": "yeshengm"
    },
    "body": "no need for an extra space here.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-07-30T21:24:59Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Fixed.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-08-01T12:51:00Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],"
  }],
  "prId": 24983
}, {
  "comments": [{
    "author": {
      "login": "yeshengm"
    },
    "body": "use `for (_ <- 1 to generations)`. It's way more concise and readable",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-07-30T21:29:50Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt\n+  }\n+\n+  private def shuffle(itemsMap: Map[Int, JoinPlan]) : Seq[JoinPlan] = {\n+    val shuffled = util.Random.shuffle(itemsMap.keySet.toList)\n+    val sb = Seq.newBuilder[JoinPlan]\n+    shuffled.foreach(index => sb += itemsMap(index))\n+    sb.result()\n+  }\n+}\n+\n+class Population(conf: SQLConf, var chromos: Seq[Chromosome]) extends Logging {\n+  private def sort(): Unit = {\n+    chromos = chromos.sortWith((left, right) => left.fitness > right.fitness)\n+  }\n+\n+  def evolve: Population = {\n+    // Sort chromos in the population first.\n+    sort()\n+    // Begin iteration.\n+    var i = 0\n+    val generations = chromos.size\n+    val crossover = EdgeRecombination\n+    while (i < generations) {"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Fixed.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-08-01T12:51:14Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt\n+  }\n+\n+  private def shuffle(itemsMap: Map[Int, JoinPlan]) : Seq[JoinPlan] = {\n+    val shuffled = util.Random.shuffle(itemsMap.keySet.toList)\n+    val sb = Seq.newBuilder[JoinPlan]\n+    shuffled.foreach(index => sb += itemsMap(index))\n+    sb.result()\n+  }\n+}\n+\n+class Population(conf: SQLConf, var chromos: Seq[Chromosome]) extends Logging {\n+  private def sort(): Unit = {\n+    chromos = chromos.sortWith((left, right) => left.fitness > right.fitness)\n+  }\n+\n+  def evolve: Population = {\n+    // Sort chromos in the population first.\n+    sort()\n+    // Begin iteration.\n+    var i = 0\n+    val generations = chromos.size\n+    val crossover = EdgeRecombination\n+    while (i < generations) {"
  }],
  "prId": 24983
}, {
  "comments": [{
    "author": {
      "login": "yeshengm"
    },
    "body": "No need for a `return` here.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-07-30T21:37:40Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Fixed.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-08-01T12:51:31Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max"
  }],
  "prId": 24983
}, {
  "comments": [{
    "author": {
      "login": "yeshengm"
    },
    "body": "This comparison logic is a bit clumsy. I'd write it as `max(min(max_val, val), min_val)`.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-07-30T21:39:51Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Fixed.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-08-01T12:51:45Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt"
  }],
  "prId": 24983
}, {
  "comments": [{
    "author": {
      "login": "yeshengm"
    },
    "body": "What's the difference from direct shuffling the valueSet?",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-07-30T21:43:25Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt\n+  }\n+\n+  private def shuffle(itemsMap: Map[Int, JoinPlan]) : Seq[JoinPlan] = {\n+    val shuffled = util.Random.shuffle(itemsMap.keySet.toList)\n+    val sb = Seq.newBuilder[JoinPlan]"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Thank you for reminding. In fact, when I implemented the code, I didn't find the valueSet, but found an iterator. I didn't consider much. Now I fixed it.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-08-01T12:53:50Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt\n+  }\n+\n+  private def shuffle(itemsMap: Map[Int, JoinPlan]) : Seq[JoinPlan] = {\n+    val shuffled = util.Random.shuffle(itemsMap.keySet.toList)\n+    val sb = Seq.newBuilder[JoinPlan]"
  }],
  "prId": 24983
}, {
  "comments": [{
    "author": {
      "login": "yeshengm"
    },
    "body": "What does ex mean?",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-07-30T21:51:30Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt\n+  }\n+\n+  private def shuffle(itemsMap: Map[Int, JoinPlan]) : Seq[JoinPlan] = {\n+    val shuffled = util.Random.shuffle(itemsMap.keySet.toList)\n+    val sb = Seq.newBuilder[JoinPlan]\n+    shuffled.foreach(index => sb += itemsMap(index))\n+    sb.result()\n+  }\n+}\n+\n+class Population(conf: SQLConf, var chromos: Seq[Chromosome]) extends Logging {\n+  private def sort(): Unit = {\n+    chromos = chromos.sortWith((left, right) => left.fitness > right.fitness)\n+  }\n+\n+  def evolve: Population = {\n+    // Sort chromos in the population first.\n+    sort()\n+    // Begin iteration.\n+    var i = 0\n+    val generations = chromos.size\n+    val crossover = EdgeRecombination\n+    while (i < generations) {\n+      val baba = GAUtils.select(conf, chromos, None)\n+      val mama = GAUtils.select(conf, chromos, Some(baba))\n+      val kid = crossover.newChromo(baba, mama)\n+      chromos = putToPop(kid)\n+      logInfo(s\"Iteration $i, fitness for kid: ${kid.fitness},\" +\n+          s\" and Fitness for plans: ${chromos.map(c => c.fitness)}\")\n+      i += 1\n+    }\n+    this\n+  }\n+\n+  private def putToPop(kid: Chromosome): Seq[Chromosome] = {\n+    val tmp = mutable.Buffer[Chromosome]()\n+    var added = false\n+    for (elem <- chromos) {\n+      if (kid.fitness >= elem.fitness && !added) {\n+        tmp.append(kid)\n+        added = true\n+      }\n+      tmp.append(elem)\n+    }\n+    // Remove the last elem whose fitness is lowest if we have inserted the kid.\n+    if (added) {\n+      tmp.remove(tmp.size - 1)\n+    }\n+    tmp\n+  }\n+}\n+\n+object GAUtils {\n+  def select(conf: SQLConf, chromos: Seq[Chromosome], ex: Option[Chromosome]): Chromosome = {"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Sorry for it. `ex` means `excluded`. However, has updated the variable name and give a doc. It's not problem now",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-08-01T12:57:27Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt\n+  }\n+\n+  private def shuffle(itemsMap: Map[Int, JoinPlan]) : Seq[JoinPlan] = {\n+    val shuffled = util.Random.shuffle(itemsMap.keySet.toList)\n+    val sb = Seq.newBuilder[JoinPlan]\n+    shuffled.foreach(index => sb += itemsMap(index))\n+    sb.result()\n+  }\n+}\n+\n+class Population(conf: SQLConf, var chromos: Seq[Chromosome]) extends Logging {\n+  private def sort(): Unit = {\n+    chromos = chromos.sortWith((left, right) => left.fitness > right.fitness)\n+  }\n+\n+  def evolve: Population = {\n+    // Sort chromos in the population first.\n+    sort()\n+    // Begin iteration.\n+    var i = 0\n+    val generations = chromos.size\n+    val crossover = EdgeRecombination\n+    while (i < generations) {\n+      val baba = GAUtils.select(conf, chromos, None)\n+      val mama = GAUtils.select(conf, chromos, Some(baba))\n+      val kid = crossover.newChromo(baba, mama)\n+      chromos = putToPop(kid)\n+      logInfo(s\"Iteration $i, fitness for kid: ${kid.fitness},\" +\n+          s\" and Fitness for plans: ${chromos.map(c => c.fitness)}\")\n+      i += 1\n+    }\n+    this\n+  }\n+\n+  private def putToPop(kid: Chromosome): Seq[Chromosome] = {\n+    val tmp = mutable.Buffer[Chromosome]()\n+    var added = false\n+    for (elem <- chromos) {\n+      if (kid.fitness >= elem.fitness && !added) {\n+        tmp.append(kid)\n+        added = true\n+      }\n+      tmp.append(elem)\n+    }\n+    // Remove the last elem whose fitness is lowest if we have inserted the kid.\n+    if (added) {\n+      tmp.remove(tmp.size - 1)\n+    }\n+    tmp\n+  }\n+}\n+\n+object GAUtils {\n+  def select(conf: SQLConf, chromos: Seq[Chromosome], ex: Option[Chromosome]): Chromosome = {"
  }],
  "prId": 24983
}, {
  "comments": [{
    "author": {
      "login": "yeshengm"
    },
    "body": "We only have `EdgeRecombination` as a combination strategy. I don't think we need a local variable here.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-07-30T21:52:37Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt\n+  }\n+\n+  private def shuffle(itemsMap: Map[Int, JoinPlan]) : Seq[JoinPlan] = {\n+    val shuffled = util.Random.shuffle(itemsMap.keySet.toList)\n+    val sb = Seq.newBuilder[JoinPlan]\n+    shuffled.foreach(index => sb += itemsMap(index))\n+    sb.result()\n+  }\n+}\n+\n+class Population(conf: SQLConf, var chromos: Seq[Chromosome]) extends Logging {\n+  private def sort(): Unit = {\n+    chromos = chromos.sortWith((left, right) => left.fitness > right.fitness)\n+  }\n+\n+  def evolve: Population = {\n+    // Sort chromos in the population first.\n+    sort()\n+    // Begin iteration.\n+    var i = 0\n+    val generations = chromos.size\n+    val crossover = EdgeRecombination\n+    while (i < generations) {\n+      val baba = GAUtils.select(conf, chromos, None)\n+      val mama = GAUtils.select(conf, chromos, Some(baba))\n+      val kid = crossover.newChromo(baba, mama)"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Fixed.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-08-01T12:57:36Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt\n+  }\n+\n+  private def shuffle(itemsMap: Map[Int, JoinPlan]) : Seq[JoinPlan] = {\n+    val shuffled = util.Random.shuffle(itemsMap.keySet.toList)\n+    val sb = Seq.newBuilder[JoinPlan]\n+    shuffled.foreach(index => sb += itemsMap(index))\n+    sb.result()\n+  }\n+}\n+\n+class Population(conf: SQLConf, var chromos: Seq[Chromosome]) extends Logging {\n+  private def sort(): Unit = {\n+    chromos = chromos.sortWith((left, right) => left.fitness > right.fitness)\n+  }\n+\n+  def evolve: Population = {\n+    // Sort chromos in the population first.\n+    sort()\n+    // Begin iteration.\n+    var i = 0\n+    val generations = chromos.size\n+    val crossover = EdgeRecombination\n+    while (i < generations) {\n+      val baba = GAUtils.select(conf, chromos, None)\n+      val mama = GAUtils.select(conf, chromos, Some(baba))\n+      val kid = crossover.newChromo(baba, mama)"
  }],
  "prId": 24983
}, {
  "comments": [{
    "author": {
      "login": "yeshengm"
    },
    "body": "I think we should reconsider the API design here. Just make `chromos` a val here. And make each `evolve` return a new population. Since you are creating new `Seq`s in the `sort` method, it will not make any difference perf-wise.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-07-30T21:57:09Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt\n+  }\n+\n+  private def shuffle(itemsMap: Map[Int, JoinPlan]) : Seq[JoinPlan] = {\n+    val shuffled = util.Random.shuffle(itemsMap.keySet.toList)\n+    val sb = Seq.newBuilder[JoinPlan]\n+    shuffled.foreach(index => sb += itemsMap(index))\n+    sb.result()\n+  }\n+}\n+\n+class Population(conf: SQLConf, var chromos: Seq[Chromosome]) extends Logging {"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Fixed.",
    "commit": "c8f112e86b3c8df9f6a161dd20ced197ccf09f9e",
    "createdAt": "2019-08-02T02:56:14Z",
    "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer.ga\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.{AttributeSet, Expression}\n+import org.apache.spark.sql.catalyst.optimizer.{JoinGraphInfo, JoinReorderDP}\n+import org.apache.spark.sql.catalyst.optimizer.JoinReorderDP.JoinPlan\n+import org.apache.spark.sql.internal.SQLConf\n+\n+case class Chromosome(\n+    conf: SQLConf,\n+    basicPlans: Seq[JoinPlan],\n+    conditions: Set[Expression],\n+    topOutputSet: AttributeSet) {\n+\n+  lazy val fitness: Double = evalFitness(integratedPlan)\n+\n+  lazy val integratedPlan: Option[JoinPlan] = makePlan\n+\n+  private def makePlan: Option[JoinPlan] = {\n+    val semiFinished = mutable.Buffer[JoinPlan]()\n+    basicPlans.foreach(mergeSemi(semiFinished, _))\n+    if (semiFinished.head.itemIds.size == basicPlans.size) {\n+      Some(semiFinished.head)\n+    } else {\n+      None\n+    }\n+  }\n+\n+  private def mergeSemi(semiFinished: mutable.Buffer[JoinPlan], right: JoinPlan): Unit = {\n+    val filters = None: Option[JoinGraphInfo]\n+    for (left <- semiFinished) {\n+      JoinReorderDP.buildJoin(left, right, conf, conditions, topOutputSet, filters) match {\n+        case Some(joined) =>\n+          semiFinished.remove(semiFinished.indexOf(left))\n+          mergeSemi(semiFinished, joined)\n+        case _ =>\n+          None\n+      }\n+    }\n+\n+    if (semiFinished.isEmpty || right.itemIds.size == 1) {\n+      semiFinished.append(right)\n+      return\n+    }\n+\n+    insertPlan(semiFinished, right)\n+  }\n+\n+  private def insertPlan(semiFinished: mutable.Buffer[JoinPlan], plan: JoinPlan): Unit = {\n+    var criticalSize = if (semiFinished.head.itemIds.size > plan.itemIds.size) {\n+      semiFinished.head.itemIds.size\n+    } else {\n+      plan.itemIds.size\n+    }\n+    var criticalIndex = 0\n+    var break: Boolean = false\n+    for (p <- semiFinished if !break) {\n+      if (plan.itemIds.size > p.itemIds.size && plan.itemIds.size <= criticalSize) {\n+        break = true\n+      } else {\n+        criticalIndex += 1\n+        criticalSize = p.itemIds.size\n+      }\n+    }\n+\n+    semiFinished.insert(criticalIndex, plan)\n+  }\n+\n+  private def evalFitness(plan: Option[JoinPlan]): Double = {\n+    plan match {\n+      case Some(joinPlan) =>\n+        // We use the negative cost as fitness.\n+        - joinPlan.planCost.card.toDouble * conf.joinReorderCardWeight -\n+            joinPlan.planCost.size.toDouble * (1 - conf.joinReorderCardWeight)\n+      case _ =>\n+        - Double.MaxValue\n+    }\n+  }\n+}\n+\n+object Population {\n+  def apply(\n+      conf: SQLConf,\n+      itemsMap: Map [Int, JoinPlan],\n+      conditions: Set[Expression],\n+      topOutputSet: AttributeSet) : Population = {\n+\n+    var chromos: Seq[Chromosome] = Seq()\n+    var i = 0\n+    val popSize = determinePopSize(conf, itemsMap.size)\n+    while(i < popSize) {\n+      chromos = chromos :+ Chromosome(conf, shuffle(itemsMap), conditions, topOutputSet)\n+      i += 1\n+    }\n+\n+    new Population(conf, chromos)\n+  }\n+\n+  private def determinePopSize(conf: SQLConf, numRelations: Int): Int = {\n+    val relaxFactor = conf.joinReorderGARelaxFactor\n+    // The default population size:\n+    // # of relations | pop size (RF=3) | pop size (RF=3.5)| pop size  (RF=4)\n+    //  < 13          |   DP based      |   DP based       |   DP based\n+    //    13          |   20            |   16 (13<16)     |   16\n+    //    14          |   25            |   16             |   16\n+    //    15          |   32            |   19             |   16\n+    //    16          |   40            |   23             |   16\n+    //    17          |   50            |   28             |   19\n+    //    18          |   64            |   35             |   22\n+    //    19          |   80            |   43             |   26\n+    //    20          |   101           |   52             |   32\n+    //    21          |   128           |   64             |   38\n+    //    22          |   128           |   78             |   45\n+    //    23          |   128           |   95             |   53\n+    //    24          |   128           |   115            |   64\n+    //    25          |   128           |   128            |   76\n+    //    26          |   128           |   128            |   90\n+    //    27          |   128           |   128            |   90\n+    //    28          |   128           |   128            |   128\n+    //  > 28          |   128           |   128            |   128\n+    val size = math.pow(2.0, numRelations / relaxFactor)\n+    val max = conf.joinReorderGAMaxPoPSize\n+    val min = conf.joinReorderGAMinPoPSize\n+\n+    if (size > max) {\n+      return max\n+    }\n+    if (size < min) {\n+      return min\n+    }\n+    math.ceil(size).toInt\n+  }\n+\n+  private def shuffle(itemsMap: Map[Int, JoinPlan]) : Seq[JoinPlan] = {\n+    val shuffled = util.Random.shuffle(itemsMap.keySet.toList)\n+    val sb = Seq.newBuilder[JoinPlan]\n+    shuffled.foreach(index => sb += itemsMap(index))\n+    sb.result()\n+  }\n+}\n+\n+class Population(conf: SQLConf, var chromos: Seq[Chromosome]) extends Logging {"
  }],
  "prId": 24983
}]