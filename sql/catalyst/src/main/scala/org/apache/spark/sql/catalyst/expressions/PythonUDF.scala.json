[{
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "Why was this removed?",
    "commit": "cc659bc2487d81a9497bd032049c2c4272660716",
    "createdAt": "2017-12-11T10:10:29Z",
    "diffHunk": "@@ -32,7 +31,5 @@ case class PythonUDF(\n     evalType: Int)\n   extends Expression with Unevaluable with NonSQLExpression with UserDefinedExpression {\n \n-  override def toString: String = s\"$name(${children.mkString(\", \")})\""
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Whoops, my bad, adding back",
    "commit": "cc659bc2487d81a9497bd032049c2c4272660716",
    "createdAt": "2017-12-19T17:34:24Z",
    "diffHunk": "@@ -32,7 +31,5 @@ case class PythonUDF(\n     evalType: Int)\n   extends Expression with Unevaluable with NonSQLExpression with UserDefinedExpression {\n \n-  override def toString: String = s\"$name(${children.mkString(\", \")})\""
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Added back",
    "commit": "cc659bc2487d81a9497bd032049c2c4272660716",
    "createdAt": "2017-12-19T22:20:49Z",
    "diffHunk": "@@ -32,7 +31,5 @@ case class PythonUDF(\n     evalType: Int)\n   extends Expression with Unevaluable with NonSQLExpression with UserDefinedExpression {\n \n-  override def toString: String = s\"$name(${children.mkString(\", \")})\""
  }],
  "prId": 19872
}, {
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "Do we need to move package to catalyst?",
    "commit": "cc659bc2487d81a9497bd032049c2c4272660716",
    "createdAt": "2017-12-11T10:48:39Z",
    "diffHunk": "@@ -15,10 +15,9 @@\n  * limitations under the License.\n  */\n \n-package org.apache.spark.sql.execution.python\n+package org.apache.spark.sql.catalyst.expressions",
    "line": 5
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "We do. This is similar to https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/ScalaUDF.scala\r\n\r\nThe reason is we need to access the class `PythonUDF` in analyzer.",
    "commit": "cc659bc2487d81a9497bd032049c2c4272660716",
    "createdAt": "2017-12-19T17:33:34Z",
    "diffHunk": "@@ -15,10 +15,9 @@\n  * limitations under the License.\n  */\n \n-package org.apache.spark.sql.execution.python\n+package org.apache.spark.sql.catalyst.expressions",
    "line": 5
  }, {
    "author": {
      "login": "ueshin"
    },
    "body": "I see, thanks!",
    "commit": "cc659bc2487d81a9497bd032049c2c4272660716",
    "createdAt": "2017-12-20T03:46:09Z",
    "diffHunk": "@@ -15,10 +15,9 @@\n  * limitations under the License.\n  */\n \n-package org.apache.spark.sql.execution.python\n+package org.apache.spark.sql.catalyst.expressions",
    "line": 5
  }],
  "prId": 19872
}, {
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "Let's make this set `private[this] val ...` in `PythonUDF` object to avoid creating the set every time we use this method.\r\n  ",
    "commit": "cc659bc2487d81a9497bd032049c2c4272660716",
    "createdAt": "2018-01-10T08:39:44Z",
    "diffHunk": "@@ -15,12 +15,30 @@\n  * limitations under the License.\n  */\n \n-package org.apache.spark.sql.execution.python\n+package org.apache.spark.sql.catalyst.expressions\n \n-import org.apache.spark.api.python.PythonFunction\n-import org.apache.spark.sql.catalyst.expressions.{Expression, NonSQLExpression, Unevaluable, UserDefinedExpression}\n+import org.apache.spark.api.python.{PythonEvalType, PythonFunction}\n+import org.apache.spark.sql.catalyst.util.toPrettySQL\n import org.apache.spark.sql.types.DataType\n \n+/**\n+ * Helper functions for PythonUDF\n+ */\n+object PythonUDF {\n+  def isScalarPythonUDF(e: Expression): Boolean = {\n+    e.isInstanceOf[PythonUDF] &&\n+      Set("
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Aha, good call.",
    "commit": "cc659bc2487d81a9497bd032049c2c4272660716",
    "createdAt": "2018-01-10T15:24:31Z",
    "diffHunk": "@@ -15,12 +15,30 @@\n  * limitations under the License.\n  */\n \n-package org.apache.spark.sql.execution.python\n+package org.apache.spark.sql.catalyst.expressions\n \n-import org.apache.spark.api.python.PythonFunction\n-import org.apache.spark.sql.catalyst.expressions.{Expression, NonSQLExpression, Unevaluable, UserDefinedExpression}\n+import org.apache.spark.api.python.{PythonEvalType, PythonFunction}\n+import org.apache.spark.sql.catalyst.util.toPrettySQL\n import org.apache.spark.sql.types.DataType\n \n+/**\n+ * Helper functions for PythonUDF\n+ */\n+object PythonUDF {\n+  def isScalarPythonUDF(e: Expression): Boolean = {\n+    e.isInstanceOf[PythonUDF] &&\n+      Set("
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Fixed.",
    "commit": "cc659bc2487d81a9497bd032049c2c4272660716",
    "createdAt": "2018-01-10T19:41:00Z",
    "diffHunk": "@@ -15,12 +15,30 @@\n  * limitations under the License.\n  */\n \n-package org.apache.spark.sql.execution.python\n+package org.apache.spark.sql.catalyst.expressions\n \n-import org.apache.spark.api.python.PythonFunction\n-import org.apache.spark.sql.catalyst.expressions.{Expression, NonSQLExpression, Unevaluable, UserDefinedExpression}\n+import org.apache.spark.api.python.{PythonEvalType, PythonFunction}\n+import org.apache.spark.sql.catalyst.util.toPrettySQL\n import org.apache.spark.sql.types.DataType\n \n+/**\n+ * Helper functions for PythonUDF\n+ */\n+object PythonUDF {\n+  def isScalarPythonUDF(e: Expression): Boolean = {\n+    e.isInstanceOf[PythonUDF] &&\n+      Set("
  }],
  "prId": 19872
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I can't believe I am nitpicking this: `PythonUDF` -> `` `PythonUDF` ``.",
    "commit": "cc659bc2487d81a9497bd032049c2c4272660716",
    "createdAt": "2018-01-15T12:31:16Z",
    "diffHunk": "@@ -15,12 +15,31 @@\n  * limitations under the License.\n  */\n \n-package org.apache.spark.sql.execution.python\n+package org.apache.spark.sql.catalyst.expressions\n \n-import org.apache.spark.api.python.PythonFunction\n-import org.apache.spark.sql.catalyst.expressions.{Expression, NonSQLExpression, Unevaluable, UserDefinedExpression}\n+import org.apache.spark.api.python.{PythonEvalType, PythonFunction}\n+import org.apache.spark.sql.catalyst.util.toPrettySQL\n import org.apache.spark.sql.types.DataType\n \n+/**\n+ * Helper functions for PythonUDF"
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "I changed to `[[PythonUDF]]`. I think Scala doc should use `[[]]`",
    "commit": "cc659bc2487d81a9497bd032049c2c4272660716",
    "createdAt": "2018-01-16T19:08:26Z",
    "diffHunk": "@@ -15,12 +15,31 @@\n  * limitations under the License.\n  */\n \n-package org.apache.spark.sql.execution.python\n+package org.apache.spark.sql.catalyst.expressions\n \n-import org.apache.spark.api.python.PythonFunction\n-import org.apache.spark.sql.catalyst.expressions.{Expression, NonSQLExpression, Unevaluable, UserDefinedExpression}\n+import org.apache.spark.api.python.{PythonEvalType, PythonFunction}\n+import org.apache.spark.sql.catalyst.util.toPrettySQL\n import org.apache.spark.sql.types.DataType\n \n+/**\n+ * Helper functions for PythonUDF"
  }],
  "prId": 19872
}]