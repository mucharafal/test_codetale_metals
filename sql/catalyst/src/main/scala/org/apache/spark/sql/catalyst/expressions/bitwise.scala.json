[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "do we allow all kind of integral types or only int and long? If input type is byte, the result is also byte, but with your change, we will cast byte to int and result will be int too.\n",
    "commit": "8fcf814be0465cc1b52f877b0f1b3f6e5c72a16a",
    "createdAt": "2015-07-11T03:00:52Z",
    "diffHunk": "@@ -28,11 +26,13 @@ import org.apache.spark.sql.types._\n  *\n  * Code generation inherited from BinaryArithmetic.\n  */\n-case class BitwiseAnd(left: Expression, right: Expression) extends BinaryArithmetic {\n+case class BitwiseAnd(left: Expression, right: Expression)\n+  extends BinaryArithmetic with ExpectsInputTypes {\n+\n   override def symbol: String = \"&\"\n \n-  protected def checkTypesInternal(t: DataType) =\n-    TypeUtils.checkForBitwiseExpr(t, \"operator \" + symbol)\n+  override def inputTypes: Seq[AbstractDataType] =\n+    Seq(TypeCollection(IntegerType, LongType), TypeCollection(IntegerType, LongType))"
  }, {
    "author": {
      "login": "chenghao-intel"
    },
    "body": "Probably we need to list all of the integral types in `TypeCollection`s.\n",
    "commit": "8fcf814be0465cc1b52f877b0f1b3f6e5c72a16a",
    "createdAt": "2015-07-13T07:02:30Z",
    "diffHunk": "@@ -28,11 +26,13 @@ import org.apache.spark.sql.types._\n  *\n  * Code generation inherited from BinaryArithmetic.\n  */\n-case class BitwiseAnd(left: Expression, right: Expression) extends BinaryArithmetic {\n+case class BitwiseAnd(left: Expression, right: Expression)\n+  extends BinaryArithmetic with ExpectsInputTypes {\n+\n   override def symbol: String = \"&\"\n \n-  protected def checkTypesInternal(t: DataType) =\n-    TypeUtils.checkForBitwiseExpr(t, \"operator \" + symbol)\n+  override def inputTypes: Seq[AbstractDataType] =\n+    Seq(TypeCollection(IntegerType, LongType), TypeCollection(IntegerType, LongType))"
  }],
  "prId": 7348
}]