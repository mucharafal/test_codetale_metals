[{
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "This pr doesn't aim to cover other project-like plan, e.g., aggregate?",
    "commit": "b2fc45c411275088ea87dcb31f3900f893f59832",
    "createdAt": "2019-02-26T07:11:49Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * This aims to handle nested column pruning pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can create a new [[CreateNamedStruct]] containing only\n+ * subset of the fields as a new project in the child.\n+ */\n+object NestedColumnPruning {\n+\n+  type ExprMap = Map[Expression, Expression]\n+  type RequiredFieldMap = Map[Attribute, Set[GetStructField]]\n+\n+  def unapply(plan: LogicalPlan): Option[(Map[ExprId, Alias], ExprMap)] = plan match {\n+    case p @ Project(_, child) if canProjectPushThrough(child) =>",
    "line": 39
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thank you for review. Yep. Those plans (having expression replacement) will be handled in my PR~",
    "commit": "b2fc45c411275088ea87dcb31f3900f893f59832",
    "createdAt": "2019-02-26T17:11:43Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * This aims to handle nested column pruning pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can create a new [[CreateNamedStruct]] containing only\n+ * subset of the fields as a new project in the child.\n+ */\n+object NestedColumnPruning {\n+\n+  type ExprMap = Map[Expression, Expression]\n+  type RequiredFieldMap = Map[Attribute, Set[GetStructField]]\n+\n+  def unapply(plan: LogicalPlan): Option[(Map[ExprId, Alias], ExprMap)] = plan match {\n+    case p @ Project(_, child) if canProjectPushThrough(child) =>",
    "line": 39
  }],
  "prId": 23873
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Can you add comment to describe the returned value?",
    "commit": "b2fc45c411275088ea87dcb31f3900f893f59832",
    "createdAt": "2019-02-26T15:16:06Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * This aims to handle nested column pruning pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can create a new [[CreateNamedStruct]] containing only\n+ * subset of the fields as a new project in the child.\n+ */\n+object NestedColumnPruning {\n+\n+  type ExprMap = Map[Expression, Expression]\n+  type RequiredFieldMap = Map[Attribute, Set[GetStructField]]\n+\n+  def unapply(plan: LogicalPlan): Option[(Map[ExprId, Alias], ExprMap)] = plan match {",
    "line": 38
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thank you for review, @viirya . Sure.",
    "commit": "b2fc45c411275088ea87dcb31f3900f893f59832",
    "createdAt": "2019-02-26T17:12:00Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * This aims to handle nested column pruning pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can create a new [[CreateNamedStruct]] containing only\n+ * subset of the fields as a new project in the child.\n+ */\n+object NestedColumnPruning {\n+\n+  type ExprMap = Map[Expression, Expression]\n+  type RequiredFieldMap = Map[Attribute, Set[GetStructField]]\n+\n+  def unapply(plan: LogicalPlan): Option[(Map[ExprId, Alias], ExprMap)] = plan match {",
    "line": 38
  }],
  "prId": 23873
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Can you give an example showing how this is different to `references`?",
    "commit": "b2fc45c411275088ea87dcb31f3900f893f59832",
    "createdAt": "2019-02-26T15:42:37Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * This aims to handle nested column pruning pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can create a new [[CreateNamedStruct]] containing only\n+ * subset of the fields as a new project in the child.\n+ */\n+object NestedColumnPruning {\n+\n+  type ExprMap = Map[Expression, Expression]\n+  type RequiredFieldMap = Map[Attribute, Set[GetStructField]]\n+\n+  def unapply(plan: LogicalPlan): Option[(Map[ExprId, Alias], ExprMap)] = plan match {\n+    case p @ Project(_, child) if canProjectPushThrough(child) =>\n+      getPrunedNestedAttrsAndProjects(getRequiredFieldMap(p, child))\n+    case _ => None\n+  }\n+\n+  /**\n+   * Add projects to prune unused nested columns.\n+   */\n+  def prune(\n+      plan: LogicalPlan,\n+      nestedAttrs: Map[ExprId, Alias],\n+      projectsOnNestedAttrs: ExprMap): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>\n+      Project(\n+        getNewProjectList(projectList, projectsOnNestedAttrs),\n+        g.copy(child = addPrunedProjectToChildren(grandChild, nestedAttrs)))\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, projectsOnNestedAttrs),\n+        addPrunedProjectToChildren(child, nestedAttrs))\n+    case _ => plan\n+  }\n+\n+  /**\n+   * Get a map from a referenced attribute to its set of required fields.\n+   */\n+  private def getRequiredFieldMap(plans: LogicalPlan*): RequiredFieldMap = {\n+    val rootReferenceAttrSet = plans.map(getRootReferences).reduce(_ ++ _)\n+    val nestedFieldReferences = plans.map(getNestedFieldReferences).reduce(_ ++ _)\n+\n+    nestedFieldReferences\n+      .filter(!_.references.subsetOf(rootReferenceAttrSet))\n+      .groupBy(_.references)\n+      .filter(_._1.size == 1)\n+      .map(x => (x._1.head, x._2.toSet))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(projectList: Seq[NamedExpression], projectsOnNestedAttrs: ExprMap) =\n+    projectList.map(_.transform {\n+      case e if projectsOnNestedAttrs.contains(e) => projectsOnNestedAttrs(e)\n+    }.asInstanceOf[NamedExpression])\n+\n+  /**\n+   * Return a plan with new childen pruned with `Project`.\n+   */\n+  private def addPrunedProjectToChildren(plan: LogicalPlan, nestedAttrs: Map[ExprId, Alias]) =\n+    plan.withNewChildren(plan.children.map { child =>\n+      Project(child.output.map(a => nestedAttrs.getOrElse(a.exprId, a)), child)\n+    })\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Similar to [[QueryPlan.references]], but this only returns all attributes\n+   * that are explicitly referenced on the root levels in a [[LogicalPlan]].",
    "line": 105
  }],
  "prId": 23873
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "`nestedFieldReferences` contains only `GetStructField`. Will it possibly have `_._1.size > 1`?",
    "commit": "b2fc45c411275088ea87dcb31f3900f893f59832",
    "createdAt": "2019-02-26T15:45:03Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * This aims to handle nested column pruning pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can create a new [[CreateNamedStruct]] containing only\n+ * subset of the fields as a new project in the child.\n+ */\n+object NestedColumnPruning {\n+\n+  type ExprMap = Map[Expression, Expression]\n+  type RequiredFieldMap = Map[Attribute, Set[GetStructField]]\n+\n+  def unapply(plan: LogicalPlan): Option[(Map[ExprId, Alias], ExprMap)] = plan match {\n+    case p @ Project(_, child) if canProjectPushThrough(child) =>\n+      getPrunedNestedAttrsAndProjects(getRequiredFieldMap(p, child))\n+    case _ => None\n+  }\n+\n+  /**\n+   * Add projects to prune unused nested columns.\n+   */\n+  def prune(\n+      plan: LogicalPlan,\n+      nestedAttrs: Map[ExprId, Alias],\n+      projectsOnNestedAttrs: ExprMap): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>\n+      Project(\n+        getNewProjectList(projectList, projectsOnNestedAttrs),\n+        g.copy(child = addPrunedProjectToChildren(grandChild, nestedAttrs)))\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, projectsOnNestedAttrs),\n+        addPrunedProjectToChildren(child, nestedAttrs))\n+    case _ => plan\n+  }\n+\n+  /**\n+   * Get a map from a referenced attribute to its set of required fields.\n+   */\n+  private def getRequiredFieldMap(plans: LogicalPlan*): RequiredFieldMap = {\n+    val rootReferenceAttrSet = plans.map(getRootReferences).reduce(_ ++ _)\n+    val nestedFieldReferences = plans.map(getNestedFieldReferences).reduce(_ ++ _)\n+\n+    nestedFieldReferences\n+      .filter(!_.references.subsetOf(rootReferenceAttrSet))\n+      .groupBy(_.references)\n+      .filter(_._1.size == 1)",
    "line": 72
  }],
  "prId": 23873
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "I think all attributes in `requiredFieldMap` are struct type, isn't?",
    "commit": "b2fc45c411275088ea87dcb31f3900f893f59832",
    "createdAt": "2019-02-26T15:57:44Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * This aims to handle nested column pruning pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can create a new [[CreateNamedStruct]] containing only\n+ * subset of the fields as a new project in the child.\n+ */\n+object NestedColumnPruning {\n+\n+  type ExprMap = Map[Expression, Expression]\n+  type RequiredFieldMap = Map[Attribute, Set[GetStructField]]\n+\n+  def unapply(plan: LogicalPlan): Option[(Map[ExprId, Alias], ExprMap)] = plan match {\n+    case p @ Project(_, child) if canProjectPushThrough(child) =>\n+      getPrunedNestedAttrsAndProjects(getRequiredFieldMap(p, child))\n+    case _ => None\n+  }\n+\n+  /**\n+   * Add projects to prune unused nested columns.\n+   */\n+  def prune(\n+      plan: LogicalPlan,\n+      nestedAttrs: Map[ExprId, Alias],\n+      projectsOnNestedAttrs: ExprMap): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>\n+      Project(\n+        getNewProjectList(projectList, projectsOnNestedAttrs),\n+        g.copy(child = addPrunedProjectToChildren(grandChild, nestedAttrs)))\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, projectsOnNestedAttrs),\n+        addPrunedProjectToChildren(child, nestedAttrs))\n+    case _ => plan\n+  }\n+\n+  /**\n+   * Get a map from a referenced attribute to its set of required fields.\n+   */\n+  private def getRequiredFieldMap(plans: LogicalPlan*): RequiredFieldMap = {\n+    val rootReferenceAttrSet = plans.map(getRootReferences).reduce(_ ++ _)\n+    val nestedFieldReferences = plans.map(getNestedFieldReferences).reduce(_ ++ _)\n+\n+    nestedFieldReferences\n+      .filter(!_.references.subsetOf(rootReferenceAttrSet))\n+      .groupBy(_.references)\n+      .filter(_._1.size == 1)\n+      .map(x => (x._1.head, x._2.toSet))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(projectList: Seq[NamedExpression], projectsOnNestedAttrs: ExprMap) =\n+    projectList.map(_.transform {\n+      case e if projectsOnNestedAttrs.contains(e) => projectsOnNestedAttrs(e)\n+    }.asInstanceOf[NamedExpression])\n+\n+  /**\n+   * Return a plan with new childen pruned with `Project`.\n+   */\n+  private def addPrunedProjectToChildren(plan: LogicalPlan, nestedAttrs: Map[ExprId, Alias]) =\n+    plan.withNewChildren(plan.children.map { child =>\n+      Project(child.output.map(a => nestedAttrs.getOrElse(a.exprId, a)), child)\n+    })\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Similar to [[QueryPlan.references]], but this only returns all attributes\n+   * that are explicitly referenced on the root levels in a [[LogicalPlan]].\n+   */\n+  private def getRootReferences(plan: LogicalPlan) = {\n+    def helper(e: Expression): AttributeSet = e match {\n+      case attr: AttributeReference => AttributeSet(attr)\n+      case _: GetStructField => AttributeSet.empty\n+      case es if es.children.nonEmpty => AttributeSet(es.children.flatMap(helper))\n+      case _ => AttributeSet.empty\n+    }\n+    AttributeSet.fromAttributeSets(plan.expressions.map(helper))\n+  }\n+\n+  /**\n+   * Returns all the nested fields that are explicitly referenced as [[Expression]]\n+   * in a [[LogicalPlan]]. Currently, we only support having [[GetStructField]] in the chain\n+   * of the expressions. If the chain contains GetArrayStructFields, GetMapValue, or\n+   * GetArrayItem, the nested field substitution will not be performed.\n+   */\n+  private def getNestedFieldReferences(plan: LogicalPlan): Seq[GetStructField] = {\n+    def helper(e: Expression): Seq[GetStructField] = e match {\n+      case f @ GetStructField(child, _, _) if isGetStructFieldOrAttr(child) => Seq(f)\n+      case es if es.children.nonEmpty => es.children.flatMap(e => helper(e))\n+      case _ => Seq.empty\n+    }\n+\n+    def isGetStructFieldOrAttr(e: Expression): Boolean = e match {\n+      case GetStructField(child, _, _) => isGetStructFieldOrAttr(child)\n+      case _: AttributeReference => true\n+      case _ => false\n+    }\n+\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return `CreateNamedStruct` iff the given expression is a struct type consisting of\n+   * some of the given nested fields. Otherwise, this returns None.\n+   */\n+  private def getReducedCreateNamedStruct(expression: Expression, nestedFields: Set[GetStructField])\n+    : Option[CreateNamedStruct] = {\n+    expression.dataType match {\n+      case st: StructType =>\n+        val pairs = st.zipWithIndex.flatMap { case (structField, ordinal) =>\n+          val newField = GetStructField(expression, ordinal, Some(structField.name))\n+          if (nestedFields.map(_.canonicalized).contains(newField.canonicalized)) {\n+            Seq(Literal(structField.name), newField)\n+          } else {\n+            None\n+          }\n+        }\n+        if (pairs.nonEmpty && pairs.length / 2 < st.length) {\n+          Some(CreateNamedStruct(pairs))\n+        } else {\n+          None\n+        }\n+      case _ => None",
    "line": 160
  }],
  "prId": 23873
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "We need to handle GlobalLimit(LocalLimit) in a single iteration here? In a next call, the match below (`case Project(projectList, child) =>`) handles this case like `GlobalLimit(Project(LocalLimit))` -> `GlobalLimit(LocalLimit(Project)`?",
    "commit": "b2fc45c411275088ea87dcb31f3900f893f59832",
    "createdAt": "2019-02-27T04:30:10Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * This aims to handle nested column pruning pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can create a new [[CreateNamedStruct]] containing only\n+ * subset of the fields as a new project in the child.\n+ */\n+object NestedColumnPruning {\n+\n+  type ExprMap = Map[Expression, Expression]\n+  type RequiredFieldMap = Map[Attribute, Set[GetStructField]]\n+\n+  def unapply(plan: LogicalPlan): Option[(Map[ExprId, Alias], ExprMap)] = plan match {\n+    case p @ Project(_, child) if canProjectPushThrough(child) =>\n+      getPrunedNestedAttrsAndProjects(getRequiredFieldMap(p, child))\n+    case _ => None\n+  }\n+\n+  /**\n+   * Add projects to prune unused nested columns.\n+   */\n+  def prune(\n+      plan: LogicalPlan,\n+      nestedAttrs: Map[ExprId, Alias],\n+      projectsOnNestedAttrs: ExprMap): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>\n+      Project(",
    "line": 52
  }],
  "prId": 23873
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "we need a required field map for `child`? `getPrunedNestedAttrsAndProjects(getRequiredFieldMap(p))` is not correct?",
    "commit": "b2fc45c411275088ea87dcb31f3900f893f59832",
    "createdAt": "2019-02-27T04:31:31Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * This aims to handle nested column pruning pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can create a new [[CreateNamedStruct]] containing only\n+ * subset of the fields as a new project in the child.\n+ */\n+object NestedColumnPruning {\n+\n+  type ExprMap = Map[Expression, Expression]\n+  type RequiredFieldMap = Map[Attribute, Set[GetStructField]]\n+\n+  def unapply(plan: LogicalPlan): Option[(Map[ExprId, Alias], ExprMap)] = plan match {\n+    case p @ Project(_, child) if canProjectPushThrough(child) =>\n+      getPrunedNestedAttrsAndProjects(getRequiredFieldMap(p, child))",
    "line": 40
  }],
  "prId": 23873
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Is the current logic different from the code below?\r\n```\r\n  private def getNestedFieldReferences(plan: LogicalPlan): Seq[GetStructField] = {\r\n    plan.expressions.flatMap(_.collect {\r\n      case gsf @ GetStructField(_: AttributeReference, _, _) => gsf\r\n    })\r\n  }\r\n```",
    "commit": "b2fc45c411275088ea87dcb31f3900f893f59832",
    "createdAt": "2019-02-27T04:33:39Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * This aims to handle nested column pruning pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can create a new [[CreateNamedStruct]] containing only\n+ * subset of the fields as a new project in the child.\n+ */\n+object NestedColumnPruning {\n+\n+  type ExprMap = Map[Expression, Expression]\n+  type RequiredFieldMap = Map[Attribute, Set[GetStructField]]\n+\n+  def unapply(plan: LogicalPlan): Option[(Map[ExprId, Alias], ExprMap)] = plan match {\n+    case p @ Project(_, child) if canProjectPushThrough(child) =>\n+      getPrunedNestedAttrsAndProjects(getRequiredFieldMap(p, child))\n+    case _ => None\n+  }\n+\n+  /**\n+   * Add projects to prune unused nested columns.\n+   */\n+  def prune(\n+      plan: LogicalPlan,\n+      nestedAttrs: Map[ExprId, Alias],\n+      projectsOnNestedAttrs: ExprMap): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>\n+      Project(\n+        getNewProjectList(projectList, projectsOnNestedAttrs),\n+        g.copy(child = addPrunedProjectToChildren(grandChild, nestedAttrs)))\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, projectsOnNestedAttrs),\n+        addPrunedProjectToChildren(child, nestedAttrs))\n+    case _ => plan\n+  }\n+\n+  /**\n+   * Get a map from a referenced attribute to its set of required fields.\n+   */\n+  private def getRequiredFieldMap(plans: LogicalPlan*): RequiredFieldMap = {\n+    val rootReferenceAttrSet = plans.map(getRootReferences).reduce(_ ++ _)\n+    val nestedFieldReferences = plans.map(getNestedFieldReferences).reduce(_ ++ _)\n+\n+    nestedFieldReferences\n+      .filter(!_.references.subsetOf(rootReferenceAttrSet))\n+      .groupBy(_.references)\n+      .filter(_._1.size == 1)\n+      .map(x => (x._1.head, x._2.toSet))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(projectList: Seq[NamedExpression], projectsOnNestedAttrs: ExprMap) =\n+    projectList.map(_.transform {\n+      case e if projectsOnNestedAttrs.contains(e) => projectsOnNestedAttrs(e)\n+    }.asInstanceOf[NamedExpression])\n+\n+  /**\n+   * Return a plan with new childen pruned with `Project`.\n+   */\n+  private def addPrunedProjectToChildren(plan: LogicalPlan, nestedAttrs: Map[ExprId, Alias]) =\n+    plan.withNewChildren(plan.children.map { child =>\n+      Project(child.output.map(a => nestedAttrs.getOrElse(a.exprId, a)), child)\n+    })\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Similar to [[QueryPlan.references]], but this only returns all attributes\n+   * that are explicitly referenced on the root levels in a [[LogicalPlan]].\n+   */\n+  private def getRootReferences(plan: LogicalPlan) = {\n+    def helper(e: Expression): AttributeSet = e match {\n+      case attr: AttributeReference => AttributeSet(attr)\n+      case _: GetStructField => AttributeSet.empty\n+      case es if es.children.nonEmpty => AttributeSet(es.children.flatMap(helper))\n+      case _ => AttributeSet.empty\n+    }\n+    AttributeSet.fromAttributeSets(plan.expressions.map(helper))\n+  }\n+\n+  /**\n+   * Returns all the nested fields that are explicitly referenced as [[Expression]]\n+   * in a [[LogicalPlan]]. Currently, we only support having [[GetStructField]] in the chain\n+   * of the expressions. If the chain contains GetArrayStructFields, GetMapValue, or\n+   * GetArrayItem, the nested field substitution will not be performed.\n+   */\n+  private def getNestedFieldReferences(plan: LogicalPlan): Seq[GetStructField] = {",
    "line": 123
  }],
  "prId": 23873
}]