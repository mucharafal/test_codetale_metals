[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "can u define the return value?\n",
    "commit": "eeee512bd94d463f741170e904ae186e238f997c",
    "createdAt": "2015-04-28T07:49:49Z",
    "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.PlatformDependent\n+import org.apache.spark.unsafe.array.ByteArrayMethods\n+\n+/**\n+ * Converts Rows into UnsafeRow format. This class is NOT thread-safe.\n+ *\n+ * @param fieldTypes the data types of the row's columns.\n+ */\n+class UnsafeRowConverter(fieldTypes: Array[DataType]) {\n+\n+  def this(schema: StructType) {\n+    this(schema.fields.map(_.dataType))\n+  }\n+\n+  /** Re-used pointer to the unsafe row being written */\n+  private[this] val unsafeRow = new UnsafeRow()\n+\n+  /** Functions for encoding each column */\n+  private[this] val writers: Array[UnsafeColumnWriter[Any]] = {\n+    fieldTypes.map(t => UnsafeColumnWriter.forType(t).asInstanceOf[UnsafeColumnWriter[Any]])\n+  }\n+\n+  /** The size, in bytes, of the fixed-length portion of the row, including the null bitmap */\n+  private[this] val fixedLengthSize: Int =\n+    (8 * fieldTypes.length) + UnsafeRow.calculateBitSetWidthInBytes(fieldTypes.length)\n+\n+  /**\n+   * Compute the amount of space, in bytes, required to encode the given row.\n+   */\n+  def getSizeRequirement(row: Row): Int = {\n+    var fieldNumber = 0\n+    var variableLengthFieldSize: Int = 0\n+    while (fieldNumber < writers.length) {\n+      if (!row.isNullAt(fieldNumber)) {\n+        variableLengthFieldSize += writers(fieldNumber).getSize(row(fieldNumber))\n+      }\n+      fieldNumber += 1\n+    }\n+    fixedLengthSize + variableLengthFieldSize\n+  }\n+\n+  /**\n+   * Convert the given row into UnsafeRow format.\n+   *\n+   * @param row the row to convert\n+   * @param baseObject the base object of the destination address\n+   * @param baseOffset the base offset of the destination address\n+   * @return the number of bytes written. This should be equal to `getSizeRequirement(row)`.\n+   */\n+  def writeRow(row: Row, baseObject: Object, baseOffset: Long): Long = {\n+    unsafeRow.pointTo(baseObject, baseOffset, writers.length, null)\n+    var fieldNumber = 0\n+    var appendCursor: Int = fixedLengthSize\n+    while (fieldNumber < writers.length) {\n+      if (row.isNullAt(fieldNumber)) {\n+        unsafeRow.setNullAt(fieldNumber)\n+      } else {\n+        appendCursor += writers(fieldNumber).write(\n+          row(fieldNumber),\n+          fieldNumber,\n+          unsafeRow,\n+          baseObject,\n+          baseOffset,\n+          appendCursor)\n+      }\n+      fieldNumber += 1\n+    }\n+    appendCursor\n+  }\n+\n+}\n+\n+/**\n+ * Function for writing a column into an UnsafeRow.\n+ */\n+private abstract class UnsafeColumnWriter[T] {\n+  /**\n+   * Write a value into an UnsafeRow.\n+   *\n+   * @param value the value to write\n+   * @param columnNumber what column to write it to\n+   * @param row a pointer to the unsafe row\n+   * @param baseObject the base object of the target row's address\n+   * @param baseOffset the base offset of the target row's address\n+   * @param appendCursor the offset from the start of the unsafe row to the end of the row;\n+   *                     used for calculating where variable-length data should be written\n+   * @return the number of variable-length bytes written\n+   */\n+  def write(\n+      value: T,\n+      columnNumber: Int,\n+      row: UnsafeRow,\n+      baseObject: Object,\n+      baseOffset: Long,\n+      appendCursor: Int): Int\n+\n+  /**\n+   * Return the number of bytes that are needed to write this variable-length value.\n+   */\n+  def getSize(value: T): Int\n+}\n+\n+private object UnsafeColumnWriter {\n+\n+  def forType(dataType: DataType): UnsafeColumnWriter[_] = {\n+    dataType match {\n+      case IntegerType => IntUnsafeColumnWriter\n+      case LongType => LongUnsafeColumnWriter\n+      case FloatType => FloatUnsafeColumnWriter\n+      case DoubleType => DoubleUnsafeColumnWriter\n+      case StringType => StringUnsafeColumnWriter\n+      case t =>\n+        throw new UnsupportedOperationException(s\"Do not know how to write columns of type $t\")\n+    }\n+  }\n+}\n+\n+// ------------------------------------------------------------------------------------------------\n+\n+private object IntUnsafeColumnWriter extends IntUnsafeColumnWriter\n+private object LongUnsafeColumnWriter extends LongUnsafeColumnWriter\n+private object FloatUnsafeColumnWriter extends FloatUnsafeColumnWriter\n+private object DoubleUnsafeColumnWriter extends DoubleUnsafeColumnWriter\n+private object StringUnsafeColumnWriter extends StringUnsafeColumnWriter\n+\n+private abstract class PrimitiveUnsafeColumnWriter[T] extends UnsafeColumnWriter[T] {\n+  def getSize(value: T): Int = 0\n+}\n+\n+private class IntUnsafeColumnWriter private() extends PrimitiveUnsafeColumnWriter[Int] {\n+  override def write("
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "The return value is the number of bytes written, which we use to increment the position cursor.  I think that I commented on this in the base `UnsafeColumnWriter` class.\n",
    "commit": "eeee512bd94d463f741170e904ae186e238f997c",
    "createdAt": "2015-04-28T17:41:49Z",
    "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.PlatformDependent\n+import org.apache.spark.unsafe.array.ByteArrayMethods\n+\n+/**\n+ * Converts Rows into UnsafeRow format. This class is NOT thread-safe.\n+ *\n+ * @param fieldTypes the data types of the row's columns.\n+ */\n+class UnsafeRowConverter(fieldTypes: Array[DataType]) {\n+\n+  def this(schema: StructType) {\n+    this(schema.fields.map(_.dataType))\n+  }\n+\n+  /** Re-used pointer to the unsafe row being written */\n+  private[this] val unsafeRow = new UnsafeRow()\n+\n+  /** Functions for encoding each column */\n+  private[this] val writers: Array[UnsafeColumnWriter[Any]] = {\n+    fieldTypes.map(t => UnsafeColumnWriter.forType(t).asInstanceOf[UnsafeColumnWriter[Any]])\n+  }\n+\n+  /** The size, in bytes, of the fixed-length portion of the row, including the null bitmap */\n+  private[this] val fixedLengthSize: Int =\n+    (8 * fieldTypes.length) + UnsafeRow.calculateBitSetWidthInBytes(fieldTypes.length)\n+\n+  /**\n+   * Compute the amount of space, in bytes, required to encode the given row.\n+   */\n+  def getSizeRequirement(row: Row): Int = {\n+    var fieldNumber = 0\n+    var variableLengthFieldSize: Int = 0\n+    while (fieldNumber < writers.length) {\n+      if (!row.isNullAt(fieldNumber)) {\n+        variableLengthFieldSize += writers(fieldNumber).getSize(row(fieldNumber))\n+      }\n+      fieldNumber += 1\n+    }\n+    fixedLengthSize + variableLengthFieldSize\n+  }\n+\n+  /**\n+   * Convert the given row into UnsafeRow format.\n+   *\n+   * @param row the row to convert\n+   * @param baseObject the base object of the destination address\n+   * @param baseOffset the base offset of the destination address\n+   * @return the number of bytes written. This should be equal to `getSizeRequirement(row)`.\n+   */\n+  def writeRow(row: Row, baseObject: Object, baseOffset: Long): Long = {\n+    unsafeRow.pointTo(baseObject, baseOffset, writers.length, null)\n+    var fieldNumber = 0\n+    var appendCursor: Int = fixedLengthSize\n+    while (fieldNumber < writers.length) {\n+      if (row.isNullAt(fieldNumber)) {\n+        unsafeRow.setNullAt(fieldNumber)\n+      } else {\n+        appendCursor += writers(fieldNumber).write(\n+          row(fieldNumber),\n+          fieldNumber,\n+          unsafeRow,\n+          baseObject,\n+          baseOffset,\n+          appendCursor)\n+      }\n+      fieldNumber += 1\n+    }\n+    appendCursor\n+  }\n+\n+}\n+\n+/**\n+ * Function for writing a column into an UnsafeRow.\n+ */\n+private abstract class UnsafeColumnWriter[T] {\n+  /**\n+   * Write a value into an UnsafeRow.\n+   *\n+   * @param value the value to write\n+   * @param columnNumber what column to write it to\n+   * @param row a pointer to the unsafe row\n+   * @param baseObject the base object of the target row's address\n+   * @param baseOffset the base offset of the target row's address\n+   * @param appendCursor the offset from the start of the unsafe row to the end of the row;\n+   *                     used for calculating where variable-length data should be written\n+   * @return the number of variable-length bytes written\n+   */\n+  def write(\n+      value: T,\n+      columnNumber: Int,\n+      row: UnsafeRow,\n+      baseObject: Object,\n+      baseOffset: Long,\n+      appendCursor: Int): Int\n+\n+  /**\n+   * Return the number of bytes that are needed to write this variable-length value.\n+   */\n+  def getSize(value: T): Int\n+}\n+\n+private object UnsafeColumnWriter {\n+\n+  def forType(dataType: DataType): UnsafeColumnWriter[_] = {\n+    dataType match {\n+      case IntegerType => IntUnsafeColumnWriter\n+      case LongType => LongUnsafeColumnWriter\n+      case FloatType => FloatUnsafeColumnWriter\n+      case DoubleType => DoubleUnsafeColumnWriter\n+      case StringType => StringUnsafeColumnWriter\n+      case t =>\n+        throw new UnsupportedOperationException(s\"Do not know how to write columns of type $t\")\n+    }\n+  }\n+}\n+\n+// ------------------------------------------------------------------------------------------------\n+\n+private object IntUnsafeColumnWriter extends IntUnsafeColumnWriter\n+private object LongUnsafeColumnWriter extends LongUnsafeColumnWriter\n+private object FloatUnsafeColumnWriter extends FloatUnsafeColumnWriter\n+private object DoubleUnsafeColumnWriter extends DoubleUnsafeColumnWriter\n+private object StringUnsafeColumnWriter extends StringUnsafeColumnWriter\n+\n+private abstract class PrimitiveUnsafeColumnWriter[T] extends UnsafeColumnWriter[T] {\n+  def getSize(value: T): Int = 0\n+}\n+\n+private class IntUnsafeColumnWriter private() extends PrimitiveUnsafeColumnWriter[Int] {\n+  override def write("
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "More specifically, this is the number of variable-length bytes written.  Primitive types, like int, don't write to the variable-length portion and thus return 0.\n",
    "commit": "eeee512bd94d463f741170e904ae186e238f997c",
    "createdAt": "2015-04-28T18:38:28Z",
    "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.PlatformDependent\n+import org.apache.spark.unsafe.array.ByteArrayMethods\n+\n+/**\n+ * Converts Rows into UnsafeRow format. This class is NOT thread-safe.\n+ *\n+ * @param fieldTypes the data types of the row's columns.\n+ */\n+class UnsafeRowConverter(fieldTypes: Array[DataType]) {\n+\n+  def this(schema: StructType) {\n+    this(schema.fields.map(_.dataType))\n+  }\n+\n+  /** Re-used pointer to the unsafe row being written */\n+  private[this] val unsafeRow = new UnsafeRow()\n+\n+  /** Functions for encoding each column */\n+  private[this] val writers: Array[UnsafeColumnWriter[Any]] = {\n+    fieldTypes.map(t => UnsafeColumnWriter.forType(t).asInstanceOf[UnsafeColumnWriter[Any]])\n+  }\n+\n+  /** The size, in bytes, of the fixed-length portion of the row, including the null bitmap */\n+  private[this] val fixedLengthSize: Int =\n+    (8 * fieldTypes.length) + UnsafeRow.calculateBitSetWidthInBytes(fieldTypes.length)\n+\n+  /**\n+   * Compute the amount of space, in bytes, required to encode the given row.\n+   */\n+  def getSizeRequirement(row: Row): Int = {\n+    var fieldNumber = 0\n+    var variableLengthFieldSize: Int = 0\n+    while (fieldNumber < writers.length) {\n+      if (!row.isNullAt(fieldNumber)) {\n+        variableLengthFieldSize += writers(fieldNumber).getSize(row(fieldNumber))\n+      }\n+      fieldNumber += 1\n+    }\n+    fixedLengthSize + variableLengthFieldSize\n+  }\n+\n+  /**\n+   * Convert the given row into UnsafeRow format.\n+   *\n+   * @param row the row to convert\n+   * @param baseObject the base object of the destination address\n+   * @param baseOffset the base offset of the destination address\n+   * @return the number of bytes written. This should be equal to `getSizeRequirement(row)`.\n+   */\n+  def writeRow(row: Row, baseObject: Object, baseOffset: Long): Long = {\n+    unsafeRow.pointTo(baseObject, baseOffset, writers.length, null)\n+    var fieldNumber = 0\n+    var appendCursor: Int = fixedLengthSize\n+    while (fieldNumber < writers.length) {\n+      if (row.isNullAt(fieldNumber)) {\n+        unsafeRow.setNullAt(fieldNumber)\n+      } else {\n+        appendCursor += writers(fieldNumber).write(\n+          row(fieldNumber),\n+          fieldNumber,\n+          unsafeRow,\n+          baseObject,\n+          baseOffset,\n+          appendCursor)\n+      }\n+      fieldNumber += 1\n+    }\n+    appendCursor\n+  }\n+\n+}\n+\n+/**\n+ * Function for writing a column into an UnsafeRow.\n+ */\n+private abstract class UnsafeColumnWriter[T] {\n+  /**\n+   * Write a value into an UnsafeRow.\n+   *\n+   * @param value the value to write\n+   * @param columnNumber what column to write it to\n+   * @param row a pointer to the unsafe row\n+   * @param baseObject the base object of the target row's address\n+   * @param baseOffset the base offset of the target row's address\n+   * @param appendCursor the offset from the start of the unsafe row to the end of the row;\n+   *                     used for calculating where variable-length data should be written\n+   * @return the number of variable-length bytes written\n+   */\n+  def write(\n+      value: T,\n+      columnNumber: Int,\n+      row: UnsafeRow,\n+      baseObject: Object,\n+      baseOffset: Long,\n+      appendCursor: Int): Int\n+\n+  /**\n+   * Return the number of bytes that are needed to write this variable-length value.\n+   */\n+  def getSize(value: T): Int\n+}\n+\n+private object UnsafeColumnWriter {\n+\n+  def forType(dataType: DataType): UnsafeColumnWriter[_] = {\n+    dataType match {\n+      case IntegerType => IntUnsafeColumnWriter\n+      case LongType => LongUnsafeColumnWriter\n+      case FloatType => FloatUnsafeColumnWriter\n+      case DoubleType => DoubleUnsafeColumnWriter\n+      case StringType => StringUnsafeColumnWriter\n+      case t =>\n+        throw new UnsupportedOperationException(s\"Do not know how to write columns of type $t\")\n+    }\n+  }\n+}\n+\n+// ------------------------------------------------------------------------------------------------\n+\n+private object IntUnsafeColumnWriter extends IntUnsafeColumnWriter\n+private object LongUnsafeColumnWriter extends LongUnsafeColumnWriter\n+private object FloatUnsafeColumnWriter extends FloatUnsafeColumnWriter\n+private object DoubleUnsafeColumnWriter extends DoubleUnsafeColumnWriter\n+private object StringUnsafeColumnWriter extends StringUnsafeColumnWriter\n+\n+private abstract class PrimitiveUnsafeColumnWriter[T] extends UnsafeColumnWriter[T] {\n+  def getSize(value: T): Int = 0\n+}\n+\n+private class IntUnsafeColumnWriter private() extends PrimitiveUnsafeColumnWriter[Int] {\n+  override def write("
  }],
  "prId": 5725
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "This is pretty minor, but is there a reason we are boxing here instead of passing the row itself in, allowing a specific accessor to be used for extraction?\n",
    "commit": "eeee512bd94d463f741170e904ae186e238f997c",
    "createdAt": "2015-04-29T00:03:58Z",
    "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.PlatformDependent\n+import org.apache.spark.unsafe.array.ByteArrayMethods\n+\n+/**\n+ * Converts Rows into UnsafeRow format. This class is NOT thread-safe.\n+ *\n+ * @param fieldTypes the data types of the row's columns.\n+ */\n+class UnsafeRowConverter(fieldTypes: Array[DataType]) {\n+\n+  def this(schema: StructType) {\n+    this(schema.fields.map(_.dataType))\n+  }\n+\n+  /** Re-used pointer to the unsafe row being written */\n+  private[this] val unsafeRow = new UnsafeRow()\n+\n+  /** Functions for encoding each column */\n+  private[this] val writers: Array[UnsafeColumnWriter[Any]] = {\n+    fieldTypes.map(t => UnsafeColumnWriter.forType(t).asInstanceOf[UnsafeColumnWriter[Any]])\n+  }\n+\n+  /** The size, in bytes, of the fixed-length portion of the row, including the null bitmap */\n+  private[this] val fixedLengthSize: Int =\n+    (8 * fieldTypes.length) + UnsafeRow.calculateBitSetWidthInBytes(fieldTypes.length)\n+\n+  /**\n+   * Compute the amount of space, in bytes, required to encode the given row.\n+   */\n+  def getSizeRequirement(row: Row): Int = {\n+    var fieldNumber = 0\n+    var variableLengthFieldSize: Int = 0\n+    while (fieldNumber < writers.length) {\n+      if (!row.isNullAt(fieldNumber)) {\n+        variableLengthFieldSize += writers(fieldNumber).getSize(row(fieldNumber))\n+      }\n+      fieldNumber += 1\n+    }\n+    fixedLengthSize + variableLengthFieldSize\n+  }\n+\n+  /**\n+   * Convert the given row into UnsafeRow format.\n+   *\n+   * @param row the row to convert\n+   * @param baseObject the base object of the destination address\n+   * @param baseOffset the base offset of the destination address\n+   * @return the number of bytes written. This should be equal to `getSizeRequirement(row)`.\n+   */\n+  def writeRow(row: Row, baseObject: Object, baseOffset: Long): Long = {\n+    unsafeRow.pointTo(baseObject, baseOffset, writers.length, null)\n+    var fieldNumber = 0\n+    var appendCursor: Int = fixedLengthSize\n+    while (fieldNumber < writers.length) {\n+      if (row.isNullAt(fieldNumber)) {\n+        unsafeRow.setNullAt(fieldNumber)\n+      } else {\n+        appendCursor += writers(fieldNumber).write(\n+          row(fieldNumber),"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "That's a really good idea; can't believe I didn't think of that...\n\nShould be an easy change, so I'll do this shortly.\n",
    "commit": "eeee512bd94d463f741170e904ae186e238f997c",
    "createdAt": "2015-04-29T00:17:16Z",
    "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.PlatformDependent\n+import org.apache.spark.unsafe.array.ByteArrayMethods\n+\n+/**\n+ * Converts Rows into UnsafeRow format. This class is NOT thread-safe.\n+ *\n+ * @param fieldTypes the data types of the row's columns.\n+ */\n+class UnsafeRowConverter(fieldTypes: Array[DataType]) {\n+\n+  def this(schema: StructType) {\n+    this(schema.fields.map(_.dataType))\n+  }\n+\n+  /** Re-used pointer to the unsafe row being written */\n+  private[this] val unsafeRow = new UnsafeRow()\n+\n+  /** Functions for encoding each column */\n+  private[this] val writers: Array[UnsafeColumnWriter[Any]] = {\n+    fieldTypes.map(t => UnsafeColumnWriter.forType(t).asInstanceOf[UnsafeColumnWriter[Any]])\n+  }\n+\n+  /** The size, in bytes, of the fixed-length portion of the row, including the null bitmap */\n+  private[this] val fixedLengthSize: Int =\n+    (8 * fieldTypes.length) + UnsafeRow.calculateBitSetWidthInBytes(fieldTypes.length)\n+\n+  /**\n+   * Compute the amount of space, in bytes, required to encode the given row.\n+   */\n+  def getSizeRequirement(row: Row): Int = {\n+    var fieldNumber = 0\n+    var variableLengthFieldSize: Int = 0\n+    while (fieldNumber < writers.length) {\n+      if (!row.isNullAt(fieldNumber)) {\n+        variableLengthFieldSize += writers(fieldNumber).getSize(row(fieldNumber))\n+      }\n+      fieldNumber += 1\n+    }\n+    fixedLengthSize + variableLengthFieldSize\n+  }\n+\n+  /**\n+   * Convert the given row into UnsafeRow format.\n+   *\n+   * @param row the row to convert\n+   * @param baseObject the base object of the destination address\n+   * @param baseOffset the base offset of the destination address\n+   * @return the number of bytes written. This should be equal to `getSizeRequirement(row)`.\n+   */\n+  def writeRow(row: Row, baseObject: Object, baseOffset: Long): Long = {\n+    unsafeRow.pointTo(baseObject, baseOffset, writers.length, null)\n+    var fieldNumber = 0\n+    var appendCursor: Int = fixedLengthSize\n+    while (fieldNumber < writers.length) {\n+      if (row.isNullAt(fieldNumber)) {\n+        unsafeRow.setNullAt(fieldNumber)\n+      } else {\n+        appendCursor += writers(fieldNumber).write(\n+          row(fieldNumber),"
  }],
  "prId": 5725
}]