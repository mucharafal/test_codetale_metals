[{
  "comments": [{
    "author": {
      "login": "mgaido91"
    },
    "body": "I don't see the need for this and the next. As of now, we are not handling overflows with integers (you can see https://github.com/apache/spark/pull/21599 is still open). So I think we can get rid of these checks. It may be worth, though, to add a comment (like a TODO) in order to remind that this issue can arise",
    "commit": "43892acab8a3508cbb55ce2012ff5a6487fab181",
    "createdAt": "2019-03-08T10:15:53Z",
    "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical.{Filter, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Rewrite arithmetic filters on an integral-type (e.g., byte, short, int and long)\n+ * column to its equivalent form, leaving attribute alone in a left side, so that\n+ * we can push it down to datasources (e.g., Parquet and ORC).\n+ *\n+ * For example, this rule can optimize a query as follows:\n+ * {{{\n+ *   SELECT * FROM table WHERE i + 3 = 5\n+ *   ==> SELECT * FROM table WHERE i = 5 - 3\n+ * }}}\n+ *\n+ * Then, the [[ConstantFolding]] rule will further optimize it as follows:\n+ * {{{\n+ *   SELECT * FROM table WHERE i = 2\n+ * }}}\n+ *\n+ * Note:\n+ * 1. This rule supports `Add` and `Subtract` in arithmetic expressions.\n+ * 2. This rule supports `=`, `>=`, `<=`, `>`, `<`, and `!=` in comparators.\n+ * 3. This rule supports integral-type (`byte`, `short`, `int`, `long`) only.\n+ *    It doesn't support `float` or `double` because of precision issues.\n+  */\n+object RewriteArithmeticFiltersOnIntegralColumn extends Rule[LogicalPlan] with PredicateHelper {\n+  def apply(plan: LogicalPlan): LogicalPlan = plan transform {\n+    case f: Filter =>\n+      f transformExpressionsUp {\n+        case e @ BinaryComparison(left: BinaryArithmetic, right: Expression)\n+            if right.foldable && isDataTypeSafe(left.dataType) =>\n+          transformLeft(e, left, right)\n+        case e @ BinaryComparison(left: Expression, right: BinaryArithmetic)\n+            if left.foldable && isDataTypeSafe(right.dataType) =>\n+          transformRight(e, left, right)\n+      }\n+  }\n+\n+  private def transformLeft(\n+      bc: BinaryComparison,\n+      left: BinaryArithmetic,\n+      right: Expression): Expression = {\n+    left match {\n+      case Add(ar: AttributeReference, e) if e.foldable && isOptSafe(Subtract(right, e)) =>\n+        bc.makeCopy(Array(ar, Subtract(right, e)))\n+      case Add(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(right, e)) =>\n+        bc.makeCopy(Array(ar, Subtract(right, e)))\n+      case Subtract(ar: AttributeReference, e) if e.foldable && isOptSafe(Add(right, e)) =>\n+        bc.makeCopy(Array(ar, Add(right, e)))\n+      case Subtract(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(e, right)) =>\n+        bc.makeCopy(Array(Subtract(e, right), ar))\n+      case _ => bc\n+    }\n+  }\n+\n+  private def transformRight(\n+      bc: BinaryComparison,\n+      left: Expression,\n+      right: BinaryArithmetic): Expression = {\n+    right match {\n+      case Add(ar: AttributeReference, e) if e.foldable && isOptSafe(Subtract(left, e)) =>\n+        bc.makeCopy(Array(Subtract(left, e), ar))\n+      case Add(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(left, e)) =>\n+        bc.makeCopy(Array(Subtract(left, e), ar))\n+      case Subtract(ar: AttributeReference, e) if e.foldable && isOptSafe(Add(left, e)) =>\n+        bc.makeCopy(Array(Add(left, e), ar))\n+      case Subtract(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(e, left)) =>\n+        bc.makeCopy(Array(ar, Subtract(e, left)))\n+      case _ => bc\n+    }\n+  }\n+\n+  private def isDataTypeSafe(dataType: DataType): Boolean = dataType match {\n+    case ByteType | ShortType | IntegerType | LongType => true\n+    case _ => false\n+  }\n+\n+  private def isOptSafe(e: BinaryArithmetic): Boolean = {\n+    val leftVal = e.left.eval(EmptyRow)\n+    val rightVal = e.right.eval(EmptyRow)\n+\n+    e match {\n+      case Add(_, _) =>\n+        e.dataType match {\n+          case ByteType =>\n+            isAddSafe(leftVal, rightVal, Byte.MinValue, Byte.MaxValue)\n+          case ShortType =>\n+            isAddSafe(leftVal, rightVal, Short.MinValue, Short.MaxValue)\n+          case IntegerType =>\n+            isAddSafe(leftVal, rightVal, Int.MinValue, Int.MaxValue)\n+          case LongType =>\n+            isAddSafe(leftVal, rightVal, Long.MinValue, Long.MaxValue)\n+          case _ => false\n+        }\n+\n+      case Subtract(_, _) =>\n+        e.dataType match {\n+          case ByteType =>\n+            isSubtractSafe(leftVal, rightVal, Byte.MinValue, Byte.MaxValue)\n+          case ShortType =>\n+            isSubtractSafe(leftVal, rightVal, Short.MinValue, Short.MaxValue)\n+          case IntegerType =>\n+            isSubtractSafe(leftVal, rightVal, Int.MinValue, Int.MaxValue)\n+          case LongType =>\n+            isSubtractSafe(leftVal, rightVal, Long.MinValue, Long.MaxValue)\n+          case _ => false\n+        }\n+\n+      case _ => false\n+    }\n+  }\n+\n+  private def isAddSafe[T](left: Any, right: Any, minValue: T, maxValue: T)(",
    "line": 135
  }, {
    "author": {
      "login": "maryannxue"
    },
    "body": "With some cases, it doesn't necessarily cause overflow if we don't rewrite it. So there's potential inconsistency again.",
    "commit": "43892acab8a3508cbb55ce2012ff5a6487fab181",
    "createdAt": "2019-03-13T21:38:25Z",
    "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical.{Filter, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Rewrite arithmetic filters on an integral-type (e.g., byte, short, int and long)\n+ * column to its equivalent form, leaving attribute alone in a left side, so that\n+ * we can push it down to datasources (e.g., Parquet and ORC).\n+ *\n+ * For example, this rule can optimize a query as follows:\n+ * {{{\n+ *   SELECT * FROM table WHERE i + 3 = 5\n+ *   ==> SELECT * FROM table WHERE i = 5 - 3\n+ * }}}\n+ *\n+ * Then, the [[ConstantFolding]] rule will further optimize it as follows:\n+ * {{{\n+ *   SELECT * FROM table WHERE i = 2\n+ * }}}\n+ *\n+ * Note:\n+ * 1. This rule supports `Add` and `Subtract` in arithmetic expressions.\n+ * 2. This rule supports `=`, `>=`, `<=`, `>`, `<`, and `!=` in comparators.\n+ * 3. This rule supports integral-type (`byte`, `short`, `int`, `long`) only.\n+ *    It doesn't support `float` or `double` because of precision issues.\n+  */\n+object RewriteArithmeticFiltersOnIntegralColumn extends Rule[LogicalPlan] with PredicateHelper {\n+  def apply(plan: LogicalPlan): LogicalPlan = plan transform {\n+    case f: Filter =>\n+      f transformExpressionsUp {\n+        case e @ BinaryComparison(left: BinaryArithmetic, right: Expression)\n+            if right.foldable && isDataTypeSafe(left.dataType) =>\n+          transformLeft(e, left, right)\n+        case e @ BinaryComparison(left: Expression, right: BinaryArithmetic)\n+            if left.foldable && isDataTypeSafe(right.dataType) =>\n+          transformRight(e, left, right)\n+      }\n+  }\n+\n+  private def transformLeft(\n+      bc: BinaryComparison,\n+      left: BinaryArithmetic,\n+      right: Expression): Expression = {\n+    left match {\n+      case Add(ar: AttributeReference, e) if e.foldable && isOptSafe(Subtract(right, e)) =>\n+        bc.makeCopy(Array(ar, Subtract(right, e)))\n+      case Add(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(right, e)) =>\n+        bc.makeCopy(Array(ar, Subtract(right, e)))\n+      case Subtract(ar: AttributeReference, e) if e.foldable && isOptSafe(Add(right, e)) =>\n+        bc.makeCopy(Array(ar, Add(right, e)))\n+      case Subtract(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(e, right)) =>\n+        bc.makeCopy(Array(Subtract(e, right), ar))\n+      case _ => bc\n+    }\n+  }\n+\n+  private def transformRight(\n+      bc: BinaryComparison,\n+      left: Expression,\n+      right: BinaryArithmetic): Expression = {\n+    right match {\n+      case Add(ar: AttributeReference, e) if e.foldable && isOptSafe(Subtract(left, e)) =>\n+        bc.makeCopy(Array(Subtract(left, e), ar))\n+      case Add(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(left, e)) =>\n+        bc.makeCopy(Array(Subtract(left, e), ar))\n+      case Subtract(ar: AttributeReference, e) if e.foldable && isOptSafe(Add(left, e)) =>\n+        bc.makeCopy(Array(Add(left, e), ar))\n+      case Subtract(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(e, left)) =>\n+        bc.makeCopy(Array(ar, Subtract(e, left)))\n+      case _ => bc\n+    }\n+  }\n+\n+  private def isDataTypeSafe(dataType: DataType): Boolean = dataType match {\n+    case ByteType | ShortType | IntegerType | LongType => true\n+    case _ => false\n+  }\n+\n+  private def isOptSafe(e: BinaryArithmetic): Boolean = {\n+    val leftVal = e.left.eval(EmptyRow)\n+    val rightVal = e.right.eval(EmptyRow)\n+\n+    e match {\n+      case Add(_, _) =>\n+        e.dataType match {\n+          case ByteType =>\n+            isAddSafe(leftVal, rightVal, Byte.MinValue, Byte.MaxValue)\n+          case ShortType =>\n+            isAddSafe(leftVal, rightVal, Short.MinValue, Short.MaxValue)\n+          case IntegerType =>\n+            isAddSafe(leftVal, rightVal, Int.MinValue, Int.MaxValue)\n+          case LongType =>\n+            isAddSafe(leftVal, rightVal, Long.MinValue, Long.MaxValue)\n+          case _ => false\n+        }\n+\n+      case Subtract(_, _) =>\n+        e.dataType match {\n+          case ByteType =>\n+            isSubtractSafe(leftVal, rightVal, Byte.MinValue, Byte.MaxValue)\n+          case ShortType =>\n+            isSubtractSafe(leftVal, rightVal, Short.MinValue, Short.MaxValue)\n+          case IntegerType =>\n+            isSubtractSafe(leftVal, rightVal, Int.MinValue, Int.MaxValue)\n+          case LongType =>\n+            isSubtractSafe(leftVal, rightVal, Long.MinValue, Long.MaxValue)\n+          case _ => false\n+        }\n+\n+      case _ => false\n+    }\n+  }\n+\n+  private def isAddSafe[T](left: Any, right: Any, minValue: T, maxValue: T)(",
    "line": 135
  }, {
    "author": {
      "login": "WangGuangxin"
    },
    "body": "The check here is to make sure if overflow may occur after rewrite, it will not rewrite this expression.",
    "commit": "43892acab8a3508cbb55ce2012ff5a6487fab181",
    "createdAt": "2019-03-14T02:01:20Z",
    "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical.{Filter, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Rewrite arithmetic filters on an integral-type (e.g., byte, short, int and long)\n+ * column to its equivalent form, leaving attribute alone in a left side, so that\n+ * we can push it down to datasources (e.g., Parquet and ORC).\n+ *\n+ * For example, this rule can optimize a query as follows:\n+ * {{{\n+ *   SELECT * FROM table WHERE i + 3 = 5\n+ *   ==> SELECT * FROM table WHERE i = 5 - 3\n+ * }}}\n+ *\n+ * Then, the [[ConstantFolding]] rule will further optimize it as follows:\n+ * {{{\n+ *   SELECT * FROM table WHERE i = 2\n+ * }}}\n+ *\n+ * Note:\n+ * 1. This rule supports `Add` and `Subtract` in arithmetic expressions.\n+ * 2. This rule supports `=`, `>=`, `<=`, `>`, `<`, and `!=` in comparators.\n+ * 3. This rule supports integral-type (`byte`, `short`, `int`, `long`) only.\n+ *    It doesn't support `float` or `double` because of precision issues.\n+  */\n+object RewriteArithmeticFiltersOnIntegralColumn extends Rule[LogicalPlan] with PredicateHelper {\n+  def apply(plan: LogicalPlan): LogicalPlan = plan transform {\n+    case f: Filter =>\n+      f transformExpressionsUp {\n+        case e @ BinaryComparison(left: BinaryArithmetic, right: Expression)\n+            if right.foldable && isDataTypeSafe(left.dataType) =>\n+          transformLeft(e, left, right)\n+        case e @ BinaryComparison(left: Expression, right: BinaryArithmetic)\n+            if left.foldable && isDataTypeSafe(right.dataType) =>\n+          transformRight(e, left, right)\n+      }\n+  }\n+\n+  private def transformLeft(\n+      bc: BinaryComparison,\n+      left: BinaryArithmetic,\n+      right: Expression): Expression = {\n+    left match {\n+      case Add(ar: AttributeReference, e) if e.foldable && isOptSafe(Subtract(right, e)) =>\n+        bc.makeCopy(Array(ar, Subtract(right, e)))\n+      case Add(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(right, e)) =>\n+        bc.makeCopy(Array(ar, Subtract(right, e)))\n+      case Subtract(ar: AttributeReference, e) if e.foldable && isOptSafe(Add(right, e)) =>\n+        bc.makeCopy(Array(ar, Add(right, e)))\n+      case Subtract(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(e, right)) =>\n+        bc.makeCopy(Array(Subtract(e, right), ar))\n+      case _ => bc\n+    }\n+  }\n+\n+  private def transformRight(\n+      bc: BinaryComparison,\n+      left: Expression,\n+      right: BinaryArithmetic): Expression = {\n+    right match {\n+      case Add(ar: AttributeReference, e) if e.foldable && isOptSafe(Subtract(left, e)) =>\n+        bc.makeCopy(Array(Subtract(left, e), ar))\n+      case Add(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(left, e)) =>\n+        bc.makeCopy(Array(Subtract(left, e), ar))\n+      case Subtract(ar: AttributeReference, e) if e.foldable && isOptSafe(Add(left, e)) =>\n+        bc.makeCopy(Array(Add(left, e), ar))\n+      case Subtract(e, ar: AttributeReference) if e.foldable && isOptSafe(Subtract(e, left)) =>\n+        bc.makeCopy(Array(ar, Subtract(e, left)))\n+      case _ => bc\n+    }\n+  }\n+\n+  private def isDataTypeSafe(dataType: DataType): Boolean = dataType match {\n+    case ByteType | ShortType | IntegerType | LongType => true\n+    case _ => false\n+  }\n+\n+  private def isOptSafe(e: BinaryArithmetic): Boolean = {\n+    val leftVal = e.left.eval(EmptyRow)\n+    val rightVal = e.right.eval(EmptyRow)\n+\n+    e match {\n+      case Add(_, _) =>\n+        e.dataType match {\n+          case ByteType =>\n+            isAddSafe(leftVal, rightVal, Byte.MinValue, Byte.MaxValue)\n+          case ShortType =>\n+            isAddSafe(leftVal, rightVal, Short.MinValue, Short.MaxValue)\n+          case IntegerType =>\n+            isAddSafe(leftVal, rightVal, Int.MinValue, Int.MaxValue)\n+          case LongType =>\n+            isAddSafe(leftVal, rightVal, Long.MinValue, Long.MaxValue)\n+          case _ => false\n+        }\n+\n+      case Subtract(_, _) =>\n+        e.dataType match {\n+          case ByteType =>\n+            isSubtractSafe(leftVal, rightVal, Byte.MinValue, Byte.MaxValue)\n+          case ShortType =>\n+            isSubtractSafe(leftVal, rightVal, Short.MinValue, Short.MaxValue)\n+          case IntegerType =>\n+            isSubtractSafe(leftVal, rightVal, Int.MinValue, Int.MaxValue)\n+          case LongType =>\n+            isSubtractSafe(leftVal, rightVal, Long.MinValue, Long.MaxValue)\n+          case _ => false\n+        }\n+\n+      case _ => false\n+    }\n+  }\n+\n+  private def isAddSafe[T](left: Any, right: Any, minValue: T, maxValue: T)(",
    "line": 135
  }],
  "prId": 23942
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "cc @liancheng per https://github.com/apache/spark/pull/8165",
    "commit": "43892acab8a3508cbb55ce2012ff5a6487fab181",
    "createdAt": "2019-03-25T07:42:40Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical.{Filter, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Rewrite arithmetic filters on an integral-type (e.g., byte, short, int and long)\n+ * column to its equivalent form, leaving attribute alone in a left side, so that\n+ * we can push it down to datasources (e.g., Parquet and ORC).",
    "line": 28
  }],
  "prId": 23942
}]