[{
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "nit: maybe we need line break before `extends`:\r\n\r\n```scala\r\ncase class RegrCount( ... )\r\n  extends CountAggregate with RegrBase {\r\n...\r\n```\r\n\r\n, and ditto for the following functions.",
    "commit": "e584adfb972a4d56acd6f222f1c5a7affc1224a6",
    "createdAt": "2018-05-01T06:09:27Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription, If, ImplicitCastInputTypes, IsNull, Literal, Or}\n+import org.apache.spark.sql.types.{AbstractDataType, DoubleType}\n+\n+/**\n+ * Base trait for all regression functions.\n+ */\n+trait RegrBase extends AggregateFunction with ImplicitCastInputTypes {\n+  def y: Expression\n+  def x: Expression\n+\n+  override def children: Seq[Expression] = Seq(y, x)\n+  override def inputTypes: Seq[AbstractDataType] = Seq(DoubleType, DoubleType)\n+\n+  def updateIfNotNull(exprs: Seq[Expression]): Seq[Expression] = {\n+    assert(aggBufferAttributes.length == exprs.length)\n+    val nullableChildren = children.filter(_.nullable)\n+    if (nullableChildren.isEmpty) {\n+      exprs\n+    } else {\n+      exprs.zip(aggBufferAttributes).map { case (e, a) =>\n+        If(nullableChildren.map(IsNull).reduce(Or), a, e)\n+      }\n+    }\n+  }\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the number of non-null pairs.\",\n+  since = \"2.4.0\")\n+case class RegrCount(y: Expression, x: Expression) extends CountAggregate\n+    with RegrBase {"
  }],
  "prId": 21054
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "`abstract class`?",
    "commit": "e584adfb972a4d56acd6f222f1c5a7affc1224a6",
    "createdAt": "2018-05-02T07:27:09Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription, If, ImplicitCastInputTypes, IsNull, Literal, Or}\n+import org.apache.spark.sql.types.{AbstractDataType, DoubleType}\n+\n+/**\n+ * Base trait for all regression functions.\n+ */\n+trait RegrBase extends AggregateFunction with ImplicitCastInputTypes {"
  }, {
    "author": {
      "login": "mgaido91"
    },
    "body": "it needs to be a trait to be mixed in with the other abstract classes (`CountLike`, `AggregateLike`, `CentralMomentAgg`, ...)",
    "commit": "e584adfb972a4d56acd6f222f1c5a7affc1224a6",
    "createdAt": "2018-05-02T09:46:55Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription, If, ImplicitCastInputTypes, IsNull, Literal, Or}\n+import org.apache.spark.sql.types.{AbstractDataType, DoubleType}\n+\n+/**\n+ * Base trait for all regression functions.\n+ */\n+trait RegrBase extends AggregateFunction with ImplicitCastInputTypes {"
  }],
  "prId": 21054
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "nit: Would it be possible to use `org.apache.spark.sql.catalyst.expressions._`?",
    "commit": "e584adfb972a4d56acd6f222f1c5a7affc1224a6",
    "createdAt": "2018-05-02T10:03:44Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription, If, ImplicitCastInputTypes, IsNull, Literal, Or}"
  }],
  "prId": 21054
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "Do we need to return `null` if `yMk === Literal(0.0)`?",
    "commit": "e584adfb972a4d56acd6f222f1c5a7affc1224a6",
    "createdAt": "2018-05-02T16:49:43Z",
    "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.types.{AbstractDataType, DoubleType}\n+\n+/**\n+ * Base trait for all regression functions.\n+ */\n+trait RegrLike extends AggregateFunction with ImplicitCastInputTypes {\n+  def y: Expression\n+  def x: Expression\n+\n+  override def children: Seq[Expression] = Seq(y, x)\n+  override def inputTypes: Seq[AbstractDataType] = Seq(DoubleType, DoubleType)\n+\n+  protected def updateIfNotNull(exprs: Seq[Expression]): Seq[Expression] = {\n+    assert(aggBufferAttributes.length == exprs.length)\n+    val nullableChildren = children.filter(_.nullable)\n+    if (nullableChildren.isEmpty) {\n+      exprs\n+    } else {\n+      exprs.zip(aggBufferAttributes).map { case (e, a) =>\n+        If(nullableChildren.map(IsNull).reduce(Or), a, e)\n+      }\n+    }\n+  }\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the number of non-null pairs.\",\n+  since = \"2.4.0\")\n+case class RegrCount(y: Expression, x: Expression)\n+  extends CountLike with RegrLike {\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(Seq(count + 1L))\n+\n+  override def prettyName: String = \"regr_count\"\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns SUM(x*x)-SUM(x)*SUM(x)/N. Any pair with a NULL is ignored.\",\n+  since = \"2.4.0\")\n+case class RegrSXX(y: Expression, x: Expression)\n+  extends CentralMomentAgg(x) with RegrLike {\n+\n+  override protected def momentOrder = 2\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(updateExpressionsDef)\n+\n+  override val evaluateExpression: Expression = {\n+    If(n === Literal(0.0), Literal.create(null, DoubleType), m2)\n+  }\n+\n+  override def prettyName: String = \"regr_sxx\"\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns SUM(y*y)-SUM(y)*SUM(y)/N. Any pair with a NULL is ignored.\",\n+  since = \"2.4.0\")\n+case class RegrSYY(y: Expression, x: Expression)\n+  extends CentralMomentAgg(y) with RegrLike {\n+\n+  override protected def momentOrder = 2\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(updateExpressionsDef)\n+\n+  override val evaluateExpression: Expression = {\n+    If(n === Literal(0.0), Literal.create(null, DoubleType), m2)\n+  }\n+\n+  override def prettyName: String = \"regr_syy\"\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the average of x. Any pair with a NULL is ignored.\",\n+  since = \"2.4.0\")\n+case class RegrAvgX(y: Expression, x: Expression)\n+  extends AverageLike(x) with RegrLike {\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(updateExpressionsDef)\n+\n+  override def prettyName: String = \"regr_avgx\"\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the average of y. Any pair with a NULL is ignored.\",\n+  since = \"2.4.0\")\n+case class RegrAvgY(y: Expression, x: Expression)\n+  extends AverageLike(y) with RegrLike {\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(updateExpressionsDef)\n+\n+  override def prettyName: String = \"regr_avgy\"\n+}\n+\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the covariance of y and x multiplied for the number of items in the dataset. Any pair with a NULL is ignored.\",\n+  since = \"2.4.0\")\n+// scalastyle:on line.size.limit\n+case class RegrSXY(y: Expression, x: Expression)\n+  extends Covariance(y, x) with RegrLike {\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(updateExpressionsDef)\n+\n+  override val evaluateExpression: Expression = {\n+    If(n === Literal(0.0), Literal.create(null, DoubleType), ck)\n+  }\n+\n+  override def prettyName: String = \"regr_sxy\"\n+}\n+\n+\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the slope of the linear regression line. Any pair with a NULL is ignored.\",\n+  since = \"2.4.0\")\n+// scalastyle:on line.size.limit\n+case class RegrSlope(y: Expression, x: Expression)\n+  extends PearsonCorrelation(y, x) with RegrLike {\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(updateExpressionsDef)\n+\n+  override val evaluateExpression: Expression = {\n+    If(n < Literal(2.0) || yMk === Literal(0.0), Literal.create(null, DoubleType), ck / yMk)\n+  }\n+\n+  override def prettyName: String = \"regr_slope\"\n+}\n+\n+\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the coefficient of determination (also called R-squared or goodness of fit) for the regression line. Any pair with a NULL is ignored.\",\n+  since = \"2.4.0\")\n+// scalastyle:on line.size.limit\n+case class RegrR2(y: Expression, x: Expression)\n+  extends PearsonCorrelation(y, x) with RegrLike {\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(updateExpressionsDef)\n+\n+  override val evaluateExpression: Expression = {\n+    If(n < Literal(2.0) || yMk === Literal(0.0), Literal.create(null, DoubleType),\n+      If(xMk === Literal(0.0), Literal(1.0), ck * ck / yMk / xMk))\n+  }\n+\n+  override def prettyName: String = \"regr_r2\"\n+}\n+\n+\n+// scalastyle:off line.size.limit\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the y-intercept of the linear regression line. Any pair with a NULL is ignored.\",\n+  since = \"2.4.0\")\n+// scalastyle:on line.size.limit\n+case class RegrIntercept(y: Expression, x: Expression)\n+  extends PearsonCorrelation(y, x) with RegrLike {\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(updateExpressionsDef)\n+\n+  override val evaluateExpression: Expression = {\n+    If(n === Literal(0.0), Literal.create(null, DoubleType), xAvg - (ck / yMk) * yAvg)"
  }],
  "prId": 21054
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "I found it is usually to explain `REGR_SXX` by `REGR_COUNT(x, y) * VAR_POP(y)`, e.g., [1](https://www.ibm.com/support/knowledgecenter/en/SSPT3X_2.1.2/com.ibm.swg.im.infosphere.biginsights.bigsql.doc/doc/bsql_regr_sxx.html) and [2](https://docs.oracle.com/cd/B19306_01/server.102/b14200/functions132.htm). Is it better to follow it?\r\n\r\nSame for `REGR_SYY`, etc..",
    "commit": "e584adfb972a4d56acd6f222f1c5a7affc1224a6",
    "createdAt": "2018-05-03T13:10:18Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.types.{AbstractDataType, DoubleType}\n+\n+/**\n+ * Base trait for all regression functions.\n+ */\n+trait RegrLike extends AggregateFunction with ImplicitCastInputTypes {\n+  def y: Expression\n+  def x: Expression\n+\n+  override def children: Seq[Expression] = Seq(y, x)\n+  override def inputTypes: Seq[AbstractDataType] = Seq(DoubleType, DoubleType)\n+\n+  protected def updateIfNotNull(exprs: Seq[Expression]): Seq[Expression] = {\n+    assert(aggBufferAttributes.length == exprs.length)\n+    val nullableChildren = children.filter(_.nullable)\n+    if (nullableChildren.isEmpty) {\n+      exprs\n+    } else {\n+      exprs.zip(aggBufferAttributes).map { case (e, a) =>\n+        If(nullableChildren.map(IsNull).reduce(Or), a, e)\n+      }\n+    }\n+  }\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the number of non-null pairs.\",\n+  since = \"2.4.0\")\n+case class RegrCount(y: Expression, x: Expression)\n+  extends CountLike with RegrLike {\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(Seq(count + 1L))\n+\n+  override def prettyName: String = \"regr_count\"\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns SUM(x*x)-SUM(x)*SUM(x)/N. Any pair with a NULL is ignored.\",",
    "line": 61
  }, {
    "author": {
      "login": "mgaido91"
    },
    "body": "Here I am following Hive. This is Hive docs and it reflects how it is actually computed. I am not sure it is a good idea to change it, since we are not really computing it as `REGR_COUNT(x, y) * VAR_POP(y)`.",
    "commit": "e584adfb972a4d56acd6f222f1c5a7affc1224a6",
    "createdAt": "2018-05-03T13:41:03Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.types.{AbstractDataType, DoubleType}\n+\n+/**\n+ * Base trait for all regression functions.\n+ */\n+trait RegrLike extends AggregateFunction with ImplicitCastInputTypes {\n+  def y: Expression\n+  def x: Expression\n+\n+  override def children: Seq[Expression] = Seq(y, x)\n+  override def inputTypes: Seq[AbstractDataType] = Seq(DoubleType, DoubleType)\n+\n+  protected def updateIfNotNull(exprs: Seq[Expression]): Seq[Expression] = {\n+    assert(aggBufferAttributes.length == exprs.length)\n+    val nullableChildren = children.filter(_.nullable)\n+    if (nullableChildren.isEmpty) {\n+      exprs\n+    } else {\n+      exprs.zip(aggBufferAttributes).map { case (e, a) =>\n+        If(nullableChildren.map(IsNull).reduce(Or), a, e)\n+      }\n+    }\n+  }\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the number of non-null pairs.\",\n+  since = \"2.4.0\")\n+case class RegrCount(y: Expression, x: Expression)\n+  extends CountLike with RegrLike {\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(Seq(count + 1L))\n+\n+  override def prettyName: String = \"regr_count\"\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns SUM(x*x)-SUM(x)*SUM(x)/N. Any pair with a NULL is ignored.\",",
    "line": 61
  }, {
    "author": {
      "login": "ueshin"
    },
    "body": "@gatorsmile What do you think?",
    "commit": "e584adfb972a4d56acd6f222f1c5a7affc1224a6",
    "createdAt": "2018-05-04T08:40:13Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.types.{AbstractDataType, DoubleType}\n+\n+/**\n+ * Base trait for all regression functions.\n+ */\n+trait RegrLike extends AggregateFunction with ImplicitCastInputTypes {\n+  def y: Expression\n+  def x: Expression\n+\n+  override def children: Seq[Expression] = Seq(y, x)\n+  override def inputTypes: Seq[AbstractDataType] = Seq(DoubleType, DoubleType)\n+\n+  protected def updateIfNotNull(exprs: Seq[Expression]): Seq[Expression] = {\n+    assert(aggBufferAttributes.length == exprs.length)\n+    val nullableChildren = children.filter(_.nullable)\n+    if (nullableChildren.isEmpty) {\n+      exprs\n+    } else {\n+      exprs.zip(aggBufferAttributes).map { case (e, a) =>\n+        If(nullableChildren.map(IsNull).reduce(Or), a, e)\n+      }\n+    }\n+  }\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the number of non-null pairs.\",\n+  since = \"2.4.0\")\n+case class RegrCount(y: Expression, x: Expression)\n+  extends CountLike with RegrLike {\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(Seq(count + 1L))\n+\n+  override def prettyName: String = \"regr_count\"\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns SUM(x*x)-SUM(x)*SUM(x)/N. Any pair with a NULL is ignored.\",",
    "line": 61
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "It is reasonable to follow Hive. Personally, I like DB2 or Oracle, because normally these commercial dbms is more professional. : )",
    "commit": "e584adfb972a4d56acd6f222f1c5a7affc1224a6",
    "createdAt": "2018-05-08T04:54:41Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.types.{AbstractDataType, DoubleType}\n+\n+/**\n+ * Base trait for all regression functions.\n+ */\n+trait RegrLike extends AggregateFunction with ImplicitCastInputTypes {\n+  def y: Expression\n+  def x: Expression\n+\n+  override def children: Seq[Expression] = Seq(y, x)\n+  override def inputTypes: Seq[AbstractDataType] = Seq(DoubleType, DoubleType)\n+\n+  protected def updateIfNotNull(exprs: Seq[Expression]): Seq[Expression] = {\n+    assert(aggBufferAttributes.length == exprs.length)\n+    val nullableChildren = children.filter(_.nullable)\n+    if (nullableChildren.isEmpty) {\n+      exprs\n+    } else {\n+      exprs.zip(aggBufferAttributes).map { case (e, a) =>\n+        If(nullableChildren.map(IsNull).reduce(Or), a, e)\n+      }\n+    }\n+  }\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns the number of non-null pairs.\",\n+  since = \"2.4.0\")\n+case class RegrCount(y: Expression, x: Expression)\n+  extends CountLike with RegrLike {\n+\n+  override lazy val updateExpressions: Seq[Expression] = updateIfNotNull(Seq(count + 1L))\n+\n+  override def prettyName: String = \"regr_count\"\n+}\n+\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(y, x) - Returns SUM(x*x)-SUM(x)*SUM(x)/N. Any pair with a NULL is ignored.\",",
    "line": 61
  }],
  "prId": 21054
}]