[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "I'll remove this in the next iteration...\n",
    "commit": "bfbf829ad1e617053993423a11a76a4a85e8467b",
    "createdAt": "2015-10-26T23:28:23Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.codegen.{GeneratedExpressionCode, CodeGenContext, CodegenFallback}\n+import org.apache.spark.sql.types.{AbstractDataType, DataType}\n+import org.apache.spark.util.collection.OpenHashSet\n+\n+/**\n+ * Fallback operator for distinct operators. This will be used when a user issues multiple\n+ * different distinct expressions in a query.\n+ *\n+ * The operator uses the OpenHashSetUDT for de-duplicating values. It is, as a result, not possible\n+ * to use UnsafeRow based aggregation.\n+ */\n+case class DistinctAggregateFallback(function: AggregateFunction2) extends DeclarativeAggregate {\n+  override def inputTypes: Seq[AbstractDataType] = function.inputTypes\n+  override def nullable: Boolean = function.nullable\n+  override def dataType: DataType = function.dataType\n+  override def children: Seq[Expression] = Seq(function)\n+\n+  private[this] val input = function.children match {\n+    case child :: Nil => child\n+    case children => CreateStruct(children) // TODO can we test this?\n+  }\n+  private[this] val items = AttributeReference(\"itemSet\", new OpenHashSetUDT(input.dataType))()\n+\n+  override def aggBufferAttributes: Seq[AttributeReference] = Seq(items)\n+  override val initialValues: Seq[Expression] = Seq(NewSet(input.dataType))\n+  override val updateExpressions: Seq[Expression] = Seq(AddItemToSet(input, items))\n+  override val mergeExpressions: Seq[Expression] = Seq(CombineSets(items.left, items.right))\n+  override val evaluateExpression: Expression = function match {\n+    case f: Count => CountSet(items)\n+    case f: DeclarativeAggregate => ReduceSetUsingDeclarativeAggregate(items, f)\n+    case f: ImperativeAggregate => ReduceSetUsingImperativeAggregate(items, f)\n+  }\n+}\n+\n+case class ReduceSetUsingImperativeAggregate(left: Expression, right: ImperativeAggregate)\n+  extends BinaryExpression with CodegenFallback {\n+\n+  override def dataType: DataType = right.dataType\n+\n+  private[this] val single = right.children.size == 1\n+\n+  // TODO can we assume that the offsets are 0 when we haven't touched them yet?\n+  private[this] val function = right\n+    .withNewInputAggBufferOffset(0)\n+    .withNewMutableAggBufferOffset(0)\n+\n+  @transient private[this] lazy val buffer =\n+    new SpecificMutableRow(right.aggBufferAttributes.map(_.dataType))\n+\n+  @transient private[this] lazy val singleValueInput = new GenericMutableRow(1)\n+\n+  override def eval(input: InternalRow): Any = {\n+    val result = left.eval(input).asInstanceOf[OpenHashSet[Any]]\n+    if (result != null) {\n+      right.initialize(buffer)\n+      val iterator = result.iterator\n+      if (single) {\n+        while (iterator.hasNext) {\n+          singleValueInput.update(0, iterator.next())\n+          function.update(buffer, singleValueInput)\n+        }\n+      } else {\n+        while (iterator.hasNext) {\n+          function.update(buffer, iterator.next().asInstanceOf[InternalRow])\n+        }\n+      }\n+      function.eval(buffer)\n+    } else null\n+  }\n+}\n+\n+case class ReduceSetUsingDeclarativeAggregate(left: Expression, right: DeclarativeAggregate)\n+  extends Expression with CodegenFallback {\n+  override def children: Seq[Expression] = Seq(left)\n+  override def nullable: Boolean = right.nullable\n+  override def dataType: DataType = right.dataType\n+\n+  private[this] val single = right.children.size == 1\n+\n+  private[this] val inputOrdinal = right.children.size\n+\n+  @transient private[this] lazy val initial =\n+    InterpretedMutableProjection(right.initialValues).target(buffer)\n+\n+  @transient private[this] lazy val update = {\n+    val boundRefs = (right.aggBufferAttributes ++ right.children).zipWithIndex.map {\n+      case (e, i) => (e, new BoundReference(i, e.dataType, e.nullable))\n+    }.toMap\n+    val boundExpressions = right.updateExpressions.map(_.transform(boundRefs))\n+    new InterpretedMutableProjection(boundExpressions).target(buffer)\n+  }\n+\n+  @transient private[this] lazy val evaluate =\n+    BindReferences.bindReference(right.evaluateExpression, right.aggBufferAttributes)\n+\n+  @transient private[this] lazy val buffer = {\n+    val singleType = if (single) {\n+      Seq(right.children.head.dataType)\n+    } else {\n+      Seq.empty\n+    }\n+    new SpecificMutableRow(right.inputAggBufferAttributes.map(_.dataType) ++ singleType)\n+  }\n+\n+  @transient private[this] lazy val joinRow = new JoinedRow\n+\n+  override def eval(input: InternalRow): Any = {\n+    val result = left.eval(input).asInstanceOf[OpenHashSet[Any]]\n+    if (result != null) {\n+      initial(EmptyRow)\n+      val iterator = result.iterator\n+      if (single) {\n+        while (iterator.hasNext) {\n+          buffer.update(inputOrdinal, iterator.next())\n+          update(buffer)\n+        }\n+      } else {\n+        while (iterator.hasNext) {\n+          joinRow(buffer, iterator.next().asInstanceOf[InternalRow])\n+          update(joinRow)\n+        }\n+      }\n+      evaluate.eval(buffer)\n+    } else null\n+  }\n+}\n+\n+case class DropAnyNull(child: Expression) extends UnaryExpression {\n+  override def nullable: Boolean = false\n+  override def dataType: DataType = child.dataType"
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "Removed....\n",
    "commit": "bfbf829ad1e617053993423a11a76a4a85e8467b",
    "createdAt": "2015-10-27T12:53:23Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.codegen.{GeneratedExpressionCode, CodeGenContext, CodegenFallback}\n+import org.apache.spark.sql.types.{AbstractDataType, DataType}\n+import org.apache.spark.util.collection.OpenHashSet\n+\n+/**\n+ * Fallback operator for distinct operators. This will be used when a user issues multiple\n+ * different distinct expressions in a query.\n+ *\n+ * The operator uses the OpenHashSetUDT for de-duplicating values. It is, as a result, not possible\n+ * to use UnsafeRow based aggregation.\n+ */\n+case class DistinctAggregateFallback(function: AggregateFunction2) extends DeclarativeAggregate {\n+  override def inputTypes: Seq[AbstractDataType] = function.inputTypes\n+  override def nullable: Boolean = function.nullable\n+  override def dataType: DataType = function.dataType\n+  override def children: Seq[Expression] = Seq(function)\n+\n+  private[this] val input = function.children match {\n+    case child :: Nil => child\n+    case children => CreateStruct(children) // TODO can we test this?\n+  }\n+  private[this] val items = AttributeReference(\"itemSet\", new OpenHashSetUDT(input.dataType))()\n+\n+  override def aggBufferAttributes: Seq[AttributeReference] = Seq(items)\n+  override val initialValues: Seq[Expression] = Seq(NewSet(input.dataType))\n+  override val updateExpressions: Seq[Expression] = Seq(AddItemToSet(input, items))\n+  override val mergeExpressions: Seq[Expression] = Seq(CombineSets(items.left, items.right))\n+  override val evaluateExpression: Expression = function match {\n+    case f: Count => CountSet(items)\n+    case f: DeclarativeAggregate => ReduceSetUsingDeclarativeAggregate(items, f)\n+    case f: ImperativeAggregate => ReduceSetUsingImperativeAggregate(items, f)\n+  }\n+}\n+\n+case class ReduceSetUsingImperativeAggregate(left: Expression, right: ImperativeAggregate)\n+  extends BinaryExpression with CodegenFallback {\n+\n+  override def dataType: DataType = right.dataType\n+\n+  private[this] val single = right.children.size == 1\n+\n+  // TODO can we assume that the offsets are 0 when we haven't touched them yet?\n+  private[this] val function = right\n+    .withNewInputAggBufferOffset(0)\n+    .withNewMutableAggBufferOffset(0)\n+\n+  @transient private[this] lazy val buffer =\n+    new SpecificMutableRow(right.aggBufferAttributes.map(_.dataType))\n+\n+  @transient private[this] lazy val singleValueInput = new GenericMutableRow(1)\n+\n+  override def eval(input: InternalRow): Any = {\n+    val result = left.eval(input).asInstanceOf[OpenHashSet[Any]]\n+    if (result != null) {\n+      right.initialize(buffer)\n+      val iterator = result.iterator\n+      if (single) {\n+        while (iterator.hasNext) {\n+          singleValueInput.update(0, iterator.next())\n+          function.update(buffer, singleValueInput)\n+        }\n+      } else {\n+        while (iterator.hasNext) {\n+          function.update(buffer, iterator.next().asInstanceOf[InternalRow])\n+        }\n+      }\n+      function.eval(buffer)\n+    } else null\n+  }\n+}\n+\n+case class ReduceSetUsingDeclarativeAggregate(left: Expression, right: DeclarativeAggregate)\n+  extends Expression with CodegenFallback {\n+  override def children: Seq[Expression] = Seq(left)\n+  override def nullable: Boolean = right.nullable\n+  override def dataType: DataType = right.dataType\n+\n+  private[this] val single = right.children.size == 1\n+\n+  private[this] val inputOrdinal = right.children.size\n+\n+  @transient private[this] lazy val initial =\n+    InterpretedMutableProjection(right.initialValues).target(buffer)\n+\n+  @transient private[this] lazy val update = {\n+    val boundRefs = (right.aggBufferAttributes ++ right.children).zipWithIndex.map {\n+      case (e, i) => (e, new BoundReference(i, e.dataType, e.nullable))\n+    }.toMap\n+    val boundExpressions = right.updateExpressions.map(_.transform(boundRefs))\n+    new InterpretedMutableProjection(boundExpressions).target(buffer)\n+  }\n+\n+  @transient private[this] lazy val evaluate =\n+    BindReferences.bindReference(right.evaluateExpression, right.aggBufferAttributes)\n+\n+  @transient private[this] lazy val buffer = {\n+    val singleType = if (single) {\n+      Seq(right.children.head.dataType)\n+    } else {\n+      Seq.empty\n+    }\n+    new SpecificMutableRow(right.inputAggBufferAttributes.map(_.dataType) ++ singleType)\n+  }\n+\n+  @transient private[this] lazy val joinRow = new JoinedRow\n+\n+  override def eval(input: InternalRow): Any = {\n+    val result = left.eval(input).asInstanceOf[OpenHashSet[Any]]\n+    if (result != null) {\n+      initial(EmptyRow)\n+      val iterator = result.iterator\n+      if (single) {\n+        while (iterator.hasNext) {\n+          buffer.update(inputOrdinal, iterator.next())\n+          update(buffer)\n+        }\n+      } else {\n+        while (iterator.hasNext) {\n+          joinRow(buffer, iterator.next().asInstanceOf[InternalRow])\n+          update(joinRow)\n+        }\n+      }\n+      evaluate.eval(buffer)\n+    } else null\n+  }\n+}\n+\n+case class DropAnyNull(child: Expression) extends UnaryExpression {\n+  override def nullable: Boolean = false\n+  override def dataType: DataType = child.dataType"
  }],
  "prId": 9280
}]