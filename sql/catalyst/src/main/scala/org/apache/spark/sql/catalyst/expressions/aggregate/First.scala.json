[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "``` sql\nspark-sql> SELECT first(array(1)), first(struct(1)), first(map(1,1));\n[1] {\"col1\":1}  {1:1}\n```\n",
    "commit": "2b437fe169080b53215f280c8987ff1d8e779df8",
    "createdAt": "2016-10-28T23:22:50Z",
    "diffHunk": "@@ -29,10 +29,16 @@ import org.apache.spark.sql.types._\n  * a single partition, and we use a single reducer to do the aggregation.).\n  */\n @ExpressionDescription(\n-  usage = \"\"\"_FUNC_(expr) - Returns the first value of `child` for a group of rows.\n-    _FUNC_(expr,isIgnoreNull=false) - Returns the first value of `child` for a group of rows.\n-      If isIgnoreNull is true, returns only non-null values.\n-    \"\"\")\n+  usage = \"\"\"\n+    _FUNC_(expr[, isIgnoreNull]) - Returns the first value of `expr` for a group of rows.\n+      If `isIgnoreNull` is true, returns only non-null values.\n+  \"\"\",\n+  extended = \"\"\"\n+    Arguments:\n+      expr - an expression of any type that represents data to collect the first.",
    "line": 14
  }],
  "prId": 15513
}]