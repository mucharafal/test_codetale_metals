[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Casting seems a bit scary. Do you want to be this flexible?",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-08T22:15:31Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {"
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "In fact I don't have a strong reason to do this. Let's just compare the equality of dataTypes.",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-09T01:48:48Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {"
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "I tested and realized the casting is needed. The dataType of child output attributes are deduced from the data, so it is possible that implict casting will be performed later.\r\n\r\nI changed the if condition to `attr.dataType != other.dataType`, and the test case `SQLViewSuite.test(\"create hive view for joined tables\")` failed with the AnalysisException:\r\n```\r\nThe dataType of attribute 'id#131' is 'IntegerType', which can't be casted to that of 'id#114L', expected 'LongType'.;\r\n```",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-09T03:08:27Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "how did we handle view schema mismatch before?",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T06:07:11Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "The rule `ImplicitTypeCasts` is done in the batch of `Resolution`, right?",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T07:06:06Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Have you added any test case for type casting?",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T07:07:06Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {"
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "We should add `Cast` to the child attribute, because it may have different dataType with the view output attribute. Will also add test case for this.",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T17:56:30Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {"
  }, {
    "author": {
      "login": "yhuai"
    },
    "body": "btw, I do not say where we actually do the cast.",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T18:19:59Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {"
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "> The child should have the same output attributes with the View operator\r\n\r\nshall we add an assert?",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T06:02:59Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {\n+      throw new AnalysisException(\n+        s\"The dataType of attribute '$other' is '${other.dataType}', which can't be casted to \" +\n+          s\"that of '$attr', expected '${attr.dataType}'.\")\n+    }\n+  }\n+}\n+\n+/**\n+ * Removes [[View]] operators from the plan. The operator is respected till the end of analysis\n+ * stage because we want to see which part of a analyzed logical plan is generated from a view.\n+ */\n+object EliminateView extends Rule[LogicalPlan] {\n+  def apply(plan: LogicalPlan): LogicalPlan = plan transformUp {\n+    // The child should have the same output attributes with the View operator, so we simply"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": ": ) I did not see your comment.",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T07:20:46Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {\n+      throw new AnalysisException(\n+        s\"The dataType of attribute '$other' is '${other.dataType}', which can't be casted to \" +\n+          s\"that of '$attr', expected '${attr.dataType}'.\")\n+    }\n+  }\n+}\n+\n+/**\n+ * Removes [[View]] operators from the plan. The operator is respected till the end of analysis\n+ * stage because we want to see which part of a analyzed logical plan is generated from a view.\n+ */\n+object EliminateView extends Rule[LogicalPlan] {\n+  def apply(plan: LogicalPlan): LogicalPlan = plan transformUp {\n+    // The child should have the same output attributes with the View operator, so we simply"
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Nit: `after the resolution batch` -> `after the batch of Resolution`",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T06:58:09Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are"
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "`stable during resolution` -> `completely resolved during the batch of Resolution`",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T06:59:30Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution."
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Nit: `case View(_, output, child) => child` -> `case View(_, _, child) => child`",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T07:08:51Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {\n+      throw new AnalysisException(\n+        s\"The dataType of attribute '$other' is '${other.dataType}', which can't be casted to \" +\n+          s\"that of '$attr', expected '${attr.dataType}'.\")\n+    }\n+  }\n+}\n+\n+/**\n+ * Removes [[View]] operators from the plan. The operator is respected till the end of analysis\n+ * stage because we want to see which part of a analyzed logical plan is generated from a view.\n+ */\n+object EliminateView extends Rule[LogicalPlan] {\n+  def apply(plan: LogicalPlan): LogicalPlan = plan transformUp {\n+    // The child should have the same output attributes with the View operator, so we simply\n+    // remove the View operator.\n+    case View(_, output, child) => child"
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Nit: `transformUp` -> `transform`. When the order does not matter, we use `transform`",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T07:12:01Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {\n+      throw new AnalysisException(\n+        s\"The dataType of attribute '$other' is '${other.dataType}', which can't be casted to \" +\n+          s\"that of '$attr', expected '${attr.dataType}'.\")\n+    }\n+  }\n+}\n+\n+/**\n+ * Removes [[View]] operators from the plan. The operator is respected till the end of analysis\n+ * stage because we want to see which part of a analyzed logical plan is generated from a view.\n+ */\n+object EliminateView extends Rule[LogicalPlan] {\n+  def apply(plan: LogicalPlan): LogicalPlan = plan transformUp {"
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Nit: `a analyzed` ->`an analyzed`",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T07:13:04Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {\n+      throw new AnalysisException(\n+        s\"The dataType of attribute '$other' is '${other.dataType}', which can't be casted to \" +\n+          s\"that of '$attr', expected '${attr.dataType}'.\")\n+    }\n+  }\n+}\n+\n+/**\n+ * Removes [[View]] operators from the plan. The operator is respected till the end of analysis\n+ * stage because we want to see which part of a analyzed logical plan is generated from a view."
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Can we add an assert below to ensure the outputs are the same? \r\n\r\nYou know, this case is different from `SubqueryAlias`, which does not have the defined `output`",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T07:19:27Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {\n+    if (!Cast.canCast(attr.dataType, other.dataType)) {\n+      throw new AnalysisException(\n+        s\"The dataType of attribute '$other' is '${other.dataType}', which can't be casted to \" +\n+          s\"that of '$attr', expected '${attr.dataType}'.\")\n+    }\n+  }\n+}\n+\n+/**\n+ * Removes [[View]] operators from the plan. The operator is respected till the end of analysis\n+ * stage because we want to see which part of a analyzed logical plan is generated from a view.\n+ */\n+object EliminateView extends Rule[LogicalPlan] {\n+  def apply(plan: LogicalPlan): LogicalPlan = plan transformUp {\n+    // The child should have the same output attributes with the View operator, so we simply"
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "When will newAttr and attr have different data types?",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T18:06:13Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)"
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "When the schema of the referenced table changes, for example:\r\n```\r\n  test(\"correctly handle type casting between view output and child output\") {\r\n    withTable(\"testTable\") {\r\n      withView(\"testView\") {\r\n        spark.range(1, 10).toDF(\"id1\").write.format(\"json\").saveAsTable(\"testTable\")\r\n        sql(\"CREATE VIEW testView AS SELECT * FROM testTable\")\r\n\r\n        // Allow casting from IntegerType to LongType\r\n        val df = (1 until 10).map(i => i).toDF(\"id1\")\r\n        df.write.format(\"json\").mode(SaveMode.Overwrite).saveAsTable(\"testTable\")\r\n        checkAnswer(sql(\"SELECT * FROM testView ORDER BY id1\"), (1 to 9).map(i => Row(i)))\r\n\r\n        // Cann't cast from ArrayType to LongType, throw an AnalysisException.\r\n        val df2 = (1 until 10).map(i => Seq(i)).toDF(\"id1\")\r\n        df2.write.format(\"json\").mode(SaveMode.Overwrite).saveAsTable(\"testTable\")\r\n        intercept[AnalysisException](sql(\"SELECT * FROM testView ORDER BY id1\"))\r\n      }\r\n    }\r\n  }\r\n```",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T18:38:43Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)"
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Is there any chance that output and child have different sizes? Also, looks like we are trying to match columns by name, can you explain the reason? Why we are not matching columns by the position? ",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T18:17:14Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>"
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "We match columns by name because the order of the child's output may be not the same with that of view output.\r\nWill update the code to handle the case when the output have extra columns.",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T18:36:50Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>"
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Since this function is used once, I'd inline it.",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-10T18:17:36Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the resolution batch, because the view attributes are\n+ * not stable during resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = child.output.map { attr =>\n+        val newAttr = findAttributeByName(attr.name, output, resolver)\n+        // Check the dataType of the output attributes, throw an AnalysisException if they don't\n+        // match up.\n+        checkDataType(attr, newAttr)\n+        Alias(attr, attr.name)(exprId = newAttr.exprId, qualifier = newAttr.qualifier,\n+          explicitMetadata = Some(newAttr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {\n+      case attr if resolver(attr.name, name) => attr\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Attribute with name '$name' is not found in \" +\n+        s\"'${attrs.map(_.name).mkString(\"(\", \",\", \")\")}'\"))\n+  }\n+\n+  /**\n+   * Check whether the dataType of `attr` could be casted to that of `other`, throw an\n+   * AnalysisException if the both attributes don't match up.\n+   */\n+  private def checkDataType(attr: Attribute, other: Attribute): Unit = {"
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit: use `find`?",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-11T05:38:58Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the batch of Resolution, because the view attributes are\n+ * not completely resolved during the batch of Resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = output.map { attr =>\n+        val originAttr = findAttributeByName(attr.name, child.output, resolver)\n+        // The dataType of the output attributes may be not the same with that of the view output,\n+        // so we should cast the attribute to the dataType of the view output attribute. If the\n+        // cast cann't perform, will throw an AnalysisException.\n+        Alias(Cast(originAttr, attr.dataType), attr.name)(exprId = attr.exprId,\n+          qualifier = attr.qualifier, explicitMetadata = Some(attr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {"
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "May I ask why `find` is better than `collectFirst` here? Thanks!",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-11T08:53:07Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the batch of Resolution, because the view attributes are\n+ * not completely resolved during the batch of Resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = output.map { attr =>\n+        val originAttr = findAttributeByName(attr.name, child.output, resolver)\n+        // The dataType of the output attributes may be not the same with that of the view output,\n+        // so we should cast the attribute to the dataType of the view output attribute. If the\n+        // cast cann't perform, will throw an AnalysisException.\n+        Alias(Cast(originAttr, attr.dataType), attr.name)(exprId = attr.exprId,\n+          qualifier = attr.qualifier, explicitMetadata = Some(attr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "`find` is more accurate here, as we won't change the type. While `collectFirst` can, e.g. `List[A].collectFirst[B] {...}`",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-11T15:16:20Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the batch of Resolution, because the view attributes are\n+ * not completely resolved during the batch of Resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = output.map { attr =>\n+        val originAttr = findAttributeByName(attr.name, child.output, resolver)\n+        // The dataType of the output attributes may be not the same with that of the view output,\n+        // so we should cast the attribute to the dataType of the view output attribute. If the\n+        // cast cann't perform, will throw an AnalysisException.\n+        Alias(Cast(originAttr, attr.dataType), attr.name)(exprId = attr.exprId,\n+          qualifier = attr.qualifier, explicitMetadata = Some(attr.metadata))\n+      }\n+      v.copy(child = Project(newOutput, child))\n+  }\n+\n+  /**\n+   * Find the attribute that has the expected attribute name from an attribute list, the names\n+   * are compared using conf.resolver.\n+   * If the expected attribute is not found, throw an AnalysisException.\n+   */\n+  private def findAttributeByName(\n+      name: String,\n+      attrs: Seq[Attribute],\n+      resolver: Resolver): Attribute = {\n+    attrs.collectFirst {"
  }],
  "prId": 16233
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Nit: `cann't ` -> `can't `",
    "commit": "3a6dd3e0185423a88541dd83e313690afdcd2543",
    "createdAt": "2017-01-11T05:49:06Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.CatalystConf\n+import org.apache.spark.sql.catalyst.expressions.{Alias, Attribute, Cast}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project, View}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+/**\n+ * This file defines analysis rules related to views.\n+ */\n+\n+/**\n+ * Make sure that a view's child plan produces the view's output attributes. We wrap the child\n+ * with a Project and add an alias for each output attribute. The attributes are resolved by\n+ * name. This should be only done after the batch of Resolution, because the view attributes are\n+ * not completely resolved during the batch of Resolution.\n+ */\n+case class AliasViewChild(conf: CatalystConf) extends Rule[LogicalPlan] {\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case v @ View(_, output, child) if child.resolved =>\n+      val resolver = conf.resolver\n+      val newOutput = output.map { attr =>\n+        val originAttr = findAttributeByName(attr.name, child.output, resolver)\n+        // The dataType of the output attributes may be not the same with that of the view output,\n+        // so we should cast the attribute to the dataType of the view output attribute. If the\n+        // cast cann't perform, will throw an AnalysisException."
  }],
  "prId": 16233
}]