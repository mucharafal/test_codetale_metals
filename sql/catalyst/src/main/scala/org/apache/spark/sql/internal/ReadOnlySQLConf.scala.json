[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "This is nice :)",
    "commit": "cfb76f59a71c04048c14892beba442753e72410f",
    "createdAt": "2018-05-11T13:47:54Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.internal\n+\n+import java.util.{Map => JMap}\n+\n+import org.apache.spark.{TaskContext, TaskContextImpl}\n+import org.apache.spark.internal.config.{ConfigEntry, ConfigProvider, ConfigReader}\n+\n+class ReadOnlySQLConf(context: TaskContext) extends SQLConf {"
  }],
  "prId": 21299
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "Do we need to allow us to do `clone`? `clone` will create mutable `SQLConf`.",
    "commit": "cfb76f59a71c04048c14892beba442753e72410f",
    "createdAt": "2018-05-11T15:34:06Z",
    "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.internal\n+\n+import java.util.{Map => JMap}\n+\n+import org.apache.spark.{TaskContext, TaskContextImpl}\n+import org.apache.spark.internal.config.{ConfigEntry, ConfigProvider, ConfigReader}\n+\n+/**\n+ * A readonly SQLConf that will be created by tasks running at the executor side. It reads the\n+ * configs from the local properties which are propagated from driver to executors.\n+ */\n+class ReadOnlySQLConf(context: TaskContext) extends SQLConf {\n+\n+  @transient override val settings: JMap[String, String] = {\n+    context.asInstanceOf[TaskContextImpl].getLocalProperties().asInstanceOf[JMap[String, String]]\n+  }\n+\n+  @transient override protected val reader: ConfigReader = {\n+    new ConfigReader(new TaskContextConfigProvider(context))\n+  }\n+\n+  override protected def setConfWithCheck(key: String, value: String): Unit = {\n+    throw new UnsupportedOperationException(\"Cannot mutate ReadOnlySQLConf.\")\n+  }\n+\n+  override def unsetConf(key: String): Unit = {\n+    throw new UnsupportedOperationException(\"Cannot mutate ReadOnlySQLConf.\")\n+  }\n+\n+  override def unsetConf(entry: ConfigEntry[_]): Unit = {\n+    throw new UnsupportedOperationException(\"Cannot mutate ReadOnlySQLConf.\")\n+  }\n+\n+  override def clear(): Unit = {\n+    throw new UnsupportedOperationException(\"Cannot mutate ReadOnlySQLConf.\")\n+  }\n+}"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "I don't think we need to clone or copy `SQLConf` in tasks, let's ban it.",
    "commit": "cfb76f59a71c04048c14892beba442753e72410f",
    "createdAt": "2018-05-11T16:43:09Z",
    "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.internal\n+\n+import java.util.{Map => JMap}\n+\n+import org.apache.spark.{TaskContext, TaskContextImpl}\n+import org.apache.spark.internal.config.{ConfigEntry, ConfigProvider, ConfigReader}\n+\n+/**\n+ * A readonly SQLConf that will be created by tasks running at the executor side. It reads the\n+ * configs from the local properties which are propagated from driver to executors.\n+ */\n+class ReadOnlySQLConf(context: TaskContext) extends SQLConf {\n+\n+  @transient override val settings: JMap[String, String] = {\n+    context.asInstanceOf[TaskContextImpl].getLocalProperties().asInstanceOf[JMap[String, String]]\n+  }\n+\n+  @transient override protected val reader: ConfigReader = {\n+    new ConfigReader(new TaskContextConfigProvider(context))\n+  }\n+\n+  override protected def setConfWithCheck(key: String, value: String): Unit = {\n+    throw new UnsupportedOperationException(\"Cannot mutate ReadOnlySQLConf.\")\n+  }\n+\n+  override def unsetConf(key: String): Unit = {\n+    throw new UnsupportedOperationException(\"Cannot mutate ReadOnlySQLConf.\")\n+  }\n+\n+  override def unsetConf(entry: ConfigEntry[_]): Unit = {\n+    throw new UnsupportedOperationException(\"Cannot mutate ReadOnlySQLConf.\")\n+  }\n+\n+  override def clear(): Unit = {\n+    throw new UnsupportedOperationException(\"Cannot mutate ReadOnlySQLConf.\")\n+  }\n+}"
  }],
  "prId": 21299
}]