[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Hey, `asNullable` should return it as nullable. This is a general problem when you read it, it becomes nullable in SparkSQL file formats (batch job-only). We need to revisit nullability (given the community discussion so far) in general, not only specifically for this one.",
    "commit": "14608bf904f39824679cfc4bd35c72cc2a550d03",
    "createdAt": "2019-03-22T07:38:57Z",
    "diffHunk": "@@ -90,7 +90,7 @@ case class ArrayType(elementType: DataType, containsNull: Boolean) extends DataT\n   override def sql: String = s\"ARRAY<${elementType.sql}>\"\n \n   override private[spark] def asNullable: ArrayType =\n-    ArrayType(elementType.asNullable, containsNull = true)\n+    ArrayType(elementType.asNullable, containsNull)",
    "line": 5
  }, {
    "author": {
      "login": "sandeep-katta"
    },
    "body": "My bad , I agree `asNullable` should return it as nullable, it cannot be decided based on the current DF. for e.g below use case will fail if we don't return as `true`\r\n`      val df = Seq(Some(Seq[Long](1L, 2L,3L)), None).toDF(\"seq\")\r\n      df.write.format(\"parquet\").saveAsTable(\"testSchema\");\r\n      val df1 = Seq(Some(Seq(null)), None).toDF(\"seq\")\r\n      df1.write.format(\"parquet\").mode(\"append\").saveAsTable(\"testSchema\")`\r\n\r\nBTW what do you mean by We need to revisit nullability (given the community discussion so far) in general, not only specifically for this one.\r\n\r\nI will close this PR and update this discussion in jira to close it as non issue",
    "commit": "14608bf904f39824679cfc4bd35c72cc2a550d03",
    "createdAt": "2019-03-22T09:29:25Z",
    "diffHunk": "@@ -90,7 +90,7 @@ case class ArrayType(elementType: DataType, containsNull: Boolean) extends DataT\n   override def sql: String = s\"ARRAY<${elementType.sql}>\"\n \n   override private[spark] def asNullable: ArrayType =\n-    ArrayType(elementType.asNullable, containsNull = true)\n+    ArrayType(elementType.asNullable, containsNull)",
    "line": 5
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "For instance, when dataframe are loaded via file format sources like parquet, orc, etc., schema is forced to billable schema, which seems wrong. We should fix it across SparkSQL ",
    "commit": "14608bf904f39824679cfc4bd35c72cc2a550d03",
    "createdAt": "2019-03-23T08:24:48Z",
    "diffHunk": "@@ -90,7 +90,7 @@ case class ArrayType(elementType: DataType, containsNull: Boolean) extends DataT\n   override def sql: String = s\"ARRAY<${elementType.sql}>\"\n \n   override private[spark] def asNullable: ArrayType =\n-    ArrayType(elementType.asNullable, containsNull = true)\n+    ArrayType(elementType.asNullable, containsNull)",
    "line": 5
  }],
  "prId": 24176
}]