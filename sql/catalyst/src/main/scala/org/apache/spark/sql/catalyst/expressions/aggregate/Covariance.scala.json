[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Ditto.\n",
    "commit": "fe6fe50eae2490e7669a40200c34483533d2b632",
    "createdAt": "2016-02-02T07:33:55Z",
    "diffHunk": "@@ -28,171 +26,90 @@ import org.apache.spark.sql.types._\n  * When applied on empty data (i.e., count is zero), it returns NULL.\n  *\n  */\n-abstract class Covariance(left: Expression, right: Expression) extends ImperativeAggregate\n-    with Serializable {\n-  override def children: Seq[Expression] = Seq(left, right)\n+abstract class Covariance(x: Expression, y: Expression) extends DeclarativeAggregate {\n \n+  override def children: Seq[Expression] = Seq(x, y)\n   override def nullable: Boolean = true\n-\n   override def dataType: DataType = DoubleType\n-\n   override def inputTypes: Seq[AbstractDataType] = Seq(DoubleType, DoubleType)\n \n-  override def checkInputDataTypes(): TypeCheckResult = {\n-    if (left.dataType.isInstanceOf[DoubleType] && right.dataType.isInstanceOf[DoubleType]) {\n-      TypeCheckResult.TypeCheckSuccess\n+  protected val count = AttributeReference(\"count\", DoubleType, nullable = false)()\n+  protected val xAvg = AttributeReference(\"xAvg\", DoubleType, nullable = false)()\n+  protected val yAvg = AttributeReference(\"yAvg\", DoubleType, nullable = false)()\n+  protected val ck = AttributeReference(\"ck\", DoubleType, nullable = false)()\n+\n+  override val aggBufferAttributes: Seq[AttributeReference] = Seq(count, xAvg, yAvg, ck)\n+\n+  override val initialValues: Seq[Expression] = Seq(\n+    /* count = */ Literal(0.0),\n+    /* xAvg = */ Literal(0.0),\n+    /* yAvg = */ Literal(0.0),\n+    /* ck = */ Literal(0.0)\n+  )\n+\n+  override lazy val updateExpressions: Seq[Expression] = {\n+    val n = count + Literal(1.0)\n+    val dx = x - xAvg\n+    val dy = y - yAvg\n+    val dyN = dy / n\n+    val newXAvg = xAvg + dx / n\n+    val newYAvg = yAvg + dyN\n+    val newCk = ck + dx * (dy - dyN)\n+\n+    val isNull = Or(IsNull(x), IsNull(y))"
  }],
  "prId": 10960
}]