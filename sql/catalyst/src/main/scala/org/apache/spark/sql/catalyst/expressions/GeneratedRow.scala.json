[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "indent is off here\n",
    "commit": "96ef82c4afbf0b3eabb246e29209d953d58b3d99",
    "createdAt": "2014-06-06T08:13:29Z",
    "diffHunk": "@@ -0,0 +1,833 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+package catalyst\n+package expressions\n+\n+import types._\n+\n+object DumpByteCode {\n+  import scala.sys.process._\n+  val dumpDirectory = util.getTempFilePath(\"sparkSqlByteCode\")\n+  dumpDirectory.mkdir()\n+\n+  def apply(obj: Any): Unit = {\n+    val generatedClass = obj.getClass\n+    val classLoader =\n+      generatedClass\n+        .getClassLoader\n+        .asInstanceOf[scala.tools.nsc.interpreter.AbstractFileClassLoader]\n+    val generatedBytes = classLoader.classBytes(generatedClass.getName)\n+\n+    val packageDir = new java.io.File(dumpDirectory, generatedClass.getPackage.getName)\n+    if (!packageDir.exists()) { packageDir.mkdir() }\n+\n+    val classFile =\n+      new java.io.File(packageDir, generatedClass.getName.split(\"\\\\.\").last + \".class\")\n+\n+    val outfile = new java.io.FileOutputStream(classFile)\n+    outfile.write(generatedBytes)\n+    outfile.close()\n+\n+    println(\n+      s\"javap -p -v -classpath ${dumpDirectory.getCanonicalPath} ${generatedClass.getName}\".!!)\n+  }\n+}\n+\n+object CodeGeneration\n+\n+class CodeGenerator extends Logging {\n+  import scala.reflect.runtime.{universe => ru}\n+  import scala.reflect.runtime.universe._\n+\n+  import scala.tools.reflect.ToolBox\n+\n+  val toolBox = runtimeMirror(getClass.getClassLoader).mkToolBox()\n+\n+  // TODO: Use typetags?\n+  val rowType = tq\"org.apache.spark.sql.catalyst.expressions.Row\"\n+  val mutableRowType = tq\"org.apache.spark.sql.catalyst.expressions.MutableRow\"\n+  val genericRowType = tq\"org.apache.spark.sql.catalyst.expressions.GenericRow\"\n+  val genericMutableRowType = tq\"org.apache.spark.sql.catalyst.expressions.GenericMutableRow\"\n+\n+  val projectionType = tq\"org.apache.spark.sql.catalyst.expressions.Projection\"\n+  val mutableProjectionType = tq\"org.apache.spark.sql.catalyst.expressions.MutableProjection\"\n+\n+  private val curId = new java.util.concurrent.atomic.AtomicInteger()\n+  private val javaSeperator = \"$\"\n+\n+  /**\n+   * Returns a term name that is unique within this instance of a `CodeGenerator`.\n+   *\n+   * (Since we aren't in a macro context we do not seem to have access to the built in `freshName`\n+   * function.)\n+   */\n+  protected def freshName(prefix: String): TermName = {\n+    newTermName(s\"$prefix$javaSeperator${curId.getAndIncrement}\")\n+  }\n+\n+  /**\n+   * Scala ASTs for evaluating an [[Expression]] given a [[Row]] of input.\n+   *\n+   * @param code The sequence of statements required to evaluate the expression.\n+   * @param nullTerm A term that holds a boolean value representing whether the expression evaluated\n+   *                 to null.\n+   * @param primitiveTerm A term for a possible primitive value of the result of the evaluation. Not\n+   *                      valid if `nullTerm` is set to `false`.\n+   * @param objectTerm An possibly boxed version of the result of evaluating this expression.\n+   */\n+  protected case class EvaluatedExpression(\n+      code: Seq[Tree],\n+      nullTerm: TermName,\n+      primitiveTerm: TermName,\n+      objectTerm: TermName) {\n+\n+    def withObjectTerm = ???\n+  }\n+\n+  /**\n+   * Given an expression tree returns the code required to determine both if the result is NULL\n+   * as well as the code required to compute the value.\n+   */\n+   def expressionEvaluator(e: Expression): EvaluatedExpression = {"
  }],
  "prId": 993
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "should we consider moving code gen for each expression into the expression itself? just like what we did with eval.\n\nJust throwing an idea out there. I can see benefits on both approaches.\n",
    "commit": "96ef82c4afbf0b3eabb246e29209d953d58b3d99",
    "createdAt": "2014-06-06T08:14:51Z",
    "diffHunk": "@@ -0,0 +1,833 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+package catalyst\n+package expressions\n+\n+import types._\n+\n+object DumpByteCode {\n+  import scala.sys.process._\n+  val dumpDirectory = util.getTempFilePath(\"sparkSqlByteCode\")\n+  dumpDirectory.mkdir()\n+\n+  def apply(obj: Any): Unit = {\n+    val generatedClass = obj.getClass\n+    val classLoader =\n+      generatedClass\n+        .getClassLoader\n+        .asInstanceOf[scala.tools.nsc.interpreter.AbstractFileClassLoader]\n+    val generatedBytes = classLoader.classBytes(generatedClass.getName)\n+\n+    val packageDir = new java.io.File(dumpDirectory, generatedClass.getPackage.getName)\n+    if (!packageDir.exists()) { packageDir.mkdir() }\n+\n+    val classFile =\n+      new java.io.File(packageDir, generatedClass.getName.split(\"\\\\.\").last + \".class\")\n+\n+    val outfile = new java.io.FileOutputStream(classFile)\n+    outfile.write(generatedBytes)\n+    outfile.close()\n+\n+    println(\n+      s\"javap -p -v -classpath ${dumpDirectory.getCanonicalPath} ${generatedClass.getName}\".!!)\n+  }\n+}\n+\n+object CodeGeneration\n+\n+class CodeGenerator extends Logging {\n+  import scala.reflect.runtime.{universe => ru}\n+  import scala.reflect.runtime.universe._\n+\n+  import scala.tools.reflect.ToolBox\n+\n+  val toolBox = runtimeMirror(getClass.getClassLoader).mkToolBox()\n+\n+  // TODO: Use typetags?\n+  val rowType = tq\"org.apache.spark.sql.catalyst.expressions.Row\"\n+  val mutableRowType = tq\"org.apache.spark.sql.catalyst.expressions.MutableRow\"\n+  val genericRowType = tq\"org.apache.spark.sql.catalyst.expressions.GenericRow\"\n+  val genericMutableRowType = tq\"org.apache.spark.sql.catalyst.expressions.GenericMutableRow\"\n+\n+  val projectionType = tq\"org.apache.spark.sql.catalyst.expressions.Projection\"\n+  val mutableProjectionType = tq\"org.apache.spark.sql.catalyst.expressions.MutableProjection\"\n+\n+  private val curId = new java.util.concurrent.atomic.AtomicInteger()\n+  private val javaSeperator = \"$\"\n+\n+  /**\n+   * Returns a term name that is unique within this instance of a `CodeGenerator`.\n+   *\n+   * (Since we aren't in a macro context we do not seem to have access to the built in `freshName`\n+   * function.)\n+   */\n+  protected def freshName(prefix: String): TermName = {\n+    newTermName(s\"$prefix$javaSeperator${curId.getAndIncrement}\")\n+  }\n+\n+  /**\n+   * Scala ASTs for evaluating an [[Expression]] given a [[Row]] of input.\n+   *\n+   * @param code The sequence of statements required to evaluate the expression.\n+   * @param nullTerm A term that holds a boolean value representing whether the expression evaluated\n+   *                 to null.\n+   * @param primitiveTerm A term for a possible primitive value of the result of the evaluation. Not\n+   *                      valid if `nullTerm` is set to `false`.\n+   * @param objectTerm An possibly boxed version of the result of evaluating this expression.\n+   */\n+  protected case class EvaluatedExpression(\n+      code: Seq[Tree],\n+      nullTerm: TermName,\n+      primitiveTerm: TermName,\n+      objectTerm: TermName) {\n+\n+    def withObjectTerm = ???\n+  }\n+\n+  /**\n+   * Given an expression tree returns the code required to determine both if the result is NULL\n+   * as well as the code required to compute the value.\n+   */\n+   def expressionEvaluator(e: Expression): EvaluatedExpression = {\n+    val primitiveTerm = freshName(\"primitiveTerm\")\n+    val nullTerm = freshName(\"nullTerm\")\n+    val objectTerm = freshName(\"objectTerm\")\n+\n+    implicit class Evaluate1(e: Expression) {\n+      def castOrNull(f: TermName => Tree, dataType: DataType): Seq[Tree] = {\n+        val eval = expressionEvaluator(e)\n+        eval.code ++\n+          q\"\"\"\n+          val $nullTerm = ${eval.nullTerm}\n+          val $primitiveTerm =\n+            if($nullTerm)\n+              ${defaultPrimitive(dataType)}\n+            else\n+              ${f(eval.primitiveTerm)}\n+        \"\"\".children\n+      }\n+    }\n+\n+    implicit class Evaluate2(expressions: (Expression, Expression)) {\n+\n+      /**\n+       * Short hand for generating binary evaluation code, which depends on two sub-evaluations of\n+       * the same type.  If either of the sub-expressions is null, the results of this computation\n+       * is assumed to be null.\n+       *\n+       * @param f a function from two primitive term names to a tree that evaluates them.\n+       */\n+      def evaluate(f: (TermName, TermName) => Tree): Seq[Tree] =\n+        evaluateAs(expressions._1.dataType)(f)\n+\n+      def evaluateAs(resultType: DataType)(f: (TermName, TermName) => Tree): Seq[Tree] = {\n+        require(expressions._1.dataType == expressions._2.dataType,\n+          s\"${expressions._1.dataType} != ${expressions._2.dataType}\")\n+\n+        val eval1 = expressionEvaluator(expressions._1)\n+        val eval2 = expressionEvaluator(expressions._2)\n+        val resultCode = f(eval1.primitiveTerm, eval2.primitiveTerm)\n+\n+        eval1.code ++ eval2.code ++\n+        q\"\"\"\n+          val $nullTerm = ${eval1.nullTerm} || ${eval2.nullTerm}\n+          val $primitiveTerm: ${termForType(resultType)} =\n+            if($nullTerm) {\n+              ${defaultPrimitive(resultType)}\n+            } else {\n+              $resultCode.asInstanceOf[${termForType(resultType)}]\n+            }\n+        \"\"\".children : Seq[Tree]\n+      }\n+    }\n+\n+    val inputTuple = newTermName(s\"i\")\n+\n+    // TODO: Skip generation of null handling code when expression are not nullable.\n+    val primitiveEvaluation: PartialFunction[Expression, Seq[Tree]] = {\n+      case b @ BoundReference(ordinal, _) =>\n+        q\"\"\"\n+          val $nullTerm: Boolean = $inputTuple.isNullAt($ordinal)\n+          val $primitiveTerm: ${termForType(b.dataType)} =\n+            if($nullTerm)\n+              ${defaultPrimitive(e.dataType)}\n+            else\n+              ${getColumn(inputTuple, b.dataType, ordinal)}\n+         \"\"\".children\n+\n+      case expressions.Literal(null, dataType) =>"
  }],
  "prId": 993
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "given how large this file is, it might be worth it to create a cg package (or not) and break the file into multiple files.\n",
    "commit": "96ef82c4afbf0b3eabb246e29209d953d58b3d99",
    "createdAt": "2014-06-06T08:16:11Z",
    "diffHunk": "@@ -0,0 +1,833 @@\n+/*"
  }],
  "prId": 993
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "guava has a nice cache we can use here\n",
    "commit": "96ef82c4afbf0b3eabb246e29209d953d58b3d99",
    "createdAt": "2014-06-06T08:16:43Z",
    "diffHunk": "@@ -0,0 +1,833 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+package catalyst\n+package expressions\n+\n+import types._\n+\n+object DumpByteCode {\n+  import scala.sys.process._\n+  val dumpDirectory = util.getTempFilePath(\"sparkSqlByteCode\")\n+  dumpDirectory.mkdir()\n+\n+  def apply(obj: Any): Unit = {\n+    val generatedClass = obj.getClass\n+    val classLoader =\n+      generatedClass\n+        .getClassLoader\n+        .asInstanceOf[scala.tools.nsc.interpreter.AbstractFileClassLoader]\n+    val generatedBytes = classLoader.classBytes(generatedClass.getName)\n+\n+    val packageDir = new java.io.File(dumpDirectory, generatedClass.getPackage.getName)\n+    if (!packageDir.exists()) { packageDir.mkdir() }\n+\n+    val classFile =\n+      new java.io.File(packageDir, generatedClass.getName.split(\"\\\\.\").last + \".class\")\n+\n+    val outfile = new java.io.FileOutputStream(classFile)\n+    outfile.write(generatedBytes)\n+    outfile.close()\n+\n+    println(\n+      s\"javap -p -v -classpath ${dumpDirectory.getCanonicalPath} ${generatedClass.getName}\".!!)\n+  }\n+}\n+\n+object CodeGeneration\n+\n+class CodeGenerator extends Logging {\n+  import scala.reflect.runtime.{universe => ru}\n+  import scala.reflect.runtime.universe._\n+\n+  import scala.tools.reflect.ToolBox\n+\n+  val toolBox = runtimeMirror(getClass.getClassLoader).mkToolBox()\n+\n+  // TODO: Use typetags?\n+  val rowType = tq\"org.apache.spark.sql.catalyst.expressions.Row\"\n+  val mutableRowType = tq\"org.apache.spark.sql.catalyst.expressions.MutableRow\"\n+  val genericRowType = tq\"org.apache.spark.sql.catalyst.expressions.GenericRow\"\n+  val genericMutableRowType = tq\"org.apache.spark.sql.catalyst.expressions.GenericMutableRow\"\n+\n+  val projectionType = tq\"org.apache.spark.sql.catalyst.expressions.Projection\"\n+  val mutableProjectionType = tq\"org.apache.spark.sql.catalyst.expressions.MutableProjection\"\n+\n+  private val curId = new java.util.concurrent.atomic.AtomicInteger()\n+  private val javaSeperator = \"$\"\n+\n+  /**\n+   * Returns a term name that is unique within this instance of a `CodeGenerator`.\n+   *\n+   * (Since we aren't in a macro context we do not seem to have access to the built in `freshName`\n+   * function.)\n+   */\n+  protected def freshName(prefix: String): TermName = {\n+    newTermName(s\"$prefix$javaSeperator${curId.getAndIncrement}\")\n+  }\n+\n+  /**\n+   * Scala ASTs for evaluating an [[Expression]] given a [[Row]] of input.\n+   *\n+   * @param code The sequence of statements required to evaluate the expression.\n+   * @param nullTerm A term that holds a boolean value representing whether the expression evaluated\n+   *                 to null.\n+   * @param primitiveTerm A term for a possible primitive value of the result of the evaluation. Not\n+   *                      valid if `nullTerm` is set to `false`.\n+   * @param objectTerm An possibly boxed version of the result of evaluating this expression.\n+   */\n+  protected case class EvaluatedExpression(\n+      code: Seq[Tree],\n+      nullTerm: TermName,\n+      primitiveTerm: TermName,\n+      objectTerm: TermName) {\n+\n+    def withObjectTerm = ???\n+  }\n+\n+  /**\n+   * Given an expression tree returns the code required to determine both if the result is NULL\n+   * as well as the code required to compute the value.\n+   */\n+   def expressionEvaluator(e: Expression): EvaluatedExpression = {\n+    val primitiveTerm = freshName(\"primitiveTerm\")\n+    val nullTerm = freshName(\"nullTerm\")\n+    val objectTerm = freshName(\"objectTerm\")\n+\n+    implicit class Evaluate1(e: Expression) {\n+      def castOrNull(f: TermName => Tree, dataType: DataType): Seq[Tree] = {\n+        val eval = expressionEvaluator(e)\n+        eval.code ++\n+          q\"\"\"\n+          val $nullTerm = ${eval.nullTerm}\n+          val $primitiveTerm =\n+            if($nullTerm)\n+              ${defaultPrimitive(dataType)}\n+            else\n+              ${f(eval.primitiveTerm)}\n+        \"\"\".children\n+      }\n+    }\n+\n+    implicit class Evaluate2(expressions: (Expression, Expression)) {\n+\n+      /**\n+       * Short hand for generating binary evaluation code, which depends on two sub-evaluations of\n+       * the same type.  If either of the sub-expressions is null, the results of this computation\n+       * is assumed to be null.\n+       *\n+       * @param f a function from two primitive term names to a tree that evaluates them.\n+       */\n+      def evaluate(f: (TermName, TermName) => Tree): Seq[Tree] =\n+        evaluateAs(expressions._1.dataType)(f)\n+\n+      def evaluateAs(resultType: DataType)(f: (TermName, TermName) => Tree): Seq[Tree] = {\n+        require(expressions._1.dataType == expressions._2.dataType,\n+          s\"${expressions._1.dataType} != ${expressions._2.dataType}\")\n+\n+        val eval1 = expressionEvaluator(expressions._1)\n+        val eval2 = expressionEvaluator(expressions._2)\n+        val resultCode = f(eval1.primitiveTerm, eval2.primitiveTerm)\n+\n+        eval1.code ++ eval2.code ++\n+        q\"\"\"\n+          val $nullTerm = ${eval1.nullTerm} || ${eval2.nullTerm}\n+          val $primitiveTerm: ${termForType(resultType)} =\n+            if($nullTerm) {\n+              ${defaultPrimitive(resultType)}\n+            } else {\n+              $resultCode.asInstanceOf[${termForType(resultType)}]\n+            }\n+        \"\"\".children : Seq[Tree]\n+      }\n+    }\n+\n+    val inputTuple = newTermName(s\"i\")\n+\n+    // TODO: Skip generation of null handling code when expression are not nullable.\n+    val primitiveEvaluation: PartialFunction[Expression, Seq[Tree]] = {\n+      case b @ BoundReference(ordinal, _) =>\n+        q\"\"\"\n+          val $nullTerm: Boolean = $inputTuple.isNullAt($ordinal)\n+          val $primitiveTerm: ${termForType(b.dataType)} =\n+            if($nullTerm)\n+              ${defaultPrimitive(e.dataType)}\n+            else\n+              ${getColumn(inputTuple, b.dataType, ordinal)}\n+         \"\"\".children\n+\n+      case expressions.Literal(null, dataType) =>\n+        q\"\"\"\n+          val $nullTerm = true\n+          val $primitiveTerm: ${termForType(dataType)} = null.asInstanceOf[${termForType(dataType)}]\n+         \"\"\".children\n+\n+      case expressions.Literal(value: Boolean, dataType) =>\n+        q\"\"\"\n+          val $nullTerm = ${value == null}\n+          val $primitiveTerm: ${termForType(dataType)} = $value\n+         \"\"\".children\n+\n+      case expressions.Literal(value: String, dataType) =>\n+        q\"\"\"\n+          val $nullTerm = ${value == null}\n+          val $primitiveTerm: ${termForType(dataType)} = $value\n+         \"\"\".children\n+      case expressions.Literal(value: Int, dataType) =>\n+        q\"\"\"\n+          val $nullTerm = ${value == null}\n+          val $primitiveTerm: ${termForType(dataType)} = $value\n+         \"\"\".children\n+      case expressions.Literal(value: Long, dataType) =>\n+        q\"\"\"\n+          val $nullTerm = ${value == null}\n+          val $primitiveTerm: ${termForType(dataType)} = $value\n+         \"\"\".children\n+\n+      case Cast(e @ BinaryType(), StringType) =>\n+        val eval = expressionEvaluator(e)\n+        eval.code ++\n+          q\"\"\"\n+          val $nullTerm = ${eval.nullTerm}\n+          val $primitiveTerm =\n+            if($nullTerm)\n+              ${defaultPrimitive(StringType)}\n+            else\n+              new String(${eval.primitiveTerm}.asInstanceOf[Array[Byte]])\n+        \"\"\".children\n+\n+      case Cast(child @ NumericType(), IntegerType) =>\n+        child.castOrNull(c => q\"$c.toInt\", IntegerType)\n+\n+      case Cast(child @ NumericType(), LongType) =>\n+        child.castOrNull(c => q\"$c.toLong\", LongType)\n+\n+      case Cast(child @ NumericType(), DoubleType) =>\n+        child.castOrNull(c => q\"$c.toDouble\", DoubleType)\n+\n+      case Cast(child @ NumericType(), FloatType) =>\n+        child.castOrNull(c => q\"$c.toFloat\", IntegerType)\n+\n+      case Cast(e, StringType) =>\n+        val eval = expressionEvaluator(e)\n+        eval.code ++\n+        q\"\"\"\n+          val $nullTerm = ${eval.nullTerm}\n+          val $primitiveTerm =\n+            if($nullTerm)\n+              ${defaultPrimitive(StringType)}\n+            else\n+              ${eval.primitiveTerm}.toString\n+        \"\"\".children\n+\n+      case Equals(e1, e2) =>\n+        (e1, e2).evaluateAs (BooleanType) { case (eval1, eval2) => q\"$eval1 == $eval2\" }\n+\n+      case In(e1, list) if !list.exists(!_.isInstanceOf[expressions.Literal]) =>\n+        val eval = expressionEvaluator(e1)\n+\n+        val checks = list.map {\n+          case expressions.Literal(v: String, dataType) =>\n+            q\"if(${eval.primitiveTerm} == $v) return true\"\n+          case expressions.Literal(v: Int, dataType) =>\n+            q\"if(${eval.primitiveTerm} == $v) return true\"\n+        }\n+\n+        val funcName = newTermName(s\"isIn${curId.getAndIncrement()}\")\n+\n+        q\"\"\"\n+            def $funcName: Boolean = {\n+              ..${eval.code}\n+              if(${eval.nullTerm}) return false\n+              ..$checks\n+              return false\n+            }\n+            val $nullTerm = false\n+            val $primitiveTerm = $funcName\n+        \"\"\".children\n+\n+      case GreaterThan(e1 @ NumericType(), e2 @ NumericType()) =>\n+        (e1, e2).evaluateAs (BooleanType) { case (eval1, eval2) => q\"$eval1 > $eval2\" }\n+      case GreaterThanOrEqual(e1 @ NumericType(), e2 @ NumericType()) =>\n+        (e1, e2).evaluateAs (BooleanType) { case (eval1, eval2) => q\"$eval1 >= $eval2\" }\n+      case LessThan(e1 @ NumericType(), e2 @ NumericType()) =>\n+        (e1, e2).evaluateAs (BooleanType) { case (eval1, eval2) => q\"$eval1 < $eval2\" }\n+      case LessThanOrEqual(e1 @ NumericType(), e2 @ NumericType()) =>\n+        (e1, e2).evaluateAs (BooleanType) { case (eval1, eval2) => q\"$eval1 <= $eval2\" }\n+\n+      case And(e1, e2) =>\n+        val eval1 = expressionEvaluator(e1)\n+        val eval2 = expressionEvaluator(e2)\n+\n+        eval1.code ++ eval2.code ++\n+        q\"\"\"\n+          var $nullTerm = false\n+          var $primitiveTerm: ${termForType(BooleanType)} = false\n+\n+          if ((!${eval1.nullTerm} && !${eval1.primitiveTerm}) ||\n+              (!${eval2.nullTerm} && !${eval2.primitiveTerm})) {\n+            $nullTerm = false\n+            $primitiveTerm = false\n+          } else if (${eval1.nullTerm} || ${eval2.nullTerm} ) {\n+            $nullTerm = true\n+          } else {\n+            $nullTerm = false\n+            $primitiveTerm = true\n+          }\n+         \"\"\".children\n+\n+      case Or(e1, e2) =>\n+        val eval1 = expressionEvaluator(e1)\n+        val eval2 = expressionEvaluator(e2)\n+\n+        eval1.code ++ eval2.code ++\n+          q\"\"\"\n+          var $nullTerm = false\n+          var $primitiveTerm: ${termForType(BooleanType)} = false\n+\n+          if ((!${eval1.nullTerm} && ${eval1.primitiveTerm}) ||\n+              (!${eval2.nullTerm} && ${eval2.primitiveTerm})) {\n+            $nullTerm = false\n+            $primitiveTerm = true\n+          } else if (${eval1.nullTerm} || ${eval2.nullTerm} ) {\n+            $nullTerm = true\n+          } else {\n+            $nullTerm = false\n+            $primitiveTerm = false\n+          }\n+         \"\"\".children\n+\n+      case Not(child) =>\n+        // Uh, bad function name...\n+        child.castOrNull(c => q\"!$c\", BooleanType)\n+\n+      case Add(e1, e2) =>      (e1, e2) evaluate { case (eval1, eval2) => q\"$eval1 + $eval2\" }\n+      case Subtract(e1, e2) => (e1, e2) evaluate { case (eval1, eval2) => q\"$eval1 - $eval2\" }\n+      case Multiply(e1, e2) => (e1, e2) evaluate { case (eval1, eval2) => q\"$eval1 * $eval2\" }\n+      case Divide(e1, e2) =>   (e1, e2) evaluate { case (eval1, eval2) => q\"$eval1 / $eval2\" }\n+\n+      case IsNotNull(e) =>\n+        val eval = expressionEvaluator(e)\n+        q\"\"\"\n+          ..${eval.code}\n+          var $nullTerm = false\n+          var $primitiveTerm: ${termForType(BooleanType)} = !${eval.nullTerm}\n+        \"\"\".children\n+\n+      case IsNull(e) =>\n+        val eval = expressionEvaluator(e)\n+        q\"\"\"\n+          ..${eval.code}\n+          var $nullTerm = false\n+          var $primitiveTerm: ${termForType(BooleanType)} = ${eval.nullTerm}\n+        \"\"\".children\n+\n+      case c @ Coalesce(children) =>\n+        q\"\"\"\n+          var $nullTerm = true\n+          var $primitiveTerm: ${termForType(c.dataType)} = ${defaultPrimitive(c.dataType)}\n+        \"\"\".children ++\n+        children.map { c =>\n+          val eval = expressionEvaluator(c)\n+          q\"\"\"\n+            if($nullTerm) {\n+              ..${eval.code}\n+              if(!${eval.nullTerm}) {\n+                $nullTerm = false\n+                $primitiveTerm = ${eval.primitiveTerm}\n+              }\n+            }\n+           \"\"\"\n+        }\n+\n+      case i @ expressions.If(condition, trueValue, falseValue) =>\n+        val condEval = expressionEvaluator(condition)\n+        val trueEval = expressionEvaluator(trueValue)\n+        val falseEval = expressionEvaluator(falseValue)\n+\n+        q\"\"\"\n+          var $nullTerm = false\n+          var $primitiveTerm: ${termForType(i.dataType)} = ${defaultPrimitive(i.dataType)}\n+          ..${condEval.code}\n+          if(!${condEval.nullTerm} && ${condEval.primitiveTerm}) {\n+            ..${trueEval.code}\n+            $nullTerm = ${trueEval.nullTerm}\n+            $primitiveTerm = ${trueEval.primitiveTerm}\n+          } else {\n+            ..${falseEval.code}\n+            $nullTerm = ${falseEval.nullTerm}\n+            $primitiveTerm = ${falseEval.primitiveTerm}\n+          }\n+        \"\"\".children\n+\n+      case SubString(str, start, end) =>\n+        val stringEval = expressionEvaluator(str)\n+        val startEval = expressionEvaluator(start)\n+        val endEval = expressionEvaluator(end)\n+\n+        stringEval.code ++ startEval.code ++ endEval.code ++\n+        q\"\"\"\n+          var $nullTerm = ${stringEval.nullTerm}\n+          var $primitiveTerm: String =\n+            if($nullTerm) {\n+              null\n+            } else {\n+              val len =\n+                if(${endEval.primitiveTerm} <= ${stringEval.primitiveTerm}.length)\n+                  ${endEval.primitiveTerm}\n+                else\n+                  ${stringEval.primitiveTerm}.length\n+              ${stringEval.primitiveTerm}.substring(${startEval.primitiveTerm}, len)\n+            }\n+        \"\"\".children\n+    }\n+\n+    // If there was no match in the partial function above, we fall back on calling the interpreted\n+    // expression evaluator.\n+    val code: Seq[Tree] =\n+      primitiveEvaluation.lift.apply(e)\n+        .getOrElse {\n+          logger.debug(s\"No rules to generate $e\")\n+          val tree = reify { e }\n+          q\"\"\"\n+            val $objectTerm = $tree.eval(i)\n+            val $nullTerm = $objectTerm == null\n+            val $primitiveTerm = $objectTerm.asInstanceOf[${termForType(e.dataType)}]\n+          \"\"\".children\n+        }\n+\n+     EvaluatedExpression(code, nullTerm, primitiveTerm, objectTerm)\n+  }\n+\n+  protected def getColumn(inputRow: TermName, dataType: DataType, ordinal: Int) = {\n+    dataType match {\n+      case dt @ NativeType() => q\"$inputRow.${accessorForType(dt)}($ordinal)\"\n+      case _ => q\"$inputRow.apply($ordinal).asInstanceOf[${termForType(dataType)}]\"\n+    }\n+  }\n+\n+  protected def setColumn(\n+      destinationRow: TermName,\n+      dataType: DataType,\n+      ordinal: Int,\n+      value: TermName) = {\n+    dataType match {\n+      case dt @ NativeType() => q\"$destinationRow.${mutatorForType(dt)}($ordinal, $value)\"\n+      case _ => q\"$destinationRow.update($ordinal, $value)\"\n+    }\n+  }\n+\n+  protected def accessorForType(dt: DataType) = newTermName(s\"get${primitiveForType(dt)}\")\n+  protected def mutatorForType(dt: DataType) = newTermName(s\"set${primitiveForType(dt)}\")\n+\n+  protected def primitiveForType(dt: DataType) = dt match {\n+    case IntegerType => \"Int\"\n+    case LongType => \"Long\"\n+    case ShortType => \"Short\"\n+    case ByteType => \"Byte\"\n+    case DoubleType => \"Double\"\n+    case FloatType => \"Float\"\n+    case BooleanType => \"Boolean\"\n+    case StringType => \"String\"\n+  }\n+\n+  protected def defaultPrimitive(dt: DataType) = dt match {\n+    case BooleanType => ru.Literal(Constant(false))\n+    case FloatType => ru.Literal(Constant(-1.0.toFloat))\n+    case StringType => ru.Literal(Constant(\"<uninit>\"))\n+    case ShortType => ru.Literal(Constant(-1.toShort))\n+    case LongType => ru.Literal(Constant(1L))\n+    case ByteType => ru.Literal(Constant(-1.toByte))\n+    case DoubleType => ru.Literal(Constant(-1.toDouble))\n+    case DecimalType => ru.Literal(Constant(-1)) // Will get implicity converted as needed.\n+    case IntegerType => ru.Literal(Constant(-1))\n+    case _ => ru.Literal(Constant(null))\n+  }\n+\n+  protected def termForType(dt: DataType) = dt match {\n+    case n: NativeType => n.tag\n+    case _ => typeTag[Any]\n+  }\n+}\n+\n+object GenerateOrdering extends CodeGenerator {\n+  import scala.reflect.runtime.{universe => ru}\n+  import scala.reflect.runtime.universe._\n+\n+  // TODO: Should be weak references... bounded in size.\n+  val orderingCache = new collection.mutable.HashMap[Seq[SortOrder], Ordering[Row]]\n+\n+  // TODO: Safe to fire up multiple instances of the compiler?\n+  def apply(ordering: Seq[SortOrder]): Ordering[Row] = CodeGeneration.synchronized {\n+    val cleanedExpression = ordering.map(ExpressionCanonicalizer(_)).asInstanceOf[Seq[SortOrder]]\n+    orderingCache.getOrElseUpdate(cleanedExpression, createOrdering(cleanedExpression))\n+  }\n+\n+  def createOrdering(ordering: Seq[SortOrder]): Ordering[Row] = {\n+    val a = newTermName(\"a\")\n+    val b = newTermName(\"b\")\n+    val comparisons = ordering.zipWithIndex.map { case (order, i) =>\n+      val evalA = expressionEvaluator(order.child)\n+      val evalB = expressionEvaluator(order.child)\n+\n+      q\"\"\"\n+        i = $a\n+        ..${evalA.code}\n+        i = $b\n+        ..${evalB.code}\n+        if (${evalA.nullTerm} && ${evalB.nullTerm}) {\n+          // Nothing\n+        } else if (${evalA.nullTerm}) {\n+          return ${if (order.direction == Ascending) q\"-1\" else q\"1\"}\n+        } else if (${evalB.nullTerm}) {\n+          return ${if (order.direction == Ascending) q\"1\" else q\"-1\"}\n+        } else {\n+          i = a\n+          val comp = ${evalA.primitiveTerm} - ${evalB.primitiveTerm}\n+          if(comp != 0) return comp.toInt\n+        }\n+      \"\"\"\n+    }\n+\n+    val q\"class $orderingName extends $orderingType { ..$body }\" = reify {\n+      class SpecificOrdering extends Ordering[Row] {\n+        val o = ordering\n+      }\n+    }.tree.children.head\n+\n+    val code = q\"\"\"\n+      class $orderingName extends $orderingType {\n+        ..$body\n+        def compare(a: $rowType, b: $rowType): Int = {\n+          var i: $rowType = null // Holds current row being evaluated.\n+          ..$comparisons\n+          return 0\n+        }\n+      }\n+      new $orderingName()\n+      \"\"\"\n+    toolBox.eval(code).asInstanceOf[Ordering[Row]]\n+  }\n+}\n+\n+// Canonicalize the expressions those those that differ only by names can reuse the same code.\n+object ExpressionCanonicalizer extends rules.RuleExecutor[Expression] {\n+  val batches =\n+    Batch(\"CleanExpressions\", FixedPoint(20), CleanExpressions) :: Nil\n+\n+  object CleanExpressions extends rules.Rule[Expression] {\n+    def apply(e: Expression): Expression = e transform {\n+      case BoundReference(o, a) =>\n+        BoundReference(o, AttributeReference(\"a\", a.dataType, a.nullable)(exprId = ExprId(0)))\n+      case Alias(c, _) => c\n+    }\n+  }\n+}\n+\n+object GenerateCondition extends CodeGenerator {\n+  import scala.reflect.runtime.{universe => ru}\n+  import scala.reflect.runtime.universe._\n+\n+  // TODO: Should be weak references... bounded in size.\n+  val conditionCache = new collection.mutable.HashMap[Expression, (Row) => Boolean]"
  }],
  "prId": 993
}, {
  "comments": [{
    "author": {
      "login": "hsaputra"
    },
    "body": "Would be helpful to add class header comment to describe the usage of this class in bigger context.\n",
    "commit": "96ef82c4afbf0b3eabb246e29209d953d58b3d99",
    "createdAt": "2014-06-06T15:26:23Z",
    "diffHunk": "@@ -0,0 +1,833 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+package catalyst\n+package expressions\n+\n+import types._\n+\n+object DumpByteCode {\n+  import scala.sys.process._\n+  val dumpDirectory = util.getTempFilePath(\"sparkSqlByteCode\")\n+  dumpDirectory.mkdir()\n+\n+  def apply(obj: Any): Unit = {\n+    val generatedClass = obj.getClass\n+    val classLoader =\n+      generatedClass\n+        .getClassLoader\n+        .asInstanceOf[scala.tools.nsc.interpreter.AbstractFileClassLoader]\n+    val generatedBytes = classLoader.classBytes(generatedClass.getName)\n+\n+    val packageDir = new java.io.File(dumpDirectory, generatedClass.getPackage.getName)\n+    if (!packageDir.exists()) { packageDir.mkdir() }\n+\n+    val classFile =\n+      new java.io.File(packageDir, generatedClass.getName.split(\"\\\\.\").last + \".class\")\n+\n+    val outfile = new java.io.FileOutputStream(classFile)\n+    outfile.write(generatedBytes)\n+    outfile.close()\n+\n+    println(\n+      s\"javap -p -v -classpath ${dumpDirectory.getCanonicalPath} ${generatedClass.getName}\".!!)\n+  }\n+}\n+\n+object CodeGeneration\n+\n+class CodeGenerator extends Logging {"
  }],
  "prId": 993
}]