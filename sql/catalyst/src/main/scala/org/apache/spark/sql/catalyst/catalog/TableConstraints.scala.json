[{
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "BinaryType?",
    "commit": "c126122879db0441abc8e2150d3caffa0d3b700a",
    "createdAt": "2017-08-21T04:36:03Z",
    "diffHunk": "@@ -0,0 +1,323 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.catalog\n+\n+import java.util.UUID\n+\n+import org.json4s._\n+import org.json4s.JsonAST.JValue\n+import org.json4s.JsonDSL._\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.analysis.Resolver\n+import org.apache.spark.sql.types._\n+import org.apache.spark.sql.util.SchemaUtils\n+\n+/**\n+ * A container class to hold all the constraints defined on a table. Scope of the\n+ * constraint names are at the table level.\n+ */\n+case class TableConstraints(\n+    primaryKey: Option[PrimaryKey] = None,\n+    foreignKeys: Seq[ForeignKey] = Seq.empty) {\n+\n+  /**\n+   * Adds the given constraint to the existing table constraints, after verifying the\n+   * constraint name is not a duplicate.\n+   */\n+  def addConstraint(constraint: TableConstraint, resolver: Resolver): TableConstraints = {\n+    if ((primaryKey.exists(pk => resolver(pk.constraintName, constraint.constraintName))\n+      || foreignKeys.exists(fk => resolver(fk.constraintName, constraint.constraintName)))) {\n+      throw new AnalysisException(\n+        s\"Failed to add constraint, duplicate constraint name '${constraint.constraintName}'\")\n+    }\n+    constraint match {\n+      case pk: PrimaryKey =>\n+        if (primaryKey.nonEmpty) {\n+          throw new AnalysisException(\n+            s\"Primary key '${primaryKey.get.constraintName}' already exists.\")\n+        }\n+        this.copy(primaryKey = Option(pk))\n+      case fk: ForeignKey => this.copy(foreignKeys = foreignKeys :+ fk)\n+    }\n+  }\n+}\n+\n+object TableConstraints {\n+  /**\n+   * Returns a [[TableConstraints]] containing [[PrimaryKey]] or [[ForeignKey]]\n+   */\n+  def apply(tableConstraint: TableConstraint): TableConstraints = {\n+    tableConstraint match {\n+      case pk: PrimaryKey => TableConstraints(primaryKey = Option(pk))\n+      case fk: ForeignKey => TableConstraints(foreignKeys = Seq(fk))\n+    }\n+  }\n+\n+  /**\n+   * Converts constraints represented in Json strings to [[TableConstraints]].\n+   */\n+  def fromJson(pkJson: Option[String], fksJson: Seq[String]): TableConstraints = {\n+    val pk = pkJson.map(pk => PrimaryKey.fromJson(parse(pk)))\n+    val fks = fksJson.map(fk => ForeignKey.fromJson(parse(fk)))\n+    TableConstraints(pk, fks)\n+  }\n+}\n+\n+/**\n+ * Common type representing a table constraint.\n+ */\n+sealed trait TableConstraint {\n+  val constraintName : String\n+  val keyColumnNames : Seq[String]\n+}\n+\n+object TableConstraint {\n+  private[TableConstraint] val curId = new java.util.concurrent.atomic.AtomicLong(0L)\n+  private[TableConstraint] val jvmId = UUID.randomUUID()\n+\n+  /**\n+   * Generates unique constraint name to use when adding table constraints,\n+   * if user does not specify a name. The `curId` field is unique within a given JVM,\n+   * while the `jvmId` is used to uniquely identify JVMs.\n+   */\n+  def generateConstraintName(constraintType: String = \"constraint\"): String = {\n+    s\"${constraintType}_${jvmId}_${curId.getAndIncrement()}\"\n+  }\n+\n+  def parseColumn(json: JValue): String = json match {\n+    case JString(name) => name\n+    case _ => json.toString\n+  }\n+\n+  object JSortedObject {\n+    def unapplySeq(value: JValue): Option[List[(String, JValue)]] = value match {\n+      case JObject(seq) => Some(seq.toList.sortBy(_._1))\n+      case _ => None\n+    }\n+  }\n+\n+  /**\n+   * Returns [[StructField]] for the given column name if it exists in the given schema.\n+   */\n+  def findColumnByName(\n+    schema: StructType, name: String, resolver: Resolver): StructField = {\n+    schema.fields.collectFirst {\n+      case field if resolver(field.name, name) => field\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Invalid column reference '$name', table data schema is '${schema}'\"))\n+  }\n+\n+  /**\n+   * Verify the user input constraint information, and add the missing information\n+   * like the unspecified reference columns that defaults to reference table's primary key.\n+   */\n+  def verifyAndBuildConstraint(\n+      inputConstraint: TableConstraint,\n+      table: CatalogTable,\n+      catalog: SessionCatalog,\n+      resolver: Resolver): TableConstraint = {\n+    SchemaUtils.checkColumnNameDuplication(\n+      inputConstraint.keyColumnNames, \"in the constraint key definition\", resolver)\n+    // check if the column names are valid non-partition columns.\n+    val keyColFields = inputConstraint.keyColumnNames\n+      .map(findColumnByName(table.dataSchema, _, resolver))\n+    // Constraints are only supported for basic sql types, throw error for any other data types.\n+    keyColFields.map(_.dataType).foreach {\n+      case ByteType | ShortType | IntegerType | LongType | FloatType |",
    "line": 144
  }, {
    "author": {
      "login": "sureshthalamati"
    },
    "body": "Thanks for the review @viirya . Overlooked the binay type , I will add it. ",
    "commit": "c126122879db0441abc8e2150d3caffa0d3b700a",
    "createdAt": "2017-08-24T07:29:05Z",
    "diffHunk": "@@ -0,0 +1,323 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.catalog\n+\n+import java.util.UUID\n+\n+import org.json4s._\n+import org.json4s.JsonAST.JValue\n+import org.json4s.JsonDSL._\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.analysis.Resolver\n+import org.apache.spark.sql.types._\n+import org.apache.spark.sql.util.SchemaUtils\n+\n+/**\n+ * A container class to hold all the constraints defined on a table. Scope of the\n+ * constraint names are at the table level.\n+ */\n+case class TableConstraints(\n+    primaryKey: Option[PrimaryKey] = None,\n+    foreignKeys: Seq[ForeignKey] = Seq.empty) {\n+\n+  /**\n+   * Adds the given constraint to the existing table constraints, after verifying the\n+   * constraint name is not a duplicate.\n+   */\n+  def addConstraint(constraint: TableConstraint, resolver: Resolver): TableConstraints = {\n+    if ((primaryKey.exists(pk => resolver(pk.constraintName, constraint.constraintName))\n+      || foreignKeys.exists(fk => resolver(fk.constraintName, constraint.constraintName)))) {\n+      throw new AnalysisException(\n+        s\"Failed to add constraint, duplicate constraint name '${constraint.constraintName}'\")\n+    }\n+    constraint match {\n+      case pk: PrimaryKey =>\n+        if (primaryKey.nonEmpty) {\n+          throw new AnalysisException(\n+            s\"Primary key '${primaryKey.get.constraintName}' already exists.\")\n+        }\n+        this.copy(primaryKey = Option(pk))\n+      case fk: ForeignKey => this.copy(foreignKeys = foreignKeys :+ fk)\n+    }\n+  }\n+}\n+\n+object TableConstraints {\n+  /**\n+   * Returns a [[TableConstraints]] containing [[PrimaryKey]] or [[ForeignKey]]\n+   */\n+  def apply(tableConstraint: TableConstraint): TableConstraints = {\n+    tableConstraint match {\n+      case pk: PrimaryKey => TableConstraints(primaryKey = Option(pk))\n+      case fk: ForeignKey => TableConstraints(foreignKeys = Seq(fk))\n+    }\n+  }\n+\n+  /**\n+   * Converts constraints represented in Json strings to [[TableConstraints]].\n+   */\n+  def fromJson(pkJson: Option[String], fksJson: Seq[String]): TableConstraints = {\n+    val pk = pkJson.map(pk => PrimaryKey.fromJson(parse(pk)))\n+    val fks = fksJson.map(fk => ForeignKey.fromJson(parse(fk)))\n+    TableConstraints(pk, fks)\n+  }\n+}\n+\n+/**\n+ * Common type representing a table constraint.\n+ */\n+sealed trait TableConstraint {\n+  val constraintName : String\n+  val keyColumnNames : Seq[String]\n+}\n+\n+object TableConstraint {\n+  private[TableConstraint] val curId = new java.util.concurrent.atomic.AtomicLong(0L)\n+  private[TableConstraint] val jvmId = UUID.randomUUID()\n+\n+  /**\n+   * Generates unique constraint name to use when adding table constraints,\n+   * if user does not specify a name. The `curId` field is unique within a given JVM,\n+   * while the `jvmId` is used to uniquely identify JVMs.\n+   */\n+  def generateConstraintName(constraintType: String = \"constraint\"): String = {\n+    s\"${constraintType}_${jvmId}_${curId.getAndIncrement()}\"\n+  }\n+\n+  def parseColumn(json: JValue): String = json match {\n+    case JString(name) => name\n+    case _ => json.toString\n+  }\n+\n+  object JSortedObject {\n+    def unapplySeq(value: JValue): Option[List[(String, JValue)]] = value match {\n+      case JObject(seq) => Some(seq.toList.sortBy(_._1))\n+      case _ => None\n+    }\n+  }\n+\n+  /**\n+   * Returns [[StructField]] for the given column name if it exists in the given schema.\n+   */\n+  def findColumnByName(\n+    schema: StructType, name: String, resolver: Resolver): StructField = {\n+    schema.fields.collectFirst {\n+      case field if resolver(field.name, name) => field\n+    }.getOrElse(throw new AnalysisException(\n+      s\"Invalid column reference '$name', table data schema is '${schema}'\"))\n+  }\n+\n+  /**\n+   * Verify the user input constraint information, and add the missing information\n+   * like the unspecified reference columns that defaults to reference table's primary key.\n+   */\n+  def verifyAndBuildConstraint(\n+      inputConstraint: TableConstraint,\n+      table: CatalogTable,\n+      catalog: SessionCatalog,\n+      resolver: Resolver): TableConstraint = {\n+    SchemaUtils.checkColumnNameDuplication(\n+      inputConstraint.keyColumnNames, \"in the constraint key definition\", resolver)\n+    // check if the column names are valid non-partition columns.\n+    val keyColFields = inputConstraint.keyColumnNames\n+      .map(findColumnByName(table.dataSchema, _, resolver))\n+    // Constraints are only supported for basic sql types, throw error for any other data types.\n+    keyColFields.map(_.dataType).foreach {\n+      case ByteType | ShortType | IntegerType | LongType | FloatType |",
    "line": 144
  }],
  "prId": 18994
}]