[{
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "This doesn't keep catalog and table resolution separate, it combines them in the `CatalogAndTable` extractor.\r\n\r\nI think those should be separate rules. Resolving the catalog should create an `UnresolvedRelation`, then resolving the table should replace it with a DSv2 relation.\r\n\r\nThis approach also keeps the connector API separate from logical plans. There's no need to make the logical `AlterTable` node dependent on the `Table` API because it is a purely SQL operation and it should not be tied to the underlying connector API.",
    "commit": "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "createdAt": "2019-09-25T18:51:20Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.plans.logical.{AlterTable, DeleteFromTable, DescribeTable, LogicalPlan, SubqueryAlias}\n+import org.apache.spark.sql.catalyst.plans.logical.sql.{AlterTableAddColumnsStatement, AlterTableAlterColumnStatement, AlterTableDropColumnsStatement, AlterTableRenameColumnStatement, AlterTableSetLocationStatement, AlterTableSetPropertiesStatement, AlterTableUnsetPropertiesStatement, AlterViewSetPropertiesStatement, AlterViewUnsetPropertiesStatement, DeleteFromStatement, DescribeColumnStatement, DescribeTableStatement, UpdateTableStatement}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.connector.catalog.{CatalogManager, LookupCatalog, Table, TableChange, V1Table}\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceV2Relation\n+\n+/**\n+ * Resolves catalogs and tables from the multi-part identifiers in SQL statements, and convert the\n+ * statements to the corresponding v2 commands if the resolved table is not a [[V1Table]].\n+ */\n+class ResolveCatalogAndTables(val catalogManager: CatalogManager)"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "I tried your idea, but unfortunately it doesn't work. For example, when resolving ALTER TABLE, what we need to do is:\r\n1. resolve catalog\r\n2. resolve table\r\n3. if table is v1, convert to v1 ALTER TABLE command. Otherwise, convert to v2 ALTER TABLE command.\r\n\r\nThese 3 steps must be done together, otherwise we need to introduce a new logical plan as an intermediate representation of the query plan that has catalog resolved, and will be converted to v1 or v2 command later.",
    "commit": "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "createdAt": "2019-09-26T03:26:31Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.plans.logical.{AlterTable, DeleteFromTable, DescribeTable, LogicalPlan, SubqueryAlias}\n+import org.apache.spark.sql.catalyst.plans.logical.sql.{AlterTableAddColumnsStatement, AlterTableAlterColumnStatement, AlterTableDropColumnsStatement, AlterTableRenameColumnStatement, AlterTableSetLocationStatement, AlterTableSetPropertiesStatement, AlterTableUnsetPropertiesStatement, AlterViewSetPropertiesStatement, AlterViewUnsetPropertiesStatement, DeleteFromStatement, DescribeColumnStatement, DescribeTableStatement, UpdateTableStatement}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.connector.catalog.{CatalogManager, LookupCatalog, Table, TableChange, V1Table}\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceV2Relation\n+\n+/**\n+ * Resolves catalogs and tables from the multi-part identifiers in SQL statements, and convert the\n+ * statements to the corresponding v2 commands if the resolved table is not a [[V1Table]].\n+ */\n+class ResolveCatalogAndTables(val catalogManager: CatalogManager)"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "These steps must be done together only for v1 tables, and we already have rules that convert v1 tables separately. So the v1 table rules will need to look up the table before converting. I agree with you there. But when the catalog is any v2 catalog other than the session catalog, it will work to use UnresolvedRelation.",
    "commit": "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "createdAt": "2019-09-26T22:00:31Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.plans.logical.{AlterTable, DeleteFromTable, DescribeTable, LogicalPlan, SubqueryAlias}\n+import org.apache.spark.sql.catalyst.plans.logical.sql.{AlterTableAddColumnsStatement, AlterTableAlterColumnStatement, AlterTableDropColumnsStatement, AlterTableRenameColumnStatement, AlterTableSetLocationStatement, AlterTableSetPropertiesStatement, AlterTableUnsetPropertiesStatement, AlterViewSetPropertiesStatement, AlterViewUnsetPropertiesStatement, DeleteFromStatement, DescribeColumnStatement, DescribeTableStatement, UpdateTableStatement}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.connector.catalog.{CatalogManager, LookupCatalog, Table, TableChange, V1Table}\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceV2Relation\n+\n+/**\n+ * Resolves catalogs and tables from the multi-part identifiers in SQL statements, and convert the\n+ * statements to the corresponding v2 commands if the resolved table is not a [[V1Table]].\n+ */\n+class ResolveCatalogAndTables(val catalogManager: CatalogManager)"
  }],
  "prId": 25747
}]