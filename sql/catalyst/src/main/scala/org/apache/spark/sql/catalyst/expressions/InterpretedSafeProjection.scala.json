[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "does `SafeProjection` need to handle `NoOp`? It's only used with `MutableProjection` in aggregate.",
    "commit": "fbfbbff55d900ae1101ceb4f7823a9298464cb07",
    "createdAt": "2018-10-16T12:39:38Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.aggregate.NoOp\n+import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, ArrayData, GenericArrayData, MapData}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * An interpreted version of a safe projection.\n+ *\n+ * @param expressions that produces the resulting fields. These expressions must be bound\n+ *                    to a schema.\n+ */\n+class InterpretedSafeProjection(expressions: Seq[Expression]) extends Projection {\n+\n+  private[this] val mutableRow = new SpecificInternalRow(expressions.map(_.dataType))\n+\n+  private[this] val exprsWithWriters = expressions.zipWithIndex.filter {\n+    case (NoOp, _) => false",
    "line": 36
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "IIUC the input expressions in `UnsafeProjection` possibly have `NoOp`s passed from aggregate expressions? So, IIUC `GenerateSafeProjection` handles `NoOp`s here:\r\nhttps://github.com/apache/spark/blob/3b4556745e90a13f4ae7ebae4ab682617de25c38/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/codegen/GenerateSafeProjection.scala#L153\r\nI'm not 100% sure though... ",
    "commit": "fbfbbff55d900ae1101ceb4f7823a9298464cb07",
    "createdAt": "2018-10-23T00:31:24Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.aggregate.NoOp\n+import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, ArrayData, GenericArrayData, MapData}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * An interpreted version of a safe projection.\n+ *\n+ * @param expressions that produces the resulting fields. These expressions must be bound\n+ *                    to a schema.\n+ */\n+class InterpretedSafeProjection(expressions: Seq[Expression]) extends Projection {\n+\n+  private[this] val mutableRow = new SpecificInternalRow(expressions.map(_.dataType))\n+\n+  private[this] val exprsWithWriters = expressions.zipWithIndex.filter {\n+    case (NoOp, _) => false",
    "line": 36
  }],
  "prId": 22468
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "`CodeGenerator.isPrimitiveType`",
    "commit": "fbfbbff55d900ae1101ceb4f7823a9298464cb07",
    "createdAt": "2018-10-16T12:40:57Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.aggregate.NoOp\n+import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, ArrayData, GenericArrayData, MapData}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * An interpreted version of a safe projection.\n+ *\n+ * @param expressions that produces the resulting fields. These expressions must be bound\n+ *                    to a schema.\n+ */\n+class InterpretedSafeProjection(expressions: Seq[Expression]) extends Projection {\n+\n+  private[this] val mutableRow = new SpecificInternalRow(expressions.map(_.dataType))\n+\n+  private[this] val exprsWithWriters = expressions.zipWithIndex.filter {\n+    case (NoOp, _) => false\n+    case _ => true\n+  }.map { case (e, i) =>\n+    val converter = generateSafeValueConverter(e.dataType)\n+    val writer = generateRowWriter(i, e.dataType)\n+    val f = if (!e.nullable) {\n+      (v: Any) => writer(converter(v))\n+    } else {\n+      (v: Any) => {\n+        if (v == null) {\n+          mutableRow.setNullAt(i)\n+        } else {\n+          writer(converter(v))\n+        }\n+      }\n+    }\n+    (e, f)\n+  }\n+\n+  private def isPrimitive(dataType: DataType): Boolean = dataType match {"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "ok. ~BTW, `isPrimitive` is a general helper function, so can we move this func. from `CodeGenerator` to an other place, e.g., `object DataType`?~ NVM, we don't need `isPrimitivieType` here.",
    "commit": "fbfbbff55d900ae1101ceb4f7823a9298464cb07",
    "createdAt": "2018-10-23T00:31:33Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.aggregate.NoOp\n+import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, ArrayData, GenericArrayData, MapData}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * An interpreted version of a safe projection.\n+ *\n+ * @param expressions that produces the resulting fields. These expressions must be bound\n+ *                    to a schema.\n+ */\n+class InterpretedSafeProjection(expressions: Seq[Expression]) extends Projection {\n+\n+  private[this] val mutableRow = new SpecificInternalRow(expressions.map(_.dataType))\n+\n+  private[this] val exprsWithWriters = expressions.zipWithIndex.filter {\n+    case (NoOp, _) => false\n+    case _ => true\n+  }.map { case (e, i) =>\n+    val converter = generateSafeValueConverter(e.dataType)\n+    val writer = generateRowWriter(i, e.dataType)\n+    val f = if (!e.nullable) {\n+      (v: Any) => writer(converter(v))\n+    } else {\n+      (v: Any) => {\n+        if (v == null) {\n+          mutableRow.setNullAt(i)\n+        } else {\n+          writer(converter(v))\n+        }\n+      }\n+    }\n+    (e, f)\n+  }\n+\n+  private def isPrimitive(dataType: DataType): Boolean = dataType match {"
  }],
  "prId": 22468
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "Let's not add this optimization at the beginning. We can add it later with a benchmark.",
    "commit": "fbfbbff55d900ae1101ceb4f7823a9298464cb07",
    "createdAt": "2018-10-16T12:42:12Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.aggregate.NoOp\n+import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, ArrayData, GenericArrayData, MapData}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * An interpreted version of a safe projection.\n+ *\n+ * @param expressions that produces the resulting fields. These expressions must be bound\n+ *                    to a schema.\n+ */\n+class InterpretedSafeProjection(expressions: Seq[Expression]) extends Projection {\n+\n+  private[this] val mutableRow = new SpecificInternalRow(expressions.map(_.dataType))\n+\n+  private[this] val exprsWithWriters = expressions.zipWithIndex.filter {\n+    case (NoOp, _) => false\n+    case _ => true\n+  }.map { case (e, i) =>\n+    val converter = generateSafeValueConverter(e.dataType)\n+    val writer = generateRowWriter(i, e.dataType)\n+    val f = if (!e.nullable) {\n+      (v: Any) => writer(converter(v))\n+    } else {\n+      (v: Any) => {\n+        if (v == null) {\n+          mutableRow.setNullAt(i)\n+        } else {\n+          writer(converter(v))\n+        }\n+      }\n+    }\n+    (e, f)\n+  }\n+\n+  private def isPrimitive(dataType: DataType): Boolean = dataType match {\n+    case BooleanType => true\n+    case ByteType => true\n+    case ShortType => true\n+    case IntegerType => true\n+    case LongType => true\n+    case FloatType => true\n+    case DoubleType => true\n+    case _ => false\n+  }\n+\n+  private def generateSafeValueConverter(dt: DataType): Any => Any = dt match {\n+    case ArrayType(elemType, _) =>\n+      if (isPrimitive(elemType)) {"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "ok",
    "commit": "fbfbbff55d900ae1101ceb4f7823a9298464cb07",
    "createdAt": "2018-10-23T00:38:15Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.aggregate.NoOp\n+import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, ArrayData, GenericArrayData, MapData}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * An interpreted version of a safe projection.\n+ *\n+ * @param expressions that produces the resulting fields. These expressions must be bound\n+ *                    to a schema.\n+ */\n+class InterpretedSafeProjection(expressions: Seq[Expression]) extends Projection {\n+\n+  private[this] val mutableRow = new SpecificInternalRow(expressions.map(_.dataType))\n+\n+  private[this] val exprsWithWriters = expressions.zipWithIndex.filter {\n+    case (NoOp, _) => false\n+    case _ => true\n+  }.map { case (e, i) =>\n+    val converter = generateSafeValueConverter(e.dataType)\n+    val writer = generateRowWriter(i, e.dataType)\n+    val f = if (!e.nullable) {\n+      (v: Any) => writer(converter(v))\n+    } else {\n+      (v: Any) => {\n+        if (v == null) {\n+          mutableRow.setNullAt(i)\n+        } else {\n+          writer(converter(v))\n+        }\n+      }\n+    }\n+    (e, f)\n+  }\n+\n+  private def isPrimitive(dataType: DataType): Boolean = dataType match {\n+    case BooleanType => true\n+    case ByteType => true\n+    case ShortType => true\n+    case IntegerType => true\n+    case LongType => true\n+    case FloatType => true\n+    case DoubleType => true\n+    case _ => false\n+  }\n+\n+  private def generateSafeValueConverter(dt: DataType): Any => Any = dt match {\n+    case ArrayType(elemType, _) =>\n+      if (isPrimitive(elemType)) {"
  }],
  "prId": 22468
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "ditto",
    "commit": "fbfbbff55d900ae1101ceb4f7823a9298464cb07",
    "createdAt": "2018-10-16T12:42:48Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.aggregate.NoOp\n+import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, ArrayData, GenericArrayData, MapData}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * An interpreted version of a safe projection.\n+ *\n+ * @param expressions that produces the resulting fields. These expressions must be bound\n+ *                    to a schema.\n+ */\n+class InterpretedSafeProjection(expressions: Seq[Expression]) extends Projection {\n+\n+  private[this] val mutableRow = new SpecificInternalRow(expressions.map(_.dataType))\n+\n+  private[this] val exprsWithWriters = expressions.zipWithIndex.filter {\n+    case (NoOp, _) => false\n+    case _ => true\n+  }.map { case (e, i) =>\n+    val converter = generateSafeValueConverter(e.dataType)\n+    val writer = generateRowWriter(i, e.dataType)\n+    val f = if (!e.nullable) {\n+      (v: Any) => writer(converter(v))\n+    } else {\n+      (v: Any) => {\n+        if (v == null) {\n+          mutableRow.setNullAt(i)\n+        } else {\n+          writer(converter(v))\n+        }\n+      }\n+    }\n+    (e, f)\n+  }\n+\n+  private def isPrimitive(dataType: DataType): Boolean = dataType match {\n+    case BooleanType => true\n+    case ByteType => true\n+    case ShortType => true\n+    case IntegerType => true\n+    case LongType => true\n+    case FloatType => true\n+    case DoubleType => true\n+    case _ => false\n+  }\n+\n+  private def generateSafeValueConverter(dt: DataType): Any => Any = dt match {\n+    case ArrayType(elemType, _) =>\n+      if (isPrimitive(elemType)) {\n+        v => {\n+          val arrayValue = v.asInstanceOf[ArrayData]\n+          new GenericArrayData(arrayValue.toArray[Any](elemType))\n+        }\n+      } else {\n+        val elementConverter = generateSafeValueConverter(elemType)\n+        v => {\n+          val arrayValue = v.asInstanceOf[ArrayData]\n+          val result = new Array[Any](arrayValue.numElements())\n+          arrayValue.foreach(elemType, (i, e) => {\n+            result(i) = elementConverter(e)\n+          })\n+          new GenericArrayData(result)\n+        }\n+      }\n+\n+    case st: StructType =>\n+      val fieldTypes = st.fields.map(_.dataType)\n+      val fieldConverters = fieldTypes.map(generateSafeValueConverter)\n+      v => {\n+        val row = v.asInstanceOf[InternalRow]\n+        val ar = new Array[Any](row.numFields)\n+        var idx = 0\n+        while (idx < row.numFields) {\n+          ar(idx) = fieldConverters(idx)(row.get(idx, fieldTypes(idx)))\n+          idx += 1\n+        }\n+        new GenericInternalRow(ar)\n+      }\n+\n+    case MapType(keyType, valueType, _) =>\n+      lazy val keyConverter = generateSafeValueConverter(keyType)\n+      lazy val valueConverter = generateSafeValueConverter(valueType)\n+      v => {\n+        val mapValue = v.asInstanceOf[MapData]\n+        val keys = mapValue.keyArray().toArray[Any](keyType)\n+        val values = mapValue.valueArray().toArray[Any](valueType)\n+        val convertedKeys =\n+          if (isPrimitive(keyType)) keys else keys.map(keyConverter)"
  }],
  "prId": 22468
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "shall we share it with other interpreted projections?",
    "commit": "fbfbbff55d900ae1101ceb4f7823a9298464cb07",
    "createdAt": "2018-10-16T12:43:59Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.aggregate.NoOp\n+import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, ArrayData, GenericArrayData, MapData}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * An interpreted version of a safe projection.\n+ *\n+ * @param expressions that produces the resulting fields. These expressions must be bound\n+ *                    to a schema.\n+ */\n+class InterpretedSafeProjection(expressions: Seq[Expression]) extends Projection {\n+\n+  private[this] val mutableRow = new SpecificInternalRow(expressions.map(_.dataType))\n+\n+  private[this] val exprsWithWriters = expressions.zipWithIndex.filter {\n+    case (NoOp, _) => false\n+    case _ => true\n+  }.map { case (e, i) =>\n+    val converter = generateSafeValueConverter(e.dataType)\n+    val writer = generateRowWriter(i, e.dataType)\n+    val f = if (!e.nullable) {\n+      (v: Any) => writer(converter(v))\n+    } else {\n+      (v: Any) => {\n+        if (v == null) {\n+          mutableRow.setNullAt(i)\n+        } else {\n+          writer(converter(v))\n+        }\n+      }\n+    }\n+    (e, f)\n+  }\n+\n+  private def isPrimitive(dataType: DataType): Boolean = dataType match {\n+    case BooleanType => true\n+    case ByteType => true\n+    case ShortType => true\n+    case IntegerType => true\n+    case LongType => true\n+    case FloatType => true\n+    case DoubleType => true\n+    case _ => false\n+  }\n+\n+  private def generateSafeValueConverter(dt: DataType): Any => Any = dt match {\n+    case ArrayType(elemType, _) =>\n+      if (isPrimitive(elemType)) {\n+        v => {\n+          val arrayValue = v.asInstanceOf[ArrayData]\n+          new GenericArrayData(arrayValue.toArray[Any](elemType))\n+        }\n+      } else {\n+        val elementConverter = generateSafeValueConverter(elemType)\n+        v => {\n+          val arrayValue = v.asInstanceOf[ArrayData]\n+          val result = new Array[Any](arrayValue.numElements())\n+          arrayValue.foreach(elemType, (i, e) => {\n+            result(i) = elementConverter(e)\n+          })\n+          new GenericArrayData(result)\n+        }\n+      }\n+\n+    case st: StructType =>\n+      val fieldTypes = st.fields.map(_.dataType)\n+      val fieldConverters = fieldTypes.map(generateSafeValueConverter)\n+      v => {\n+        val row = v.asInstanceOf[InternalRow]\n+        val ar = new Array[Any](row.numFields)\n+        var idx = 0\n+        while (idx < row.numFields) {\n+          ar(idx) = fieldConverters(idx)(row.get(idx, fieldTypes(idx)))\n+          idx += 1\n+        }\n+        new GenericInternalRow(ar)\n+      }\n+\n+    case MapType(keyType, valueType, _) =>\n+      lazy val keyConverter = generateSafeValueConverter(keyType)\n+      lazy val valueConverter = generateSafeValueConverter(valueType)\n+      v => {\n+        val mapValue = v.asInstanceOf[MapData]\n+        val keys = mapValue.keyArray().toArray[Any](keyType)\n+        val values = mapValue.valueArray().toArray[Any](valueType)\n+        val convertedKeys =\n+          if (isPrimitive(keyType)) keys else keys.map(keyConverter)\n+        val convertedValues =\n+          if (isPrimitive(valueType)) values else values.map(valueConverter)\n+\n+        ArrayBasedMapData(convertedKeys, convertedValues)\n+      }\n+\n+    case udt: UserDefinedType[_] =>\n+      generateSafeValueConverter(udt.sqlType)\n+\n+    case _ => identity\n+  }\n+\n+  private def generateRowWriter(ordinal: Int, dt: DataType): Any => Unit = dt match {"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "~ok, I'll brush up.~  The master doesn't have this logic yet in the other interpreted projections, and #22512 has the same logic. So, I'll fix #22512 first, then share it in this pr.",
    "commit": "fbfbbff55d900ae1101ceb4f7823a9298464cb07",
    "createdAt": "2018-10-23T00:40:46Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.catalyst.expressions\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.aggregate.NoOp\n+import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, ArrayData, GenericArrayData, MapData}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * An interpreted version of a safe projection.\n+ *\n+ * @param expressions that produces the resulting fields. These expressions must be bound\n+ *                    to a schema.\n+ */\n+class InterpretedSafeProjection(expressions: Seq[Expression]) extends Projection {\n+\n+  private[this] val mutableRow = new SpecificInternalRow(expressions.map(_.dataType))\n+\n+  private[this] val exprsWithWriters = expressions.zipWithIndex.filter {\n+    case (NoOp, _) => false\n+    case _ => true\n+  }.map { case (e, i) =>\n+    val converter = generateSafeValueConverter(e.dataType)\n+    val writer = generateRowWriter(i, e.dataType)\n+    val f = if (!e.nullable) {\n+      (v: Any) => writer(converter(v))\n+    } else {\n+      (v: Any) => {\n+        if (v == null) {\n+          mutableRow.setNullAt(i)\n+        } else {\n+          writer(converter(v))\n+        }\n+      }\n+    }\n+    (e, f)\n+  }\n+\n+  private def isPrimitive(dataType: DataType): Boolean = dataType match {\n+    case BooleanType => true\n+    case ByteType => true\n+    case ShortType => true\n+    case IntegerType => true\n+    case LongType => true\n+    case FloatType => true\n+    case DoubleType => true\n+    case _ => false\n+  }\n+\n+  private def generateSafeValueConverter(dt: DataType): Any => Any = dt match {\n+    case ArrayType(elemType, _) =>\n+      if (isPrimitive(elemType)) {\n+        v => {\n+          val arrayValue = v.asInstanceOf[ArrayData]\n+          new GenericArrayData(arrayValue.toArray[Any](elemType))\n+        }\n+      } else {\n+        val elementConverter = generateSafeValueConverter(elemType)\n+        v => {\n+          val arrayValue = v.asInstanceOf[ArrayData]\n+          val result = new Array[Any](arrayValue.numElements())\n+          arrayValue.foreach(elemType, (i, e) => {\n+            result(i) = elementConverter(e)\n+          })\n+          new GenericArrayData(result)\n+        }\n+      }\n+\n+    case st: StructType =>\n+      val fieldTypes = st.fields.map(_.dataType)\n+      val fieldConverters = fieldTypes.map(generateSafeValueConverter)\n+      v => {\n+        val row = v.asInstanceOf[InternalRow]\n+        val ar = new Array[Any](row.numFields)\n+        var idx = 0\n+        while (idx < row.numFields) {\n+          ar(idx) = fieldConverters(idx)(row.get(idx, fieldTypes(idx)))\n+          idx += 1\n+        }\n+        new GenericInternalRow(ar)\n+      }\n+\n+    case MapType(keyType, valueType, _) =>\n+      lazy val keyConverter = generateSafeValueConverter(keyType)\n+      lazy val valueConverter = generateSafeValueConverter(valueType)\n+      v => {\n+        val mapValue = v.asInstanceOf[MapData]\n+        val keys = mapValue.keyArray().toArray[Any](keyType)\n+        val values = mapValue.valueArray().toArray[Any](valueType)\n+        val convertedKeys =\n+          if (isPrimitive(keyType)) keys else keys.map(keyConverter)\n+        val convertedValues =\n+          if (isPrimitive(valueType)) values else values.map(valueConverter)\n+\n+        ArrayBasedMapData(convertedKeys, convertedValues)\n+      }\n+\n+    case udt: UserDefinedType[_] =>\n+      generateSafeValueConverter(udt.sqlType)\n+\n+    case _ => identity\n+  }\n+\n+  private def generateRowWriter(ordinal: Int, dt: DataType): Any => Unit = dt match {"
  }],
  "prId": 22468
}]