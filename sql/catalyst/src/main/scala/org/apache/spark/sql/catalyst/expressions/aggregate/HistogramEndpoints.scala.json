[{
  "comments": [{
    "author": {
      "login": "srinathshankar"
    },
    "body": "Isn't this just\n`mergeMap(baseMap, (value -> 1), numBins)`\n",
    "commit": "b7fcaf46a865a1f48ffa1377f47d8f17ffe3e445",
    "createdAt": "2016-10-28T21:03:33Z",
    "diffHunk": "@@ -0,0 +1,465 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import java.nio.ByteBuffer\n+\n+import scala.collection.immutable.TreeMap\n+import scala.collection.mutable\n+\n+import com.google.common.primitives.{Doubles, Ints, Longs}\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription, Literal}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile.{PercentileDigest, PercentileDigestSerializer}\n+import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, QuantileSummaries}\n+import org.apache.spark.sql.catalyst.util.QuantileSummaries._\n+import org.apache.spark.sql.types.{DataType, _}\n+import org.apache.spark.unsafe.types.UTF8String\n+\n+/**\n+ * The HistogramEndpoints function for a column returns bins - (distinct value, frequency) pairs\n+ * of equi-width histogram when the number of distinct values is less than or equal to the\n+ * specified maximum number of bins. Otherwise, for column of string type, it returns an empty\n+ * map; for column of numeric type, it returns endpoints of equi-height histogram - approximate\n+ * percentiles at percentages 0.0, 1/numBins, 2/numBins, ..., (numBins-1)/numBins, 1.0.\n+ *\n+ * @param child child expression that can produce column value with `child.eval(inputRow)`\n+ * @param numBinsExpression The maximum number of bins.\n+ * @param accuracyExpression Accuracy used in computing approximate percentiles.\n+ */\n+@ExpressionDescription(\n+  usage =\n+    \"\"\"\n+      _FUNC_(col, numBins [, accuracy]) - Returns bins - (distinct value, frequency) pairs\n+      of equi-width histogram when the number of distinct values is less than or equal to the\n+      specified maximum number of bins. Otherwise, for column of string type, it returns an empty\n+      map; for column of numeric type, it returns endpoints of equi-height histogram - approximate\n+      percentiles at percentages 0.0, 1/numBins, 2/numBins, ..., (numBins-1)/numBins, 1.0. The\n+      `accuracy` parameter (default: 10000) is a positive integer literal which controls percentiles\n+      approximation accuracy at the cost of memory. Higher value of `accuracy` yields better\n+      accuracy, `1.0/accuracy` is the relative error of the approximation.\n+    \"\"\")\n+case class HistogramEndpoints(\n+    child: Expression,\n+    numBinsExpression: Expression,\n+    accuracyExpression: Expression,\n+    override val mutableAggBufferOffset: Int,\n+    override val inputAggBufferOffset: Int) extends TypedImperativeAggregate[EndpointsDigest] {\n+\n+  def this(child: Expression, numBinsExpression: Expression, accuracyExpression: Expression) = {\n+    this(child, numBinsExpression, accuracyExpression, 0, 0)\n+  }\n+\n+  def this(child: Expression, numBinsExpression: Expression) = {\n+    this(child, numBinsExpression, Literal(ApproximatePercentile.DEFAULT_PERCENTILE_ACCURACY))\n+  }\n+\n+  // Mark as lazy so that numBinsExpression is not evaluated during tree transformation.\n+  private lazy val numBins: Int = numBinsExpression.eval().asInstanceOf[Int]\n+\n+  private lazy val percentages: Array[Double] = {\n+    val array = new Array[Double](numBins + 1)\n+    for (i <- 0 to numBins) {\n+      array(i) = i / numBins.toDouble\n+    }\n+    array\n+  }\n+\n+  private lazy val accuracy: Int = accuracyExpression.eval().asInstanceOf[Int]\n+\n+  override def inputTypes: Seq[AbstractDataType] = {\n+    Seq(TypeCollection(NumericType, TimestampType, DateType, StringType), IntegerType, IntegerType)\n+  }\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    val defaultCheck = super.checkInputDataTypes()\n+    if (defaultCheck.isFailure) {\n+      defaultCheck\n+    } else if (!numBinsExpression.foldable || !accuracyExpression.foldable) {\n+      TypeCheckFailure(\"The maximum number of bins or accuracy provided must be a constant literal\")\n+    } else if (numBins < 2) {\n+      TypeCheckFailure(\n+        \"The maximum number of bins provided must be a positive integer literal >= 2 \" +\n+          s\"(current value = $numBins)\")\n+    } else if (accuracy <= 0) {\n+      TypeCheckFailure(\n+        s\"The accuracy provided must be a positive integer literal (current value = $accuracy)\")\n+    } else {\n+      TypeCheckSuccess\n+    }\n+  }\n+\n+  override def update(buffer: EndpointsDigest, input: InternalRow): Unit = {\n+    if (buffer.invalid) {\n+      return\n+    }\n+    val evaluated = child.eval(input)\n+    if (evaluated != null) {\n+      buffer.update(child.dataType, evaluated, numBins)\n+    }\n+  }\n+\n+  override def merge(buffer: EndpointsDigest, other: EndpointsDigest): Unit = {\n+    if (buffer.invalid) return\n+    if (other.invalid) {\n+      buffer.invalid = true\n+      buffer.clear()\n+      return\n+    }\n+    buffer.merge(other, numBins)\n+  }\n+\n+  override def eval(buffer: EndpointsDigest): Any = {\n+    if (buffer.invalid) {\n+      // return empty map\n+      ArrayBasedMapData(Map.empty)\n+    } else {\n+      buffer match {\n+        case stringDigest: StringEndpointsDigest =>\n+          // sort the result to make it more readable\n+          val sorted = TreeMap[UTF8String, Long](stringDigest.bins.toSeq: _*)\n+          ArrayBasedMapData(sorted.keys.toArray, sorted.values.toArray)\n+        case numericDigest: NumericEndpointsDigest =>\n+          if (!numericDigest.mapInvalid) {\n+            val sorted = TreeMap[Double, Long](numericDigest.bins.toSeq: _*)\n+            ArrayBasedMapData(sorted.keys.toArray, sorted.values.toArray)\n+          } else {\n+            val percentiles = numericDigest.percentileDigest.getPercentiles(percentages)\n+            // we only need percentiles, this is for constructing MapData\n+            val padding = new Array[Long](percentiles.length)\n+            ArrayBasedMapData(percentiles, padding)\n+          }\n+      }\n+    }\n+  }\n+\n+  override def serialize(buffer: EndpointsDigest): Array[Byte] = {\n+    buffer match {\n+      case stringDigest: StringEndpointsDigest => StringEndpointsDigest.serialize(stringDigest)\n+      case numericDigest: NumericEndpointsDigest => NumericEndpointsDigest.serialize(numericDigest)\n+    }\n+  }\n+\n+  override def deserialize(bytes: Array[Byte]): EndpointsDigest = {\n+    child.dataType match {\n+      case StringType => StringEndpointsDigest.deserialize(bytes)\n+      case _ => NumericEndpointsDigest.deserialize(bytes)\n+    }\n+  }\n+\n+  override def createAggregationBuffer(): EndpointsDigest = {\n+    child.dataType match {\n+      case StringType =>\n+        StringEndpointsDigest()\n+      case _ =>\n+        NumericEndpointsDigest(new PercentileDigest(1.0D / accuracy))\n+    }\n+  }\n+\n+  override def withNewMutableAggBufferOffset(newMutableAggBufferOffset: Int): HistogramEndpoints = {\n+    copy(mutableAggBufferOffset = newMutableAggBufferOffset)\n+  }\n+\n+  override def withNewInputAggBufferOffset(newInputAggBufferOffset: Int): HistogramEndpoints = {\n+    copy(inputAggBufferOffset = newInputAggBufferOffset)\n+  }\n+\n+  override def nullable: Boolean = false\n+\n+  override def dataType: DataType = {\n+    child.dataType match {\n+      case StringType => MapType(StringType, LongType)\n+      case _ => MapType(DoubleType, LongType)\n+    }\n+  }\n+\n+  override def children: Seq[Expression] = Seq(child, numBinsExpression, accuracyExpression)\n+\n+  override def prettyName: String = \"histogram_endpoints\"\n+}\n+\n+trait EndpointsDigest {\n+\n+  // Mark this EndpointsDigest as invalid when:\n+  // 1. for string type - the size of the hashmap (ndv of the column) exceeds numBins;\n+  // 2. for numeric type - Some Decimal value out of the range of Double occurs.\n+  var invalid: Boolean = false\n+\n+  def update(dataType: DataType, value: Any, numBins: Int): Unit\n+  def merge(otherDigest: EndpointsDigest, numBins: Int): Unit\n+  def clear(): Unit\n+\n+  // Updates baseMap, and returns success or not.\n+  def updateMap[T](baseMap: mutable.HashMap[T, Long], value: T, numBins: Int): Boolean = {\n+    if (baseMap.contains(value)) {"
  }],
  "prId": 15637
}, {
  "comments": [{
    "author": {
      "login": "srinathshankar"
    },
    "body": "I take it you're updating the percentile in all cases because you don;t want to merge maps with percentiledigests ?\n",
    "commit": "b7fcaf46a865a1f48ffa1377f47d8f17ffe3e445",
    "createdAt": "2016-10-28T22:16:20Z",
    "diffHunk": "@@ -0,0 +1,465 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import java.nio.ByteBuffer\n+\n+import scala.collection.immutable.TreeMap\n+import scala.collection.mutable\n+\n+import com.google.common.primitives.{Doubles, Ints, Longs}\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription, Literal}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile.{PercentileDigest, PercentileDigestSerializer}\n+import org.apache.spark.sql.catalyst.util.{ArrayBasedMapData, QuantileSummaries}\n+import org.apache.spark.sql.catalyst.util.QuantileSummaries._\n+import org.apache.spark.sql.types.{DataType, _}\n+import org.apache.spark.unsafe.types.UTF8String\n+\n+/**\n+ * The HistogramEndpoints function for a column returns bins - (distinct value, frequency) pairs\n+ * of equi-width histogram when the number of distinct values is less than or equal to the\n+ * specified maximum number of bins. Otherwise, for column of string type, it returns an empty\n+ * map; for column of numeric type, it returns endpoints of equi-height histogram - approximate\n+ * percentiles at percentages 0.0, 1/numBins, 2/numBins, ..., (numBins-1)/numBins, 1.0.\n+ *\n+ * @param child child expression that can produce column value with `child.eval(inputRow)`\n+ * @param numBinsExpression The maximum number of bins.\n+ * @param accuracyExpression Accuracy used in computing approximate percentiles.\n+ */\n+@ExpressionDescription(\n+  usage =\n+    \"\"\"\n+      _FUNC_(col, numBins [, accuracy]) - Returns bins - (distinct value, frequency) pairs\n+      of equi-width histogram when the number of distinct values is less than or equal to the\n+      specified maximum number of bins. Otherwise, for column of string type, it returns an empty\n+      map; for column of numeric type, it returns endpoints of equi-height histogram - approximate\n+      percentiles at percentages 0.0, 1/numBins, 2/numBins, ..., (numBins-1)/numBins, 1.0. The\n+      `accuracy` parameter (default: 10000) is a positive integer literal which controls percentiles\n+      approximation accuracy at the cost of memory. Higher value of `accuracy` yields better\n+      accuracy, `1.0/accuracy` is the relative error of the approximation.\n+    \"\"\")\n+case class HistogramEndpoints(\n+    child: Expression,\n+    numBinsExpression: Expression,\n+    accuracyExpression: Expression,\n+    override val mutableAggBufferOffset: Int,\n+    override val inputAggBufferOffset: Int) extends TypedImperativeAggregate[EndpointsDigest] {\n+\n+  def this(child: Expression, numBinsExpression: Expression, accuracyExpression: Expression) = {\n+    this(child, numBinsExpression, accuracyExpression, 0, 0)\n+  }\n+\n+  def this(child: Expression, numBinsExpression: Expression) = {\n+    this(child, numBinsExpression, Literal(ApproximatePercentile.DEFAULT_PERCENTILE_ACCURACY))\n+  }\n+\n+  // Mark as lazy so that numBinsExpression is not evaluated during tree transformation.\n+  private lazy val numBins: Int = numBinsExpression.eval().asInstanceOf[Int]\n+\n+  private lazy val percentages: Array[Double] = {\n+    val array = new Array[Double](numBins + 1)\n+    for (i <- 0 to numBins) {\n+      array(i) = i / numBins.toDouble\n+    }\n+    array\n+  }\n+\n+  private lazy val accuracy: Int = accuracyExpression.eval().asInstanceOf[Int]\n+\n+  override def inputTypes: Seq[AbstractDataType] = {\n+    Seq(TypeCollection(NumericType, TimestampType, DateType, StringType), IntegerType, IntegerType)\n+  }\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    val defaultCheck = super.checkInputDataTypes()\n+    if (defaultCheck.isFailure) {\n+      defaultCheck\n+    } else if (!numBinsExpression.foldable || !accuracyExpression.foldable) {\n+      TypeCheckFailure(\"The maximum number of bins or accuracy provided must be a constant literal\")\n+    } else if (numBins < 2) {\n+      TypeCheckFailure(\n+        \"The maximum number of bins provided must be a positive integer literal >= 2 \" +\n+          s\"(current value = $numBins)\")\n+    } else if (accuracy <= 0) {\n+      TypeCheckFailure(\n+        s\"The accuracy provided must be a positive integer literal (current value = $accuracy)\")\n+    } else {\n+      TypeCheckSuccess\n+    }\n+  }\n+\n+  override def update(buffer: EndpointsDigest, input: InternalRow): Unit = {\n+    if (buffer.invalid) {\n+      return\n+    }\n+    val evaluated = child.eval(input)\n+    if (evaluated != null) {\n+      buffer.update(child.dataType, evaluated, numBins)\n+    }\n+  }\n+\n+  override def merge(buffer: EndpointsDigest, other: EndpointsDigest): Unit = {\n+    if (buffer.invalid) return\n+    if (other.invalid) {\n+      buffer.invalid = true\n+      buffer.clear()\n+      return\n+    }\n+    buffer.merge(other, numBins)\n+  }\n+\n+  override def eval(buffer: EndpointsDigest): Any = {\n+    if (buffer.invalid) {\n+      // return empty map\n+      ArrayBasedMapData(Map.empty)\n+    } else {\n+      buffer match {\n+        case stringDigest: StringEndpointsDigest =>\n+          // sort the result to make it more readable\n+          val sorted = TreeMap[UTF8String, Long](stringDigest.bins.toSeq: _*)\n+          ArrayBasedMapData(sorted.keys.toArray, sorted.values.toArray)\n+        case numericDigest: NumericEndpointsDigest =>\n+          if (!numericDigest.mapInvalid) {\n+            val sorted = TreeMap[Double, Long](numericDigest.bins.toSeq: _*)\n+            ArrayBasedMapData(sorted.keys.toArray, sorted.values.toArray)\n+          } else {\n+            val percentiles = numericDigest.percentileDigest.getPercentiles(percentages)\n+            // we only need percentiles, this is for constructing MapData\n+            val padding = new Array[Long](percentiles.length)\n+            ArrayBasedMapData(percentiles, padding)\n+          }\n+      }\n+    }\n+  }\n+\n+  override def serialize(buffer: EndpointsDigest): Array[Byte] = {\n+    buffer match {\n+      case stringDigest: StringEndpointsDigest => StringEndpointsDigest.serialize(stringDigest)\n+      case numericDigest: NumericEndpointsDigest => NumericEndpointsDigest.serialize(numericDigest)\n+    }\n+  }\n+\n+  override def deserialize(bytes: Array[Byte]): EndpointsDigest = {\n+    child.dataType match {\n+      case StringType => StringEndpointsDigest.deserialize(bytes)\n+      case _ => NumericEndpointsDigest.deserialize(bytes)\n+    }\n+  }\n+\n+  override def createAggregationBuffer(): EndpointsDigest = {\n+    child.dataType match {\n+      case StringType =>\n+        StringEndpointsDigest()\n+      case _ =>\n+        NumericEndpointsDigest(new PercentileDigest(1.0D / accuracy))\n+    }\n+  }\n+\n+  override def withNewMutableAggBufferOffset(newMutableAggBufferOffset: Int): HistogramEndpoints = {\n+    copy(mutableAggBufferOffset = newMutableAggBufferOffset)\n+  }\n+\n+  override def withNewInputAggBufferOffset(newInputAggBufferOffset: Int): HistogramEndpoints = {\n+    copy(inputAggBufferOffset = newInputAggBufferOffset)\n+  }\n+\n+  override def nullable: Boolean = false\n+\n+  override def dataType: DataType = {\n+    child.dataType match {\n+      case StringType => MapType(StringType, LongType)\n+      case _ => MapType(DoubleType, LongType)\n+    }\n+  }\n+\n+  override def children: Seq[Expression] = Seq(child, numBinsExpression, accuracyExpression)\n+\n+  override def prettyName: String = \"histogram_endpoints\"\n+}\n+\n+trait EndpointsDigest {\n+\n+  // Mark this EndpointsDigest as invalid when:\n+  // 1. for string type - the size of the hashmap (ndv of the column) exceeds numBins;\n+  // 2. for numeric type - Some Decimal value out of the range of Double occurs.\n+  var invalid: Boolean = false\n+\n+  def update(dataType: DataType, value: Any, numBins: Int): Unit\n+  def merge(otherDigest: EndpointsDigest, numBins: Int): Unit\n+  def clear(): Unit\n+\n+  // Updates baseMap, and returns success or not.\n+  def updateMap[T](baseMap: mutable.HashMap[T, Long], value: T, numBins: Int): Boolean = {\n+    if (baseMap.contains(value)) {\n+      baseMap.update(value, baseMap(value) + 1)\n+    } else {\n+      if (baseMap.size >= numBins) {\n+        return false\n+      } else {\n+        baseMap.put(value, 1)\n+      }\n+    }\n+    true\n+  }\n+\n+  // Merges two Maps into baseMap, and returns success or not.\n+  def mergeMaps[T](\n+      baseMap: mutable.HashMap[T, Long],\n+      otherMap: mutable.HashMap[T, Long],\n+      numBins: Int): Boolean = {\n+    otherMap.foreach { case (key, value) =>\n+      if (baseMap.contains(key)) {\n+        baseMap.update(key, baseMap(key) + value)\n+      } else {\n+        if (baseMap.size >= numBins) {\n+          return false\n+        } else {\n+          baseMap.put(key, value)\n+        }\n+      }\n+    }\n+    true\n+  }\n+}\n+\n+/**\n+ * Digest class for column of string type.\n+ * @param bins A HashMap to maintain frequency of each distinct value.\n+ */\n+case class StringEndpointsDigest(\n+    bins: mutable.HashMap[UTF8String, Long] = mutable.HashMap.empty[UTF8String, Long])\n+  extends EndpointsDigest {\n+\n+  def this(bins: mutable.HashMap[UTF8String, Long], invalid: Boolean) = {\n+    this(bins)\n+    this.invalid = invalid\n+  }\n+\n+  override def update(dataType: DataType, value: Any, numBins: Int): Unit = {\n+    val success = updateMap(baseMap = bins, value.asInstanceOf[UTF8String], numBins)\n+    if (!success) {\n+      // clear the map and mark this digest as invalid\n+      bins.clear()\n+      invalid = true\n+    }\n+  }\n+\n+  override def merge(otherDigest: EndpointsDigest, numBins: Int): Unit = {\n+    val other = otherDigest.asInstanceOf[StringEndpointsDigest]\n+    val success = mergeMaps(baseMap = bins, otherMap = other.bins, numBins)\n+    if (!success) {\n+      // clear the map and mark this digest as invalid\n+      bins.clear()\n+      invalid = true\n+    }\n+  }\n+\n+  override def clear(): Unit = {\n+    bins.clear()\n+  }\n+}\n+\n+object StringEndpointsDigest {\n+\n+  private final def length(obj: StringEndpointsDigest): Int = {\n+    // invalid, size of bins\n+    var len: Int = Ints.BYTES + Ints.BYTES\n+    obj.bins.foreach { case (key, value) =>\n+      // length of key, key, value\n+      len += Ints.BYTES + key.getBytes.length + Longs.BYTES\n+    }\n+    len\n+  }\n+\n+  final def serialize(obj: StringEndpointsDigest): Array[Byte] = {\n+    val buffer = ByteBuffer.wrap(new Array(length(obj)))\n+    buffer.putInt(if (obj.invalid) 0 else 1)\n+    buffer.putInt(obj.bins.size)\n+    obj.bins.foreach { case (key, value) =>\n+      val bytes = key.getBytes\n+      buffer.putInt(bytes.length)\n+      buffer.put(bytes)\n+      buffer.putLong(value)\n+    }\n+    buffer.array()\n+  }\n+\n+  final def deserialize(bytes: Array[Byte]): StringEndpointsDigest = {\n+    val buffer = ByteBuffer.wrap(bytes)\n+    val invalid = if (buffer.getInt == 0) true else false\n+    val size = buffer.getInt\n+    val bins = new mutable.HashMap[UTF8String, Long]\n+    var i = 0\n+    while (i < size) {\n+      val keyLength = buffer.getInt\n+      var j = 0\n+      val keyBytes = new Array[Byte](keyLength)\n+      while (j < keyLength) {\n+        keyBytes(j) = buffer.get()\n+        j += 1\n+      }\n+      val value = buffer.getLong\n+      bins.put(UTF8String.fromBytes(keyBytes), value)\n+      i += 1\n+    }\n+    new StringEndpointsDigest(bins, invalid)\n+  }\n+}\n+\n+/**\n+ * Digest class for column of numeric type.\n+ * @param bins A HashMap to maintain frequency of each distinct value.\n+ * @param percentileDigest A helper class to compute approximate percentiles.\n+ */\n+case class NumericEndpointsDigest(\n+    percentileDigest: PercentileDigest,\n+    bins: mutable.HashMap[Double, Long] = mutable.HashMap.empty[Double, Long])\n+  extends EndpointsDigest {\n+\n+  var mapInvalid = false\n+\n+  def this(\n+      percentileDigest: PercentileDigest,\n+      bins: mutable.HashMap[Double, Long],\n+      invalid: Boolean,\n+      mapInvalid: Boolean) = {\n+    this(percentileDigest, bins)\n+    this.invalid = invalid\n+    this.mapInvalid = mapInvalid\n+  }\n+\n+  override def update(dataType: DataType, value: Any, numBins: Int): Unit = {\n+    if (dataType.isInstanceOf[DecimalType]) {\n+      val decimal = value.asInstanceOf[Decimal]\n+      val double = decimal.toDouble\n+      if (double == Double.PositiveInfinity || double == Double.NegativeInfinity) {\n+        // This value has too great a magnitude to represent as a Double.\n+        invalid = true\n+        clear()\n+        return\n+      }\n+    }\n+\n+    // We use Double to represent endpoints (in histograms) for simplicity.\n+    // Loss of precision is acceptable because we are computing approximate answers anyway.\n+    val doubleValue = dataType match {\n+      case n: NumericType =>\n+        n.numeric.toDouble(value.asInstanceOf[n.InternalType])\n+      case d: DateType =>\n+        value.asInstanceOf[Int].toDouble\n+      case t: TimestampType =>\n+        value.asInstanceOf[Long].toDouble\n+    }\n+    // update percentileDigest\n+    percentileDigest.add(doubleValue)"
  }],
  "prId": 15637
}]