[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "it's really weird to see a `var` in the constructor of case class, how about\n\n```\ncase class xxx {\n  var invalide = false\n}\n```\n",
    "commit": "a843920983914de7efd21608b8f0e39c70b210d7",
    "createdAt": "2016-10-14T07:07:16Z",
    "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import java.nio.ByteBuffer\n+\n+import scala.collection.immutable.TreeMap\n+import scala.collection.mutable\n+\n+import com.google.common.primitives.{Ints, Longs}\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.StringHistogram.StringHistogramInfo\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+\n+/**\n+ * The StringHistogram function returns the histogram bins - (distinct value, frequency) pairs\n+ * for a string column.\n+ * @param child child expression that can produce column value with `child.eval(inputRow)`\n+ * @param numBinsExpression The maximum number of bins. When the number of distinct values is\n+ *                          larger than this, the function will return an empty result.\n+ */\n+@ExpressionDescription(\n+  usage = \"_FUNC_(col, numBins) - Returns histogram bins with the maximum number of bins allowed.\")\n+case class StringHistogram(\n+    child: Expression,\n+    numBinsExpression: Expression,\n+    override val mutableAggBufferOffset: Int,\n+    override val inputAggBufferOffset: Int) extends TypedImperativeAggregate[StringHistogramInfo] {\n+\n+  def this(child: Expression, numBinsExpression: Expression) = {\n+    this(child, numBinsExpression, 0, 0)\n+  }\n+\n+  // Mark as lazy so that numBinsExpression is not evaluated during tree transformation.\n+  private lazy val numBins: Int = numBinsExpression.eval().asInstanceOf[Int]\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    val defaultCheck = super.checkInputDataTypes()\n+    if (defaultCheck.isFailure) {\n+      defaultCheck\n+    } else if (!numBinsExpression.foldable) {\n+      TypeCheckFailure(s\"The maximum number of bins provided must be a constant literal\")\n+    } else if (numBins <= 0) {\n+      TypeCheckFailure(\n+        s\"The maximum number of bins provided must be a positive integer literal (current value\" +\n+          s\" = $numBins)\")\n+    } else {\n+      TypeCheckSuccess\n+    }\n+  }\n+\n+  override def update(buffer: StringHistogramInfo, input: InternalRow): Unit = {\n+    if (buffer.invalid) {\n+      return\n+    }\n+    val evaluated = child.eval(input)\n+    if (evaluated != null) {\n+      val str = evaluated.asInstanceOf[UTF8String]\n+      if (buffer.bins.contains(str)) {\n+        buffer.bins.update(str, buffer.bins(str) + 1)\n+      } else {\n+        if (buffer.bins.size >= numBins) {\n+          // clear the buffer and mark it as invalid\n+          buffer.bins.clear()\n+          buffer.invalid = true\n+        } else {\n+          buffer.bins.put(str, 1)\n+        }\n+      }\n+    }\n+  }\n+\n+  override def merge(buffer: StringHistogramInfo, other: StringHistogramInfo): Unit = {\n+    if (buffer.invalid || other.invalid) {\n+      buffer.bins.clear()\n+      return\n+    }\n+    other.bins.foreach { case (key, value) =>\n+      if (buffer.bins.contains(key)) {\n+        buffer.bins.update(key, buffer.bins(key) + value)\n+      } else {\n+        if (buffer.bins.size >= numBins) {\n+          // clear the buffer and mark it as invalid\n+          buffer.bins.clear()\n+          buffer.invalid = true\n+          return\n+        } else {\n+          buffer.bins.put(key, value)\n+        }\n+      }\n+    }\n+  }\n+\n+  override def eval(buffer: StringHistogramInfo): Any = {\n+    val sorted = TreeMap[UTF8String, Long](buffer.bins.toSeq: _*)\n+    ArrayBasedMapData(sorted.keys.toArray, sorted.values.toArray)\n+  }\n+\n+  override def serialize(buffer: StringHistogramInfo): Array[Byte] = {\n+    StringHistogram.serializer.serialize(buffer)\n+  }\n+\n+  override def deserialize(storageFormat: Array[Byte]): StringHistogramInfo = {\n+    StringHistogram.serializer.deserialize(storageFormat)\n+  }\n+\n+  override def createAggregationBuffer(): StringHistogramInfo = new StringHistogramInfo()\n+\n+  override def withNewMutableAggBufferOffset(newMutableAggBufferOffset: Int): StringHistogram = {\n+    copy(mutableAggBufferOffset = newMutableAggBufferOffset)\n+  }\n+\n+  override def withNewInputAggBufferOffset(newInputAggBufferOffset: Int): StringHistogram = {\n+    copy(inputAggBufferOffset = newInputAggBufferOffset)\n+  }\n+\n+  override def inputTypes: Seq[AbstractDataType] = Seq(StringType, IntegerType)\n+\n+  override def nullable: Boolean = false\n+\n+  override def dataType: DataType = MapType(StringType, LongType)\n+\n+  override def children: Seq[Expression] = Seq(child, numBinsExpression)\n+\n+  override def prettyName: String = \"string_histogram\"\n+}\n+\n+object StringHistogram {\n+\n+  /**\n+   * StringHistogramInfo maintains frequency of each distinct value.\n+   * @param invalid This is to mark the HashMap as invalid when its size (ndv of the column)\n+   *                exceeds numBins, because we won't generate string histograms in that case.\n+   * @param bins A HashMap to maintain frequency of each distinct value.\n+   */\n+  case class StringHistogramInfo(\n+      var invalid: Boolean = false,",
    "line": 158
  }],
  "prId": 15443
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "why sort it?\n",
    "commit": "a843920983914de7efd21608b8f0e39c70b210d7",
    "createdAt": "2016-10-14T07:10:33Z",
    "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import java.nio.ByteBuffer\n+\n+import scala.collection.immutable.TreeMap\n+import scala.collection.mutable\n+\n+import com.google.common.primitives.{Ints, Longs}\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.StringHistogram.StringHistogramInfo\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+\n+/**\n+ * The StringHistogram function returns the histogram bins - (distinct value, frequency) pairs\n+ * for a string column.\n+ * @param child child expression that can produce column value with `child.eval(inputRow)`\n+ * @param numBinsExpression The maximum number of bins. When the number of distinct values is\n+ *                          larger than this, the function will return an empty result.\n+ */\n+@ExpressionDescription(\n+  usage = \"_FUNC_(col, numBins) - Returns histogram bins with the maximum number of bins allowed.\")\n+case class StringHistogram(\n+    child: Expression,\n+    numBinsExpression: Expression,\n+    override val mutableAggBufferOffset: Int,\n+    override val inputAggBufferOffset: Int) extends TypedImperativeAggregate[StringHistogramInfo] {\n+\n+  def this(child: Expression, numBinsExpression: Expression) = {\n+    this(child, numBinsExpression, 0, 0)\n+  }\n+\n+  // Mark as lazy so that numBinsExpression is not evaluated during tree transformation.\n+  private lazy val numBins: Int = numBinsExpression.eval().asInstanceOf[Int]\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    val defaultCheck = super.checkInputDataTypes()\n+    if (defaultCheck.isFailure) {\n+      defaultCheck\n+    } else if (!numBinsExpression.foldable) {\n+      TypeCheckFailure(s\"The maximum number of bins provided must be a constant literal\")\n+    } else if (numBins <= 0) {\n+      TypeCheckFailure(\n+        s\"The maximum number of bins provided must be a positive integer literal (current value\" +\n+          s\" = $numBins)\")\n+    } else {\n+      TypeCheckSuccess\n+    }\n+  }\n+\n+  override def update(buffer: StringHistogramInfo, input: InternalRow): Unit = {\n+    if (buffer.invalid) {\n+      return\n+    }\n+    val evaluated = child.eval(input)\n+    if (evaluated != null) {\n+      val str = evaluated.asInstanceOf[UTF8String]\n+      if (buffer.bins.contains(str)) {\n+        buffer.bins.update(str, buffer.bins(str) + 1)\n+      } else {\n+        if (buffer.bins.size >= numBins) {\n+          // clear the buffer and mark it as invalid\n+          buffer.bins.clear()\n+          buffer.invalid = true\n+        } else {\n+          buffer.bins.put(str, 1)\n+        }\n+      }\n+    }\n+  }\n+\n+  override def merge(buffer: StringHistogramInfo, other: StringHistogramInfo): Unit = {\n+    if (buffer.invalid || other.invalid) {\n+      buffer.bins.clear()\n+      return\n+    }\n+    other.bins.foreach { case (key, value) =>\n+      if (buffer.bins.contains(key)) {\n+        buffer.bins.update(key, buffer.bins(key) + value)\n+      } else {\n+        if (buffer.bins.size >= numBins) {\n+          // clear the buffer and mark it as invalid\n+          buffer.bins.clear()\n+          buffer.invalid = true\n+          return\n+        } else {\n+          buffer.bins.put(key, value)\n+        }\n+      }\n+    }\n+  }\n+\n+  override def eval(buffer: StringHistogramInfo): Any = {\n+    val sorted = TreeMap[UTF8String, Long](buffer.bins.toSeq: _*)",
    "line": 116
  }, {
    "author": {
      "login": "wzhfy"
    },
    "body": "It's more readable when we support `desc formatted columns` syntax, and in debugging.\nNo strong opinion on this though.\n",
    "commit": "a843920983914de7efd21608b8f0e39c70b210d7",
    "createdAt": "2016-10-14T07:36:04Z",
    "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import java.nio.ByteBuffer\n+\n+import scala.collection.immutable.TreeMap\n+import scala.collection.mutable\n+\n+import com.google.common.primitives.{Ints, Longs}\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.StringHistogram.StringHistogramInfo\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+\n+/**\n+ * The StringHistogram function returns the histogram bins - (distinct value, frequency) pairs\n+ * for a string column.\n+ * @param child child expression that can produce column value with `child.eval(inputRow)`\n+ * @param numBinsExpression The maximum number of bins. When the number of distinct values is\n+ *                          larger than this, the function will return an empty result.\n+ */\n+@ExpressionDescription(\n+  usage = \"_FUNC_(col, numBins) - Returns histogram bins with the maximum number of bins allowed.\")\n+case class StringHistogram(\n+    child: Expression,\n+    numBinsExpression: Expression,\n+    override val mutableAggBufferOffset: Int,\n+    override val inputAggBufferOffset: Int) extends TypedImperativeAggregate[StringHistogramInfo] {\n+\n+  def this(child: Expression, numBinsExpression: Expression) = {\n+    this(child, numBinsExpression, 0, 0)\n+  }\n+\n+  // Mark as lazy so that numBinsExpression is not evaluated during tree transformation.\n+  private lazy val numBins: Int = numBinsExpression.eval().asInstanceOf[Int]\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    val defaultCheck = super.checkInputDataTypes()\n+    if (defaultCheck.isFailure) {\n+      defaultCheck\n+    } else if (!numBinsExpression.foldable) {\n+      TypeCheckFailure(s\"The maximum number of bins provided must be a constant literal\")\n+    } else if (numBins <= 0) {\n+      TypeCheckFailure(\n+        s\"The maximum number of bins provided must be a positive integer literal (current value\" +\n+          s\" = $numBins)\")\n+    } else {\n+      TypeCheckSuccess\n+    }\n+  }\n+\n+  override def update(buffer: StringHistogramInfo, input: InternalRow): Unit = {\n+    if (buffer.invalid) {\n+      return\n+    }\n+    val evaluated = child.eval(input)\n+    if (evaluated != null) {\n+      val str = evaluated.asInstanceOf[UTF8String]\n+      if (buffer.bins.contains(str)) {\n+        buffer.bins.update(str, buffer.bins(str) + 1)\n+      } else {\n+        if (buffer.bins.size >= numBins) {\n+          // clear the buffer and mark it as invalid\n+          buffer.bins.clear()\n+          buffer.invalid = true\n+        } else {\n+          buffer.bins.put(str, 1)\n+        }\n+      }\n+    }\n+  }\n+\n+  override def merge(buffer: StringHistogramInfo, other: StringHistogramInfo): Unit = {\n+    if (buffer.invalid || other.invalid) {\n+      buffer.bins.clear()\n+      return\n+    }\n+    other.bins.foreach { case (key, value) =>\n+      if (buffer.bins.contains(key)) {\n+        buffer.bins.update(key, buffer.bins(key) + value)\n+      } else {\n+        if (buffer.bins.size >= numBins) {\n+          // clear the buffer and mark it as invalid\n+          buffer.bins.clear()\n+          buffer.invalid = true\n+          return\n+        } else {\n+          buffer.bins.put(key, value)\n+        }\n+      }\n+    }\n+  }\n+\n+  override def eval(buffer: StringHistogramInfo): Any = {\n+    val sorted = TreeMap[UTF8String, Long](buffer.bins.toSeq: _*)",
    "line": 116
  }],
  "prId": 15443
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "are we going to create similar aggregate functions for other data types?\n",
    "commit": "a843920983914de7efd21608b8f0e39c70b210d7",
    "createdAt": "2016-10-14T07:12:25Z",
    "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import java.nio.ByteBuffer\n+\n+import scala.collection.immutable.TreeMap\n+import scala.collection.mutable\n+\n+import com.google.common.primitives.{Ints, Longs}\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.StringHistogram.StringHistogramInfo\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+\n+/**\n+ * The StringHistogram function returns the histogram bins - (distinct value, frequency) pairs\n+ * for a string column.\n+ * @param child child expression that can produce column value with `child.eval(inputRow)`\n+ * @param numBinsExpression The maximum number of bins. When the number of distinct values is\n+ *                          larger than this, the function will return an empty result.\n+ */\n+@ExpressionDescription(\n+  usage = \"_FUNC_(col, numBins) - Returns histogram bins with the maximum number of bins allowed.\")\n+case class StringHistogram(",
    "line": 45
  }, {
    "author": {
      "login": "wzhfy"
    },
    "body": "We will support histogram for numeric types, but the logics in that agg function will be very different from this. You can refer to discussion on the [jira](https://issues.apache.org/jira/browse/SPARK-17074).\n",
    "commit": "a843920983914de7efd21608b8f0e39c70b210d7",
    "createdAt": "2016-10-14T07:39:44Z",
    "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import java.nio.ByteBuffer\n+\n+import scala.collection.immutable.TreeMap\n+import scala.collection.mutable\n+\n+import com.google.common.primitives.{Ints, Longs}\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.StringHistogram.StringHistogramInfo\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+\n+/**\n+ * The StringHistogram function returns the histogram bins - (distinct value, frequency) pairs\n+ * for a string column.\n+ * @param child child expression that can produce column value with `child.eval(inputRow)`\n+ * @param numBinsExpression The maximum number of bins. When the number of distinct values is\n+ *                          larger than this, the function will return an empty result.\n+ */\n+@ExpressionDescription(\n+  usage = \"_FUNC_(col, numBins) - Returns histogram bins with the maximum number of bins allowed.\")\n+case class StringHistogram(",
    "line": 45
  }],
  "prId": 15443
}, {
  "comments": [{
    "author": {
      "login": "wzhfy"
    },
    "body": "remove \"s\"\n",
    "commit": "a843920983914de7efd21608b8f0e39c70b210d7",
    "createdAt": "2016-10-14T11:37:35Z",
    "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import java.nio.ByteBuffer\n+\n+import scala.collection.immutable.TreeMap\n+import scala.collection.mutable\n+\n+import com.google.common.primitives.{Ints, Longs}\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.{TypeCheckFailure, TypeCheckSuccess}\n+import org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionDescription}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.StringHistogram.StringHistogramInfo\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData\n+import org.apache.spark.sql.types._\n+import org.apache.spark.unsafe.types.UTF8String\n+\n+/**\n+ * The StringHistogram function returns the histogram bins - (distinct value, frequency) pairs\n+ * for a string column.\n+ * @param child child expression that can produce column value with `child.eval(inputRow)`\n+ * @param numBinsExpression The maximum number of bins. When the number of distinct values is\n+ *                          larger than this, the function will return an empty result.\n+ */\n+@ExpressionDescription(\n+  usage = \"_FUNC_(col, numBins) - Returns histogram bins with the maximum number of bins allowed.\")\n+case class StringHistogram(\n+    child: Expression,\n+    numBinsExpression: Expression,\n+    override val mutableAggBufferOffset: Int,\n+    override val inputAggBufferOffset: Int) extends TypedImperativeAggregate[StringHistogramInfo] {\n+\n+  def this(child: Expression, numBinsExpression: Expression) = {\n+    this(child, numBinsExpression, 0, 0)\n+  }\n+\n+  // Mark as lazy so that numBinsExpression is not evaluated during tree transformation.\n+  private lazy val numBins: Int = numBinsExpression.eval().asInstanceOf[Int]\n+\n+  override def checkInputDataTypes(): TypeCheckResult = {\n+    val defaultCheck = super.checkInputDataTypes()\n+    if (defaultCheck.isFailure) {\n+      defaultCheck\n+    } else if (!numBinsExpression.foldable) {\n+      TypeCheckFailure(s\"The maximum number of bins provided must be a constant literal\")",
    "line": 63
  }],
  "prId": 15443
}]