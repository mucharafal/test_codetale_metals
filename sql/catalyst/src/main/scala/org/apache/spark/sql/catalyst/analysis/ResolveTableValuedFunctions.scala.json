[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "+1 for doing this in a separate file\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-15T23:33:26Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {",
    "line": 30
  }],
  "prId": 14656
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Can't we reuse the code in the FunctionRegistry for this? This is not to hard to isolate if I remember correctly: https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/FunctionRegistry.scala#L438-L470\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-15T23:40:30Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, Class[_])*) {\n+    /**\n+     * @return whether this list is assignable from the given sequence of values.\n+     */\n+    def assignableFrom(values: Seq[Any]): Boolean = {\n+      if (args.length == values.length) {\n+        args.zip(values).forall { case ((name, clazz), value) =>\n+          clazz.isAssignableFrom(value.getClass)\n+        }\n+      } else {\n+        false\n+      }\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.getSimpleName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * Internal registry of table-valued functions. TODO(ekl) we should have a proper registry\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map("
  }, {
    "author": {
      "login": "ericl"
    },
    "body": "Hmm, it is harder to produce a nice error message if the constructor is inferred. Though it does make it easier to register functions.\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-16T00:32:22Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, Class[_])*) {\n+    /**\n+     * @return whether this list is assignable from the given sequence of values.\n+     */\n+    def assignableFrom(values: Seq[Any]): Boolean = {\n+      if (args.length == values.length) {\n+        args.zip(values).forall { case ((name, clazz), value) =>\n+          clazz.isAssignableFrom(value.getClass)\n+        }\n+      } else {\n+        false\n+      }\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.getSimpleName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * Internal registry of table-valued functions. TODO(ekl) we should have a proper registry\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map("
  }, {
    "author": {
      "login": "ericl"
    },
    "body": "Going to at least change the types here to specify catalyst datatypes instead of java classes. That way the coercion behavior will be more clear.\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-16T02:29:54Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, Class[_])*) {\n+    /**\n+     * @return whether this list is assignable from the given sequence of values.\n+     */\n+    def assignableFrom(values: Seq[Any]): Boolean = {\n+      if (args.length == values.length) {\n+        args.zip(values).forall { case ((name, clazz), value) =>\n+          clazz.isAssignableFrom(value.getClass)\n+        }\n+      } else {\n+        false\n+      }\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.getSimpleName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * Internal registry of table-valued functions. TODO(ekl) we should have a proper registry\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map("
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "So I think the catalyst way to do this is that the resolution rule only works if all the children of the expression is resolved, and then you have a checkanalysis rule that shows the error if there is an UnresolvedTableValuedFunction\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-16T06:42:52Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, Class[_])*) {\n+    /**\n+     * @return whether this list is assignable from the given sequence of values.\n+     */\n+    def assignableFrom(values: Seq[Any]): Boolean = {\n+      if (args.length == values.length) {\n+        args.zip(values).forall { case ((name, clazz), value) =>\n+          clazz.isAssignableFrom(value.getClass)\n+        }\n+      } else {\n+        false\n+      }\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.getSimpleName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * Internal registry of table-valued functions. TODO(ekl) we should have a proper registry\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map("
  }, {
    "author": {
      "login": "ericl"
    },
    "body": "Made that change.\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-16T20:37:10Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, Class[_])*) {\n+    /**\n+     * @return whether this list is assignable from the given sequence of values.\n+     */\n+    def assignableFrom(values: Seq[Any]): Boolean = {\n+      if (args.length == values.length) {\n+        args.zip(values).forall { case ((name, clazz), value) =>\n+          clazz.isAssignableFrom(value.getClass)\n+        }\n+      } else {\n+        false\n+      }\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.getSimpleName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * Internal registry of table-valued functions. TODO(ekl) we should have a proper registry\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map("
  }],
  "prId": 14656
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "We could make this a bit more concise by using a combination of a builder and partial function. For example:\n\n``` scala\n// Builder\ndef tvf(params: (String, DataType)*)(pf: PartialFunction[Seq[Expression], LogicalPlan]): TVF = (ArgumentList(params: _*), pf)\n\n// Use\nprivate val builtinFunctions: Map[String, TVF] = Map(\n  \"range\" -> Map(\n    /* range(end) */\n    tvf(\"end\" -> LongType) { case Seq(end: Long) =>\n      Range(0, end, 1, defaultParallelism)\n    },\n    /* range(start, end) */\n    tvf(\"start\" -> LongType, \"end\" -> LongType) { case Seq(start: Long, end: Long) =>\n      Range(start, end, 1, defaultParallelism)\n    }\n    /* ... */)\n```\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-16T22:21:03Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+import org.apache.spark.sql.types.{DataType, IntegerType, LongType}\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, DataType)*) {\n+    /**\n+     * Try to cast the expressions to satisfy the expected types of this argument list. If there\n+     * are any types that cannot be casted, then None is returned.\n+     */\n+    def implicitCast(values: Seq[Expression]): Option[Seq[Expression]] = {\n+      if (args.length == values.length) {\n+        val casted = values.zip(args).map { case (value, (_, expectedType)) =>\n+          TypeCoercion.ImplicitTypeCasts.implicitCast(value, expectedType)\n+        }\n+        if (casted.forall(_.isDefined)) {\n+          return Some(casted.map(_.get))\n+        }\n+      }\n+      None\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.typeName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * Internal registry of table-valued functions. TODO(ekl) we should have a proper registry\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map(\n+    \"range\" -> Map(\n+      /* range(end) */"
  }, {
    "author": {
      "login": "ericl"
    },
    "body": "That seems nice. Updated.\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-16T23:00:29Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+import org.apache.spark.sql.types.{DataType, IntegerType, LongType}\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, DataType)*) {\n+    /**\n+     * Try to cast the expressions to satisfy the expected types of this argument list. If there\n+     * are any types that cannot be casted, then None is returned.\n+     */\n+    def implicitCast(values: Seq[Expression]): Option[Seq[Expression]] = {\n+      if (args.length == values.length) {\n+        val casted = values.zip(args).map { case (value, (_, expectedType)) =>\n+          TypeCoercion.ImplicitTypeCasts.implicitCast(value, expectedType)\n+        }\n+        if (casted.forall(_.isDefined)) {\n+          return Some(casted.map(_.get))\n+        }\n+      }\n+      None\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.typeName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * Internal registry of table-valued functions. TODO(ekl) we should have a proper registry\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map(\n+    \"range\" -> Map(\n+      /* range(end) */"
  }],
  "prId": 14656
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Smallish: Do you think we can avoid a non-local return?\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-17T22:54:10Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+import org.apache.spark.sql.types.{DataType, IntegerType, LongType}\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, DataType)*) {\n+    /**\n+     * Try to cast the expressions to satisfy the expected types of this argument list. If there\n+     * are any types that cannot be casted, then None is returned.\n+     */\n+    def implicitCast(values: Seq[Expression]): Option[Seq[Expression]] = {\n+      if (args.length == values.length) {\n+        val casted = values.zip(args).map { case (value, (_, expectedType)) =>\n+          TypeCoercion.ImplicitTypeCasts.implicitCast(value, expectedType)\n+        }\n+        if (casted.forall(_.isDefined)) {\n+          return Some(casted.map(_.get))\n+        }\n+      }\n+      None\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.typeName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * TVF builder.\n+   */\n+  private def tvf(args: (String, DataType)*)(pf: PartialFunction[Seq[Any], LogicalPlan])\n+    : (ArgumentList, Seq[Any] => LogicalPlan) = (ArgumentList(args: _*), pf)\n+\n+  /**\n+   * Internal registry of table-valued functions.\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map(\n+    \"range\" -> Map(\n+      /* range(end) */\n+      tvf(\"end\" -> LongType) { case Seq(end: Long) =>\n+        Range(0, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType) { case Seq(start: Long, end: Long) =>\n+        Range(start, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end, step) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType, \"step\" -> LongType) {\n+          case Seq(start: Long, end: Long, step: Long) =>\n+        Range(start, end, step, defaultParallelism)\n+      },\n+\n+      /* range(start, end, step, numPartitions) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType, \"step\" -> LongType,\n+          \"numPartitions\" -> IntegerType) {\n+          case Seq(start: Long, end: Long, step: Long, numPartitions: Int) =>\n+        Range(start, end, step, numPartitions)\n+      })\n+  )\n+\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case u: UnresolvedTableValuedFunction if u.functionArgs.forall(_.resolved) =>\n+      builtinFunctions.get(u.functionName) match {\n+        case Some(tvf) =>\n+          for ((argList, resolver) <- tvf) {\n+            val casted = argList.implicitCast(u.functionArgs)\n+            if (casted.isDefined) {\n+              return resolver(casted.get.map(_.eval()))"
  }, {
    "author": {
      "login": "ericl"
    },
    "body": "flatMap it is\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-18T02:24:11Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+import org.apache.spark.sql.types.{DataType, IntegerType, LongType}\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, DataType)*) {\n+    /**\n+     * Try to cast the expressions to satisfy the expected types of this argument list. If there\n+     * are any types that cannot be casted, then None is returned.\n+     */\n+    def implicitCast(values: Seq[Expression]): Option[Seq[Expression]] = {\n+      if (args.length == values.length) {\n+        val casted = values.zip(args).map { case (value, (_, expectedType)) =>\n+          TypeCoercion.ImplicitTypeCasts.implicitCast(value, expectedType)\n+        }\n+        if (casted.forall(_.isDefined)) {\n+          return Some(casted.map(_.get))\n+        }\n+      }\n+      None\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.typeName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * TVF builder.\n+   */\n+  private def tvf(args: (String, DataType)*)(pf: PartialFunction[Seq[Any], LogicalPlan])\n+    : (ArgumentList, Seq[Any] => LogicalPlan) = (ArgumentList(args: _*), pf)\n+\n+  /**\n+   * Internal registry of table-valued functions.\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map(\n+    \"range\" -> Map(\n+      /* range(end) */\n+      tvf(\"end\" -> LongType) { case Seq(end: Long) =>\n+        Range(0, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType) { case Seq(start: Long, end: Long) =>\n+        Range(start, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end, step) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType, \"step\" -> LongType) {\n+          case Seq(start: Long, end: Long, step: Long) =>\n+        Range(start, end, step, defaultParallelism)\n+      },\n+\n+      /* range(start, end, step, numPartitions) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType, \"step\" -> LongType,\n+          \"numPartitions\" -> IntegerType) {\n+          case Seq(start: Long, end: Long, step: Long, numPartitions: Int) =>\n+        Range(start, end, step, numPartitions)\n+      })\n+  )\n+\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan resolveOperators {\n+    case u: UnresolvedTableValuedFunction if u.functionArgs.forall(_.resolved) =>\n+      builtinFunctions.get(u.functionName) match {\n+        case Some(tvf) =>\n+          for ((argList, resolver) <- tvf) {\n+            val casted = argList.implicitCast(u.functionArgs)\n+            if (casted.isDefined) {\n+              return resolver(casted.get.map(_.eval()))"
  }],
  "prId": 14656
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Nit Style: Weird indentation.\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-17T22:58:47Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+import org.apache.spark.sql.types.{DataType, IntegerType, LongType}\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, DataType)*) {\n+    /**\n+     * Try to cast the expressions to satisfy the expected types of this argument list. If there\n+     * are any types that cannot be casted, then None is returned.\n+     */\n+    def implicitCast(values: Seq[Expression]): Option[Seq[Expression]] = {\n+      if (args.length == values.length) {\n+        val casted = values.zip(args).map { case (value, (_, expectedType)) =>\n+          TypeCoercion.ImplicitTypeCasts.implicitCast(value, expectedType)\n+        }\n+        if (casted.forall(_.isDefined)) {\n+          return Some(casted.map(_.get))\n+        }\n+      }\n+      None\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.typeName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * TVF builder.\n+   */\n+  private def tvf(args: (String, DataType)*)(pf: PartialFunction[Seq[Any], LogicalPlan])\n+    : (ArgumentList, Seq[Any] => LogicalPlan) = (ArgumentList(args: _*), pf)\n+\n+  /**\n+   * Internal registry of table-valued functions.\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map(\n+    \"range\" -> Map(\n+      /* range(end) */\n+      tvf(\"end\" -> LongType) { case Seq(end: Long) =>\n+        Range(0, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType) { case Seq(start: Long, end: Long) =>\n+        Range(start, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end, step) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType, \"step\" -> LongType) {\n+          case Seq(start: Long, end: Long, step: Long) =>\n+        Range(start, end, step, defaultParallelism)"
  }, {
    "author": {
      "login": "ericl"
    },
    "body": "Fixed\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-18T02:23:49Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+import org.apache.spark.sql.types.{DataType, IntegerType, LongType}\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, DataType)*) {\n+    /**\n+     * Try to cast the expressions to satisfy the expected types of this argument list. If there\n+     * are any types that cannot be casted, then None is returned.\n+     */\n+    def implicitCast(values: Seq[Expression]): Option[Seq[Expression]] = {\n+      if (args.length == values.length) {\n+        val casted = values.zip(args).map { case (value, (_, expectedType)) =>\n+          TypeCoercion.ImplicitTypeCasts.implicitCast(value, expectedType)\n+        }\n+        if (casted.forall(_.isDefined)) {\n+          return Some(casted.map(_.get))\n+        }\n+      }\n+      None\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.typeName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * TVF builder.\n+   */\n+  private def tvf(args: (String, DataType)*)(pf: PartialFunction[Seq[Any], LogicalPlan])\n+    : (ArgumentList, Seq[Any] => LogicalPlan) = (ArgumentList(args: _*), pf)\n+\n+  /**\n+   * Internal registry of table-valued functions.\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map(\n+    \"range\" -> Map(\n+      /* range(end) */\n+      tvf(\"end\" -> LongType) { case Seq(end: Long) =>\n+        Range(0, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType) { case Seq(start: Long, end: Long) =>\n+        Range(start, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end, step) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType, \"step\" -> LongType) {\n+          case Seq(start: Long, end: Long, step: Long) =>\n+        Range(start, end, step, defaultParallelism)"
  }],
  "prId": 14656
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Nit style: weird indentation\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-17T22:59:11Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+import org.apache.spark.sql.types.{DataType, IntegerType, LongType}\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, DataType)*) {\n+    /**\n+     * Try to cast the expressions to satisfy the expected types of this argument list. If there\n+     * are any types that cannot be casted, then None is returned.\n+     */\n+    def implicitCast(values: Seq[Expression]): Option[Seq[Expression]] = {\n+      if (args.length == values.length) {\n+        val casted = values.zip(args).map { case (value, (_, expectedType)) =>\n+          TypeCoercion.ImplicitTypeCasts.implicitCast(value, expectedType)\n+        }\n+        if (casted.forall(_.isDefined)) {\n+          return Some(casted.map(_.get))\n+        }\n+      }\n+      None\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.typeName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * TVF builder.\n+   */\n+  private def tvf(args: (String, DataType)*)(pf: PartialFunction[Seq[Any], LogicalPlan])\n+    : (ArgumentList, Seq[Any] => LogicalPlan) = (ArgumentList(args: _*), pf)\n+\n+  /**\n+   * Internal registry of table-valued functions.\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map(\n+    \"range\" -> Map(\n+      /* range(end) */\n+      tvf(\"end\" -> LongType) { case Seq(end: Long) =>\n+        Range(0, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType) { case Seq(start: Long, end: Long) =>\n+        Range(start, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end, step) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType, \"step\" -> LongType) {\n+          case Seq(start: Long, end: Long, step: Long) =>\n+        Range(start, end, step, defaultParallelism)\n+      },\n+\n+      /* range(start, end, step, numPartitions) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType, \"step\" -> LongType,\n+          \"numPartitions\" -> IntegerType) {\n+          case Seq(start: Long, end: Long, step: Long, numPartitions: Int) =>\n+        Range(start, end, step, numPartitions)"
  }, {
    "author": {
      "login": "ericl"
    },
    "body": "Fixed\n",
    "commit": "7ebd563fca73ae4a4e05970709f334a4d09b5ff1",
    "createdAt": "2016-08-18T02:24:47Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Range}\n+import org.apache.spark.sql.catalyst.rules._\n+import org.apache.spark.sql.types.{DataType, IntegerType, LongType}\n+\n+/**\n+ * Rule that resolves table-valued function references.\n+ */\n+object ResolveTableValuedFunctions extends Rule[LogicalPlan] {\n+  private lazy val defaultParallelism =\n+    SparkContext.getOrCreate(new SparkConf(false)).defaultParallelism\n+\n+  /**\n+   * List of argument names and their types, used to declare a function.\n+   */\n+  private case class ArgumentList(args: (String, DataType)*) {\n+    /**\n+     * Try to cast the expressions to satisfy the expected types of this argument list. If there\n+     * are any types that cannot be casted, then None is returned.\n+     */\n+    def implicitCast(values: Seq[Expression]): Option[Seq[Expression]] = {\n+      if (args.length == values.length) {\n+        val casted = values.zip(args).map { case (value, (_, expectedType)) =>\n+          TypeCoercion.ImplicitTypeCasts.implicitCast(value, expectedType)\n+        }\n+        if (casted.forall(_.isDefined)) {\n+          return Some(casted.map(_.get))\n+        }\n+      }\n+      None\n+    }\n+\n+    override def toString: String = {\n+      args.map { a =>\n+        s\"${a._1}: ${a._2.typeName}\"\n+      }.mkString(\", \")\n+    }\n+  }\n+\n+  /**\n+   * A TVF maps argument lists to resolver functions that accept those arguments. Using a map\n+   * here allows for function overloading.\n+   */\n+  private type TVF = Map[ArgumentList, Seq[Any] => LogicalPlan]\n+\n+  /**\n+   * TVF builder.\n+   */\n+  private def tvf(args: (String, DataType)*)(pf: PartialFunction[Seq[Any], LogicalPlan])\n+    : (ArgumentList, Seq[Any] => LogicalPlan) = (ArgumentList(args: _*), pf)\n+\n+  /**\n+   * Internal registry of table-valued functions.\n+   */\n+  private val builtinFunctions: Map[String, TVF] = Map(\n+    \"range\" -> Map(\n+      /* range(end) */\n+      tvf(\"end\" -> LongType) { case Seq(end: Long) =>\n+        Range(0, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType) { case Seq(start: Long, end: Long) =>\n+        Range(start, end, 1, defaultParallelism)\n+      },\n+\n+      /* range(start, end, step) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType, \"step\" -> LongType) {\n+          case Seq(start: Long, end: Long, step: Long) =>\n+        Range(start, end, step, defaultParallelism)\n+      },\n+\n+      /* range(start, end, step, numPartitions) */\n+      tvf(\"start\" -> LongType, \"end\" -> LongType, \"step\" -> LongType,\n+          \"numPartitions\" -> IntegerType) {\n+          case Seq(start: Long, end: Long, step: Long, numPartitions: Int) =>\n+        Range(start, end, step, numPartitions)"
  }],
  "prId": 14656
}]