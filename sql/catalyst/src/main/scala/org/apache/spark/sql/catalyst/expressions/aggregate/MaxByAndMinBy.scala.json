[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "since we import the expression DSL, can we use DSL to build the expression tree in this file?",
    "commit": "05f1767dc49e6caebd91abf207014bcd8029b4f1",
    "createdAt": "2019-05-10T13:52:16Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.dsl.expressions._",
    "line": 21
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Some can, like `And`, `IsNull`. Some can't, like `CaseWhen`, `If`.",
    "commit": "05f1767dc49e6caebd91abf207014bcd8029b4f1",
    "createdAt": "2019-05-11T01:48:25Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.dsl.expressions._",
    "line": 21
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "I rewrite `And` and `IsNull` using DSL. ",
    "commit": "05f1767dc49e6caebd91abf207014bcd8029b4f1",
    "createdAt": "2019-05-11T01:55:02Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.dsl.expressions._",
    "line": 21
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "maybe we can add DSL for CaseWhen and If. Not a blocker here.",
    "commit": "05f1767dc49e6caebd91abf207014bcd8029b4f1",
    "createdAt": "2019-05-13T07:03:50Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.dsl.expressions._",
    "line": 21
  }],
  "prId": 24557
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit: `maxOrdering` is more precise.",
    "commit": "05f1767dc49e6caebd91abf207014bcd8029b4f1",
    "createdAt": "2019-05-13T07:05:53Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.util.TypeUtils\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * The shared abstract superclass for `MaxBy` and `MinBy` SQL aggregate functions.\n+ */\n+abstract class MaxMinBy extends DeclarativeAggregate {\n+\n+  def valueExpr: Expression\n+  def orderingExpr: Expression\n+\n+  protected def funcName: String\n+  // The predicate compares two ordering values.\n+  protected def predicate(oldExpr: Expression, newExpr: Expression): Expression\n+  // The arithmetic expression returns greatest/least value of all parameters.\n+  // Used to pick up updated ordering value.\n+  protected def orderingUpdater(oldExpr: Expression, newExpr: Expression): Expression\n+\n+  override def children: Seq[Expression] = valueExpr :: orderingExpr :: Nil\n+\n+  override def nullable: Boolean = true\n+\n+  // Return data type.\n+  override def dataType: DataType = valueExpr.dataType\n+\n+  override def checkInputDataTypes(): TypeCheckResult =\n+    TypeUtils.checkForOrderingExpr(orderingExpr.dataType, s\"function $funcName\")\n+\n+  private lazy val ordering = AttributeReference(\"ordering\", orderingExpr.dataType)()"
  }],
  "prId": 24557
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "`valueWithMaxOrdering`",
    "commit": "05f1767dc49e6caebd91abf207014bcd8029b4f1",
    "createdAt": "2019-05-13T07:06:03Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.util.TypeUtils\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * The shared abstract superclass for `MaxBy` and `MinBy` SQL aggregate functions.\n+ */\n+abstract class MaxMinBy extends DeclarativeAggregate {\n+\n+  def valueExpr: Expression\n+  def orderingExpr: Expression\n+\n+  protected def funcName: String\n+  // The predicate compares two ordering values.\n+  protected def predicate(oldExpr: Expression, newExpr: Expression): Expression\n+  // The arithmetic expression returns greatest/least value of all parameters.\n+  // Used to pick up updated ordering value.\n+  protected def orderingUpdater(oldExpr: Expression, newExpr: Expression): Expression\n+\n+  override def children: Seq[Expression] = valueExpr :: orderingExpr :: Nil\n+\n+  override def nullable: Boolean = true\n+\n+  // Return data type.\n+  override def dataType: DataType = valueExpr.dataType\n+\n+  override def checkInputDataTypes(): TypeCheckResult =\n+    TypeUtils.checkForOrderingExpr(orderingExpr.dataType, s\"function $funcName\")\n+\n+  private lazy val ordering = AttributeReference(\"ordering\", orderingExpr.dataType)()\n+  private lazy val value = AttributeReference(\"value\", valueExpr.dataType)()"
  }],
  "prId": 24557
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit `olderExpr > newExpr`",
    "commit": "05f1767dc49e6caebd91abf207014bcd8029b4f1",
    "createdAt": "2019-05-13T07:07:04Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.util.TypeUtils\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * The shared abstract superclass for `MaxBy` and `MinBy` SQL aggregate functions.\n+ */\n+abstract class MaxMinBy extends DeclarativeAggregate {\n+\n+  def valueExpr: Expression\n+  def orderingExpr: Expression\n+\n+  protected def funcName: String\n+  // The predicate compares two ordering values.\n+  protected def predicate(oldExpr: Expression, newExpr: Expression): Expression\n+  // The arithmetic expression returns greatest/least value of all parameters.\n+  // Used to pick up updated ordering value.\n+  protected def orderingUpdater(oldExpr: Expression, newExpr: Expression): Expression\n+\n+  override def children: Seq[Expression] = valueExpr :: orderingExpr :: Nil\n+\n+  override def nullable: Boolean = true\n+\n+  // Return data type.\n+  override def dataType: DataType = valueExpr.dataType\n+\n+  override def checkInputDataTypes(): TypeCheckResult =\n+    TypeUtils.checkForOrderingExpr(orderingExpr.dataType, s\"function $funcName\")\n+\n+  private lazy val ordering = AttributeReference(\"ordering\", orderingExpr.dataType)()\n+  private lazy val value = AttributeReference(\"value\", valueExpr.dataType)()\n+\n+  override lazy val aggBufferAttributes: Seq[AttributeReference] = value :: ordering :: Nil\n+\n+  private lazy val nullValue = Literal.create(null, valueExpr.dataType)\n+  private lazy val nullOrdering = Literal.create(null, orderingExpr.dataType)\n+\n+  override lazy val initialValues: Seq[Literal] = Seq(\n+    /* value = */ nullValue,\n+    /* ordering = */ nullOrdering\n+  )\n+\n+  override lazy val updateExpressions: Seq[Expression] = Seq(\n+    /* value = */\n+    CaseWhen(\n+      (ordering.isNull && orderingExpr.isNull, nullValue) ::\n+        (ordering.isNull, valueExpr) ::\n+        (orderingExpr.isNull, value) :: Nil,\n+      If(predicate(ordering, orderingExpr), value, valueExpr)\n+    ),\n+    /* ordering = */ orderingUpdater(ordering, orderingExpr)\n+  )\n+\n+  override lazy val mergeExpressions: Seq[Expression] = Seq(\n+    /* value = */\n+    CaseWhen(\n+      (ordering.left.isNull && ordering.right.isNull, nullValue) ::\n+        (ordering.left.isNull, value.right) ::\n+        (ordering.right.isNull, value.left) :: Nil,\n+      If(predicate(ordering.left, ordering.right), value.left, value.right)\n+    ),\n+    /* ordering = */ orderingUpdater(ordering.left, ordering.right)\n+  )\n+\n+  override lazy val evaluateExpression: AttributeReference = value\n+}\n+\n+@ExpressionDescription(\n+  usage = \"_FUNC_(x, y) - Returns the value of `x` associated with the maximum value of `y`.\",\n+  examples = \"\"\"\n+    Examples:\n+      > SELECT _FUNC_(x, y) FROM VALUES (('a', 10)), (('b', 50)), (('c', 20)) AS tab(x, y);\n+       b\n+  \"\"\",\n+  since = \"3.0\")\n+case class MaxBy(valueExpr: Expression, orderingExpr: Expression) extends MaxMinBy {\n+  override protected def funcName: String = \"max_by\"\n+\n+  override protected def predicate(oldExpr: Expression, newExpr: Expression): Expression =\n+    GreaterThan(oldExpr, newExpr)"
  }],
  "prId": 24557
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "ah that's a good point. Shall we call it `extremumOrdering` then?",
    "commit": "05f1767dc49e6caebd91abf207014bcd8029b4f1",
    "createdAt": "2019-05-13T08:33:40Z",
    "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.util.TypeUtils\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * The shared abstract superclass for `MaxBy` and `MinBy` SQL aggregate functions.\n+ */\n+abstract class MaxMinBy extends DeclarativeAggregate {\n+\n+  def valueExpr: Expression\n+  def orderingExpr: Expression\n+\n+  protected def funcName: String\n+  // The predicate compares two ordering values.\n+  protected def predicate(oldExpr: Expression, newExpr: Expression): Expression\n+  // The arithmetic expression returns greatest/least value of all parameters.\n+  // Used to pick up updated ordering value.\n+  protected def orderingUpdater(oldExpr: Expression, newExpr: Expression): Expression\n+\n+  override def children: Seq[Expression] = valueExpr :: orderingExpr :: Nil\n+\n+  override def nullable: Boolean = true\n+\n+  // Return data type.\n+  override def dataType: DataType = valueExpr.dataType\n+\n+  override def checkInputDataTypes(): TypeCheckResult =\n+    TypeUtils.checkForOrderingExpr(orderingExpr.dataType, s\"function $funcName\")\n+\n+  // The attributes used to keep extremum (max or min) and associated aggregated values.",
    "line": 51
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Good for me. +1",
    "commit": "05f1767dc49e6caebd91abf207014bcd8029b4f1",
    "createdAt": "2019-05-13T08:36:14Z",
    "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions.aggregate\n+\n+import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.util.TypeUtils\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * The shared abstract superclass for `MaxBy` and `MinBy` SQL aggregate functions.\n+ */\n+abstract class MaxMinBy extends DeclarativeAggregate {\n+\n+  def valueExpr: Expression\n+  def orderingExpr: Expression\n+\n+  protected def funcName: String\n+  // The predicate compares two ordering values.\n+  protected def predicate(oldExpr: Expression, newExpr: Expression): Expression\n+  // The arithmetic expression returns greatest/least value of all parameters.\n+  // Used to pick up updated ordering value.\n+  protected def orderingUpdater(oldExpr: Expression, newExpr: Expression): Expression\n+\n+  override def children: Seq[Expression] = valueExpr :: orderingExpr :: Nil\n+\n+  override def nullable: Boolean = true\n+\n+  // Return data type.\n+  override def dataType: DataType = valueExpr.dataType\n+\n+  override def checkInputDataTypes(): TypeCheckResult =\n+    TypeUtils.checkForOrderingExpr(orderingExpr.dataType, s\"function $funcName\")\n+\n+  // The attributes used to keep extremum (max or min) and associated aggregated values.",
    "line": 51
  }],
  "prId": 24557
}]