[{
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Can you move all the duplicate code into the base class where possible?",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-15T00:33:33Z",
    "diffHunk": "@@ -75,9 +85,57 @@ case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n \n   override def dataType: DataType = BooleanType\n \n-  override def nullable: Boolean = child.nullable\n-\n   override def toString: String = s\"PostgreCastToBoolean($child as ${dataType.simpleString})\"\n \n   override def sql: String = s\"CAST(${child.sql} AS ${dataType.sql})\"\n }\n+\n+case class PostgreCastToTimestamp(child: Expression, timeZoneId: Option[String])\n+  extends PostgreCastBase {\n+  override def dataType: DataType = TimestampType\n+\n+  override def checkInputDataTypes(): TypeCheckResult = child.dataType match {\n+    case StringType | DateType =>\n+      TypeCheckResult.TypeCheckSuccess\n+    case _ =>\n+      TypeCheckResult.TypeCheckFailure(s\"cannot cast type ${child.dataType} to timestamp\")\n+  }\n+  /** Returns a copy of this expression with the specified timeZoneId. */\n+  override def withTimeZone(timeZoneId: String): TimeZoneAwareExpression =\n+    copy(timeZoneId = Option(timeZoneId))\n+\n+  override def castToTimestamp(from: DataType): Any => Any = from match {\n+    case StringType =>\n+      buildCast[UTF8String](_, utfs => DateTimeUtils.stringToTimestamp(utfs, zoneId)\n+        .getOrElse(throw new AnalysisException(s\"invalid input syntax for type timestamp:$utfs\")))\n+    case DateType =>\n+      super.castToTimestamp(from)\n+  }\n+\n+  override def castToTimestampCode(\n+      from: DataType,\n+      ctx: CodegenContext): CastFunction = from match {\n+    case StringType =>\n+      val zoneIdClass = classOf[ZoneId]\n+      val zid = JavaCode.global(\n+        ctx.addReferenceObj(\"zoneId\", zoneId, zoneIdClass.getName),\n+        zoneIdClass)\n+      val longOpt = ctx.freshVariable(\"longOpt\", classOf[Option[Long]])\n+      (c, evPrim, evNull) =>\n+        code\"\"\"\n+          scala.Option<Long> $longOpt =\n+            org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToTimestamp($c, $zid);\n+          if ($longOpt.isDefined()) {\n+            $evPrim = ((Long) $longOpt.get()).longValue();\n+          } else {\n+            $evNull = throw new AnalysisException(s\"invalid input syntax for type timestamp:$c\");\n+          }\n+         \"\"\"\n+    case DateType =>\n+      super.castToTimestampCode(from, ctx)\n+  }\n+\n+  override def toString: String = s\"PostgreCastToTimestamp($child as ${dataType.simpleString})\"\n+\n+  override def sql: String = s\"CAST(${child.sql} AS ${dataType.sql})\""
  }, {
    "author": {
      "login": "amanomer"
    },
    "body": "Done",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-21T06:22:45Z",
    "diffHunk": "@@ -75,9 +85,57 @@ case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n \n   override def dataType: DataType = BooleanType\n \n-  override def nullable: Boolean = child.nullable\n-\n   override def toString: String = s\"PostgreCastToBoolean($child as ${dataType.simpleString})\"\n \n   override def sql: String = s\"CAST(${child.sql} AS ${dataType.sql})\"\n }\n+\n+case class PostgreCastToTimestamp(child: Expression, timeZoneId: Option[String])\n+  extends PostgreCastBase {\n+  override def dataType: DataType = TimestampType\n+\n+  override def checkInputDataTypes(): TypeCheckResult = child.dataType match {\n+    case StringType | DateType =>\n+      TypeCheckResult.TypeCheckSuccess\n+    case _ =>\n+      TypeCheckResult.TypeCheckFailure(s\"cannot cast type ${child.dataType} to timestamp\")\n+  }\n+  /** Returns a copy of this expression with the specified timeZoneId. */\n+  override def withTimeZone(timeZoneId: String): TimeZoneAwareExpression =\n+    copy(timeZoneId = Option(timeZoneId))\n+\n+  override def castToTimestamp(from: DataType): Any => Any = from match {\n+    case StringType =>\n+      buildCast[UTF8String](_, utfs => DateTimeUtils.stringToTimestamp(utfs, zoneId)\n+        .getOrElse(throw new AnalysisException(s\"invalid input syntax for type timestamp:$utfs\")))\n+    case DateType =>\n+      super.castToTimestamp(from)\n+  }\n+\n+  override def castToTimestampCode(\n+      from: DataType,\n+      ctx: CodegenContext): CastFunction = from match {\n+    case StringType =>\n+      val zoneIdClass = classOf[ZoneId]\n+      val zid = JavaCode.global(\n+        ctx.addReferenceObj(\"zoneId\", zoneId, zoneIdClass.getName),\n+        zoneIdClass)\n+      val longOpt = ctx.freshVariable(\"longOpt\", classOf[Option[Long]])\n+      (c, evPrim, evNull) =>\n+        code\"\"\"\n+          scala.Option<Long> $longOpt =\n+            org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToTimestamp($c, $zid);\n+          if ($longOpt.isDefined()) {\n+            $evPrim = ((Long) $longOpt.get()).longValue();\n+          } else {\n+            $evNull = throw new AnalysisException(s\"invalid input syntax for type timestamp:$c\");\n+          }\n+         \"\"\"\n+    case DateType =>\n+      super.castToTimestampCode(from, ctx)\n+  }\n+\n+  override def toString: String = s\"PostgreCastToTimestamp($child as ${dataType.simpleString})\"\n+\n+  override def sql: String = s\"CAST(${child.sql} AS ${dataType.sql})\""
  }],
  "prId": 26472
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "nit: `CastBase{` => `CastBase {`. Can you check again more carefully?",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-15T00:34:13Z",
    "diffHunk": "@@ -16,19 +16,29 @@\n  */\n package org.apache.spark.sql.catalyst.expressions.postgreSQL\n \n+import java.time.ZoneId\n+\n+import org.apache.spark.sql.AnalysisException\n import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n import org.apache.spark.sql.catalyst.expressions.{CastBase, Expression, TimeZoneAwareExpression}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{CodegenContext, JavaCode}\n import org.apache.spark.sql.catalyst.expressions.codegen.Block._\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils\n import org.apache.spark.sql.catalyst.util.postgreSQL.StringUtils\n-import org.apache.spark.sql.types._\n+import org.apache.spark.sql.types.{BooleanType, DataType, DateType, IntegerType, NullType, StringType, TimestampType}\n import org.apache.spark.unsafe.types.UTF8String\n \n-case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n-  extends CastBase {\n+abstract class PostgreCastBase extends CastBase{"
  }, {
    "author": {
      "login": "amanomer"
    },
    "body": "Done",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-21T06:22:36Z",
    "diffHunk": "@@ -16,19 +16,29 @@\n  */\n package org.apache.spark.sql.catalyst.expressions.postgreSQL\n \n+import java.time.ZoneId\n+\n+import org.apache.spark.sql.AnalysisException\n import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n import org.apache.spark.sql.catalyst.expressions.{CastBase, Expression, TimeZoneAwareExpression}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{CodegenContext, JavaCode}\n import org.apache.spark.sql.catalyst.expressions.codegen.Block._\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils\n import org.apache.spark.sql.catalyst.util.postgreSQL.StringUtils\n-import org.apache.spark.sql.types._\n+import org.apache.spark.sql.types.{BooleanType, DataType, DateType, IntegerType, NullType, StringType, TimestampType}\n import org.apache.spark.unsafe.types.UTF8String\n \n-case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n-  extends CastBase {\n+abstract class PostgreCastBase extends CastBase{"
  }],
  "prId": 26472
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "I think `import org.apache.spark.sql.types._` is better because many type classes are expected to be used in this file.",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-15T00:35:24Z",
    "diffHunk": "@@ -16,19 +16,29 @@\n  */\n package org.apache.spark.sql.catalyst.expressions.postgreSQL\n \n+import java.time.ZoneId\n+\n+import org.apache.spark.sql.AnalysisException\n import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n import org.apache.spark.sql.catalyst.expressions.{CastBase, Expression, TimeZoneAwareExpression}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{CodegenContext, JavaCode}\n import org.apache.spark.sql.catalyst.expressions.codegen.Block._\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils\n import org.apache.spark.sql.catalyst.util.postgreSQL.StringUtils\n-import org.apache.spark.sql.types._",
    "line": 13
  }, {
    "author": {
      "login": "amanomer"
    },
    "body": "Done",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-21T06:22:24Z",
    "diffHunk": "@@ -16,19 +16,29 @@\n  */\n package org.apache.spark.sql.catalyst.expressions.postgreSQL\n \n+import java.time.ZoneId\n+\n+import org.apache.spark.sql.AnalysisException\n import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n import org.apache.spark.sql.catalyst.expressions.{CastBase, Expression, TimeZoneAwareExpression}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{CodegenContext, JavaCode}\n import org.apache.spark.sql.catalyst.expressions.codegen.Block._\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils\n import org.apache.spark.sql.catalyst.util.postgreSQL.StringUtils\n-import org.apache.spark.sql.types._",
    "line": 13
  }],
  "prId": 26472
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "How about the base class impl. like this?\r\n```\r\nabstract class PostgreCastBase(toType: DataType) extends CastBase {\r\n\r\n  def fromTypes: TypeCollection\r\n\r\n  override def dataType: DataType = toType\r\n\r\n  override protected def ansiEnabled: Boolean =\r\n    throw new UnsupportedOperationException(\"PostgreSQL dialect doesn't support ansi mode\")\r\n\r\n  override def checkInputDataTypes(): TypeCheckResult = {\r\n    if (!fromTypes.acceptsType(child.dataType)) {\r\n      TypeCheckResult.TypeCheckFailure(\r\n        s\"cannot cast type ${child.dataType.simpleString} to boolean\")\r\n    } else {\r\n      TypeCheckResult.TypeCheckSuccess\r\n    }\r\n  }\r\n\r\n  override def nullable: Boolean = child.nullable\r\n\r\n  override def sql: String = s\"CAST(${child.sql} AS ${toType.sql})\"\r\n\r\n  override def toString: String =\r\n    s\"PostgreCastTo${toType.simpleString}($child as ${toType.simpleString})\"\r\n}\r\n```",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-15T14:17:21Z",
    "diffHunk": "@@ -16,19 +16,31 @@\n  */\n package org.apache.spark.sql.catalyst.expressions.postgreSQL\n \n+import java.time.ZoneId\n+\n+import org.apache.spark.sql.AnalysisException\n import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n import org.apache.spark.sql.catalyst.expressions.{CastBase, Expression, TimeZoneAwareExpression}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{CodegenContext, JavaCode}\n import org.apache.spark.sql.catalyst.expressions.codegen.Block._\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils\n import org.apache.spark.sql.catalyst.util.postgreSQL.StringUtils\n import org.apache.spark.sql.types._\n import org.apache.spark.unsafe.types.UTF8String\n \n-case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n-  extends CastBase {\n+abstract class PostgreCastBase extends CastBase {"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "(just wrote it roughly, so we need more reviews for the base class..)",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-15T15:00:36Z",
    "diffHunk": "@@ -16,19 +16,31 @@\n  */\n package org.apache.spark.sql.catalyst.expressions.postgreSQL\n \n+import java.time.ZoneId\n+\n+import org.apache.spark.sql.AnalysisException\n import org.apache.spark.sql.catalyst.analysis.TypeCheckResult\n import org.apache.spark.sql.catalyst.expressions.{CastBase, Expression, TimeZoneAwareExpression}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{CodegenContext, JavaCode}\n import org.apache.spark.sql.catalyst.expressions.codegen.Block._\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils\n import org.apache.spark.sql.catalyst.util.postgreSQL.StringUtils\n import org.apache.spark.sql.types._\n import org.apache.spark.unsafe.types.UTF8String\n \n-case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n-  extends CastBase {\n+abstract class PostgreCastBase extends CastBase {"
  }],
  "prId": 26472
}, {
  "comments": [{
    "author": {
      "login": "Ngone51"
    },
    "body": "I believe that postgre could correctly parse string `19700101`, `1970/01/01`, `January 1 04:05:06 1970 PST` while spark can't. So, I think that we may also need to support it in `PostgreCastToTimestamp`.",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-16T15:32:26Z",
    "diffHunk": "@@ -68,16 +91,47 @@ case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n             throw new IllegalArgumentException(\"invalid input syntax for type boolean: $c\");\n           }\n         \"\"\"\n-\n     case IntegerType =>\n       super.castToBooleanCode(from)\n   }\n+}\n \n-  override def dataType: DataType = BooleanType\n+case class PostgreCastToTimestamp(child: Expression, timeZoneId: Option[String])\n+  extends PostgreCastBase(TimestampType) {\n \n-  override def nullable: Boolean = child.nullable\n+  override def fromTypes: TypeCollection = TypeCollection(StringType, DateType, NullType)\n \n-  override def toString: String = s\"PostgreCastToBoolean($child as ${dataType.simpleString})\"\n+  override def withTimeZone(timeZoneId: String): TimeZoneAwareExpression =\n+    copy(timeZoneId = Option(timeZoneId))\n \n-  override def sql: String = s\"CAST(${child.sql} AS ${dataType.sql})\"\n+  override def castToTimestamp(from: DataType): Any => Any = from match {\n+    case StringType =>\n+      buildCast[UTF8String](_, utfs => DateTimeUtils.stringToTimestamp(utfs, zoneId)",
    "line": 96
  }, {
    "author": {
      "login": "amanomer"
    },
    "body": "Thanks for your suggestion.  I will check this.",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-16T17:32:54Z",
    "diffHunk": "@@ -68,16 +91,47 @@ case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n             throw new IllegalArgumentException(\"invalid input syntax for type boolean: $c\");\n           }\n         \"\"\"\n-\n     case IntegerType =>\n       super.castToBooleanCode(from)\n   }\n+}\n \n-  override def dataType: DataType = BooleanType\n+case class PostgreCastToTimestamp(child: Expression, timeZoneId: Option[String])\n+  extends PostgreCastBase(TimestampType) {\n \n-  override def nullable: Boolean = child.nullable\n+  override def fromTypes: TypeCollection = TypeCollection(StringType, DateType, NullType)\n \n-  override def toString: String = s\"PostgreCastToBoolean($child as ${dataType.simpleString})\"\n+  override def withTimeZone(timeZoneId: String): TimeZoneAwareExpression =\n+    copy(timeZoneId = Option(timeZoneId))\n \n-  override def sql: String = s\"CAST(${child.sql} AS ${dataType.sql})\"\n+  override def castToTimestamp(from: DataType): Any => Any = from match {\n+    case StringType =>\n+      buildCast[UTF8String](_, utfs => DateTimeUtils.stringToTimestamp(utfs, zoneId)",
    "line": 96
  }, {
    "author": {
      "login": "amanomer"
    },
    "body": "```\r\npostgres# select cast('19700101' as timestamp);\r\n01.01.1970 00:00:00\r\n```\r\n```\r\npostgres# select cast('1970/01/01' as timestamp);\r\n01.01.1970 00:00:00\r\n```\r\n```\r\npostgres# select cast('January 1 04:05:06 1970 PST' as timestamp);\r\n01.01.1970 04:05:06\r\n```\r\nSpark results with NULL for all of them.",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-18T06:01:09Z",
    "diffHunk": "@@ -68,16 +91,47 @@ case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n             throw new IllegalArgumentException(\"invalid input syntax for type boolean: $c\");\n           }\n         \"\"\"\n-\n     case IntegerType =>\n       super.castToBooleanCode(from)\n   }\n+}\n \n-  override def dataType: DataType = BooleanType\n+case class PostgreCastToTimestamp(child: Expression, timeZoneId: Option[String])\n+  extends PostgreCastBase(TimestampType) {\n \n-  override def nullable: Boolean = child.nullable\n+  override def fromTypes: TypeCollection = TypeCollection(StringType, DateType, NullType)\n \n-  override def toString: String = s\"PostgreCastToBoolean($child as ${dataType.simpleString})\"\n+  override def withTimeZone(timeZoneId: String): TimeZoneAwareExpression =\n+    copy(timeZoneId = Option(timeZoneId))\n \n-  override def sql: String = s\"CAST(${child.sql} AS ${dataType.sql})\"\n+  override def castToTimestamp(from: DataType): Any => Any = from match {\n+    case StringType =>\n+      buildCast[UTF8String](_, utfs => DateTimeUtils.stringToTimestamp(utfs, zoneId)",
    "line": 96
  }, {
    "author": {
      "login": "amanomer"
    },
    "body": "@maropu kindly review latest changes and give your feedback on supporting above queries.\r\n\r\nDo we need to support them in this PR? If yes, we need to list all formats for timestamps which postgres supports but spark don't.",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-18T06:16:59Z",
    "diffHunk": "@@ -68,16 +91,47 @@ case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n             throw new IllegalArgumentException(\"invalid input syntax for type boolean: $c\");\n           }\n         \"\"\"\n-\n     case IntegerType =>\n       super.castToBooleanCode(from)\n   }\n+}\n \n-  override def dataType: DataType = BooleanType\n+case class PostgreCastToTimestamp(child: Expression, timeZoneId: Option[String])\n+  extends PostgreCastBase(TimestampType) {\n \n-  override def nullable: Boolean = child.nullable\n+  override def fromTypes: TypeCollection = TypeCollection(StringType, DateType, NullType)\n \n-  override def toString: String = s\"PostgreCastToBoolean($child as ${dataType.simpleString})\"\n+  override def withTimeZone(timeZoneId: String): TimeZoneAwareExpression =\n+    copy(timeZoneId = Option(timeZoneId))\n \n-  override def sql: String = s\"CAST(${child.sql} AS ${dataType.sql})\"\n+  override def castToTimestamp(from: DataType): Any => Any = from match {\n+    case StringType =>\n+      buildCast[UTF8String](_, utfs => DateTimeUtils.stringToTimestamp(utfs, zoneId)",
    "line": 96
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "I personally think that the support above is not a main issue of this pr, so better to separate the two work: the timestamp cast support and the timestamp format support for the pg dialect.",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-20T11:52:38Z",
    "diffHunk": "@@ -68,16 +91,47 @@ case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n             throw new IllegalArgumentException(\"invalid input syntax for type boolean: $c\");\n           }\n         \"\"\"\n-\n     case IntegerType =>\n       super.castToBooleanCode(from)\n   }\n+}\n \n-  override def dataType: DataType = BooleanType\n+case class PostgreCastToTimestamp(child: Expression, timeZoneId: Option[String])\n+  extends PostgreCastBase(TimestampType) {\n \n-  override def nullable: Boolean = child.nullable\n+  override def fromTypes: TypeCollection = TypeCollection(StringType, DateType, NullType)\n \n-  override def toString: String = s\"PostgreCastToBoolean($child as ${dataType.simpleString})\"\n+  override def withTimeZone(timeZoneId: String): TimeZoneAwareExpression =\n+    copy(timeZoneId = Option(timeZoneId))\n \n-  override def sql: String = s\"CAST(${child.sql} AS ${dataType.sql})\"\n+  override def castToTimestamp(from: DataType): Any => Any = from match {\n+    case StringType =>\n+      buildCast[UTF8String](_, utfs => DateTimeUtils.stringToTimestamp(utfs, zoneId)",
    "line": 96
  }],
  "prId": 26472
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "btw, we need to define a new rule and a new cast expr for each Pg cast pattern? I mean we cannot define all the Pg cast patterns in a single rule and a cast expr? cc: @cloud-fan @Ngone51 ",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-20T11:49:12Z",
    "diffHunk": "@@ -68,16 +91,47 @@ case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n             throw new IllegalArgumentException(\"invalid input syntax for type boolean: $c\");\n           }\n         \"\"\"\n-\n     case IntegerType =>\n       super.castToBooleanCode(from)\n   }\n+}\n \n-  override def dataType: DataType = BooleanType\n+case class PostgreCastToTimestamp(child: Expression, timeZoneId: Option[String])",
    "line": 83
  }, {
    "author": {
      "login": "Ngone51"
    },
    "body": "I think we can and should combine them into a single one(both rule and expression) when more types get in. Just like the original `Cast` does. But I'm not sure where shall we start. Maybe, this one ?",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-21T04:03:53Z",
    "diffHunk": "@@ -68,16 +91,47 @@ case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n             throw new IllegalArgumentException(\"invalid input syntax for type boolean: $c\");\n           }\n         \"\"\"\n-\n     case IntegerType =>\n       super.castToBooleanCode(from)\n   }\n+}\n \n-  override def dataType: DataType = BooleanType\n+case class PostgreCastToTimestamp(child: Expression, timeZoneId: Option[String])",
    "line": 83
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "yea, I personally think so. @cloud-fan ",
    "commit": "08c71f1eaf0e6f867b964832ccc360a50cf6fc53",
    "createdAt": "2019-11-21T04:15:44Z",
    "diffHunk": "@@ -68,16 +91,47 @@ case class PostgreCastToBoolean(child: Expression, timeZoneId: Option[String])\n             throw new IllegalArgumentException(\"invalid input syntax for type boolean: $c\");\n           }\n         \"\"\"\n-\n     case IntegerType =>\n       super.castToBooleanCode(from)\n   }\n+}\n \n-  override def dataType: DataType = BooleanType\n+case class PostgreCastToTimestamp(child: Expression, timeZoneId: Option[String])",
    "line": 83
  }],
  "prId": 26472
}]