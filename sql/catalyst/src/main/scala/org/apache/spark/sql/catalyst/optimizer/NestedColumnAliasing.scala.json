[{
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "I feel `getRootReferences` and `getNestedFieldReferences` are a bit complicated, so how about this ?\r\nhttps://github.com/apache/spark/commit/bbf5a5718fc9ab889f2e630edb40a0d4377f3ddc",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-07T06:56:58Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        g.copy(child = replaceChildrenWithAliases(grandChild, attrToAliases)))\n+\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Similar to [[QueryPlan.references]], but this only returns all attributes\n+   * that are explicitly referenced on the root levels in a [[LogicalPlan]].\n+   */\n+  private def getRootReferences(plan: LogicalPlan): AttributeSet = {\n+    def helper(e: Expression): AttributeSet = e match {\n+      case attr: AttributeReference => AttributeSet(attr)\n+      case _: GetStructField => AttributeSet.empty\n+      case es if es.children.nonEmpty => AttributeSet(es.children.flatMap(helper))\n+      case _ => AttributeSet.empty\n+    }\n+    AttributeSet.fromAttributeSets(plan.expressions.map(helper))\n+  }\n+\n+  /**\n+   * Returns all the nested fields that are explicitly referenced as [[Expression]]\n+   * in a [[LogicalPlan]]. Currently, we only support having [[GetStructField]] in the chain\n+   * of the expressions. If the chain contains GetArrayStructFields, GetMapValue, or\n+   * GetArrayItem, the nested field substitution will not be performed.\n+   */\n+  private def getNestedFieldReferences(plan: LogicalPlan): Seq[GetStructField] = {\n+    def helper(e: Expression): Seq[GetStructField] = e match {\n+      case f @ GetStructField(child, _, _) if isGetStructFieldOrAttr(child) => Seq(f)\n+      case es if es.children.nonEmpty => es.children.flatMap(e => helper(e))\n+      case _ => Seq.empty\n+    }\n+\n+    def isGetStructFieldOrAttr(e: Expression): Boolean = e match {\n+      case GetStructField(child, _, _) => isGetStructFieldOrAttr(child)\n+      case _: AttributeReference => true\n+      case _ => false\n+    }\n+\n+    plan.expressions.flatMap(helper)\n+  }",
    "line": 95
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "super nit: \" * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\"",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-07T06:58:23Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule."
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "typo: `substitute the` -> `substitute them`",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-07T06:59:37Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project"
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "IMHO it'd be better to move this into `NestedColumnAliasingSuite` now. Then, we move back when reusing this in other optimization?",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-07T07:11:04Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        g.copy(child = replaceChildrenWithAliases(grandChild, attrToAliases)))\n+\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Similar to [[QueryPlan.references]], but this only returns all attributes\n+   * that are explicitly referenced on the root levels in a [[LogicalPlan]].\n+   */\n+  private def getRootReferences(plan: LogicalPlan): AttributeSet = {\n+    def helper(e: Expression): AttributeSet = e match {\n+      case attr: AttributeReference => AttributeSet(attr)\n+      case _: GetStructField => AttributeSet.empty\n+      case es if es.children.nonEmpty => AttributeSet(es.children.flatMap(helper))\n+      case _ => AttributeSet.empty\n+    }\n+    AttributeSet.fromAttributeSets(plan.expressions.map(helper))\n+  }\n+\n+  /**\n+   * Returns all the nested fields that are explicitly referenced as [[Expression]]\n+   * in a [[LogicalPlan]]. Currently, we only support having [[GetStructField]] in the chain\n+   * of the expressions. If the chain contains GetArrayStructFields, GetMapValue, or\n+   * GetArrayItem, the nested field substitution will not be performed.\n+   */\n+  private def getNestedFieldReferences(plan: LogicalPlan): Seq[GetStructField] = {\n+    def helper(e: Expression): Seq[GetStructField] = e match {\n+      case f @ GetStructField(child, _, _) if isGetStructFieldOrAttr(child) => Seq(f)\n+      case es if es.children.nonEmpty => es.children.flatMap(e => helper(e))\n+      case _ => Seq.empty\n+    }\n+\n+    def isGetStructFieldOrAttr(e: Expression): Boolean = e match {\n+      case GetStructField(child, _, _) => isGetStructFieldOrAttr(child)\n+      case _: AttributeReference => true\n+      case _ => false\n+    }\n+\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val rootReferences = plans.map(getRootReferences).reduce(_ ++ _)\n+    val nestedFieldReferences = plans.map(getNestedFieldReferences).reduce(_ ++ _)\n+\n+    val aliasSub = nestedFieldReferences\n+      .filter(!_.references.subsetOf(rootReferences))\n+      .groupBy(_.references.head)\n+      .flatMap { case (attr: Attribute, nestedFields: Seq[GetStructField]) =>\n+        // Each expression can contain multiple nested fields.\n+        // Note that we keep the original names to deliver to parquet in a case-sensitive way.\n+        val nestedFieldToAlias = nestedFields.distinct.map { f =>\n+          val exprId = NamedExpression.newExprId\n+          (f, Alias(f, s\"_gen_alias_${exprId.id}\")(exprId, Seq.empty, None))\n+        }\n+\n+        if (nestedFieldToAlias.nonEmpty &&\n+            nestedFieldToAlias.length < totalFieldNum(attr.dataType)) {\n+          Some(attr.exprId -> nestedFieldToAlias)\n+        } else {\n+          None\n+        }\n+      }\n+\n+    if (aliasSub.isEmpty) {\n+      None\n+    } else {\n+      Some((aliasSub.values.flatten.toMap, aliasSub.map(x => (x._1, x._2.map(_._2)))))\n+    }\n+  }\n+\n+  /**\n+   * Return total number of fields of this type. This is used as a threshold to use nested column\n+   * pruning. It's okay to underestimate. If the number of reference is bigger than this, the parent\n+   * reference is used instead of nested field references.\n+   */\n+  private def totalFieldNum(dataType: DataType): Int = dataType match {\n+    case _: AtomicType => 1\n+    case StructType(fields) => fields.map(f => totalFieldNum(f.dataType)).sum\n+    case ArrayType(elementType, _) => totalFieldNum(elementType)\n+    case MapType(keyType, valueType, _) => totalFieldNum(keyType) + totalFieldNum(valueType)\n+    case _ => 1 // UDT and others\n+  }\n+\n+  /**\n+   * Return all generated aliases. Although this is used in testing, this utility function can\n+   * be used for other optimizations."
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "We need this match? IIUC, if this match doesn't exist, this rule generates unnecessary aliases between local/global limits. We cannot remove these unnecessary aliases in another optimizer rule, e.g., RemoveNoopOperators?\r\n\r\nI think this rule could generate unnecessary aliases in other cases, too, e.g.,\r\n```\r\n\r\nscala> spark.table(\"t\").printSchema\r\nroot\r\n |-- c0: long (nullable = true)\r\n |-- c1: struct (nullable = true)\r\n |    |-- n0: long (nullable = true)\r\n |    |-- n1: long (nullable = true)\r\n\r\nscala> spark.table(\"t\").sample(0.5).repartition(1).select(\"c1.n0\").explain(true)\r\n== Optimized Logical Plan ==\r\nProject [_gen_alias_36#36L AS n0#35L]\r\n+- Repartition 1, true\r\n   +- Project [_gen_alias_37#37L AS _gen_alias_36#36L]\r\n      +- Sample 0.0, 0.5, false, 5378592115661057580\r\n         +- Project [c1#25.n0 AS _gen_alias_37#37L]\r\n            +- Relation[c1#25] parquet\r\n```",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-07T08:16:58Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Yes. Right. Current, I didn't add additional optimizer rule to handle that redundant one. However, the reduced size of data will overwhelm the additional simple projection.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-07T23:48:14Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Yea, I know the great metric against the additional cost (unnecessary aliases)! So, I just wanted to know which one we should cover in this pr, and which one we could resolve in feature work. If we have TODO tasks, IMO it would be better to leave TODO comments where possible.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-08T01:15:29Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Sure. Thanks. Noop Alias issue is a general one because users can make it, too. I'll try to file a general JIRA issue for removing Noop Alias.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-08T18:38:36Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "@maropu . Since that is a general issue, I created [SPARK-27123](https://issues.apache.org/jira/browse/SPARK-27123) and make a [PR](https://github.com/apache/spark/pull/24049) for that.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-11T05:55:43Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>"
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Can you add a test case for a plan having `LocalLimit` w/o `GlobalLimit`?",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-07T08:21:10Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        g.copy(child = replaceChildrenWithAliases(grandChild, attrToAliases)))\n+\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true",
    "line": 82
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Since this PR doesn't support `Union` and `Join`, `LocalLimit` w/o `GlobalLimit` is not considered. Do you mean some negative cases with `Union` and `Join`?",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-07T23:59:51Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        g.copy(child = replaceChildrenWithAliases(grandChild, attrToAliases)))\n+\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true",
    "line": 82
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "I'll add one negative case with Union~",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-08T00:08:41Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        g.copy(child = replaceChildrenWithAliases(grandChild, attrToAliases)))\n+\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true",
    "line": 82
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Ah, what I'm worried about is that no test fails with/without this entry: `case _: LocalLimit => true`.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-08T01:06:09Z",
    "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle nested column aliasing pattern inside `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute the by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, g @ GlobalLimit(_, grandChild: LocalLimit)) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        g.copy(child = replaceChildrenWithAliases(grandChild, attrToAliases)))\n+\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true",
    "line": 82
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "I feel it is better: Return root references that are individually accessed as a whole, and `GetStructField`s.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-14T09:21:37Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references and `GetStructField`s."
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Sure!",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-14T16:28:03Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references and `GetStructField`s."
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "For the current aliasing approach, it possibly produces many aliases. For certain cases, it can be annoying to see a lot of aliases. As this feature can be disabled by the config, I guess this concern might not be serious.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-14T09:35:41Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)",
    "line": 73
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Also,, `CollapseProject` improvement is merged first for that reason. That prevents aliases at every steps.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-14T16:29:49Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)",
    "line": 73
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Suppose we access `a.b`, and `a` is a struct like `\"a struct<b:struct<c: int, d: int, e: string>>`. `totalFieldNum` will report 3 fields for `a`.\r\n\r\nLooks like we will create an alias for `a.b`? But for this case, I guess we don't need pruning.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-14T09:46:55Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {\n+      case _: AttributeReference | _: GetStructField => Seq(e)\n+      case es if es.children.nonEmpty => es.children.flatMap(helper)\n+      case _ => Seq.empty\n+    }\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val (nestedFieldReferences, otherRootReferences) = plans\n+      .map(collectRootReferenceAndGetStructField).reduce(_ ++ _).partition {\n+        case _: GetStructField => true\n+        case _ => false\n+      }\n+\n+    val aliasSub = nestedFieldReferences.asInstanceOf[Seq[GetStructField]]\n+      .filter(!_.references.subsetOf(AttributeSet(otherRootReferences)))\n+      .groupBy(_.references.head)\n+      .flatMap { case (attr: Attribute, nestedFields: Seq[GetStructField]) =>\n+        // Each expression can contain multiple nested fields.\n+        // Note that we keep the original names to deliver to parquet in a case-sensitive way.\n+        val nestedFieldToAlias = nestedFields.distinct.map { f =>\n+          val exprId = NamedExpression.newExprId\n+          (f, Alias(f, s\"_gen_alias_${exprId.id}\")(exprId, Seq.empty, None))\n+        }\n+\n+        if (nestedFieldToAlias.nonEmpty &&\n+            nestedFieldToAlias.length < totalFieldNum(attr.dataType)) {",
    "line": 125
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "It's `Aliasing` instead of `Pruning`. With `ColumnPruning` and `CollapseProject`, your case is also covered. I added a test case for your concern.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-14T18:23:24Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {\n+      case _: AttributeReference | _: GetStructField => Seq(e)\n+      case es if es.children.nonEmpty => es.children.flatMap(helper)\n+      case _ => Seq.empty\n+    }\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val (nestedFieldReferences, otherRootReferences) = plans\n+      .map(collectRootReferenceAndGetStructField).reduce(_ ++ _).partition {\n+        case _: GetStructField => true\n+        case _ => false\n+      }\n+\n+    val aliasSub = nestedFieldReferences.asInstanceOf[Seq[GetStructField]]\n+      .filter(!_.references.subsetOf(AttributeSet(otherRootReferences)))\n+      .groupBy(_.references.head)\n+      .flatMap { case (attr: Attribute, nestedFields: Seq[GetStructField]) =>\n+        // Each expression can contain multiple nested fields.\n+        // Note that we keep the original names to deliver to parquet in a case-sensitive way.\n+        val nestedFieldToAlias = nestedFields.distinct.map { f =>\n+          val exprId = NamedExpression.newExprId\n+          (f, Alias(f, s\"_gen_alias_${exprId.id}\")(exprId, Seq.empty, None))\n+        }\n+\n+        if (nestedFieldToAlias.nonEmpty &&\n+            nestedFieldToAlias.length < totalFieldNum(attr.dataType)) {",
    "line": 125
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Could you leave comments here about why we need the check: `nestedFieldToAlias.length < totalFieldNum(attr.dataType)`?",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-15T04:48:37Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references that are individually accessed as a whole, and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {\n+      case _: AttributeReference | _: GetStructField => Seq(e)\n+      case es if es.children.nonEmpty => es.children.flatMap(helper)\n+      case _ => Seq.empty\n+    }\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val (nestedFieldReferences, otherRootReferences) = plans\n+      .map(collectRootReferenceAndGetStructField).reduce(_ ++ _).partition {\n+        case _: GetStructField => true\n+        case _ => false\n+      }\n+\n+    val aliasSub = nestedFieldReferences.asInstanceOf[Seq[GetStructField]]\n+      .filter(!_.references.subsetOf(AttributeSet(otherRootReferences)))\n+      .groupBy(_.references.head)\n+      .flatMap { case (attr: Attribute, nestedFields: Seq[GetStructField]) =>\n+        // Each expression can contain multiple nested fields.\n+        // Note that we keep the original names to deliver to parquet in a case-sensitive way.\n+        val nestedFieldToAlias = nestedFields.distinct.map { f =>\n+          val exprId = NamedExpression.newExprId\n+          (f, Alias(f, s\"_gen_alias_${exprId.id}\")(exprId, Seq.empty, None))\n+        }\n+\n+        if (nestedFieldToAlias.nonEmpty &&\n+            nestedFieldToAlias.length < totalFieldNum(attr.dataType)) {",
    "line": 125
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Sure. Done.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-15T16:01:25Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references that are individually accessed as a whole, and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {\n+      case _: AttributeReference | _: GetStructField => Seq(e)\n+      case es if es.children.nonEmpty => es.children.flatMap(helper)\n+      case _ => Seq.empty\n+    }\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val (nestedFieldReferences, otherRootReferences) = plans\n+      .map(collectRootReferenceAndGetStructField).reduce(_ ++ _).partition {\n+        case _: GetStructField => true\n+        case _ => false\n+      }\n+\n+    val aliasSub = nestedFieldReferences.asInstanceOf[Seq[GetStructField]]\n+      .filter(!_.references.subsetOf(AttributeSet(otherRootReferences)))\n+      .groupBy(_.references.head)\n+      .flatMap { case (attr: Attribute, nestedFields: Seq[GetStructField]) =>\n+        // Each expression can contain multiple nested fields.\n+        // Note that we keep the original names to deliver to parquet in a case-sensitive way.\n+        val nestedFieldToAlias = nestedFields.distinct.map { f =>\n+          val exprId = NamedExpression.newExprId\n+          (f, Alias(f, s\"_gen_alias_${exprId.id}\")(exprId, Seq.empty, None))\n+        }\n+\n+        if (nestedFieldToAlias.nonEmpty &&\n+            nestedFieldToAlias.length < totalFieldNum(attr.dataType)) {",
    "line": 125
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "super nit: How about `doCollectFunc`?",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-15T04:51:05Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references that are individually accessed as a whole, and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "No problem.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-15T16:02:38Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references that are individually accessed as a whole, and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {"
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "nit: Drop `.asInstanceOf[Seq[GetStructField]]`.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-15T05:06:33Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references that are individually accessed as a whole, and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {\n+      case _: AttributeReference | _: GetStructField => Seq(e)\n+      case es if es.children.nonEmpty => es.children.flatMap(helper)\n+      case _ => Seq.empty\n+    }\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val (nestedFieldReferences, otherRootReferences) = plans\n+      .map(collectRootReferenceAndGetStructField).reduce(_ ++ _).partition {\n+        case _: GetStructField => true\n+        case _ => false\n+      }\n+\n+    val aliasSub = nestedFieldReferences.asInstanceOf[Seq[GetStructField]]",
    "line": 111
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thanks.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-15T16:03:37Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references that are individually accessed as a whole, and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {\n+      case _: AttributeReference | _: GetStructField => Seq(e)\n+      case es if es.children.nonEmpty => es.children.flatMap(helper)\n+      case _ => Seq.empty\n+    }\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val (nestedFieldReferences, otherRootReferences) = plans\n+      .map(collectRootReferenceAndGetStructField).reduce(_ ++ _).partition {\n+        case _: GetStructField => true\n+        case _ => false\n+      }\n+\n+    val aliasSub = nestedFieldReferences.asInstanceOf[Seq[GetStructField]]",
    "line": 111
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Oops. I forgot that I added this for Scala issue. We need this here for the below `flatMap`.\r\n```\r\n[error] [warn] /.../sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/NestedColumnAliasing.scala:117: non-variable type argument org.apache.spark.sql.catalyst.expressions.GetStructField in type pattern Seq[org.apache.spark.sql.catalyst.expressions.GetStructField] (the underlying of Seq[org.apache.spark.sql.catalyst.expressions.GetStructField]) is unchecked since it is eliminated by erasure\r\n[error] [warn]       .flatMap { case (attr, nestedFields: Seq[GetStructField]) =>\r\n[error] [warn] \r\n```\r\n\r\nI'll keep the current one.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-15T16:10:59Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references that are individually accessed as a whole, and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {\n+      case _: AttributeReference | _: GetStructField => Seq(e)\n+      case es if es.children.nonEmpty => es.children.flatMap(helper)\n+      case _ => Seq.empty\n+    }\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val (nestedFieldReferences, otherRootReferences) = plans\n+      .map(collectRootReferenceAndGetStructField).reduce(_ ++ _).partition {\n+        case _: GetStructField => true\n+        case _ => false\n+      }\n+\n+    val aliasSub = nestedFieldReferences.asInstanceOf[Seq[GetStructField]]",
    "line": 111
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "ok",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-15T22:00:11Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references that are individually accessed as a whole, and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {\n+      case _: AttributeReference | _: GetStructField => Seq(e)\n+      case es if es.children.nonEmpty => es.children.flatMap(helper)\n+      case _ => Seq.empty\n+    }\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val (nestedFieldReferences, otherRootReferences) = plans\n+      .map(collectRootReferenceAndGetStructField).reduce(_ ++ _).partition {\n+        case _: GetStructField => true\n+        case _ => false\n+      }\n+\n+    val aliasSub = nestedFieldReferences.asInstanceOf[Seq[GetStructField]]",
    "line": 111
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thanks!",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-15T22:02:22Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references that are individually accessed as a whole, and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {\n+      case _: AttributeReference | _: GetStructField => Seq(e)\n+      case es if es.children.nonEmpty => es.children.flatMap(helper)\n+      case _ => Seq.empty\n+    }\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val (nestedFieldReferences, otherRootReferences) = plans\n+      .map(collectRootReferenceAndGetStructField).reduce(_ ++ _).partition {\n+        case _: GetStructField => true\n+        case _ => false\n+      }\n+\n+    val aliasSub = nestedFieldReferences.asInstanceOf[Seq[GetStructField]]",
    "line": 111
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "nit: `.flatMap { case (attr, nestedFields: Seq[GetStructField]) =>`",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-15T05:06:51Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references that are individually accessed as a whole, and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {\n+      case _: AttributeReference | _: GetStructField => Seq(e)\n+      case es if es.children.nonEmpty => es.children.flatMap(helper)\n+      case _ => Seq.empty\n+    }\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val (nestedFieldReferences, otherRootReferences) = plans\n+      .map(collectRootReferenceAndGetStructField).reduce(_ ++ _).partition {\n+        case _: GetStructField => true\n+        case _ => false\n+      }\n+\n+    val aliasSub = nestedFieldReferences.asInstanceOf[Seq[GetStructField]]\n+      .filter(!_.references.subsetOf(AttributeSet(otherRootReferences)))\n+      .groupBy(_.references.head)\n+      .flatMap { case (attr: Attribute, nestedFields: Seq[GetStructField]) =>"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Sure.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-15T16:04:32Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child) if canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases.\n+   */\n+  private def replaceChildrenWithAliases(\n+      plan: LogicalPlan,\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {\n+    plan.withNewChildren(plan.children.map { plan =>\n+      Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)\n+    })\n+  }\n+\n+  /**\n+   * Returns true for those operators that project can be pushed through.\n+   */\n+  private def canProjectPushThrough(plan: LogicalPlan) = plan match {\n+    case _: GlobalLimit => true\n+    case _: LocalLimit => true\n+    case _: Repartition => true\n+    case _: Sample => true\n+    case _ => false\n+  }\n+\n+  /**\n+   * Return root references that are individually accessed as a whole, and `GetStructField`s.\n+   */\n+  private def collectRootReferenceAndGetStructField(plan: LogicalPlan): Seq[Expression] = {\n+    def helper(e: Expression): Seq[Expression] = e match {\n+      case _: AttributeReference | _: GetStructField => Seq(e)\n+      case es if es.children.nonEmpty => es.children.flatMap(helper)\n+      case _ => Seq.empty\n+    }\n+    plan.expressions.flatMap(helper)\n+  }\n+\n+  /**\n+   * Return two maps in order to replace nested fields to aliases.\n+   *\n+   * 1. GetStructField -> Alias: A new alias is created for each nested field.\n+   * 2. ExprId -> Seq[Alias]: A reference attribute has multiple aliases pointing it.\n+   */\n+  private def getAliasSubMap(plans: LogicalPlan*)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = {\n+    val (nestedFieldReferences, otherRootReferences) = plans\n+      .map(collectRootReferenceAndGetStructField).reduce(_ ++ _).partition {\n+        case _: GetStructField => true\n+        case _ => false\n+      }\n+\n+    val aliasSub = nestedFieldReferences.asInstanceOf[Seq[GetStructField]]\n+      .filter(!_.references.subsetOf(AttributeSet(otherRootReferences)))\n+      .groupBy(_.references.head)\n+      .flatMap { case (attr: Attribute, nestedFields: Seq[GetStructField]) =>"
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "I modified abit for refactoring and could you check? https://github.com/dongjoon-hyun/spark/pull/4",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-18T01:51:16Z",
    "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "That looks better to me. I merged it. Thank you so much.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-18T04:54:37Z",
    "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)"
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "nit: childen -> children",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-18T01:51:42Z",
    "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>\n+      getAliasSubMap(plan, child)\n+    case _ => None\n+  }\n+\n+  /**\n+   * Replace nested columns to prune unused nested columns later.\n+   */\n+  def replaceToAliases(\n+      plan: LogicalPlan,\n+      nestedFieldToAlias: Map[GetStructField, Alias],\n+      attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = plan match {\n+    case Project(projectList, child) =>\n+      Project(\n+        getNewProjectList(projectList, nestedFieldToAlias),\n+        replaceChildrenWithAliases(child, attrToAliases))\n+  }\n+\n+  /**\n+   * Return a replaced project list.\n+   */\n+  private def getNewProjectList(\n+      projectList: Seq[NamedExpression],\n+      nestedFieldToAlias: Map[GetStructField, Alias]): Seq[NamedExpression] = {\n+    projectList.map(_.transform {\n+      case f: GetStructField if nestedFieldToAlias.contains(f) =>\n+        nestedFieldToAlias(f).toAttribute\n+    }.asInstanceOf[NamedExpression])\n+  }\n+\n+  /**\n+   * Return a plan with new childen replaced with aliases."
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "How about pre-checking if `projectList` has at least one`GetStructField` here before computing `getAliasSubMap`?",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-18T01:54:32Z",
    "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>",
    "line": 36
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "The complexity will be the same since `getAliasSubMap` do `partition` at the first line and the rest of logic will not executed. We need `collectRootReferenceAndGetStructField` here, too.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-18T05:03:11Z",
    "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(_, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>",
    "line": 36
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "This rule applies even Spark can't prune nested fields. For example, when reading from data sources don't support nested schema pruning.\r\n\r\nThis is a special rule that only makes sense when pruning nested fields. But now it is applied to all queries. @dongjoon-hyun WDYT? Shall we apply it when pruning nested fields happens actually?\r\n\r\n",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-18T16:11:10Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(projectList, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>",
    "line": 36
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thank you for reivew, @viirya !\r\n1. Do you mean JSON and AVRO?\r\n> For example, when reading from data sources don't support nested schema pruning.\r\n2. For the following,\r\n> Shall we apply it when pruning nested fields happens actually?\r\n\r\nThis line is `unapply` and this is used [at the following pattern](https://github.com/apache/spark/pull/23964/files#diff-a636a87d8843eeccca90140be91d4fafR650) inside `ColumnPruning` optimizer rule and `NestedColumnAliasing.replaceToAliases` is not called if `getAliasSubMap` return `None`.\r\n```scala\r\n    case p @ NestedColumnAliasing(nestedFieldToAlias, attrToAliases) =>\r\n\t      NestedColumnAliasing.replaceToAliases(p, nestedFieldToAlias, attrToAliases)\r\n```",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-18T17:37:48Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(projectList, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>",
    "line": 36
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "> 1. Do you mean JSON and AVRO?\r\n\r\nThere might be data sources not included in Spark and they don't support nested schema pruning.\r\n\r\n> This line is unapply and this is used at the following pattern inside ColumnPruning optimizer rule and NestedColumnAliasing.replaceToAliases is not called if getAliasSubMap return None.\r\n\r\n`getAliasSubMap` returns something when the config is enabled and nested field access is found. But nested schema pruning works when underlying data source supports it. Otherwise, pushing down and aliasing nested field access is not useful. It doesn't have negative effect in query execution though. Maybe not a big deal, it is probably better if we apply this rule when nested schema pruning actually happens. It should not block this, I think.\r\n\r\n",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-19T05:32:50Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(projectList, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>",
    "line": 36
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Yep. I don't think that block this.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-19T15:38:14Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(projectList, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>",
    "line": 36
  }, {
    "author": {
      "login": "dbtsai"
    },
    "body": "Agree with @viirya , this rule can be useful even for datasources that do't support nested pruning. We can have a followup to make it as a separate conf to enable it.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-03-20T18:56:52Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(projectList, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>",
    "line": 36
  }],
  "prId": 23964
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Hey @dongjoon-hyun, @viirya, and @dbtsai. Sorry for late input - I was just looking through the PRs in my notification queue.\r\n\r\nJust out of curiosity. WDYT about this idea?\r\n\r\n1. Putting this as a separate rule under `defaultBatches` in `Optimizer` \r\n2. Removing `spark.sql[.optimizer].serializer.nestedSchemaPruning.enabled`\r\n3. Add the rule into `spark.sql.optimizer.excludedRules` as default.\r\n4. Add some comments on the rule that this rule is intentionally excluded from optimizer as it's an experimental rule set.\r\n\r\nIn this way, we don't have to add a configuration for each nested column access improvement, and leverage the existing configuration. It requires to take a look here and there but I was thinking it's a cleaner way.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-04-02T01:22:41Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(projectList, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>",
    "line": 36
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Hi, @HyukjinKwon . Actually, this is the 3rd try for purpose. At every PR, there exists the same question about `a separate rule`. :)\r\n\r\n1. 1st PR: https://github.com/apache/spark/pull/23542#discussion_r248095908\r\n2. 2nd PR: https://github.com/apache/spark/pull/23873#discussion_r261768034\r\n3. 3rd one: Yours.\r\n\r\nIn short, this should be here. Otherwise, the projection is already moved down as the whole attribute instead of a subset of fields.",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-04-02T01:50:24Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(projectList, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>",
    "line": 36
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Oops, sorry looks I missed the discussion. but still we could remove other rule-specific configuration (not this PR one).. but yes, maybe I should go to that PR and ask the idea :).",
    "commit": "3711312af5c443e861929e1a2bdde18c05728856",
    "createdAt": "2019-04-02T01:55:21Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * This aims to handle a nested column aliasing pattern inside the `ColumnPruning` optimizer rule.\n+ * If a project or its child references to nested fields, and not all the fields\n+ * in a nested attribute are used, we can substitute them by alias attributes; then a project\n+ * of the nested fields as aliases on the children of the child will be created.\n+ */\n+object NestedColumnAliasing {\n+\n+  def unapply(plan: LogicalPlan)\n+    : Option[(Map[GetStructField, Alias], Map[ExprId, Seq[Alias]])] = plan match {\n+    case Project(projectList, child)\n+        if SQLConf.get.nestedSchemaPruningEnabled && canProjectPushThrough(child) =>",
    "line": 36
  }],
  "prId": 23964
}]