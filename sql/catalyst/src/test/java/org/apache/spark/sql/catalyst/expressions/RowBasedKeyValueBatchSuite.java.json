[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "This should just use the value configure in SparkConf? at least that would be the more standard way to plumb through this value to tests.\n",
    "commit": "96a5c6607e47dd4431f59672f25506181223a93f",
    "createdAt": "2016-09-13T12:47:38Z",
    "diffHunk": "@@ -338,15 +338,18 @@ public void appendRowUntilExceedingCapacity() throws Exception {\n \n   @Test\n   public void appendRowUntilExceedingPageSize() throws Exception {\n+    // Use of this property prevents issues when running on a two core machine\n+    // A developer may override this size to 1 MB not 64 MB, so use that if so\n+    int pageSizeToUse = Integer.parseInt(System.getProperty(\"spark.buffer.pageSize\"));"
  }, {
    "author": {
      "login": "a-roberts"
    },
    "body": "Yeah that's right, couldn't figure out how to get the SparkConf from that test though, will have another look now\n",
    "commit": "96a5c6607e47dd4431f59672f25506181223a93f",
    "createdAt": "2016-09-13T12:49:58Z",
    "diffHunk": "@@ -338,15 +338,18 @@ public void appendRowUntilExceedingCapacity() throws Exception {\n \n   @Test\n   public void appendRowUntilExceedingPageSize() throws Exception {\n+    // Use of this property prevents issues when running on a two core machine\n+    // A developer may override this size to 1 MB not 64 MB, so use that if so\n+    int pageSizeToUse = Integer.parseInt(System.getProperty(\"spark.buffer.pageSize\"));"
  }, {
    "author": {
      "login": "a-roberts"
    },
    "body": "Running the tests now with \n\n```\nint pageSizeToUse = (int) memoryManager.pageSizeBytes(); \n```\n\nLooking at the logic in here I see we either use the default page size or whatever the user specifies\n\nAn int is accepted for the allocate method in RowBasedKeyValueBatch, given that a max int in Java is 2,147m I doubt this will be a problem\n",
    "commit": "96a5c6607e47dd4431f59672f25506181223a93f",
    "createdAt": "2016-09-13T13:55:05Z",
    "diffHunk": "@@ -338,15 +338,18 @@ public void appendRowUntilExceedingCapacity() throws Exception {\n \n   @Test\n   public void appendRowUntilExceedingPageSize() throws Exception {\n+    // Use of this property prevents issues when running on a two core machine\n+    // A developer may override this size to 1 MB not 64 MB, so use that if so\n+    int pageSizeToUse = Integer.parseInt(System.getProperty(\"spark.buffer.pageSize\"));"
  }],
  "prId": 15079
}]