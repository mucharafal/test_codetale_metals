[{
  "comments": [{
    "author": {
      "login": "jodersky"
    },
    "body": "This test fails on my Debian Stretch installation:\n`java.lang.AssertionError: expected:<-626931337744172849> but was:<3803688792395291579>`\n\nDigging through the code, it seems that the root cause is `sun.misc.Unsafe#arrayBaseOffset(int[].class)` returning something different on my machine.\n\njava -version:\n\n```\nopenjdk version \"1.8.0_72-internal\"\nOpenJDK Runtime Environment (build 1.8.0_72-internal-b05)\nOpenJDK 64-Bit Server VM (build 25.72-b05, mixed mode)\n```\n",
    "commit": "fcb25c2d252ad89ac60626b67f85e81e7564617e",
    "createdAt": "2016-02-16T00:18:59Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.spark.unsafe.Platform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test the XXH64 function.\n+ *\n+ * Test constants were taken from the original implementation and the airlift/slice implementation.\n+ */\n+public class XXH64Suite {\n+\n+  private static final XXH64 hasher = new XXH64(0);\n+\n+  private static final int SIZE = 101;\n+  private static final long PRIME = 2654435761L;\n+  private static final byte[] BUFFER = new byte[SIZE];\n+  private static final int TEST_INT = Platform.getInt(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+  private static final long TEST_LONG = Platform.getLong(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+\n+  /* Create the test data buffer. */\n+  static {\n+    long seed = PRIME;\n+    for (int i = 0; i < SIZE; i++) {\n+      BUFFER[i] = (byte)(seed >> 24);\n+      seed *= seed;\n+    }\n+  }\n+\n+  @Test\n+  public void testKnownIntegerInputs() {\n+    Assert.assertEquals(0x9256E58AA397AEF1L, hasher.hashInt(TEST_INT));",
    "line": 56
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "weird, even `sun.misc.Unsafe#arrayBaseOffset(int[].class)` returning something different, `TEST_INT` logically is just parsing first 4 bytes of `BUFFER` to an integer, it should be platform independent.\n",
    "commit": "fcb25c2d252ad89ac60626b67f85e81e7564617e",
    "createdAt": "2016-02-16T00:58:07Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.spark.unsafe.Platform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test the XXH64 function.\n+ *\n+ * Test constants were taken from the original implementation and the airlift/slice implementation.\n+ */\n+public class XXH64Suite {\n+\n+  private static final XXH64 hasher = new XXH64(0);\n+\n+  private static final int SIZE = 101;\n+  private static final long PRIME = 2654435761L;\n+  private static final byte[] BUFFER = new byte[SIZE];\n+  private static final int TEST_INT = Platform.getInt(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+  private static final long TEST_LONG = Platform.getLong(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+\n+  /* Create the test data buffer. */\n+  static {\n+    long seed = PRIME;\n+    for (int i = 0; i < SIZE; i++) {\n+      BUFFER[i] = (byte)(seed >> 24);\n+      seed *= seed;\n+    }\n+  }\n+\n+  @Test\n+  public void testKnownIntegerInputs() {\n+    Assert.assertEquals(0x9256E58AA397AEF1L, hasher.hashInt(TEST_INT));",
    "line": 56
  }, {
    "author": {
      "login": "jodersky"
    },
    "body": "I just saw that CI also fails. @hvanhovell, is the expected number correct? does the testsuite pass on your local machine?\n",
    "commit": "fcb25c2d252ad89ac60626b67f85e81e7564617e",
    "createdAt": "2016-02-16T01:10:35Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.spark.unsafe.Platform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test the XXH64 function.\n+ *\n+ * Test constants were taken from the original implementation and the airlift/slice implementation.\n+ */\n+public class XXH64Suite {\n+\n+  private static final XXH64 hasher = new XXH64(0);\n+\n+  private static final int SIZE = 101;\n+  private static final long PRIME = 2654435761L;\n+  private static final byte[] BUFFER = new byte[SIZE];\n+  private static final int TEST_INT = Platform.getInt(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+  private static final long TEST_LONG = Platform.getLong(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+\n+  /* Create the test data buffer. */\n+  static {\n+    long seed = PRIME;\n+    for (int i = 0; i < SIZE; i++) {\n+      BUFFER[i] = (byte)(seed >> 24);\n+      seed *= seed;\n+    }\n+  }\n+\n+  @Test\n+  public void testKnownIntegerInputs() {\n+    Assert.assertEquals(0x9256E58AA397AEF1L, hasher.hashInt(TEST_INT));",
    "line": 56
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "Is this assertion endian independent?  I think that this assertion assumes little-endian. s.m.u.getInt() and s.m.u.getLong fetch data by using machine native endian.\nhttp://java-performance.info/various-methods-of-binary-serialization-in-java/\n",
    "commit": "fcb25c2d252ad89ac60626b67f85e81e7564617e",
    "createdAt": "2016-03-14T17:26:53Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.spark.unsafe.Platform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test the XXH64 function.\n+ *\n+ * Test constants were taken from the original implementation and the airlift/slice implementation.\n+ */\n+public class XXH64Suite {\n+\n+  private static final XXH64 hasher = new XXH64(0);\n+\n+  private static final int SIZE = 101;\n+  private static final long PRIME = 2654435761L;\n+  private static final byte[] BUFFER = new byte[SIZE];\n+  private static final int TEST_INT = Platform.getInt(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+  private static final long TEST_LONG = Platform.getLong(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+\n+  /* Create the test data buffer. */\n+  static {\n+    long seed = PRIME;\n+    for (int i = 0; i < SIZE; i++) {\n+      BUFFER[i] = (byte)(seed >> 24);\n+      seed *= seed;\n+    }\n+  }\n+\n+  @Test\n+  public void testKnownIntegerInputs() {\n+    Assert.assertEquals(0x9256E58AA397AEF1L, hasher.hashInt(TEST_INT));",
    "line": 56
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "@kiszk first of, the problem @jodersky and @cloud-fan are discussing here has been fixed.\n\nAs for endianness I can guarantee that this works on little endian. I do not have the hardware lying arround to test this on big endian platforms; it'll be great if someone could pick this up. The algorithm itself contains a few shifts that might be problematic if you want the same results on LE and BE. The constants I use in the tests come from the original tests. I presume that they imply  LE, but again I am no expert.\n",
    "commit": "fcb25c2d252ad89ac60626b67f85e81e7564617e",
    "createdAt": "2016-03-14T18:04:08Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.spark.unsafe.Platform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test the XXH64 function.\n+ *\n+ * Test constants were taken from the original implementation and the airlift/slice implementation.\n+ */\n+public class XXH64Suite {\n+\n+  private static final XXH64 hasher = new XXH64(0);\n+\n+  private static final int SIZE = 101;\n+  private static final long PRIME = 2654435761L;\n+  private static final byte[] BUFFER = new byte[SIZE];\n+  private static final int TEST_INT = Platform.getInt(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+  private static final long TEST_LONG = Platform.getLong(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+\n+  /* Create the test data buffer. */\n+  static {\n+    long seed = PRIME;\n+    for (int i = 0; i < SIZE; i++) {\n+      BUFFER[i] = (byte)(seed >> 24);\n+      seed *= seed;\n+    }\n+  }\n+\n+  @Test\n+  public void testKnownIntegerInputs() {\n+    Assert.assertEquals(0x9256E58AA397AEF1L, hasher.hashInt(TEST_INT));",
    "line": 56
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "@hvanhovell , when I ran this test on a BE environment, three assertion failures occurred.\n\nA short script at the last line is a test that checks endian of this environment, as described [here](http://stackoverflow.com/questions/26859098/testing-endianness-of-system-with-the-unix-shell)\n\n```\n$ build/mvn  -pl 'sql/catalyst'  -DwildcardSuites=\"org.apache.spark.sql.catalyst.expressions.X*\" test\n...\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nOpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0\nRunning org.apache.spark.sql.catalyst.expressions.XXH64Suite\nTests run: 6, Failures: 3, Errors: 0, Skipped: 0, Time elapsed: 0.64 sec <<< FAILURE! - in org.apache.spark.sql.catalyst.expressions.XXH64Suite\ntestKnownLongInputs(org.apache.spark.sql.catalyst.expressions.XXH64Suite)  Time elapsed: 0.007 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<-626931337744172849> but was:<9051962445396881414>\n    at org.apache.spark.sql.catalyst.expressions.XXH64Suite.testKnownLongInputs(XXH64Suite.java:63)\n\ntestKnownIntegerInputs(org.apache.spark.sql.catalyst.expressions.XXH64Suite)  Time elapsed: 0 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<-7901876112562082063> but was:<9189406001848835548>\n    at org.apache.spark.sql.catalyst.expressions.XXH64Suite.testKnownIntegerInputs(XXH64Suite.java:57)\n\ntestKnownByteArrayInputs(org.apache.spark.sql.catalyst.expressions.XXH64Suite)  Time elapsed: 0.001 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<-7901876112562082063> but was:<9189406001848835548>\n    at org.apache.spark.sql.catalyst.expressions.XXH64Suite.testKnownByteArrayInputs(XXH64Suite.java:77)\n\n\nResults :\n\nFailed tests: \n  XXH64Suite.testKnownByteArrayInputs:77 expected:<-7901876112562082063> but was:<9189406001848835548>\n  XXH64Suite.testKnownIntegerInputs:57 expected:<-7901876112562082063> but was:<9189406001848835548>\n  XXH64Suite.testKnownLongInputs:63 expected:<-626931337744172849> but was:<9051962445396881414>\n\nTests run: 6, Failures: 3, Errors: 0, Skipped: 0\n...\n$ java -version\nopenjdk version \"1.8.0_72\"\nOpenJDK Runtime Environment (build 1.8.0_72-b15)\nOpenJDK 64-Bit Server VM (build 25.72-b15, mixed mode)\n$ printf '\\1' | od -dAn\n   256\n$\n```\n",
    "commit": "fcb25c2d252ad89ac60626b67f85e81e7564617e",
    "createdAt": "2016-03-15T12:32:28Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.spark.unsafe.Platform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test the XXH64 function.\n+ *\n+ * Test constants were taken from the original implementation and the airlift/slice implementation.\n+ */\n+public class XXH64Suite {\n+\n+  private static final XXH64 hasher = new XXH64(0);\n+\n+  private static final int SIZE = 101;\n+  private static final long PRIME = 2654435761L;\n+  private static final byte[] BUFFER = new byte[SIZE];\n+  private static final int TEST_INT = Platform.getInt(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+  private static final long TEST_LONG = Platform.getLong(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+\n+  /* Create the test data buffer. */\n+  static {\n+    long seed = PRIME;\n+    for (int i = 0; i < SIZE; i++) {\n+      BUFFER[i] = (byte)(seed >> 24);\n+      seed *= seed;\n+    }\n+  }\n+\n+  @Test\n+  public void testKnownIntegerInputs() {\n+    Assert.assertEquals(0x9256E58AA397AEF1L, hasher.hashInt(TEST_INT));",
    "line": 56
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "@kiszk does the `Murmur3_x86_32Suite` pass? That should be equally problematic.\n\nThe good news is that the test constants are the same. The problem is caused by the `Platform.get*...` methods, there has been discussion/controversy/PRs to make these methods endian aware. This PR however is not place to fix this.\n\nI can make some of the tests pass by hardcoding the `TEST_INT` and `TEST_LONG` values. The `testKnownByteArrayInputs` is not easily fixable because of the heavy use of `Platform.get*...` methods.\n\nIf you want to have a high quality 64-bit hash code this is still a safe bet. But you really shouldn't use it in a mixed endian setting.\n",
    "commit": "fcb25c2d252ad89ac60626b67f85e81e7564617e",
    "createdAt": "2016-03-15T13:29:44Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.spark.unsafe.Platform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test the XXH64 function.\n+ *\n+ * Test constants were taken from the original implementation and the airlift/slice implementation.\n+ */\n+public class XXH64Suite {\n+\n+  private static final XXH64 hasher = new XXH64(0);\n+\n+  private static final int SIZE = 101;\n+  private static final long PRIME = 2654435761L;\n+  private static final byte[] BUFFER = new byte[SIZE];\n+  private static final int TEST_INT = Platform.getInt(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+  private static final long TEST_LONG = Platform.getLong(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+\n+  /* Create the test data buffer. */\n+  static {\n+    long seed = PRIME;\n+    for (int i = 0; i < SIZE; i++) {\n+      BUFFER[i] = (byte)(seed >> 24);\n+      seed *= seed;\n+    }\n+  }\n+\n+  @Test\n+  public void testKnownIntegerInputs() {\n+    Assert.assertEquals(0x9256E58AA397AEF1L, hasher.hashInt(TEST_INT));",
    "line": 56
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "@hvanhovell , `MurMur3_x86_32Suite` passed. When I see [the test](https://github.com/apache/spark/blob/master/common/unsafe/src/test/java/org/apache/spark/unsafe/hash/Murmur3_x86_32Suite.java) , it seems to avoid comparison with a constant if a target method uses `Platform.get*...`. I am not sure whether this strategy is good.\n\nDo you want to create the same hash value from a given array `BUFFER` on BE and LE? Or, do you accept the different hash value among BE and LE?  For now, we really should not this function in a mixed endian environment (e.g. some machines for BE, other machines for LE).\n\n```\n$ build/mvn  -pl 'common/unsafe'  -DwildcardSuites=\"org.apache.spark.unsafe.hash.M*\" test\n...\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nOpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0\nRunning org.apache.spark.unsafe.array.LongArraySuite\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.057 sec - in org.apache.spark.unsafe.array.LongArraySuite\nRunning org.apache.spark.unsafe.PlatformUtilSuite\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.037 sec - in org.apache.spark.unsafe.PlatformUtilSuite\nRunning org.apache.spark.unsafe.types.UTF8StringSuite\nTests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.069 sec - in org.apache.spark.unsafe.types.UTF8StringSuite\nRunning org.apache.spark.unsafe.types.CalendarIntervalSuite\nTests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec - in org.apache.spark.unsafe.types.CalendarIntervalSuite\nRunning org.apache.spark.unsafe.hash.Murmur3_x86_32Suite\nTests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.604 sec - in org.apache.spark.unsafe.hash.Murmur3_x86_32Suite\n\nResults :\n\nTests run: 40, Failures: 0, Errors: 0, Skipped: 0\n\n[INFO] \n[INFO] --- scalatest-maven-plugin:1.0:test (test) @ spark-unsafe_2.11 ---\nOpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0\nDiscovery starting.\nDiscovery completed in 159 milliseconds.\nRun starting. Expected test count is: 0\nDiscoverySuite:\nRun completed in 253 milliseconds.\nTotal number of tests run: 0\nSuites: completed 1, aborted 0\nTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0\nNo tests were executed.\n...\n```\n",
    "commit": "fcb25c2d252ad89ac60626b67f85e81e7564617e",
    "createdAt": "2016-03-15T15:44:19Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.spark.unsafe.Platform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test the XXH64 function.\n+ *\n+ * Test constants were taken from the original implementation and the airlift/slice implementation.\n+ */\n+public class XXH64Suite {\n+\n+  private static final XXH64 hasher = new XXH64(0);\n+\n+  private static final int SIZE = 101;\n+  private static final long PRIME = 2654435761L;\n+  private static final byte[] BUFFER = new byte[SIZE];\n+  private static final int TEST_INT = Platform.getInt(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+  private static final long TEST_LONG = Platform.getLong(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+\n+  /* Create the test data buffer. */\n+  static {\n+    long seed = PRIME;\n+    for (int i = 0; i < SIZE; i++) {\n+      BUFFER[i] = (byte)(seed >> 24);\n+      seed *= seed;\n+    }\n+  }\n+\n+  @Test\n+  public void testKnownIntegerInputs() {\n+    Assert.assertEquals(0x9256E58AA397AEF1L, hasher.hashInt(TEST_INT));",
    "line": 56
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "@kiszk I have updated the tests; they should work now on BE. Could you do another round of testing on BE?\n\nAny function that uses `Platform.get*` shouldn't be used in a mixed endian setting. That includes  `Murmur3_x86_32` and quite a large part of Spark (SQL). \n",
    "commit": "fcb25c2d252ad89ac60626b67f85e81e7564617e",
    "createdAt": "2016-03-15T22:10:37Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.spark.unsafe.Platform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test the XXH64 function.\n+ *\n+ * Test constants were taken from the original implementation and the airlift/slice implementation.\n+ */\n+public class XXH64Suite {\n+\n+  private static final XXH64 hasher = new XXH64(0);\n+\n+  private static final int SIZE = 101;\n+  private static final long PRIME = 2654435761L;\n+  private static final byte[] BUFFER = new byte[SIZE];\n+  private static final int TEST_INT = Platform.getInt(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+  private static final long TEST_LONG = Platform.getLong(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+\n+  /* Create the test data buffer. */\n+  static {\n+    long seed = PRIME;\n+    for (int i = 0; i < SIZE; i++) {\n+      BUFFER[i] = (byte)(seed >> 24);\n+      seed *= seed;\n+    }\n+  }\n+\n+  @Test\n+  public void testKnownIntegerInputs() {\n+    Assert.assertEquals(0x9256E58AA397AEF1L, hasher.hashInt(TEST_INT));",
    "line": 56
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "@hvanhovell , thanks. The tests passed well.\n\n```\n$ git log -n 1\ncommit 79af847a491abe186e3cc88e0d9352e6a99b1b3e\nAuthor: Herman van Hovell <hvanhovell@questtec.nl>\nDate:   Tue Mar 15 20:53:57 2016 +0100\n\n    Make test pass in Big Endian platforms.\n\n$ build/mvn  -pl 'sql/catalyst'  -DwildcardSuites=\"org.apache.spark.sql.catalyst.expressions.X*\" test\n...\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nOpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0\nRunning org.apache.spark.sql.catalyst.expressions.XXH64Suite\nTests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.628 sec - in org.apache.spark.sql.catalyst.expressions.XXH64Suite\n\nResults :\n\nTests run: 6, Failures: 0, Errors: 0, Skipped: 0\n\n[INFO] \n[INFO] --- scalatest-maven-plugin:1.0:test (test) @ spark-catalyst_2.11 ---\nOpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0\nDiscovery starting.\nDiscovery completed in 2 seconds, 104 milliseconds.\nRun starting. Expected test count is: 0\nDiscoverySuite:\nRun completed in 2 seconds, 172 milliseconds.\nTotal number of tests run: 0\nSuites: completed 1, aborted 0\nTests: succeeded 0, failed 0, canceled 0, ignored 0, pending 0\nNo tests were executed.\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 02:46 min\n[INFO] Finished at: 2016-03-16T14:55:37+09:00\n[INFO] Final Memory: 47M/444M\n[INFO] ------------------------------------------------------------------------\n$\n```\n",
    "commit": "fcb25c2d252ad89ac60626b67f85e81e7564617e",
    "createdAt": "2016-03-16T06:30:51Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.spark.unsafe.Platform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test the XXH64 function.\n+ *\n+ * Test constants were taken from the original implementation and the airlift/slice implementation.\n+ */\n+public class XXH64Suite {\n+\n+  private static final XXH64 hasher = new XXH64(0);\n+\n+  private static final int SIZE = 101;\n+  private static final long PRIME = 2654435761L;\n+  private static final byte[] BUFFER = new byte[SIZE];\n+  private static final int TEST_INT = Platform.getInt(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+  private static final long TEST_LONG = Platform.getLong(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+\n+  /* Create the test data buffer. */\n+  static {\n+    long seed = PRIME;\n+    for (int i = 0; i < SIZE; i++) {\n+      BUFFER[i] = (byte)(seed >> 24);\n+      seed *= seed;\n+    }\n+  }\n+\n+  @Test\n+  public void testKnownIntegerInputs() {\n+    Assert.assertEquals(0x9256E58AA397AEF1L, hasher.hashInt(TEST_INT));",
    "line": 56
  }],
  "prId": 11209
}, {
  "comments": [{
    "author": {
      "login": "jodersky"
    },
    "body": "I get a similar error to `testKnownIntegerInputs()`\n",
    "commit": "fcb25c2d252ad89ac60626b67f85e81e7564617e",
    "createdAt": "2016-02-16T00:19:43Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.expressions;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.spark.unsafe.Platform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test the XXH64 function.\n+ *\n+ * Test constants were taken from the original implementation and the airlift/slice implementation.\n+ */\n+public class XXH64Suite {\n+\n+  private static final XXH64 hasher = new XXH64(0);\n+\n+  private static final int SIZE = 101;\n+  private static final long PRIME = 2654435761L;\n+  private static final byte[] BUFFER = new byte[SIZE];\n+  private static final int TEST_INT = Platform.getInt(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+  private static final long TEST_LONG = Platform.getLong(BUFFER, Platform.BYTE_ARRAY_OFFSET);\n+\n+  /* Create the test data buffer. */\n+  static {\n+    long seed = PRIME;\n+    for (int i = 0; i < SIZE; i++) {\n+      BUFFER[i] = (byte)(seed >> 24);\n+      seed *= seed;\n+    }\n+  }\n+\n+  @Test\n+  public void testKnownIntegerInputs() {\n+    Assert.assertEquals(0x9256E58AA397AEF1L, hasher.hashInt(TEST_INT));\n+    Assert.assertEquals(0x9D5FFDFB928AB4BL, XXH64.hashInt(TEST_INT, PRIME));\n+  }\n+\n+  @Test\n+  public void testKnownLongInputs() {\n+    Assert.assertEquals(0xF74CB1451B32B8CFL, hasher.hashLong(TEST_LONG));\n+    Assert.assertEquals(0x9C44B77FBCC302C5L, XXH64.hashLong(TEST_LONG, PRIME));",
    "line": 63
  }],
  "prId": 11209
}]