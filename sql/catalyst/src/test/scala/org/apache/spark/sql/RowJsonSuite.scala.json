[{
  "comments": [{
    "author": {
      "login": "MaxGekk"
    },
    "body": "Why did you forcibly set it to `UTC`?",
    "commit": "43c2d249614359e80f61c275b16e0a498abcb842",
    "createdAt": "2019-10-04T11:45:17Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import java.sql.{Date, Timestamp}\n+import java.time.{Instant, LocalDate}\n+\n+import org.json4s.JsonAST.{JArray, JBool, JDecimal, JDouble, JLong, JNull, JObject, JString, JValue}\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.encoders.{ExamplePoint, ExamplePointUDT}\n+import org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Test suite for [[Row]] JSON serialization.\n+ */\n+class RowJsonSuite extends SparkFunSuite {\n+  private val schema = new StructType()\n+    .add(\"c1\", \"string\")\n+    .add(\"c2\", IntegerType)\n+\n+  private val conf: SQLConf = {\n+    val conf = new SQLConf\n+    conf.setConf(SQLConf.SESSION_LOCAL_TIMEZONE, \"UTC\")"
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "`Instant.parse(..)` parse a UTC instant, if I don't set the timezone to UTC then it makes comparing the test input and output harder.",
    "commit": "43c2d249614359e80f61c275b16e0a498abcb842",
    "createdAt": "2019-10-04T11:58:30Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import java.sql.{Date, Timestamp}\n+import java.time.{Instant, LocalDate}\n+\n+import org.json4s.JsonAST.{JArray, JBool, JDecimal, JDouble, JLong, JNull, JObject, JString, JValue}\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.encoders.{ExamplePoint, ExamplePointUDT}\n+import org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Test suite for [[Row]] JSON serialization.\n+ */\n+class RowJsonSuite extends SparkFunSuite {\n+  private val schema = new StructType()\n+    .add(\"c1\", \"string\")\n+    .add(\"c2\", IntegerType)\n+\n+  private val conf: SQLConf = {\n+    val conf = new SQLConf\n+    conf.setConf(SQLConf.SESSION_LOCAL_TIMEZONE, \"UTC\")"
  }, {
    "author": {
      "login": "MaxGekk"
    },
    "body": "If you would remove this config settings, you can replace:\r\n```scala\r\n  testJson(\r\n    new Timestamp(Instant.parse(\"2017-01-06T10:22:03.00Z\").toEpochMilli),\r\n    TimestampType,\r\n    JString(\"2017-01-06 10:22:03\"))\r\n  testJson(\r\n    Instant.parse(\"2017-05-30T10:22:03.00Z\"),\r\n    TimestampType,\r\n    JString(\"2017-05-30 10:22:03\"))\r\n```\r\nby\r\n```scala\r\n  testJson(\r\n    Timestamp.valueOf(\"2017-01-06 10:22:03.00\"),\r\n    TimestampType,\r\n    JString(\"2017-01-06 10:22:03\"))\r\n  testJson(\r\n    Timestamp.valueOf(\"2017-05-30 10:22:03.00\").toInstant,\r\n    TimestampType,\r\n    JString(\"2017-05-30 10:22:03\"))\r\n```",
    "commit": "43c2d249614359e80f61c275b16e0a498abcb842",
    "createdAt": "2019-10-04T17:10:05Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import java.sql.{Date, Timestamp}\n+import java.time.{Instant, LocalDate}\n+\n+import org.json4s.JsonAST.{JArray, JBool, JDecimal, JDouble, JLong, JNull, JObject, JString, JValue}\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.encoders.{ExamplePoint, ExamplePointUDT}\n+import org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Test suite for [[Row]] JSON serialization.\n+ */\n+class RowJsonSuite extends SparkFunSuite {\n+  private val schema = new StructType()\n+    .add(\"c1\", \"string\")\n+    .add(\"c2\", IntegerType)\n+\n+  private val conf: SQLConf = {\n+    val conf = new SQLConf\n+    conf.setConf(SQLConf.SESSION_LOCAL_TIMEZONE, \"UTC\")"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "+1",
    "commit": "43c2d249614359e80f61c275b16e0a498abcb842",
    "createdAt": "2019-10-07T09:14:16Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import java.sql.{Date, Timestamp}\n+import java.time.{Instant, LocalDate}\n+\n+import org.json4s.JsonAST.{JArray, JBool, JDecimal, JDouble, JLong, JNull, JObject, JString, JValue}\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.encoders.{ExamplePoint, ExamplePointUDT}\n+import org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Test suite for [[Row]] JSON serialization.\n+ */\n+class RowJsonSuite extends SparkFunSuite {\n+  private val schema = new StructType()\n+    .add(\"c1\", \"string\")\n+    .add(\"c2\", IntegerType)\n+\n+  private val conf: SQLConf = {\n+    val conf = new SQLConf\n+    conf.setConf(SQLConf.SESSION_LOCAL_TIMEZONE, \"UTC\")"
  }],
  "prId": 26013
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit: wrong indentation ",
    "commit": "43c2d249614359e80f61c275b16e0a498abcb842",
    "createdAt": "2019-10-09T14:43:36Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import java.sql.{Date, Timestamp}\n+import java.time.{Instant, LocalDate}\n+\n+import org.json4s.JsonAST.{JArray, JBool, JDecimal, JDouble, JLong, JNull, JObject, JString, JValue}\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.encoders.{ExamplePoint, ExamplePointUDT}\n+import org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Test suite for [[Row]] JSON serialization.\n+ */\n+class RowJsonSuite extends SparkFunSuite {\n+  private val schema = new StructType()\n+    .add(\"c1\", \"string\")\n+    .add(\"c2\", IntegerType)\n+\n+    private def testJson(name: String, value: Any, dt: DataType, expected: JValue): Unit = {"
  }],
  "prId": 26013
}]