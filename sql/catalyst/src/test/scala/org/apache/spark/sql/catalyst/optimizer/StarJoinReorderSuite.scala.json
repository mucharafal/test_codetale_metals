[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "2 `d3`, typo?",
    "commit": "891813ff7316ab06acfcf28a7268da65ac9fd4cf",
    "createdAt": "2017-03-20T08:02:52Z",
    "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.SimpleCatalystConf\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeMap}\n+import org.apache.spark.sql.catalyst.plans.{Inner, PlanTest}\n+import org.apache.spark.sql.catalyst.plans.logical.{ColumnStat, LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.catalyst.statsEstimation.{StatsEstimationTestBase, StatsTestPlan}\n+\n+\n+class StarJoinReorderSuite extends PlanTest with StatsEstimationTestBase {\n+\n+  override val conf = SimpleCatalystConf(\n+    caseSensitiveAnalysis = true, starSchemaDetection = true)\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Operator Optimizations\", FixedPoint(100),\n+        CombineFilters,\n+        PushDownPredicate,\n+        ReorderJoin(conf),\n+        PushPredicateThroughJoin,\n+        ColumnPruning,\n+        CollapseProject) :: Nil\n+  }\n+\n+  // Table setup using star schema relationships:\n+  //\n+  // d1 - f1 - d2\n+  //      |\n+  //      d3 - s3\n+  //\n+  // Table f1 is the fact table. Tables d1, d2, and d3 are the dimension tables.\n+  // Dimension d3 is further joined/normalized into table s3.\n+  // Tables' cardinality: f1 > d3 > d1 > d2 > s3\n+  private val columnInfo: AttributeMap[ColumnStat] = AttributeMap(Seq(\n+    // F1\n+    attr(\"f1_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_fk2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_fk3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_c4\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D1\n+    attr(\"d1_pk1\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c4\") -> ColumnStat(distinctCount = 2, min = Some(2), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D2\n+    attr(\"d2_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 1, avgLen = 4, maxLen = 4),\n+    attr(\"d2_pk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d2_c3\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d2_c4\") -> ColumnStat(distinctCount = 2, min = Some(3), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D3\n+    attr(\"d3_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_pk1\") -> ColumnStat(distinctCount = 5, min = Some(1), max = Some(5),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_c4\") -> ColumnStat(distinctCount = 2, min = Some(2), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // S3\n+    attr(\"s3_pk1\") -> ColumnStat(distinctCount = 2, min = Some(1), max = Some(2),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c2\") -> ColumnStat(distinctCount = 1, min = Some(3), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c3\") -> ColumnStat(distinctCount = 1, min = Some(3), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c4\") -> ColumnStat(distinctCount = 2, min = Some(3), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // F11\n+    attr(\"f11_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_fk2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_fk3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_c4\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4)\n+  ))\n+\n+  private val nameToAttr: Map[String, Attribute] = columnInfo.map(kv => kv._1.name -> kv._1)\n+  private val nameToColInfo: Map[String, (Attribute, ColumnStat)] =\n+    columnInfo.map(kv => kv._1.name -> kv)\n+\n+  private val f1 = StatsTestPlan(\n+    outputList = Seq(\"f1_fk1\", \"f1_fk2\", \"f1_fk3\", \"f1_c4\").map(nameToAttr),\n+    rowCount = 6,\n+    size = Some(48),\n+    attributeStats = AttributeMap(Seq(\"f1_fk1\", \"f1_fk2\", \"f1_fk3\", \"f1_c4\").map(nameToColInfo)))\n+\n+  private val d1 = StatsTestPlan(\n+    outputList = Seq(\"d1_pk1\", \"d1_c2\", \"d1_c3\", \"d1_c4\").map(nameToAttr),\n+    rowCount = 4,\n+    size = Some(32),\n+    attributeStats = AttributeMap(Seq(\"d1_pk1\", \"d1_c2\", \"d1_c3\", \"d1_c4\").map(nameToColInfo)))\n+\n+  private val d2 = StatsTestPlan(\n+    outputList = Seq(\"d2_c2\", \"d2_pk1\", \"d2_c3\", \"d2_c4\").map(nameToAttr),\n+    rowCount = 3,\n+    size = Some(24),\n+    attributeStats = AttributeMap(Seq(\"d2_c2\", \"d2_pk1\", \"d2_c3\", \"d2_c4\").map(nameToColInfo)))\n+\n+  private val d3 = StatsTestPlan(\n+    outputList = Seq(\"d3_fk1\", \"d3_c2\", \"d3_pk1\", \"d3_c4\").map(nameToAttr),\n+    rowCount = 5,\n+    size = Some(40),\n+    attributeStats = AttributeMap(Seq(\"d3_fk1\", \"d3_c2\", \"d3_pk1\", \"d3_c4\").map(nameToColInfo)))\n+\n+  private val s3 = StatsTestPlan(\n+    outputList = Seq(\"s3_pk1\", \"s3_c2\", \"s3_c3\", \"s3_c4\").map(nameToAttr),\n+    rowCount = 2,\n+    size = Some(17),\n+    attributeStats = AttributeMap(Seq(\"s3_pk1\", \"s3_c2\", \"s3_c3\", \"s3_c4\").map(nameToColInfo)))\n+\n+  private val d3_ns = LocalRelation('d3_fk1.int, 'd3_c2.int, 'd3_pk1.int, 'd3_c4.int)\n+\n+  private val f11 = StatsTestPlan(\n+    outputList = Seq(\"f11_fk1\", \"f11_fk2\", \"f11_fk3\", \"f11_c4\").map(nameToAttr),\n+    rowCount = 6,\n+    size = Some(48),\n+    attributeStats = AttributeMap(Seq(\"f11_fk1\", \"f11_fk2\", \"f11_fk3\", \"f11_c4\")\n+      .map(nameToColInfo)))\n+\n+  private val subq = d3.select(sum('d3_fk1).as('col))\n+\n+  test(\"Test 1: Selective star-join on all dimensions\") {\n+    // Star join:\n+    //   (=)  (=)\n+    // d1 - f1 - d2\n+    //      | (=)\n+    //      s3 - d3\n+    //\n+    // Query:\n+    //  select f1_fk1, f1_fk3\n+    //  from d1, d2, f1, d3, s3\n+    //  where f1_fk2 = d2_pk1 and d2_c2 < 2\n+    //  and f1_fk1 = d1_pk1\n+    //  and f1_fk3 = d3_pk1\n+    //  and d3_fk1 = s3_pk1\n+    //\n+    // Positional join reordering: d1, f1, d2, d3, s3\n+    // Star join reordering: f1, d2, d1, d3, s3\n+    val query =\n+      d1.join(d2).join(f1).join(d3).join(s3)\n+        .where((nameToAttr(\"f1_fk2\") === nameToAttr(\"d2_pk1\")) &&\n+          (nameToAttr(\"d2_c2\") === 2) &&\n+          (nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")) &&\n+          (nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")) &&\n+          (nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    val expected =\n+      f1.join(d2.where(nameToAttr(\"d2_c2\") === 2), Inner,\n+          Some(nameToAttr(\"f1_fk2\") === nameToAttr(\"d2_pk1\")))\n+        .join(d1, Inner, Some(nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")))\n+        .join(d3, Inner, Some(nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")))\n+        .join(s3, Inner, Some(nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    assertEqualPlans(query, expected)\n+  }\n+\n+  test(\"Test 2: Star join on a subset of dimensions due to inequality joins\") {\n+    // Star join:\n+    //   (=)  (<)\n+    // d1 - f1 - d2\n+    //      |\n+    //      | (=)\n+    //      d3 - s3\n+    //        (=)\n+    //\n+    // Query:\n+    //  select f1_fk1, f1_fk3\n+    //  from d1, f1, d2, s3, d3\n+    //  where f1_fk2 < d2_pk1\n+    //  and f1_fk1 = d1_pk1 and d1_c2 = 2\n+    //  and f1_fk3 = d3_pk1\n+    //  and d3_fk1 = s3_pk1\n+    //\n+    // Default join reordering: d1, f1, d2, d3, s3\n+    // Star join reordering: f1, d1, d3, d2,, d3",
    "line": 210
  }, {
    "author": {
      "login": "ioana-delaney"
    },
    "body": "@cloud-fan It's a typo. I will fix in my next PR.",
    "commit": "891813ff7316ab06acfcf28a7268da65ac9fd4cf",
    "createdAt": "2017-03-20T21:14:41Z",
    "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.SimpleCatalystConf\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeMap}\n+import org.apache.spark.sql.catalyst.plans.{Inner, PlanTest}\n+import org.apache.spark.sql.catalyst.plans.logical.{ColumnStat, LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.catalyst.statsEstimation.{StatsEstimationTestBase, StatsTestPlan}\n+\n+\n+class StarJoinReorderSuite extends PlanTest with StatsEstimationTestBase {\n+\n+  override val conf = SimpleCatalystConf(\n+    caseSensitiveAnalysis = true, starSchemaDetection = true)\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Operator Optimizations\", FixedPoint(100),\n+        CombineFilters,\n+        PushDownPredicate,\n+        ReorderJoin(conf),\n+        PushPredicateThroughJoin,\n+        ColumnPruning,\n+        CollapseProject) :: Nil\n+  }\n+\n+  // Table setup using star schema relationships:\n+  //\n+  // d1 - f1 - d2\n+  //      |\n+  //      d3 - s3\n+  //\n+  // Table f1 is the fact table. Tables d1, d2, and d3 are the dimension tables.\n+  // Dimension d3 is further joined/normalized into table s3.\n+  // Tables' cardinality: f1 > d3 > d1 > d2 > s3\n+  private val columnInfo: AttributeMap[ColumnStat] = AttributeMap(Seq(\n+    // F1\n+    attr(\"f1_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_fk2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_fk3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_c4\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D1\n+    attr(\"d1_pk1\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c4\") -> ColumnStat(distinctCount = 2, min = Some(2), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D2\n+    attr(\"d2_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 1, avgLen = 4, maxLen = 4),\n+    attr(\"d2_pk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d2_c3\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d2_c4\") -> ColumnStat(distinctCount = 2, min = Some(3), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D3\n+    attr(\"d3_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_pk1\") -> ColumnStat(distinctCount = 5, min = Some(1), max = Some(5),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_c4\") -> ColumnStat(distinctCount = 2, min = Some(2), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // S3\n+    attr(\"s3_pk1\") -> ColumnStat(distinctCount = 2, min = Some(1), max = Some(2),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c2\") -> ColumnStat(distinctCount = 1, min = Some(3), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c3\") -> ColumnStat(distinctCount = 1, min = Some(3), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c4\") -> ColumnStat(distinctCount = 2, min = Some(3), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // F11\n+    attr(\"f11_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_fk2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_fk3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_c4\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4)\n+  ))\n+\n+  private val nameToAttr: Map[String, Attribute] = columnInfo.map(kv => kv._1.name -> kv._1)\n+  private val nameToColInfo: Map[String, (Attribute, ColumnStat)] =\n+    columnInfo.map(kv => kv._1.name -> kv)\n+\n+  private val f1 = StatsTestPlan(\n+    outputList = Seq(\"f1_fk1\", \"f1_fk2\", \"f1_fk3\", \"f1_c4\").map(nameToAttr),\n+    rowCount = 6,\n+    size = Some(48),\n+    attributeStats = AttributeMap(Seq(\"f1_fk1\", \"f1_fk2\", \"f1_fk3\", \"f1_c4\").map(nameToColInfo)))\n+\n+  private val d1 = StatsTestPlan(\n+    outputList = Seq(\"d1_pk1\", \"d1_c2\", \"d1_c3\", \"d1_c4\").map(nameToAttr),\n+    rowCount = 4,\n+    size = Some(32),\n+    attributeStats = AttributeMap(Seq(\"d1_pk1\", \"d1_c2\", \"d1_c3\", \"d1_c4\").map(nameToColInfo)))\n+\n+  private val d2 = StatsTestPlan(\n+    outputList = Seq(\"d2_c2\", \"d2_pk1\", \"d2_c3\", \"d2_c4\").map(nameToAttr),\n+    rowCount = 3,\n+    size = Some(24),\n+    attributeStats = AttributeMap(Seq(\"d2_c2\", \"d2_pk1\", \"d2_c3\", \"d2_c4\").map(nameToColInfo)))\n+\n+  private val d3 = StatsTestPlan(\n+    outputList = Seq(\"d3_fk1\", \"d3_c2\", \"d3_pk1\", \"d3_c4\").map(nameToAttr),\n+    rowCount = 5,\n+    size = Some(40),\n+    attributeStats = AttributeMap(Seq(\"d3_fk1\", \"d3_c2\", \"d3_pk1\", \"d3_c4\").map(nameToColInfo)))\n+\n+  private val s3 = StatsTestPlan(\n+    outputList = Seq(\"s3_pk1\", \"s3_c2\", \"s3_c3\", \"s3_c4\").map(nameToAttr),\n+    rowCount = 2,\n+    size = Some(17),\n+    attributeStats = AttributeMap(Seq(\"s3_pk1\", \"s3_c2\", \"s3_c3\", \"s3_c4\").map(nameToColInfo)))\n+\n+  private val d3_ns = LocalRelation('d3_fk1.int, 'd3_c2.int, 'd3_pk1.int, 'd3_c4.int)\n+\n+  private val f11 = StatsTestPlan(\n+    outputList = Seq(\"f11_fk1\", \"f11_fk2\", \"f11_fk3\", \"f11_c4\").map(nameToAttr),\n+    rowCount = 6,\n+    size = Some(48),\n+    attributeStats = AttributeMap(Seq(\"f11_fk1\", \"f11_fk2\", \"f11_fk3\", \"f11_c4\")\n+      .map(nameToColInfo)))\n+\n+  private val subq = d3.select(sum('d3_fk1).as('col))\n+\n+  test(\"Test 1: Selective star-join on all dimensions\") {\n+    // Star join:\n+    //   (=)  (=)\n+    // d1 - f1 - d2\n+    //      | (=)\n+    //      s3 - d3\n+    //\n+    // Query:\n+    //  select f1_fk1, f1_fk3\n+    //  from d1, d2, f1, d3, s3\n+    //  where f1_fk2 = d2_pk1 and d2_c2 < 2\n+    //  and f1_fk1 = d1_pk1\n+    //  and f1_fk3 = d3_pk1\n+    //  and d3_fk1 = s3_pk1\n+    //\n+    // Positional join reordering: d1, f1, d2, d3, s3\n+    // Star join reordering: f1, d2, d1, d3, s3\n+    val query =\n+      d1.join(d2).join(f1).join(d3).join(s3)\n+        .where((nameToAttr(\"f1_fk2\") === nameToAttr(\"d2_pk1\")) &&\n+          (nameToAttr(\"d2_c2\") === 2) &&\n+          (nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")) &&\n+          (nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")) &&\n+          (nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    val expected =\n+      f1.join(d2.where(nameToAttr(\"d2_c2\") === 2), Inner,\n+          Some(nameToAttr(\"f1_fk2\") === nameToAttr(\"d2_pk1\")))\n+        .join(d1, Inner, Some(nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")))\n+        .join(d3, Inner, Some(nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")))\n+        .join(s3, Inner, Some(nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    assertEqualPlans(query, expected)\n+  }\n+\n+  test(\"Test 2: Star join on a subset of dimensions due to inequality joins\") {\n+    // Star join:\n+    //   (=)  (<)\n+    // d1 - f1 - d2\n+    //      |\n+    //      | (=)\n+    //      d3 - s3\n+    //        (=)\n+    //\n+    // Query:\n+    //  select f1_fk1, f1_fk3\n+    //  from d1, f1, d2, s3, d3\n+    //  where f1_fk2 < d2_pk1\n+    //  and f1_fk1 = d1_pk1 and d1_c2 = 2\n+    //  and f1_fk3 = d3_pk1\n+    //  and d3_fk1 = s3_pk1\n+    //\n+    // Default join reordering: d1, f1, d2, d3, s3\n+    // Star join reordering: f1, d1, d3, d2,, d3",
    "line": 210
  }],
  "prId": 15363
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "the last `d3` should be `s3`",
    "commit": "891813ff7316ab06acfcf28a7268da65ac9fd4cf",
    "createdAt": "2017-03-20T08:03:53Z",
    "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.SimpleCatalystConf\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeMap}\n+import org.apache.spark.sql.catalyst.plans.{Inner, PlanTest}\n+import org.apache.spark.sql.catalyst.plans.logical.{ColumnStat, LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.catalyst.statsEstimation.{StatsEstimationTestBase, StatsTestPlan}\n+\n+\n+class StarJoinReorderSuite extends PlanTest with StatsEstimationTestBase {\n+\n+  override val conf = SimpleCatalystConf(\n+    caseSensitiveAnalysis = true, starSchemaDetection = true)\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Operator Optimizations\", FixedPoint(100),\n+        CombineFilters,\n+        PushDownPredicate,\n+        ReorderJoin(conf),\n+        PushPredicateThroughJoin,\n+        ColumnPruning,\n+        CollapseProject) :: Nil\n+  }\n+\n+  // Table setup using star schema relationships:\n+  //\n+  // d1 - f1 - d2\n+  //      |\n+  //      d3 - s3\n+  //\n+  // Table f1 is the fact table. Tables d1, d2, and d3 are the dimension tables.\n+  // Dimension d3 is further joined/normalized into table s3.\n+  // Tables' cardinality: f1 > d3 > d1 > d2 > s3\n+  private val columnInfo: AttributeMap[ColumnStat] = AttributeMap(Seq(\n+    // F1\n+    attr(\"f1_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_fk2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_fk3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_c4\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D1\n+    attr(\"d1_pk1\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c4\") -> ColumnStat(distinctCount = 2, min = Some(2), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D2\n+    attr(\"d2_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 1, avgLen = 4, maxLen = 4),\n+    attr(\"d2_pk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d2_c3\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d2_c4\") -> ColumnStat(distinctCount = 2, min = Some(3), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D3\n+    attr(\"d3_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_pk1\") -> ColumnStat(distinctCount = 5, min = Some(1), max = Some(5),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_c4\") -> ColumnStat(distinctCount = 2, min = Some(2), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // S3\n+    attr(\"s3_pk1\") -> ColumnStat(distinctCount = 2, min = Some(1), max = Some(2),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c2\") -> ColumnStat(distinctCount = 1, min = Some(3), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c3\") -> ColumnStat(distinctCount = 1, min = Some(3), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c4\") -> ColumnStat(distinctCount = 2, min = Some(3), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // F11\n+    attr(\"f11_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_fk2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_fk3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_c4\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4)\n+  ))\n+\n+  private val nameToAttr: Map[String, Attribute] = columnInfo.map(kv => kv._1.name -> kv._1)\n+  private val nameToColInfo: Map[String, (Attribute, ColumnStat)] =\n+    columnInfo.map(kv => kv._1.name -> kv)\n+\n+  private val f1 = StatsTestPlan(\n+    outputList = Seq(\"f1_fk1\", \"f1_fk2\", \"f1_fk3\", \"f1_c4\").map(nameToAttr),\n+    rowCount = 6,\n+    size = Some(48),\n+    attributeStats = AttributeMap(Seq(\"f1_fk1\", \"f1_fk2\", \"f1_fk3\", \"f1_c4\").map(nameToColInfo)))\n+\n+  private val d1 = StatsTestPlan(\n+    outputList = Seq(\"d1_pk1\", \"d1_c2\", \"d1_c3\", \"d1_c4\").map(nameToAttr),\n+    rowCount = 4,\n+    size = Some(32),\n+    attributeStats = AttributeMap(Seq(\"d1_pk1\", \"d1_c2\", \"d1_c3\", \"d1_c4\").map(nameToColInfo)))\n+\n+  private val d2 = StatsTestPlan(\n+    outputList = Seq(\"d2_c2\", \"d2_pk1\", \"d2_c3\", \"d2_c4\").map(nameToAttr),\n+    rowCount = 3,\n+    size = Some(24),\n+    attributeStats = AttributeMap(Seq(\"d2_c2\", \"d2_pk1\", \"d2_c3\", \"d2_c4\").map(nameToColInfo)))\n+\n+  private val d3 = StatsTestPlan(\n+    outputList = Seq(\"d3_fk1\", \"d3_c2\", \"d3_pk1\", \"d3_c4\").map(nameToAttr),\n+    rowCount = 5,\n+    size = Some(40),\n+    attributeStats = AttributeMap(Seq(\"d3_fk1\", \"d3_c2\", \"d3_pk1\", \"d3_c4\").map(nameToColInfo)))\n+\n+  private val s3 = StatsTestPlan(\n+    outputList = Seq(\"s3_pk1\", \"s3_c2\", \"s3_c3\", \"s3_c4\").map(nameToAttr),\n+    rowCount = 2,\n+    size = Some(17),\n+    attributeStats = AttributeMap(Seq(\"s3_pk1\", \"s3_c2\", \"s3_c3\", \"s3_c4\").map(nameToColInfo)))\n+\n+  private val d3_ns = LocalRelation('d3_fk1.int, 'd3_c2.int, 'd3_pk1.int, 'd3_c4.int)\n+\n+  private val f11 = StatsTestPlan(\n+    outputList = Seq(\"f11_fk1\", \"f11_fk2\", \"f11_fk3\", \"f11_c4\").map(nameToAttr),\n+    rowCount = 6,\n+    size = Some(48),\n+    attributeStats = AttributeMap(Seq(\"f11_fk1\", \"f11_fk2\", \"f11_fk3\", \"f11_c4\")\n+      .map(nameToColInfo)))\n+\n+  private val subq = d3.select(sum('d3_fk1).as('col))\n+\n+  test(\"Test 1: Selective star-join on all dimensions\") {\n+    // Star join:\n+    //   (=)  (=)\n+    // d1 - f1 - d2\n+    //      | (=)\n+    //      s3 - d3\n+    //\n+    // Query:\n+    //  select f1_fk1, f1_fk3\n+    //  from d1, d2, f1, d3, s3\n+    //  where f1_fk2 = d2_pk1 and d2_c2 < 2\n+    //  and f1_fk1 = d1_pk1\n+    //  and f1_fk3 = d3_pk1\n+    //  and d3_fk1 = s3_pk1\n+    //\n+    // Positional join reordering: d1, f1, d2, d3, s3\n+    // Star join reordering: f1, d2, d1, d3, s3\n+    val query =\n+      d1.join(d2).join(f1).join(d3).join(s3)\n+        .where((nameToAttr(\"f1_fk2\") === nameToAttr(\"d2_pk1\")) &&\n+          (nameToAttr(\"d2_c2\") === 2) &&\n+          (nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")) &&\n+          (nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")) &&\n+          (nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    val expected =\n+      f1.join(d2.where(nameToAttr(\"d2_c2\") === 2), Inner,\n+          Some(nameToAttr(\"f1_fk2\") === nameToAttr(\"d2_pk1\")))\n+        .join(d1, Inner, Some(nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")))\n+        .join(d3, Inner, Some(nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")))\n+        .join(s3, Inner, Some(nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    assertEqualPlans(query, expected)\n+  }\n+\n+  test(\"Test 2: Star join on a subset of dimensions due to inequality joins\") {\n+    // Star join:\n+    //   (=)  (<)\n+    // d1 - f1 - d2\n+    //      |\n+    //      | (=)\n+    //      d3 - s3\n+    //        (=)\n+    //\n+    // Query:\n+    //  select f1_fk1, f1_fk3\n+    //  from d1, f1, d2, s3, d3\n+    //  where f1_fk2 < d2_pk1\n+    //  and f1_fk1 = d1_pk1 and d1_c2 = 2\n+    //  and f1_fk3 = d3_pk1\n+    //  and d3_fk1 = s3_pk1\n+    //\n+    // Default join reordering: d1, f1, d2, d3, s3\n+    // Star join reordering: f1, d1, d3, d2,, d3\n+\n+    val query =\n+      d1.join(f1).join(d2).join(s3).join(d3)\n+        .where((nameToAttr(\"f1_fk2\") < nameToAttr(\"d2_pk1\")) &&\n+          (nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")) &&\n+          (nameToAttr(\"d1_c2\") === 2) &&\n+          (nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")) &&\n+          (nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    val expected =\n+      f1.join(d1.where(nameToAttr(\"d1_c2\") === 2), Inner,\n+          Some(nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")))\n+        .join(d3, Inner, Some(nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")))\n+        .join(d2, Inner, Some(nameToAttr(\"f1_fk2\") < nameToAttr(\"d2_pk1\")))\n+        .join(s3, Inner, Some(nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    assertEqualPlans(query, expected)\n+  }\n+\n+  test(\"Test 3:  Star join on a subset of dimensions since join column is not unique\") {\n+    // Star join:\n+    //   (=)  (=)\n+    // d1 - f1 - d2\n+    //      | (=)\n+    //      d3 - s3\n+    //\n+    // Query:\n+    //  select f1_fk1, f1_fk3\n+    //  from d1, f1, d2, s3, d3\n+    //  where f1_fk2 = d2_c4\n+    //  and f1_fk1 = d1_pk1 and d1_c2 = 2\n+    //  and f1_fk3 = d3_pk1\n+    //  and d3_fk1 = s3_pk1\n+    //\n+    // Default join reordering: d1, f1, d2, d3, s3\n+    // Star join reordering: f1, d1, d3, d2, d3",
    "line": 246
  }, {
    "author": {
      "login": "ioana-delaney"
    },
    "body": "@cloud-fan Yes, it's a typo like above. I did some small changes to the queries when I rewrote the test suite and didn't update the code comments properly. I will fix. Thanks!",
    "commit": "891813ff7316ab06acfcf28a7268da65ac9fd4cf",
    "createdAt": "2017-03-20T21:17:08Z",
    "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.catalyst.SimpleCatalystConf\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeMap}\n+import org.apache.spark.sql.catalyst.plans.{Inner, PlanTest}\n+import org.apache.spark.sql.catalyst.plans.logical.{ColumnStat, LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.catalyst.statsEstimation.{StatsEstimationTestBase, StatsTestPlan}\n+\n+\n+class StarJoinReorderSuite extends PlanTest with StatsEstimationTestBase {\n+\n+  override val conf = SimpleCatalystConf(\n+    caseSensitiveAnalysis = true, starSchemaDetection = true)\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Operator Optimizations\", FixedPoint(100),\n+        CombineFilters,\n+        PushDownPredicate,\n+        ReorderJoin(conf),\n+        PushPredicateThroughJoin,\n+        ColumnPruning,\n+        CollapseProject) :: Nil\n+  }\n+\n+  // Table setup using star schema relationships:\n+  //\n+  // d1 - f1 - d2\n+  //      |\n+  //      d3 - s3\n+  //\n+  // Table f1 is the fact table. Tables d1, d2, and d3 are the dimension tables.\n+  // Dimension d3 is further joined/normalized into table s3.\n+  // Tables' cardinality: f1 > d3 > d1 > d2 > s3\n+  private val columnInfo: AttributeMap[ColumnStat] = AttributeMap(Seq(\n+    // F1\n+    attr(\"f1_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_fk2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_fk3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f1_c4\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D1\n+    attr(\"d1_pk1\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d1_c4\") -> ColumnStat(distinctCount = 2, min = Some(2), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D2\n+    attr(\"d2_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 1, avgLen = 4, maxLen = 4),\n+    attr(\"d2_pk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d2_c3\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d2_c4\") -> ColumnStat(distinctCount = 2, min = Some(3), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // D3\n+    attr(\"d3_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_c2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_pk1\") -> ColumnStat(distinctCount = 5, min = Some(1), max = Some(5),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"d3_c4\") -> ColumnStat(distinctCount = 2, min = Some(2), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // S3\n+    attr(\"s3_pk1\") -> ColumnStat(distinctCount = 2, min = Some(1), max = Some(2),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c2\") -> ColumnStat(distinctCount = 1, min = Some(3), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c3\") -> ColumnStat(distinctCount = 1, min = Some(3), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"s3_c4\") -> ColumnStat(distinctCount = 2, min = Some(3), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    // F11\n+    attr(\"f11_fk1\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_fk2\") -> ColumnStat(distinctCount = 3, min = Some(1), max = Some(3),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_fk3\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4),\n+    attr(\"f11_c4\") -> ColumnStat(distinctCount = 4, min = Some(1), max = Some(4),\n+      nullCount = 0, avgLen = 4, maxLen = 4)\n+  ))\n+\n+  private val nameToAttr: Map[String, Attribute] = columnInfo.map(kv => kv._1.name -> kv._1)\n+  private val nameToColInfo: Map[String, (Attribute, ColumnStat)] =\n+    columnInfo.map(kv => kv._1.name -> kv)\n+\n+  private val f1 = StatsTestPlan(\n+    outputList = Seq(\"f1_fk1\", \"f1_fk2\", \"f1_fk3\", \"f1_c4\").map(nameToAttr),\n+    rowCount = 6,\n+    size = Some(48),\n+    attributeStats = AttributeMap(Seq(\"f1_fk1\", \"f1_fk2\", \"f1_fk3\", \"f1_c4\").map(nameToColInfo)))\n+\n+  private val d1 = StatsTestPlan(\n+    outputList = Seq(\"d1_pk1\", \"d1_c2\", \"d1_c3\", \"d1_c4\").map(nameToAttr),\n+    rowCount = 4,\n+    size = Some(32),\n+    attributeStats = AttributeMap(Seq(\"d1_pk1\", \"d1_c2\", \"d1_c3\", \"d1_c4\").map(nameToColInfo)))\n+\n+  private val d2 = StatsTestPlan(\n+    outputList = Seq(\"d2_c2\", \"d2_pk1\", \"d2_c3\", \"d2_c4\").map(nameToAttr),\n+    rowCount = 3,\n+    size = Some(24),\n+    attributeStats = AttributeMap(Seq(\"d2_c2\", \"d2_pk1\", \"d2_c3\", \"d2_c4\").map(nameToColInfo)))\n+\n+  private val d3 = StatsTestPlan(\n+    outputList = Seq(\"d3_fk1\", \"d3_c2\", \"d3_pk1\", \"d3_c4\").map(nameToAttr),\n+    rowCount = 5,\n+    size = Some(40),\n+    attributeStats = AttributeMap(Seq(\"d3_fk1\", \"d3_c2\", \"d3_pk1\", \"d3_c4\").map(nameToColInfo)))\n+\n+  private val s3 = StatsTestPlan(\n+    outputList = Seq(\"s3_pk1\", \"s3_c2\", \"s3_c3\", \"s3_c4\").map(nameToAttr),\n+    rowCount = 2,\n+    size = Some(17),\n+    attributeStats = AttributeMap(Seq(\"s3_pk1\", \"s3_c2\", \"s3_c3\", \"s3_c4\").map(nameToColInfo)))\n+\n+  private val d3_ns = LocalRelation('d3_fk1.int, 'd3_c2.int, 'd3_pk1.int, 'd3_c4.int)\n+\n+  private val f11 = StatsTestPlan(\n+    outputList = Seq(\"f11_fk1\", \"f11_fk2\", \"f11_fk3\", \"f11_c4\").map(nameToAttr),\n+    rowCount = 6,\n+    size = Some(48),\n+    attributeStats = AttributeMap(Seq(\"f11_fk1\", \"f11_fk2\", \"f11_fk3\", \"f11_c4\")\n+      .map(nameToColInfo)))\n+\n+  private val subq = d3.select(sum('d3_fk1).as('col))\n+\n+  test(\"Test 1: Selective star-join on all dimensions\") {\n+    // Star join:\n+    //   (=)  (=)\n+    // d1 - f1 - d2\n+    //      | (=)\n+    //      s3 - d3\n+    //\n+    // Query:\n+    //  select f1_fk1, f1_fk3\n+    //  from d1, d2, f1, d3, s3\n+    //  where f1_fk2 = d2_pk1 and d2_c2 < 2\n+    //  and f1_fk1 = d1_pk1\n+    //  and f1_fk3 = d3_pk1\n+    //  and d3_fk1 = s3_pk1\n+    //\n+    // Positional join reordering: d1, f1, d2, d3, s3\n+    // Star join reordering: f1, d2, d1, d3, s3\n+    val query =\n+      d1.join(d2).join(f1).join(d3).join(s3)\n+        .where((nameToAttr(\"f1_fk2\") === nameToAttr(\"d2_pk1\")) &&\n+          (nameToAttr(\"d2_c2\") === 2) &&\n+          (nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")) &&\n+          (nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")) &&\n+          (nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    val expected =\n+      f1.join(d2.where(nameToAttr(\"d2_c2\") === 2), Inner,\n+          Some(nameToAttr(\"f1_fk2\") === nameToAttr(\"d2_pk1\")))\n+        .join(d1, Inner, Some(nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")))\n+        .join(d3, Inner, Some(nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")))\n+        .join(s3, Inner, Some(nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    assertEqualPlans(query, expected)\n+  }\n+\n+  test(\"Test 2: Star join on a subset of dimensions due to inequality joins\") {\n+    // Star join:\n+    //   (=)  (<)\n+    // d1 - f1 - d2\n+    //      |\n+    //      | (=)\n+    //      d3 - s3\n+    //        (=)\n+    //\n+    // Query:\n+    //  select f1_fk1, f1_fk3\n+    //  from d1, f1, d2, s3, d3\n+    //  where f1_fk2 < d2_pk1\n+    //  and f1_fk1 = d1_pk1 and d1_c2 = 2\n+    //  and f1_fk3 = d3_pk1\n+    //  and d3_fk1 = s3_pk1\n+    //\n+    // Default join reordering: d1, f1, d2, d3, s3\n+    // Star join reordering: f1, d1, d3, d2,, d3\n+\n+    val query =\n+      d1.join(f1).join(d2).join(s3).join(d3)\n+        .where((nameToAttr(\"f1_fk2\") < nameToAttr(\"d2_pk1\")) &&\n+          (nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")) &&\n+          (nameToAttr(\"d1_c2\") === 2) &&\n+          (nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")) &&\n+          (nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    val expected =\n+      f1.join(d1.where(nameToAttr(\"d1_c2\") === 2), Inner,\n+          Some(nameToAttr(\"f1_fk1\") === nameToAttr(\"d1_pk1\")))\n+        .join(d3, Inner, Some(nameToAttr(\"f1_fk3\") === nameToAttr(\"d3_pk1\")))\n+        .join(d2, Inner, Some(nameToAttr(\"f1_fk2\") < nameToAttr(\"d2_pk1\")))\n+        .join(s3, Inner, Some(nameToAttr(\"d3_fk1\") === nameToAttr(\"s3_pk1\")))\n+\n+    assertEqualPlans(query, expected)\n+  }\n+\n+  test(\"Test 3:  Star join on a subset of dimensions since join column is not unique\") {\n+    // Star join:\n+    //   (=)  (=)\n+    // d1 - f1 - d2\n+    //      | (=)\n+    //      d3 - s3\n+    //\n+    // Query:\n+    //  select f1_fk1, f1_fk3\n+    //  from d1, f1, d2, s3, d3\n+    //  where f1_fk2 = d2_c4\n+    //  and f1_fk1 = d1_pk1 and d1_c2 = 2\n+    //  and f1_fk3 = d3_pk1\n+    //  and d3_fk1 = s3_pk1\n+    //\n+    // Default join reordering: d1, f1, d2, d3, s3\n+    // Star join reordering: f1, d1, d3, d2, d3",
    "line": 246
  }],
  "prId": 15363
}]