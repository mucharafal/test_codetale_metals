[{
  "comments": [{
    "author": {
      "login": "wzhfy"
    },
    "body": "also test BinaryType?",
    "commit": "2a301188287726f4f87fffe33f57cd3a2ae36c30",
    "createdAt": "2016-12-01T14:12:30Z",
    "diffHunk": "@@ -17,199 +17,112 @@\n \n package org.apache.spark.sql.catalyst.expressions.aggregate\n \n-import java.io.ByteArrayInputStream\n-import java.nio.charset.StandardCharsets\n+import java.{lang => jl}\n \n-import scala.reflect.ClassTag\n import scala.util.Random\n \n import org.apache.spark.SparkFunSuite\n import org.apache.spark.sql.catalyst.InternalRow\n import org.apache.spark.sql.catalyst.analysis.TypeCheckResult.TypeCheckFailure\n-import org.apache.spark.sql.catalyst.expressions.{AttributeReference, BoundReference, Cast, GenericInternalRow, Literal}\n-import org.apache.spark.sql.types.{DecimalType, _}\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.types._\n import org.apache.spark.unsafe.types.UTF8String\n import org.apache.spark.util.sketch.CountMinSketch\n \n+/**\n+ * Unit test suite for the count-min sketch SQL aggregate funciton [[CountMinSketchAgg]].\n+ */\n class CountMinSketchAggSuite extends SparkFunSuite {\n   private val childExpression = BoundReference(0, IntegerType, nullable = true)\n   private val epsOfTotalCount = 0.0001\n   private val confidence = 0.99\n   private val seed = 42\n-\n-  test(\"serialize and de-serialize\") {\n-    // Check empty serialize and de-serialize\n-    val agg = new CountMinSketchAgg(childExpression, Literal(epsOfTotalCount), Literal(confidence),\n-      Literal(seed))\n-    val buffer = CountMinSketch.create(epsOfTotalCount, confidence, seed)\n-    assert(buffer.equals(agg.deserialize(agg.serialize(buffer))))\n-\n-    // Check non-empty serialize and de-serialize\n-    val random = new Random(31)\n-    (0 until 10000).map(_ => random.nextInt(100)).foreach { value =>\n-      buffer.add(value)\n-    }\n-    assert(buffer.equals(agg.deserialize(agg.serialize(buffer))))\n+  private val rand = new Random(seed)\n+\n+  /** Creates a count-min sketch aggregate expression, using the child expression defined above. */\n+  private def cms(eps: jl.Double, confidence: jl.Double, seed: jl.Integer): CountMinSketchAgg = {\n+    new CountMinSketchAgg(\n+      child = childExpression,\n+      epsExpression = Literal(eps, DoubleType),\n+      confidenceExpression = Literal(confidence, DoubleType),\n+      seedExpression = Literal(seed, IntegerType))\n   }\n \n-  def testHighLevelInterface[T: ClassTag](\n-      dataType: DataType,\n-      sampledItemIndices: Array[Int],\n-      allItems: Array[T],\n-      exactFreq: Map[Any, Long]): Any = {\n-    test(s\"high level interface, update, merge, eval... - $dataType\") {\n+  /**\n+   * Creates a new test case that compares our aggregate function with a reference implementation\n+   * (using the underlying [[CountMinSketch]]).\n+   *\n+   * This works by splitting the items into two separate groups, aggregates them, and then merges\n+   * the two groups back (to emulate partial aggregation), and then compares the result with\n+   * that generated by [[CountMinSketch]] directly. This assumes insertion order does not impact\n+   * the result in count-min sketch.\n+   */\n+  private def testDataType[T](dataType: DataType, items: Seq[T]): Unit = {\n+    test(\"test data type \" + dataType) {\n       val agg = new CountMinSketchAgg(BoundReference(0, dataType, nullable = true),\n         Literal(epsOfTotalCount), Literal(confidence), Literal(seed))\n       assert(!agg.nullable)\n \n-      val group1 = 0 until sampledItemIndices.length / 2\n-      val group1Buffer = agg.createAggregationBuffer()\n-      group1.foreach { index =>\n-        val input = InternalRow(allItems(sampledItemIndices(index)))\n-        agg.update(group1Buffer, input)\n+      val (seq1, seq2) = items.splitAt(items.size / 2)\n+      val buf1 = addToAggregateBuffer(agg, seq1)\n+      val buf2 = addToAggregateBuffer(agg, seq2)\n+\n+      val sketch = agg.createAggregationBuffer()\n+      agg.merge(sketch, buf1)\n+      agg.merge(sketch, buf2)\n+\n+      // Validate cardinality estimation against reference implementation.\n+      val referenceSketch = CountMinSketch.create(epsOfTotalCount, confidence, seed)\n+      items.foreach { item =>\n+        referenceSketch.add(item match {\n+          case u: UTF8String => u.getBytes\n+          case _ => item\n+        })\n       }\n \n-      val group2 = sampledItemIndices.length / 2 until sampledItemIndices.length\n-      val group2Buffer = agg.createAggregationBuffer()\n-      group2.foreach { index =>\n-        val input = InternalRow(allItems(sampledItemIndices(index)))\n-        agg.update(group2Buffer, input)\n+      items.foreach { item =>\n+        withClue(s\"For item $item\") {\n+          val itemToTest = item match {\n+            case u: UTF8String => u.getBytes\n+            case _ => item\n+          }\n+          assert(referenceSketch.estimateCount(itemToTest) == sketch.estimateCount(itemToTest))\n+        }\n       }\n-\n-      var mergeBuffer = agg.createAggregationBuffer()\n-      agg.merge(mergeBuffer, group1Buffer)\n-      agg.merge(mergeBuffer, group2Buffer)\n-      checkResult(agg.eval(mergeBuffer), allItems, exactFreq)\n-\n-      // Merge in a different order\n-      mergeBuffer = agg.createAggregationBuffer()\n-      agg.merge(mergeBuffer, group2Buffer)\n-      agg.merge(mergeBuffer, group1Buffer)\n-      checkResult(agg.eval(mergeBuffer), allItems, exactFreq)\n-\n-      // Merge with an empty partition\n-      val emptyBuffer = agg.createAggregationBuffer()\n-      agg.merge(mergeBuffer, emptyBuffer)\n-      checkResult(agg.eval(mergeBuffer), allItems, exactFreq)\n     }\n-  }\n \n-  def testLowLevelInterface[T: ClassTag](\n-      dataType: DataType,\n-      sampledItemIndices: Array[Int],\n-      allItems: Array[T],\n-      exactFreq: Map[Any, Long]): Any = {\n-    test(s\"low level interface, update, merge, eval... - ${dataType.typeName}\") {\n-      val inputAggregationBufferOffset = 1\n-      val mutableAggregationBufferOffset = 2\n-\n-      // Phase one, partial mode aggregation\n-      val agg = new CountMinSketchAgg(BoundReference(0, dataType, nullable = true),\n-        Literal(epsOfTotalCount), Literal(confidence), Literal(seed))\n-        .withNewInputAggBufferOffset(inputAggregationBufferOffset)\n-        .withNewMutableAggBufferOffset(mutableAggregationBufferOffset)\n-\n-      val mutableAggBuffer = new GenericInternalRow(\n-        new Array[Any](mutableAggregationBufferOffset + 1))\n-      agg.initialize(mutableAggBuffer)\n-\n-      sampledItemIndices.foreach { i =>\n-        agg.update(mutableAggBuffer, InternalRow(allItems(i)))\n-      }\n-      agg.serializeAggregateBufferInPlace(mutableAggBuffer)\n-\n-      // Serialize the aggregation buffer\n-      val serialized = mutableAggBuffer.getBinary(mutableAggregationBufferOffset)\n-      val inputAggBuffer = new GenericInternalRow(Array[Any](null, serialized))\n-\n-      // Phase 2: final mode aggregation\n-      // Re-initialize the aggregation buffer\n-      agg.initialize(mutableAggBuffer)\n-      agg.merge(mutableAggBuffer, inputAggBuffer)\n-      checkResult(agg.eval(mutableAggBuffer), allItems, exactFreq)\n+    def addToAggregateBuffer[T](agg: CountMinSketchAgg, items: Seq[T]): CountMinSketch = {\n+      val buf = agg.createAggregationBuffer()\n+      items.foreach { item => agg.update(buf, InternalRow(item)) }\n+      buf\n     }\n   }\n \n-  private def checkResult[T: ClassTag](\n-      result: Any,\n-      data: Array[T],\n-      exactFreq: Map[Any, Long]): Unit = {\n-    result match {\n-      case bytesData: Array[Byte] =>\n-        val in = new ByteArrayInputStream(bytesData)\n-        val cms = CountMinSketch.readFrom(in)\n-        val probCorrect = {\n-          val numErrors = data.map { i =>\n-            val count = exactFreq.getOrElse(getProbeItem(i), 0L)\n-            val item = i match {\n-              case dec: Decimal => dec.toJavaBigDecimal\n-              case str: UTF8String => str.getBytes\n-              case _ => i\n-            }\n-            val ratio = (cms.estimateCount(item) - count).toDouble / data.length\n-            if (ratio > epsOfTotalCount) 1 else 0\n-          }.sum\n+  testDataType[Byte](ByteType, Seq.fill(100) { rand.nextInt(10).toByte })\n \n-          1D - numErrors.toDouble / data.length\n-        }\n+  testDataType[Short](ShortType, Seq.fill(100) { rand.nextInt(10).toShort })\n \n-        assert(\n-          probCorrect > confidence,\n-          s\"Confidence not reached: required $confidence, reached $probCorrect\"\n-        )\n-      case _ => fail(\"unexpected return type\")\n-    }\n-  }\n+  testDataType[Int](IntegerType, Seq.fill(100) { rand.nextInt(10) })\n \n-  private def getProbeItem[T: ClassTag](item: T): Any = item match {\n-    // Use a string to represent the content of an array of bytes\n-    case bytes: Array[Byte] => new String(bytes, StandardCharsets.UTF_8)\n-    case i => identity(i)\n-  }\n-\n-  def testItemType[T: ClassTag](dataType: DataType)(itemGenerator: Random => T): Unit = {\n-    // Uses fixed seed to ensure reproducible test execution\n-    val r = new Random(31)\n+  testDataType[Long](LongType, Seq.fill(100) { rand.nextInt(10) })\n \n-    val numAllItems = 1000000\n-    val allItems = Array.fill(numAllItems)(itemGenerator(r))\n+  testDataType[UTF8String](StringType, Seq.fill(100) { UTF8String.fromString(rand.nextString(1)) })\n "
  }],
  "prId": 16093
}]