[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Overall, it looks like the content of this file was copied to a superclass, and now this is trait that extends it without adding anything. Is the point that it \"extends SparkFunSuite\"?\r\n\r\nI don't know if this is possible in git, but renaming the class to PlanTestBase and then re-creating the current trait might have led to a diff where it's possible to see what did and didn't change in the move. Was there any substantive change? that's what I'm having trouble evaluating.",
    "commit": "6c0b0d569ae1d779fd9253da0c7e97d12634063c",
    "createdAt": "2017-10-23T07:42:46Z",
    "diffHunk": "@@ -18,158 +18,9 @@\n package org.apache.spark.sql.catalyst.plans\n \n import org.apache.spark.SparkFunSuite\n-import org.apache.spark.sql.AnalysisException\n-import org.apache.spark.sql.catalyst.analysis.SimpleAnalyzer\n-import org.apache.spark.sql.catalyst.expressions._\n-import org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression\n-import org.apache.spark.sql.catalyst.plans.logical._\n-import org.apache.spark.sql.catalyst.util._\n-import org.apache.spark.sql.internal.SQLConf\n \n /**\n  * Provides helper methods for comparing plans.\n  */\n-trait PlanTest extends SparkFunSuite with PredicateHelper {\n-\n-  // TODO(gatorsmile): remove this from PlanTest and all the analyzer rules\n-  protected def conf = SQLConf.get\n-\n-  /**\n-   * Since attribute references are given globally unique ids during analysis,\n-   * we must normalize them to check if two different queries are identical.\n-   */\n-  protected def normalizeExprIds(plan: LogicalPlan) = {\n-    plan transformAllExpressions {\n-      case s: ScalarSubquery =>\n-        s.copy(exprId = ExprId(0))\n-      case e: Exists =>\n-        e.copy(exprId = ExprId(0))\n-      case l: ListQuery =>\n-        l.copy(exprId = ExprId(0))\n-      case a: AttributeReference =>\n-        AttributeReference(a.name, a.dataType, a.nullable)(exprId = ExprId(0))\n-      case a: Alias =>\n-        Alias(a.child, a.name)(exprId = ExprId(0))\n-      case ae: AggregateExpression =>\n-        ae.copy(resultId = ExprId(0))\n-    }\n-  }\n-\n-  /**\n-   * Normalizes plans:\n-   * - Filter the filter conditions that appear in a plan. For instance,\n-   *   ((expr 1 && expr 2) && expr 3), (expr 1 && expr 2 && expr 3), (expr 3 && (expr 1 && expr 2)\n-   *   etc., will all now be equivalent.\n-   * - Sample the seed will replaced by 0L.\n-   * - Join conditions will be resorted by hashCode.\n-   */\n-  protected def normalizePlan(plan: LogicalPlan): LogicalPlan = {\n-    plan transform {\n-      case Filter(condition: Expression, child: LogicalPlan) =>\n-        Filter(splitConjunctivePredicates(condition).map(rewriteEqual).sortBy(_.hashCode())\n-          .reduce(And), child)\n-      case sample: Sample =>\n-        sample.copy(seed = 0L)\n-      case Join(left, right, joinType, condition) if condition.isDefined =>\n-        val newCondition =\n-          splitConjunctivePredicates(condition.get).map(rewriteEqual).sortBy(_.hashCode())\n-            .reduce(And)\n-        Join(left, right, joinType, Some(newCondition))\n-    }\n-  }\n-\n-  /**\n-   * Rewrite [[EqualTo]] and [[EqualNullSafe]] operator to keep order. The following cases will be\n-   * equivalent:\n-   * 1. (a = b), (b = a);\n-   * 2. (a <=> b), (b <=> a).\n-   */\n-  private def rewriteEqual(condition: Expression): Expression = condition match {\n-    case eq @ EqualTo(l: Expression, r: Expression) =>\n-      Seq(l, r).sortBy(_.hashCode()).reduce(EqualTo)\n-    case eq @ EqualNullSafe(l: Expression, r: Expression) =>\n-      Seq(l, r).sortBy(_.hashCode()).reduce(EqualNullSafe)\n-    case _ => condition // Don't reorder.\n-  }\n-\n-  /** Fails the test if the two plans do not match */\n-  protected def comparePlans(\n-      plan1: LogicalPlan,\n-      plan2: LogicalPlan,\n-      checkAnalysis: Boolean = true): Unit = {\n-    if (checkAnalysis) {\n-      // Make sure both plan pass checkAnalysis.\n-      SimpleAnalyzer.checkAnalysis(plan1)\n-      SimpleAnalyzer.checkAnalysis(plan2)\n-    }\n-\n-    val normalized1 = normalizePlan(normalizeExprIds(plan1))\n-    val normalized2 = normalizePlan(normalizeExprIds(plan2))\n-    if (normalized1 != normalized2) {\n-      fail(\n-        s\"\"\"\n-          |== FAIL: Plans do not match ===\n-          |${sideBySide(normalized1.treeString, normalized2.treeString).mkString(\"\\n\")}\n-         \"\"\".stripMargin)\n-    }\n-  }\n-\n-  /** Fails the test if the two expressions do not match */\n-  protected def compareExpressions(e1: Expression, e2: Expression): Unit = {\n-    comparePlans(Filter(e1, OneRowRelation()), Filter(e2, OneRowRelation()), checkAnalysis = false)\n-  }\n-\n-  /** Fails the test if the join order in the two plans do not match */\n-  protected def compareJoinOrder(plan1: LogicalPlan, plan2: LogicalPlan) {\n-    val normalized1 = normalizePlan(normalizeExprIds(plan1))\n-    val normalized2 = normalizePlan(normalizeExprIds(plan2))\n-    if (!sameJoinPlan(normalized1, normalized2)) {\n-      fail(\n-        s\"\"\"\n-           |== FAIL: Plans do not match ===\n-           |${sideBySide(normalized1.treeString, normalized2.treeString).mkString(\"\\n\")}\n-         \"\"\".stripMargin)\n-    }\n-  }\n-\n-  /** Consider symmetry for joins when comparing plans. */\n-  private def sameJoinPlan(plan1: LogicalPlan, plan2: LogicalPlan): Boolean = {\n-    (plan1, plan2) match {\n-      case (j1: Join, j2: Join) =>\n-        (sameJoinPlan(j1.left, j2.left) && sameJoinPlan(j1.right, j2.right)) ||\n-          (sameJoinPlan(j1.left, j2.right) && sameJoinPlan(j1.right, j2.left))\n-      case (p1: Project, p2: Project) =>\n-        p1.projectList == p2.projectList && sameJoinPlan(p1.child, p2.child)\n-      case _ =>\n-        plan1 == plan2\n-    }\n-  }\n-\n-  /**\n-   * Sets all SQL configurations specified in `pairs`, calls `f`, and then restore all SQL\n-   * configurations.\n-   */\n-  protected def withSQLConf(pairs: (String, String)*)(f: => Unit): Unit = {\n-    val conf = SQLConf.get\n-    val (keys, values) = pairs.unzip\n-    val currentValues = keys.map { key =>\n-      if (conf.contains(key)) {\n-        Some(conf.getConfString(key))\n-      } else {\n-        None\n-      }\n-    }\n-    (keys, values).zipped.foreach { (k, v) =>\n-      if (SQLConf.staticConfKeys.contains(k)) {\n-        throw new AnalysisException(s\"Cannot modify the value of a static config: $k\")\n-      }\n-      conf.setConfString(k, v)\n-    }\n-    try f finally {\n-      keys.zip(currentValues).foreach {\n-        case (key, Some(value)) => conf.setConfString(key, value)\n-        case (key, None) => conf.unsetConf(key)\n-      }\n-    }\n-  }\n+trait PlanTest extends SparkFunSuite with PlanTestBase {"
  }, {
    "author": {
      "login": "nkronenfeld"
    },
    "body": "I actually did start with 'git mv PlanTest.scala PlanTestBase.scala' - sadly, the diffs don't catch that. :-(\r\nYou understand the intent exactly - to pull the FunSuite part out of PlanTestBase and include it in PlanTest.\r\n\r\nTo confirm that nothing else changed, I ran:\r\n\r\n    git checkout 4a779bdac3e75c17b7d36c5a009ba6c948fa9fb6 PlanTest.scala\r\n    diff PlanTest.scala PlanTestBase.scala\r\n\r\nand got the following:\r\n\r\n    20c20,21\r\n    < import org.apache.spark.SparkFunSuite\r\n    ---\r\n    > import org.scalatest.Suite\r\n    > \r\n    30c31,32\r\n    <  * Provides helper methods for comparing plans.\r\n    ---\r\n    >  * Provides helper methods for comparing plans, but without the overhead of\r\n    >  * mandating a FunSuite.\r\n    32c34\r\n    < trait PlanTest extends SparkFunSuite with PredicateHelper {\r\n    ---\r\n    > trait PlanTestBase extends PredicateHelper { self: Suite =>\r\n",
    "commit": "6c0b0d569ae1d779fd9253da0c7e97d12634063c",
    "createdAt": "2017-10-23T15:41:11Z",
    "diffHunk": "@@ -18,158 +18,9 @@\n package org.apache.spark.sql.catalyst.plans\n \n import org.apache.spark.SparkFunSuite\n-import org.apache.spark.sql.AnalysisException\n-import org.apache.spark.sql.catalyst.analysis.SimpleAnalyzer\n-import org.apache.spark.sql.catalyst.expressions._\n-import org.apache.spark.sql.catalyst.expressions.aggregate.AggregateExpression\n-import org.apache.spark.sql.catalyst.plans.logical._\n-import org.apache.spark.sql.catalyst.util._\n-import org.apache.spark.sql.internal.SQLConf\n \n /**\n  * Provides helper methods for comparing plans.\n  */\n-trait PlanTest extends SparkFunSuite with PredicateHelper {\n-\n-  // TODO(gatorsmile): remove this from PlanTest and all the analyzer rules\n-  protected def conf = SQLConf.get\n-\n-  /**\n-   * Since attribute references are given globally unique ids during analysis,\n-   * we must normalize them to check if two different queries are identical.\n-   */\n-  protected def normalizeExprIds(plan: LogicalPlan) = {\n-    plan transformAllExpressions {\n-      case s: ScalarSubquery =>\n-        s.copy(exprId = ExprId(0))\n-      case e: Exists =>\n-        e.copy(exprId = ExprId(0))\n-      case l: ListQuery =>\n-        l.copy(exprId = ExprId(0))\n-      case a: AttributeReference =>\n-        AttributeReference(a.name, a.dataType, a.nullable)(exprId = ExprId(0))\n-      case a: Alias =>\n-        Alias(a.child, a.name)(exprId = ExprId(0))\n-      case ae: AggregateExpression =>\n-        ae.copy(resultId = ExprId(0))\n-    }\n-  }\n-\n-  /**\n-   * Normalizes plans:\n-   * - Filter the filter conditions that appear in a plan. For instance,\n-   *   ((expr 1 && expr 2) && expr 3), (expr 1 && expr 2 && expr 3), (expr 3 && (expr 1 && expr 2)\n-   *   etc., will all now be equivalent.\n-   * - Sample the seed will replaced by 0L.\n-   * - Join conditions will be resorted by hashCode.\n-   */\n-  protected def normalizePlan(plan: LogicalPlan): LogicalPlan = {\n-    plan transform {\n-      case Filter(condition: Expression, child: LogicalPlan) =>\n-        Filter(splitConjunctivePredicates(condition).map(rewriteEqual).sortBy(_.hashCode())\n-          .reduce(And), child)\n-      case sample: Sample =>\n-        sample.copy(seed = 0L)\n-      case Join(left, right, joinType, condition) if condition.isDefined =>\n-        val newCondition =\n-          splitConjunctivePredicates(condition.get).map(rewriteEqual).sortBy(_.hashCode())\n-            .reduce(And)\n-        Join(left, right, joinType, Some(newCondition))\n-    }\n-  }\n-\n-  /**\n-   * Rewrite [[EqualTo]] and [[EqualNullSafe]] operator to keep order. The following cases will be\n-   * equivalent:\n-   * 1. (a = b), (b = a);\n-   * 2. (a <=> b), (b <=> a).\n-   */\n-  private def rewriteEqual(condition: Expression): Expression = condition match {\n-    case eq @ EqualTo(l: Expression, r: Expression) =>\n-      Seq(l, r).sortBy(_.hashCode()).reduce(EqualTo)\n-    case eq @ EqualNullSafe(l: Expression, r: Expression) =>\n-      Seq(l, r).sortBy(_.hashCode()).reduce(EqualNullSafe)\n-    case _ => condition // Don't reorder.\n-  }\n-\n-  /** Fails the test if the two plans do not match */\n-  protected def comparePlans(\n-      plan1: LogicalPlan,\n-      plan2: LogicalPlan,\n-      checkAnalysis: Boolean = true): Unit = {\n-    if (checkAnalysis) {\n-      // Make sure both plan pass checkAnalysis.\n-      SimpleAnalyzer.checkAnalysis(plan1)\n-      SimpleAnalyzer.checkAnalysis(plan2)\n-    }\n-\n-    val normalized1 = normalizePlan(normalizeExprIds(plan1))\n-    val normalized2 = normalizePlan(normalizeExprIds(plan2))\n-    if (normalized1 != normalized2) {\n-      fail(\n-        s\"\"\"\n-          |== FAIL: Plans do not match ===\n-          |${sideBySide(normalized1.treeString, normalized2.treeString).mkString(\"\\n\")}\n-         \"\"\".stripMargin)\n-    }\n-  }\n-\n-  /** Fails the test if the two expressions do not match */\n-  protected def compareExpressions(e1: Expression, e2: Expression): Unit = {\n-    comparePlans(Filter(e1, OneRowRelation()), Filter(e2, OneRowRelation()), checkAnalysis = false)\n-  }\n-\n-  /** Fails the test if the join order in the two plans do not match */\n-  protected def compareJoinOrder(plan1: LogicalPlan, plan2: LogicalPlan) {\n-    val normalized1 = normalizePlan(normalizeExprIds(plan1))\n-    val normalized2 = normalizePlan(normalizeExprIds(plan2))\n-    if (!sameJoinPlan(normalized1, normalized2)) {\n-      fail(\n-        s\"\"\"\n-           |== FAIL: Plans do not match ===\n-           |${sideBySide(normalized1.treeString, normalized2.treeString).mkString(\"\\n\")}\n-         \"\"\".stripMargin)\n-    }\n-  }\n-\n-  /** Consider symmetry for joins when comparing plans. */\n-  private def sameJoinPlan(plan1: LogicalPlan, plan2: LogicalPlan): Boolean = {\n-    (plan1, plan2) match {\n-      case (j1: Join, j2: Join) =>\n-        (sameJoinPlan(j1.left, j2.left) && sameJoinPlan(j1.right, j2.right)) ||\n-          (sameJoinPlan(j1.left, j2.right) && sameJoinPlan(j1.right, j2.left))\n-      case (p1: Project, p2: Project) =>\n-        p1.projectList == p2.projectList && sameJoinPlan(p1.child, p2.child)\n-      case _ =>\n-        plan1 == plan2\n-    }\n-  }\n-\n-  /**\n-   * Sets all SQL configurations specified in `pairs`, calls `f`, and then restore all SQL\n-   * configurations.\n-   */\n-  protected def withSQLConf(pairs: (String, String)*)(f: => Unit): Unit = {\n-    val conf = SQLConf.get\n-    val (keys, values) = pairs.unzip\n-    val currentValues = keys.map { key =>\n-      if (conf.contains(key)) {\n-        Some(conf.getConfString(key))\n-      } else {\n-        None\n-      }\n-    }\n-    (keys, values).zipped.foreach { (k, v) =>\n-      if (SQLConf.staticConfKeys.contains(k)) {\n-        throw new AnalysisException(s\"Cannot modify the value of a static config: $k\")\n-      }\n-      conf.setConfString(k, v)\n-    }\n-    try f finally {\n-      keys.zip(currentValues).foreach {\n-        case (key, Some(value)) => conf.setConfString(key, value)\n-        case (key, None) => conf.unsetConf(key)\n-      }\n-    }\n-  }\n+trait PlanTest extends SparkFunSuite with PlanTestBase {"
  }],
  "prId": 19529
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Please remove the useless `{` and `}`",
    "commit": "6c0b0d569ae1d779fd9253da0c7e97d12634063c",
    "createdAt": "2017-10-25T20:25:01Z",
    "diffHunk": "@@ -29,7 +31,14 @@ import org.apache.spark.sql.internal.SQLConf\n /**\n  * Provides helper methods for comparing plans.\n  */\n-trait PlanTest extends SparkFunSuite with PredicateHelper {\n+trait PlanTest extends SparkFunSuite with PlanTestBase {\n+}"
  }, {
    "author": {
      "login": "nkronenfeld"
    },
    "body": "done",
    "commit": "6c0b0d569ae1d779fd9253da0c7e97d12634063c",
    "createdAt": "2017-10-26T03:24:50Z",
    "diffHunk": "@@ -29,7 +31,14 @@ import org.apache.spark.sql.internal.SQLConf\n /**\n  * Provides helper methods for comparing plans.\n  */\n-trait PlanTest extends SparkFunSuite with PredicateHelper {\n+trait PlanTest extends SparkFunSuite with PlanTestBase {\n+}"
  }],
  "prId": 19529
}]