[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "Shall we update `GetArrayItem.nullable`, to special-handle the combination of `CreateArray` and `Literal`?",
    "commit": "9f9460576fd6dd06ea8ca436ffc38da8c65e00e1",
    "createdAt": "2019-01-11T04:09:38Z",
    "diffHunk": "@@ -1,58 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.spark.sql.catalyst.optimizer\n-\n-import org.apache.spark.sql.catalyst.analysis.UpdateAttributeNullability\n-import org.apache.spark.sql.catalyst.dsl.expressions._\n-import org.apache.spark.sql.catalyst.dsl.plans._\n-import org.apache.spark.sql.catalyst.expressions.{CreateArray, GetArrayItem}\n-import org.apache.spark.sql.catalyst.plans.PlanTest\n-import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n-import org.apache.spark.sql.catalyst.rules.RuleExecutor\n-\n-\n-class UpdateAttributeNullabilityInOptimizerSuite extends PlanTest {\n-\n-  object Optimizer extends RuleExecutor[LogicalPlan] {\n-    val batches =\n-      Batch(\"Constant Folding\", FixedPoint(10),\n-          NullPropagation,\n-          ConstantFolding,\n-          BooleanSimplification,\n-          SimplifyConditionals,\n-          SimplifyBinaryComparison,\n-          SimplifyExtractValueOps) ::\n-      Batch(\"UpdateNullability\", Once,\n-        UpdateAttributeNullability) :: Nil\n-  }\n-\n-  test(\"update nullability in AttributeReference\")  {\n-    val rel = LocalRelation('a.long.notNull)\n-    // In the 'original' plans below, the Aggregate node produced by groupBy() has a\n-    // nullable AttributeReference to `b`, because both array indexing and map lookup are\n-    // nullable expressions. After optimization, the same attribute is now non-nullable,\n-    // but the AttributeReference is not updated to reflect this. So, we need to update nullability\n-    // by the `UpdateAttributeNullability` rule.\n-    val original = rel\n-      .select(GetArrayItem(CreateArray(Seq('a, 'a + 1L)), 0) as \"b\")",
    "line": 52
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Ah, I see, we can do so. Is it ok to file a separate jira and make a pr for that in following activities?",
    "commit": "9f9460576fd6dd06ea8ca436ffc38da8c65e00e1",
    "createdAt": "2019-01-11T04:55:34Z",
    "diffHunk": "@@ -1,58 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.spark.sql.catalyst.optimizer\n-\n-import org.apache.spark.sql.catalyst.analysis.UpdateAttributeNullability\n-import org.apache.spark.sql.catalyst.dsl.expressions._\n-import org.apache.spark.sql.catalyst.dsl.plans._\n-import org.apache.spark.sql.catalyst.expressions.{CreateArray, GetArrayItem}\n-import org.apache.spark.sql.catalyst.plans.PlanTest\n-import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n-import org.apache.spark.sql.catalyst.rules.RuleExecutor\n-\n-\n-class UpdateAttributeNullabilityInOptimizerSuite extends PlanTest {\n-\n-  object Optimizer extends RuleExecutor[LogicalPlan] {\n-    val batches =\n-      Batch(\"Constant Folding\", FixedPoint(10),\n-          NullPropagation,\n-          ConstantFolding,\n-          BooleanSimplification,\n-          SimplifyConditionals,\n-          SimplifyBinaryComparison,\n-          SimplifyExtractValueOps) ::\n-      Batch(\"UpdateNullability\", Once,\n-        UpdateAttributeNullability) :: Nil\n-  }\n-\n-  test(\"update nullability in AttributeReference\")  {\n-    val rel = LocalRelation('a.long.notNull)\n-    // In the 'original' plans below, the Aggregate node produced by groupBy() has a\n-    // nullable AttributeReference to `b`, because both array indexing and map lookup are\n-    // nullable expressions. After optimization, the same attribute is now non-nullable,\n-    // but the AttributeReference is not updated to reflect this. So, we need to update nullability\n-    // by the `UpdateAttributeNullability` rule.\n-    val original = rel\n-      .select(GetArrayItem(CreateArray(Seq('a, 'a + 1L)), 0) as \"b\")",
    "line": 52
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "sure\r\n",
    "commit": "9f9460576fd6dd06ea8ca436ffc38da8c65e00e1",
    "createdAt": "2019-01-11T05:48:34Z",
    "diffHunk": "@@ -1,58 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.spark.sql.catalyst.optimizer\n-\n-import org.apache.spark.sql.catalyst.analysis.UpdateAttributeNullability\n-import org.apache.spark.sql.catalyst.dsl.expressions._\n-import org.apache.spark.sql.catalyst.dsl.plans._\n-import org.apache.spark.sql.catalyst.expressions.{CreateArray, GetArrayItem}\n-import org.apache.spark.sql.catalyst.plans.PlanTest\n-import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n-import org.apache.spark.sql.catalyst.rules.RuleExecutor\n-\n-\n-class UpdateAttributeNullabilityInOptimizerSuite extends PlanTest {\n-\n-  object Optimizer extends RuleExecutor[LogicalPlan] {\n-    val batches =\n-      Batch(\"Constant Folding\", FixedPoint(10),\n-          NullPropagation,\n-          ConstantFolding,\n-          BooleanSimplification,\n-          SimplifyConditionals,\n-          SimplifyBinaryComparison,\n-          SimplifyExtractValueOps) ::\n-      Batch(\"UpdateNullability\", Once,\n-        UpdateAttributeNullability) :: Nil\n-  }\n-\n-  test(\"update nullability in AttributeReference\")  {\n-    val rel = LocalRelation('a.long.notNull)\n-    // In the 'original' plans below, the Aggregate node produced by groupBy() has a\n-    // nullable AttributeReference to `b`, because both array indexing and map lookup are\n-    // nullable expressions. After optimization, the same attribute is now non-nullable,\n-    // but the AttributeReference is not updated to reflect this. So, we need to update nullability\n-    // by the `UpdateAttributeNullability` rule.\n-    val original = rel\n-      .select(GetArrayItem(CreateArray(Seq('a, 'a + 1L)), 0) as \"b\")",
    "line": 52
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Made a pr in #23566",
    "commit": "9f9460576fd6dd06ea8ca436ffc38da8c65e00e1",
    "createdAt": "2019-01-16T12:53:04Z",
    "diffHunk": "@@ -1,58 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.spark.sql.catalyst.optimizer\n-\n-import org.apache.spark.sql.catalyst.analysis.UpdateAttributeNullability\n-import org.apache.spark.sql.catalyst.dsl.expressions._\n-import org.apache.spark.sql.catalyst.dsl.plans._\n-import org.apache.spark.sql.catalyst.expressions.{CreateArray, GetArrayItem}\n-import org.apache.spark.sql.catalyst.plans.PlanTest\n-import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n-import org.apache.spark.sql.catalyst.rules.RuleExecutor\n-\n-\n-class UpdateAttributeNullabilityInOptimizerSuite extends PlanTest {\n-\n-  object Optimizer extends RuleExecutor[LogicalPlan] {\n-    val batches =\n-      Batch(\"Constant Folding\", FixedPoint(10),\n-          NullPropagation,\n-          ConstantFolding,\n-          BooleanSimplification,\n-          SimplifyConditionals,\n-          SimplifyBinaryComparison,\n-          SimplifyExtractValueOps) ::\n-      Batch(\"UpdateNullability\", Once,\n-        UpdateAttributeNullability) :: Nil\n-  }\n-\n-  test(\"update nullability in AttributeReference\")  {\n-    val rel = LocalRelation('a.long.notNull)\n-    // In the 'original' plans below, the Aggregate node produced by groupBy() has a\n-    // nullable AttributeReference to `b`, because both array indexing and map lookup are\n-    // nullable expressions. After optimization, the same attribute is now non-nullable,\n-    // but the AttributeReference is not updated to reflect this. So, we need to update nullability\n-    // by the `UpdateAttributeNullability` rule.\n-    val original = rel\n-      .select(GetArrayItem(CreateArray(Seq('a, 'a + 1L)), 0) as \"b\")",
    "line": 52
  }],
  "prId": 23508
}]