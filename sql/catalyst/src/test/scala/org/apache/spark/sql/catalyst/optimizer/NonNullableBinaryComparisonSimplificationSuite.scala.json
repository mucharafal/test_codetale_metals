[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "use `&&`, or the second condition is not tested.\n",
    "commit": "9ca13be7dd0d0994d072407ede52008e1bcffbb6",
    "createdAt": "2016-04-11T01:26:42Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.analysis._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.Literal.{FalseLiteral, TrueLiteral}\n+import org.apache.spark.sql.catalyst.plans.PlanTest\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.rules._\n+\n+class NonNullableBinaryComparisonSimplificationSuite extends PlanTest with PredicateHelper {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"AnalysisNodes\", Once,\n+        EliminateSubqueryAliases) ::\n+      Batch(\"Constant Folding\", FixedPoint(50),\n+        NullPropagation,\n+        ConstantFolding,\n+        BooleanSimplification,\n+        NonNullableBinaryComparisonSimplification,\n+        PruneFilters) :: Nil\n+  }\n+\n+  val nullableRelation = LocalRelation.fromExternalRows(\n+    Seq('a.int.withNullability(true)),\n+    Seq(null, null, null, null).map(x => Row(x)))\n+  val nonNullableRelation = LocalRelation.fromExternalRows(\n+    Seq('a.int.withNullability(false)),\n+    Seq(1, 2, 3, 4).map(x => Row(x)))\n+\n+  test(\"Preserve nullable or non-deterministic exprs\") {\n+    for (e <- Seq('a === 'a, Rand(0) === Rand(0))) {\n+      val plan = nullableRelation.where('a === 'a).analyze\n+      val actual = Optimize.execute(plan)\n+      val correctAnswer = plan\n+      comparePlans(actual, correctAnswer)\n+    }\n+  }\n+\n+  test(\"Non-Nullable Simplification Primitive\") {\n+    val plan = nonNullableRelation\n+      .select('a === 'a, 'a <=> 'a, 'a <= 'a, 'a >= 'a, 'a < 'a, 'a > 'a).analyze\n+    val actual = Optimize.execute(plan)\n+    val correctAnswer = nonNullableRelation\n+      .select(\n+        Alias(TrueLiteral, \"(a = a)\")(),\n+        Alias(TrueLiteral, \"(a <=> a)\")(),\n+        Alias(TrueLiteral, \"(a <= a)\")(),\n+        Alias(TrueLiteral, \"(a >= a)\")(),\n+        Alias(FalseLiteral, \"(a < a)\")(),\n+        Alias(FalseLiteral, \"(a > a)\")())\n+      .analyze\n+    comparePlans(actual, correctAnswer)\n+  }\n+\n+  test(\"TRUE Filter\") {\n+    val plan = nonNullableRelation.where('a === 'a && 'a <=> 'a && 'a <= 'a && 'a >= 'a).analyze\n+    val actual = Optimize.execute(plan)\n+    val correctAnswer = nonNullableRelation.analyze\n+    comparePlans(actual, correctAnswer)\n+  }\n+\n+  test(\"FALSE Filter\") {\n+    val plan = nonNullableRelation.where('a < 'a || 'a > 'a).analyze\n+    val actual = Optimize.execute(plan)\n+    val correctAnswer = LocalRelation(Seq('a.int.withNullability(false)), Seq.empty)\n+    comparePlans(actual, correctAnswer)\n+  }\n+\n+  test(\"Expression Normalization\") {\n+    val plan = nonNullableRelation.where(\n+      'a * Literal(100) + Pi() === Pi() + Literal(100) * 'a ||"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Oh. Sure.\n",
    "commit": "9ca13be7dd0d0994d072407ede52008e1bcffbb6",
    "createdAt": "2016-04-11T04:53:27Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.analysis._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.Literal.{FalseLiteral, TrueLiteral}\n+import org.apache.spark.sql.catalyst.plans.PlanTest\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.rules._\n+\n+class NonNullableBinaryComparisonSimplificationSuite extends PlanTest with PredicateHelper {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"AnalysisNodes\", Once,\n+        EliminateSubqueryAliases) ::\n+      Batch(\"Constant Folding\", FixedPoint(50),\n+        NullPropagation,\n+        ConstantFolding,\n+        BooleanSimplification,\n+        NonNullableBinaryComparisonSimplification,\n+        PruneFilters) :: Nil\n+  }\n+\n+  val nullableRelation = LocalRelation.fromExternalRows(\n+    Seq('a.int.withNullability(true)),\n+    Seq(null, null, null, null).map(x => Row(x)))\n+  val nonNullableRelation = LocalRelation.fromExternalRows(\n+    Seq('a.int.withNullability(false)),\n+    Seq(1, 2, 3, 4).map(x => Row(x)))\n+\n+  test(\"Preserve nullable or non-deterministic exprs\") {\n+    for (e <- Seq('a === 'a, Rand(0) === Rand(0))) {\n+      val plan = nullableRelation.where('a === 'a).analyze\n+      val actual = Optimize.execute(plan)\n+      val correctAnswer = plan\n+      comparePlans(actual, correctAnswer)\n+    }\n+  }\n+\n+  test(\"Non-Nullable Simplification Primitive\") {\n+    val plan = nonNullableRelation\n+      .select('a === 'a, 'a <=> 'a, 'a <= 'a, 'a >= 'a, 'a < 'a, 'a > 'a).analyze\n+    val actual = Optimize.execute(plan)\n+    val correctAnswer = nonNullableRelation\n+      .select(\n+        Alias(TrueLiteral, \"(a = a)\")(),\n+        Alias(TrueLiteral, \"(a <=> a)\")(),\n+        Alias(TrueLiteral, \"(a <= a)\")(),\n+        Alias(TrueLiteral, \"(a >= a)\")(),\n+        Alias(FalseLiteral, \"(a < a)\")(),\n+        Alias(FalseLiteral, \"(a > a)\")())\n+      .analyze\n+    comparePlans(actual, correctAnswer)\n+  }\n+\n+  test(\"TRUE Filter\") {\n+    val plan = nonNullableRelation.where('a === 'a && 'a <=> 'a && 'a <= 'a && 'a >= 'a).analyze\n+    val actual = Optimize.execute(plan)\n+    val correctAnswer = nonNullableRelation.analyze\n+    comparePlans(actual, correctAnswer)\n+  }\n+\n+  test(\"FALSE Filter\") {\n+    val plan = nonNullableRelation.where('a < 'a || 'a > 'a).analyze\n+    val actual = Optimize.execute(plan)\n+    val correctAnswer = LocalRelation(Seq('a.int.withNullability(false)), Seq.empty)\n+    comparePlans(actual, correctAnswer)\n+  }\n+\n+  test(\"Expression Normalization\") {\n+    val plan = nonNullableRelation.where(\n+      'a * Literal(100) + Pi() === Pi() + Literal(100) * 'a ||"
  }],
  "prId": 12267
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit: we can use `LocalRelation('a.int.withNullability(true))` to define the relation\n",
    "commit": "9ca13be7dd0d0994d072407ede52008e1bcffbb6",
    "createdAt": "2016-04-11T02:07:51Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.analysis._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.Literal.{FalseLiteral, TrueLiteral}\n+import org.apache.spark.sql.catalyst.plans.PlanTest\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.rules._\n+\n+class NonNullableBinaryComparisonSimplificationSuite extends PlanTest with PredicateHelper {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"AnalysisNodes\", Once,\n+        EliminateSubqueryAliases) ::\n+      Batch(\"Constant Folding\", FixedPoint(50),\n+        NullPropagation,\n+        ConstantFolding,\n+        BooleanSimplification,\n+        NonNullableBinaryComparisonSimplification,\n+        PruneFilters) :: Nil\n+  }\n+\n+  val nullableRelation = LocalRelation.fromExternalRows("
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "In that case, usually how can I fill data together briefly? Maybe should I use the following style?\n\n```\nLocalRelation(\n      LocalRelation('a.int.withNullability(true)).output,\n      InternalRow(null) :: InternalRow(null) :: InternalRow(null) :: InternalRow(null) :: Nil)\n```\n",
    "commit": "9ca13be7dd0d0994d072407ede52008e1bcffbb6",
    "createdAt": "2016-04-11T05:26:05Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.analysis._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.Literal.{FalseLiteral, TrueLiteral}\n+import org.apache.spark.sql.catalyst.plans.PlanTest\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.rules._\n+\n+class NonNullableBinaryComparisonSimplificationSuite extends PlanTest with PredicateHelper {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"AnalysisNodes\", Once,\n+        EliminateSubqueryAliases) ::\n+      Batch(\"Constant Folding\", FixedPoint(50),\n+        NullPropagation,\n+        ConstantFolding,\n+        BooleanSimplification,\n+        NonNullableBinaryComparisonSimplification,\n+        PruneFilters) :: Nil\n+  }\n+\n+  val nullableRelation = LocalRelation.fromExternalRows("
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "We usually don't test data for analysis and optimize tests, so I think it's ok to use empty `LocalRelation`. Is there any tests here need to set the data?\n",
    "commit": "9ca13be7dd0d0994d072407ede52008e1bcffbb6",
    "createdAt": "2016-04-11T05:33:03Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.analysis._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.Literal.{FalseLiteral, TrueLiteral}\n+import org.apache.spark.sql.catalyst.plans.PlanTest\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.rules._\n+\n+class NonNullableBinaryComparisonSimplificationSuite extends PlanTest with PredicateHelper {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"AnalysisNodes\", Once,\n+        EliminateSubqueryAliases) ::\n+      Batch(\"Constant Folding\", FixedPoint(50),\n+        NullPropagation,\n+        ConstantFolding,\n+        BooleanSimplification,\n+        NonNullableBinaryComparisonSimplification,\n+        PruneFilters) :: Nil\n+  }\n+\n+  val nullableRelation = LocalRelation.fromExternalRows("
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Let me check again. I'm not sure right now, but when I tested in this PR, the following test case returns different optimized result: `OneRowRelation(?)`?\n\n```\n  test(\"FALSE Filter\") {\n    val plan = nonNullableRelation.where('a < 'a || 'a > 'a).analyze\n    val actual = Optimize.execute(plan)\n    val correctAnswer = LocalRelation(Seq('a.int.withNullability(false)), Seq.empty)\n    comparePlans(actual, correctAnswer)\n  }\n```\n\nI'll be back soon. :)\n",
    "commit": "9ca13be7dd0d0994d072407ede52008e1bcffbb6",
    "createdAt": "2016-04-11T05:40:25Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.analysis._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.Literal.{FalseLiteral, TrueLiteral}\n+import org.apache.spark.sql.catalyst.plans.PlanTest\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.rules._\n+\n+class NonNullableBinaryComparisonSimplificationSuite extends PlanTest with PredicateHelper {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"AnalysisNodes\", Once,\n+        EliminateSubqueryAliases) ::\n+      Batch(\"Constant Folding\", FixedPoint(50),\n+        NullPropagation,\n+        ConstantFolding,\n+        BooleanSimplification,\n+        NonNullableBinaryComparisonSimplification,\n+        PruneFilters) :: Nil\n+  }\n+\n+  val nullableRelation = LocalRelation.fromExternalRows("
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Oh, I was wrong. With the following, pass the all test correctly. \n\n```\n  val nullableRelation = LocalRelation('a.int.withNullability(true))\n  val nonNullableRelation = LocalRelation('a.int.withNullability(false))\n```\n\nThank you again. I'll fix right now.\n",
    "commit": "9ca13be7dd0d0994d072407ede52008e1bcffbb6",
    "createdAt": "2016-04-11T05:43:23Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.analysis._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.Literal.{FalseLiteral, TrueLiteral}\n+import org.apache.spark.sql.catalyst.plans.PlanTest\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.rules._\n+\n+class NonNullableBinaryComparisonSimplificationSuite extends PlanTest with PredicateHelper {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"AnalysisNodes\", Once,\n+        EliminateSubqueryAliases) ::\n+      Batch(\"Constant Folding\", FixedPoint(50),\n+        NullPropagation,\n+        ConstantFolding,\n+        BooleanSimplification,\n+        NonNullableBinaryComparisonSimplification,\n+        PruneFilters) :: Nil\n+  }\n+\n+  val nullableRelation = LocalRelation.fromExternalRows("
  }],
  "prId": 12267
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "1. the `e` is not used.\n2. it's a overkill to use loop here for only 2 cases.\n",
    "commit": "9ca13be7dd0d0994d072407ede52008e1bcffbb6",
    "createdAt": "2016-04-11T06:02:21Z",
    "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.analysis._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.Literal.{FalseLiteral, TrueLiteral}\n+import org.apache.spark.sql.catalyst.plans.PlanTest\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.rules._\n+\n+class NonNullableBinaryComparisonSimplificationSuite extends PlanTest with PredicateHelper {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"AnalysisNodes\", Once,\n+        EliminateSubqueryAliases) ::\n+      Batch(\"Constant Folding\", FixedPoint(50),\n+        NullPropagation,\n+        ConstantFolding,\n+        BooleanSimplification,\n+        NonNullableBinaryComparisonSimplification,\n+        PruneFilters) :: Nil\n+  }\n+\n+  val nullableRelation = LocalRelation('a.int.withNullability(true))\n+  val nonNullableRelation = LocalRelation('a.int.withNullability(false))\n+\n+  test(\"Preserve nullable or non-deterministic exprs\") {\n+    for (e <- Seq('a === 'a, Rand(0) === Rand(0))) {"
  }],
  "prId": 12267
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "ah I see why you need to set the data of `LocalRelation`, otherwise we can't test this case. However, I think `Non-Nullable Simplification Primitive` already cover the `TRUE Filter` and `FALSE Filter`. We only need to prove some binary comparison can be simplified, and using whether `Project` or `Filter` to test it doesn't matter.\n",
    "commit": "9ca13be7dd0d0994d072407ede52008e1bcffbb6",
    "createdAt": "2016-04-11T06:07:41Z",
    "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.analysis._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.Literal.{FalseLiteral, TrueLiteral}\n+import org.apache.spark.sql.catalyst.plans.PlanTest\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.catalyst.rules._\n+\n+class NonNullableBinaryComparisonSimplificationSuite extends PlanTest with PredicateHelper {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"AnalysisNodes\", Once,\n+        EliminateSubqueryAliases) ::\n+      Batch(\"Constant Folding\", FixedPoint(50),\n+        NullPropagation,\n+        ConstantFolding,\n+        BooleanSimplification,\n+        NonNullableBinaryComparisonSimplification,\n+        PruneFilters) :: Nil\n+  }\n+\n+  val nullableRelation = LocalRelation('a.int.withNullability(true))\n+  val nonNullableRelation = LocalRelation('a.int.withNullability(false))\n+\n+  test(\"Preserve nullable or non-deterministic exprs\") {\n+    for (e <- Seq('a === 'a, Rand(0) === Rand(0))) {\n+      val plan = nullableRelation.where('a === 'a).analyze\n+      val actual = Optimize.execute(plan)\n+      val correctAnswer = plan\n+      comparePlans(actual, correctAnswer)\n+    }\n+  }\n+\n+  test(\"Non-Nullable Simplification Primitive\") {\n+    val plan = nonNullableRelation\n+      .select('a === 'a, 'a <=> 'a, 'a <= 'a, 'a >= 'a, 'a < 'a, 'a > 'a).analyze\n+    val actual = Optimize.execute(plan)\n+    val correctAnswer = nonNullableRelation\n+      .select(\n+        Alias(TrueLiteral, \"(a = a)\")(),\n+        Alias(TrueLiteral, \"(a <=> a)\")(),\n+        Alias(TrueLiteral, \"(a <= a)\")(),\n+        Alias(TrueLiteral, \"(a >= a)\")(),\n+        Alias(FalseLiteral, \"(a < a)\")(),\n+        Alias(FalseLiteral, \"(a > a)\")())\n+      .analyze\n+    comparePlans(actual, correctAnswer)\n+  }\n+\n+  test(\"TRUE Filter\") {\n+    val plan = nonNullableRelation.where('a === 'a && 'a <=> 'a && 'a <= 'a && 'a >= 'a).analyze\n+    val actual = Optimize.execute(plan)\n+    val correctAnswer = nonNullableRelation.analyze\n+    comparePlans(actual, correctAnswer)\n+  }\n+\n+  test(\"FALSE Filter\") {\n+    val plan = nonNullableRelation.where('a < 'a || 'a > 'a).analyze\n+    val actual = Optimize.execute(plan)\n+    val correctAnswer = LocalRelation(Seq('a.int.withNullability(false)), Seq.empty)"
  }],
  "prId": 12267
}]