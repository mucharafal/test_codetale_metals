[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "how about `key-1-5`, `key-5-9`, etc.? then we can know the key value range directly from the name.",
    "commit": "8182123f09328ddffabcc1d180c0309f550489f8",
    "createdAt": "2017-02-13T21:27:30Z",
    "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.statsEstimation\n+\n+import java.sql.{Date, Timestamp}\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions.{And, Attribute, AttributeMap, AttributeReference, EqualTo}\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{ColumnStat, Join, Project, Statistics}\n+import org.apache.spark.sql.types.{DateType, TimestampType, _}\n+\n+\n+class JoinEstimationSuite extends StatsEstimationTestBase {\n+\n+  /** Set up tables and its columns for testing */\n+  private val columnInfo: AttributeMap[ColumnStat] = AttributeMap(Seq(\n+    attr(\"key11\") -> ColumnStat(distinctCount = 5, min = Some(1), max = Some(5), nullCount = 0,"
  }],
  "prId": 16228
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "actually we can just use `key12 = key22`, so that it's more different from the test `inner join with multiple equi-join keys`",
    "commit": "8182123f09328ddffabcc1d180c0309f550489f8",
    "createdAt": "2017-02-13T21:35:00Z",
    "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.statsEstimation\n+\n+import java.sql.{Date, Timestamp}\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions.{And, Attribute, AttributeMap, AttributeReference, EqualTo}\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{ColumnStat, Join, Project, Statistics}\n+import org.apache.spark.sql.types.{DateType, TimestampType, _}\n+\n+\n+class JoinEstimationSuite extends StatsEstimationTestBase {\n+\n+  /** Set up tables and its columns for testing */\n+  private val columnInfo: AttributeMap[ColumnStat] = AttributeMap(Seq(\n+    attr(\"key11\") -> ColumnStat(distinctCount = 5, min = Some(1), max = Some(5), nullCount = 0,\n+      avgLen = 4, maxLen = 4),\n+    attr(\"key12\") -> ColumnStat(distinctCount = 5, min = Some(5), max = Some(9), nullCount = 0,\n+      avgLen = 4, maxLen = 4),\n+    attr(\"key21\") -> ColumnStat(distinctCount = 2, min = Some(1), max = Some(2), nullCount = 0,\n+      avgLen = 4, maxLen = 4),\n+    attr(\"key22\") -> ColumnStat(distinctCount = 3, min = Some(2), max = Some(4), nullCount = 0,\n+      avgLen = 4, maxLen = 4),\n+    attr(\"key31\") -> ColumnStat(distinctCount = 2, min = Some(1), max = Some(2), nullCount = 0,\n+      avgLen = 4, maxLen = 4),\n+    attr(\"key32\") -> ColumnStat(distinctCount = 2, min = Some(2), max = Some(3), nullCount = 0,\n+      avgLen = 4, maxLen = 4)\n+  ))\n+\n+  private val nameToAttr: Map[String, Attribute] = columnInfo.map(kv => kv._1.name -> kv._1)\n+  private val nameToColInfo: Map[String, (Attribute, ColumnStat)] =\n+    columnInfo.map(kv => kv._1.name -> kv)\n+\n+  // Suppose table1 (key11 int, key12 int) has 5 records: (1, 9), (2, 8), (3, 7), (4, 6), (5, 5)\n+  private val table1 = StatsTestPlan(\n+    outputList = Seq(\"key11\", \"key12\").map(nameToAttr),\n+    rowCount = 5,\n+    attributeStats = AttributeMap(Seq(\"key11\", \"key12\").map(nameToColInfo)))\n+\n+  // Suppose table2 (key21 int, key22 int) has 3 records: (1, 2), (2, 3), (2, 4)\n+  private val table2 = StatsTestPlan(\n+    outputList = Seq(\"key21\", \"key22\").map(nameToAttr),\n+    rowCount = 3,\n+    attributeStats = AttributeMap(Seq(\"key21\", \"key22\").map(nameToColInfo)))\n+\n+  // Suppose table3 (key31 int, key32 int) has 2 records: (1, 2), (2, 3)\n+  private val table3 = StatsTestPlan(\n+    outputList = Seq(\"key31\", \"key32\").map(nameToAttr),\n+    rowCount = 2,\n+    attributeStats = AttributeMap(Seq(\"key31\", \"key32\").map(nameToColInfo)))\n+\n+  test(\"cross join\") {\n+    // table1 (key11 int, key12 int): (1, 9), (2, 8), (3, 7), (4, 6), (5, 5)\n+    // table2 (key21 int, key22 int): (1, 2), (2, 3), (2, 4)\n+    val join = Join(table1, table2, Cross, None)\n+    val expectedStats = Statistics(\n+      sizeInBytes = 5 * 3 * (8 + 4 * 4),\n+      rowCount = Some(5 * 3),\n+      // Keep the column stat from both sides unchanged.\n+      attributeStats = AttributeMap(Seq(\"key11\", \"key12\", \"key21\", \"key22\").map(nameToColInfo)))\n+    assert(join.stats(conf) == expectedStats)\n+  }\n+\n+  test(\"disjoint inner join\") {\n+    // table1 (key11 int, key12 int): (1, 9), (2, 8), (3, 7), (4, 6), (5, 5)\n+    // table2 (key21 int, key22 int): (1, 2), (2, 3), (2, 4)\n+    // key12 and key22 are disjoint\n+    val join = Join(table1, table2, Inner, Some(\n+      And(EqualTo(nameToAttr(\"key11\"), nameToAttr(\"key21\")),"
  }],
  "prId": 16228
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "are these totally same with the `columnInfo1`? may we can create a method to do this",
    "commit": "8182123f09328ddffabcc1d180c0309f550489f8",
    "createdAt": "2017-02-15T00:31:49Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.statsEstimation\n+\n+import java.sql.{Date, Timestamp}\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.catalyst.expressions.{And, Attribute, AttributeMap, AttributeReference, EqualTo}\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{ColumnStat, Join, Project, Statistics}\n+import org.apache.spark.sql.catalyst.plans.logical.statsEstimation.EstimationUtils._\n+import org.apache.spark.sql.types.{DateType, TimestampType, _}\n+\n+\n+class JoinEstimationSuite extends StatsEstimationTestBase {\n+\n+  /** Set up tables and its columns for testing */\n+  private val columnInfo: AttributeMap[ColumnStat] = AttributeMap(Seq(\n+    attr(\"key-1-5\") -> ColumnStat(distinctCount = 5, min = Some(1), max = Some(5), nullCount = 0,\n+      avgLen = 4, maxLen = 4),\n+    attr(\"key-5-9\") -> ColumnStat(distinctCount = 5, min = Some(5), max = Some(9), nullCount = 0,\n+      avgLen = 4, maxLen = 4),\n+    attr(\"key-1-2\") -> ColumnStat(distinctCount = 2, min = Some(1), max = Some(2), nullCount = 0,\n+      avgLen = 4, maxLen = 4),\n+    attr(\"key-2-4\") -> ColumnStat(distinctCount = 3, min = Some(2), max = Some(4), nullCount = 0,\n+      avgLen = 4, maxLen = 4),\n+    attr(\"key-2-3\") -> ColumnStat(distinctCount = 2, min = Some(2), max = Some(3), nullCount = 0,\n+      avgLen = 4, maxLen = 4)\n+  ))\n+\n+  private val nameToAttr: Map[String, Attribute] = columnInfo.map(kv => kv._1.name -> kv._1)\n+  private val nameToColInfo: Map[String, (Attribute, ColumnStat)] =\n+    columnInfo.map(kv => kv._1.name -> kv)\n+\n+  // Suppose table1 (key-1-5 int, key-5-9 int) has 5 records: (1, 9), (2, 8), (3, 7), (4, 6), (5, 5)\n+  private val table1 = StatsTestPlan(\n+    outputList = Seq(\"key-1-5\", \"key-5-9\").map(nameToAttr),\n+    rowCount = 5,\n+    attributeStats = AttributeMap(Seq(\"key-1-5\", \"key-5-9\").map(nameToColInfo)))\n+\n+  // Suppose table2 (key-1-2 int, key-2-4 int) has 3 records: (1, 2), (2, 3), (2, 4)\n+  private val table2 = StatsTestPlan(\n+    outputList = Seq(\"key-1-2\", \"key-2-4\").map(nameToAttr),\n+    rowCount = 3,\n+    attributeStats = AttributeMap(Seq(\"key-1-2\", \"key-2-4\").map(nameToColInfo)))\n+\n+  // Suppose table3 (key-1-2 int, key-2-3 int) has 2 records: (1, 2), (2, 3)\n+  private val table3 = StatsTestPlan(\n+    outputList = Seq(\"key-1-2\", \"key-2-3\").map(nameToAttr),\n+    rowCount = 2,\n+    attributeStats = AttributeMap(Seq(\"key-1-2\", \"key-2-3\").map(nameToColInfo)))\n+\n+  test(\"cross join\") {\n+    // table1 (key-1-5 int, key-5-9 int): (1, 9), (2, 8), (3, 7), (4, 6), (5, 5)\n+    // table2 (key-1-2 int, key-2-4 int): (1, 2), (2, 3), (2, 4)\n+    val join = Join(table1, table2, Cross, None)\n+    val expectedStats = Statistics(\n+      sizeInBytes = 5 * 3 * (8 + 4 * 4),\n+      rowCount = Some(5 * 3),\n+      // Keep the column stat from both sides unchanged.\n+      attributeStats = AttributeMap(\n+        Seq(\"key-1-5\", \"key-5-9\", \"key-1-2\", \"key-2-4\").map(nameToColInfo)))\n+    assert(join.stats(conf) == expectedStats)\n+  }\n+\n+  test(\"disjoint inner join\") {\n+    // table1 (key-1-5 int, key-5-9 int): (1, 9), (2, 8), (3, 7), (4, 6), (5, 5)\n+    // table2 (key-1-2 int, key-2-4 int): (1, 2), (2, 3), (2, 4)\n+    // key-5-9 and key-2-4 are disjoint\n+    val join = Join(table1, table2, Inner,\n+      Some(EqualTo(nameToAttr(\"key-5-9\"), nameToAttr(\"key-2-4\"))))\n+    val expectedStats = Statistics(\n+      sizeInBytes = 1,\n+      rowCount = Some(0),\n+      attributeStats = AttributeMap(Nil))\n+    assert(join.stats(conf) == expectedStats)\n+  }\n+\n+  test(\"disjoint left outer join\") {\n+    // table1 (key-1-5 int, key-5-9 int): (1, 9), (2, 8), (3, 7), (4, 6), (5, 5)\n+    // table2 (key-1-2 int, key-2-4 int): (1, 2), (2, 3), (2, 4)\n+    // key-5-9 and key-2-4 are disjoint\n+    val join = Join(table1, table2, LeftOuter,\n+      Some(EqualTo(nameToAttr(\"key-5-9\"), nameToAttr(\"key-2-4\"))))\n+    val expectedStats = Statistics(\n+      sizeInBytes = 5 * (8 + 4 * 4),\n+      rowCount = Some(5),\n+      attributeStats = AttributeMap(Seq(\"key-1-5\", \"key-5-9\").map(nameToColInfo) ++\n+        // Null count for right side columns = left row count\n+        Seq(nameToAttr(\"key-1-2\") -> nullColumnStat(nameToAttr(\"key-1-2\").dataType, 5),\n+          nameToAttr(\"key-2-4\") -> nullColumnStat(nameToAttr(\"key-2-4\").dataType, 5))))\n+    assert(join.stats(conf) == expectedStats)\n+  }\n+\n+  test(\"disjoint right outer join\") {\n+    // table1 (key-1-5 int, key-5-9 int): (1, 9), (2, 8), (3, 7), (4, 6), (5, 5)\n+    // table2 (key-1-2 int, key-2-4 int): (1, 2), (2, 3), (2, 4)\n+    // key-5-9 and key-2-4 are disjoint\n+    val join = Join(table1, table2, RightOuter,\n+      Some(EqualTo(nameToAttr(\"key-5-9\"), nameToAttr(\"key-2-4\"))))\n+    val expectedStats = Statistics(\n+      sizeInBytes = 3 * (8 + 4 * 4),\n+      rowCount = Some(3),\n+      attributeStats = AttributeMap(Seq(\"key-1-2\", \"key-2-4\").map(nameToColInfo) ++\n+        // Null count for left side columns = right row count\n+        Seq(nameToAttr(\"key-1-5\") -> nullColumnStat(nameToAttr(\"key-1-5\").dataType, 3),\n+          nameToAttr(\"key-5-9\") -> nullColumnStat(nameToAttr(\"key-5-9\").dataType, 3))))\n+    assert(join.stats(conf) == expectedStats)\n+  }\n+\n+  test(\"disjoint full outer join\") {\n+    // table1 (key-1-5 int, key-5-9 int): (1, 9), (2, 8), (3, 7), (4, 6), (5, 5)\n+    // table2 (key-1-2 int, key-2-4 int): (1, 2), (2, 3), (2, 4)\n+    // key-5-9 and key-2-4 are disjoint\n+    val join = Join(table1, table2, FullOuter,\n+      Some(EqualTo(nameToAttr(\"key-5-9\"), nameToAttr(\"key-2-4\"))))\n+    val expectedStats = Statistics(\n+      sizeInBytes = (5 + 3) * (8 + 4 * 4),\n+      rowCount = Some(5 + 3),\n+      attributeStats = AttributeMap(\n+        // Update null count in column stats.\n+        Seq(nameToAttr(\"key-1-5\") -> columnInfo(nameToAttr(\"key-1-5\")).copy(nullCount = 3),\n+          nameToAttr(\"key-5-9\") -> columnInfo(nameToAttr(\"key-5-9\")).copy(nullCount = 3),\n+          nameToAttr(\"key-1-2\") -> columnInfo(nameToAttr(\"key-1-2\")).copy(nullCount = 5),\n+          nameToAttr(\"key-2-4\") -> columnInfo(nameToAttr(\"key-2-4\")).copy(nullCount = 5))))\n+    assert(join.stats(conf) == expectedStats)\n+  }\n+\n+  test(\"inner join\") {\n+    // table1 (key-1-5 int, key-5-9 int): (1, 9), (2, 8), (3, 7), (4, 6), (5, 5)\n+    // table2 (key-1-2 int, key-2-4 int): (1, 2), (2, 3), (2, 4)\n+    val join = Join(table1, table2, Inner,\n+      Some(EqualTo(nameToAttr(\"key-1-5\"), nameToAttr(\"key-1-2\"))))\n+    // Update column stats for equi-join keys (key-1-5 and key-1-2).\n+    val joinedColStat = ColumnStat(distinctCount = 2, min = Some(1), max = Some(2), nullCount = 0,\n+      avgLen = 4, maxLen = 4)\n+    // Update column stat for other column if #outputRow / #sideRow < 1 (key-5-9), or keep it\n+    // unchanged (key-2-4).\n+    val colStatForkey59 = nameToColInfo(\"key-5-9\")._2.copy(distinctCount = 5 * 3 / 5)\n+\n+    val expectedStats = Statistics(\n+      sizeInBytes = 3 * (8 + 4 * 4),\n+      rowCount = Some(3),\n+      attributeStats = AttributeMap(\n+        Seq(nameToAttr(\"key-1-5\") -> joinedColStat, nameToAttr(\"key-1-2\") -> joinedColStat,\n+          nameToAttr(\"key-5-9\") -> colStatForkey59, nameToColInfo(\"key-2-4\"))))\n+    assert(join.stats(conf) == expectedStats)\n+  }\n+\n+  test(\"inner join with multiple equi-join keys\") {\n+    // table2 (key-1-2 int, key-2-4 int): (1, 2), (2, 3), (2, 4)\n+    // table3 (key-1-2 int, key-2-3 int): (1, 2), (2, 3)\n+    val join = Join(table2, table3, Inner, Some(\n+      And(EqualTo(nameToAttr(\"key-1-2\"), nameToAttr(\"key-1-2\")),\n+        EqualTo(nameToAttr(\"key-2-4\"), nameToAttr(\"key-2-3\")))))\n+\n+    // Update column stats for join keys.\n+    val joinedColStat1 = ColumnStat(distinctCount = 2, min = Some(1), max = Some(2), nullCount = 0,\n+        avgLen = 4, maxLen = 4)\n+    val joinedColStat2 = ColumnStat(distinctCount = 2, min = Some(2), max = Some(3), nullCount = 0,\n+      avgLen = 4, maxLen = 4)\n+\n+    val expectedStats = Statistics(\n+      sizeInBytes = 2 * (8 + 4 * 4),\n+      rowCount = Some(2),\n+      attributeStats = AttributeMap(\n+        Seq(nameToAttr(\"key-1-2\") -> joinedColStat1, nameToAttr(\"key-1-2\") -> joinedColStat1,\n+          nameToAttr(\"key-2-4\") -> joinedColStat2, nameToAttr(\"key-2-3\") -> joinedColStat2)))\n+    assert(join.stats(conf) == expectedStats)\n+  }\n+\n+  test(\"left outer join\") {\n+    // table2 (key-1-2 int, key-2-4 int): (1, 2), (2, 3), (2, 4)\n+    // table3 (key-1-2 int, key-2-3 int): (1, 2), (2, 3)\n+    val join = Join(table3, table2, LeftOuter,\n+      Some(EqualTo(nameToAttr(\"key-2-3\"), nameToAttr(\"key-2-4\"))))\n+    val joinedColStat = ColumnStat(distinctCount = 2, min = Some(2), max = Some(3), nullCount = 0,\n+      avgLen = 4, maxLen = 4)\n+\n+    val expectedStats = Statistics(\n+      sizeInBytes = 2 * (8 + 4 * 4),\n+      rowCount = Some(2),\n+      // Keep the column stat from left side unchanged.\n+      attributeStats = AttributeMap(\n+        Seq(nameToColInfo(\"key-1-2\"), nameToColInfo(\"key-2-3\"),\n+          nameToColInfo(\"key-1-2\"), nameToAttr(\"key-2-4\") -> joinedColStat)))\n+    assert(join.stats(conf) == expectedStats)\n+  }\n+\n+  test(\"right outer join\") {\n+    // table2 (key-1-2 int, key-2-4 int): (1, 2), (2, 3), (2, 4)\n+    // table3 (key-1-2 int, key-2-3 int): (1, 2), (2, 3)\n+    val join = Join(table2, table3, RightOuter,\n+      Some(EqualTo(nameToAttr(\"key-2-4\"), nameToAttr(\"key-2-3\"))))\n+    val joinedColStat = ColumnStat(distinctCount = 2, min = Some(2), max = Some(3), nullCount = 0,\n+      avgLen = 4, maxLen = 4)\n+\n+    val expectedStats = Statistics(\n+      sizeInBytes = 2 * (8 + 4 * 4),\n+      rowCount = Some(2),\n+      // Keep the column stat from right side unchanged.\n+      attributeStats = AttributeMap(\n+        Seq(nameToColInfo(\"key-1-2\"), nameToAttr(\"key-2-4\") -> joinedColStat,\n+          nameToColInfo(\"key-1-2\"), nameToColInfo(\"key-2-3\"))))\n+    assert(join.stats(conf) == expectedStats)\n+  }\n+\n+  test(\"full outer join\") {\n+    // table2 (key-1-2 int, key-2-4 int): (1, 2), (2, 3), (2, 4)\n+    // table3 (key-1-2 int, key-2-3 int): (1, 2), (2, 3)\n+    val join = Join(table2, table3, FullOuter,\n+      Some(EqualTo(nameToAttr(\"key-2-4\"), nameToAttr(\"key-2-3\"))))\n+\n+    val expectedStats = Statistics(\n+      sizeInBytes = 3 * (8 + 4 * 4),\n+      rowCount = Some(3),\n+      // Keep the column stat from both sides unchanged.\n+      attributeStats = AttributeMap(Seq(nameToColInfo(\"key-1-2\"), nameToColInfo(\"key-2-4\"),\n+        nameToColInfo(\"key-1-2\"), nameToColInfo(\"key-2-3\"))))\n+    assert(join.stats(conf) == expectedStats)\n+  }\n+\n+  test(\"left semi/anti join\") {\n+    // table2 (key-1-2 int, key-2-4 int): (1, 2), (2, 3), (2, 4)\n+    // table3 (key-1-2 int, key-2-3 int): (1, 2), (2, 3)\n+    Seq(LeftSemi, LeftAnti).foreach { jt =>\n+      val join = Join(table2, table3, jt,\n+        Some(EqualTo(nameToAttr(\"key-2-4\"), nameToAttr(\"key-2-3\"))))\n+      // For now we just propagate the statistics from left side for left semi/anti join.\n+      val expectedStats = Statistics(\n+        sizeInBytes = 3 * (8 + 4 * 2),\n+        rowCount = Some(3),\n+        attributeStats = AttributeMap(Seq(nameToColInfo(\"key-1-2\"), nameToColInfo(\"key-2-4\"))))\n+      assert(join.stats(conf) == expectedStats)\n+    }\n+  }\n+\n+  test(\"test join keys of different types\") {\n+    val dec1 = new java.math.BigDecimal(\"1.000000000000000000\")\n+    val dec2 = new java.math.BigDecimal(\"8.000000000000000000\")\n+    val d1 = Date.valueOf(\"2016-05-08\")\n+    val d2 = Date.valueOf(\"2016-05-09\")\n+    val t1 = Timestamp.valueOf(\"2016-05-08 00:00:01\")\n+    val t2 = Timestamp.valueOf(\"2016-05-09 00:00:02\")\n+\n+    /** Columns in a table with only one row */\n+    val columnInfo1 = mutable.LinkedHashMap[Attribute, ColumnStat](\n+      AttributeReference(\"cbool\", BooleanType)() -> ColumnStat(distinctCount = 1,\n+        min = Some(false), max = Some(false), nullCount = 0, avgLen = 1, maxLen = 1),\n+      AttributeReference(\"cbyte\", ByteType)() -> ColumnStat(distinctCount = 1,\n+        min = Some(1L), max = Some(1L), nullCount = 0, avgLen = 1, maxLen = 1),\n+      AttributeReference(\"cshort\", ShortType)() -> ColumnStat(distinctCount = 1,\n+        min = Some(1L), max = Some(1L), nullCount = 0, avgLen = 2, maxLen = 2),\n+      AttributeReference(\"cint\", IntegerType)() -> ColumnStat(distinctCount = 1,\n+        min = Some(1L), max = Some(1L), nullCount = 0, avgLen = 4, maxLen = 4),\n+      AttributeReference(\"clong\", LongType)() -> ColumnStat(distinctCount = 1,\n+        min = Some(1L), max = Some(1L), nullCount = 0, avgLen = 8, maxLen = 8),\n+      AttributeReference(\"cdouble\", DoubleType)() -> ColumnStat(distinctCount = 1,\n+        min = Some(1.0), max = Some(1.0), nullCount = 0, avgLen = 8, maxLen = 8),\n+      AttributeReference(\"cfloat\", FloatType)() -> ColumnStat(distinctCount = 1,\n+        min = Some(1.0), max = Some(1.0), nullCount = 0, avgLen = 4, maxLen = 4),\n+      AttributeReference(\"cdecimal\", DecimalType.SYSTEM_DEFAULT)() -> ColumnStat(distinctCount = 1,\n+        min = Some(dec1), max = Some(dec1), nullCount = 0, avgLen = 16, maxLen = 16),\n+      AttributeReference(\"cstring\", StringType)() -> ColumnStat(distinctCount = 1,\n+        min = None, max = None, nullCount = 0, avgLen = 3, maxLen = 3),\n+      AttributeReference(\"cbinary\", BinaryType)() -> ColumnStat(distinctCount = 1,\n+        min = None, max = None, nullCount = 0, avgLen = 3, maxLen = 3),\n+      AttributeReference(\"cdate\", DateType)() -> ColumnStat(distinctCount = 1,\n+        min = Some(d1), max = Some(d1), nullCount = 0, avgLen = 4, maxLen = 4),\n+      AttributeReference(\"ctimestamp\", TimestampType)() -> ColumnStat(distinctCount = 1,\n+        min = Some(t1), max = Some(t1), nullCount = 0, avgLen = 8, maxLen = 8)\n+    )\n+\n+    /** Columns in a table with two rows */\n+    val columnInfo2 = mutable.LinkedHashMap[Attribute, ColumnStat]("
  }],
  "prId": 16228
}]