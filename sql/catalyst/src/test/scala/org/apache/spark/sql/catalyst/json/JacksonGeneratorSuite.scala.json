[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I think previous result was a valid test case .. ",
    "commit": "559c201a1ee45b4525d3ec455499f2dd4eb6b86a",
    "createdAt": "2018-03-23T12:11:36Z",
    "diffHunk": "@@ -56,7 +56,7 @@ class JacksonGeneratorSuite extends SparkFunSuite {\n     val gen = new JacksonGenerator(dataType, writer, option)\n     gen.write(input)\n     gen.flush()\n-    assert(writer.toString === \"\"\"[{}]\"\"\")\n+    assert(writer.toString === \"\"\"[{\"a\":null}]\"\"\")",
    "line": 5
  }, {
    "author": {
      "login": "sameeragarwal"
    },
    "body": "+1",
    "commit": "559c201a1ee45b4525d3ec455499f2dd4eb6b86a",
    "createdAt": "2018-03-23T16:47:54Z",
    "diffHunk": "@@ -56,7 +56,7 @@ class JacksonGeneratorSuite extends SparkFunSuite {\n     val gen = new JacksonGenerator(dataType, writer, option)\n     gen.write(input)\n     gen.flush()\n-    assert(writer.toString === \"\"\"[{}]\"\"\")\n+    assert(writer.toString === \"\"\"[{\"a\":null}]\"\"\")",
    "line": 5
  }, {
    "author": {
      "login": "makagonov"
    },
    "body": "@HyukjinKwon actually, it looks like the result should be `[null]` rather than `[{}]`.\r\nLook at the following repro from spark-shell (downloaded binaries):\r\n```scala\r\nscala> val df = sqlContext.sql(\"\"\" select array(cast(null as struct<k:string>)) as my_array\"\"\")\r\ndf: org.apache.spark.sql.DataFrame = [my_array: array<struct<k:string>>]\r\n\r\nscala> df.printSchema\r\nroot\r\n |-- my_array: array (nullable = false)\r\n |    |-- element: struct (containsNull = true)\r\n |    |    |-- k: string (nullable = true)\r\nscala> df.toJSON.collect().foreach(println)\r\n{\"my_array\":[null]}\r\nscala> df.select(to_json($\"my_array\")).collect().foreach(x => println(x(0)))\r\n[null]\r\n```\r\n\r\nIn older version of `JacksonGenerator`, we had a filter by element value, and if it was `null`, `gen.writeNull()` was called no matter what the type was ([old implementation](https://github.com/apache/spark/blob/3258f27a881dfeb5ab8bae90c338603fa4b6f9d8/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/json/JacksonGenerator.scala#L41)). But currently, we're calling `gen.writeStartObject()...gen.writeEndObject()` no matter if the value is null.\r\n\r\nI couldn't repro this with a query, but when `StructsToJson` is called from this unit test, it goes through `JacksonGenerator.arrElementWriter` which has lines\r\n```scala\r\ncase st: StructType =>\r\n(arr: SpecializedGetters, i: Int) => {\r\n  writeObject(writeFields(arr.getStruct(i, st.length), st, rootFieldWriters))\r\n}\r\n```\r\nthat makes it print json object even there is `null`.\r\n\r\nI'll look into this later and will try to find the easy workaround.",
    "commit": "559c201a1ee45b4525d3ec455499f2dd4eb6b86a",
    "createdAt": "2018-03-23T19:30:22Z",
    "diffHunk": "@@ -56,7 +56,7 @@ class JacksonGeneratorSuite extends SparkFunSuite {\n     val gen = new JacksonGenerator(dataType, writer, option)\n     gen.write(input)\n     gen.flush()\n-    assert(writer.toString === \"\"\"[{}]\"\"\")\n+    assert(writer.toString === \"\"\"[{\"a\":null}]\"\"\")",
    "line": 5
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I think you should compare this:\r\n\r\n```scala\r\nscala> sql(\"\"\" select array(cast(null as struct<k:string>)) as my_array\"\"\").toJSON.collect().foreach(println)\r\n{\"my_array\":[null]}\r\n\r\nscala> sql(\"\"\" select array(struct(cast(null as string))) as my_array\"\"\").toJSON.collect().foreach(println)\r\n{\"my_array\":[{}]}\r\n```",
    "commit": "559c201a1ee45b4525d3ec455499f2dd4eb6b86a",
    "createdAt": "2018-03-24T02:26:25Z",
    "diffHunk": "@@ -56,7 +56,7 @@ class JacksonGeneratorSuite extends SparkFunSuite {\n     val gen = new JacksonGenerator(dataType, writer, option)\n     gen.write(input)\n     gen.flush()\n-    assert(writer.toString === \"\"\"[{}]\"\"\")\n+    assert(writer.toString === \"\"\"[{\"a\":null}]\"\"\")",
    "line": 5
  }],
  "prId": 20884
}]