[{
  "comments": [{
    "author": {
      "login": "MaxGekk"
    },
    "body": "Can you check positive case when two arrays have the same element type? and the same elements.",
    "commit": "a30de22183cab3cde90fce6029cd03dfc5b5758a",
    "createdAt": "2018-06-26T11:22:45Z",
    "diffHunk": "@@ -104,4 +104,13 @@ class ComplexDataSuite extends SparkFunSuite {\n     // The copied data should not be changed externally.\n     assert(copied.getStruct(0, 1).getUTF8String(0).toString == \"a\")\n   }\n+\n+  test(\"SPARK-24659: GenericArrayData.equals should respect element type differences\") {\n+    // Spark SQL considers array<int> and array<long> to be incompatible,\n+    // so an underlying implementation of array type should return false in this case.\n+    val array1 = new GenericArrayData(Array[Int](123))\n+    val array2 = new GenericArrayData(Array[Long](123L))\n+\n+    assert(!array1.equals(array2))"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Good catch! Can you test short and byte, too?\r\n```\r\n\r\n// GenericArrayData\r\nscala> val arrayByte= new GenericArrayData(Array[Short](123.toByte))\r\nscala> val arrayShort = new GenericArrayData(Array[Short](123.toShort))\r\nscala> val arrayInt = new GenericArrayData(Array[Int](123))\r\nscala> val arrayLong = new GenericArrayData(Array[Long](123L))\r\nscala> arrayByte.equals(arrayLong)\r\nres8: Boolean = true\r\n\r\nscala> arrayByte.equals(arrayInt)\r\nres9: Boolean = true\r\n\r\nscala> arrayShort.equals(arrayInt)\r\nres10: Boolean = true\r\n\r\nscala> arrayShort.equals(arrayLong)\r\nres11: Boolean = true\r\n\r\n\r\n// UnsafeArrayData\r\nscala> val unsafeByte = ExpressionEncoder[Array[Byte]].resolveAndBind().toRow(arrayByte).getArray(0)\r\nscala> val unsafeShort = ExpressionEncoder[Array[Short]].resolveAndBind().toRow(arrayShort).getArray(0)\r\nscala> val unsafeInt = ExpressionEncoder[Array[Int]].resolveAndBind().toRow(arrayInt).getArray(0)\r\nscala> val unsafeLong = ExpressionEncoder[Array[Long]].resolveAndBind().toRow(arrayLong).getArray(0)\r\nscala> arrayByte.equals(arrayLong)\r\nres12: Boolean = false\r\n\r\nscala> arrayByte.equals(arrayInt)\r\nres13: Boolean = false\r\n\r\nscala> arrayShort.equals(arrayInt)\r\nres14: Boolean = false\r\n\r\nscala> arrayShort.equals(arrayLong)\r\nres15: Boolean = false\r\n```",
    "commit": "a30de22183cab3cde90fce6029cd03dfc5b5758a",
    "createdAt": "2018-06-26T12:09:19Z",
    "diffHunk": "@@ -104,4 +104,13 @@ class ComplexDataSuite extends SparkFunSuite {\n     // The copied data should not be changed externally.\n     assert(copied.getStruct(0, 1).getUTF8String(0).toString == \"a\")\n   }\n+\n+  test(\"SPARK-24659: GenericArrayData.equals should respect element type differences\") {\n+    // Spark SQL considers array<int> and array<long> to be incompatible,\n+    // so an underlying implementation of array type should return false in this case.\n+    val array1 = new GenericArrayData(Array[Int](123))\n+    val array2 = new GenericArrayData(Array[Long](123L))\n+\n+    assert(!array1.equals(array2))"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "without schema, Spark can never compare a generic and an unsafe array. This fix is not a real bug fix, but makes the `GenericArrayData` more clear about equals semantic, which is good to have, and might be useful when writing tests.",
    "commit": "a30de22183cab3cde90fce6029cd03dfc5b5758a",
    "createdAt": "2018-06-26T15:22:38Z",
    "diffHunk": "@@ -104,4 +104,13 @@ class ComplexDataSuite extends SparkFunSuite {\n     // The copied data should not be changed externally.\n     assert(copied.getStruct(0, 1).getUTF8String(0).toString == \"a\")\n   }\n+\n+  test(\"SPARK-24659: GenericArrayData.equals should respect element type differences\") {\n+    // Spark SQL considers array<int> and array<long> to be incompatible,\n+    // so an underlying implementation of array type should return false in this case.\n+    val array1 = new GenericArrayData(Array[Int](123))\n+    val array2 = new GenericArrayData(Array[Long](123L))\n+\n+    assert(!array1.equals(array2))"
  }],
  "prId": 21643
}, {
  "comments": [{
    "author": {
      "login": "MaxGekk"
    },
    "body": "It is not important but if you are checking corner cases, probably, it makes sense to pass values like `Long.MinValue` and `Double.MaxValue`",
    "commit": "a30de22183cab3cde90fce6029cd03dfc5b5758a",
    "createdAt": "2018-06-26T19:23:05Z",
    "diffHunk": "@@ -104,4 +104,38 @@ class ComplexDataSuite extends SparkFunSuite {\n     // The copied data should not be changed externally.\n     assert(copied.getStruct(0, 1).getUTF8String(0).toString == \"a\")\n   }\n+\n+  test(\"SPARK-24659: GenericArrayData.equals should respect element type differences\") {\n+    import scala.reflect.ClassTag\n+\n+    // Expected positive cases\n+    def arraysShouldEqual[T: ClassTag](element: T*): Unit = {\n+      val array1 = new GenericArrayData(Array[T](element: _*))\n+      val array2 = new GenericArrayData(Array[T](element: _*))\n+      assert(array1.equals(array2))\n+    }\n+    arraysShouldEqual(true, false)                            // Boolean\n+    arraysShouldEqual(0.toByte, 123.toByte, (-123).toByte)    // Byte\n+    arraysShouldEqual(0.toShort, 123.toShort, (-256).toShort) // Short\n+    arraysShouldEqual(0, 123, -65536)                         // Int\n+    arraysShouldEqual(0L, 123L, -65536L)                      // Long"
  }, {
    "author": {
      "login": "rednaxelafx"
    },
    "body": "That's a good one. I can do that (and NaNs/Infinity for floating point types too)",
    "commit": "a30de22183cab3cde90fce6029cd03dfc5b5758a",
    "createdAt": "2018-06-26T19:24:21Z",
    "diffHunk": "@@ -104,4 +104,38 @@ class ComplexDataSuite extends SparkFunSuite {\n     // The copied data should not be changed externally.\n     assert(copied.getStruct(0, 1).getUTF8String(0).toString == \"a\")\n   }\n+\n+  test(\"SPARK-24659: GenericArrayData.equals should respect element type differences\") {\n+    import scala.reflect.ClassTag\n+\n+    // Expected positive cases\n+    def arraysShouldEqual[T: ClassTag](element: T*): Unit = {\n+      val array1 = new GenericArrayData(Array[T](element: _*))\n+      val array2 = new GenericArrayData(Array[T](element: _*))\n+      assert(array1.equals(array2))\n+    }\n+    arraysShouldEqual(true, false)                            // Boolean\n+    arraysShouldEqual(0.toByte, 123.toByte, (-123).toByte)    // Byte\n+    arraysShouldEqual(0.toShort, 123.toShort, (-256).toShort) // Short\n+    arraysShouldEqual(0, 123, -65536)                         // Int\n+    arraysShouldEqual(0L, 123L, -65536L)                      // Long"
  }],
  "prId": 21643
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "nit:  you can move this import to the head of this file.",
    "commit": "a30de22183cab3cde90fce6029cd03dfc5b5758a",
    "createdAt": "2018-06-27T01:01:33Z",
    "diffHunk": "@@ -104,4 +104,40 @@ class ComplexDataSuite extends SparkFunSuite {\n     // The copied data should not be changed externally.\n     assert(copied.getStruct(0, 1).getUTF8String(0).toString == \"a\")\n   }\n+\n+  test(\"SPARK-24659: GenericArrayData.equals should respect element type differences\") {\n+    import scala.reflect.ClassTag",
    "line": 6
  }, {
    "author": {
      "login": "rednaxelafx"
    },
    "body": "Thanks for your suggestion! I'm used to making one-off imports inside a function when an import is only used within that function, so that the scope is as narrow as possible without being disturbing.\r\nAre there any Spark coding style guidelines that suggest otherwise? If so I'll follow the guideline and always import at the beginning of the file.",
    "commit": "a30de22183cab3cde90fce6029cd03dfc5b5758a",
    "createdAt": "2018-06-27T05:27:31Z",
    "diffHunk": "@@ -104,4 +104,40 @@ class ComplexDataSuite extends SparkFunSuite {\n     // The copied data should not be changed externally.\n     assert(copied.getStruct(0, 1).getUTF8String(0).toString == \"a\")\n   }\n+\n+  test(\"SPARK-24659: GenericArrayData.equals should respect element type differences\") {\n+    import scala.reflect.ClassTag",
    "line": 6
  }],
  "prId": 21643
}]