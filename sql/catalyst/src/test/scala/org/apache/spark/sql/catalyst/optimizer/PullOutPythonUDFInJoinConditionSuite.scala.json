[{
  "comments": [{
    "author": {
      "login": "mgaido91"
    },
    "body": "nit: `unsupportedJoinTypes`?",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-08T10:41:34Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.scalatest.Matchers._\n+\n+import org.apache.spark.api.python.PythonEvalType\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.PythonUDF\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.internal.SQLConf._\n+import org.apache.spark.sql.types.BooleanType\n+\n+class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Extract PythonUDF From JoinCondition\", Once,\n+        PullOutPythonUDFInJoinCondition) ::\n+      Batch(\"Check Cartesian Products\", Once,\n+        CheckCartesianProducts) :: Nil\n+  }\n+\n+  val testRelationLeft = LocalRelation('a.int, 'b.int)\n+  val testRelationRight = LocalRelation('c.int, 'd.int)\n+\n+  // Dummy python UDF for testing. Unable to execute.\n+  val pythonUDF = PythonUDF(\"pythonUDF\", null,\n+    BooleanType,\n+    Seq.empty,\n+    PythonEvalType.SQL_BATCHED_UDF,\n+    udfDeterministic = true)\n+\n+  val notSupportJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Thanks, done in 38b1555.",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-09T07:43:51Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.scalatest.Matchers._\n+\n+import org.apache.spark.api.python.PythonEvalType\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.PythonUDF\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.internal.SQLConf._\n+import org.apache.spark.sql.types.BooleanType\n+\n+class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Extract PythonUDF From JoinCondition\", Once,\n+        PullOutPythonUDFInJoinCondition) ::\n+      Batch(\"Check Cartesian Products\", Once,\n+        CheckCartesianProducts) :: Nil\n+  }\n+\n+  val testRelationLeft = LocalRelation('a.int, 'b.int)\n+  val testRelationRight = LocalRelation('c.int, 'd.int)\n+\n+  // Dummy python UDF for testing. Unable to execute.\n+  val pythonUDF = PythonUDF(\"pythonUDF\", null,\n+    BooleanType,\n+    Seq.empty,\n+    PythonEvalType.SQL_BATCHED_UDF,\n+    udfDeterministic = true)\n+\n+  val notSupportJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)"
  }],
  "prId": 22955
}, {
  "comments": [{
    "author": {
      "login": "mgaido91"
    },
    "body": "nit: `intercept` is more widespread in the codebase, we can maybe use that for consistency..",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-08T10:43:26Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.scalatest.Matchers._\n+\n+import org.apache.spark.api.python.PythonEvalType\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.PythonUDF\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.internal.SQLConf._\n+import org.apache.spark.sql.types.BooleanType\n+\n+class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Extract PythonUDF From JoinCondition\", Once,\n+        PullOutPythonUDFInJoinCondition) ::\n+      Batch(\"Check Cartesian Products\", Once,\n+        CheckCartesianProducts) :: Nil\n+  }\n+\n+  val testRelationLeft = LocalRelation('a.int, 'b.int)\n+  val testRelationRight = LocalRelation('c.int, 'd.int)\n+\n+  // Dummy python UDF for testing. Unable to execute.\n+  val pythonUDF = PythonUDF(\"pythonUDF\", null,\n+    BooleanType,\n+    Seq.empty,\n+    PythonEvalType.SQL_BATCHED_UDF,\n+    udfDeterministic = true)\n+\n+  val notSupportJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n+\n+  test(\"inner join condition with python udf only\") {\n+    val query = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = Inner,\n+      condition = Some(pythonUDF))\n+    val expected = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = Inner,\n+      condition = None).where(pythonUDF).analyze\n+\n+    // AnalysisException thrown by CheckCartesianProducts while spark.sql.crossJoin.enabled=false\n+    val exception = the [AnalysisException] thrownBy {"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Thanks, done in 38b1555.",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-09T07:44:01Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.scalatest.Matchers._\n+\n+import org.apache.spark.api.python.PythonEvalType\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.PythonUDF\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.internal.SQLConf._\n+import org.apache.spark.sql.types.BooleanType\n+\n+class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Extract PythonUDF From JoinCondition\", Once,\n+        PullOutPythonUDFInJoinCondition) ::\n+      Batch(\"Check Cartesian Products\", Once,\n+        CheckCartesianProducts) :: Nil\n+  }\n+\n+  val testRelationLeft = LocalRelation('a.int, 'b.int)\n+  val testRelationRight = LocalRelation('c.int, 'd.int)\n+\n+  // Dummy python UDF for testing. Unable to execute.\n+  val pythonUDF = PythonUDF(\"pythonUDF\", null,\n+    BooleanType,\n+    Seq.empty,\n+    PythonEvalType.SQL_BATCHED_UDF,\n+    udfDeterministic = true)\n+\n+  val notSupportJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n+\n+  test(\"inner join condition with python udf only\") {\n+    val query = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = Inner,\n+      condition = Some(pythonUDF))\n+    val expected = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = Inner,\n+      condition = None).where(pythonUDF).analyze\n+\n+    // AnalysisException thrown by CheckCartesianProducts while spark.sql.crossJoin.enabled=false\n+    val exception = the [AnalysisException] thrownBy {"
  }],
  "prId": 22955
}, {
  "comments": [{
    "author": {
      "login": "mgaido91"
    },
    "body": "shall we dedup the code of this and the next testcase? they differ only by the join type...",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-08T10:45:43Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.scalatest.Matchers._\n+\n+import org.apache.spark.api.python.PythonEvalType\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.PythonUDF\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.internal.SQLConf._\n+import org.apache.spark.sql.types.BooleanType\n+\n+class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Extract PythonUDF From JoinCondition\", Once,\n+        PullOutPythonUDFInJoinCondition) ::\n+      Batch(\"Check Cartesian Products\", Once,\n+        CheckCartesianProducts) :: Nil\n+  }\n+\n+  val testRelationLeft = LocalRelation('a.int, 'b.int)\n+  val testRelationRight = LocalRelation('c.int, 'd.int)\n+\n+  // Dummy python UDF for testing. Unable to execute.\n+  val pythonUDF = PythonUDF(\"pythonUDF\", null,\n+    BooleanType,\n+    Seq.empty,\n+    PythonEvalType.SQL_BATCHED_UDF,\n+    udfDeterministic = true)\n+\n+  val notSupportJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n+\n+  test(\"inner join condition with python udf only\") {"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Sorry for this, done in 38b1555.",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-09T07:44:21Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.scalatest.Matchers._\n+\n+import org.apache.spark.api.python.PythonEvalType\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.PythonUDF\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.internal.SQLConf._\n+import org.apache.spark.sql.types.BooleanType\n+\n+class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Extract PythonUDF From JoinCondition\", Once,\n+        PullOutPythonUDFInJoinCondition) ::\n+      Batch(\"Check Cartesian Products\", Once,\n+        CheckCartesianProducts) :: Nil\n+  }\n+\n+  val testRelationLeft = LocalRelation('a.int, 'b.int)\n+  val testRelationRight = LocalRelation('c.int, 'd.int)\n+\n+  // Dummy python UDF for testing. Unable to execute.\n+  val pythonUDF = PythonUDF(\"pythonUDF\", null,\n+    BooleanType,\n+    Seq.empty,\n+    PythonEvalType.SQL_BATCHED_UDF,\n+    udfDeterministic = true)\n+\n+  val notSupportJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n+\n+  test(\"inner join condition with python udf only\") {"
  }],
  "prId": 22955
}, {
  "comments": [{
    "author": {
      "login": "mgaido91"
    },
    "body": "shall we add more cases like this for `Or` instead of `And`? And with several UDF/other conditions? Thanks.",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-08T10:47:44Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.scalatest.Matchers._\n+\n+import org.apache.spark.api.python.PythonEvalType\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.PythonUDF\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.internal.SQLConf._\n+import org.apache.spark.sql.types.BooleanType\n+\n+class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Extract PythonUDF From JoinCondition\", Once,\n+        PullOutPythonUDFInJoinCondition) ::\n+      Batch(\"Check Cartesian Products\", Once,\n+        CheckCartesianProducts) :: Nil\n+  }\n+\n+  val testRelationLeft = LocalRelation('a.int, 'b.int)\n+  val testRelationRight = LocalRelation('c.int, 'd.int)\n+\n+  // Dummy python UDF for testing. Unable to execute.\n+  val pythonUDF = PythonUDF(\"pythonUDF\", null,\n+    BooleanType,\n+    Seq.empty,\n+    PythonEvalType.SQL_BATCHED_UDF,\n+    udfDeterministic = true)\n+\n+  val notSupportJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n+\n+  test(\"inner join condition with python udf only\") {\n+    val query = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = Inner,\n+      condition = Some(pythonUDF))\n+    val expected = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = Inner,\n+      condition = None).where(pythonUDF).analyze\n+\n+    // AnalysisException thrown by CheckCartesianProducts while spark.sql.crossJoin.enabled=false\n+    val exception = the [AnalysisException] thrownBy {\n+      Optimize.execute(query.analyze)\n+    }\n+    assert(exception.message.startsWith(\"Detected implicit cartesian product\"))\n+\n+    // pull out the python udf while set spark.sql.crossJoin.enabled=true\n+    withSQLConf(CROSS_JOINS_ENABLED.key -> \"true\") {\n+      val optimized = Optimize.execute(query.analyze)\n+      comparePlans(optimized, expected)\n+    }\n+  }\n+\n+  test(\"left semi join condition with python udf only\") {\n+    val query = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = LeftSemi,\n+      condition = Some(pythonUDF))\n+    val expected = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = Inner,\n+      condition = None).where(pythonUDF).select('a, 'b).analyze\n+\n+    // AnalysisException thrown by CheckCartesianProducts while spark.sql.crossJoin.enabled=false\n+    val exception = the [AnalysisException] thrownBy {\n+      Optimize.execute(query.analyze)\n+    }\n+    assert(exception.message.startsWith(\"Detected implicit cartesian product\"))\n+\n+    // pull out the python udf while set spark.sql.crossJoin.enabled=true\n+    withSQLConf(CROSS_JOINS_ENABLED.key -> \"true\") {\n+      val optimized = Optimize.execute(query.analyze)\n+      comparePlans(optimized, expected)\n+    }\n+  }\n+\n+  test(\"python udf with other common condition\") {"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Thanks, add more cases in 38b1555.",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-09T07:45:29Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.scalatest.Matchers._\n+\n+import org.apache.spark.api.python.PythonEvalType\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.PythonUDF\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.internal.SQLConf._\n+import org.apache.spark.sql.types.BooleanType\n+\n+class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Extract PythonUDF From JoinCondition\", Once,\n+        PullOutPythonUDFInJoinCondition) ::\n+      Batch(\"Check Cartesian Products\", Once,\n+        CheckCartesianProducts) :: Nil\n+  }\n+\n+  val testRelationLeft = LocalRelation('a.int, 'b.int)\n+  val testRelationRight = LocalRelation('c.int, 'd.int)\n+\n+  // Dummy python UDF for testing. Unable to execute.\n+  val pythonUDF = PythonUDF(\"pythonUDF\", null,\n+    BooleanType,\n+    Seq.empty,\n+    PythonEvalType.SQL_BATCHED_UDF,\n+    udfDeterministic = true)\n+\n+  val notSupportJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n+\n+  test(\"inner join condition with python udf only\") {\n+    val query = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = Inner,\n+      condition = Some(pythonUDF))\n+    val expected = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = Inner,\n+      condition = None).where(pythonUDF).analyze\n+\n+    // AnalysisException thrown by CheckCartesianProducts while spark.sql.crossJoin.enabled=false\n+    val exception = the [AnalysisException] thrownBy {\n+      Optimize.execute(query.analyze)\n+    }\n+    assert(exception.message.startsWith(\"Detected implicit cartesian product\"))\n+\n+    // pull out the python udf while set spark.sql.crossJoin.enabled=true\n+    withSQLConf(CROSS_JOINS_ENABLED.key -> \"true\") {\n+      val optimized = Optimize.execute(query.analyze)\n+      comparePlans(optimized, expected)\n+    }\n+  }\n+\n+  test(\"left semi join condition with python udf only\") {\n+    val query = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = LeftSemi,\n+      condition = Some(pythonUDF))\n+    val expected = testRelationLeft.join(\n+      testRelationRight,\n+      joinType = Inner,\n+      condition = None).where(pythonUDF).select('a, 'b).analyze\n+\n+    // AnalysisException thrown by CheckCartesianProducts while spark.sql.crossJoin.enabled=false\n+    val exception = the [AnalysisException] thrownBy {\n+      Optimize.execute(query.analyze)\n+    }\n+    assert(exception.message.startsWith(\"Detected implicit cartesian product\"))\n+\n+    // pull out the python udf while set spark.sql.crossJoin.enabled=true\n+    withSQLConf(CROSS_JOINS_ENABLED.key -> \"true\") {\n+      val optimized = Optimize.execute(query.analyze)\n+      comparePlans(optimized, expected)\n+    }\n+  }\n+\n+  test(\"python udf with other common condition\") {"
  }],
  "prId": 22955
}, {
  "comments": [{
    "author": {
      "login": "mgaido91"
    },
    "body": "better naming? what does it mean `WithConf`?",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-10T09:57:16Z",
    "diffHunk": "@@ -50,20 +50,11 @@ class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n     PythonEvalType.SQL_BATCHED_UDF,\n     udfDeterministic = true)\n \n-  val notSupportJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n-\n-  test(\"inner join condition with python udf only\") {\n-    val query = testRelationLeft.join(\n-      testRelationRight,\n-      joinType = Inner,\n-      condition = Some(pythonUDF))\n-    val expected = testRelationLeft.join(\n-      testRelationRight,\n-      joinType = Inner,\n-      condition = None).where(pythonUDF).analyze\n+  val unsupportedJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n \n+  private def comparePlansWithConf(query: LogicalPlan, expected: LogicalPlan): Unit = {"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "how about `comparePlanWithCrossJoinEnable`? Just afraid it's too long at first, any advise :) Thanks. ",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-11T13:57:13Z",
    "diffHunk": "@@ -50,20 +50,11 @@ class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n     PythonEvalType.SQL_BATCHED_UDF,\n     udfDeterministic = true)\n \n-  val notSupportJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n-\n-  test(\"inner join condition with python udf only\") {\n-    val query = testRelationLeft.join(\n-      testRelationRight,\n-      joinType = Inner,\n-      condition = Some(pythonUDF))\n-    val expected = testRelationLeft.join(\n-      testRelationRight,\n-      joinType = Inner,\n-      condition = None).where(pythonUDF).analyze\n+  val unsupportedJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n \n+  private def comparePlansWithConf(query: LogicalPlan, expected: LogicalPlan): Unit = {"
  }],
  "prId": 22955
}, {
  "comments": [{
    "author": {
      "login": "mgaido91"
    },
    "body": "sorry, probably I was not clear enough in my previous comment. This UT and the following differ only for the join type. We can dedup them by doing something like:\r\n\r\n```\r\nSeq(Inner, LeftSemi).foreach { joinType =>\r\n  test(...) { ...}\r\n}\r\n```\r\n\r\nPS nit: maybe we can also define a new `val supportedJoinTypes = Seq(Inner, LeftSemi)`...",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-10T10:01:32Z",
    "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.scalatest.Matchers._\n+\n+import org.apache.spark.api.python.PythonEvalType\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.PythonUDF\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.internal.SQLConf._\n+import org.apache.spark.sql.types.BooleanType\n+\n+class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Extract PythonUDF From JoinCondition\", Once,\n+        PullOutPythonUDFInJoinCondition) ::\n+      Batch(\"Check Cartesian Products\", Once,\n+        CheckCartesianProducts) :: Nil\n+  }\n+\n+  val testRelationLeft = LocalRelation('a.int, 'b.int)\n+  val testRelationRight = LocalRelation('c.int, 'd.int)\n+\n+  // Dummy python UDF for testing. Unable to execute.\n+  val pythonUDF = PythonUDF(\"pythonUDF\", null,\n+    BooleanType,\n+    Seq.empty,\n+    PythonEvalType.SQL_BATCHED_UDF,\n+    udfDeterministic = true)\n+\n+  val unsupportedJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n+\n+  private def comparePlansWithConf(query: LogicalPlan, expected: LogicalPlan): Unit = {\n+    // AnalysisException thrown by CheckCartesianProducts while spark.sql.crossJoin.enabled=false\n+    val exception = intercept[AnalysisException] {\n+      Optimize.execute(query.analyze)\n+    }\n+    assert(exception.message.startsWith(\"Detected implicit cartesian product\"))\n+\n+    // pull out the python udf while set spark.sql.crossJoin.enabled=true\n+    withSQLConf(CROSS_JOINS_ENABLED.key -> \"true\") {\n+      val optimized = Optimize.execute(query.analyze)\n+      comparePlans(optimized, expected)\n+    }\n+  }\n+\n+  test(\"inner join condition with python udf only\") {",
    "line": 69
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "I'm sorry for lacking of comments to your previous comment `they differ only by the join type...`, they differ not only the type, but also the expected plan.",
    "commit": "8d04b4c4f084610e8ce8f11590ad4cd537c5952f",
    "createdAt": "2018-11-11T13:59:56Z",
    "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.optimizer\n+\n+import org.scalatest.Matchers._\n+\n+import org.apache.spark.api.python.PythonEvalType\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.expressions.PythonUDF\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.internal.SQLConf._\n+import org.apache.spark.sql.types.BooleanType\n+\n+class PullOutPythonUDFInJoinConditionSuite extends PlanTest {\n+\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Extract PythonUDF From JoinCondition\", Once,\n+        PullOutPythonUDFInJoinCondition) ::\n+      Batch(\"Check Cartesian Products\", Once,\n+        CheckCartesianProducts) :: Nil\n+  }\n+\n+  val testRelationLeft = LocalRelation('a.int, 'b.int)\n+  val testRelationRight = LocalRelation('c.int, 'd.int)\n+\n+  // Dummy python UDF for testing. Unable to execute.\n+  val pythonUDF = PythonUDF(\"pythonUDF\", null,\n+    BooleanType,\n+    Seq.empty,\n+    PythonEvalType.SQL_BATCHED_UDF,\n+    udfDeterministic = true)\n+\n+  val unsupportedJoinTypes = Seq(LeftOuter, RightOuter, FullOuter, LeftAnti)\n+\n+  private def comparePlansWithConf(query: LogicalPlan, expected: LogicalPlan): Unit = {\n+    // AnalysisException thrown by CheckCartesianProducts while spark.sql.crossJoin.enabled=false\n+    val exception = intercept[AnalysisException] {\n+      Optimize.execute(query.analyze)\n+    }\n+    assert(exception.message.startsWith(\"Detected implicit cartesian product\"))\n+\n+    // pull out the python udf while set spark.sql.crossJoin.enabled=true\n+    withSQLConf(CROSS_JOINS_ENABLED.key -> \"true\") {\n+      val optimized = Optimize.execute(query.analyze)\n+      comparePlans(optimized, expected)\n+    }\n+  }\n+\n+  test(\"inner join condition with python udf only\") {",
    "line": 69
  }],
  "prId": 22955
}]