[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Ping, @liufengdb and @gatorsmile .",
    "commit": "81d647793c7491c2f806e78ccae353d652d61d96",
    "createdAt": "2018-02-19T18:51:27Z",
    "diffHunk": "@@ -58,15 +58,20 @@ object BufferHolderSparkSubmitSuite {\n     val holder = new BufferHolder(new UnsafeRow(1000))\n \n     holder.reset()\n+    // execute here since reset() updates holder.cursor\n+    val smallBuffer = new Array[Byte](holder.cursor)"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "ping @liufengdb and @gatorsmile",
    "commit": "81d647793c7491c2f806e78ccae353d652d61d96",
    "createdAt": "2018-02-26T02:31:32Z",
    "diffHunk": "@@ -58,15 +58,20 @@ object BufferHolderSparkSubmitSuite {\n     val holder = new BufferHolder(new UnsafeRow(1000))\n \n     holder.reset()\n+    // execute here since reset() updates holder.cursor\n+    val smallBuffer = new Array[Byte](holder.cursor)"
  }],
  "prId": 20636
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Do we still support this?",
    "commit": "81d647793c7491c2f806e78ccae353d652d61d96",
    "createdAt": "2018-04-10T17:35:51Z",
    "diffHunk": "@@ -39,8 +39,8 @@ class BufferHolderSparkSubmitSuite\n     val argsForSparkSubmit = Seq(\n       \"--class\", BufferHolderSparkSubmitSuite.getClass.getName.stripSuffix(\"$\"),\n       \"--name\", \"SPARK-22222\",\n-      \"--master\", \"local-cluster[2,1,1024]\",\n-      \"--driver-memory\", \"4g\",\n+      \"--master\", \"local-cluster[1,1,7168]\","
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "Good question. Several tests still seem to use `local-cluster`. Is it better to use `local` while it may require more memory?\r\n",
    "commit": "81d647793c7491c2f806e78ccae353d652d61d96",
    "createdAt": "2018-04-10T18:42:39Z",
    "diffHunk": "@@ -39,8 +39,8 @@ class BufferHolderSparkSubmitSuite\n     val argsForSparkSubmit = Seq(\n       \"--class\", BufferHolderSparkSubmitSuite.getClass.getName.stripSuffix(\"$\"),\n       \"--name\", \"SPARK-22222\",\n-      \"--master\", \"local-cluster[2,1,1024]\",\n-      \"--driver-memory\", \"4g\",\n+      \"--master\", \"local-cluster[1,1,7168]\","
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "ping @hvanhovell ",
    "commit": "81d647793c7491c2f806e78ccae353d652d61d96",
    "createdAt": "2018-04-17T10:29:54Z",
    "diffHunk": "@@ -39,8 +39,8 @@ class BufferHolderSparkSubmitSuite\n     val argsForSparkSubmit = Seq(\n       \"--class\", BufferHolderSparkSubmitSuite.getClass.getName.stripSuffix(\"$\"),\n       \"--name\", \"SPARK-22222\",\n-      \"--master\", \"local-cluster[2,1,1024]\",\n-      \"--driver-memory\", \"4g\",\n+      \"--master\", \"local-cluster[1,1,7168]\","
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I think we support this for testing purpose since, IIRC, that's going to make separate processes for workers.",
    "commit": "81d647793c7491c2f806e78ccae353d652d61d96",
    "createdAt": "2018-08-01T03:46:08Z",
    "diffHunk": "@@ -39,8 +39,8 @@ class BufferHolderSparkSubmitSuite\n     val argsForSparkSubmit = Seq(\n       \"--class\", BufferHolderSparkSubmitSuite.getClass.getName.stripSuffix(\"$\"),\n       \"--name\", \"SPARK-22222\",\n-      \"--master\", \"local-cluster[2,1,1024]\",\n-      \"--driver-memory\", \"4g\",\n+      \"--master\", \"local-cluster[1,1,7168]\","
  }],
  "prId": 20636
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Fix the indents here. `assert(true)` is a no-op, so just omit it. `assert(false)` is less useful than `fail(...message...)`, above. Let an unexpected `Throwable` just fly out of the method to fail it rather than swallow it. But do you really just want to use `intercept` here?",
    "commit": "81d647793c7491c2f806e78ccae353d652d61d96",
    "createdAt": "2018-07-31T18:33:17Z",
    "diffHunk": "@@ -55,22 +55,30 @@ object BufferHolderSparkSubmitSuite {\n \n     val ARRAY_MAX = ByteArrayMethods.MAX_ROUNDED_ARRAY_LENGTH\n \n-    val holder = new BufferHolder(new UnsafeRow(1000))\n+    val unsafeRow = new UnsafeRow(1000)\n+    val holder = new BufferHolder(unsafeRow)\n \n     holder.reset()\n-    holder.grow(roundToWord(ARRAY_MAX / 2))\n \n-    holder.reset()\n-    holder.grow(roundToWord(ARRAY_MAX / 2 + 8))\n+    // while to reuse a buffer may happen, this test checks whether the buffer can be grown\n+    holder.grow(ARRAY_MAX / 2)\n+    assert(unsafeRow.getSizeInBytes % 8 == 0)\n \n-    holder.reset()\n-    holder.grow(roundToWord(Integer.MAX_VALUE / 2))\n+    holder.grow(ARRAY_MAX / 2 + 7)\n+    assert(unsafeRow.getSizeInBytes % 8 == 0)\n \n-    holder.reset()\n-    holder.grow(roundToWord(Integer.MAX_VALUE))\n-  }\n+    holder.grow(Integer.MAX_VALUE / 2)\n+    assert(unsafeRow.getSizeInBytes % 8 == 0)\n+\n+    holder.grow(ARRAY_MAX - holder.totalSize())\n+    assert(unsafeRow.getSizeInBytes % 8 == 0)\n \n-  private def roundToWord(len: Int): Int = {\n-    ByteArrayMethods.roundNumberOfBytesToNearestWord(len)\n+    try {\n+      holder.grow(ARRAY_MAX + 1 - holder.totalSize())\n+      assert(false)\n+    } catch {\n+        case _: UnsupportedOperationException => assert(true)"
  }],
  "prId": 20636
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Hm, just wondering if it's going to be problematic that the test now spawns a job that needs more than 7G of RAM? maybe I misunderstand.",
    "commit": "81d647793c7491c2f806e78ccae353d652d61d96",
    "createdAt": "2018-07-31T18:33:43Z",
    "diffHunk": "@@ -39,8 +39,8 @@ class BufferHolderSparkSubmitSuite\n     val argsForSparkSubmit = Seq(\n       \"--class\", BufferHolderSparkSubmitSuite.getClass.getName.stripSuffix(\"$\"),\n       \"--name\", \"SPARK-22222\",\n-      \"--master\", \"local-cluster[2,1,1024]\",\n-      \"--driver-memory\", \"4g\",\n+      \"--master\", \"local-cluster[1,1,7168]\",\n+      \"--driver-memory\", \"7g\","
  }],
  "prId": 20636
}]