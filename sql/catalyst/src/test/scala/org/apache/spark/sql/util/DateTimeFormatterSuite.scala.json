[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "how about `assert(daysSinceEpoch === 17867)`? then we can remove that map.",
    "commit": "60ab5b18f031c97640195a7ff0a94070e928f7f5",
    "createdAt": "2018-12-13T02:37:26Z",
    "diffHunk": "@@ -20,22 +20,24 @@ package org.apache.spark.sql.util\n import java.util.{Locale, TimeZone}\n \n import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n import org.apache.spark.sql.catalyst.util.{DateFormatter, DateTimeFormatter, DateTimeTestUtils}\n+import org.apache.spark.sql.internal.SQLConf\n \n-class DateTimeFormatterSuite  extends SparkFunSuite {\n-  test(\"parsing dates using time zones\") {\n+class DateTimeFormatterSuite  extends SparkFunSuite with SQLHelper {\n+  test(\"parsing dates\") {\n     val localDate = \"2018-12-02\"\n     val expectedDays = Map(\n       \"UTC\" -> 17867,\n       \"PST\" -> 17867,\n-      \"CET\" -> 17866,\n+      \"CET\" -> 17867,\n       \"Africa/Dakar\" -> 17867,\n       \"America/Los_Angeles\" -> 17867,\n-      \"Antarctica/Vostok\" -> 17866,\n-      \"Asia/Hong_Kong\" -> 17866,\n-      \"Europe/Amsterdam\" -> 17866)\n+      \"Antarctica/Vostok\" -> 17867,\n+      \"Asia/Hong_Kong\" -> 17867,\n+      \"Europe/Amsterdam\" -> 17867)\n     DateTimeTestUtils.outstandingTimezonesIds.foreach { timeZone =>\n-      val formatter = DateFormatter(\"yyyy-MM-dd\", TimeZone.getTimeZone(timeZone), Locale.US)\n+      val formatter = DateFormatter(\"yyyy-MM-dd\", Locale.US)\n       val daysSinceEpoch = formatter.parse(localDate)\n       assert(daysSinceEpoch === expectedDays(timeZone))"
  }],
  "prId": 23196
}]