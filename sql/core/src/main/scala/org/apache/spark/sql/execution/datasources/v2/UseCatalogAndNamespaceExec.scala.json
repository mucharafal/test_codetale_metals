[{
  "comments": [{
    "author": {
      "login": "imback82"
    },
    "body": "This is a temporary hack to show what needs to be done to make some of the tests pass (such as thriftserver tests). Without this, I had to update `ResolveTables` and `CreateTable` to use current namespace to fix the failing tests. This should be addressed from [SPARK-29014](https://issues.apache.org/jira/browse/SPARK-29014) .\r\n\r\n@rdblue @cloud-fan I think we need to expose `setCurrentNamespace` and `getCurrentNamespace` in `SupportsNamespace`. Without this, I don't think it's possible to propagate current namespace to `SessionCatalog` (or `DelegatingCatalogExtension`). We have many code paths that rely on `SessionCatalog.getCurrentDatabase` and things can break if we store the current namespace in `CatalogManager`. Any thoughts? If this change is needed, I can follow up with a PR.\r\n\r\n\r\n",
    "commit": "84856190f5bf7f7865ce3428986cca61471c9845",
    "createdAt": "2019-09-22T04:19:29Z",
    "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.connector.catalog.CatalogManager\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for setting the current catalog and/or namespace.\n+ */\n+case class UseCatalogAndNamespaceExec(\n+    catalogManager: CatalogManager,\n+    catalogName: Option[String],\n+    namespace: Option[Seq[String]])\n+    extends LeafExecNode {\n+  override protected def doExecute(): RDD[InternalRow] = {\n+    // The catalog is updated first because CatalogManager resets the current namespace\n+    // when the current catalog is set.\n+    catalogName.map(catalogManager.setCurrentCatalog)\n+\n+    namespace.map { ns =>\n+      SparkSession.active.sessionState.catalog.setCurrentDatabase(ns.head)"
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "This is resolved by #25903. Thanks @cloud-fan ",
    "commit": "84856190f5bf7f7865ce3428986cca61471c9845",
    "createdAt": "2019-09-26T04:37:45Z",
    "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.connector.catalog.CatalogManager\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for setting the current catalog and/or namespace.\n+ */\n+case class UseCatalogAndNamespaceExec(\n+    catalogManager: CatalogManager,\n+    catalogName: Option[String],\n+    namespace: Option[Seq[String]])\n+    extends LeafExecNode {\n+  override protected def doExecute(): RDD[InternalRow] = {\n+    // The catalog is updated first because CatalogManager resets the current namespace\n+    // when the current catalog is set.\n+    catalogName.map(catalogManager.setCurrentCatalog)\n+\n+    namespace.map { ns =>\n+      SparkSession.active.sessionState.catalog.setCurrentDatabase(ns.head)"
  }],
  "prId": 25771
}]