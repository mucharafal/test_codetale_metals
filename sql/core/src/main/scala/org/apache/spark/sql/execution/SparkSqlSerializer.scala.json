[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "sort imports\n",
    "commit": "5c7848d52070b639e23088972eb2a8316cddc54f",
    "createdAt": "2014-08-20T22:24:32Z",
    "diffHunk": "@@ -19,6 +19,9 @@ package org.apache.spark.sql.execution\n \n import java.nio.ByteBuffer\n \n+import org.apache.spark.sql.catalyst.expressions.GenericRow"
  }],
  "prId": 1935
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "maybe we should push this into spark core directly?\n",
    "commit": "5c7848d52070b639e23088972eb2a8316cddc54f",
    "createdAt": "2014-08-20T22:24:46Z",
    "diffHunk": "@@ -41,6 +46,13 @@ private[sql] class SparkSqlSerializer(conf: SparkConf) extends KryoSerializer(co\n     kryo.register(classOf[com.clearspring.analytics.stream.cardinality.HyperLogLog],\n                   new HyperLogLogSerializer)\n     kryo.register(classOf[scala.math.BigDecimal], new BigDecimalSerializer)\n+\n+    // Specific hashsets must come first"
  }, {
    "author": {
      "login": "marmbrus"
    },
    "body": "Good idea.  I'll add a TODO.\n",
    "commit": "5c7848d52070b639e23088972eb2a8316cddc54f",
    "createdAt": "2014-08-20T22:57:24Z",
    "diffHunk": "@@ -41,6 +46,13 @@ private[sql] class SparkSqlSerializer(conf: SparkConf) extends KryoSerializer(co\n     kryo.register(classOf[com.clearspring.analytics.stream.cardinality.HyperLogLog],\n                   new HyperLogLogSerializer)\n     kryo.register(classOf[scala.math.BigDecimal], new BigDecimalSerializer)\n+\n+    // Specific hashsets must come first"
  }],
  "prId": 1935
}]