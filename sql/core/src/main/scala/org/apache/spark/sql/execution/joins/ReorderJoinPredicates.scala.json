[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit:\r\n```\r\ndef reorder(\r\n    expectedOrderOfKeys: Seq[Expression],\r\n    currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression])\r\n```",
    "commit": "7171b58f860496f40981ff0f2c3e4366694b91fc",
    "createdAt": "2017-05-12T06:10:06Z",
    "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans.physical.{HashPartitioning, Partitioning}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * When the physical operators are created for JOIN, the ordering of join keys is based on order\n+ * in which the join keys appear in the user query. That might not match with the output\n+ * partitioning of the join node's children (thus leading to extra sort / shuffle being\n+ * introduced). This rule will change the ordering of the join keys to match with the\n+ * partitioning of the join nodes' children.\n+ */\n+class ReorderJoinPredicates extends Rule[SparkPlan] {\n+  private def reorderJoinKeys(\n+      leftKeys: Seq[Expression],\n+      rightKeys: Seq[Expression],\n+      leftPartitioning: Partitioning,\n+      rightPartitioning: Partitioning): (Seq[Expression], Seq[Expression]) = {\n+\n+    def reorder(expectedOrderOfKeys: Seq[Expression],"
  }, {
    "author": {
      "login": "tejasapatil"
    },
    "body": "fixed this. \r\n\r\nPS: I always manually fix this. If there is some predefined checkstyle which I could import in Intelij, that will save this trouble for me and reviewers.",
    "commit": "7171b58f860496f40981ff0f2c3e4366694b91fc",
    "createdAt": "2017-05-12T07:05:25Z",
    "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans.physical.{HashPartitioning, Partitioning}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * When the physical operators are created for JOIN, the ordering of join keys is based on order\n+ * in which the join keys appear in the user query. That might not match with the output\n+ * partitioning of the join node's children (thus leading to extra sort / shuffle being\n+ * introduced). This rule will change the ordering of the join keys to match with the\n+ * partitioning of the join nodes' children.\n+ */\n+class ReorderJoinPredicates extends Rule[SparkPlan] {\n+  private def reorderJoinKeys(\n+      leftKeys: Seq[Expression],\n+      rightKeys: Seq[Expression],\n+      leftPartitioning: Partitioning,\n+      rightPartitioning: Partitioning): (Seq[Expression], Seq[Expression]) = {\n+\n+    def reorder(expectedOrderOfKeys: Seq[Expression],"
  }],
  "prId": 16985
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "why do we need the same length? Let's say the child partitioning is `a, b, c, d` and the join key is `b, a`, we can reorder the join key to avoid shuffle, right?",
    "commit": "7171b58f860496f40981ff0f2c3e4366694b91fc",
    "createdAt": "2017-05-12T06:12:54Z",
    "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans.physical.{HashPartitioning, Partitioning}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * When the physical operators are created for JOIN, the ordering of join keys is based on order\n+ * in which the join keys appear in the user query. That might not match with the output\n+ * partitioning of the join node's children (thus leading to extra sort / shuffle being\n+ * introduced). This rule will change the ordering of the join keys to match with the\n+ * partitioning of the join nodes' children.\n+ */\n+class ReorderJoinPredicates extends Rule[SparkPlan] {\n+  private def reorderJoinKeys(\n+      leftKeys: Seq[Expression],\n+      rightKeys: Seq[Expression],\n+      leftPartitioning: Partitioning,\n+      rightPartitioning: Partitioning): (Seq[Expression], Seq[Expression]) = {\n+\n+    def reorder(expectedOrderOfKeys: Seq[Expression],\n+                currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression]) = {\n+      val leftKeysBuffer = ArrayBuffer[Expression]()\n+      val rightKeysBuffer = ArrayBuffer[Expression]()\n+\n+      expectedOrderOfKeys.foreach(expression => {\n+        val index = currentOrderOfKeys.indexWhere(e => e.semanticEquals(expression))\n+        leftKeysBuffer.append(leftKeys(index))\n+        rightKeysBuffer.append(rightKeys(index))\n+      })\n+      (leftKeysBuffer, rightKeysBuffer)\n+    }\n+\n+    if (leftKeys.forall(_.deterministic) && rightKeys.forall(_.deterministic)) {\n+      leftPartitioning match {\n+        case HashPartitioning(leftExpressions, _)\n+          if leftExpressions.length == leftKeys.length &&",
    "line": 58
  }, {
    "author": {
      "login": "tejasapatil"
    },
    "body": "I don't think that would be right thing to do. If child is partitioned on `a, b, c, d`, its basically means rows are distributed over hash of `a, b, c, d`. Lets say we have two rows with values of `a, b, c, d` as:\r\n- row1 : 1,1,1,1 ==> hash(1,1,1,1) = x\r\n- row2 : 1,1,2,2 ==> hash(1,1,2,2) = y\r\n\r\nIf the join key `b,a` is reordered as `a,b` and we want to avoid shuffle, that would mean that we expect the child to have same values of `a,b` in the same partition. But if you look at row1 and row2 above, even if values of `a` and `b` are the same, there is no guarantee that they would belong to the same partition... as the partition is based on hash of all `a,b,c,d`.\r\n\r\nIf the join keys are a subset of the partitioning, then there needs to be a shuffle to be done. There is only one exception to this (more of a corner case) : https://issues.apache.org/jira/browse/SPARK-18067",
    "commit": "7171b58f860496f40981ff0f2c3e4366694b91fc",
    "createdAt": "2017-05-12T07:03:03Z",
    "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans.physical.{HashPartitioning, Partitioning}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * When the physical operators are created for JOIN, the ordering of join keys is based on order\n+ * in which the join keys appear in the user query. That might not match with the output\n+ * partitioning of the join node's children (thus leading to extra sort / shuffle being\n+ * introduced). This rule will change the ordering of the join keys to match with the\n+ * partitioning of the join nodes' children.\n+ */\n+class ReorderJoinPredicates extends Rule[SparkPlan] {\n+  private def reorderJoinKeys(\n+      leftKeys: Seq[Expression],\n+      rightKeys: Seq[Expression],\n+      leftPartitioning: Partitioning,\n+      rightPartitioning: Partitioning): (Seq[Expression], Seq[Expression]) = {\n+\n+    def reorder(expectedOrderOfKeys: Seq[Expression],\n+                currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression]) = {\n+      val leftKeysBuffer = ArrayBuffer[Expression]()\n+      val rightKeysBuffer = ArrayBuffer[Expression]()\n+\n+      expectedOrderOfKeys.foreach(expression => {\n+        val index = currentOrderOfKeys.indexWhere(e => e.semanticEquals(expression))\n+        leftKeysBuffer.append(leftKeys(index))\n+        rightKeysBuffer.append(rightKeys(index))\n+      })\n+      (leftKeysBuffer, rightKeysBuffer)\n+    }\n+\n+    if (leftKeys.forall(_.deterministic) && rightKeys.forall(_.deterministic)) {\n+      leftPartitioning match {\n+        case HashPartitioning(leftExpressions, _)\n+          if leftExpressions.length == leftKeys.length &&",
    "line": 58
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "oh sorry I made a mistake.\r\n\r\nif the child partitioning is `a, b` and the join key is `b, a, c, d`, does it make sense to reorder it as `a, b ,c ,d`?",
    "commit": "7171b58f860496f40981ff0f2c3e4366694b91fc",
    "createdAt": "2017-05-12T08:24:44Z",
    "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans.physical.{HashPartitioning, Partitioning}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * When the physical operators are created for JOIN, the ordering of join keys is based on order\n+ * in which the join keys appear in the user query. That might not match with the output\n+ * partitioning of the join node's children (thus leading to extra sort / shuffle being\n+ * introduced). This rule will change the ordering of the join keys to match with the\n+ * partitioning of the join nodes' children.\n+ */\n+class ReorderJoinPredicates extends Rule[SparkPlan] {\n+  private def reorderJoinKeys(\n+      leftKeys: Seq[Expression],\n+      rightKeys: Seq[Expression],\n+      leftPartitioning: Partitioning,\n+      rightPartitioning: Partitioning): (Seq[Expression], Seq[Expression]) = {\n+\n+    def reorder(expectedOrderOfKeys: Seq[Expression],\n+                currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression]) = {\n+      val leftKeysBuffer = ArrayBuffer[Expression]()\n+      val rightKeysBuffer = ArrayBuffer[Expression]()\n+\n+      expectedOrderOfKeys.foreach(expression => {\n+        val index = currentOrderOfKeys.indexWhere(e => e.semanticEquals(expression))\n+        leftKeysBuffer.append(leftKeys(index))\n+        rightKeysBuffer.append(rightKeys(index))\n+      })\n+      (leftKeysBuffer, rightKeysBuffer)\n+    }\n+\n+    if (leftKeys.forall(_.deterministic) && rightKeys.forall(_.deterministic)) {\n+      leftPartitioning match {\n+        case HashPartitioning(leftExpressions, _)\n+          if leftExpressions.length == leftKeys.length &&",
    "line": 58
  }, {
    "author": {
      "login": "tejasapatil"
    },
    "body": "`EnsureRequirements` would still add a shuffle in either case even if we reorder.\r\n\r\nJOIN would expect data to be distributed over `b, a, c, d` (or `a,b,c,d` if you reorder) which maps to HashPartitioning(`a,b,c,d`) : https://github.com/apache/spark/blob/e9c91badce64731ffd3e53cbcd9f044a7593e6b8/sql/core/src/main/scala/org/apache/spark/sql/execution/exchange/EnsureRequirements.scala#L185\r\n\r\nBut the child nodes won't have matching partitioning ie. they will have HashPartitioning(`a,b`).\r\n\r\n",
    "commit": "7171b58f860496f40981ff0f2c3e4366694b91fc",
    "createdAt": "2017-05-13T00:43:26Z",
    "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans.physical.{HashPartitioning, Partitioning}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * When the physical operators are created for JOIN, the ordering of join keys is based on order\n+ * in which the join keys appear in the user query. That might not match with the output\n+ * partitioning of the join node's children (thus leading to extra sort / shuffle being\n+ * introduced). This rule will change the ordering of the join keys to match with the\n+ * partitioning of the join nodes' children.\n+ */\n+class ReorderJoinPredicates extends Rule[SparkPlan] {\n+  private def reorderJoinKeys(\n+      leftKeys: Seq[Expression],\n+      rightKeys: Seq[Expression],\n+      leftPartitioning: Partitioning,\n+      rightPartitioning: Partitioning): (Seq[Expression], Seq[Expression]) = {\n+\n+    def reorder(expectedOrderOfKeys: Seq[Expression],\n+                currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression]) = {\n+      val leftKeysBuffer = ArrayBuffer[Expression]()\n+      val rightKeysBuffer = ArrayBuffer[Expression]()\n+\n+      expectedOrderOfKeys.foreach(expression => {\n+        val index = currentOrderOfKeys.indexWhere(e => e.semanticEquals(expression))\n+        leftKeysBuffer.append(leftKeys(index))\n+        rightKeysBuffer.append(rightKeys(index))\n+      })\n+      (leftKeysBuffer, rightKeysBuffer)\n+    }\n+\n+    if (leftKeys.forall(_.deterministic) && rightKeys.forall(_.deterministic)) {\n+      leftPartitioning match {\n+        case HashPartitioning(leftExpressions, _)\n+          if leftExpressions.length == leftKeys.length &&",
    "line": 58
  }, {
    "author": {
      "login": "tejasapatil"
    },
    "body": "The contract for reordering is that the set of join keys must be equal to the set of child's partitioning columns (implemented at L58-L59 in this file). Thus there won't be reordering for the case you pointed out. I have added a test case of the same.",
    "commit": "7171b58f860496f40981ff0f2c3e4366694b91fc",
    "createdAt": "2017-08-11T06:00:10Z",
    "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.expressions.Expression\n+import org.apache.spark.sql.catalyst.plans.physical.{HashPartitioning, Partitioning}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * When the physical operators are created for JOIN, the ordering of join keys is based on order\n+ * in which the join keys appear in the user query. That might not match with the output\n+ * partitioning of the join node's children (thus leading to extra sort / shuffle being\n+ * introduced). This rule will change the ordering of the join keys to match with the\n+ * partitioning of the join nodes' children.\n+ */\n+class ReorderJoinPredicates extends Rule[SparkPlan] {\n+  private def reorderJoinKeys(\n+      leftKeys: Seq[Expression],\n+      rightKeys: Seq[Expression],\n+      leftPartitioning: Partitioning,\n+      rightPartitioning: Partitioning): (Seq[Expression], Seq[Expression]) = {\n+\n+    def reorder(expectedOrderOfKeys: Seq[Expression],\n+                currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression]) = {\n+      val leftKeysBuffer = ArrayBuffer[Expression]()\n+      val rightKeysBuffer = ArrayBuffer[Expression]()\n+\n+      expectedOrderOfKeys.foreach(expression => {\n+        val index = currentOrderOfKeys.indexWhere(e => e.semanticEquals(expression))\n+        leftKeysBuffer.append(leftKeys(index))\n+        rightKeysBuffer.append(rightKeys(index))\n+      })\n+      (leftKeysBuffer, rightKeysBuffer)\n+    }\n+\n+    if (leftKeys.forall(_.deterministic) && rightKeys.forall(_.deterministic)) {\n+      leftPartitioning match {\n+        case HashPartitioning(leftExpressions, _)\n+          if leftExpressions.length == leftKeys.length &&",
    "line": 58
  }],
  "prId": 16985
}]