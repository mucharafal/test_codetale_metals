[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "how about `CreateTableCommand` and `CreateHiveTableAsSelectLogicalPlan`\n",
    "commit": "08b5374e827f6680b4e4a00ed700ef689dce22ff",
    "createdAt": "2016-06-23T01:08:35Z",
    "diffHunk": "@@ -206,7 +206,22 @@ private[sql] case class PreWriteCheck(conf: SQLConf, catalog: SessionCatalog)\n         // The relation in l is not an InsertableRelation.\n         failAnalysis(s\"$l does not allow insertion.\")\n \n+      case c: CreateTableUsing =>"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": ": ) True. Let me add them now. \n",
    "commit": "08b5374e827f6680b4e4a00ed700ef689dce22ff",
    "createdAt": "2016-06-23T05:42:58Z",
    "diffHunk": "@@ -206,7 +206,22 @@ private[sql] case class PreWriteCheck(conf: SQLConf, catalog: SessionCatalog)\n         // The relation in l is not an InsertableRelation.\n         failAnalysis(s\"$l does not allow insertion.\")\n \n+      case c: CreateTableUsing =>"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Only found one case: `CREATE TABLE` with `PARTITION BY`. Let me explain what I found.\n\nFirst, `CREATE TABLE` command does not support `bucketSpec`. See [code](https://github.com/gatorsmile/spark/blob/24edb5f60f3caf79c6e860905041cd09301589db/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkSqlParser.scala#L901-L903)\n\nSecond, `CREATE TABLE AS SELECT` that can generate `CreateHiveTableAsSelectLogicalPlan` [does not allow users to specify the schema](https://github.com/gatorsmile/spark/blob/24edb5f60f3caf79c6e860905041cd09301589db/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkSqlParser.scala#L984-L989), which includes partitionBy columns.\n\nLet me know if anything is still missing. Thanks!\n",
    "commit": "08b5374e827f6680b4e4a00ed700ef689dce22ff",
    "createdAt": "2016-06-23T06:28:19Z",
    "diffHunk": "@@ -206,7 +206,22 @@ private[sql] case class PreWriteCheck(conf: SQLConf, catalog: SessionCatalog)\n         // The relation in l is not an InsertableRelation.\n         failAnalysis(s\"$l does not allow insertion.\")\n \n+      case c: CreateTableUsing =>"
  }],
  "prId": 13756
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Is it safe to do case sensitive comparison here?\n",
    "commit": "08b5374e827f6680b4e4a00ed700ef689dce22ff",
    "createdAt": "2016-07-05T10:31:10Z",
    "diffHunk": "@@ -206,7 +207,39 @@ private[sql] case class PreWriteCheck(conf: SQLConf, catalog: SessionCatalog)\n         // The relation in l is not an InsertableRelation.\n         failAnalysis(s\"$l does not allow insertion.\")\n \n+      case c: CreateTableCommand =>\n+        val allColNamesInSchema = c.table.schema.map(_.name)\n+        val colNames = allColNamesInSchema.diff(c.table.partitionColumnNames)"
  }],
  "prId": 13756
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Code style within this block looks weird.\n",
    "commit": "08b5374e827f6680b4e4a00ed700ef689dce22ff",
    "createdAt": "2016-07-05T10:32:47Z",
    "diffHunk": "@@ -248,4 +281,15 @@ private[sql] case class PreWriteCheck(conf: SQLConf, catalog: SessionCatalog)\n       case _ => // OK\n     }\n   }\n+\n+  private def checkDuplicates(columnNames: Seq[String], columnType: String): Unit = {\n+    val duplicateColumns = columnNames.groupBy { name =>\n+      if (conf.caseSensitiveAnalysis) name else name.toLowerCase }.collect {\n+      case (x, ys) if ys.length > 1 => s\"`$x`\"\n+    }"
  }],
  "prId": 13756
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Again, this line is using case sensitive comparison.\n",
    "commit": "08b5374e827f6680b4e4a00ed700ef689dce22ff",
    "createdAt": "2016-07-05T10:34:35Z",
    "diffHunk": "@@ -206,7 +207,39 @@ private[sql] case class PreWriteCheck(conf: SQLConf, catalog: SessionCatalog)\n         // The relation in l is not an InsertableRelation.\n         failAnalysis(s\"$l does not allow insertion.\")\n \n+      case c: CreateTableCommand =>\n+        val allColNamesInSchema = c.table.schema.map(_.name)\n+        val colNames = allColNamesInSchema.diff(c.table.partitionColumnNames)\n+        val partitionColumnNames = c.table.partitionColumnNames\n+        // Duplicates are not allowed in partitionBy\n+        // Todo: when bucketBy and sortBy are supported, we also need to ban the duplication.\n+        checkDuplicates(partitionColumnNames, \"Partition\")\n+        // Ensuring whether no duplicate name is used in table definition\n+        checkDuplicates(colNames, s\"table definition of ${c.table.identifier}\")\n+        // For non-data-source tables, partition columns must not be part of the schema\n+        val badPartCols = partitionColumnNames.toSet.intersect(colNames.toSet)"
  }],
  "prId": 13756
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Use\n\n``` scala\nfoo.foreach { b =>\n  ...\n}\n```\n\ninstead of\n\n``` scala\nfoo.foreach(b => {\n  ...\n})\n```\n",
    "commit": "08b5374e827f6680b4e4a00ed700ef689dce22ff",
    "createdAt": "2016-07-05T10:36:09Z",
    "diffHunk": "@@ -206,7 +207,39 @@ private[sql] case class PreWriteCheck(conf: SQLConf, catalog: SessionCatalog)\n         // The relation in l is not an InsertableRelation.\n         failAnalysis(s\"$l does not allow insertion.\")\n \n+      case c: CreateTableCommand =>\n+        val allColNamesInSchema = c.table.schema.map(_.name)\n+        val colNames = allColNamesInSchema.diff(c.table.partitionColumnNames)\n+        val partitionColumnNames = c.table.partitionColumnNames\n+        // Duplicates are not allowed in partitionBy\n+        // Todo: when bucketBy and sortBy are supported, we also need to ban the duplication.\n+        checkDuplicates(partitionColumnNames, \"Partition\")\n+        // Ensuring whether no duplicate name is used in table definition\n+        checkDuplicates(colNames, s\"table definition of ${c.table.identifier}\")\n+        // For non-data-source tables, partition columns must not be part of the schema\n+        val badPartCols = partitionColumnNames.toSet.intersect(colNames.toSet)\n+        if (badPartCols.nonEmpty) {\n+          failAnalysis(s\"Operation not allowed: Partition columns may not be specified in the \" +\n+            \"schema: \" + badPartCols.map(\"`\" + _ + \"`\").mkString(\",\"))\n+        }\n+\n+\n+      case c: CreateTableUsing =>\n+        // Duplicates are not allowed in partitionBy/bucketBy/sortBy columns.\n+        checkDuplicates(c.partitionColumns, \"Partition\")\n+        c.bucketSpec.foreach(b => {\n+          checkDuplicates(b.bucketColumnNames, \"Bucketing\")\n+          checkDuplicates(b.sortColumnNames, \"Sorting\")\n+        })"
  }],
  "prId": 13756
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Same as above.\n",
    "commit": "08b5374e827f6680b4e4a00ed700ef689dce22ff",
    "createdAt": "2016-07-05T10:36:23Z",
    "diffHunk": "@@ -206,7 +207,39 @@ private[sql] case class PreWriteCheck(conf: SQLConf, catalog: SessionCatalog)\n         // The relation in l is not an InsertableRelation.\n         failAnalysis(s\"$l does not allow insertion.\")\n \n+      case c: CreateTableCommand =>\n+        val allColNamesInSchema = c.table.schema.map(_.name)\n+        val colNames = allColNamesInSchema.diff(c.table.partitionColumnNames)\n+        val partitionColumnNames = c.table.partitionColumnNames\n+        // Duplicates are not allowed in partitionBy\n+        // Todo: when bucketBy and sortBy are supported, we also need to ban the duplication.\n+        checkDuplicates(partitionColumnNames, \"Partition\")\n+        // Ensuring whether no duplicate name is used in table definition\n+        checkDuplicates(colNames, s\"table definition of ${c.table.identifier}\")\n+        // For non-data-source tables, partition columns must not be part of the schema\n+        val badPartCols = partitionColumnNames.toSet.intersect(colNames.toSet)\n+        if (badPartCols.nonEmpty) {\n+          failAnalysis(s\"Operation not allowed: Partition columns may not be specified in the \" +\n+            \"schema: \" + badPartCols.map(\"`\" + _ + \"`\").mkString(\",\"))\n+        }\n+\n+\n+      case c: CreateTableUsing =>\n+        // Duplicates are not allowed in partitionBy/bucketBy/sortBy columns.\n+        checkDuplicates(c.partitionColumns, \"Partition\")\n+        c.bucketSpec.foreach(b => {\n+          checkDuplicates(b.bucketColumnNames, \"Bucketing\")\n+          checkDuplicates(b.sortColumnNames, \"Sorting\")\n+        })\n+\n       case c: CreateTableUsingAsSelect =>\n+        // Duplicates are not allowed in partitionBy/bucketBy/sortBy columns.\n+        checkDuplicates(c.partitionColumns, \"Partition\")\n+        c.bucketSpec.foreach(b => {\n+          checkDuplicates(b.bucketColumnNames, \"Bucketing\")\n+          checkDuplicates(b.sortColumnNames, \"Sorting\")\n+        })"
  }],
  "prId": 13756
}]