[{
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "This makes it sound like its okay to have more than one running as long as they aren't on the same spark cluster.",
    "commit": "4041a2297289aa6186a07e1ea74541d625174599",
    "createdAt": "2016-12-03T00:02:45Z",
    "diffHunk": "@@ -32,21 +32,33 @@ import org.apache.spark.sql.SparkSession\n trait StreamingQuery {\n \n   /**\n-   * Returns the name of the query. This name is unique across all active queries. This can be\n-   * set in the `org.apache.spark.sql.streaming.DataStreamWriter` as\n-   * `dataframe.writeStream.queryName(\"query\").start()`.\n+   * Returns the user-specified name of the query, or null if not specified.\n+   * This name can be specified in the `org.apache.spark.sql.streaming.DataStreamWriter`\n+   * as `dataframe.writeStream.queryName(\"query\").start()`.\n+   * This name, if set, must be unique across all active queries.\n    *\n    * @since 2.0.0\n    */\n   def name: String\n \n   /**\n-   * Returns the unique id of this query.\n+   * Returns the unique id of this query that persists across restarts from checkpoint data.\n+   * That is, this id is generated when a query is started for the first time, and\n+   * will be the same every time it is restarted from checkpoint data.\n+   * There can only be one query with the same id active in a Spark cluster."
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "I will just remove that line. ",
    "commit": "4041a2297289aa6186a07e1ea74541d625174599",
    "createdAt": "2016-12-03T00:27:37Z",
    "diffHunk": "@@ -32,21 +32,33 @@ import org.apache.spark.sql.SparkSession\n trait StreamingQuery {\n \n   /**\n-   * Returns the name of the query. This name is unique across all active queries. This can be\n-   * set in the `org.apache.spark.sql.streaming.DataStreamWriter` as\n-   * `dataframe.writeStream.queryName(\"query\").start()`.\n+   * Returns the user-specified name of the query, or null if not specified.\n+   * This name can be specified in the `org.apache.spark.sql.streaming.DataStreamWriter`\n+   * as `dataframe.writeStream.queryName(\"query\").start()`.\n+   * This name, if set, must be unique across all active queries.\n    *\n    * @since 2.0.0\n    */\n   def name: String\n \n   /**\n-   * Returns the unique id of this query.\n+   * Returns the unique id of this query that persists across restarts from checkpoint data.\n+   * That is, this id is generated when a query is started for the first time, and\n+   * will be the same every time it is restarted from checkpoint data.\n+   * There can only be one query with the same id active in a Spark cluster."
  }],
  "prId": 16113
}]