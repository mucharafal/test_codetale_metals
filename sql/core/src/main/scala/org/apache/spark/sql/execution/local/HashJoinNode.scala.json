[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "no space\n",
    "commit": "fcec2975d74710f9d1604a01b806566e1f47f1a1",
    "createdAt": "2015-09-09T23:36:04Z",
    "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins._\n+\n+case class HashJoinNode ("
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "also can you add a comment here that says much of this code is similar to `HashJoin#hashJoin`?\n",
    "commit": "fcec2975d74710f9d1604a01b806566e1f47f1a1",
    "createdAt": "2015-09-10T00:59:39Z",
    "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins._\n+\n+case class HashJoinNode ("
  }],
  "prId": 8535
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "this could be\n\n```\nprivate[this] lazy val (buildNode, buildKeys, streamedNode, streamedKeys) = {\n  buildSide match {\n    case BuildLeft => (left, leftKeys, right, rightKeys)\n    case BuildRight => (right, rightKeys, left, leftKeys)\n  }\n}\n```\n\n:)\n",
    "commit": "fcec2975d74710f9d1604a01b806566e1f47f1a1",
    "createdAt": "2015-09-09T23:37:11Z",
    "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins._\n+\n+case class HashJoinNode (\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, streamedNode) = buildSide match {\n+    case BuildLeft => (left, right)\n+    case BuildRight => (right, left)\n+  }\n+\n+  private[this] lazy val (buildKeys, streamedKeys) = buildSide match {\n+    case BuildLeft => (leftKeys, rightKeys)\n+    case BuildRight => (rightKeys, leftKeys)\n+  }"
  }],
  "prId": 8535
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "can you add `{ }` around this method and `streamSideKeyGenerator`?\n",
    "commit": "fcec2975d74710f9d1604a01b806566e1f47f1a1",
    "createdAt": "2015-09-10T00:23:29Z",
    "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins._\n+\n+case class HashJoinNode (\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, streamedNode) = buildSide match {\n+    case BuildLeft => (left, right)\n+    case BuildRight => (right, left)\n+  }\n+\n+  private[this] lazy val (buildKeys, streamedKeys) = buildSide match {\n+    case BuildLeft => (leftKeys, rightKeys)\n+    case BuildRight => (rightKeys, leftKeys)\n+  }\n+\n+  override def output: Seq[Attribute] = left.output ++ right.output\n+\n+  private[this] def isUnsafeMode: Boolean = {\n+    (codegenEnabled && unsafeEnabled\n+      && UnsafeProjection.canSupport(buildKeys)\n+      && UnsafeProjection.canSupport(schema))\n+  }\n+\n+  private[this] def buildSideKeyGenerator: Projection ="
  }],
  "prId": 8535
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "I think the following is functionally equivalent and easier to read:\n\n```\ncurrentMatchPosition += 1\nif (currentHashMatches == null || currentMatchPosition >= currentHashMatches.size) {\n  fetchNextMatch()\n} else {\n  true\n}\n```\n\nwhich says if we don't currently have matches, or we've already joined all of our existing matches, then fetch more matches.\n",
    "commit": "fcec2975d74710f9d1604a01b806566e1f47f1a1",
    "createdAt": "2015-09-10T01:07:39Z",
    "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins._\n+\n+case class HashJoinNode (\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, streamedNode) = buildSide match {\n+    case BuildLeft => (left, right)\n+    case BuildRight => (right, left)\n+  }\n+\n+  private[this] lazy val (buildKeys, streamedKeys) = buildSide match {\n+    case BuildLeft => (leftKeys, rightKeys)\n+    case BuildRight => (rightKeys, leftKeys)\n+  }\n+\n+  override def output: Seq[Attribute] = left.output ++ right.output\n+\n+  private[this] def isUnsafeMode: Boolean = {\n+    (codegenEnabled && unsafeEnabled\n+      && UnsafeProjection.canSupport(buildKeys)\n+      && UnsafeProjection.canSupport(schema))\n+  }\n+\n+  private[this] def buildSideKeyGenerator: Projection =\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(buildKeys, buildNode.output)\n+    } else {\n+      newMutableProjection(buildKeys, buildNode.output)()\n+    }\n+\n+  private[this] def streamSideKeyGenerator: Projection =\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(streamedKeys, streamedNode.output)\n+    } else {\n+      newMutableProjection(streamedKeys, streamedNode.output)()\n+    }\n+\n+  private[this] var currentStreamedRow: InternalRow = _\n+  private[this] var currentHashMatches: Seq[InternalRow] = _\n+  private[this] var currentMatchPosition: Int = -1\n+\n+  // Mutable per row objects.\n+  private[this] var joinRow: JoinedRow = _\n+  private[this] var resultProjection: (InternalRow) => InternalRow = _\n+\n+  private[this] var hashed: HashedRelation = _\n+  private[this] var joinKeys: Projection = _\n+\n+  override def open(): Unit = {\n+    buildNode.open()\n+    hashed = HashedRelation.createLocalHashedRelation(buildNode, buildSideKeyGenerator)\n+    streamedNode.open()\n+    joinRow = new JoinedRow\n+    resultProjection = {\n+      if (isUnsafeMode) {\n+        UnsafeProjection.create(schema)\n+      } else {\n+        identity[InternalRow]\n+      }\n+    }\n+    joinKeys = streamSideKeyGenerator\n+  }\n+\n+  override def next(): Boolean = {\n+    if (currentMatchPosition != -1) {\n+      currentMatchPosition += 1\n+      if (currentMatchPosition < currentHashMatches.size) {\n+        true\n+      } else {\n+        fetchNextMatch()\n+      }\n+    } else {\n+      fetchNextMatch()\n+    }"
  }],
  "prId": 8535
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "can you add some java docs here:\n\n```\n/**\n * Populate `currentHashMatches` with build-side rows matching the next streamed row.\n * @return whether matches are found such that subsequent calls to `fetch` are valid.\n */\n```\n",
    "commit": "fcec2975d74710f9d1604a01b806566e1f47f1a1",
    "createdAt": "2015-09-10T01:34:51Z",
    "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins._\n+\n+case class HashJoinNode (\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, streamedNode) = buildSide match {\n+    case BuildLeft => (left, right)\n+    case BuildRight => (right, left)\n+  }\n+\n+  private[this] lazy val (buildKeys, streamedKeys) = buildSide match {\n+    case BuildLeft => (leftKeys, rightKeys)\n+    case BuildRight => (rightKeys, leftKeys)\n+  }\n+\n+  override def output: Seq[Attribute] = left.output ++ right.output\n+\n+  private[this] def isUnsafeMode: Boolean = {\n+    (codegenEnabled && unsafeEnabled\n+      && UnsafeProjection.canSupport(buildKeys)\n+      && UnsafeProjection.canSupport(schema))\n+  }\n+\n+  private[this] def buildSideKeyGenerator: Projection =\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(buildKeys, buildNode.output)\n+    } else {\n+      newMutableProjection(buildKeys, buildNode.output)()\n+    }\n+\n+  private[this] def streamSideKeyGenerator: Projection =\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(streamedKeys, streamedNode.output)\n+    } else {\n+      newMutableProjection(streamedKeys, streamedNode.output)()\n+    }\n+\n+  private[this] var currentStreamedRow: InternalRow = _\n+  private[this] var currentHashMatches: Seq[InternalRow] = _\n+  private[this] var currentMatchPosition: Int = -1\n+\n+  // Mutable per row objects.\n+  private[this] var joinRow: JoinedRow = _\n+  private[this] var resultProjection: (InternalRow) => InternalRow = _\n+\n+  private[this] var hashed: HashedRelation = _\n+  private[this] var joinKeys: Projection = _\n+\n+  override def open(): Unit = {\n+    buildNode.open()\n+    hashed = HashedRelation.createLocalHashedRelation(buildNode, buildSideKeyGenerator)\n+    streamedNode.open()\n+    joinRow = new JoinedRow\n+    resultProjection = {\n+      if (isUnsafeMode) {\n+        UnsafeProjection.create(schema)\n+      } else {\n+        identity[InternalRow]\n+      }\n+    }\n+    joinKeys = streamSideKeyGenerator\n+  }\n+\n+  override def next(): Boolean = {\n+    if (currentMatchPosition != -1) {\n+      currentMatchPosition += 1\n+      if (currentMatchPosition < currentHashMatches.size) {\n+        true\n+      } else {\n+        fetchNextMatch()\n+      }\n+    } else {\n+      fetchNextMatch()\n+    }\n+  }\n+\n+  private def fetchNextMatch(): Boolean = {"
  }],
  "prId": 8535
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "what does this mean?\n",
    "commit": "fcec2975d74710f9d1604a01b806566e1f47f1a1",
    "createdAt": "2015-09-10T01:39:02Z",
    "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins._\n+\n+case class HashJoinNode (\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, streamedNode) = buildSide match {\n+    case BuildLeft => (left, right)\n+    case BuildRight => (right, left)\n+  }\n+\n+  private[this] lazy val (buildKeys, streamedKeys) = buildSide match {\n+    case BuildLeft => (leftKeys, rightKeys)\n+    case BuildRight => (rightKeys, leftKeys)\n+  }\n+\n+  override def output: Seq[Attribute] = left.output ++ right.output\n+\n+  private[this] def isUnsafeMode: Boolean = {\n+    (codegenEnabled && unsafeEnabled\n+      && UnsafeProjection.canSupport(buildKeys)\n+      && UnsafeProjection.canSupport(schema))\n+  }\n+\n+  private[this] def buildSideKeyGenerator: Projection =\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(buildKeys, buildNode.output)\n+    } else {\n+      newMutableProjection(buildKeys, buildNode.output)()\n+    }\n+\n+  private[this] def streamSideKeyGenerator: Projection =\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(streamedKeys, streamedNode.output)\n+    } else {\n+      newMutableProjection(streamedKeys, streamedNode.output)()\n+    }\n+\n+  private[this] var currentStreamedRow: InternalRow = _\n+  private[this] var currentHashMatches: Seq[InternalRow] = _\n+  private[this] var currentMatchPosition: Int = -1\n+\n+  // Mutable per row objects."
  }],
  "prId": 8535
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "nit: can you put all the `var`s before `def`s so it's easy to find them?\n",
    "commit": "fcec2975d74710f9d1604a01b806566e1f47f1a1",
    "createdAt": "2015-09-10T01:39:19Z",
    "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins._\n+\n+case class HashJoinNode (\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, streamedNode) = buildSide match {\n+    case BuildLeft => (left, right)\n+    case BuildRight => (right, left)\n+  }\n+\n+  private[this] lazy val (buildKeys, streamedKeys) = buildSide match {\n+    case BuildLeft => (leftKeys, rightKeys)\n+    case BuildRight => (rightKeys, leftKeys)\n+  }\n+\n+  override def output: Seq[Attribute] = left.output ++ right.output\n+\n+  private[this] def isUnsafeMode: Boolean = {\n+    (codegenEnabled && unsafeEnabled\n+      && UnsafeProjection.canSupport(buildKeys)\n+      && UnsafeProjection.canSupport(schema))\n+  }\n+\n+  private[this] def buildSideKeyGenerator: Projection =\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(buildKeys, buildNode.output)\n+    } else {\n+      newMutableProjection(buildKeys, buildNode.output)()\n+    }\n+\n+  private[this] def streamSideKeyGenerator: Projection =\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(streamedKeys, streamedNode.output)\n+    } else {\n+      newMutableProjection(streamedKeys, streamedNode.output)()\n+    }\n+\n+  private[this] var currentStreamedRow: InternalRow = _\n+  private[this] var currentHashMatches: Seq[InternalRow] = _\n+  private[this] var currentMatchPosition: Int = -1\n+\n+  // Mutable per row objects.\n+  private[this] var joinRow: JoinedRow = _\n+  private[this] var resultProjection: (InternalRow) => InternalRow = _\n+\n+  private[this] var hashed: HashedRelation = _\n+  private[this] var joinKeys: Projection = _",
    "line": 50
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "Sure. Moved them.\n",
    "commit": "fcec2975d74710f9d1604a01b806566e1f47f1a1",
    "createdAt": "2015-09-10T15:02:32Z",
    "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins._\n+\n+case class HashJoinNode (\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, streamedNode) = buildSide match {\n+    case BuildLeft => (left, right)\n+    case BuildRight => (right, left)\n+  }\n+\n+  private[this] lazy val (buildKeys, streamedKeys) = buildSide match {\n+    case BuildLeft => (leftKeys, rightKeys)\n+    case BuildRight => (rightKeys, leftKeys)\n+  }\n+\n+  override def output: Seq[Attribute] = left.output ++ right.output\n+\n+  private[this] def isUnsafeMode: Boolean = {\n+    (codegenEnabled && unsafeEnabled\n+      && UnsafeProjection.canSupport(buildKeys)\n+      && UnsafeProjection.canSupport(schema))\n+  }\n+\n+  private[this] def buildSideKeyGenerator: Projection =\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(buildKeys, buildNode.output)\n+    } else {\n+      newMutableProjection(buildKeys, buildNode.output)()\n+    }\n+\n+  private[this] def streamSideKeyGenerator: Projection =\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(streamedKeys, streamedNode.output)\n+    } else {\n+      newMutableProjection(streamedKeys, streamedNode.output)()\n+    }\n+\n+  private[this] var currentStreamedRow: InternalRow = _\n+  private[this] var currentHashMatches: Seq[InternalRow] = _\n+  private[this] var currentMatchPosition: Int = -1\n+\n+  // Mutable per row objects.\n+  private[this] var joinRow: JoinedRow = _\n+  private[this] var resultProjection: (InternalRow) => InternalRow = _\n+\n+  private[this] var hashed: HashedRelation = _\n+  private[this] var joinKeys: Projection = _",
    "line": 50
  }],
  "prId": 8535
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "minor: I would prefer for `LocalNodeIterator` to be hidden outside `LocalNode` so the separation is cleaner. I'll submit a follow-up patch to do this.\n",
    "commit": "fcec2975d74710f9d1604a01b806566e1f47f1a1",
    "createdAt": "2015-09-10T18:23:35Z",
    "diffHunk": "@@ -0,0 +1,137 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins._\n+import org.apache.spark.sql.execution.metric.SQLMetrics\n+\n+/**\n+ * Much of this code is similar to [[org.apache.spark.sql.execution.joins.HashJoin]].\n+ */\n+case class HashJoinNode(\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, buildKeys, streamedNode, streamedKeys) = buildSide match {\n+    case BuildLeft => (left, leftKeys, right, rightKeys)\n+    case BuildRight => (right, rightKeys, left, leftKeys)\n+  }\n+\n+  private[this] var currentStreamedRow: InternalRow = _\n+  private[this] var currentHashMatches: Seq[InternalRow] = _\n+  private[this] var currentMatchPosition: Int = -1\n+\n+  private[this] var joinRow: JoinedRow = _\n+  private[this] var resultProjection: (InternalRow) => InternalRow = _\n+\n+  private[this] var hashed: HashedRelation = _\n+  private[this] var joinKeys: Projection = _\n+\n+  override def output: Seq[Attribute] = left.output ++ right.output\n+\n+  private[this] def isUnsafeMode: Boolean = {\n+    (codegenEnabled && unsafeEnabled\n+      && UnsafeProjection.canSupport(buildKeys)\n+      && UnsafeProjection.canSupport(schema))\n+  }\n+\n+  private[this] def buildSideKeyGenerator: Projection = {\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(buildKeys, buildNode.output)\n+    } else {\n+      newMutableProjection(buildKeys, buildNode.output)()\n+    }\n+  }\n+\n+  private[this] def streamSideKeyGenerator: Projection = {\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(streamedKeys, streamedNode.output)\n+    } else {\n+      newMutableProjection(streamedKeys, streamedNode.output)()\n+    }\n+  }\n+\n+  override def open(): Unit = {\n+    buildNode.open()\n+    hashed = HashedRelation.apply(\n+      new LocalNodeIterator(buildNode), SQLMetrics.nullLongMetric, buildSideKeyGenerator)",
    "line": 79
  }],
  "prId": 8535
}]