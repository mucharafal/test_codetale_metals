[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Lets just drop row buffer in favor of `ExternalAppendOnlyUnsafeRowArray` it doesn't make a lot of sense to keep this around.  We just need a `generateIterator(offset)` for the unbounded following case.",
    "commit": "23acc3ff82bc885b295d069bd865129427d3c59e",
    "createdAt": "2017-02-13T09:57:46Z",
    "diffHunk": "@@ -17,99 +17,33 @@\n \n package org.apache.spark.sql.execution.window\n \n-import scala.collection.mutable.ArrayBuffer\n-\n import org.apache.spark.sql.catalyst.InternalRow\n import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n-import org.apache.spark.util.collection.unsafe.sort.{UnsafeExternalSorter, UnsafeSorterIterator}\n-\n+import org.apache.spark.sql.execution.ExternalAppendOnlyUnsafeRowArray\n \n /**\n- * The interface of row buffer for a partition. In absence of a buffer pool (with locking), the\n+ * Represents row buffer for a partition. In absence of a buffer pool (with locking), the\n  * row buffer is used to materialize a partition of rows since we need to repeatedly scan these\n  * rows in window function processing.\n  */\n-private[window] abstract class RowBuffer {\n-\n-  /** Number of rows. */\n-  def size: Int\n-\n-  /** Return next row in the buffer, null if no more left. */\n-  def next(): InternalRow\n-\n-  /** Skip the next `n` rows. */\n-  def skip(n: Int): Unit\n-\n-  /** Return a new RowBuffer that has the same rows. */\n-  def copy(): RowBuffer\n-}\n-\n-/**\n- * A row buffer based on ArrayBuffer (the number of rows is limited).\n- */\n-private[window] class ArrayRowBuffer(buffer: ArrayBuffer[UnsafeRow]) extends RowBuffer {\n-\n-  private[this] var cursor: Int = -1\n-\n-  /** Number of rows. */\n-  override def size: Int = buffer.length\n-\n-  /** Return next row in the buffer, null if no more left. */\n-  override def next(): InternalRow = {\n-    cursor += 1\n-    if (cursor < buffer.length) {\n-      buffer(cursor)\n-    } else {\n-      null\n-    }\n-  }\n-\n-  /** Skip the next `n` rows. */\n-  override def skip(n: Int): Unit = {\n-    cursor += n\n-  }\n-\n-  /** Return a new RowBuffer that has the same rows. */\n-  override def copy(): RowBuffer = {\n-    new ArrayRowBuffer(buffer)\n-  }\n-}\n-\n-/**\n- * An external buffer of rows based on UnsafeExternalSorter.\n- */\n-private[window] class ExternalRowBuffer(sorter: UnsafeExternalSorter, numFields: Int)\n-  extends RowBuffer {\n-\n-  private[this] val iter: UnsafeSorterIterator = sorter.getIterator\n-\n-  private[this] val currentRow = new UnsafeRow(numFields)\n+private[window] class RowBuffer(appendOnlyExternalArray: ExternalAppendOnlyUnsafeRowArray) {"
  }, {
    "author": {
      "login": "tejasapatil"
    },
    "body": "Removed `RowBuffer`",
    "commit": "23acc3ff82bc885b295d069bd865129427d3c59e",
    "createdAt": "2017-02-14T21:43:56Z",
    "diffHunk": "@@ -17,99 +17,33 @@\n \n package org.apache.spark.sql.execution.window\n \n-import scala.collection.mutable.ArrayBuffer\n-\n import org.apache.spark.sql.catalyst.InternalRow\n import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n-import org.apache.spark.util.collection.unsafe.sort.{UnsafeExternalSorter, UnsafeSorterIterator}\n-\n+import org.apache.spark.sql.execution.ExternalAppendOnlyUnsafeRowArray\n \n /**\n- * The interface of row buffer for a partition. In absence of a buffer pool (with locking), the\n+ * Represents row buffer for a partition. In absence of a buffer pool (with locking), the\n  * row buffer is used to materialize a partition of rows since we need to repeatedly scan these\n  * rows in window function processing.\n  */\n-private[window] abstract class RowBuffer {\n-\n-  /** Number of rows. */\n-  def size: Int\n-\n-  /** Return next row in the buffer, null if no more left. */\n-  def next(): InternalRow\n-\n-  /** Skip the next `n` rows. */\n-  def skip(n: Int): Unit\n-\n-  /** Return a new RowBuffer that has the same rows. */\n-  def copy(): RowBuffer\n-}\n-\n-/**\n- * A row buffer based on ArrayBuffer (the number of rows is limited).\n- */\n-private[window] class ArrayRowBuffer(buffer: ArrayBuffer[UnsafeRow]) extends RowBuffer {\n-\n-  private[this] var cursor: Int = -1\n-\n-  /** Number of rows. */\n-  override def size: Int = buffer.length\n-\n-  /** Return next row in the buffer, null if no more left. */\n-  override def next(): InternalRow = {\n-    cursor += 1\n-    if (cursor < buffer.length) {\n-      buffer(cursor)\n-    } else {\n-      null\n-    }\n-  }\n-\n-  /** Skip the next `n` rows. */\n-  override def skip(n: Int): Unit = {\n-    cursor += n\n-  }\n-\n-  /** Return a new RowBuffer that has the same rows. */\n-  override def copy(): RowBuffer = {\n-    new ArrayRowBuffer(buffer)\n-  }\n-}\n-\n-/**\n- * An external buffer of rows based on UnsafeExternalSorter.\n- */\n-private[window] class ExternalRowBuffer(sorter: UnsafeExternalSorter, numFields: Int)\n-  extends RowBuffer {\n-\n-  private[this] val iter: UnsafeSorterIterator = sorter.getIterator\n-\n-  private[this] val currentRow = new UnsafeRow(numFields)\n+private[window] class RowBuffer(appendOnlyExternalArray: ExternalAppendOnlyUnsafeRowArray) {"
  }],
  "prId": 16909
}]