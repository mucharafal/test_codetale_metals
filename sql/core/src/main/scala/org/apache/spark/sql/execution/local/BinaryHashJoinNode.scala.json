[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Why is this a lazy val?\n",
    "commit": "081e33118685f8bfa537ae954b1b889d90912f9c",
    "createdAt": "2015-10-06T19:04:10Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins.{HashedRelation, BuildLeft, BuildRight, BuildSide}\n+\n+/**\n+ * A wrapper of [[HashJoinNode]]. It will build the [[HashedRelation]] according to the value of\n+ * `buildSide`. The actual work of this node will be delegated to the [[HashJoinNode]]\n+ * that is created in `open`.\n+ */\n+case class BinaryHashJoinNode(\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, buildKeys, streamedNode, streamedKeys) = buildSide match {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "agreed, doesn't need to be\n",
    "commit": "081e33118685f8bfa537ae954b1b889d90912f9c",
    "createdAt": "2015-10-06T20:26:54Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins.{HashedRelation, BuildLeft, BuildRight, BuildSide}\n+\n+/**\n+ * A wrapper of [[HashJoinNode]]. It will build the [[HashedRelation]] according to the value of\n+ * `buildSide`. The actual work of this node will be delegated to the [[HashJoinNode]]\n+ * that is created in `open`.\n+ */\n+case class BinaryHashJoinNode(\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, buildKeys, streamedNode, streamedKeys) = buildSide match {"
  }, {
    "author": {
      "login": "yhuai"
    },
    "body": "Removed `lazy`.\n",
    "commit": "081e33118685f8bfa537ae954b1b889d90912f9c",
    "createdAt": "2015-10-07T20:07:19Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins.{HashedRelation, BuildLeft, BuildRight, BuildSide}\n+\n+/**\n+ * A wrapper of [[HashJoinNode]]. It will build the [[HashedRelation]] according to the value of\n+ * `buildSide`. The actual work of this node will be delegated to the [[HashJoinNode]]\n+ * that is created in `open`.\n+ */\n+case class BinaryHashJoinNode(\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, buildKeys, streamedNode, streamedKeys) = buildSide match {"
  }],
  "prId": 8953
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "is it too late to call the hash join node's `prepare` here in `open`? Don't we need to call it in our own `prepare`?\n",
    "commit": "081e33118685f8bfa537ae954b1b889d90912f9c",
    "createdAt": "2015-10-07T01:10:30Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins.{HashedRelation, BuildLeft, BuildRight, BuildSide}\n+\n+/**\n+ * A wrapper of [[HashJoinNode]]. It will build the [[HashedRelation]] according to the value of\n+ * `buildSide`. The actual work of this node will be delegated to the [[HashJoinNode]]\n+ * that is created in `open`.\n+ */\n+case class BinaryHashJoinNode(\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, buildKeys, streamedNode, streamedKeys) = buildSide match {\n+    case BuildLeft => (left, leftKeys, right, rightKeys)\n+    case BuildRight => (right, rightKeys, left, leftKeys)\n+  }\n+\n+  private[this] val hashJoinNode: HashJoinNode = {\n+    HashJoinNode(\n+      conf = conf,\n+      streamedKeys = streamedKeys,\n+      streamedNode = streamedNode,\n+      buildSide = buildSide,\n+      buildOutput = buildNode.output,\n+      isWrapped = true)\n+  }\n+  override def output: Seq[Attribute] = left.output ++ right.output\n+\n+  private[this] def isUnsafeMode: Boolean = {\n+    (codegenEnabled && unsafeEnabled && UnsafeProjection.canSupport(buildKeys))\n+  }\n+\n+  private[this] def buildSideKeyGenerator: Projection = {\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(buildKeys, buildNode.output)\n+    } else {\n+      newMutableProjection(buildKeys, buildNode.output)()\n+    }\n+  }\n+\n+  override def open(): Unit = {\n+    // buildNode's prepare has been called in this.prepare.\n+    buildNode.open()\n+    val hashedRelation = HashedRelation(buildNode, buildSideKeyGenerator)\n+    // We have built the HashedRelation. So, close buildNode.\n+    buildNode.close()\n+\n+    // Call the open of streamedNode.\n+    streamedNode.open()\n+    // Set the HashedRelation used by the HashJoinNode.\n+    hashJoinNode.withHashedRelation(hashedRelation)\n+    // Setup this HashJoinNode. We still call these in case there is any setup work\n+    // that needs to be done in this HashJoinNode. Because isWrapped is true,\n+    // prepare and open will not propagate to the child of streamedNode.\n+    hashJoinNode.prepare()"
  }],
  "prId": 8953
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "these comments are not very useful... :) I would just remove them since they don't add any value.\n",
    "commit": "081e33118685f8bfa537ae954b1b889d90912f9c",
    "createdAt": "2015-10-07T01:11:31Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins.{HashedRelation, BuildLeft, BuildRight, BuildSide}\n+\n+/**\n+ * A wrapper of [[HashJoinNode]]. It will build the [[HashedRelation]] according to the value of\n+ * `buildSide`. The actual work of this node will be delegated to the [[HashJoinNode]]\n+ * that is created in `open`.\n+ */\n+case class BinaryHashJoinNode(\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, buildKeys, streamedNode, streamedKeys) = buildSide match {\n+    case BuildLeft => (left, leftKeys, right, rightKeys)\n+    case BuildRight => (right, rightKeys, left, leftKeys)\n+  }\n+\n+  private[this] val hashJoinNode: HashJoinNode = {\n+    HashJoinNode(\n+      conf = conf,\n+      streamedKeys = streamedKeys,\n+      streamedNode = streamedNode,\n+      buildSide = buildSide,\n+      buildOutput = buildNode.output,\n+      isWrapped = true)\n+  }\n+  override def output: Seq[Attribute] = left.output ++ right.output\n+\n+  private[this] def isUnsafeMode: Boolean = {\n+    (codegenEnabled && unsafeEnabled && UnsafeProjection.canSupport(buildKeys))\n+  }\n+\n+  private[this] def buildSideKeyGenerator: Projection = {\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(buildKeys, buildNode.output)\n+    } else {\n+      newMutableProjection(buildKeys, buildNode.output)()\n+    }\n+  }\n+\n+  override def open(): Unit = {\n+    // buildNode's prepare has been called in this.prepare.\n+    buildNode.open()\n+    val hashedRelation = HashedRelation(buildNode, buildSideKeyGenerator)\n+    // We have built the HashedRelation. So, close buildNode.\n+    buildNode.close()\n+\n+    // Call the open of streamedNode."
  }, {
    "author": {
      "login": "yhuai"
    },
    "body": "removed\n",
    "commit": "081e33118685f8bfa537ae954b1b889d90912f9c",
    "createdAt": "2015-10-07T20:08:13Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins.{HashedRelation, BuildLeft, BuildRight, BuildSide}\n+\n+/**\n+ * A wrapper of [[HashJoinNode]]. It will build the [[HashedRelation]] according to the value of\n+ * `buildSide`. The actual work of this node will be delegated to the [[HashJoinNode]]\n+ * that is created in `open`.\n+ */\n+case class BinaryHashJoinNode(\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode) extends BinaryLocalNode(conf) {\n+\n+  private[this] lazy val (buildNode, buildKeys, streamedNode, streamedKeys) = buildSide match {\n+    case BuildLeft => (left, leftKeys, right, rightKeys)\n+    case BuildRight => (right, rightKeys, left, leftKeys)\n+  }\n+\n+  private[this] val hashJoinNode: HashJoinNode = {\n+    HashJoinNode(\n+      conf = conf,\n+      streamedKeys = streamedKeys,\n+      streamedNode = streamedNode,\n+      buildSide = buildSide,\n+      buildOutput = buildNode.output,\n+      isWrapped = true)\n+  }\n+  override def output: Seq[Attribute] = left.output ++ right.output\n+\n+  private[this] def isUnsafeMode: Boolean = {\n+    (codegenEnabled && unsafeEnabled && UnsafeProjection.canSupport(buildKeys))\n+  }\n+\n+  private[this] def buildSideKeyGenerator: Projection = {\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(buildKeys, buildNode.output)\n+    } else {\n+      newMutableProjection(buildKeys, buildNode.output)()\n+    }\n+  }\n+\n+  override def open(): Unit = {\n+    // buildNode's prepare has been called in this.prepare.\n+    buildNode.open()\n+    val hashedRelation = HashedRelation(buildNode, buildSideKeyGenerator)\n+    // We have built the HashedRelation. So, close buildNode.\n+    buildNode.close()\n+\n+    // Call the open of streamedNode."
  }],
  "prId": 8953
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "probably don't need this comment? We generally don't call `prepare` in `open` I don't think\n",
    "commit": "081e33118685f8bfa537ae954b1b889d90912f9c",
    "createdAt": "2015-10-07T22:09:51Z",
    "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.execution.joins.{HashedRelation, BuildLeft, BuildRight, BuildSide}\n+\n+/**\n+ * A [[HashJoinNode]] that builds the [[HashedRelation]] according to the value of\n+ * `buildSide`. The actual work of this node is defined in [[HashJoinNode]].\n+ */\n+case class BinaryHashJoinNode(\n+    conf: SQLConf,\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    buildSide: BuildSide,\n+    left: LocalNode,\n+    right: LocalNode)\n+  extends BinaryLocalNode(conf) with HashJoinNode {\n+\n+  protected override val (streamedNode, streamedKeys) = buildSide match {\n+    case BuildLeft => (right, rightKeys)\n+    case BuildRight => (left, leftKeys)\n+  }\n+\n+  private val (buildNode, buildKeys) = buildSide match {\n+    case BuildLeft => (left, leftKeys)\n+    case BuildRight => (right, rightKeys)\n+  }\n+\n+  override def output: Seq[Attribute] = left.output ++ right.output\n+\n+  private def buildSideKeyGenerator: Projection = {\n+    // We are expecting the data types of buildKeys and streamedKeys are the same.\n+    assert(buildKeys.map(_.dataType) == streamedKeys.map(_.dataType))\n+    if (isUnsafeMode) {\n+      UnsafeProjection.create(buildKeys, buildNode.output)\n+    } else {\n+      newMutableProjection(buildKeys, buildNode.output)()\n+    }\n+  }\n+\n+  protected override def doOpen(): Unit = {\n+    // buildNode's prepare has been called in this.prepare."
  }],
  "prId": 8953
}]