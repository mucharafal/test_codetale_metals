[{
  "comments": [{
    "author": {
      "login": "chenghao-intel"
    },
    "body": "Do we really need this configuration key?\n",
    "commit": "bc3cd737bdb5836780e7e0caa80817e075c91ef7",
    "createdAt": "2015-07-17T07:20:54Z",
    "diffHunk": "@@ -447,6 +452,12 @@ private[sql] class SQLConf extends Serializable with CatalystConf {\n   /** When true uses verifyPartitionPath to prune the path which is not exists. */\n   private[spark] def verifyPartitionPath: Boolean = getConf(HIVE_VERIFY_PARTITION_PATH)\n \n+  /**\n+   * When true will write the schema serde info into the hive metastore\n+   * while CREATE / ALTER data sourced table via HiveContext-backend DataFrame API.\n+   */\n+  private[spark] def writeSchemaToHiveMetastore = getConf(HIVE_WRITE_DATASOURCE_SCHEMA)"
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "I don't think this is necessary.\n",
    "commit": "bc3cd737bdb5836780e7e0caa80817e075c91ef7",
    "createdAt": "2015-07-28T16:21:13Z",
    "diffHunk": "@@ -447,6 +452,12 @@ private[sql] class SQLConf extends Serializable with CatalystConf {\n   /** When true uses verifyPartitionPath to prune the path which is not exists. */\n   private[spark] def verifyPartitionPath: Boolean = getConf(HIVE_VERIFY_PARTITION_PATH)\n \n+  /**\n+   * When true will write the schema serde info into the hive metastore\n+   * while CREATE / ALTER data sourced table via HiveContext-backend DataFrame API.\n+   */\n+  private[spark] def writeSchemaToHiveMetastore = getConf(HIVE_WRITE_DATASOURCE_SCHEMA)"
  }],
  "prId": 5733
}]