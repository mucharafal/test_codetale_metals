[{
  "comments": [{
    "author": {
      "login": "icexelloss"
    },
    "body": "This is no longer needed because this rule will only extract Python UDF and Scalar Pandas UDF and ignore other types of UDFs",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-06-27T22:49:47Z",
    "diffHunk": "@@ -94,36 +95,59 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  private def canEvaluateInPython(e: PythonUDF, evalType: Int): Boolean = {\n+    if (e.evalType != evalType) {\n+      false\n+    } else {\n+      e.children match {\n+        // single PythonUDF child could be chained and evaluated in Python\n+        case Seq(u: PythonUDF) => canEvaluateInPython(u, evalType)\n+        // Python UDF can't be evaluated directly in JVM\n+        case children => !children.exists(hasScalarPythonUDF)\n+      }\n     }\n   }\n \n-  private def collectEvaluatableUDF(expr: Expression): Seq[PythonUDF] = expr match {\n-    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf) => Seq(udf)\n-    case e => e.children.flatMap(collectEvaluatableUDF)\n+  private def collectEvaluableUDF(expr: Expression, evalType: Int): Seq[PythonUDF] = expr match {\n+    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf, evalType) =>\n+      Seq(udf)\n+    case e => e.children.flatMap(collectEvaluableUDF(_, evalType))\n+  }\n+\n+  /**\n+   * Collect evaluable UDFs from the current node.\n+   *\n+   * This function collects Python UDFs or Scalar Python UDFs from expressions of the input node,\n+   * and returns a list of UDFs of the same eval type.\n+   *\n+   * If expressions contain both UDFs eval types, this function will only return Python UDFs.\n+   *\n+   * The caller should call this function multiple times until all evaluable UDFs are collected.\n+   */\n+  private def collectEvaluableUDFs(plan: SparkPlan): Seq[PythonUDF] = {\n+    val pythonUDFs =\n+      plan.expressions.flatMap(collectEvaluableUDF(_, PythonEvalType.SQL_BATCHED_UDF))\n+\n+    if (pythonUDFs.isEmpty) {\n+      plan.expressions.flatMap(collectEvaluableUDF(_, PythonEvalType.SQL_SCALAR_PANDAS_UDF))\n+    } else {\n+      pythonUDFs\n+    }\n   }\n \n   def apply(plan: SparkPlan): SparkPlan = plan transformUp {\n-    // AggregateInPandasExec and FlatMapGroupsInPandas can be evaluated directly in python worker\n-    // Therefore we don't need to extract the UDFs\n-    case plan: FlatMapGroupsInPandasExec => plan",
    "line": 58
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "BryanCutler"
    },
    "body": "What happens if the user tries to mix a non-scalar UDF?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-06-28T23:57:22Z",
    "diffHunk": "@@ -94,36 +95,59 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  private def canEvaluateInPython(e: PythonUDF, evalType: Int): Boolean = {\n+    if (e.evalType != evalType) {\n+      false\n+    } else {\n+      e.children match {\n+        // single PythonUDF child could be chained and evaluated in Python\n+        case Seq(u: PythonUDF) => canEvaluateInPython(u, evalType)\n+        // Python UDF can't be evaluated directly in JVM\n+        case children => !children.exists(hasScalarPythonUDF)\n+      }\n     }\n   }\n \n-  private def collectEvaluatableUDF(expr: Expression): Seq[PythonUDF] = expr match {\n-    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf) => Seq(udf)\n-    case e => e.children.flatMap(collectEvaluatableUDF)\n+  private def collectEvaluableUDF(expr: Expression, evalType: Int): Seq[PythonUDF] = expr match {\n+    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf, evalType) =>\n+      Seq(udf)\n+    case e => e.children.flatMap(collectEvaluableUDF(_, evalType))\n+  }\n+\n+  /**\n+   * Collect evaluable UDFs from the current node.\n+   *\n+   * This function collects Python UDFs or Scalar Python UDFs from expressions of the input node,\n+   * and returns a list of UDFs of the same eval type."
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Hmm.. It currently will throw an exception in the codegen stage. (Because non-scalar UDF will not be extracted by this rule)\r\n\r\nWe should probably throw a better exception but I need to think a bit how to do it.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-06-29T00:39:29Z",
    "diffHunk": "@@ -94,36 +95,59 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  private def canEvaluateInPython(e: PythonUDF, evalType: Int): Boolean = {\n+    if (e.evalType != evalType) {\n+      false\n+    } else {\n+      e.children match {\n+        // single PythonUDF child could be chained and evaluated in Python\n+        case Seq(u: PythonUDF) => canEvaluateInPython(u, evalType)\n+        // Python UDF can't be evaluated directly in JVM\n+        case children => !children.exists(hasScalarPythonUDF)\n+      }\n     }\n   }\n \n-  private def collectEvaluatableUDF(expr: Expression): Seq[PythonUDF] = expr match {\n-    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf) => Seq(udf)\n-    case e => e.children.flatMap(collectEvaluatableUDF)\n+  private def collectEvaluableUDF(expr: Expression, evalType: Int): Seq[PythonUDF] = expr match {\n+    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf, evalType) =>\n+      Seq(udf)\n+    case e => e.children.flatMap(collectEvaluableUDF(_, evalType))\n+  }\n+\n+  /**\n+   * Collect evaluable UDFs from the current node.\n+   *\n+   * This function collects Python UDFs or Scalar Python UDFs from expressions of the input node,\n+   * and returns a list of UDFs of the same eval type."
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "I tried this on master and got the same exception:\r\n\r\n```\r\n>>> foo = pandas_udf(lambda x: x, 'v int', PandasUDFType.GROUPED_MAP)\r\n>>> df.select(foo(df['v'])).show()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/icexelloss/workspace/upstream/spark/python/pyspark/sql/dataframe.py\", line 353, in show\r\n    print(self._jdf.showString(n, 20, vertical))\r\n  File \"/Users/icexelloss/workspace/upstream/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\r\n  File \"/Users/icexelloss/workspace/upstream/spark/python/pyspark/sql/utils.py\", line 63, in deco\r\n    return f(*a, **kw)\r\n  File \"/Users/icexelloss/workspace/upstream/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\r\npy4j.protocol.Py4JJavaError: An error occurred while calling o257.showString.\r\n: java.lang.UnsupportedOperationException: Cannot evaluate expression: <lambda>(input[0, bigint, false])\r\n\tat org.apache.spark.sql.catalyst.expressions.Unevaluable$class.doGenCode(Expression.scala:261)\r\n\tat org.apache.spark.sql.catalyst.expressions.PythonUDF.doGenCode(PythonUDF.scala:50)\r\n\tat org.apache.spark.sql.catalyst.expressions.Expression$$anonfun$genCode$2.apply(Expression.scala:108)\r\n\tat org.apache.spark.sql.catalyst.expressions.Expression$$anonfun$genCode$2.apply(Expression.scala:105)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n        ...\r\n```\r\nTherefore, this PR doesn't change that behavior. Both master and this PR don't extract non-scalar UDF in the expression. ",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-06-29T15:48:56Z",
    "diffHunk": "@@ -94,36 +95,59 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  private def canEvaluateInPython(e: PythonUDF, evalType: Int): Boolean = {\n+    if (e.evalType != evalType) {\n+      false\n+    } else {\n+      e.children match {\n+        // single PythonUDF child could be chained and evaluated in Python\n+        case Seq(u: PythonUDF) => canEvaluateInPython(u, evalType)\n+        // Python UDF can't be evaluated directly in JVM\n+        case children => !children.exists(hasScalarPythonUDF)\n+      }\n     }\n   }\n \n-  private def collectEvaluatableUDF(expr: Expression): Seq[PythonUDF] = expr match {\n-    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf) => Seq(udf)\n-    case e => e.children.flatMap(collectEvaluatableUDF)\n+  private def collectEvaluableUDF(expr: Expression, evalType: Int): Seq[PythonUDF] = expr match {\n+    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf, evalType) =>\n+      Seq(udf)\n+    case e => e.children.flatMap(collectEvaluableUDF(_, evalType))\n+  }\n+\n+  /**\n+   * Collect evaluable UDFs from the current node.\n+   *\n+   * This function collects Python UDFs or Scalar Python UDFs from expressions of the input node,\n+   * and returns a list of UDFs of the same eval type."
  }, {
    "author": {
      "login": "BryanCutler"
    },
    "body": "Yeah, that's not a very informative exception but we can fix that later. I made https://issues.apache.org/jira/browse/SPARK-24735 to track.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-03T20:21:57Z",
    "diffHunk": "@@ -94,36 +95,59 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  private def canEvaluateInPython(e: PythonUDF, evalType: Int): Boolean = {\n+    if (e.evalType != evalType) {\n+      false\n+    } else {\n+      e.children match {\n+        // single PythonUDF child could be chained and evaluated in Python\n+        case Seq(u: PythonUDF) => canEvaluateInPython(u, evalType)\n+        // Python UDF can't be evaluated directly in JVM\n+        case children => !children.exists(hasScalarPythonUDF)\n+      }\n     }\n   }\n \n-  private def collectEvaluatableUDF(expr: Expression): Seq[PythonUDF] = expr match {\n-    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf) => Seq(udf)\n-    case e => e.children.flatMap(collectEvaluatableUDF)\n+  private def collectEvaluableUDF(expr: Expression, evalType: Int): Seq[PythonUDF] = expr match {\n+    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf, evalType) =>\n+      Seq(udf)\n+    case e => e.children.flatMap(collectEvaluableUDF(_, evalType))\n+  }\n+\n+  /**\n+   * Collect evaluable UDFs from the current node.\n+   *\n+   * This function collects Python UDFs or Scalar Python UDFs from expressions of the input node,\n+   * and returns a list of UDFs of the same eval type."
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "BryanCutler"
    },
    "body": "Why change the exception type?  Can you make a test that causes this?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-06-28T23:58:01Z",
    "diffHunk": "@@ -166,8 +190,9 @@ object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n               ArrowEvalPythonExec(vectorizedUdfs, child.output ++ resultAttrs, child)\n             case (vectorizedUdfs, plainUdfs) if vectorizedUdfs.isEmpty =>\n               BatchEvalPythonExec(plainUdfs, child.output ++ resultAttrs, child)\n-            case _ =>\n-              throw new IllegalArgumentException(\"Can not mix vectorized and non-vectorized UDFs\")\n+            case (vectorizedUdfs, plainUdfs) =>\n+              throw new AnalysisException("
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "This is because we shouldn't reach here. (Otherwise it's bug). Don't know what's the best exception type here though.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-06-29T00:40:51Z",
    "diffHunk": "@@ -166,8 +190,9 @@ object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n               ArrowEvalPythonExec(vectorizedUdfs, child.output ++ resultAttrs, child)\n             case (vectorizedUdfs, plainUdfs) if vectorizedUdfs.isEmpty =>\n               BatchEvalPythonExec(plainUdfs, child.output ++ resultAttrs, child)\n-            case _ =>\n-              throw new IllegalArgumentException(\"Can not mix vectorized and non-vectorized UDFs\")\n+            case (vectorizedUdfs, plainUdfs) =>\n+              throw new AnalysisException("
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "BryanCutler"
    },
    "body": "So this will pipeline UDFs of the same eval type so that they can be processed together in the same call to python worker?  \r\n\r\nFor example if we have `pandas_udf, pandas_udf, udf, udf` then both `pandas_udfs` will be sent together to the worker, then both `udfs` together - python runner gets executed twice.\r\n\r\nOn the other hand, if we have `pandas_udf, udf, pandas_udf, udf` then each one will have to be executed at a time, and python runner gets executed 4 times.  Is that right?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-06-29T00:06:14Z",
    "diffHunk": "@@ -94,36 +95,59 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  private def canEvaluateInPython(e: PythonUDF, evalType: Int): Boolean = {\n+    if (e.evalType != evalType) {\n+      false\n+    } else {\n+      e.children match {\n+        // single PythonUDF child could be chained and evaluated in Python\n+        case Seq(u: PythonUDF) => canEvaluateInPython(u, evalType)\n+        // Python UDF can't be evaluated directly in JVM\n+        case children => !children.exists(hasScalarPythonUDF)\n+      }\n     }\n   }\n \n-  private def collectEvaluatableUDF(expr: Expression): Seq[PythonUDF] = expr match {\n-    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf) => Seq(udf)\n-    case e => e.children.flatMap(collectEvaluatableUDF)\n+  private def collectEvaluableUDF(expr: Expression, evalType: Int): Seq[PythonUDF] = expr match {\n+    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf, evalType) =>\n+      Seq(udf)\n+    case e => e.children.flatMap(collectEvaluableUDF(_, evalType))\n+  }\n+\n+  /**\n+   * Collect evaluable UDFs from the current node.\n+   *\n+   * This function collects Python UDFs or Scalar Python UDFs from expressions of the input node,\n+   * and returns a list of UDFs of the same eval type.\n+   *\n+   * If expressions contain both UDFs eval types, this function will only return Python UDFs.\n+   *\n+   * The caller should call this function multiple times until all evaluable UDFs are collected."
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "That's correct. ",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-06-29T00:41:23Z",
    "diffHunk": "@@ -94,36 +95,59 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  private def canEvaluateInPython(e: PythonUDF, evalType: Int): Boolean = {\n+    if (e.evalType != evalType) {\n+      false\n+    } else {\n+      e.children match {\n+        // single PythonUDF child could be chained and evaluated in Python\n+        case Seq(u: PythonUDF) => canEvaluateInPython(u, evalType)\n+        // Python UDF can't be evaluated directly in JVM\n+        case children => !children.exists(hasScalarPythonUDF)\n+      }\n     }\n   }\n \n-  private def collectEvaluatableUDF(expr: Expression): Seq[PythonUDF] = expr match {\n-    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf) => Seq(udf)\n-    case e => e.children.flatMap(collectEvaluatableUDF)\n+  private def collectEvaluableUDF(expr: Expression, evalType: Int): Seq[PythonUDF] = expr match {\n+    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf, evalType) =>\n+      Seq(udf)\n+    case e => e.children.flatMap(collectEvaluableUDF(_, evalType))\n+  }\n+\n+  /**\n+   * Collect evaluable UDFs from the current node.\n+   *\n+   * This function collects Python UDFs or Scalar Python UDFs from expressions of the input node,\n+   * and returns a list of UDFs of the same eval type.\n+   *\n+   * If expressions contain both UDFs eval types, this function will only return Python UDFs.\n+   *\n+   * The caller should call this function multiple times until all evaluable UDFs are collected."
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "`case _ =>` should work?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-06-29T04:36:10Z",
    "diffHunk": "@@ -166,8 +190,9 @@ object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n               ArrowEvalPythonExec(vectorizedUdfs, child.output ++ resultAttrs, child)\n             case (vectorizedUdfs, plainUdfs) if vectorizedUdfs.isEmpty =>\n               BatchEvalPythonExec(plainUdfs, child.output ++ resultAttrs, child)\n-            case _ =>\n-              throw new IllegalArgumentException(\"Can not mix vectorized and non-vectorized UDFs\")\n+            case (vectorizedUdfs, plainUdfs) =>"
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Oh yes, let me revert.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-06-29T13:57:18Z",
    "diffHunk": "@@ -166,8 +190,9 @@ object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n               ArrowEvalPythonExec(vectorizedUdfs, child.output ++ resultAttrs, child)\n             case (vectorizedUdfs, plainUdfs) if vectorizedUdfs.isEmpty =>\n               BatchEvalPythonExec(plainUdfs, child.output ++ resultAttrs, child)\n-            case _ =>\n-              throw new IllegalArgumentException(\"Can not mix vectorized and non-vectorized UDFs\")\n+            case (vectorizedUdfs, plainUdfs) =>"
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "BryanCutler"
    },
    "body": "I think it would be better to loop through the expressions and find the first scalar python udf, either `SQL_BATCHED_UDF` or `SQL_SCALAR_PANDAS_UDF` and then collect the rest of that type.  This is really what is happening here so I think it would be more straightforward to do this in a single loop instead of 2 `flatMaps`.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-17T00:02:44Z",
    "diffHunk": "@@ -94,36 +95,59 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  private def canEvaluateInPython(e: PythonUDF, evalType: Int): Boolean = {\n+    if (e.evalType != evalType) {\n+      false\n+    } else {\n+      e.children match {\n+        // single PythonUDF child could be chained and evaluated in Python\n+        case Seq(u: PythonUDF) => canEvaluateInPython(u, evalType)\n+        // Python UDF can't be evaluated directly in JVM\n+        case children => !children.exists(hasScalarPythonUDF)\n+      }\n     }\n   }\n \n-  private def collectEvaluatableUDF(expr: Expression): Seq[PythonUDF] = expr match {\n-    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf) => Seq(udf)\n-    case e => e.children.flatMap(collectEvaluatableUDF)\n+  private def collectEvaluableUDF(expr: Expression, evalType: Int): Seq[PythonUDF] = expr match {\n+    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf, evalType) =>\n+      Seq(udf)\n+    case e => e.children.flatMap(collectEvaluableUDF(_, evalType))\n+  }\n+\n+  /**\n+   * Collect evaluable UDFs from the current node.\n+   *\n+   * This function collects Python UDFs or Scalar Python UDFs from expressions of the input node,\n+   * and returns a list of UDFs of the same eval type.\n+   *\n+   * If expressions contain both UDFs eval types, this function will only return Python UDFs.\n+   *\n+   * The caller should call this function multiple times until all evaluable UDFs are collected.\n+   */\n+  private def collectEvaluableUDFs(plan: SparkPlan): Seq[PythonUDF] = {\n+    val pythonUDFs =\n+      plan.expressions.flatMap(collectEvaluableUDF(_, PythonEvalType.SQL_BATCHED_UDF))\n+\n+    if (pythonUDFs.isEmpty) {\n+      plan.expressions.flatMap(collectEvaluableUDF(_, PythonEvalType.SQL_SCALAR_PANDAS_UDF))\n+    } else {\n+      pythonUDFs"
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "What you said makes sense and that's actually my first attempt but end up being pretty complicated. The issue is that it is hard to do a one traversal of the expression tree to find the UDFs because we need to pass the evalType to all subtree and the result of one subtree can affect the result of another (i.e, if we find one type of UDF in one subtree, we need to pass the type to all other subtree because they must agree on evalType). Because the code is recursive in natural, this makes it pretty complicated to pass the correct eval Type in all places.\r\n\r\nAnother way is to do two traversals where in the first traversal, we look for eval type and in the second traversal, we look for UDFs of the eval type, but this isn't much different from what I have now in terms of efficiency and I find the current logic is simpler and less likely to have bugs. I actually tried these approaches and found the current way to be the easiest to implement and least likely to have bugs.\r\n\r\nWDYT?\r\n",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-23T14:48:16Z",
    "diffHunk": "@@ -94,36 +95,59 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  private def canEvaluateInPython(e: PythonUDF, evalType: Int): Boolean = {\n+    if (e.evalType != evalType) {\n+      false\n+    } else {\n+      e.children match {\n+        // single PythonUDF child could be chained and evaluated in Python\n+        case Seq(u: PythonUDF) => canEvaluateInPython(u, evalType)\n+        // Python UDF can't be evaluated directly in JVM\n+        case children => !children.exists(hasScalarPythonUDF)\n+      }\n     }\n   }\n \n-  private def collectEvaluatableUDF(expr: Expression): Seq[PythonUDF] = expr match {\n-    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf) => Seq(udf)\n-    case e => e.children.flatMap(collectEvaluatableUDF)\n+  private def collectEvaluableUDF(expr: Expression, evalType: Int): Seq[PythonUDF] = expr match {\n+    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf, evalType) =>\n+      Seq(udf)\n+    case e => e.children.flatMap(collectEvaluableUDF(_, evalType))\n+  }\n+\n+  /**\n+   * Collect evaluable UDFs from the current node.\n+   *\n+   * This function collects Python UDFs or Scalar Python UDFs from expressions of the input node,\n+   * and returns a list of UDFs of the same eval type.\n+   *\n+   * If expressions contain both UDFs eval types, this function will only return Python UDFs.\n+   *\n+   * The caller should call this function multiple times until all evaluable UDFs are collected.\n+   */\n+  private def collectEvaluableUDFs(plan: SparkPlan): Seq[PythonUDF] = {\n+    val pythonUDFs =\n+      plan.expressions.flatMap(collectEvaluableUDF(_, PythonEvalType.SQL_BATCHED_UDF))\n+\n+    if (pythonUDFs.isEmpty) {\n+      plan.expressions.flatMap(collectEvaluableUDF(_, PythonEvalType.SQL_SCALAR_PANDAS_UDF))\n+    } else {\n+      pythonUDFs"
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "BryanCutler"
    },
    "body": "It's a little confusing to have this function named so similar to the one below, maybe you can combine them if just doing a single loop (see other comment).",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-17T00:04:03Z",
    "diffHunk": "@@ -94,36 +95,59 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  private def canEvaluateInPython(e: PythonUDF, evalType: Int): Boolean = {\n+    if (e.evalType != evalType) {\n+      false\n+    } else {\n+      e.children match {\n+        // single PythonUDF child could be chained and evaluated in Python\n+        case Seq(u: PythonUDF) => canEvaluateInPython(u, evalType)\n+        // Python UDF can't be evaluated directly in JVM\n+        case children => !children.exists(hasScalarPythonUDF)\n+      }\n     }\n   }\n \n-  private def collectEvaluatableUDF(expr: Expression): Seq[PythonUDF] = expr match {\n-    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf) => Seq(udf)\n-    case e => e.children.flatMap(collectEvaluatableUDF)\n+  private def collectEvaluableUDF(expr: Expression, evalType: Int): Seq[PythonUDF] = expr match {"
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "BryanCutler"
    },
    "body": "Change this to \"Expected either Scalar Pandas UDFs or Batched UDFs but got both\"",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-17T00:16:02Z",
    "diffHunk": "@@ -167,7 +191,8 @@ object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n             case (vectorizedUdfs, plainUdfs) if vectorizedUdfs.isEmpty =>\n               BatchEvalPythonExec(plainUdfs, child.output ++ resultAttrs, child)\n             case _ =>\n-              throw new IllegalArgumentException(\"Can not mix vectorized and non-vectorized UDFs\")\n+              throw new AnalysisException(\n+                \"Mixed Python and Scalar Pandas UDFs are not expected here\")"
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Can we rename this function or write a comment since Scalar both Vectorized UDF and normal UDF can be evaluated in Python each but it returns `false` in this case?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T10:38:26Z",
    "diffHunk": "@@ -94,36 +95,59 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  private def canEvaluateInPython(e: PythonUDF, evalType: Int): Boolean = {\n+    if (e.evalType != evalType) {"
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "icexelloss"
    },
    "body": "@BryanCutler I rewrite this function using mutable state based on your suggestion. It's not quite the same as your code so please take a look and let me know if this looks better now. Thanks!",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T14:32:20Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {\n+\n+    def isSet: Boolean = evalType >= 0\n+\n+    def set(evalType: Int): Unit = {\n+      if (isSet) {\n+        throw new IllegalStateException(\"Eval type has already been set\")\n+      } else {\n+        this.evalType = evalType\n+      }\n+    }\n+\n+    def get(): Int = {\n+      if (!isSet) {\n+        throw new IllegalStateException(\"Eval type is not set\")\n+      } else {\n+        evalType\n+      }\n+    }\n+  }\n+\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  /**\n+   * Check whether a PythonUDF expression can be evaluated in Python.\n+   *\n+   * If the lazy eval type is not set, this method checks for either Batched Python UDF and Scalar\n+   * Pandas UDF. If the lazy eval type is set, this method checks for the expression of the\n+   * specified eval type.\n+   *\n+   * This method will also set the lazy eval type to be the type of the first evaluable expression,\n+   * i.e., if lazy eval type is not set and we find a evaluable Python UDF expression, lazy eval\n+   * type will be set to the eval type of the expression.\n+   *\n+   */\n+  private def canEvaluateInPython(e: PythonUDF, lazyEvalType: LazyEvalType): Boolean = {"
  }, {
    "author": {
      "login": "BryanCutler"
    },
    "body": "The one method seems overly complicated, so I prefer the code from my suggestion.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T17:02:06Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {\n+\n+    def isSet: Boolean = evalType >= 0\n+\n+    def set(evalType: Int): Unit = {\n+      if (isSet) {\n+        throw new IllegalStateException(\"Eval type has already been set\")\n+      } else {\n+        this.evalType = evalType\n+      }\n+    }\n+\n+    def get(): Int = {\n+      if (!isSet) {\n+        throw new IllegalStateException(\"Eval type is not set\")\n+      } else {\n+        evalType\n+      }\n+    }\n+  }\n+\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  /**\n+   * Check whether a PythonUDF expression can be evaluated in Python.\n+   *\n+   * If the lazy eval type is not set, this method checks for either Batched Python UDF and Scalar\n+   * Pandas UDF. If the lazy eval type is set, this method checks for the expression of the\n+   * specified eval type.\n+   *\n+   * This method will also set the lazy eval type to be the type of the first evaluable expression,\n+   * i.e., if lazy eval type is not set and we find a evaluable Python UDF expression, lazy eval\n+   * type will be set to the eval type of the expression.\n+   *\n+   */\n+  private def canEvaluateInPython(e: PythonUDF, lazyEvalType: LazyEvalType): Boolean = {"
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "In your code:\r\n\r\n```\r\n  private def canEvaluateInPython(e: PythonUDF, firstEvalType: FirstEvalType): Boolean = {\r\n    if (firstEvalType.isEvalTypeSet() && e.evalType != firstEvalType.evalType) {\r\n      false\r\n    } else {\r\n      firstEvalType.evalType = e.evalType\r\n      e.children match {\r\n        // single PythonUDF child could be chained and evaluated in Python\r\n        case Seq(u: PythonUDF) => canEvaluateInPython(u, firstEvalType)\r\n        // Python UDF can't be evaluated directly in JVM\r\n        case children => !children.exists(hasScalarPythonUDF)\r\n      }\r\n    }\r\n  }\r\n```\r\n\r\nI think what's confusing part here is that the value of `firstEvalType.evalType` keeps changing while we are traversing the tree, and we could be carrying the value across independent subtrees (i.e., after finish traversing one subtree, the firstEvalType can be set to Scalar Pandas, even we didn't find a evaluable UDF and we never reset it so when we visit another subtree, we could get wrong results). The fact that the firstEvalType keeps changing as we traverse the tree seems very error prone to me.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T17:56:20Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {\n+\n+    def isSet: Boolean = evalType >= 0\n+\n+    def set(evalType: Int): Unit = {\n+      if (isSet) {\n+        throw new IllegalStateException(\"Eval type has already been set\")\n+      } else {\n+        this.evalType = evalType\n+      }\n+    }\n+\n+    def get(): Int = {\n+      if (!isSet) {\n+        throw new IllegalStateException(\"Eval type is not set\")\n+      } else {\n+        evalType\n+      }\n+    }\n+  }\n+\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  /**\n+   * Check whether a PythonUDF expression can be evaluated in Python.\n+   *\n+   * If the lazy eval type is not set, this method checks for either Batched Python UDF and Scalar\n+   * Pandas UDF. If the lazy eval type is set, this method checks for the expression of the\n+   * specified eval type.\n+   *\n+   * This method will also set the lazy eval type to be the type of the first evaluable expression,\n+   * i.e., if lazy eval type is not set and we find a evaluable Python UDF expression, lazy eval\n+   * type will be set to the eval type of the expression.\n+   *\n+   */\n+  private def canEvaluateInPython(e: PythonUDF, lazyEvalType: LazyEvalType): Boolean = {"
  }, {
    "author": {
      "login": "BryanCutler"
    },
    "body": "I'm not sure I follow how this could get wrong results.  `firstEvalType.evalType = e.evalType` is called only if the eval type is not set or if it is set and it equals the current eval type.  In the latter case, it does assign the same value again, but that's fine.  If there is some case that this fails, can you add that as a test?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T20:42:28Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {\n+\n+    def isSet: Boolean = evalType >= 0\n+\n+    def set(evalType: Int): Unit = {\n+      if (isSet) {\n+        throw new IllegalStateException(\"Eval type has already been set\")\n+      } else {\n+        this.evalType = evalType\n+      }\n+    }\n+\n+    def get(): Int = {\n+      if (!isSet) {\n+        throw new IllegalStateException(\"Eval type is not set\")\n+      } else {\n+        evalType\n+      }\n+    }\n+  }\n+\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  /**\n+   * Check whether a PythonUDF expression can be evaluated in Python.\n+   *\n+   * If the lazy eval type is not set, this method checks for either Batched Python UDF and Scalar\n+   * Pandas UDF. If the lazy eval type is set, this method checks for the expression of the\n+   * specified eval type.\n+   *\n+   * This method will also set the lazy eval type to be the type of the first evaluable expression,\n+   * i.e., if lazy eval type is not set and we find a evaluable Python UDF expression, lazy eval\n+   * type will be set to the eval type of the expression.\n+   *\n+   */\n+  private def canEvaluateInPython(e: PythonUDF, lazyEvalType: LazyEvalType): Boolean = {"
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Bryan, I tried to apply your implementation and the simple test fails:\r\n\r\n```\r\n@udf('int')\r\ndef f1(x):\r\n    assert type(x) == int\r\n    return x + 1\r\n\r\n@pandas_udf('int')\r\ndef f2(x):\r\n    assert type(x) == pd.Series\r\n    return x + 10\r\n\r\ndf = self.spark.range(0, 1).toDF('v')\r\ndf_chained_1 = df.withColumn('f2_f1', f2(f1(df['v'])))\r\nexpected_chained_1 = df.withColumn('f2_f1', df['v'] + 11)\r\nself.assertEquals(expected_chained_1.collect(), df_chained_1.collect())\r\n```\r\n\r\nDo you mind trying this too? Hopefully I didn't do something silly here..",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T21:07:03Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {\n+\n+    def isSet: Boolean = evalType >= 0\n+\n+    def set(evalType: Int): Unit = {\n+      if (isSet) {\n+        throw new IllegalStateException(\"Eval type has already been set\")\n+      } else {\n+        this.evalType = evalType\n+      }\n+    }\n+\n+    def get(): Int = {\n+      if (!isSet) {\n+        throw new IllegalStateException(\"Eval type is not set\")\n+      } else {\n+        evalType\n+      }\n+    }\n+  }\n+\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  /**\n+   * Check whether a PythonUDF expression can be evaluated in Python.\n+   *\n+   * If the lazy eval type is not set, this method checks for either Batched Python UDF and Scalar\n+   * Pandas UDF. If the lazy eval type is set, this method checks for the expression of the\n+   * specified eval type.\n+   *\n+   * This method will also set the lazy eval type to be the type of the first evaluable expression,\n+   * i.e., if lazy eval type is not set and we find a evaluable Python UDF expression, lazy eval\n+   * type will be set to the eval type of the expression.\n+   *\n+   */\n+  private def canEvaluateInPython(e: PythonUDF, lazyEvalType: LazyEvalType): Boolean = {"
  }, {
    "author": {
      "login": "BryanCutler"
    },
    "body": "Is the above test part of sql/tests.py?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T21:26:37Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {\n+\n+    def isSet: Boolean = evalType >= 0\n+\n+    def set(evalType: Int): Unit = {\n+      if (isSet) {\n+        throw new IllegalStateException(\"Eval type has already been set\")\n+      } else {\n+        this.evalType = evalType\n+      }\n+    }\n+\n+    def get(): Int = {\n+      if (!isSet) {\n+        throw new IllegalStateException(\"Eval type is not set\")\n+      } else {\n+        evalType\n+      }\n+    }\n+  }\n+\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  /**\n+   * Check whether a PythonUDF expression can be evaluated in Python.\n+   *\n+   * If the lazy eval type is not set, this method checks for either Batched Python UDF and Scalar\n+   * Pandas UDF. If the lazy eval type is set, this method checks for the expression of the\n+   * specified eval type.\n+   *\n+   * This method will also set the lazy eval type to be the type of the first evaluable expression,\n+   * i.e., if lazy eval type is not set and we find a evaluable Python UDF expression, lazy eval\n+   * type will be set to the eval type of the expression.\n+   *\n+   */\n+  private def canEvaluateInPython(e: PythonUDF, lazyEvalType: LazyEvalType): Boolean = {"
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Yes it's in the most recent commit.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T21:30:25Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {\n+\n+    def isSet: Boolean = evalType >= 0\n+\n+    def set(evalType: Int): Unit = {\n+      if (isSet) {\n+        throw new IllegalStateException(\"Eval type has already been set\")\n+      } else {\n+        this.evalType = evalType\n+      }\n+    }\n+\n+    def get(): Int = {\n+      if (!isSet) {\n+        throw new IllegalStateException(\"Eval type is not set\")\n+      } else {\n+        evalType\n+      }\n+    }\n+  }\n+\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  /**\n+   * Check whether a PythonUDF expression can be evaluated in Python.\n+   *\n+   * If the lazy eval type is not set, this method checks for either Batched Python UDF and Scalar\n+   * Pandas UDF. If the lazy eval type is set, this method checks for the expression of the\n+   * specified eval type.\n+   *\n+   * This method will also set the lazy eval type to be the type of the first evaluable expression,\n+   * i.e., if lazy eval type is not set and we find a evaluable Python UDF expression, lazy eval\n+   * type will be set to the eval type of the expression.\n+   *\n+   */\n+  private def canEvaluateInPython(e: PythonUDF, lazyEvalType: LazyEvalType): Boolean = {"
  }, {
    "author": {
      "login": "BryanCutler"
    },
    "body": "Ok, I think I see the problem. Since there was a map over `plan.expressions`, a new `FirstEvalType` object was being created for each expression.  Changing this to the following corrected the failure:\r\n```\r\nval setEvalType = new FirstEvalType\r\nval udfs = plan.expressions.flatMap(collectEvaluableUDFs(_, setEvalType))\r\n```\r\nI updated my above code to this, does that look correct now?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T21:58:07Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {\n+\n+    def isSet: Boolean = evalType >= 0\n+\n+    def set(evalType: Int): Unit = {\n+      if (isSet) {\n+        throw new IllegalStateException(\"Eval type has already been set\")\n+      } else {\n+        this.evalType = evalType\n+      }\n+    }\n+\n+    def get(): Int = {\n+      if (!isSet) {\n+        throw new IllegalStateException(\"Eval type is not set\")\n+      } else {\n+        evalType\n+      }\n+    }\n+  }\n+\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  /**\n+   * Check whether a PythonUDF expression can be evaluated in Python.\n+   *\n+   * If the lazy eval type is not set, this method checks for either Batched Python UDF and Scalar\n+   * Pandas UDF. If the lazy eval type is set, this method checks for the expression of the\n+   * specified eval type.\n+   *\n+   * This method will also set the lazy eval type to be the type of the first evaluable expression,\n+   * i.e., if lazy eval type is not set and we find a evaluable Python UDF expression, lazy eval\n+   * type will be set to the eval type of the expression.\n+   *\n+   */\n+  private def canEvaluateInPython(e: PythonUDF, lazyEvalType: LazyEvalType): Boolean = {"
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "I applied you new code but the test I mentioned above still fails.\r\n\r\nI think the issue could be when visiting `f2(f1(col('v')))`, firstEvalType is set to Scalar Pandas first and isn't set to Batched SQL later so f1 is not extracted. It's possible that my code is still different than yours somehow.\r\n\r\nBut similar to https://github.com/apache/spark/pull/21650#issuecomment-407951457, I think the state machine of the firstEvalType here is fairly complicated (i.e., what is the expected state of the eval type holder before and after `canEvaluateInPython`and what's the invariants of the algo) with your suggested implementation and I found myself think pretty hard to prove the state machine is correct in all cases. If we want to go with this implementation, we need to carefully think about it and explain it in code...\r\n\r\nThe lazyEvalType implementation is better IMHO because the state machine is simpler - lazyEvalType is empty until we find the first evaluable UDF and the value doesn't change once it's set.\r\n\r\nThe first implementation (two pass, immutable state) is probably the simplest in terms of the mental complexity of the algo but is less efficient. \r\n\r\nI think I am ok with both immutable state or the lazy state. I think @HyukjinKwon prefers the immutable state one. @BryanCutler WDYT?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-26T13:10:08Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {\n+\n+    def isSet: Boolean = evalType >= 0\n+\n+    def set(evalType: Int): Unit = {\n+      if (isSet) {\n+        throw new IllegalStateException(\"Eval type has already been set\")\n+      } else {\n+        this.evalType = evalType\n+      }\n+    }\n+\n+    def get(): Int = {\n+      if (!isSet) {\n+        throw new IllegalStateException(\"Eval type is not set\")\n+      } else {\n+        evalType\n+      }\n+    }\n+  }\n+\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  /**\n+   * Check whether a PythonUDF expression can be evaluated in Python.\n+   *\n+   * If the lazy eval type is not set, this method checks for either Batched Python UDF and Scalar\n+   * Pandas UDF. If the lazy eval type is set, this method checks for the expression of the\n+   * specified eval type.\n+   *\n+   * This method will also set the lazy eval type to be the type of the first evaluable expression,\n+   * i.e., if lazy eval type is not set and we find a evaluable Python UDF expression, lazy eval\n+   * type will be set to the eval type of the expression.\n+   *\n+   */\n+  private def canEvaluateInPython(e: PythonUDF, lazyEvalType: LazyEvalType): Boolean = {"
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "hmmmmm looks messier then I thought .. previous one looks a bit better to me .. wdyt @BryanCutler ?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T15:05:50Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {"
  }, {
    "author": {
      "login": "BryanCutler"
    },
    "body": "I'm not too fond of the name `LazyEvalType`, makes it sound like something else.  Maybe `CurrentEvalType`?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T16:59:35Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {"
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Yeah the idea of the LazyEvalType is a container object that can be set once. Maybe the name LazyEvalType is confusing. I don't think CurrentEvalType is accurate either because the original idea is that we don't change the value once it's set. Maybe call it `EvalTypeHolder` and add docs to explain?",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T19:56:13Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {"
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "BryanCutler"
    },
    "body": "There are 2 paths for recursion here, which is probably not a good idea.  This method is much more complicated now and a little difficult to follow.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-25T16:56:56Z",
    "diffHunk": "@@ -94,36 +95,94 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class LazyEvalType(var evalType: Int = -1) {\n+\n+    def isSet: Boolean = evalType >= 0\n+\n+    def set(evalType: Int): Unit = {\n+      if (isSet) {\n+        throw new IllegalStateException(\"Eval type has already been set\")\n+      } else {\n+        this.evalType = evalType\n+      }\n+    }\n+\n+    def get(): Int = {\n+      if (!isSet) {\n+        throw new IllegalStateException(\"Eval type is not set\")\n+      } else {\n+        evalType\n+      }\n+    }\n+  }\n+\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n-  private def canEvaluateInPython(e: PythonUDF): Boolean = {\n-    e.children match {\n-      // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n-      // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+  /**\n+   * Check whether a PythonUDF expression can be evaluated in Python.\n+   *\n+   * If the lazy eval type is not set, this method checks for either Batched Python UDF and Scalar\n+   * Pandas UDF. If the lazy eval type is set, this method checks for the expression of the\n+   * specified eval type.\n+   *\n+   * This method will also set the lazy eval type to be the type of the first evaluable expression,\n+   * i.e., if lazy eval type is not set and we find a evaluable Python UDF expression, lazy eval\n+   * type will be set to the eval type of the expression.\n+   *\n+   */\n+  private def canEvaluateInPython(e: PythonUDF, lazyEvalType: LazyEvalType): Boolean = {\n+    if (!lazyEvalType.isSet) {\n+      e.children match {\n+        // single PythonUDF child could be chained and evaluated in Python if eval type is the same\n+        case Seq(u: PythonUDF) =>\n+          // Need to recheck the eval type because lazy eval type will be set if child Python UDF is\n+          // evaluable\n+          canEvaluateInPython(u, lazyEvalType) && lazyEvalType.get == e.evalType\n+        // Python UDF can't be evaluated directly in JVM\n+        case children => if (!children.exists(hasScalarPythonUDF)) {\n+          // We found the first evaluable expression, set lazy eval type to its eval type.\n+          lazyEvalType.set(e.evalType)\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+    } else {\n+      if (e.evalType != lazyEvalType.get) {\n+        false\n+      } else {\n+        e.children match {\n+          case Seq(u: PythonUDF) => canEvaluateInPython(u, lazyEvalType)"
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "How about this:\r\n\r\n```scala\r\n  private type EvalType = Int\r\n  private type EvalTypeChecker = EvalType => Boolean\r\n\r\n  private def collectEvaluableUDFsFromExpressions(expressions: Seq[Expression]): Seq[PythonUDF] = {\r\n    // Eval type checker is set in the middle of checking because once it's found,\r\n    // the same eval type should be checked .. blah blah\r\n    var evalChecker: Option[EvalTypeChecker] = None\r\n\r\n    def collectEvaluableUDFs(expr: Expression): Seq[PythonUDF] = expr match {\r\n      case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf)\r\n        && evalChecker.isEmpty =>\r\n        evalChecker = Some((otherEvalType: EvalType) => otherEvalType == udf.evalType)\r\n        collectEvaluableUDFs(expr)\r\n      case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf)\r\n        && evalChecker.get(udf.evalType) =>\r\n        Seq(udf)\r\n      case e => e.children.flatMap(collectEvaluableUDFs)\r\n    }\r\n\r\n    expressions.flatMap(collectEvaluableUDFs)\r\n  }\r\n\r\n  def apply(plan: SparkPlan): SparkPlan = plan transformUp {\r\n    case plan: SparkPlan => extract(plan)\r\n  }\r\n\r\n  /**\r\n   * Extract all the PythonUDFs from the current operator and evaluate them before the operator.\r\n   */\r\n  private def extract(plan: SparkPlan): SparkPlan = {\r\n    val udfs = collectEvaluableUDFsFromExpressions(plan.expressions)\r\n```",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-27T15:52:25Z",
    "diffHunk": "@@ -94,36 +95,61 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class EvalTypeHolder(private var evalType: Int = -1) {"
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "I see... You uses a var and nested function definition and var to remove the need of a holder object. \r\n\r\nIMHO I usually find nested function definition and function that refers to variable outside its definition scope hard to read, but it could be my personal preference. \r\n\r\nAnother thing I like about the current impl the is `EvalTypeHolder` class ensures its value is ever changed once it's set so I think that's more robust.\r\n\r\nThat being said, I am ok with your suggestions too if you insist or @BryanCutler also prefers it.\r\n\r\n",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-27T18:21:11Z",
    "diffHunk": "@@ -94,36 +95,61 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class EvalTypeHolder(private var evalType: Int = -1) {"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "yup. I do avoid nested functions but I found here is where is's needed. If it's clear when it's set and unset within a function, I think the shorter one is fine.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-27T18:39:29Z",
    "diffHunk": "@@ -94,36 +95,61 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class EvalTypeHolder(private var evalType: Int = -1) {"
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Ok, I will update the code then.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-27T18:45:29Z",
    "diffHunk": "@@ -94,36 +95,61 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private case class EvalTypeHolder(private var evalType: Int = -1) {"
  }],
  "prId": 21650
}, {
  "comments": [{
    "author": {
      "login": "icexelloss"
    },
    "body": "@HyukjinKwon In your code this line is `collectEvaluableUDFs(expr)`. I think we should just return `Seq(udf)` to avoid checking the expression twice.",
    "commit": "f3a45a576b6a186f3694e6bd0f22a8198a9d19a2",
    "createdAt": "2018-07-27T19:07:59Z",
    "diffHunk": "@@ -94,36 +95,52 @@ object ExtractPythonUDFFromAggregate extends Rule[LogicalPlan] {\n  */\n object ExtractPythonUDFs extends Rule[SparkPlan] with PredicateHelper {\n \n-  private def hasPythonUDF(e: Expression): Boolean = {\n+  private type EvalType = Int\n+  private type EvalTypeChecker = EvalType => Boolean\n+\n+  private def hasScalarPythonUDF(e: Expression): Boolean = {\n     e.find(PythonUDF.isScalarPythonUDF).isDefined\n   }\n \n   private def canEvaluateInPython(e: PythonUDF): Boolean = {\n     e.children match {\n       // single PythonUDF child could be chained and evaluated in Python\n-      case Seq(u: PythonUDF) => canEvaluateInPython(u)\n+      case Seq(u: PythonUDF) => e.evalType == u.evalType && canEvaluateInPython(u)\n       // Python UDF can't be evaluated directly in JVM\n-      case children => !children.exists(hasPythonUDF)\n+      case children => !children.exists(hasScalarPythonUDF)\n     }\n   }\n \n-  private def collectEvaluatableUDF(expr: Expression): Seq[PythonUDF] = expr match {\n-    case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf) => Seq(udf)\n-    case e => e.children.flatMap(collectEvaluatableUDF)\n+  private def collectEvaluableUDFsFromExpressions(expressions: Seq[Expression]): Seq[PythonUDF] = {\n+    // Eval type checker is set once when we find the first evaluable UDF and its value\n+    // shouldn't change later.\n+    // Used to check if subsequent UDFs are of the same type as the first UDF. (since we can only\n+    // extract UDFs of the same eval type)\n+    var evalTypeChecker: Option[EvalTypeChecker] = None\n+\n+    def collectEvaluableUDFs(expr: Expression): Seq[PythonUDF] = expr match {\n+      case udf: PythonUDF if PythonUDF.isScalarPythonUDF(udf) && canEvaluateInPython(udf)\n+        && evalTypeChecker.isEmpty =>\n+        evalTypeChecker = Some((otherEvalType: EvalType) => otherEvalType == udf.evalType)\n+        Seq(udf)",
    "line": 45
  }],
  "prId": 21650
}]