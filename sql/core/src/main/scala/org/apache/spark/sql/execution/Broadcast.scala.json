[{
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "Since we do include this in generated code of BroadcastHashJoin, I think it's better to not implement CodegenSupport, then we don't need the special case in CollapseCodegenStages \n",
    "commit": "c8c175e91ad2896573a4d6efab9ee13d7f28103c",
    "createdAt": "2016-02-08T18:42:52Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.concurrent._\n+import scala.concurrent.duration._\n+\n+import org.apache.spark.broadcast\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext\n+import org.apache.spark.sql.execution.metric.SQLMetrics\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A broadcast collects, transforms and finally broadcasts the result of a transformed SparkPlan.\n+ *\n+ * TODO whole stage codegen.\n+ */\n+case class Broadcast(\n+    f: Iterable[InternalRow] => Any,\n+    child: SparkPlan)\n+  extends UnaryNode with CodegenSupport {"
  }],
  "prId": 11083
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Throw an UnsupportedOperationException?\n",
    "commit": "c8c175e91ad2896573a4d6efab9ee13d7f28103c",
    "createdAt": "2016-02-16T06:09:30Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.concurrent._\n+import scala.concurrent.duration._\n+\n+import org.apache.spark.broadcast\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.plans.physical.BroadcastMode\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A broadcast collects, transforms and finally broadcasts the result of a transformed SparkPlan.\n+ */\n+case class Broadcast(\n+    mode: BroadcastMode,\n+    child: SparkPlan) extends UnaryNode {\n+\n+  override def output: Seq[Attribute] = child.output\n+\n+  val timeout: Duration = {\n+    val timeoutValue = sqlContext.conf.broadcastTimeout\n+    if (timeoutValue < 0) {\n+      Duration.Inf\n+    } else {\n+      timeoutValue.seconds\n+    }\n+  }\n+\n+  @transient\n+  private lazy val relationFuture: Future[broadcast.Broadcast[Any]] = {\n+    // broadcastFuture is used in \"doExecute\". Therefore we can get the execution id correctly here.\n+    val executionId = sparkContext.getLocalProperty(SQLExecution.EXECUTION_ID_KEY)\n+    Future {\n+      // This will run in another thread. Set the execution id so that we can connect these jobs\n+      // with the correct execution.\n+      SQLExecution.withExecutionId(sparkContext, executionId) {\n+        // Note that we use .execute().collect() because we don't want to convert data to Scala\n+        // types\n+        val input: Array[InternalRow] = child.execute().map { row =>\n+          row.copy()\n+        }.collect()\n+\n+        // Construct and broadcast the relation.\n+        sparkContext.broadcast(mode(input))\n+      }\n+    }(Broadcast.executionContext)\n+  }\n+\n+  override protected def doPrepare(): Unit = {\n+    // Materialize the future.\n+    relationFuture\n+  }\n+\n+  override protected def doExecute(): RDD[InternalRow] = {\n+    child.execute() // TODO throw an Exception here?"
  }],
  "prId": 11083
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Do we need to merge this class with Exchange?\n",
    "commit": "c8c175e91ad2896573a4d6efab9ee13d7f28103c",
    "createdAt": "2016-02-16T06:18:58Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.concurrent._\n+import scala.concurrent.duration._\n+\n+import org.apache.spark.broadcast\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.plans.physical.BroadcastMode\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A broadcast collects, transforms and finally broadcasts the result of a transformed SparkPlan.\n+ */\n+case class Broadcast("
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "You want to add this to `Exchange.scala`?\n",
    "commit": "c8c175e91ad2896573a4d6efab9ee13d7f28103c",
    "createdAt": "2016-02-16T20:46:19Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.concurrent._\n+import scala.concurrent.duration._\n+\n+import org.apache.spark.broadcast\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.plans.physical.BroadcastMode\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A broadcast collects, transforms and finally broadcasts the result of a transformed SparkPlan.\n+ */\n+case class Broadcast("
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "@yhuai It took a while for your question to sink in. We _could_ integrate this with Exchange. It makes sense because both operators are distributing data and their structure actually is quite similar. I am not huge fan of this because we will end up conflating concerns by implementing two naturally separate code and data paths in one operator. \n\nLemme know what you think.\n",
    "commit": "c8c175e91ad2896573a4d6efab9ee13d7f28103c",
    "createdAt": "2016-02-16T21:59:40Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.concurrent._\n+import scala.concurrent.duration._\n+\n+import org.apache.spark.broadcast\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.plans.physical.BroadcastMode\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A broadcast collects, transforms and finally broadcasts the result of a transformed SparkPlan.\n+ */\n+case class Broadcast("
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "It is a logical exchange, but probably deserve two different physical operator.\n",
    "commit": "c8c175e91ad2896573a4d6efab9ee13d7f28103c",
    "createdAt": "2016-02-16T22:16:56Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.concurrent._\n+import scala.concurrent.duration._\n+\n+import org.apache.spark.broadcast\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.plans.physical.BroadcastMode\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A broadcast collects, transforms and finally broadcasts the result of a transformed SparkPlan.\n+ */\n+case class Broadcast("
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "One way is ... rename the current exchange ShuffleExchange, and rename Broadcast BroadcastExchange.\n",
    "commit": "c8c175e91ad2896573a4d6efab9ee13d7f28103c",
    "createdAt": "2016-02-16T22:17:24Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.concurrent._\n+import scala.concurrent.duration._\n+\n+import org.apache.spark.broadcast\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.plans.physical.BroadcastMode\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A broadcast collects, transforms and finally broadcasts the result of a transformed SparkPlan.\n+ */\n+case class Broadcast("
  }],
  "prId": 11083
}]