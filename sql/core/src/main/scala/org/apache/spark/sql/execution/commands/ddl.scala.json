[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "`CreateDatabase`\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-03-02T21:24:13Z",
    "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, Row, SQLContext}\n+import org.apache.spark.sql.catalyst.{CatalystTypeConverters, InternalRow, TableIdentifier}\n+import org.apache.spark.sql.catalyst.errors.TreeNodeException\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution._\n+import org.apache.spark.sql.execution.datasources.BucketSpec\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+abstract class NativeDDLCommands(val sql: String) extends RunnableCommand {\n+  override def run(sqlContext: SQLContext): Seq[Row] = {\n+    sqlContext.catalog.runNativeCommand(sql)\n+  }\n+\n+  override val output: Seq[Attribute] =\n+    Seq(AttributeReference(\"result\", StringType, nullable = false)())\n+}\n+\n+case class CreateDataBase(",
    "line": 44
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "I see, it's because we want the `NativeDDLCommands` to be in the sql package, where it shouldn't know anything about Hive. In the future these commands will no longer be passed to Hive directly as a string so they shouldn't be \"native\" anymore. For now, I would create a temporary method in `SQLContext`:\n\n```\n// In SQLContext.scala\n// TODO: remove this once we call specific operations in the catalog instead\nprotected[sql] def runDDLCommand(text: String): Seq[Row] = {\n  throw new UnsupportedOperationException\n}\n\n// In HiveContext.scala\nprotected[sql] override def runDDLCommand(text: String): Seq[Row] = {\n  runHiveSql(text).map(Row(_))\n}\n```\n\neven though it's temporary I still think it's cleaner than doing it in the catalog.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-03-02T21:37:34Z",
    "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, Row, SQLContext}\n+import org.apache.spark.sql.catalyst.{CatalystTypeConverters, InternalRow, TableIdentifier}\n+import org.apache.spark.sql.catalyst.errors.TreeNodeException\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution._\n+import org.apache.spark.sql.execution.datasources.BucketSpec\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+abstract class NativeDDLCommands(val sql: String) extends RunnableCommand {\n+  override def run(sqlContext: SQLContext): Seq[Row] = {\n+    sqlContext.catalog.runNativeCommand(sql)",
    "line": 37
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "by the way there are a lot of unused imports in this file and other files. Please take the time to remove the ones that are not used.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-03-02T21:38:43Z",
    "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, Row, SQLContext}\n+import org.apache.spark.sql.catalyst.{CatalystTypeConverters, InternalRow, TableIdentifier}\n+import org.apache.spark.sql.catalyst.errors.TreeNodeException",
    "line": 26
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "by the way, this division of commands into 2 files is kind of arbitrary; the things in `commands.scala` are _also_ DDLs.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-03-02T21:44:00Z",
    "diffHunk": "@@ -0,0 +1,189 @@\n+/*",
    "line": 1
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "What do you mean by `asName`? Maybe this should be called `alias`\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-03-03T01:00:06Z",
    "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, Row, SQLContext}\n+import org.apache.spark.sql.catalyst.{CatalystTypeConverters, InternalRow, TableIdentifier}\n+import org.apache.spark.sql.catalyst.errors.TreeNodeException\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution._\n+import org.apache.spark.sql.execution.datasources.BucketSpec\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+abstract class NativeDDLCommands(val sql: String) extends RunnableCommand {\n+  override def run(sqlContext: SQLContext): Seq[Row] = {\n+    sqlContext.catalog.runNativeCommand(sql)\n+  }\n+\n+  override val output: Seq[Attribute] =\n+    Seq(AttributeReference(\"result\", StringType, nullable = false)())\n+}\n+\n+case class CreateDataBase(\n+    databaseName: String,\n+    allowExisting: Boolean,\n+    path: Option[String],\n+    comment: Option[String],\n+    props: Map[String, String])(sql: String) extends NativeDDLCommands(sql) with Logging\n+\n+case class CreateFunction(\n+    functionName: String,\n+    asName: String,",
    "line": 53
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "iiuc, you need two things. one is the fully qualified name for source code of the function, and the other is the name of the function.\n\nthe current naming is confusing.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-03-03T01:02:28Z",
    "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, Row, SQLContext}\n+import org.apache.spark.sql.catalyst.{CatalystTypeConverters, InternalRow, TableIdentifier}\n+import org.apache.spark.sql.catalyst.errors.TreeNodeException\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution._\n+import org.apache.spark.sql.execution.datasources.BucketSpec\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types._\n+\n+abstract class NativeDDLCommands(val sql: String) extends RunnableCommand {\n+  override def run(sqlContext: SQLContext): Seq[Row] = {\n+    sqlContext.catalog.runNativeCommand(sql)\n+  }\n+\n+  override val output: Seq[Attribute] =\n+    Seq(AttributeReference(\"result\", StringType, nullable = false)())\n+}\n+\n+case class CreateDataBase(\n+    databaseName: String,\n+    allowExisting: Boolean,\n+    path: Option[String],\n+    comment: Option[String],\n+    props: Map[String, String])(sql: String) extends NativeDDLCommands(sql) with Logging\n+\n+case class CreateFunction(\n+    functionName: String,\n+    asName: String,",
    "line": 53
  }],
  "prId": 11048
}]