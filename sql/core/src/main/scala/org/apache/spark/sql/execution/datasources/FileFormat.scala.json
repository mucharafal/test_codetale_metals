[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Hm, shouldn't we better whitelist them rather then blacklist?",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-06-29T07:28:18Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = dataType match {"
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "Blacklist is easier.\r\nWith whitelist , we will have to validate \r\n``` \r\nBooleanType | ByteType | ShortType | IntegerType | LongType | FloatType | DoubleType |\r\n          StringType | BinaryType | DateType | TimestampType | DecimalType\r\n```\r\nOf course we can have a default function to process these. But if we add a new data source which didn't support all of them, the implementation will be verbose.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-06-29T07:48:42Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = dataType match {"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Might be easier to write but it doesn't consider if we happened to have some more types on the other hand. It should better be explicit on what we support on the other hand.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-06-29T08:53:24Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = dataType match {"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I wrote CSV's with whitelisting before per @hvanhovell's comment long time ago. I was (am still) okay either way but might be good to leave a cc for him.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-06-29T08:54:58Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = dataType match {"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "I like the whilelist, too. As @HyukjinKwon said, if someone implements a new type, the blacklist pass through it...",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-02T08:23:41Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = dataType match {"
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "Whitelist for all file formats is behavior change. There are external file sources like https://github.com/databricks/spark-avro , which we probably have to update the code to make it compatible.\r\n\r\nCurrently exceptions are thrown in `buildReader` / `buildReaderWithPartitionValues`/ `prepareWrite` for unsupported types.  New types are handled.\r\n\r\nSo overall I prefer blacklist.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-02T13:21:51Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = dataType match {"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I meant the `case`s in the match in each implementation within Spark. I didn't mean about the semantic about the API itself. ",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-02T14:14:29Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = dataType match {"
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "@HyukjinKwon Sorry I don't understand. Do you mean the default case is not supported?\r\n ```\r\ncase _  =>  false\r\n```\r\nBut how to make all the external formats work?",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-02T14:38:51Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = dataType match {"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "OK. I meant, leaving the default case `true`\r\n\r\n```scala\r\ndef supportDataType(...): Boolean = dataType match {\r\n  case _ => true\r\n}\r\n```\r\n\r\nand whitelist each type within each implementation, for example, in `CSVFileFormat.scala`\r\n\r\n```scala\r\ndef supportDataType(...) ...\r\n    case _: StringType | ... => true\r\n    case _ => false\r\n```",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-02T14:50:25Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = dataType match {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "blacklist is easier, but whitelist is safer.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-03T06:28:21Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = dataType match {"
  }],
  "prId": 21667
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Also, do we really need this API? All what it does it is just to check the type and throw an exception.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-02T14:27:08Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = dataType match {"
  }],
  "prId": 21667
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "FYI, `CalendarIntervalType` isn't completely public yet .. cc @cloud-fan.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-02T15:00:20Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path."
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "yea, it's not by default, we can't write out interval type. This check is in `DataSource.planForWriting`",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-03T06:27:06Z",
    "diffHunk": "@@ -152,6 +152,16 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   *\n+   * By default all data types are supported except [[CalendarIntervalType]] in write path."
  }],
  "prId": 21667
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "it's better to return boolean here, and let the caller side to throw exception, so that we can unify the error message.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-03T15:57:53Z",
    "diffHunk": "@@ -152,6 +152,12 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Validate the given [[DataType]] in read/write path for this file format.\n+   * If the [[DataType]] is not supported, an exception will be thrown.\n+   * By default all data types are supported.\n+   */\n+  def validateDataType(dataType: DataType, isReadPath: Boolean): Unit = {}"
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "Yes, that was what I did in first commit.  If the unsupported type is inside struct/array, then the error message is not accurate as the current way.\r\nI am OK with revert to return Boolean though.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-04T03:23:07Z",
    "diffHunk": "@@ -152,6 +152,12 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Validate the given [[DataType]] in read/write path for this file format.\n+   * If the [[DataType]] is not supported, an exception will be thrown.\n+   * By default all data types are supported.\n+   */\n+  def validateDataType(dataType: DataType, isReadPath: Boolean): Unit = {}"
  }],
  "prId": 21667
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "who does not overwrite it?",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-05T05:29:14Z",
    "diffHunk": "@@ -152,6 +152,11 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   * By default all data types are supported.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = true",
    "line": 26
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "`HiveFileFormat`. Currently I don't know Hive well. If someone can override it for `HiveFileFormat`, please create a follow up PR.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-05T07:32:33Z",
    "diffHunk": "@@ -152,6 +152,11 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   * By default all data types are supported.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = true",
    "line": 26
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "then why not remove this default implementation and create `HiveFileFormat#supportDataType` to return true?",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-05T10:22:48Z",
    "diffHunk": "@@ -152,6 +152,11 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   * By default all data types are supported.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = true",
    "line": 26
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "Then we also need to update `LibSVMFileFormat`, and several file format in unit test. I really prefer to have a default behavior here, as `FileFormat` can still work without the new method.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-06T09:04:35Z",
    "diffHunk": "@@ -152,6 +152,11 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   * By default all data types are supported.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = true",
    "line": 26
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "makes sense",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-06T10:41:22Z",
    "diffHunk": "@@ -152,6 +152,11 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   * By default all data types are supported.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = true",
    "line": 26
  }],
  "prId": 21667
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Technically this is an internal API but we better concern about the compatibility particularly here in practice when it's possible. I think I already see we are concerned about Avro, right? I still doubt if it's a good idea to expose this in this trait.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-06T11:08:00Z",
    "diffHunk": "@@ -152,6 +152,11 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   * By default all data types are supported.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = true",
    "line": 26
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "This is the only way to allow avro to define its supported types. BTW the default true value here is good for compatibility: if a file source doesn't know this API, it doesn't need to implement it and the behavior is unchanged, which is, no check applied.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-06T11:46:39Z",
    "diffHunk": "@@ -152,6 +152,11 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   * By default all data types are supported.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = true",
    "line": 26
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I meant to say it's not free to remove or change the signature later once we happen to add it. Do we plan to refactor or remove this `FileFormat` out in the near future? If so I am okay.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-06T11:50:39Z",
    "diffHunk": "@@ -152,6 +152,11 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   * By default all data types are supported.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = true",
    "line": 26
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "the entire FileFormat will be migrated to data source v2 in the future. The FileFormat will be still there for backward compatibility, and I don't think we will update it frequently.",
    "commit": "13de60ec3916b8396e6fe04e755eeb7d70c54b3a",
    "createdAt": "2018-07-06T12:39:47Z",
    "diffHunk": "@@ -152,6 +152,11 @@ trait FileFormat {\n     }\n   }\n \n+  /**\n+   * Returns whether this format supports the given [[DataType]] in read/write path.\n+   * By default all data types are supported.\n+   */\n+  def supportDataType(dataType: DataType, isReadPath: Boolean): Boolean = true",
    "line": 26
  }],
  "prId": 21667
}]