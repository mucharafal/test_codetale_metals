[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "IIRC, @viirya also has a PR for vectorized orc reader. In that PR, we simply wrap the orc column batch to expose spark column batch interfaces, instead of writing orc column batch to spark column batch. I think that approach is more efficient.",
    "commit": "85ef73134b7b7450e0689e138339433a30b92dea",
    "createdAt": "2017-05-10T03:02:19Z",
    "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.orc\n+\n+import org.apache.hadoop.mapreduce.{InputSplit, RecordReader, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.input.FileSplit\n+import org.apache.orc._\n+import org.apache.orc.mapred.OrcInputFormat\n+import org.apache.orc.storage.ql.exec.vector._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.memory.MemoryMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.parser.CatalystSqlParser\n+import org.apache.spark.sql.execution.vectorized.{ColumnarBatch, ColumnVectorUtils}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * To support vectorization in WholeStageCodeGen, this reader returns ColumnarBatch.\n+ */\n+private[orc] class OrcColumnarBatchReader extends RecordReader[Void, ColumnarBatch] with Logging {\n+  import OrcColumnarBatchReader._\n+\n+  /**\n+   * ORC File Reader.\n+   */\n+  private var reader: Reader = _\n+\n+  /**\n+   * ORC Data Schema.\n+   */\n+  private var schema: TypeDescription = _\n+\n+  /**\n+   * Vectorized Row Batch.\n+   */\n+  private var batch: VectorizedRowBatch = _\n+\n+  /**\n+   * Record reader from row batch.\n+   */\n+  private var rows: org.apache.orc.RecordReader = _\n+\n+  /**\n+   * Spark Schema.\n+   */\n+  private var sparkSchema: StructType = _\n+\n+  /**\n+   * Required Schema.\n+   */\n+  private var requiredSchema: StructType = _\n+\n+  /**\n+   * Partition Column.\n+   */\n+  private var partitionColumns: StructType = _\n+\n+  private var useIndex: Boolean = false\n+\n+  /**\n+   * Full Schema: requiredSchema + partition schema.\n+   */\n+  private var fullSchema: StructType = _\n+\n+  /**\n+   * ColumnarBatch for vectorized execution by whole-stage codegen.\n+   */\n+  private var columnarBatch: ColumnarBatch = _",
    "line": 85
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Oh, thank you for the comment. It sounds efficient. I'll take a look.",
    "commit": "85ef73134b7b7450e0689e138339433a30b92dea",
    "createdAt": "2017-05-10T03:05:38Z",
    "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.orc\n+\n+import org.apache.hadoop.mapreduce.{InputSplit, RecordReader, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.input.FileSplit\n+import org.apache.orc._\n+import org.apache.orc.mapred.OrcInputFormat\n+import org.apache.orc.storage.ql.exec.vector._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.memory.MemoryMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.parser.CatalystSqlParser\n+import org.apache.spark.sql.execution.vectorized.{ColumnarBatch, ColumnVectorUtils}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * To support vectorization in WholeStageCodeGen, this reader returns ColumnarBatch.\n+ */\n+private[orc] class OrcColumnarBatchReader extends RecordReader[Void, ColumnarBatch] with Logging {\n+  import OrcColumnarBatchReader._\n+\n+  /**\n+   * ORC File Reader.\n+   */\n+  private var reader: Reader = _\n+\n+  /**\n+   * ORC Data Schema.\n+   */\n+  private var schema: TypeDescription = _\n+\n+  /**\n+   * Vectorized Row Batch.\n+   */\n+  private var batch: VectorizedRowBatch = _\n+\n+  /**\n+   * Record reader from row batch.\n+   */\n+  private var rows: org.apache.orc.RecordReader = _\n+\n+  /**\n+   * Spark Schema.\n+   */\n+  private var sparkSchema: StructType = _\n+\n+  /**\n+   * Required Schema.\n+   */\n+  private var requiredSchema: StructType = _\n+\n+  /**\n+   * Partition Column.\n+   */\n+  private var partitionColumns: StructType = _\n+\n+  private var useIndex: Boolean = false\n+\n+  /**\n+   * Full Schema: requiredSchema + partition schema.\n+   */\n+  private var fullSchema: StructType = _\n+\n+  /**\n+   * ColumnarBatch for vectorized execution by whole-stage codegen.\n+   */\n+  private var columnarBatch: ColumnarBatch = _",
    "line": 85
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "More specially, we wrap Hive's `ColumnVector` in a batch to expose Spark's `ColumnVector` for constructing Spark's `ColumnarBatch`. So we don't need to move data from one vector format to another vector format.\r\n",
    "commit": "85ef73134b7b7450e0689e138339433a30b92dea",
    "createdAt": "2017-05-10T03:11:42Z",
    "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.orc\n+\n+import org.apache.hadoop.mapreduce.{InputSplit, RecordReader, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.input.FileSplit\n+import org.apache.orc._\n+import org.apache.orc.mapred.OrcInputFormat\n+import org.apache.orc.storage.ql.exec.vector._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.memory.MemoryMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.parser.CatalystSqlParser\n+import org.apache.spark.sql.execution.vectorized.{ColumnarBatch, ColumnVectorUtils}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * To support vectorization in WholeStageCodeGen, this reader returns ColumnarBatch.\n+ */\n+private[orc] class OrcColumnarBatchReader extends RecordReader[Void, ColumnarBatch] with Logging {\n+  import OrcColumnarBatchReader._\n+\n+  /**\n+   * ORC File Reader.\n+   */\n+  private var reader: Reader = _\n+\n+  /**\n+   * ORC Data Schema.\n+   */\n+  private var schema: TypeDescription = _\n+\n+  /**\n+   * Vectorized Row Batch.\n+   */\n+  private var batch: VectorizedRowBatch = _\n+\n+  /**\n+   * Record reader from row batch.\n+   */\n+  private var rows: org.apache.orc.RecordReader = _\n+\n+  /**\n+   * Spark Schema.\n+   */\n+  private var sparkSchema: StructType = _\n+\n+  /**\n+   * Required Schema.\n+   */\n+  private var requiredSchema: StructType = _\n+\n+  /**\n+   * Partition Column.\n+   */\n+  private var partitionColumns: StructType = _\n+\n+  private var useIndex: Boolean = false\n+\n+  /**\n+   * Full Schema: requiredSchema + partition schema.\n+   */\n+  private var fullSchema: StructType = _\n+\n+  /**\n+   * ColumnarBatch for vectorized execution by whole-stage codegen.\n+   */\n+  private var columnarBatch: ColumnarBatch = _",
    "line": 85
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Btw, the PR is at #13775.",
    "commit": "85ef73134b7b7450e0689e138339433a30b92dea",
    "createdAt": "2017-05-10T03:13:59Z",
    "diffHunk": "@@ -0,0 +1,407 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.orc\n+\n+import org.apache.hadoop.mapreduce.{InputSplit, RecordReader, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.input.FileSplit\n+import org.apache.orc._\n+import org.apache.orc.mapred.OrcInputFormat\n+import org.apache.orc.storage.ql.exec.vector._\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.memory.MemoryMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.parser.CatalystSqlParser\n+import org.apache.spark.sql.execution.vectorized.{ColumnarBatch, ColumnVectorUtils}\n+import org.apache.spark.sql.types._\n+\n+\n+/**\n+ * To support vectorization in WholeStageCodeGen, this reader returns ColumnarBatch.\n+ */\n+private[orc] class OrcColumnarBatchReader extends RecordReader[Void, ColumnarBatch] with Logging {\n+  import OrcColumnarBatchReader._\n+\n+  /**\n+   * ORC File Reader.\n+   */\n+  private var reader: Reader = _\n+\n+  /**\n+   * ORC Data Schema.\n+   */\n+  private var schema: TypeDescription = _\n+\n+  /**\n+   * Vectorized Row Batch.\n+   */\n+  private var batch: VectorizedRowBatch = _\n+\n+  /**\n+   * Record reader from row batch.\n+   */\n+  private var rows: org.apache.orc.RecordReader = _\n+\n+  /**\n+   * Spark Schema.\n+   */\n+  private var sparkSchema: StructType = _\n+\n+  /**\n+   * Required Schema.\n+   */\n+  private var requiredSchema: StructType = _\n+\n+  /**\n+   * Partition Column.\n+   */\n+  private var partitionColumns: StructType = _\n+\n+  private var useIndex: Boolean = false\n+\n+  /**\n+   * Full Schema: requiredSchema + partition schema.\n+   */\n+  private var fullSchema: StructType = _\n+\n+  /**\n+   * ColumnarBatch for vectorized execution by whole-stage codegen.\n+   */\n+  private var columnarBatch: ColumnarBatch = _",
    "line": 85
  }],
  "prId": 17924
}]