[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "so we never auto update column stats?",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-26T05:18:44Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.command\n+\n+import java.net.URI\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.fs.{FileSystem, Path}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.catalog.{CatalogStatistics, CatalogTable}\n+import org.apache.spark.sql.internal.SessionState\n+\n+\n+object CommandUtils extends Logging {\n+\n+  /**\n+   * Update statistics (currently only sizeInBytes) after changing data by commands.\n+   */\n+  def updateTableStats(\n+      sparkSession: SparkSession,\n+      table: CatalogTable,\n+      newTableSize: Option[BigInt] = None,\n+      newRowCount: Option[BigInt] = None): Unit = {\n+    if (sparkSession.sessionState.conf.autoStatsUpdate && table.stats.nonEmpty) {\n+      val catalog = sparkSession.sessionState.catalog\n+      val newTable = catalog.getTableMetadata(table.identifier)\n+      val newSize = newTableSize.getOrElse(\n+        CommandUtils.calculateTotalSize(sparkSession.sessionState, newTable))\n+      catalog.alterTableStats(table.identifier,\n+        CatalogStatistics(sizeInBytes = newSize, rowCount = newRowCount))"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "since we are protected by a flag, can we be more aggressive and auto update all stats?",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-26T05:39:33Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.command\n+\n+import java.net.URI\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.fs.{FileSystem, Path}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.catalog.{CatalogStatistics, CatalogTable}\n+import org.apache.spark.sql.internal.SessionState\n+\n+\n+object CommandUtils extends Logging {\n+\n+  /**\n+   * Update statistics (currently only sizeInBytes) after changing data by commands.\n+   */\n+  def updateTableStats(\n+      sparkSession: SparkSession,\n+      table: CatalogTable,\n+      newTableSize: Option[BigInt] = None,\n+      newRowCount: Option[BigInt] = None): Unit = {\n+    if (sparkSession.sessionState.conf.autoStatsUpdate && table.stats.nonEmpty) {\n+      val catalog = sparkSession.sessionState.catalog\n+      val newTable = catalog.getTableMetadata(table.identifier)\n+      val newSize = newTableSize.getOrElse(\n+        CommandUtils.calculateTotalSize(sparkSession.sessionState, newTable))\n+      catalog.alterTableStats(table.identifier,\n+        CatalogStatistics(sizeInBytes = newSize, rowCount = newRowCount))"
  }, {
    "author": {
      "login": "wzhfy"
    },
    "body": "In my initial design, I planned to update size by default and update other stats based on a flag. Auto update all stats seems too aggressive to me with one flag...",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-26T06:38:06Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.command\n+\n+import java.net.URI\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.fs.{FileSystem, Path}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.catalog.{CatalogStatistics, CatalogTable}\n+import org.apache.spark.sql.internal.SessionState\n+\n+\n+object CommandUtils extends Logging {\n+\n+  /**\n+   * Update statistics (currently only sizeInBytes) after changing data by commands.\n+   */\n+  def updateTableStats(\n+      sparkSession: SparkSession,\n+      table: CatalogTable,\n+      newTableSize: Option[BigInt] = None,\n+      newRowCount: Option[BigInt] = None): Unit = {\n+    if (sparkSession.sessionState.conf.autoStatsUpdate && table.stats.nonEmpty) {\n+      val catalog = sparkSession.sessionState.catalog\n+      val newTable = catalog.getTableMetadata(table.identifier)\n+      val newSize = newTableSize.getOrElse(\n+        CommandUtils.calculateTotalSize(sparkSession.sessionState, newTable))\n+      catalog.alterTableStats(table.identifier,\n+        CatalogStatistics(sizeInBytes = newSize, rowCount = newRowCount))"
  }, {
    "author": {
      "login": "wzhfy"
    },
    "body": "Since updating size only needs to calculate file sizes, while updating other stats needs to scan the data, the two costs are in different orders of magnitude. How about adding another flag to auto update other stats in a separate pr or followup?",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-26T06:57:06Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.command\n+\n+import java.net.URI\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.fs.{FileSystem, Path}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.catalog.{CatalogStatistics, CatalogTable}\n+import org.apache.spark.sql.internal.SessionState\n+\n+\n+object CommandUtils extends Logging {\n+\n+  /**\n+   * Update statistics (currently only sizeInBytes) after changing data by commands.\n+   */\n+  def updateTableStats(\n+      sparkSession: SparkSession,\n+      table: CatalogTable,\n+      newTableSize: Option[BigInt] = None,\n+      newRowCount: Option[BigInt] = None): Unit = {\n+    if (sparkSession.sessionState.conf.autoStatsUpdate && table.stats.nonEmpty) {\n+      val catalog = sparkSession.sessionState.catalog\n+      val newTable = catalog.getTableMetadata(table.identifier)\n+      val newSize = newTableSize.getOrElse(\n+        CommandUtils.calculateTotalSize(sparkSession.sessionState, newTable))\n+      catalog.alterTableStats(table.identifier,\n+        CatalogStatistics(sizeInBytes = newSize, rowCount = newRowCount))"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "then shall we update the config name? we need to mention that it only auto updates table size",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-26T07:43:58Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.command\n+\n+import java.net.URI\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.fs.{FileSystem, Path}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.catalog.{CatalogStatistics, CatalogTable}\n+import org.apache.spark.sql.internal.SessionState\n+\n+\n+object CommandUtils extends Logging {\n+\n+  /**\n+   * Update statistics (currently only sizeInBytes) after changing data by commands.\n+   */\n+  def updateTableStats(\n+      sparkSession: SparkSession,\n+      table: CatalogTable,\n+      newTableSize: Option[BigInt] = None,\n+      newRowCount: Option[BigInt] = None): Unit = {\n+    if (sparkSession.sessionState.conf.autoStatsUpdate && table.stats.nonEmpty) {\n+      val catalog = sparkSession.sessionState.catalog\n+      val newTable = catalog.getTableMetadata(table.identifier)\n+      val newSize = newTableSize.getOrElse(\n+        CommandUtils.calculateTotalSize(sparkSession.sessionState, newTable))\n+      catalog.alterTableStats(table.identifier,\n+        CatalogStatistics(sizeInBytes = newSize, rowCount = newRowCount))"
  }, {
    "author": {
      "login": "wzhfy"
    },
    "body": "Sure.",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-26T08:25:02Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.command\n+\n+import java.net.URI\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.fs.{FileSystem, Path}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.catalog.{CatalogStatistics, CatalogTable}\n+import org.apache.spark.sql.internal.SessionState\n+\n+\n+object CommandUtils extends Logging {\n+\n+  /**\n+   * Update statistics (currently only sizeInBytes) after changing data by commands.\n+   */\n+  def updateTableStats(\n+      sparkSession: SparkSession,\n+      table: CatalogTable,\n+      newTableSize: Option[BigInt] = None,\n+      newRowCount: Option[BigInt] = None): Unit = {\n+    if (sparkSession.sessionState.conf.autoStatsUpdate && table.stats.nonEmpty) {\n+      val catalog = sparkSession.sessionState.catalog\n+      val newTable = catalog.getTableMetadata(table.identifier)\n+      val newSize = newTableSize.getOrElse(\n+        CommandUtils.calculateTotalSize(sparkSession.sessionState, newTable))\n+      catalog.alterTableStats(table.identifier,\n+        CatalogStatistics(sizeInBytes = newSize, rowCount = newRowCount))"
  }],
  "prId": 18334
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Actually, the log message contains the timestamp. It does not need to calculate the total time, but I think it is fine here.",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-07-01T04:18:15Z",
    "diffHunk": "@@ -97,6 +106,10 @@ object CommandUtils extends Logging {\n           0L\n       }\n     }.getOrElse(0L)\n+    val durationInMs = (System.nanoTime() - startTime) / (1000 * 1000)\n+    logInfo(s\"It took $durationInMs ms to calculate the total file size under path $locationUri.\")",
    "line": 32
  }],
  "prId": 18334
}]