[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "nit you can merge this with the one above\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-11T21:00:30Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer"
  }],
  "prId": 8642
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "it would be clearer if this looks like:\n\n```\n// If this row had no matches and we're using outer join, join it with the null row\nif (!streamRowMatched) {\n  (joinType, buildSide) match {\n    ...\n  }\n}\n```\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-11T21:22:08Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)\n+    val resultProj = genResultProjection\n+    streamed.open()\n+\n+    val matchesOrStreamedRowsWithNulls = streamed.asIterator.flatMap { streamedRow =>\n+      val matchedRows = new CompactBuffer[InternalRow]\n+\n+      var i = 0\n+      var streamRowMatched = false\n+\n+      while (i < buildRelation.size) {\n+        val buildRow = buildRelation(i)\n+        buildSide match {\n+          case BuildRight if boundCondition(joinedRow(streamedRow, buildRow)) =>\n+            matchedRows += resultProj(joinedRow(streamedRow, buildRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case BuildLeft if boundCondition(joinedRow(buildRow, streamedRow)) =>\n+            matchedRows += resultProj(joinedRow(buildRow, streamedRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case _ =>\n+        }\n+        i += 1\n+      }\n+\n+      (streamRowMatched, joinType, buildSide) match {\n+        case (false, LeftOuter | FullOuter, BuildRight) =>\n+          matchedRows += resultProj(joinedRow(streamedRow, rightNulls)).copy()\n+        case (false, RightOuter | FullOuter, BuildLeft) =>\n+          matchedRows += resultProj(joinedRow(leftNulls, streamedRow)).copy()\n+        case _ =>\n+      }"
  }],
  "prId": 8642
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "I would just call this `streamedRowMatches` and add a comment to explain it could contain null rows if we're using outer join\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-11T21:24:05Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)\n+    val resultProj = genResultProjection\n+    streamed.open()\n+\n+    val matchesOrStreamedRowsWithNulls = streamed.asIterator.flatMap { streamedRow =>"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "also can you add a return type here? It helps readability a little bit since this flat map block is kind of big:\n\n```\nval streamedRowMatches: Iterator[InternalRow] = ...\n```\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-11T21:40:53Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)\n+    val resultProj = genResultProjection\n+    streamed.open()\n+\n+    val matchesOrStreamedRowsWithNulls = streamed.asIterator.flatMap { streamedRow =>"
  }],
  "prId": 8642
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "Reduce duplicate code:\n\n```\nbuildSide match {\n  case BuildRight => joinedRow(streamedRow, buildRow)\n  case BuildLeft => joinedRow(buildRow, streamedRow)\n  case _ =>\n}\nif (boundCondition(joinedRow)) {\n  matchedRows += resultProj(joinedRow).copy()\n  streamedRowMatched = true\n  matchedBuildTuples.set(i)\n}\n```\n\nalso `joinedRow(x, y)` mutates the row itself, so you can just use `joinedRow` directly when doing the projection\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-11T21:28:14Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)\n+    val resultProj = genResultProjection\n+    streamed.open()\n+\n+    val matchesOrStreamedRowsWithNulls = streamed.asIterator.flatMap { streamedRow =>\n+      val matchedRows = new CompactBuffer[InternalRow]\n+\n+      var i = 0\n+      var streamRowMatched = false\n+\n+      while (i < buildRelation.size) {\n+        val buildRow = buildRelation(i)\n+        buildSide match {\n+          case BuildRight if boundCondition(joinedRow(streamedRow, buildRow)) =>\n+            matchedRows += resultProj(joinedRow(streamedRow, buildRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case BuildLeft if boundCondition(joinedRow(buildRow, streamedRow)) =>\n+            matchedRows += resultProj(joinedRow(buildRow, streamedRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case _ =>\n+        }"
  }],
  "prId": 8642
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "matchedBuildTuples\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-11T21:28:34Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)"
  }],
  "prId": 8642
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "could just be `resultProj(joinedRow(leftNulls, buildRow))`, same in L136\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-11T21:37:07Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)\n+    val resultProj = genResultProjection\n+    streamed.open()\n+\n+    val matchesOrStreamedRowsWithNulls = streamed.asIterator.flatMap { streamedRow =>\n+      val matchedRows = new CompactBuffer[InternalRow]\n+\n+      var i = 0\n+      var streamRowMatched = false\n+\n+      while (i < buildRelation.size) {\n+        val buildRow = buildRelation(i)\n+        buildSide match {\n+          case BuildRight if boundCondition(joinedRow(streamedRow, buildRow)) =>\n+            matchedRows += resultProj(joinedRow(streamedRow, buildRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case BuildLeft if boundCondition(joinedRow(buildRow, streamedRow)) =>\n+            matchedRows += resultProj(joinedRow(buildRow, streamedRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case _ =>\n+        }\n+        i += 1\n+      }\n+\n+      (streamRowMatched, joinType, buildSide) match {\n+        case (false, LeftOuter | FullOuter, BuildRight) =>\n+          matchedRows += resultProj(joinedRow(streamedRow, rightNulls)).copy()\n+        case (false, RightOuter | FullOuter, BuildLeft) =>\n+          matchedRows += resultProj(joinedRow(leftNulls, streamedRow)).copy()\n+        case _ =>\n+      }\n+\n+      matchedRows.iterator\n+    }\n+\n+    iterator = (joinType, buildSide) match {\n+      case (RightOuter | FullOuter, BuildRight) =>\n+        var i = 0\n+        matchesOrStreamedRowsWithNulls ++ buildRelation.filter { row =>\n+          val r = !includedBuildTuples.get(i)\n+          i += 1\n+          r\n+        }.iterator.map { buildRow =>\n+          joinedRow.withLeft(leftNulls)\n+          resultProj(joinedRow.withRight(buildRow))"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "also, don't we need to do a copy here?\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-11T21:37:30Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)\n+    val resultProj = genResultProjection\n+    streamed.open()\n+\n+    val matchesOrStreamedRowsWithNulls = streamed.asIterator.flatMap { streamedRow =>\n+      val matchedRows = new CompactBuffer[InternalRow]\n+\n+      var i = 0\n+      var streamRowMatched = false\n+\n+      while (i < buildRelation.size) {\n+        val buildRow = buildRelation(i)\n+        buildSide match {\n+          case BuildRight if boundCondition(joinedRow(streamedRow, buildRow)) =>\n+            matchedRows += resultProj(joinedRow(streamedRow, buildRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case BuildLeft if boundCondition(joinedRow(buildRow, streamedRow)) =>\n+            matchedRows += resultProj(joinedRow(buildRow, streamedRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case _ =>\n+        }\n+        i += 1\n+      }\n+\n+      (streamRowMatched, joinType, buildSide) match {\n+        case (false, LeftOuter | FullOuter, BuildRight) =>\n+          matchedRows += resultProj(joinedRow(streamedRow, rightNulls)).copy()\n+        case (false, RightOuter | FullOuter, BuildLeft) =>\n+          matchedRows += resultProj(joinedRow(leftNulls, streamedRow)).copy()\n+        case _ =>\n+      }\n+\n+      matchedRows.iterator\n+    }\n+\n+    iterator = (joinType, buildSide) match {\n+      case (RightOuter | FullOuter, BuildRight) =>\n+        var i = 0\n+        matchesOrStreamedRowsWithNulls ++ buildRelation.filter { row =>\n+          val r = !includedBuildTuples.get(i)\n+          i += 1\n+          r\n+        }.iterator.map { buildRow =>\n+          joinedRow.withLeft(leftNulls)\n+          resultProj(joinedRow.withRight(buildRow))"
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "> also, don't we need to do a copy here?\n\nIt's not necessary since we don't need to cache `joinedRow` here. If the user needs to use multiple rows of this Iterator, he should copy it by himself.\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-14T11:02:30Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)\n+    val resultProj = genResultProjection\n+    streamed.open()\n+\n+    val matchesOrStreamedRowsWithNulls = streamed.asIterator.flatMap { streamedRow =>\n+      val matchedRows = new CompactBuffer[InternalRow]\n+\n+      var i = 0\n+      var streamRowMatched = false\n+\n+      while (i < buildRelation.size) {\n+        val buildRow = buildRelation(i)\n+        buildSide match {\n+          case BuildRight if boundCondition(joinedRow(streamedRow, buildRow)) =>\n+            matchedRows += resultProj(joinedRow(streamedRow, buildRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case BuildLeft if boundCondition(joinedRow(buildRow, streamedRow)) =>\n+            matchedRows += resultProj(joinedRow(buildRow, streamedRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case _ =>\n+        }\n+        i += 1\n+      }\n+\n+      (streamRowMatched, joinType, buildSide) match {\n+        case (false, LeftOuter | FullOuter, BuildRight) =>\n+          matchedRows += resultProj(joinedRow(streamedRow, rightNulls)).copy()\n+        case (false, RightOuter | FullOuter, BuildLeft) =>\n+          matchedRows += resultProj(joinedRow(leftNulls, streamedRow)).copy()\n+        case _ =>\n+      }\n+\n+      matchedRows.iterator\n+    }\n+\n+    iterator = (joinType, buildSide) match {\n+      case (RightOuter | FullOuter, BuildRight) =>\n+        var i = 0\n+        matchesOrStreamedRowsWithNulls ++ buildRelation.filter { row =>\n+          val r = !includedBuildTuples.get(i)\n+          i += 1\n+          r\n+        }.iterator.map { buildRow =>\n+          joinedRow.withLeft(leftNulls)\n+          resultProj(joinedRow.withRight(buildRow))"
  }],
  "prId": 8642
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "How about the following to reduce duplicate code? It should be functionally the same.\n\n```\n// If we're using outer join, find rows on the build side that didn't match anything\n// and join them with the null row\nlazy val unmatchedBuildRows: Iterator[InternalRow] = {\n  var i = 0\n  buildRelation.filter { row =>\n    val r = !includedBuildTuples.get(i)\n    i += 1\n    r\n  }.iterator\n}\nval additionalRows: Iterator[InternalRow] = (joinType, buildSide) match {\n  case (RightOuter | FullOuter, BuildRight) =>\n    unmatchedBuildRows.map { resultProj(joinedRow(leftNulls, _)) } // copy?\n  case (LeftOuter | FullOuter, BuildLeft) =>\n    unmatchedBuildRows.map { resultProj(joinedRow(_, rightNulls)) }\n  case _ =>\n    Iterator.empty[InternalRow]\n}\n\niterator = streamedRowMatches ++ additionalRows\n```\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-11T21:47:27Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)\n+    val resultProj = genResultProjection\n+    streamed.open()\n+\n+    val matchesOrStreamedRowsWithNulls = streamed.asIterator.flatMap { streamedRow =>\n+      val matchedRows = new CompactBuffer[InternalRow]\n+\n+      var i = 0\n+      var streamRowMatched = false\n+\n+      while (i < buildRelation.size) {\n+        val buildRow = buildRelation(i)\n+        buildSide match {\n+          case BuildRight if boundCondition(joinedRow(streamedRow, buildRow)) =>\n+            matchedRows += resultProj(joinedRow(streamedRow, buildRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case BuildLeft if boundCondition(joinedRow(buildRow, streamedRow)) =>\n+            matchedRows += resultProj(joinedRow(buildRow, streamedRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case _ =>\n+        }\n+        i += 1\n+      }\n+\n+      (streamRowMatched, joinType, buildSide) match {\n+        case (false, LeftOuter | FullOuter, BuildRight) =>\n+          matchedRows += resultProj(joinedRow(streamedRow, rightNulls)).copy()\n+        case (false, RightOuter | FullOuter, BuildLeft) =>\n+          matchedRows += resultProj(joinedRow(leftNulls, streamedRow)).copy()\n+        case _ =>\n+      }\n+\n+      matchedRows.iterator\n+    }\n+\n+    iterator = (joinType, buildSide) match {\n+      case (RightOuter | FullOuter, BuildRight) =>\n+        var i = 0\n+        matchesOrStreamedRowsWithNulls ++ buildRelation.filter { row =>\n+          val r = !includedBuildTuples.get(i)\n+          i += 1\n+          r\n+        }.iterator.map { buildRow =>\n+          joinedRow.withLeft(leftNulls)\n+          resultProj(joinedRow.withRight(buildRow))\n+        }\n+      case (LeftOuter | FullOuter, BuildLeft) =>\n+        var i = 0\n+        matchesOrStreamedRowsWithNulls ++ buildRelation.filter { row =>\n+          val r = !includedBuildTuples.get(i)\n+          i += 1\n+          r\n+        }.iterator.map { buildRow =>\n+          joinedRow.withRight(rightNulls)\n+          resultProj(joinedRow.withLeft(buildRow))\n+        }\n+      case _ => matchesOrStreamedRowsWithNulls\n+    }"
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "I did a little change to your suggest to avoid using `Iterator.empty[InternalRow]`.\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-14T11:03:19Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)\n+    val resultProj = genResultProjection\n+    streamed.open()\n+\n+    val matchesOrStreamedRowsWithNulls = streamed.asIterator.flatMap { streamedRow =>\n+      val matchedRows = new CompactBuffer[InternalRow]\n+\n+      var i = 0\n+      var streamRowMatched = false\n+\n+      while (i < buildRelation.size) {\n+        val buildRow = buildRelation(i)\n+        buildSide match {\n+          case BuildRight if boundCondition(joinedRow(streamedRow, buildRow)) =>\n+            matchedRows += resultProj(joinedRow(streamedRow, buildRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case BuildLeft if boundCondition(joinedRow(buildRow, streamedRow)) =>\n+            matchedRows += resultProj(joinedRow(buildRow, streamedRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case _ =>\n+        }\n+        i += 1\n+      }\n+\n+      (streamRowMatched, joinType, buildSide) match {\n+        case (false, LeftOuter | FullOuter, BuildRight) =>\n+          matchedRows += resultProj(joinedRow(streamedRow, rightNulls)).copy()\n+        case (false, RightOuter | FullOuter, BuildLeft) =>\n+          matchedRows += resultProj(joinedRow(leftNulls, streamedRow)).copy()\n+        case _ =>\n+      }\n+\n+      matchedRows.iterator\n+    }\n+\n+    iterator = (joinType, buildSide) match {\n+      case (RightOuter | FullOuter, BuildRight) =>\n+        var i = 0\n+        matchesOrStreamedRowsWithNulls ++ buildRelation.filter { row =>\n+          val r = !includedBuildTuples.get(i)\n+          i += 1\n+          r\n+        }.iterator.map { buildRow =>\n+          joinedRow.withLeft(leftNulls)\n+          resultProj(joinedRow.withRight(buildRow))\n+        }\n+      case (LeftOuter | FullOuter, BuildLeft) =>\n+        var i = 0\n+        matchesOrStreamedRowsWithNulls ++ buildRelation.filter { row =>\n+          val r = !includedBuildTuples.get(i)\n+          i += 1\n+          r\n+        }.iterator.map { buildRow =>\n+          joinedRow.withRight(rightNulls)\n+          resultProj(joinedRow.withLeft(buildRow))\n+        }\n+      case _ => matchesOrStreamedRowsWithNulls\n+    }"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "ok that's fine\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-14T21:59:08Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)\n+    val resultProj = genResultProjection\n+    streamed.open()\n+\n+    val matchesOrStreamedRowsWithNulls = streamed.asIterator.flatMap { streamedRow =>\n+      val matchedRows = new CompactBuffer[InternalRow]\n+\n+      var i = 0\n+      var streamRowMatched = false\n+\n+      while (i < buildRelation.size) {\n+        val buildRow = buildRelation(i)\n+        buildSide match {\n+          case BuildRight if boundCondition(joinedRow(streamedRow, buildRow)) =>\n+            matchedRows += resultProj(joinedRow(streamedRow, buildRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case BuildLeft if boundCondition(joinedRow(buildRow, streamedRow)) =>\n+            matchedRows += resultProj(joinedRow(buildRow, streamedRow)).copy()\n+            streamRowMatched = true\n+            includedBuildTuples.set(i)\n+          case _ =>\n+        }\n+        i += 1\n+      }\n+\n+      (streamRowMatched, joinType, buildSide) match {\n+        case (false, LeftOuter | FullOuter, BuildRight) =>\n+          matchedRows += resultProj(joinedRow(streamedRow, rightNulls)).copy()\n+        case (false, RightOuter | FullOuter, BuildLeft) =>\n+          matchedRows += resultProj(joinedRow(leftNulls, streamedRow)).copy()\n+        case _ =>\n+      }\n+\n+      matchedRows.iterator\n+    }\n+\n+    iterator = (joinType, buildSide) match {\n+      case (RightOuter | FullOuter, BuildRight) =>\n+        var i = 0\n+        matchesOrStreamedRowsWithNulls ++ buildRelation.filter { row =>\n+          val r = !includedBuildTuples.get(i)\n+          i += 1\n+          r\n+        }.iterator.map { buildRow =>\n+          joinedRow.withLeft(leftNulls)\n+          resultProj(joinedRow.withRight(buildRow))\n+        }\n+      case (LeftOuter | FullOuter, BuildLeft) =>\n+        var i = 0\n+        matchesOrStreamedRowsWithNulls ++ buildRelation.filter { row =>\n+          val r = !includedBuildTuples.get(i)\n+          i += 1\n+          r\n+        }.iterator.map { buildRow =>\n+          joinedRow.withRight(rightNulls)\n+          resultProj(joinedRow.withLeft(buildRow))\n+        }\n+      case _ => matchesOrStreamedRowsWithNulls\n+    }"
  }],
  "prId": 8642
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "```\n// Scan the build relation to look for matches for each streamed row\n```\n",
    "commit": "c6e80a2f0fa71dc788a754dd9d0f7e8e89bab56f",
    "createdAt": "2015-09-11T21:49:27Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import org.apache.spark.sql.SQLConf\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, RightOuter, LeftOuter, JoinType}\n+import org.apache.spark.sql.execution.joins.{BuildLeft, BuildRight, BuildSide}\n+import org.apache.spark.util.collection.BitSet\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+case class NestedLoopJoinNode(\n+    conf: SQLConf,\n+    left: LocalNode,\n+    right: LocalNode,\n+    buildSide: BuildSide,\n+    joinType: JoinType,\n+    condition: Option[Expression]) extends BinaryLocalNode(conf) {\n+\n+  override def output: Seq[Attribute] = {\n+    joinType match {\n+      case LeftOuter =>\n+        left.output ++ right.output.map(_.withNullability(true))\n+      case RightOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output\n+      case FullOuter =>\n+        left.output.map(_.withNullability(true)) ++ right.output.map(_.withNullability(true))\n+      case x =>\n+        throw new IllegalArgumentException(\n+          s\"NestedLoopJoin should not take $x as the JoinType\")\n+    }\n+  }\n+\n+  private[this] def genResultProjection: InternalRow => InternalRow = {\n+    if (outputsUnsafeRows) {\n+      UnsafeProjection.create(schema)\n+    } else {\n+      identity[InternalRow]\n+    }\n+  }\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  override def open(): Unit = {\n+    val (streamed, build) = buildSide match {\n+      case BuildRight => (left, right)\n+      case BuildLeft => (right, left)\n+    }\n+    build.open()\n+    val buildRelation = new CompactBuffer[InternalRow]\n+    while (build.next()) {\n+      buildRelation += build.fetch().copy()\n+    }\n+    build.close()\n+\n+    val boundCondition =\n+      newPredicate(condition.getOrElse(Literal(true)), left.output ++ right.output)\n+\n+    val leftNulls = new GenericMutableRow(left.output.size)\n+    val rightNulls = new GenericMutableRow(right.output.size)\n+    val joinedRow = new JoinedRow\n+    val includedBuildTuples = new BitSet(buildRelation.size)\n+    val resultProj = genResultProjection\n+    streamed.open()\n+\n+    val matchesOrStreamedRowsWithNulls = streamed.asIterator.flatMap { streamedRow =>\n+      val matchedRows = new CompactBuffer[InternalRow]\n+\n+      var i = 0\n+      var streamRowMatched = false\n+\n+      while (i < buildRelation.size) {"
  }],
  "prId": 8642
}]