[{
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "Why not add a path for `InsertableRelation`?",
    "commit": "27598ce9b5ef7bc8224e37df6f14907e766ddd54",
    "createdAt": "2019-08-05T18:57:08Z",
    "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.writer\n+\n+import org.apache.spark.annotation.{Experimental, Unstable}\n+import org.apache.spark.sql.sources.CreatableRelationProvider\n+\n+/**\n+ * A trait that should be implemented by V1 DataSources that would like to leverage the DataSource\n+ * V2 write code paths.\n+ *\n+ * @since 3.0.0\n+ */\n+@Experimental\n+@Unstable\n+trait V1WriteBuilder extends WriteBuilder {\n+\n+  /**\n+   * Creates a [[CreatableRelationProvider]] that allows saving a DataFrame to a\n+   * a destination (using data source-specific parameters).\n+   *\n+   * The relation will receive a string to string map of options that will be case sensitive,\n+   * therefore the implementation of the data source should be able to handle case insensitive\n+   * option checking.\n+   *\n+   * @since 3.0.0\n+   */\n+  def buildForV1Write(): CreatableRelationProvider = {"
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "insert semantics are weird. It doesn't support the passing in of options as well.\r\n`CreatableRelationProvider` is more flexible. I also did a quick spot check of:\r\nhttps://spark-packages.org/?q=tags%3A%22Data%20Sources%22\r\n\r\nAll sources that I checked support `CreatableRelationProvider`, but some don't support `InsertableRelation`",
    "commit": "27598ce9b5ef7bc8224e37df6f14907e766ddd54",
    "createdAt": "2019-08-05T22:18:42Z",
    "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.writer\n+\n+import org.apache.spark.annotation.{Experimental, Unstable}\n+import org.apache.spark.sql.sources.CreatableRelationProvider\n+\n+/**\n+ * A trait that should be implemented by V1 DataSources that would like to leverage the DataSource\n+ * V2 write code paths.\n+ *\n+ * @since 3.0.0\n+ */\n+@Experimental\n+@Unstable\n+trait V1WriteBuilder extends WriteBuilder {\n+\n+  /**\n+   * Creates a [[CreatableRelationProvider]] that allows saving a DataFrame to a\n+   * a destination (using data source-specific parameters).\n+   *\n+   * The relation will receive a string to string map of options that will be case sensitive,\n+   * therefore the implementation of the data source should be able to handle case insensitive\n+   * option checking.\n+   *\n+   * @since 3.0.0\n+   */\n+  def buildForV1Write(): CreatableRelationProvider = {"
  }],
  "prId": 25348
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "Do we need to throw an exception by default? This is a mixin trait. If users mix it in, they must provide the implementation.",
    "commit": "27598ce9b5ef7bc8224e37df6f14907e766ddd54",
    "createdAt": "2019-08-07T07:37:49Z",
    "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.writer\n+\n+import org.apache.spark.annotation.{Experimental, Unstable}\n+import org.apache.spark.sql.sources.{CreatableRelationProvider, InsertableRelation}\n+\n+/**\n+ * A trait that should be implemented by V1 DataSources that would like to leverage the DataSource\n+ * V2 write code paths. The CreatableRelationProvider will be used only to Append data. Other\n+ * instances of the [[WriteBuilder]] interface such as [[SupportsOverwrite]], [[SupportsTruncate]]\n+ * should be extended as well to support additional operations other than data appends.\n+ *\n+ * @since 3.0.0\n+ */\n+@Experimental\n+@Unstable\n+trait V1WriteBuilder extends WriteBuilder {\n+\n+  /**\n+   * Creates an [[InsertableRelation]] that allows appending a DataFrame to a\n+   * a destination (using data source-specific parameters). The insert method will only be\n+   * called with `overwrite=false`. The DataSource should implement the overwrite behavior as\n+   * part of the [[SupportsOverwrite]], and [[SupportsTruncate]] interfaces.\n+   *\n+   * @since 3.0.0\n+   */\n+  def buildForV1Write(): InsertableRelation = {\n+    throw new UnsupportedOperationException(getClass.getName + \" does not support batch write\")"
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "yeah, not needed.",
    "commit": "27598ce9b5ef7bc8224e37df6f14907e766ddd54",
    "createdAt": "2019-08-07T16:49:03Z",
    "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.writer\n+\n+import org.apache.spark.annotation.{Experimental, Unstable}\n+import org.apache.spark.sql.sources.{CreatableRelationProvider, InsertableRelation}\n+\n+/**\n+ * A trait that should be implemented by V1 DataSources that would like to leverage the DataSource\n+ * V2 write code paths. The CreatableRelationProvider will be used only to Append data. Other\n+ * instances of the [[WriteBuilder]] interface such as [[SupportsOverwrite]], [[SupportsTruncate]]\n+ * should be extended as well to support additional operations other than data appends.\n+ *\n+ * @since 3.0.0\n+ */\n+@Experimental\n+@Unstable\n+trait V1WriteBuilder extends WriteBuilder {\n+\n+  /**\n+   * Creates an [[InsertableRelation]] that allows appending a DataFrame to a\n+   * a destination (using data source-specific parameters). The insert method will only be\n+   * called with `overwrite=false`. The DataSource should implement the overwrite behavior as\n+   * part of the [[SupportsOverwrite]], and [[SupportsTruncate]] interfaces.\n+   *\n+   * @since 3.0.0\n+   */\n+  def buildForV1Write(): InsertableRelation = {\n+    throw new UnsupportedOperationException(getClass.getName + \" does not support batch write\")"
  }],
  "prId": 25348
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "since it's a mixin trait, how about naming it `SupportsV1Fallback`?",
    "commit": "27598ce9b5ef7bc8224e37df6f14907e766ddd54",
    "createdAt": "2019-08-14T14:30:54Z",
    "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.writer\n+\n+import org.apache.spark.annotation.{Experimental, Unstable}\n+import org.apache.spark.sql.sources.InsertableRelation\n+\n+/**\n+ * A trait that should be implemented by V1 DataSources that would like to leverage the DataSource\n+ * V2 write code paths. The CreatableRelationProvider will be used only to Append data. Other\n+ * instances of the [[WriteBuilder]] interface such as [[SupportsOverwrite]], [[SupportsTruncate]]\n+ * should be extended as well to support additional operations other than data appends.\n+ *\n+ * This interface is designed to provide Spark DataSources time to migrate to DataSource V2 and\n+ * will be removed in a future Spark release.\n+ *\n+ * @since 3.0.0\n+ */\n+@Experimental\n+@Unstable\n+trait V1WriteBuilder extends WriteBuilder {",
    "line": 37
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "Hmm, all of the other mixins and their functions return a `WriteBuilder` after their supported operation, whereas this ends the chain. I don't have too strong opinions on this. (I'm also considering, whether this should also finalize unsupported operations for the V2 writes, e.g. `final buildBatchWrite() => Unsupported`)",
    "commit": "27598ce9b5ef7bc8224e37df6f14907e766ddd54",
    "createdAt": "2019-08-14T15:52:39Z",
    "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.writer\n+\n+import org.apache.spark.annotation.{Experimental, Unstable}\n+import org.apache.spark.sql.sources.InsertableRelation\n+\n+/**\n+ * A trait that should be implemented by V1 DataSources that would like to leverage the DataSource\n+ * V2 write code paths. The CreatableRelationProvider will be used only to Append data. Other\n+ * instances of the [[WriteBuilder]] interface such as [[SupportsOverwrite]], [[SupportsTruncate]]\n+ * should be extended as well to support additional operations other than data appends.\n+ *\n+ * This interface is designed to provide Spark DataSources time to migrate to DataSource V2 and\n+ * will be removed in a future Spark release.\n+ *\n+ * @since 3.0.0\n+ */\n+@Experimental\n+@Unstable\n+trait V1WriteBuilder extends WriteBuilder {",
    "line": 37
  }],
  "prId": 25348
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "We need to update the comment.",
    "commit": "27598ce9b5ef7bc8224e37df6f14907e766ddd54",
    "createdAt": "2019-08-14T14:48:19Z",
    "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.writer\n+\n+import org.apache.spark.annotation.{Experimental, Unstable}\n+import org.apache.spark.sql.sources.InsertableRelation\n+\n+/**\n+ * A trait that should be implemented by V1 DataSources that would like to leverage the DataSource\n+ * V2 write code paths. The CreatableRelationProvider will be used only to Append data. Other"
  }],
  "prId": 25348
}, {
  "comments": [{
    "author": {
      "login": "brkyvz"
    },
    "body": "not sure if this is required. Now WriteBuilder implementations need to \r\n```scala\r\nclass ExampleBuilder extends WriteBuilder with V1WriteBuilder\r\n```\r\n",
    "commit": "27598ce9b5ef7bc8224e37df6f14907e766ddd54",
    "createdAt": "2019-08-20T21:23:24Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.writer\n+\n+import org.apache.spark.annotation.{Experimental, Unstable}\n+import org.apache.spark.sql.sources.InsertableRelation\n+import org.apache.spark.sql.sources.v2.writer.streaming.StreamingWrite\n+\n+/**\n+ * A trait that should be implemented by V1 DataSources that would like to leverage the DataSource\n+ * V2 write code paths. The InsertableRelation will be used only to Append data. Other\n+ * instances of the [[WriteBuilder]] interface such as [[SupportsOverwrite]], [[SupportsTruncate]]\n+ * should be extended as well to support additional operations other than data appends.\n+ *\n+ * This interface is designed to provide Spark DataSources time to migrate to DataSource V2 and\n+ * will be removed in a future Spark release.\n+ *\n+ * @since 3.0.0\n+ */\n+@Experimental\n+@Unstable\n+trait V1WriteBuilder extends WriteBuilder {\n+\n+  /**\n+   * Creates an InsertableRelation that allows appending a DataFrame to a\n+   * a destination (using data source-specific parameters). The insert method will only be\n+   * called with `overwrite=false`. The DataSource should implement the overwrite behavior as\n+   * part of the [[SupportsOverwrite]], and [[SupportsTruncate]] interfaces.\n+   *\n+   * @since 3.0.0\n+   */\n+  def buildForV1Write(): InsertableRelation\n+\n+  // These methods cannot be implemented by a V1WriteBuilder.\n+  override final def buildForBatch(): BatchWrite = super.buildForBatch()",
    "line": 51
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "Minor: would be nice to have a comment that the superclass is going to throw an exception.",
    "commit": "27598ce9b5ef7bc8224e37df6f14907e766ddd54",
    "createdAt": "2019-08-20T23:39:09Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.writer\n+\n+import org.apache.spark.annotation.{Experimental, Unstable}\n+import org.apache.spark.sql.sources.InsertableRelation\n+import org.apache.spark.sql.sources.v2.writer.streaming.StreamingWrite\n+\n+/**\n+ * A trait that should be implemented by V1 DataSources that would like to leverage the DataSource\n+ * V2 write code paths. The InsertableRelation will be used only to Append data. Other\n+ * instances of the [[WriteBuilder]] interface such as [[SupportsOverwrite]], [[SupportsTruncate]]\n+ * should be extended as well to support additional operations other than data appends.\n+ *\n+ * This interface is designed to provide Spark DataSources time to migrate to DataSource V2 and\n+ * will be removed in a future Spark release.\n+ *\n+ * @since 3.0.0\n+ */\n+@Experimental\n+@Unstable\n+trait V1WriteBuilder extends WriteBuilder {\n+\n+  /**\n+   * Creates an InsertableRelation that allows appending a DataFrame to a\n+   * a destination (using data source-specific parameters). The insert method will only be\n+   * called with `overwrite=false`. The DataSource should implement the overwrite behavior as\n+   * part of the [[SupportsOverwrite]], and [[SupportsTruncate]] interfaces.\n+   *\n+   * @since 3.0.0\n+   */\n+  def buildForV1Write(): InsertableRelation\n+\n+  // These methods cannot be implemented by a V1WriteBuilder.\n+  override final def buildForBatch(): BatchWrite = super.buildForBatch()",
    "line": 51
  }],
  "prId": 25348
}]