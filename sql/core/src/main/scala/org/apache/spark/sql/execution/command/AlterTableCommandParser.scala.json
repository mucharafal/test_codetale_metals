[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "I think unqoute string does the cleaning (i.e. stripping leading and trailing quotes) for us.\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-08T09:19:18Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))",
    "line": 52
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "if you look at `ParserUtils` that's done in `cleanIdentifier`\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-09T08:46:21Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))",
    "line": 52
  }],
  "prId": 11573
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Pattern match this?\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-08T09:23:18Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>\n+        val renamedTable = getClause(\"TOK_TABNAME\", renameArgs)\n+        val renamedTableIdent: TableIdentifier = extractTableIdent(renamedTable)\n+        AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: _ =>\n+        val setTableProperties = extractTableProps(args.head)\n+        AlterTableSetProperties(\n+          tableIdent,\n+          setTableProperties)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: _ =>\n+        val dropTableProperties = extractTableProps(args.head)\n+        val allowExisting = getClauseOption(\"TOK_IFEXISTS\", args)\n+        AlterTableDropProperties(\n+          tableIdent,\n+          dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERIALIZER\", Token(serdeClassName, Nil) :: serdeArgs) :: _ =>\n+        // When SET SERDE serde_classname WITH SERDEPROPERTIES, this is None\n+        val serdeProperties: Option[Map[String, Option[String]]] =\n+          serdeArgs.headOption.map(extractTableProps)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          Some(cleanAndUnquoteString(serdeClassName)),\n+          serdeProperties,\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: _ =>\n+        val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          None,\n+          Some(serdeProperties),\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) :: _ =>\n+        val (buckets, noClustered, noSorted) = clusterAndSoryByArgs match {\n+          case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgsHead :: bucketArgs) =>\n+            val bucketCols = bucketArgsHead.children.map(_.text)\n+            val (sortCols, sortDirections, numBuckets) = {\n+              if (bucketArgs.head.text == \"TOK_TABCOLNAME\") {\n+                val (cols, directions) = bucketArgs.head.children.map {\n+                  case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Ascending)\n+                  case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Descending)\n+                }.unzip\n+                (cols, directions, bucketArgs.last.text.toInt)\n+              } else {\n+                (Nil, Nil, bucketArgs.head.text.toInt)\n+              }\n+            }\n+            val bucketSpec = BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)\n+            (Some(bucketSpec), false, false)\n+          case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+            (None, true, false)\n+          case Token(\"TOK_NOT_SORTED\", Nil) =>\n+            (None, false, true)\n+        }\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered,\n+          noSorted)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: _ =>\n+        val num = bucketNum.toInt\n+        val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered = false,\n+          noSorted = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Nil) :: _ =>\n+        // ALTER TABLE table_name NOT SKEWED\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = true,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+        // ALTER TABLE table_name NOT STORED AS DIRECTORIES\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = false,\n+          notStoredAsDirs = true)(node.source)\n+\n+      case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: _ =>\n+        val skewedArgs = tableSkewed match {\n+          case Token(\"TOK_ALTERTABLE_SKEWED\", args :: Nil) =>\n+            args match {\n+              case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+                val cols = skewedCols.children.map(n => cleanAndUnquoteString(n.text))\n+                val values = skewedValues match {\n+                  case Token(\"TOK_TABCOLVALUE\", colVal) =>\n+                    Seq(colVal.map(n => cleanAndUnquoteString(n.text)))\n+                  case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                    pairs.map {\n+                      case Token(\"TOK_TABCOLVALUES\", colVals :: Nil) =>\n+                        colVals match {\n+                          case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                            vals.map(n => cleanAndUnquoteString(n.text))\n+                        }\n+                    }\n+                }\n+\n+                val storedAsDirs = stored match {\n+                  case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                  case _ => false\n+                }\n+\n+                (cols, values, storedAsDirs)\n+            }\n+        }\n+        val (cols, values, storedAsDirs) = skewedArgs\n+        AlterTableSkewed(\n+          tableIdent,\n+          cols,\n+          values,\n+          storedAsDirs,\n+          notSkewed = false,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\",\n+      Token(\"TOK_SKEWED_LOCATIONS\",\n+      Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) :: Nil) :: Nil) :: _ =>\n+        val skewedMaps = locationMaps.map {\n+          case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+            val k = key match {\n+              case Token(const, Nil) => Seq(cleanAndUnquoteString(const))\n+              case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                values match {\n+                  case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                    vals.map(n => cleanAndUnquoteString(n.text))\n+                }\n+            }\n+            (k, cleanAndUnquoteString(value.text))\n+        }.toMap\n+        AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: _ =>\n+        val (allowExisting, parts) = addPartsArgs match {\n+          case Token(\"TOK_IFNOTEXISTS\", Nil) :: others => (true, others)\n+          case _ => (false, addPartsArgs)\n+        }\n+        val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+          new ArrayBuffer()\n+        var currentPart: Map[String, Option[String]] = null\n+        parts.map {\n+          case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+            if (currentPart != null) {\n+              partitions += ((currentPart, None))\n+            }\n+            currentPart = parsePartitionSpec(t).get\n+          case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+            val location = unquoteString(loc.text)\n+            if (currentPart != null) {\n+              partitions += ((currentPart, Some(location)))\n+              currentPart = null\n+            } else {\n+              // We should not reach here\n+              throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+            }\n+        }\n+        if (currentPart != null) {\n+          partitions += ((currentPart, None))\n+        }\n+        AlterTableAddPartition(tableIdent, partitions, allowExisting)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_RENAMEPART\", partArg :: Nil) :: _ =>\n+        val Some(newPartition) = parsePartitionSpec(partArg)\n+        AlterTableRenamePartition(tableIdent, partition.get, newPartition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\",\n+      (p @ Token(\"TOK_PARTSPEC\", _)) :: (t @ Token(\"TOK_TABNAME\", _)) :: Nil) :: _ =>\n+        val Some(partition) = parsePartitionSpec(p)\n+        val fromTableIdent = extractTableIdent(t)\n+        AlterTableExchangePartition(tableIdent, fromTableIdent, partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_DROPPARTS\", args) :: _ =>\n+        val parts = args.collect {\n+          case Token(\"TOK_PARTSPEC\", partitions) =>\n+            partitions.map {\n+              case Token(\"TOK_PARTVAL\", ident :: op :: constant :: Nil) =>\n+                (cleanAndUnquoteString(ident.text),\n+                  op.text, cleanAndUnquoteString(constant.text))\n+            }\n+        }\n+        val allowExisting = getClauseOption(\"TOK_IFEXISTS\", args).isDefined\n+        val purge = getClauseOption(\"PURGE\", args)\n+        val replication = getClauseOption(\"TOK_REPLICATION\", args).map {\n+          case Token(\"TOK_REPLICATION\", replId :: metadata) =>\n+            (cleanAndUnquoteString(replId.text), metadata.nonEmpty)\n+        }\n+        AlterTableDropPartition(\n+          tableIdent,\n+          parts,\n+          allowExisting,\n+          purge.isDefined,\n+          replication)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_ARCHIVE\", partArg :: Nil) :: _ =>\n+        val Some(partition) = parsePartitionSpec(partArg)\n+        AlterTableArchivePartition(tableIdent, partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_UNARCHIVE\", partArg :: Nil) :: _ =>\n+        val Some(partition) = parsePartitionSpec(partArg)\n+        AlterTableUnarchivePartition(tableIdent, partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_FILEFORMAT\", args) :: _ =>\n+        val Seq(fileFormat, genericFormat) =\n+          getClauses(Seq(\"TOK_TABLEFILEFORMAT\", \"TOK_FILEFORMAT_GENERIC\"),\n+            args)\n+        val fFormat = fileFormat.map(_.children.map(n => cleanAndUnquoteString(n.text)))\n+        val gFormat = genericFormat.map(f => cleanAndUnquoteString(f.children(0).text))\n+        AlterTableSetFileFormat(tableIdent, partition, fFormat, gFormat)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_LOCATION\", Token(loc, Nil) :: Nil) :: _ =>\n+        AlterTableSetLocation(tableIdent, partition, cleanAndUnquoteString(loc))(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_TOUCH\", args) :: _ =>\n+        val part = getClauseOption(\"TOK_PARTSPEC\", args).flatMap(parsePartitionSpec)\n+        AlterTableTouch(tableIdent, part)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_COMPACT\", Token(compactType, Nil) :: Nil) :: _ =>\n+        AlterTableCompact(tableIdent, partition, cleanAndUnquoteString(compactType))(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_MERGEFILES\", _) :: _ =>\n+        AlterTableMerge(tableIdent, partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_RENAMECOL\", args) :: _ =>\n+        val oldName = args(0).text"
  }],
  "prId": 11573
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "This pattern match is redundant.\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-08T09:33:06Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>\n+        val renamedTable = getClause(\"TOK_TABNAME\", renameArgs)\n+        val renamedTableIdent: TableIdentifier = extractTableIdent(renamedTable)\n+        AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: _ =>\n+        val setTableProperties = extractTableProps(args.head)\n+        AlterTableSetProperties(\n+          tableIdent,\n+          setTableProperties)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: _ =>\n+        val dropTableProperties = extractTableProps(args.head)\n+        val allowExisting = getClauseOption(\"TOK_IFEXISTS\", args)\n+        AlterTableDropProperties(\n+          tableIdent,\n+          dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERIALIZER\", Token(serdeClassName, Nil) :: serdeArgs) :: _ =>\n+        // When SET SERDE serde_classname WITH SERDEPROPERTIES, this is None\n+        val serdeProperties: Option[Map[String, Option[String]]] =\n+          serdeArgs.headOption.map(extractTableProps)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          Some(cleanAndUnquoteString(serdeClassName)),\n+          serdeProperties,\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: _ =>\n+        val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          None,\n+          Some(serdeProperties),\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) :: _ =>\n+        val (buckets, noClustered, noSorted) = clusterAndSoryByArgs match {\n+          case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgsHead :: bucketArgs) =>\n+            val bucketCols = bucketArgsHead.children.map(_.text)\n+            val (sortCols, sortDirections, numBuckets) = {\n+              if (bucketArgs.head.text == \"TOK_TABCOLNAME\") {\n+                val (cols, directions) = bucketArgs.head.children.map {\n+                  case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Ascending)\n+                  case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Descending)\n+                }.unzip\n+                (cols, directions, bucketArgs.last.text.toInt)\n+              } else {\n+                (Nil, Nil, bucketArgs.head.text.toInt)\n+              }\n+            }\n+            val bucketSpec = BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)\n+            (Some(bucketSpec), false, false)\n+          case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+            (None, true, false)\n+          case Token(\"TOK_NOT_SORTED\", Nil) =>\n+            (None, false, true)\n+        }\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered,\n+          noSorted)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: _ =>\n+        val num = bucketNum.toInt\n+        val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered = false,\n+          noSorted = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Nil) :: _ =>\n+        // ALTER TABLE table_name NOT SKEWED\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = true,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+        // ALTER TABLE table_name NOT STORED AS DIRECTORIES\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = false,\n+          notStoredAsDirs = true)(node.source)\n+\n+      case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: _ =>\n+        val skewedArgs = tableSkewed match {"
  }],
  "prId": 11573
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Style\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-08T09:33:34Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>\n+        val renamedTable = getClause(\"TOK_TABNAME\", renameArgs)\n+        val renamedTableIdent: TableIdentifier = extractTableIdent(renamedTable)\n+        AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: _ =>\n+        val setTableProperties = extractTableProps(args.head)\n+        AlterTableSetProperties(\n+          tableIdent,\n+          setTableProperties)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: _ =>\n+        val dropTableProperties = extractTableProps(args.head)\n+        val allowExisting = getClauseOption(\"TOK_IFEXISTS\", args)\n+        AlterTableDropProperties(\n+          tableIdent,\n+          dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERIALIZER\", Token(serdeClassName, Nil) :: serdeArgs) :: _ =>\n+        // When SET SERDE serde_classname WITH SERDEPROPERTIES, this is None\n+        val serdeProperties: Option[Map[String, Option[String]]] =\n+          serdeArgs.headOption.map(extractTableProps)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          Some(cleanAndUnquoteString(serdeClassName)),\n+          serdeProperties,\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: _ =>\n+        val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          None,\n+          Some(serdeProperties),\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) :: _ =>\n+        val (buckets, noClustered, noSorted) = clusterAndSoryByArgs match {\n+          case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgsHead :: bucketArgs) =>\n+            val bucketCols = bucketArgsHead.children.map(_.text)\n+            val (sortCols, sortDirections, numBuckets) = {\n+              if (bucketArgs.head.text == \"TOK_TABCOLNAME\") {\n+                val (cols, directions) = bucketArgs.head.children.map {\n+                  case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Ascending)\n+                  case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Descending)\n+                }.unzip\n+                (cols, directions, bucketArgs.last.text.toInt)\n+              } else {\n+                (Nil, Nil, bucketArgs.head.text.toInt)\n+              }\n+            }\n+            val bucketSpec = BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)\n+            (Some(bucketSpec), false, false)\n+          case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+            (None, true, false)\n+          case Token(\"TOK_NOT_SORTED\", Nil) =>\n+            (None, false, true)\n+        }\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered,\n+          noSorted)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: _ =>\n+        val num = bucketNum.toInt\n+        val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered = false,\n+          noSorted = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Nil) :: _ =>\n+        // ALTER TABLE table_name NOT SKEWED\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = true,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+        // ALTER TABLE table_name NOT STORED AS DIRECTORIES\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = false,\n+          notStoredAsDirs = true)(node.source)\n+\n+      case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: _ =>\n+        val skewedArgs = tableSkewed match {\n+          case Token(\"TOK_ALTERTABLE_SKEWED\", args :: Nil) =>\n+            args match {\n+              case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+                val cols = skewedCols.children.map(n => cleanAndUnquoteString(n.text))\n+                val values = skewedValues match {\n+                  case Token(\"TOK_TABCOLVALUE\", colVal) =>\n+                    Seq(colVal.map(n => cleanAndUnquoteString(n.text)))\n+                  case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                    pairs.map {\n+                      case Token(\"TOK_TABCOLVALUES\", colVals :: Nil) =>\n+                        colVals match {\n+                          case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                            vals.map(n => cleanAndUnquoteString(n.text))\n+                        }\n+                    }\n+                }\n+\n+                val storedAsDirs = stored match {\n+                  case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                  case _ => false\n+                }\n+\n+                (cols, values, storedAsDirs)\n+            }\n+        }\n+        val (cols, values, storedAsDirs) = skewedArgs\n+        AlterTableSkewed(\n+          tableIdent,\n+          cols,\n+          values,\n+          storedAsDirs,\n+          notSkewed = false,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\",\n+      Token(\"TOK_SKEWED_LOCATIONS\","
  }],
  "prId": 11573
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "We use wildcards at the end every pattern match. Do we expect additional input which can safely ignore?\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-08T09:34:32Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "I also had this question while I was going throguh the code myself. @viirya can you answer this?\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-09T08:50:15Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Ah. That is because the node is structured as (take `TOK_ALTERTABLE_RENAME` as an example):\n\n```\nToken(\"TOK_TABNAME\", _) :: Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: Token(\"TOK_PARTSPEC\", _)\n```\n\nAs you see, Token(\"TOK_PARTSPEC\", _) is put at the end of the AST. Although I've parsed partspec early, I pass the all nodes after `Token(\"TOK_TABNAME\", _)` to the method `matchAlterTableCommands`. So there is always an additional input that can safely ignore.\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-09T09:11:12Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "If you extract the command from the AST, we can remove the additional input of course.\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-09T09:12:21Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>"
  }],
  "prId": 11573
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "We could change the parser rule in such a way that it will nest the locations inside a partition specification.\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-08T09:42:22Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>\n+        val renamedTable = getClause(\"TOK_TABNAME\", renameArgs)\n+        val renamedTableIdent: TableIdentifier = extractTableIdent(renamedTable)\n+        AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: _ =>\n+        val setTableProperties = extractTableProps(args.head)\n+        AlterTableSetProperties(\n+          tableIdent,\n+          setTableProperties)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: _ =>\n+        val dropTableProperties = extractTableProps(args.head)\n+        val allowExisting = getClauseOption(\"TOK_IFEXISTS\", args)\n+        AlterTableDropProperties(\n+          tableIdent,\n+          dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERIALIZER\", Token(serdeClassName, Nil) :: serdeArgs) :: _ =>\n+        // When SET SERDE serde_classname WITH SERDEPROPERTIES, this is None\n+        val serdeProperties: Option[Map[String, Option[String]]] =\n+          serdeArgs.headOption.map(extractTableProps)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          Some(cleanAndUnquoteString(serdeClassName)),\n+          serdeProperties,\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: _ =>\n+        val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          None,\n+          Some(serdeProperties),\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) :: _ =>\n+        val (buckets, noClustered, noSorted) = clusterAndSoryByArgs match {\n+          case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgsHead :: bucketArgs) =>\n+            val bucketCols = bucketArgsHead.children.map(_.text)\n+            val (sortCols, sortDirections, numBuckets) = {\n+              if (bucketArgs.head.text == \"TOK_TABCOLNAME\") {\n+                val (cols, directions) = bucketArgs.head.children.map {\n+                  case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Ascending)\n+                  case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Descending)\n+                }.unzip\n+                (cols, directions, bucketArgs.last.text.toInt)\n+              } else {\n+                (Nil, Nil, bucketArgs.head.text.toInt)\n+              }\n+            }\n+            val bucketSpec = BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)\n+            (Some(bucketSpec), false, false)\n+          case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+            (None, true, false)\n+          case Token(\"TOK_NOT_SORTED\", Nil) =>\n+            (None, false, true)\n+        }\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered,\n+          noSorted)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: _ =>\n+        val num = bucketNum.toInt\n+        val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered = false,\n+          noSorted = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Nil) :: _ =>\n+        // ALTER TABLE table_name NOT SKEWED\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = true,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+        // ALTER TABLE table_name NOT STORED AS DIRECTORIES\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = false,\n+          notStoredAsDirs = true)(node.source)\n+\n+      case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: _ =>\n+        val skewedArgs = tableSkewed match {\n+          case Token(\"TOK_ALTERTABLE_SKEWED\", args :: Nil) =>\n+            args match {\n+              case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+                val cols = skewedCols.children.map(n => cleanAndUnquoteString(n.text))\n+                val values = skewedValues match {\n+                  case Token(\"TOK_TABCOLVALUE\", colVal) =>\n+                    Seq(colVal.map(n => cleanAndUnquoteString(n.text)))\n+                  case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                    pairs.map {\n+                      case Token(\"TOK_TABCOLVALUES\", colVals :: Nil) =>\n+                        colVals match {\n+                          case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                            vals.map(n => cleanAndUnquoteString(n.text))\n+                        }\n+                    }\n+                }\n+\n+                val storedAsDirs = stored match {\n+                  case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                  case _ => false\n+                }\n+\n+                (cols, values, storedAsDirs)\n+            }\n+        }\n+        val (cols, values, storedAsDirs) = skewedArgs\n+        AlterTableSkewed(\n+          tableIdent,\n+          cols,\n+          values,\n+          storedAsDirs,\n+          notSkewed = false,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\",\n+      Token(\"TOK_SKEWED_LOCATIONS\",\n+      Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) :: Nil) :: Nil) :: _ =>\n+        val skewedMaps = locationMaps.map {\n+          case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+            val k = key match {\n+              case Token(const, Nil) => Seq(cleanAndUnquoteString(const))\n+              case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                values match {\n+                  case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                    vals.map(n => cleanAndUnquoteString(n.text))\n+                }\n+            }\n+            (k, cleanAndUnquoteString(value.text))\n+        }.toMap\n+        AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: _ =>\n+        val (allowExisting, parts) = addPartsArgs match {\n+          case Token(\"TOK_IFNOTEXISTS\", Nil) :: others => (true, others)\n+          case _ => (false, addPartsArgs)\n+        }\n+        val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+          new ArrayBuffer()\n+        var currentPart: Map[String, Option[String]] = null\n+        parts.map {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "we could do that later\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-09T08:50:46Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>\n+        val renamedTable = getClause(\"TOK_TABNAME\", renameArgs)\n+        val renamedTableIdent: TableIdentifier = extractTableIdent(renamedTable)\n+        AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: _ =>\n+        val setTableProperties = extractTableProps(args.head)\n+        AlterTableSetProperties(\n+          tableIdent,\n+          setTableProperties)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: _ =>\n+        val dropTableProperties = extractTableProps(args.head)\n+        val allowExisting = getClauseOption(\"TOK_IFEXISTS\", args)\n+        AlterTableDropProperties(\n+          tableIdent,\n+          dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERIALIZER\", Token(serdeClassName, Nil) :: serdeArgs) :: _ =>\n+        // When SET SERDE serde_classname WITH SERDEPROPERTIES, this is None\n+        val serdeProperties: Option[Map[String, Option[String]]] =\n+          serdeArgs.headOption.map(extractTableProps)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          Some(cleanAndUnquoteString(serdeClassName)),\n+          serdeProperties,\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: _ =>\n+        val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          None,\n+          Some(serdeProperties),\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) :: _ =>\n+        val (buckets, noClustered, noSorted) = clusterAndSoryByArgs match {\n+          case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgsHead :: bucketArgs) =>\n+            val bucketCols = bucketArgsHead.children.map(_.text)\n+            val (sortCols, sortDirections, numBuckets) = {\n+              if (bucketArgs.head.text == \"TOK_TABCOLNAME\") {\n+                val (cols, directions) = bucketArgs.head.children.map {\n+                  case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Ascending)\n+                  case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Descending)\n+                }.unzip\n+                (cols, directions, bucketArgs.last.text.toInt)\n+              } else {\n+                (Nil, Nil, bucketArgs.head.text.toInt)\n+              }\n+            }\n+            val bucketSpec = BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)\n+            (Some(bucketSpec), false, false)\n+          case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+            (None, true, false)\n+          case Token(\"TOK_NOT_SORTED\", Nil) =>\n+            (None, false, true)\n+        }\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered,\n+          noSorted)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: _ =>\n+        val num = bucketNum.toInt\n+        val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered = false,\n+          noSorted = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Nil) :: _ =>\n+        // ALTER TABLE table_name NOT SKEWED\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = true,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+        // ALTER TABLE table_name NOT STORED AS DIRECTORIES\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = false,\n+          notStoredAsDirs = true)(node.source)\n+\n+      case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: _ =>\n+        val skewedArgs = tableSkewed match {\n+          case Token(\"TOK_ALTERTABLE_SKEWED\", args :: Nil) =>\n+            args match {\n+              case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+                val cols = skewedCols.children.map(n => cleanAndUnquoteString(n.text))\n+                val values = skewedValues match {\n+                  case Token(\"TOK_TABCOLVALUE\", colVal) =>\n+                    Seq(colVal.map(n => cleanAndUnquoteString(n.text)))\n+                  case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                    pairs.map {\n+                      case Token(\"TOK_TABCOLVALUES\", colVals :: Nil) =>\n+                        colVals match {\n+                          case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                            vals.map(n => cleanAndUnquoteString(n.text))\n+                        }\n+                    }\n+                }\n+\n+                val storedAsDirs = stored match {\n+                  case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                  case _ => false\n+                }\n+\n+                (cols, values, storedAsDirs)\n+            }\n+        }\n+        val (cols, values, storedAsDirs) = skewedArgs\n+        AlterTableSkewed(\n+          tableIdent,\n+          cols,\n+          values,\n+          storedAsDirs,\n+          notSkewed = false,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\",\n+      Token(\"TOK_SKEWED_LOCATIONS\",\n+      Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) :: Nil) :: Nil) :: _ =>\n+        val skewedMaps = locationMaps.map {\n+          case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+            val k = key match {\n+              case Token(const, Nil) => Seq(cleanAndUnquoteString(const))\n+              case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                values match {\n+                  case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                    vals.map(n => cleanAndUnquoteString(n.text))\n+                }\n+            }\n+            (k, cleanAndUnquoteString(value.text))\n+        }.toMap\n+        AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: _ =>\n+        val (allowExisting, parts) = addPartsArgs match {\n+          case Token(\"TOK_IFNOTEXISTS\", Nil) :: others => (true, others)\n+          case _ => (false, addPartsArgs)\n+        }\n+        val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+          new ArrayBuffer()\n+        var currentPart: Map[String, Option[String]] = null\n+        parts.map {"
  }],
  "prId": 11573
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "We assume that `TOK_ALTERTABLE_EXCHANGEPARTITION` is followed by `TOK_PARTSPEC` and `TOK_TABNAME`. Why not let `parsePartitionSpec` and `extractTableIdent` validate this for us? This would save us some trouble in the match.\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-08T09:45:45Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>\n+        val renamedTable = getClause(\"TOK_TABNAME\", renameArgs)\n+        val renamedTableIdent: TableIdentifier = extractTableIdent(renamedTable)\n+        AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: _ =>\n+        val setTableProperties = extractTableProps(args.head)\n+        AlterTableSetProperties(\n+          tableIdent,\n+          setTableProperties)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: _ =>\n+        val dropTableProperties = extractTableProps(args.head)\n+        val allowExisting = getClauseOption(\"TOK_IFEXISTS\", args)\n+        AlterTableDropProperties(\n+          tableIdent,\n+          dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERIALIZER\", Token(serdeClassName, Nil) :: serdeArgs) :: _ =>\n+        // When SET SERDE serde_classname WITH SERDEPROPERTIES, this is None\n+        val serdeProperties: Option[Map[String, Option[String]]] =\n+          serdeArgs.headOption.map(extractTableProps)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          Some(cleanAndUnquoteString(serdeClassName)),\n+          serdeProperties,\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: _ =>\n+        val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          None,\n+          Some(serdeProperties),\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) :: _ =>\n+        val (buckets, noClustered, noSorted) = clusterAndSoryByArgs match {\n+          case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgsHead :: bucketArgs) =>\n+            val bucketCols = bucketArgsHead.children.map(_.text)\n+            val (sortCols, sortDirections, numBuckets) = {\n+              if (bucketArgs.head.text == \"TOK_TABCOLNAME\") {\n+                val (cols, directions) = bucketArgs.head.children.map {\n+                  case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Ascending)\n+                  case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Descending)\n+                }.unzip\n+                (cols, directions, bucketArgs.last.text.toInt)\n+              } else {\n+                (Nil, Nil, bucketArgs.head.text.toInt)\n+              }\n+            }\n+            val bucketSpec = BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)\n+            (Some(bucketSpec), false, false)\n+          case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+            (None, true, false)\n+          case Token(\"TOK_NOT_SORTED\", Nil) =>\n+            (None, false, true)\n+        }\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered,\n+          noSorted)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: _ =>\n+        val num = bucketNum.toInt\n+        val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered = false,\n+          noSorted = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Nil) :: _ =>\n+        // ALTER TABLE table_name NOT SKEWED\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = true,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+        // ALTER TABLE table_name NOT STORED AS DIRECTORIES\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = false,\n+          notStoredAsDirs = true)(node.source)\n+\n+      case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: _ =>\n+        val skewedArgs = tableSkewed match {\n+          case Token(\"TOK_ALTERTABLE_SKEWED\", args :: Nil) =>\n+            args match {\n+              case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+                val cols = skewedCols.children.map(n => cleanAndUnquoteString(n.text))\n+                val values = skewedValues match {\n+                  case Token(\"TOK_TABCOLVALUE\", colVal) =>\n+                    Seq(colVal.map(n => cleanAndUnquoteString(n.text)))\n+                  case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                    pairs.map {\n+                      case Token(\"TOK_TABCOLVALUES\", colVals :: Nil) =>\n+                        colVals match {\n+                          case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                            vals.map(n => cleanAndUnquoteString(n.text))\n+                        }\n+                    }\n+                }\n+\n+                val storedAsDirs = stored match {\n+                  case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                  case _ => false\n+                }\n+\n+                (cols, values, storedAsDirs)\n+            }\n+        }\n+        val (cols, values, storedAsDirs) = skewedArgs\n+        AlterTableSkewed(\n+          tableIdent,\n+          cols,\n+          values,\n+          storedAsDirs,\n+          notSkewed = false,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\",\n+      Token(\"TOK_SKEWED_LOCATIONS\",\n+      Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) :: Nil) :: Nil) :: _ =>\n+        val skewedMaps = locationMaps.map {\n+          case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+            val k = key match {\n+              case Token(const, Nil) => Seq(cleanAndUnquoteString(const))\n+              case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                values match {\n+                  case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                    vals.map(n => cleanAndUnquoteString(n.text))\n+                }\n+            }\n+            (k, cleanAndUnquoteString(value.text))\n+        }.toMap\n+        AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: _ =>\n+        val (allowExisting, parts) = addPartsArgs match {\n+          case Token(\"TOK_IFNOTEXISTS\", Nil) :: others => (true, others)\n+          case _ => (false, addPartsArgs)\n+        }\n+        val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+          new ArrayBuffer()\n+        var currentPart: Map[String, Option[String]] = null\n+        parts.map {\n+          case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+            if (currentPart != null) {\n+              partitions += ((currentPart, None))\n+            }\n+            currentPart = parsePartitionSpec(t).get\n+          case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+            val location = unquoteString(loc.text)\n+            if (currentPart != null) {\n+              partitions += ((currentPart, Some(location)))\n+              currentPart = null\n+            } else {\n+              // We should not reach here\n+              throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+            }\n+        }\n+        if (currentPart != null) {\n+          partitions += ((currentPart, None))\n+        }\n+        AlterTableAddPartition(tableIdent, partitions, allowExisting)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_RENAMEPART\", partArg :: Nil) :: _ =>\n+        val Some(newPartition) = parsePartitionSpec(partArg)\n+        AlterTableRenamePartition(tableIdent, partition.get, newPartition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\","
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "agreed\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-09T08:52:51Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>\n+        val renamedTable = getClause(\"TOK_TABNAME\", renameArgs)\n+        val renamedTableIdent: TableIdentifier = extractTableIdent(renamedTable)\n+        AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: _ =>\n+        val setTableProperties = extractTableProps(args.head)\n+        AlterTableSetProperties(\n+          tableIdent,\n+          setTableProperties)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: _ =>\n+        val dropTableProperties = extractTableProps(args.head)\n+        val allowExisting = getClauseOption(\"TOK_IFEXISTS\", args)\n+        AlterTableDropProperties(\n+          tableIdent,\n+          dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERIALIZER\", Token(serdeClassName, Nil) :: serdeArgs) :: _ =>\n+        // When SET SERDE serde_classname WITH SERDEPROPERTIES, this is None\n+        val serdeProperties: Option[Map[String, Option[String]]] =\n+          serdeArgs.headOption.map(extractTableProps)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          Some(cleanAndUnquoteString(serdeClassName)),\n+          serdeProperties,\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: _ =>\n+        val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          None,\n+          Some(serdeProperties),\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) :: _ =>\n+        val (buckets, noClustered, noSorted) = clusterAndSoryByArgs match {\n+          case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgsHead :: bucketArgs) =>\n+            val bucketCols = bucketArgsHead.children.map(_.text)\n+            val (sortCols, sortDirections, numBuckets) = {\n+              if (bucketArgs.head.text == \"TOK_TABCOLNAME\") {\n+                val (cols, directions) = bucketArgs.head.children.map {\n+                  case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Ascending)\n+                  case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Descending)\n+                }.unzip\n+                (cols, directions, bucketArgs.last.text.toInt)\n+              } else {\n+                (Nil, Nil, bucketArgs.head.text.toInt)\n+              }\n+            }\n+            val bucketSpec = BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)\n+            (Some(bucketSpec), false, false)\n+          case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+            (None, true, false)\n+          case Token(\"TOK_NOT_SORTED\", Nil) =>\n+            (None, false, true)\n+        }\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered,\n+          noSorted)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: _ =>\n+        val num = bucketNum.toInt\n+        val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered = false,\n+          noSorted = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Nil) :: _ =>\n+        // ALTER TABLE table_name NOT SKEWED\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = true,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+        // ALTER TABLE table_name NOT STORED AS DIRECTORIES\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = false,\n+          notStoredAsDirs = true)(node.source)\n+\n+      case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: _ =>\n+        val skewedArgs = tableSkewed match {\n+          case Token(\"TOK_ALTERTABLE_SKEWED\", args :: Nil) =>\n+            args match {\n+              case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+                val cols = skewedCols.children.map(n => cleanAndUnquoteString(n.text))\n+                val values = skewedValues match {\n+                  case Token(\"TOK_TABCOLVALUE\", colVal) =>\n+                    Seq(colVal.map(n => cleanAndUnquoteString(n.text)))\n+                  case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                    pairs.map {\n+                      case Token(\"TOK_TABCOLVALUES\", colVals :: Nil) =>\n+                        colVals match {\n+                          case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                            vals.map(n => cleanAndUnquoteString(n.text))\n+                        }\n+                    }\n+                }\n+\n+                val storedAsDirs = stored match {\n+                  case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                  case _ => false\n+                }\n+\n+                (cols, values, storedAsDirs)\n+            }\n+        }\n+        val (cols, values, storedAsDirs) = skewedArgs\n+        AlterTableSkewed(\n+          tableIdent,\n+          cols,\n+          values,\n+          storedAsDirs,\n+          notSkewed = false,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\",\n+      Token(\"TOK_SKEWED_LOCATIONS\",\n+      Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) :: Nil) :: Nil) :: _ =>\n+        val skewedMaps = locationMaps.map {\n+          case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+            val k = key match {\n+              case Token(const, Nil) => Seq(cleanAndUnquoteString(const))\n+              case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                values match {\n+                  case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                    vals.map(n => cleanAndUnquoteString(n.text))\n+                }\n+            }\n+            (k, cleanAndUnquoteString(value.text))\n+        }.toMap\n+        AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: _ =>\n+        val (allowExisting, parts) = addPartsArgs match {\n+          case Token(\"TOK_IFNOTEXISTS\", Nil) :: others => (true, others)\n+          case _ => (false, addPartsArgs)\n+        }\n+        val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+          new ArrayBuffer()\n+        var currentPart: Map[String, Option[String]] = null\n+        parts.map {\n+          case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+            if (currentPart != null) {\n+              partitions += ((currentPart, None))\n+            }\n+            currentPart = parsePartitionSpec(t).get\n+          case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+            val location = unquoteString(loc.text)\n+            if (currentPart != null) {\n+              partitions += ((currentPart, Some(location)))\n+              currentPart = null\n+            } else {\n+              // We should not reach here\n+              throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+            }\n+        }\n+        if (currentPart != null) {\n+          partitions += ((currentPart, None))\n+        }\n+        AlterTableAddPartition(tableIdent, partitions, allowExisting)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_RENAMEPART\", partArg :: Nil) :: _ =>\n+        val Some(newPartition) = parsePartitionSpec(partArg)\n+        AlterTableRenamePartition(tableIdent, partition.get, newPartition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\","
  }],
  "prId": 11573
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Error message could be better, e.g.: `Unsupported ALTER TABLE command: ....`?\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-08T09:51:01Z",
    "diffHunk": "@@ -0,0 +1,410 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(v1: ASTNode): LogicalPlan = {\n+    v1.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: restNodes =>\n+        val tableIdent: TableIdentifier = extractTableIdent(tabName)\n+        val partitionSpec = getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+        val partition = partitionSpec.flatMap(parsePartitionSpec)\n+        matchAlterTableCommands(v1, restNodes, tableIdent, partition)\n+      case _ =>\n+        throw new AnalysisException(s\"Could not parse alter table command: '${v1.text}'\")\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  private def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), Some(cleanAndUnquoteString(constant.text)))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (cleanAndUnquoteString(ident.text), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  private def extractTableProps(node: ASTNode): Map[String, Option[String]] = {\n+    node match {\n+      case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+        propsList.flatMap {\n+          case Token(\"TOK_TABLEPROPLIST\", props) =>\n+            props.map {\n+              case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                (k, None)\n+              case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+                val k = cleanAndUnquoteString(key.text)\n+                val v = cleanAndUnquoteString(value.text)\n+                (k, Some(v))\n+            }\n+        }.toMap\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Expected table properties in alter table command: '${node.text}'\")\n+    }\n+  }\n+\n+  // TODO: This method is massive. Break it down. Also, add some comments...\n+  private def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = {\n+    nodes match {\n+      case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: _ =>\n+        val renamedTable = getClause(\"TOK_TABNAME\", renameArgs)\n+        val renamedTableIdent: TableIdentifier = extractTableIdent(renamedTable)\n+        AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: _ =>\n+        val setTableProperties = extractTableProps(args.head)\n+        AlterTableSetProperties(\n+          tableIdent,\n+          setTableProperties)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: _ =>\n+        val dropTableProperties = extractTableProps(args.head)\n+        val allowExisting = getClauseOption(\"TOK_IFEXISTS\", args)\n+        AlterTableDropProperties(\n+          tableIdent,\n+          dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERIALIZER\", Token(serdeClassName, Nil) :: serdeArgs) :: _ =>\n+        // When SET SERDE serde_classname WITH SERDEPROPERTIES, this is None\n+        val serdeProperties: Option[Map[String, Option[String]]] =\n+          serdeArgs.headOption.map(extractTableProps)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          Some(cleanAndUnquoteString(serdeClassName)),\n+          serdeProperties,\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: _ =>\n+        val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+        AlterTableSerDeProperties(\n+          tableIdent,\n+          None,\n+          Some(serdeProperties),\n+          partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) :: _ =>\n+        val (buckets, noClustered, noSorted) = clusterAndSoryByArgs match {\n+          case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgsHead :: bucketArgs) =>\n+            val bucketCols = bucketArgsHead.children.map(_.text)\n+            val (sortCols, sortDirections, numBuckets) = {\n+              if (bucketArgs.head.text == \"TOK_TABCOLNAME\") {\n+                val (cols, directions) = bucketArgs.head.children.map {\n+                  case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Ascending)\n+                  case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                    (colName, Descending)\n+                }.unzip\n+                (cols, directions, bucketArgs.last.text.toInt)\n+              } else {\n+                (Nil, Nil, bucketArgs.head.text.toInt)\n+              }\n+            }\n+            val bucketSpec = BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)\n+            (Some(bucketSpec), false, false)\n+          case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+            (None, true, false)\n+          case Token(\"TOK_NOT_SORTED\", Nil) =>\n+            (None, false, true)\n+        }\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered,\n+          noSorted)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: _ =>\n+        val num = bucketNum.toInt\n+        val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+        AlterTableStoreProperties(\n+          tableIdent,\n+          buckets,\n+          noClustered = false,\n+          noSorted = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Nil) :: _ =>\n+        // ALTER TABLE table_name NOT SKEWED\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = true,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+        // ALTER TABLE table_name NOT STORED AS DIRECTORIES\n+        AlterTableSkewed(\n+          tableIdent,\n+          Nil,\n+          Nil,\n+          storedAsDirs = false,\n+          notSkewed = false,\n+          notStoredAsDirs = true)(node.source)\n+\n+      case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: _ =>\n+        val skewedArgs = tableSkewed match {\n+          case Token(\"TOK_ALTERTABLE_SKEWED\", args :: Nil) =>\n+            args match {\n+              case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+                val cols = skewedCols.children.map(n => cleanAndUnquoteString(n.text))\n+                val values = skewedValues match {\n+                  case Token(\"TOK_TABCOLVALUE\", colVal) =>\n+                    Seq(colVal.map(n => cleanAndUnquoteString(n.text)))\n+                  case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                    pairs.map {\n+                      case Token(\"TOK_TABCOLVALUES\", colVals :: Nil) =>\n+                        colVals match {\n+                          case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                            vals.map(n => cleanAndUnquoteString(n.text))\n+                        }\n+                    }\n+                }\n+\n+                val storedAsDirs = stored match {\n+                  case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                  case _ => false\n+                }\n+\n+                (cols, values, storedAsDirs)\n+            }\n+        }\n+        val (cols, values, storedAsDirs) = skewedArgs\n+        AlterTableSkewed(\n+          tableIdent,\n+          cols,\n+          values,\n+          storedAsDirs,\n+          notSkewed = false,\n+          notStoredAsDirs = false)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\",\n+      Token(\"TOK_SKEWED_LOCATIONS\",\n+      Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) :: Nil) :: Nil) :: _ =>\n+        val skewedMaps = locationMaps.map {\n+          case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+            val k = key match {\n+              case Token(const, Nil) => Seq(cleanAndUnquoteString(const))\n+              case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                values match {\n+                  case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                    vals.map(n => cleanAndUnquoteString(n.text))\n+                }\n+            }\n+            (k, cleanAndUnquoteString(value.text))\n+        }.toMap\n+        AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: _ =>\n+        val (allowExisting, parts) = addPartsArgs match {\n+          case Token(\"TOK_IFNOTEXISTS\", Nil) :: others => (true, others)\n+          case _ => (false, addPartsArgs)\n+        }\n+        val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+          new ArrayBuffer()\n+        var currentPart: Map[String, Option[String]] = null\n+        parts.map {\n+          case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+            if (currentPart != null) {\n+              partitions += ((currentPart, None))\n+            }\n+            currentPart = parsePartitionSpec(t).get\n+          case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+            val location = unquoteString(loc.text)\n+            if (currentPart != null) {\n+              partitions += ((currentPart, Some(location)))\n+              currentPart = null\n+            } else {\n+              // We should not reach here\n+              throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+            }\n+        }\n+        if (currentPart != null) {\n+          partitions += ((currentPart, None))\n+        }\n+        AlterTableAddPartition(tableIdent, partitions, allowExisting)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_RENAMEPART\", partArg :: Nil) :: _ =>\n+        val Some(newPartition) = parsePartitionSpec(partArg)\n+        AlterTableRenamePartition(tableIdent, partition.get, newPartition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\",\n+      (p @ Token(\"TOK_PARTSPEC\", _)) :: (t @ Token(\"TOK_TABNAME\", _)) :: Nil) :: _ =>\n+        val Some(partition) = parsePartitionSpec(p)\n+        val fromTableIdent = extractTableIdent(t)\n+        AlterTableExchangePartition(tableIdent, fromTableIdent, partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_DROPPARTS\", args) :: _ =>\n+        val parts = args.collect {\n+          case Token(\"TOK_PARTSPEC\", partitions) =>\n+            partitions.map {\n+              case Token(\"TOK_PARTVAL\", ident :: op :: constant :: Nil) =>\n+                (cleanAndUnquoteString(ident.text),\n+                  op.text, cleanAndUnquoteString(constant.text))\n+            }\n+        }\n+        val allowExisting = getClauseOption(\"TOK_IFEXISTS\", args).isDefined\n+        val purge = getClauseOption(\"PURGE\", args)\n+        val replication = getClauseOption(\"TOK_REPLICATION\", args).map {\n+          case Token(\"TOK_REPLICATION\", replId :: metadata) =>\n+            (cleanAndUnquoteString(replId.text), metadata.nonEmpty)\n+        }\n+        AlterTableDropPartition(\n+          tableIdent,\n+          parts,\n+          allowExisting,\n+          purge.isDefined,\n+          replication)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_ARCHIVE\", partArg :: Nil) :: _ =>\n+        val Some(partition) = parsePartitionSpec(partArg)\n+        AlterTableArchivePartition(tableIdent, partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_UNARCHIVE\", partArg :: Nil) :: _ =>\n+        val Some(partition) = parsePartitionSpec(partArg)\n+        AlterTableUnarchivePartition(tableIdent, partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_FILEFORMAT\", args) :: _ =>\n+        val Seq(fileFormat, genericFormat) =\n+          getClauses(Seq(\"TOK_TABLEFILEFORMAT\", \"TOK_FILEFORMAT_GENERIC\"),\n+            args)\n+        val fFormat = fileFormat.map(_.children.map(n => cleanAndUnquoteString(n.text)))\n+        val gFormat = genericFormat.map(f => cleanAndUnquoteString(f.children(0).text))\n+        AlterTableSetFileFormat(tableIdent, partition, fFormat, gFormat)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_LOCATION\", Token(loc, Nil) :: Nil) :: _ =>\n+        AlterTableSetLocation(tableIdent, partition, cleanAndUnquoteString(loc))(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_TOUCH\", args) :: _ =>\n+        val part = getClauseOption(\"TOK_PARTSPEC\", args).flatMap(parsePartitionSpec)\n+        AlterTableTouch(tableIdent, part)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_COMPACT\", Token(compactType, Nil) :: Nil) :: _ =>\n+        AlterTableCompact(tableIdent, partition, cleanAndUnquoteString(compactType))(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_MERGEFILES\", _) :: _ =>\n+        AlterTableMerge(tableIdent, partition)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_RENAMECOL\", args) :: _ =>\n+        val oldName = args(0).text\n+        val newName = args(1).text\n+        val dataType = nodeToDataType(args(2))\n+        val afterPos =\n+          getClauseOption(\"TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION\", args)\n+        val afterPosCol = afterPos.map { ap =>\n+          ap.children match {\n+            case Token(col, Nil) :: Nil => col\n+            case _ => null\n+          }\n+        }\n+        val restrict = getClauseOption(\"TOK_RESTRICT\", args)\n+        val cascade = getClauseOption(\"TOK_CASCADE\", args)\n+        val comment = if (args.size > 3) {\n+          args(3) match {\n+            case Token(commentStr, Nil)\n+              if commentStr != \"TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION\" &&\n+                commentStr != \"TOK_RESTRICT\" && commentStr != \"TOK_CASCADE\" =>\n+              Some(cleanAndUnquoteString(commentStr))\n+            case _ =>\n+              None\n+          }\n+        } else {\n+          None\n+        }\n+        AlterTableChangeCol(\n+          tableIdent,\n+          partition,\n+          oldName,\n+          newName,\n+          dataType,\n+          comment,\n+          afterPos.isDefined,\n+          afterPosCol,\n+          restrict.isDefined,\n+          cascade.isDefined)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_ADDCOLS\", args) :: _ =>\n+        val tableCols = getClause(\"TOK_TABCOLLIST\", args)\n+        val columns = tableCols match {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+        val restrict = getClauseOption(\"TOK_RESTRICT\", args)\n+        val cascade = getClauseOption(\"TOK_CASCADE\", args)\n+        AlterTableAddCol(\n+          tableIdent,\n+          partition,\n+          columns,\n+          restrict.isDefined,\n+          cascade.isDefined)(node.source)\n+\n+      case Token(\"TOK_ALTERTABLE_REPLACECOLS\", args) :: _ =>\n+        val tableCols = getClause(\"TOK_TABCOLLIST\", args)\n+        val columns = tableCols match {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+        val restrict = getClauseOption(\"TOK_RESTRICT\", args)\n+        val cascade = getClauseOption(\"TOK_CASCADE\", args)\n+        AlterTableReplaceCol(\n+          tableIdent,\n+          partition,\n+          columns,\n+          restrict.isDefined,\n+          cascade.isDefined)(node.source)\n+\n+      case _ =>\n+        throw new AnalysisException(\n+          s\"Unexpected children nodes in alter table command: '${node.text}'\")"
  }],
  "prId": 11573
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Maybe it will be good to provide a concrete example? Is it caused by what a user types?\n",
    "commit": "bd91b0f3c850da796b22c7e575658625d2486057",
    "createdAt": "2016-03-11T21:43:33Z",
    "diffHunk": "@@ -0,0 +1,428 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.command\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.catalog.ExternalCatalog.TablePartitionSpec\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending, SortDirection}\n+import org.apache.spark.sql.catalyst.parser._\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Helper object to parse alter table commands.\n+ */\n+object AlterTableCommandParser {\n+  import ParserUtils._\n+\n+  /**\n+   * Parse the given node assuming it is an alter table command.\n+   */\n+  def parse(node: ASTNode): LogicalPlan = {\n+    node.children match {\n+      case (tabName @ Token(\"TOK_TABNAME\", _)) :: otherNodes =>\n+        val tableIdent = extractTableIdent(tabName)\n+        val partSpec = getClauseOption(\"TOK_PARTSPEC\", node.children).map(parsePartitionSpec)\n+        matchAlterTableCommands(node, otherNodes, tableIdent, partSpec)\n+      case _ =>\n+        parseFailed(\"Could not parse ALTER TABLE command\", node)\n+    }\n+  }\n+\n+  private def cleanAndUnquoteString(s: String): String = {\n+    cleanIdentifier(unquoteString(s))\n+  }\n+\n+  /**\n+   * Extract partition spec from the given [[ASTNode]] as a map, assuming it exists.\n+   *\n+   * Expected format:\n+   *   +- TOK_PARTSPEC\n+   *      :- TOK_PARTVAL\n+   *      :  :- dt\n+   *      :  +- '2008-08-08'\n+   *      +- TOK_PARTVAL\n+   *         :- country\n+   *         +- 'us'\n+   */\n+  private def parsePartitionSpec(node: ASTNode): Map[String, String] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        partitions.map {\n+          // Note: sometimes there's a \"=\", \"<\" or \">\" between the key and the value",
    "line": 71
  }],
  "prId": 11573
}]