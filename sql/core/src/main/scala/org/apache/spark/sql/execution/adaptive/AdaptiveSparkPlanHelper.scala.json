[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit: `allSubqueries`?",
    "commit": "6401d9cf25e8a9d1aec96c9478fe01741de82f12",
    "createdAt": "2019-09-12T08:36:38Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * This class provides utility methods related to tree traversal of an [[AdaptiveSparkPlanExec]]\n+ * plan. Unlike their counterparts in [[org.apache.spark.sql.catalyst.trees.TreeNode]] or\n+ * [[org.apache.spark.sql.catalyst.plans.QueryPlan]], these methods traverse down leaf nodes of\n+ * adaptive plans, i.e., [[AdaptiveSparkPlanExec]] and [[QueryStageExec]].\n+ */\n+trait AdaptiveSparkPlanHelper {\n+\n+  /**\n+   * Find the first [[SparkPlan]] that satisfies the condition specified by `f`.\n+   * The condition is recursively applied to this node and all of its children (pre-order).\n+   */\n+  def find(p: SparkPlan)(f: SparkPlan => Boolean): Option[SparkPlan] = if (f(p)) {\n+    Some(p)\n+  } else {\n+    allChildren(p).foldLeft(Option.empty[SparkPlan]) { (l, r) => l.orElse(find(r)(f)) }\n+  }\n+\n+  /**\n+   * Runs the given function on this node and then recursively on children.\n+   * @param f the function to be applied to each node in the tree.\n+   */\n+  def foreach(p: SparkPlan)(f: SparkPlan => Unit): Unit = {\n+    f(p)\n+    allChildren(p).foreach(foreach(_)(f))\n+  }\n+\n+  /**\n+   * Runs the given function recursively on children then on this node.\n+   * @param f the function to be applied to each node in the tree.\n+   */\n+  def foreachUp(p: SparkPlan)(f: SparkPlan => Unit): Unit = {\n+    allChildren(p).foreach(foreachUp(_)(f))\n+    f(p)\n+  }\n+\n+  /**\n+   * Returns a Seq containing the result of applying the given function to each\n+   * node in this tree in a preorder traversal.\n+   * @param f the function to be applied.\n+   */\n+  def map[A](p: SparkPlan)(f: SparkPlan => A): Seq[A] = {\n+    val ret = new collection.mutable.ArrayBuffer[A]()\n+    foreach(p)(ret += f(_))\n+    ret\n+  }\n+\n+  /**\n+   * Returns a Seq by applying a function to all nodes in this tree and using the elements of the\n+   * resulting collections.\n+   */\n+  def flatMap[A](p: SparkPlan)(f: SparkPlan => TraversableOnce[A]): Seq[A] = {\n+    val ret = new collection.mutable.ArrayBuffer[A]()\n+    foreach(p)(ret ++= f(_))\n+    ret\n+  }\n+\n+  /**\n+   * Returns a Seq containing the result of applying a partial function to all elements in this\n+   * tree on which the function is defined.\n+   */\n+  def collect[B](p: SparkPlan)(pf: PartialFunction[SparkPlan, B]): Seq[B] = {\n+    val ret = new collection.mutable.ArrayBuffer[B]()\n+    val lifted = pf.lift\n+    foreach(p)(node => lifted(node).foreach(ret.+=))\n+    ret\n+  }\n+\n+  /**\n+   * Returns a Seq containing the leaves in this tree.\n+   */\n+  def collectLeaves(p: SparkPlan): Seq[SparkPlan] = {\n+    collect(p) { case plan if allChildren(plan).isEmpty => plan }\n+  }\n+\n+  /**\n+   * Finds and returns the first [[SparkPlan]] of the tree for which the given partial function\n+   * is defined (pre-order), and applies the partial function to it.\n+   */\n+  def collectFirst[B](p: SparkPlan)(pf: PartialFunction[SparkPlan, B]): Option[B] = {\n+    val lifted = pf.lift\n+    lifted(p).orElse {\n+      allChildren(p).foldLeft(Option.empty[B]) { (l, r) => l.orElse(collectFirst(r)(pf)) }\n+    }\n+  }\n+\n+  /**\n+   * Returns a sequence containing the result of applying a partial function to all elements in this\n+   * plan, also considering all the plans in its (nested) subqueries\n+   */\n+  def collectInPlanAndSubqueries[B](p: SparkPlan)(f: PartialFunction[SparkPlan, B]): Seq[B] = {\n+    (p +: subqueriesAll(p)).flatMap(collect(_)(f))\n+  }\n+\n+  /**\n+   * Returns a sequence containing the subqueries in this plan, also including the (nested)\n+   * subquries in its children\n+   */\n+  def subqueriesAll(p: SparkPlan): Seq[SparkPlan] = {",
    "line": 120
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "nvm, this consistent with `QueryPlan.subqueriesAll`",
    "commit": "6401d9cf25e8a9d1aec96c9478fe01741de82f12",
    "createdAt": "2019-09-12T13:46:05Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * This class provides utility methods related to tree traversal of an [[AdaptiveSparkPlanExec]]\n+ * plan. Unlike their counterparts in [[org.apache.spark.sql.catalyst.trees.TreeNode]] or\n+ * [[org.apache.spark.sql.catalyst.plans.QueryPlan]], these methods traverse down leaf nodes of\n+ * adaptive plans, i.e., [[AdaptiveSparkPlanExec]] and [[QueryStageExec]].\n+ */\n+trait AdaptiveSparkPlanHelper {\n+\n+  /**\n+   * Find the first [[SparkPlan]] that satisfies the condition specified by `f`.\n+   * The condition is recursively applied to this node and all of its children (pre-order).\n+   */\n+  def find(p: SparkPlan)(f: SparkPlan => Boolean): Option[SparkPlan] = if (f(p)) {\n+    Some(p)\n+  } else {\n+    allChildren(p).foldLeft(Option.empty[SparkPlan]) { (l, r) => l.orElse(find(r)(f)) }\n+  }\n+\n+  /**\n+   * Runs the given function on this node and then recursively on children.\n+   * @param f the function to be applied to each node in the tree.\n+   */\n+  def foreach(p: SparkPlan)(f: SparkPlan => Unit): Unit = {\n+    f(p)\n+    allChildren(p).foreach(foreach(_)(f))\n+  }\n+\n+  /**\n+   * Runs the given function recursively on children then on this node.\n+   * @param f the function to be applied to each node in the tree.\n+   */\n+  def foreachUp(p: SparkPlan)(f: SparkPlan => Unit): Unit = {\n+    allChildren(p).foreach(foreachUp(_)(f))\n+    f(p)\n+  }\n+\n+  /**\n+   * Returns a Seq containing the result of applying the given function to each\n+   * node in this tree in a preorder traversal.\n+   * @param f the function to be applied.\n+   */\n+  def map[A](p: SparkPlan)(f: SparkPlan => A): Seq[A] = {\n+    val ret = new collection.mutable.ArrayBuffer[A]()\n+    foreach(p)(ret += f(_))\n+    ret\n+  }\n+\n+  /**\n+   * Returns a Seq by applying a function to all nodes in this tree and using the elements of the\n+   * resulting collections.\n+   */\n+  def flatMap[A](p: SparkPlan)(f: SparkPlan => TraversableOnce[A]): Seq[A] = {\n+    val ret = new collection.mutable.ArrayBuffer[A]()\n+    foreach(p)(ret ++= f(_))\n+    ret\n+  }\n+\n+  /**\n+   * Returns a Seq containing the result of applying a partial function to all elements in this\n+   * tree on which the function is defined.\n+   */\n+  def collect[B](p: SparkPlan)(pf: PartialFunction[SparkPlan, B]): Seq[B] = {\n+    val ret = new collection.mutable.ArrayBuffer[B]()\n+    val lifted = pf.lift\n+    foreach(p)(node => lifted(node).foreach(ret.+=))\n+    ret\n+  }\n+\n+  /**\n+   * Returns a Seq containing the leaves in this tree.\n+   */\n+  def collectLeaves(p: SparkPlan): Seq[SparkPlan] = {\n+    collect(p) { case plan if allChildren(plan).isEmpty => plan }\n+  }\n+\n+  /**\n+   * Finds and returns the first [[SparkPlan]] of the tree for which the given partial function\n+   * is defined (pre-order), and applies the partial function to it.\n+   */\n+  def collectFirst[B](p: SparkPlan)(pf: PartialFunction[SparkPlan, B]): Option[B] = {\n+    val lifted = pf.lift\n+    lifted(p).orElse {\n+      allChildren(p).foldLeft(Option.empty[B]) { (l, r) => l.orElse(collectFirst(r)(pf)) }\n+    }\n+  }\n+\n+  /**\n+   * Returns a sequence containing the result of applying a partial function to all elements in this\n+   * plan, also considering all the plans in its (nested) subqueries\n+   */\n+  def collectInPlanAndSubqueries[B](p: SparkPlan)(f: PartialFunction[SparkPlan, B]): Seq[B] = {\n+    (p +: subqueriesAll(p)).flatMap(collect(_)(f))\n+  }\n+\n+  /**\n+   * Returns a sequence containing the subqueries in this plan, also including the (nested)\n+   * subquries in its children\n+   */\n+  def subqueriesAll(p: SparkPlan): Seq[SparkPlan] = {",
    "line": 120
  }],
  "prId": 25764
}]