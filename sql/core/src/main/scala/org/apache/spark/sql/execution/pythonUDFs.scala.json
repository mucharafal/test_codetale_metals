[{
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "I think we should keep the `copy()` here.\n",
    "commit": "5e55bf60018e53fc67a153e39f3ae028b4c5fd8f",
    "createdAt": "2015-09-20T03:33:18Z",
    "diffHunk": "@@ -342,51 +348,57 @@ case class BatchPythonEvaluation(udf: PythonUDF, output: Seq[Attribute], child:\n   override def canProcessSafeRows: Boolean = true\n \n   protected override def doExecute(): RDD[InternalRow] = {\n-    val childResults = child.execute().map(_.copy())\n+    val inputRDD = child.execute()"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "good idea\n",
    "commit": "5e55bf60018e53fc67a153e39f3ae028b4c5fd8f",
    "createdAt": "2015-09-20T04:10:34Z",
    "diffHunk": "@@ -342,51 +348,57 @@ case class BatchPythonEvaluation(udf: PythonUDF, output: Seq[Attribute], child:\n   override def canProcessSafeRows: Boolean = true\n \n   protected override def doExecute(): RDD[InternalRow] = {\n-    val childResults = child.execute().map(_.copy())\n+    val inputRDD = child.execute()"
  }],
  "prId": 8835
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Could we mitigate this by using a [LinkedBlockingDeque](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/LinkedBlockingDeque.html) to have the producer-side block on inserts once the queue grows to a certain size?\n",
    "commit": "5e55bf60018e53fc67a153e39f3ae028b4c5fd8f",
    "createdAt": "2015-09-22T19:34:04Z",
    "diffHunk": "@@ -329,7 +329,13 @@ case class EvaluatePython(\n /**\n  * :: DeveloperApi ::\n  * Uses PythonRDD to evaluate a [[PythonUDF]], one partition of tuples at a time.\n- * The input data is zipped with the result of the udf evaluation.\n+ *\n+ * Python evaluation works by sending the necessary (projected) input data via a socket to an\n+ * external Python process, and combine the result from the Python process with the original row.\n+ *\n+ * For each row we send to Python, we also put it in a queue. For each output row from Python,\n+ * we drain the queue to find the original input row. Note that if the Python process is way too\n+ * slow, this could lead to the queue growing unbounded and eventually run out of memory.",
    "line": 29
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Per discussion offline, the only scenario where the queue can grow really large is when the Python buffer size has been configured to be very large and the UDF result rows are very small. As a result, I think that this comment should be expanded / clarified, but this can take place in a followup PR.\n",
    "commit": "5e55bf60018e53fc67a153e39f3ae028b4c5fd8f",
    "createdAt": "2015-09-22T21:01:16Z",
    "diffHunk": "@@ -329,7 +329,13 @@ case class EvaluatePython(\n /**\n  * :: DeveloperApi ::\n  * Uses PythonRDD to evaluate a [[PythonUDF]], one partition of tuples at a time.\n- * The input data is zipped with the result of the udf evaluation.\n+ *\n+ * Python evaluation works by sending the necessary (projected) input data via a socket to an\n+ * external Python process, and combine the result from the Python process with the original row.\n+ *\n+ * For each row we send to Python, we also put it in a queue. For each output row from Python,\n+ * we drain the queue to find the original input row. Note that if the Python process is way too\n+ * slow, this could lead to the queue growing unbounded and eventually run out of memory.",
    "line": 29
  }],
  "prId": 8835
}]