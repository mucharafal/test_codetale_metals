[{
  "comments": [{
    "author": {
      "login": "imback82"
    },
    "body": "@rdblue There is no APIs to get `isTemporary`. Where would be the right place to introduce it?",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-07-24T19:25:49Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.{Identifier, TableCatalog}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.plans.ShowTablesSchema\n+import org.apache.spark.sql.execution.LeafExecNode\n+import org.apache.spark.sql.types.{BooleanType, StringType, StructField, StructType}\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(catalog: TableCatalog, ident: Identifier, pattern: Option[String])\n+    extends LeafExecNode {\n+  // TODO: \"pattern\" is not yet supported.\n+  require(pattern.isEmpty)\n+\n+  override def output: Seq[AttributeReference] = ShowTablesSchema.attributes()\n+\n+  override protected def doExecute(): RDD[InternalRow] = {\n+    val rows = new ArrayBuffer[InternalRow]()\n+    val encoder = RowEncoder(ShowTablesSchema.SHOW_TABLES_SCHEMA).resolveAndBind()\n+\n+    val tables = catalog.listTables(ident.namespace() :+ ident.name())\n+    tables.map { table =>\n+      rows += encoder.toRow(\n+        new GenericRowWithSchema(\n+          // TODO: there is no v2 catalog API to retrieve 'isTemporary',\n+          //  and it is set to true for time being.\n+          Array(\"\", table.name(), true),"
  }],
  "prId": 25247
}, {
  "comments": [{
    "author": {
      "login": "imback82"
    },
    "body": "This will be implemented in `doExecute()` as discussed in the weekly sync.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-07-25T22:26:43Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.{Identifier, TableCatalog}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.plans.ShowTablesSchema\n+import org.apache.spark.sql.execution.LeafExecNode\n+import org.apache.spark.sql.types.{BooleanType, StringType, StructField, StructType}\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(catalog: TableCatalog, ident: Identifier, pattern: Option[String])\n+    extends LeafExecNode {\n+  // TODO: \"pattern\" is not yet supported."
  }],
  "prId": 25247
}, {
  "comments": [{
    "author": {
      "login": "imback82"
    },
    "body": "@rdblue does it make sense to use the whole namespace as a database name?\r\n```\r\nCREATE TABLE testcat.n1.n2.db.table_name (id bigint, data string) USING foo\r\n```\r\nShould it display the database as `db` , `n1.n2.db` or `testcat.n1.n2`?",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-07-29T22:11:52Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.{Identifier, TableCatalog}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.plans.ShowTablesSchema\n+import org.apache.spark.sql.catalyst.util.StringUtils\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(catalog: TableCatalog, ident: Identifier, pattern: Option[String])\n+  extends LeafExecNode {\n+  override def output: Seq[AttributeReference] = ShowTablesSchema.attributes()\n+\n+  override protected def doExecute(): RDD[InternalRow] = {\n+    val rows = new ArrayBuffer[InternalRow]()\n+    val encoder = RowEncoder(ShowTablesSchema.schema).resolveAndBind()\n+\n+    val tables = catalog.listTables(ident.namespace() :+ ident.name())\n+    tables.map { table =>\n+      if (pattern.map(StringUtils.filterPattern(Seq(table.name()), _).nonEmpty).getOrElse(true)) {\n+        rows += encoder.toRow(\n+          new GenericRowWithSchema(\n+            // TODO: there is no v2 catalog API to retrieve 'isTemporary',\n+            //  and it is set to false for the time being.\n+            Array(table.namespace().mkString(\".\"), table.name(), false),"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "I think it should use the full namespace, `n1.n2.db`, without the catalog.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-07-31T23:12:40Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.{Identifier, TableCatalog}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.plans.ShowTablesSchema\n+import org.apache.spark.sql.catalyst.util.StringUtils\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(catalog: TableCatalog, ident: Identifier, pattern: Option[String])\n+  extends LeafExecNode {\n+  override def output: Seq[AttributeReference] = ShowTablesSchema.attributes()\n+\n+  override protected def doExecute(): RDD[InternalRow] = {\n+    val rows = new ArrayBuffer[InternalRow]()\n+    val encoder = RowEncoder(ShowTablesSchema.schema).resolveAndBind()\n+\n+    val tables = catalog.listTables(ident.namespace() :+ ident.name())\n+    tables.map { table =>\n+      if (pattern.map(StringUtils.filterPattern(Seq(table.name()), _).nonEmpty).getOrElse(true)) {\n+        rows += encoder.toRow(\n+          new GenericRowWithSchema(\n+            // TODO: there is no v2 catalog API to retrieve 'isTemporary',\n+            //  and it is set to false for the time being.\n+            Array(table.namespace().mkString(\".\"), table.name(), false),"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "Also, use `quoted` from `CatalogV2Implicits` instead of `mkString` to ensure that the names are escaped.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-07-31T23:13:29Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.{Identifier, TableCatalog}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.plans.ShowTablesSchema\n+import org.apache.spark.sql.catalyst.util.StringUtils\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(catalog: TableCatalog, ident: Identifier, pattern: Option[String])\n+  extends LeafExecNode {\n+  override def output: Seq[AttributeReference] = ShowTablesSchema.attributes()\n+\n+  override protected def doExecute(): RDD[InternalRow] = {\n+    val rows = new ArrayBuffer[InternalRow]()\n+    val encoder = RowEncoder(ShowTablesSchema.schema).resolveAndBind()\n+\n+    val tables = catalog.listTables(ident.namespace() :+ ident.name())\n+    tables.map { table =>\n+      if (pattern.map(StringUtils.filterPattern(Seq(table.name()), _).nonEmpty).getOrElse(true)) {\n+        rows += encoder.toRow(\n+          new GenericRowWithSchema(\n+            // TODO: there is no v2 catalog API to retrieve 'isTemporary',\n+            //  and it is set to false for the time being.\n+            Array(table.namespace().mkString(\".\"), table.name(), false),"
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "Thanks. Changed it to use `quoted`.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-01T18:13:00Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.{Identifier, TableCatalog}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.plans.ShowTablesSchema\n+import org.apache.spark.sql.catalyst.util.StringUtils\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(catalog: TableCatalog, ident: Identifier, pattern: Option[String])\n+  extends LeafExecNode {\n+  override def output: Seq[AttributeReference] = ShowTablesSchema.attributes()\n+\n+  override protected def doExecute(): RDD[InternalRow] = {\n+    val rows = new ArrayBuffer[InternalRow]()\n+    val encoder = RowEncoder(ShowTablesSchema.schema).resolveAndBind()\n+\n+    val tables = catalog.listTables(ident.namespace() :+ ident.name())\n+    tables.map { table =>\n+      if (pattern.map(StringUtils.filterPattern(Seq(table.name()), _).nonEmpty).getOrElse(true)) {\n+        rows += encoder.toRow(\n+          new GenericRowWithSchema(\n+            // TODO: there is no v2 catalog API to retrieve 'isTemporary',\n+            //  and it is set to false for the time being.\n+            Array(table.namespace().mkString(\".\"), table.name(), false),"
  }],
  "prId": 25247
}, {
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "Exec nodes should use the same attributes as the logical plan nodes they are created from. I think this should have an additional param for `output: Seq[Attribute]`.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-02T18:24:43Z",
    "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.{Identifier, TableCatalog}\n+import org.apache.spark.sql.catalog.v2.CatalogV2Implicits.NamespaceHelper\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.plans.ShowTablesSchema\n+import org.apache.spark.sql.catalyst.util.StringUtils\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(catalog: TableCatalog, ident: Identifier, pattern: Option[String])\n+  extends LeafExecNode {\n+  override def output: Seq[AttributeReference] = ShowTablesSchema.attributes()"
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "Then, this needs to be updated as well? https://github.com/apache/spark/pull/25040/files#diff-2e91a80e6e602695acbfe626b54eba50R34",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-03T06:37:36Z",
    "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.{Identifier, TableCatalog}\n+import org.apache.spark.sql.catalog.v2.CatalogV2Implicits.NamespaceHelper\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.plans.ShowTablesSchema\n+import org.apache.spark.sql.catalyst.util.StringUtils\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(catalog: TableCatalog, ident: Identifier, pattern: Option[String])\n+  extends LeafExecNode {\n+  override def output: Seq[AttributeReference] = ShowTablesSchema.attributes()"
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "Fixed this and `ShowTablesStatement` -> `ShowTables` as well. Now the expression ids are the same across the plans:\r\n```\r\n== Analyzed Logical Plan ==\r\ndatabase: string, tableName: string, isTemporary: boolean\r\nShowTables [database#19, tableName#20, isTemporary#21], org.apache.spark.sql.sources.v2.TestInMemoryTableCatalog@3ce7394f, `db`\r\n\r\n== Optimized Logical Plan ==\r\nShowTables [database#19, tableName#20, isTemporary#21], org.apache.spark.sql.sources.v2.TestInMemoryTableCatalog@3ce7394f, `db`\r\n\r\n== Physical Plan ==\r\nShowTables [database#19, tableName#20, isTemporary#21], org.apache.spark.sql.sources.v2.TestInMemoryTableCatalog@3ce7394f, `db`\r\n```",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-04T02:33:05Z",
    "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.{Identifier, TableCatalog}\n+import org.apache.spark.sql.catalog.v2.CatalogV2Implicits.NamespaceHelper\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.plans.ShowTablesSchema\n+import org.apache.spark.sql.catalyst.util.StringUtils\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(catalog: TableCatalog, ident: Identifier, pattern: Option[String])\n+  extends LeafExecNode {\n+  override def output: Seq[AttributeReference] = ShowTablesSchema.attributes()"
  }],
  "prId": 25247
}, {
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "This can use `schema` instead of `ShowTablesSchema.schema`. The latter doesn't use this node's attributes.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-02T18:25:29Z",
    "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.{Identifier, TableCatalog}\n+import org.apache.spark.sql.catalog.v2.CatalogV2Implicits.NamespaceHelper\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.plans.ShowTablesSchema\n+import org.apache.spark.sql.catalyst.util.StringUtils\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(catalog: TableCatalog, ident: Identifier, pattern: Option[String])\n+  extends LeafExecNode {\n+  override def output: Seq[AttributeReference] = ShowTablesSchema.attributes()\n+\n+  override protected def doExecute(): RDD[InternalRow] = {\n+    val rows = new ArrayBuffer[InternalRow]()\n+    val encoder = RowEncoder(ShowTablesSchema.schema).resolveAndBind()\n+\n+    val tables = catalog.listTables(ident.namespace() :+ ident.name())\n+    tables.map { table =>\n+      if (pattern.map(StringUtils.filterPattern(Seq(table.name()), _).nonEmpty).getOrElse(true)) {\n+        rows += encoder\n+          .toRow(\n+            new GenericRowWithSchema(\n+              // TODO: there is no v2 catalog API to retrieve 'isTemporary',\n+              //  and it is set to false for the time being.\n+              Array(table.namespace().quoted, table.name(), false),\n+              ShowTablesSchema.schema))"
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "Fixed.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-04T01:11:47Z",
    "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.{Identifier, TableCatalog}\n+import org.apache.spark.sql.catalog.v2.CatalogV2Implicits.NamespaceHelper\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.plans.ShowTablesSchema\n+import org.apache.spark.sql.catalyst.util.StringUtils\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(catalog: TableCatalog, ident: Identifier, pattern: Option[String])\n+  extends LeafExecNode {\n+  override def output: Seq[AttributeReference] = ShowTablesSchema.attributes()\n+\n+  override protected def doExecute(): RDD[InternalRow] = {\n+    val rows = new ArrayBuffer[InternalRow]()\n+    val encoder = RowEncoder(ShowTablesSchema.schema).resolveAndBind()\n+\n+    val tables = catalog.listTables(ident.namespace() :+ ident.name())\n+    tables.map { table =>\n+      if (pattern.map(StringUtils.filterPattern(Seq(table.name()), _).nonEmpty).getOrElse(true)) {\n+        rows += encoder\n+          .toRow(\n+            new GenericRowWithSchema(\n+              // TODO: there is no v2 catalog API to retrieve 'isTemporary',\n+              //  and it is set to false for the time being.\n+              Array(table.namespace().quoted, table.name(), false),\n+              ShowTablesSchema.schema))"
  }],
  "prId": 25247
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "not related to this PR, but this reminds me that, we should make sure the physical plan and corresponding logical plan have the same output attributes. Unfortunately, this is not true for `DescribeTableExec`. @imback82 do you have time to help fix it later?",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-23T01:59:52Z",
    "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.CatalogV2Implicits.NamespaceHelper\n+import org.apache.spark.sql.catalog.v2.TableCatalog\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.util.StringUtils\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(\n+    output: Seq[Attribute],",
    "line": 35
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "Yes. I will fix that.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-23T03:03:45Z",
    "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalog.v2.CatalogV2Implicits.NamespaceHelper\n+import org.apache.spark.sql.catalog.v2.TableCatalog\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.encoders.RowEncoder\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, GenericRowWithSchema}\n+import org.apache.spark.sql.catalyst.util.StringUtils\n+import org.apache.spark.sql.execution.LeafExecNode\n+\n+/**\n+ * Physical plan node for showing tables.\n+ */\n+case class ShowTablesExec(\n+    output: Seq[Attribute],",
    "line": 35
  }],
  "prId": 25247
}]