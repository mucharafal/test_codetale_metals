[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "why do we need this? since it is just \n\nmap(_...).distinct\n",
    "commit": "e251f87a830df9f40d523f00bbe14c174c91b2ae",
    "createdAt": "2015-10-22T01:26:50Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.catalyst.encoders.Encoder\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.execution.QueryExecution\n+\n+/**\n+ * A [[Dataset]] has been logically grouped by a user specified grouping key.  Users should not\n+ * construct a [[GroupedDataset]] directly, but should instead call `groupBy` on an existing\n+ * [[Dataset]].\n+ */\n+class GroupedDataset[K, T] private[sql](\n+    private val kEncoder: Encoder[K],\n+    private val tEncoder: Encoder[T],\n+    queryExecution: QueryExecution,\n+    private val dataAttributes: Seq[Attribute],\n+    private val groupingAttributes: Seq[Attribute]) extends Serializable {\n+\n+  private implicit def kEnc = kEncoder\n+  private implicit def tEnc = tEncoder\n+  private def logicalPlan = queryExecution.analyzed\n+  private def sqlContext = queryExecution.sqlContext\n+\n+  /**\n+   * Returns a [[Dataset]] that contains each unique key.\n+   */\n+  def keys: Dataset[K] = {",
    "line": 45
  }, {
    "author": {
      "login": "marmbrus"
    },
    "body": "We don't _need_ it, but its virtually free to implement efficiently, additionally:\n- [Scalding has it](https://github.com/twitter/scalding/wiki/Type-safe-api-reference#creating-groups-and-joining-cogrouping)\n- [PairRDD has it](https://spark.apache.org/docs/0.7.2/api/core/spark/PairRDDFunctions.html)\n",
    "commit": "e251f87a830df9f40d523f00bbe14c174c91b2ae",
    "createdAt": "2015-10-22T17:14:46Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.catalyst.encoders.Encoder\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.catalyst.plans.logical._\n+import org.apache.spark.sql.execution.QueryExecution\n+\n+/**\n+ * A [[Dataset]] has been logically grouped by a user specified grouping key.  Users should not\n+ * construct a [[GroupedDataset]] directly, but should instead call `groupBy` on an existing\n+ * [[Dataset]].\n+ */\n+class GroupedDataset[K, T] private[sql](\n+    private val kEncoder: Encoder[K],\n+    private val tEncoder: Encoder[T],\n+    queryExecution: QueryExecution,\n+    private val dataAttributes: Seq[Attribute],\n+    private val groupingAttributes: Seq[Attribute]) extends Serializable {\n+\n+  private implicit def kEnc = kEncoder\n+  private implicit def tEnc = tEncoder\n+  private def logicalPlan = queryExecution.analyzed\n+  private def sqlContext = queryExecution.sqlContext\n+\n+  /**\n+   * Returns a [[Dataset]] that contains each unique key.\n+   */\n+  def keys: Dataset[K] = {",
    "line": 45
  }],
  "prId": 9190
}]