[{
  "comments": [{
    "author": {
      "login": "SaintBacchus"
    },
    "body": "Nit: code format\n",
    "commit": "99b830584aafb53112b5bdd2d723080fa19baa54",
    "createdAt": "2016-10-11T06:00:48Z",
    "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import java.util.Arrays\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+class SkewCoalescedPartitioner(\n+        val parent: Partitioner,"
  }, {
    "author": {
      "login": "YuhuWang2002"
    },
    "body": "OK\n",
    "commit": "99b830584aafb53112b5bdd2d723080fa19baa54",
    "createdAt": "2016-10-11T12:16:08Z",
    "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import java.util.Arrays\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+class SkewCoalescedPartitioner(\n+        val parent: Partitioner,"
  }],
  "prId": 15297
}, {
  "comments": [{
    "author": {
      "login": "witgo"
    },
    "body": "`for(i <- 0 until partitionStartIndices.length )` -> `for (i <- partitionStartIndices.indices)`\n",
    "commit": "99b830584aafb53112b5bdd2d723080fa19baa54",
    "createdAt": "2016-10-12T01:28:12Z",
    "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import java.util.Arrays\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+class SkewCoalescedPartitioner(\n+        val parent: Partitioner,\n+        val partitionStartIndices: Array[(Int, Int)])\n+  extends Partitioner {\n+\n+  @transient private lazy val parentPartitionMapping: Array[Int] = {\n+    val n = parent.numPartitions\n+    val result = new Array[Int](n)\n+    for (i <- 0 until partitionStartIndices.length) {\n+      val start = partitionStartIndices(i)._2\n+      val end = if (i < partitionStartIndices.length - 1) partitionStartIndices(i + 1)._2 else n\n+      for (j <- start until end) {\n+        result(j) = i\n+      }\n+    }\n+    result\n+  }\n+\n+  override def numPartitions: Int = partitionStartIndices.length\n+\n+  override def getPartition(key: Any): Int = {\n+    parentPartitionMapping(parent.getPartition(key))\n+  }\n+\n+  override def equals(other: Any): Boolean = other match {\n+    case c: SkewCoalescedPartitioner =>\n+      c.parent == parent &&\n+        c.partitionStartIndices.zip(partitionStartIndices).\n+          forall( r => r match {\n+            case (x, y) => (x._1 == y._1 && x._2 == y._2)\n+            })\n+    case _ =>\n+      false\n+  }\n+\n+  override def hashCode(): Int = 31 * parent.hashCode() + partitionStartIndices.hashCode()\n+}\n+\n+ /**\n+  * if mapIndex is -1, same as ShuffledRowRDDPartition\n+  * if mapIndex > -1 ,only read one block of mappers.\n+  */\n+private final class SkewShuffledRowRDDPartition(\n+    val postShufflePartitionIndex: Int,\n+    val mapIndex: Int,\n+    val startPreShufflePartitionIndex: Int,\n+    val endPreShufflePartitionIndex: Int) extends Partition {\n+  override val index: Int = postShufflePartitionIndex\n+\n+  override def hashCode(): Int = postShufflePartitionIndex\n+\n+  override def equals(other: Any): Boolean = super.equals(other)\n+}\n+\n+ /**\n+  * only use for skew data join. In join case , need fetch the same partition of\n+  * left output and rigth output together. but when some partiton have bigger data than\n+  * other partitions, it occur data skew . in the case , we need a specialized RDD to handling this.\n+  * in skew partition side,we don't produce one partition, because one partition produce\n+  * one task deal so much data is too slaw . but produce per-stage mapping task num parititons.\n+  * one task only deal one mapper data. in other no skew side. In order to deal with the\n+  * corresponding skew partition , we need produce same partition per-stage parititon num\n+  * times.(Equivalent to broadcoast this partition)\n+  *\n+  * other no skew partition, then deal like ShuffledRowRDD\n+  */\n+class SkewShuffleRowRDD(\n+    var dependency1: ShuffleDependency[Int, InternalRow, InternalRow],\n+    partitionStartIndices: Array[(Int, Int, Int)])\n+  extends ShuffledRowRDD ( dependency1, None) {\n+\n+  private[this] val numPreShufflePartitions = dependency.partitioner.numPartitions\n+\n+  override def getPartitions: Array[Partition] = {\n+    val partitions = ArrayBuffer[Partition]()\n+    var partitionIndex = -1\n+    for(i <- 0 until partitionStartIndices.length ) {"
  }],
  "prId": 15297
}, {
  "comments": [{
    "author": {
      "login": "witgo"
    },
    "body": "`for (i <- 0 until partitionStartIndices.length)` ->`for (i <- partitionStartIndices.indices)`\n",
    "commit": "99b830584aafb53112b5bdd2d723080fa19baa54",
    "createdAt": "2016-10-12T01:30:45Z",
    "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import java.util.Arrays\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+class SkewCoalescedPartitioner(\n+        val parent: Partitioner,\n+        val partitionStartIndices: Array[(Int, Int)])\n+  extends Partitioner {\n+\n+  @transient private lazy val parentPartitionMapping: Array[Int] = {\n+    val n = parent.numPartitions\n+    val result = new Array[Int](n)\n+    for (i <- 0 until partitionStartIndices.length) {",
    "line": 42
  }],
  "prId": 15297
}]