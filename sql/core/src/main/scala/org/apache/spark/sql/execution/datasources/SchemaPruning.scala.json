[{
  "comments": [{
    "author": {
      "login": "gengliangwang"
    },
    "body": "`orgDataSchema` is a bit confusing. How about just `dataSchema`.",
    "commit": "3086d845eb6ef3debde872ae18548907262230b4",
    "createdAt": "2019-04-16T15:48:55Z",
    "diffHunk": "@@ -50,73 +50,62 @@ object SchemaPruning extends Rule[LogicalPlan] {\n       case op @ PhysicalOperation(projects, filters,\n           l @ LogicalRelation(hadoopFsRelation: HadoopFsRelation, _, _, _))\n         if canPruneRelation(hadoopFsRelation) =>\n-        val (normalizedProjects, normalizedFilters) =\n-          normalizeAttributeRefNames(l.output, projects, filters)\n-        val requestedRootFields = identifyRootFields(normalizedProjects, normalizedFilters)\n-\n-        // If requestedRootFields includes a nested field, continue. Otherwise,\n-        // return op\n-        if (requestedRootFields.exists { root: RootField => !root.derivedFromAtt }) {\n-          val dataSchema = hadoopFsRelation.dataSchema\n-          val prunedDataSchema = pruneDataSchema(dataSchema, requestedRootFields)\n-\n-          // If the data schema is different from the pruned data schema, continue. Otherwise,\n-          // return op. We effect this comparison by counting the number of \"leaf\" fields in\n-          // each schemata, assuming the fields in prunedDataSchema are a subset of the fields\n-          // in dataSchema.\n-          if (countLeaves(dataSchema) > countLeaves(prunedDataSchema)) {\n+\n+        prunePhysicalColumns(l.output, projects, filters, hadoopFsRelation.dataSchema,\n+          prunedDataSchema => {\n             val prunedHadoopRelation =\n               hadoopFsRelation.copy(dataSchema = prunedDataSchema)(hadoopFsRelation.sparkSession)\n-\n-            val prunedRelation = buildPrunedRelation(l, prunedHadoopRelation)\n-            val projectionOverSchema = ProjectionOverSchema(prunedDataSchema)\n-\n-            buildNewProjection(normalizedProjects, normalizedFilters, prunedRelation,\n-              projectionOverSchema)\n-          } else {\n-            op\n-          }\n-        } else {\n-          op\n-        }\n+            buildPrunedRelation(l, prunedHadoopRelation)\n+          }).getOrElse(op)\n \n       case op @ PhysicalOperation(projects, filters,\n           d @ DataSourceV2Relation(table: FileTable, output, _)) if canPruneTable(table) =>\n-        val (normalizedProjects, normalizedFilters) =\n-          normalizeAttributeRefNames(output, projects, filters)\n-        val requestedRootFields = identifyRootFields(normalizedProjects, normalizedFilters)\n-\n-        // If requestedRootFields includes a nested field, continue. Otherwise,\n-        // return op\n-        if (requestedRootFields.exists { root: RootField => !root.derivedFromAtt }) {\n-          val dataSchema = table.dataSchema\n-          val prunedDataSchema = pruneDataSchema(dataSchema, requestedRootFields)\n-\n-          // If the data schema is different from the pruned data schema, continue. Otherwise,\n-          // return op. We effect this comparison by counting the number of \"leaf\" fields in\n-          // each schemata, assuming the fields in prunedDataSchema are a subset of the fields\n-          // in dataSchema.\n-          if (countLeaves(dataSchema) > countLeaves(prunedDataSchema)) {\n+\n+        prunePhysicalColumns(output, projects, filters, table.dataSchema,\n+          prunedDataSchema => {\n             val prunedFileTable = table match {\n               case o: OrcTable => o.copy(userSpecifiedSchema = Some(prunedDataSchema))\n               case _ =>\n                 val message = s\"${table.formatName} data source doesn't support schema pruning.\"\n                 throw new AnalysisException(message)\n             }\n+            buildPrunedRelationV2(d, prunedFileTable)\n+          }).getOrElse(op)\n+    }\n \n-\n-            val prunedRelationV2 = buildPrunedRelationV2(d, prunedFileTable)\n-            val projectionOverSchema = ProjectionOverSchema(prunedDataSchema)\n-\n-            buildNewProjection(normalizedProjects, normalizedFilters, prunedRelationV2,\n-              projectionOverSchema)\n-          } else {\n-            op\n-          }\n-        } else {\n-          op\n-        }\n+  private def prunePhysicalColumns(\n+      output: Seq[AttributeReference],\n+      projects: Seq[NamedExpression],\n+      filters: Seq[Expression],\n+      orgDataSchema: StructType,"
  }],
  "prId": 24383
}, {
  "comments": [{
    "author": {
      "login": "gengliangwang"
    },
    "body": "Nit: Add comments about the return result.",
    "commit": "3086d845eb6ef3debde872ae18548907262230b4",
    "createdAt": "2019-04-16T15:50:47Z",
    "diffHunk": "@@ -50,73 +50,62 @@ object SchemaPruning extends Rule[LogicalPlan] {\n       case op @ PhysicalOperation(projects, filters,\n           l @ LogicalRelation(hadoopFsRelation: HadoopFsRelation, _, _, _))\n         if canPruneRelation(hadoopFsRelation) =>\n-        val (normalizedProjects, normalizedFilters) =\n-          normalizeAttributeRefNames(l.output, projects, filters)\n-        val requestedRootFields = identifyRootFields(normalizedProjects, normalizedFilters)\n-\n-        // If requestedRootFields includes a nested field, continue. Otherwise,\n-        // return op\n-        if (requestedRootFields.exists { root: RootField => !root.derivedFromAtt }) {\n-          val dataSchema = hadoopFsRelation.dataSchema\n-          val prunedDataSchema = pruneDataSchema(dataSchema, requestedRootFields)\n-\n-          // If the data schema is different from the pruned data schema, continue. Otherwise,\n-          // return op. We effect this comparison by counting the number of \"leaf\" fields in\n-          // each schemata, assuming the fields in prunedDataSchema are a subset of the fields\n-          // in dataSchema.\n-          if (countLeaves(dataSchema) > countLeaves(prunedDataSchema)) {\n+\n+        prunePhysicalColumns(l.output, projects, filters, hadoopFsRelation.dataSchema,\n+          prunedDataSchema => {\n             val prunedHadoopRelation =\n               hadoopFsRelation.copy(dataSchema = prunedDataSchema)(hadoopFsRelation.sparkSession)\n-\n-            val prunedRelation = buildPrunedRelation(l, prunedHadoopRelation)\n-            val projectionOverSchema = ProjectionOverSchema(prunedDataSchema)\n-\n-            buildNewProjection(normalizedProjects, normalizedFilters, prunedRelation,\n-              projectionOverSchema)\n-          } else {\n-            op\n-          }\n-        } else {\n-          op\n-        }\n+            buildPrunedRelation(l, prunedHadoopRelation)\n+          }).getOrElse(op)\n \n       case op @ PhysicalOperation(projects, filters,\n           d @ DataSourceV2Relation(table: FileTable, output, _)) if canPruneTable(table) =>\n-        val (normalizedProjects, normalizedFilters) =\n-          normalizeAttributeRefNames(output, projects, filters)\n-        val requestedRootFields = identifyRootFields(normalizedProjects, normalizedFilters)\n-\n-        // If requestedRootFields includes a nested field, continue. Otherwise,\n-        // return op\n-        if (requestedRootFields.exists { root: RootField => !root.derivedFromAtt }) {\n-          val dataSchema = table.dataSchema\n-          val prunedDataSchema = pruneDataSchema(dataSchema, requestedRootFields)\n-\n-          // If the data schema is different from the pruned data schema, continue. Otherwise,\n-          // return op. We effect this comparison by counting the number of \"leaf\" fields in\n-          // each schemata, assuming the fields in prunedDataSchema are a subset of the fields\n-          // in dataSchema.\n-          if (countLeaves(dataSchema) > countLeaves(prunedDataSchema)) {\n+\n+        prunePhysicalColumns(output, projects, filters, table.dataSchema,\n+          prunedDataSchema => {\n             val prunedFileTable = table match {\n               case o: OrcTable => o.copy(userSpecifiedSchema = Some(prunedDataSchema))\n               case _ =>\n                 val message = s\"${table.formatName} data source doesn't support schema pruning.\"\n                 throw new AnalysisException(message)\n             }\n+            buildPrunedRelationV2(d, prunedFileTable)\n+          }).getOrElse(op)\n+    }\n \n-\n-            val prunedRelationV2 = buildPrunedRelationV2(d, prunedFileTable)\n-            val projectionOverSchema = ProjectionOverSchema(prunedDataSchema)\n-\n-            buildNewProjection(normalizedProjects, normalizedFilters, prunedRelationV2,\n-              projectionOverSchema)\n-          } else {\n-            op\n-          }\n-        } else {\n-          op\n-        }\n+  private def prunePhysicalColumns(",
    "line": 85
  }],
  "prId": 24383
}]