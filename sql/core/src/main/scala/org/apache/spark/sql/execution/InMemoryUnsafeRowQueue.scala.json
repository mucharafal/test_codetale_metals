[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "No way to avoid making a custom queue implementation here? is it messier without such a structure?",
    "commit": "07ff4d3a69967e13438dd8bd3e4130bf23b65c7d",
    "createdAt": "2018-06-07T13:01:43Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import java.util.ConcurrentModificationException\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.{SparkEnv, TaskContext}\n+import org.apache.spark.memory.TaskMemoryManager\n+import org.apache.spark.serializer.SerializerManager\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.ExternalAppendOnlyUnsafeRowArray.DefaultInitialSizeOfInMemoryBuffer\n+import org.apache.spark.storage.BlockManager\n+\n+/**\n+ * An append-only array for [[UnsafeRow]]s that strictly keeps content in an in-memory array\n+ * until [[numRowsInMemoryBufferThreshold]] is reached post which it will switch to a mode which\n+ * would flush to disk after [[numRowsSpillThreshold]] is met (or before if there is\n+ * excessive memory consumption). Setting these threshold involves following trade-offs:\n+ *\n+ * - If [[numRowsInMemoryBufferThreshold]] is too high, the in-memory array may occupy more memory\n+ *   than is available, resulting in OOM.\n+ * - If [[numRowsSpillThreshold]] is too low, data will be spilled frequently and lead to\n+ *   excessive disk writes. This may lead to a performance regression compared to the normal case\n+ *   of using an [[ArrayBuffer]] or [[Array]].\n+ */\n+private[sql] class InMemoryUnsafeRowQueue("
  }, {
    "author": {
      "login": "zecevicp"
    },
    "body": "A queue is needed here because it's a moving window instead of a fixed block of rows. Maybe I missed an existing class that could do this easily so I'll take another look. But, I believe any alternative would indeed be messier.",
    "commit": "07ff4d3a69967e13438dd8bd3e4130bf23b65c7d",
    "createdAt": "2018-06-07T13:51:58Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import java.util.ConcurrentModificationException\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.{SparkEnv, TaskContext}\n+import org.apache.spark.memory.TaskMemoryManager\n+import org.apache.spark.serializer.SerializerManager\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.ExternalAppendOnlyUnsafeRowArray.DefaultInitialSizeOfInMemoryBuffer\n+import org.apache.spark.storage.BlockManager\n+\n+/**\n+ * An append-only array for [[UnsafeRow]]s that strictly keeps content in an in-memory array\n+ * until [[numRowsInMemoryBufferThreshold]] is reached post which it will switch to a mode which\n+ * would flush to disk after [[numRowsSpillThreshold]] is met (or before if there is\n+ * excessive memory consumption). Setting these threshold involves following trade-offs:\n+ *\n+ * - If [[numRowsInMemoryBufferThreshold]] is too high, the in-memory array may occupy more memory\n+ *   than is available, resulting in OOM.\n+ * - If [[numRowsSpillThreshold]] is too low, data will be spilled frequently and lead to\n+ *   excessive disk writes. This may lead to a performance regression compared to the normal case\n+ *   of using an [[ArrayBuffer]] or [[Array]].\n+ */\n+private[sql] class InMemoryUnsafeRowQueue("
  }],
  "prId": 21109
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "nit: Is this comment necessary?",
    "commit": "07ff4d3a69967e13438dd8bd3e4130bf23b65c7d",
    "createdAt": "2018-06-07T14:16:46Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import java.util.ConcurrentModificationException\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.{SparkEnv, TaskContext}\n+import org.apache.spark.memory.TaskMemoryManager\n+import org.apache.spark.serializer.SerializerManager\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.ExternalAppendOnlyUnsafeRowArray.DefaultInitialSizeOfInMemoryBuffer\n+import org.apache.spark.storage.BlockManager\n+\n+/**\n+ * An append-only array for [[UnsafeRow]]s that strictly keeps content in an in-memory array\n+ * until [[numRowsInMemoryBufferThreshold]] is reached post which it will switch to a mode which\n+ * would flush to disk after [[numRowsSpillThreshold]] is met (or before if there is\n+ * excessive memory consumption). Setting these threshold involves following trade-offs:\n+ *\n+ * - If [[numRowsInMemoryBufferThreshold]] is too high, the in-memory array may occupy more memory\n+ *   than is available, resulting in OOM.\n+ * - If [[numRowsSpillThreshold]] is too low, data will be spilled frequently and lead to\n+ *   excessive disk writes. This may lead to a performance regression compared to the normal case\n+ *   of using an [[ArrayBuffer]] or [[Array]].\n+ */\n+private[sql] class InMemoryUnsafeRowQueue(\n+    taskMemoryManager: TaskMemoryManager,\n+    blockManager: BlockManager,\n+    serializerManager: SerializerManager,\n+    taskContext: TaskContext,\n+    initialSize: Int,\n+    pageSizeBytes: Long,\n+    numRowsInMemoryBufferThreshold: Int,\n+    numRowsSpillThreshold: Int)\n+  extends ExternalAppendOnlyUnsafeRowArray(taskMemoryManager,\n+      blockManager,\n+      serializerManager,\n+      taskContext,\n+      initialSize,\n+      pageSizeBytes,\n+      numRowsInMemoryBufferThreshold,\n+      numRowsSpillThreshold) {\n+\n+  def this(numRowsInMemoryBufferThreshold: Int, numRowsSpillThreshold: Int) {\n+    this(\n+      TaskContext.get().taskMemoryManager(),\n+      SparkEnv.get.blockManager,\n+      SparkEnv.get.serializerManager,\n+      TaskContext.get(),\n+      1024,\n+      SparkEnv.get.memoryManager.pageSizeBytes,\n+      numRowsInMemoryBufferThreshold,\n+      numRowsSpillThreshold)\n+  }\n+\n+  private val initialSizeOfInMemoryBuffer =\n+    Math.min(DefaultInitialSizeOfInMemoryBuffer, numRowsInMemoryBufferThreshold)\n+\n+  private val inMemoryQueue = if (initialSizeOfInMemoryBuffer > 0) {\n+    new mutable.Queue[UnsafeRow]()\n+  } else {\n+    null\n+  }\n+\n+//  private var spillableArray: UnsafeExternalSorter = _"
  }, {
    "author": {
      "login": "zecevicp"
    },
    "body": "No, it's not. Thank you",
    "commit": "07ff4d3a69967e13438dd8bd3e4130bf23b65c7d",
    "createdAt": "2018-06-07T14:18:14Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import java.util.ConcurrentModificationException\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.{SparkEnv, TaskContext}\n+import org.apache.spark.memory.TaskMemoryManager\n+import org.apache.spark.serializer.SerializerManager\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.ExternalAppendOnlyUnsafeRowArray.DefaultInitialSizeOfInMemoryBuffer\n+import org.apache.spark.storage.BlockManager\n+\n+/**\n+ * An append-only array for [[UnsafeRow]]s that strictly keeps content in an in-memory array\n+ * until [[numRowsInMemoryBufferThreshold]] is reached post which it will switch to a mode which\n+ * would flush to disk after [[numRowsSpillThreshold]] is met (or before if there is\n+ * excessive memory consumption). Setting these threshold involves following trade-offs:\n+ *\n+ * - If [[numRowsInMemoryBufferThreshold]] is too high, the in-memory array may occupy more memory\n+ *   than is available, resulting in OOM.\n+ * - If [[numRowsSpillThreshold]] is too low, data will be spilled frequently and lead to\n+ *   excessive disk writes. This may lead to a performance regression compared to the normal case\n+ *   of using an [[ArrayBuffer]] or [[Array]].\n+ */\n+private[sql] class InMemoryUnsafeRowQueue(\n+    taskMemoryManager: TaskMemoryManager,\n+    blockManager: BlockManager,\n+    serializerManager: SerializerManager,\n+    taskContext: TaskContext,\n+    initialSize: Int,\n+    pageSizeBytes: Long,\n+    numRowsInMemoryBufferThreshold: Int,\n+    numRowsSpillThreshold: Int)\n+  extends ExternalAppendOnlyUnsafeRowArray(taskMemoryManager,\n+      blockManager,\n+      serializerManager,\n+      taskContext,\n+      initialSize,\n+      pageSizeBytes,\n+      numRowsInMemoryBufferThreshold,\n+      numRowsSpillThreshold) {\n+\n+  def this(numRowsInMemoryBufferThreshold: Int, numRowsSpillThreshold: Int) {\n+    this(\n+      TaskContext.get().taskMemoryManager(),\n+      SparkEnv.get.blockManager,\n+      SparkEnv.get.serializerManager,\n+      TaskContext.get(),\n+      1024,\n+      SparkEnv.get.memoryManager.pageSizeBytes,\n+      numRowsInMemoryBufferThreshold,\n+      numRowsSpillThreshold)\n+  }\n+\n+  private val initialSizeOfInMemoryBuffer =\n+    Math.min(DefaultInitialSizeOfInMemoryBuffer, numRowsInMemoryBufferThreshold)\n+\n+  private val inMemoryQueue = if (initialSizeOfInMemoryBuffer > 0) {\n+    new mutable.Queue[UnsafeRow]()\n+  } else {\n+    null\n+  }\n+\n+//  private var spillableArray: UnsafeExternalSorter = _"
  }],
  "prId": 21109
}]