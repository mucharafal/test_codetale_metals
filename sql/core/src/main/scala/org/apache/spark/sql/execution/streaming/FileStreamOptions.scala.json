[{
  "comments": [{
    "author": {
      "login": "petermaxlee"
    },
    "body": "This is a similar setup to CSVOptions and JSONOptions. I felt it would be easier to track the list of options read by the source here.\n",
    "commit": "9a5ed19f3b397b991794a6852aebb2b14c83d635",
    "createdAt": "2016-08-20T06:40:32Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import scala.util.Try\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.datasources.CaseInsensitiveMap\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * User specified options for file streams.\n+ */\n+class FileStreamOptions(@transient private val parameters: Map[String, String])"
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "You can remove `Serializable` and `@transient` from this class. It's not used in the executor side.\n",
    "commit": "9a5ed19f3b397b991794a6852aebb2b14c83d635",
    "createdAt": "2016-08-25T22:48:16Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import scala.util.Try\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.datasources.CaseInsensitiveMap\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * User specified options for file streams.\n+ */\n+class FileStreamOptions(@transient private val parameters: Map[String, String])"
  }],
  "prId": 14728
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "24 hour seems too short. Maybe a month or a week?\n",
    "commit": "9a5ed19f3b397b991794a6852aebb2b14c83d635",
    "createdAt": "2016-08-20T06:54:52Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import scala.util.Try\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.datasources.CaseInsensitiveMap\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * User specified options for file streams.\n+ */\n+class FileStreamOptions(@transient private val parameters: Map[String, String])\n+  extends Logging with Serializable {\n+\n+  val maxFilesPerTrigger: Option[Int] = parameters.get(\"maxFilesPerTrigger\").map { str =>\n+    Try(str.toInt).toOption.filter(_ > 0).getOrElse {\n+      throw new IllegalArgumentException(\n+        s\"Invalid value '$str' for option 'maxFilesPerTrigger', must be a positive integer\")\n+    }\n+  }\n+\n+  /** Maximum age of a file that can be found in this directory, before it is deleted. */\n+  val maxFileAgeMs: Long =\n+    Utils.timeStringAsMs(parameters.getOrElse(\"maxFileAge\", \"24h\"))"
  }],
  "prId": 14728
}, {
  "comments": [{
    "author": {
      "login": "jerryshao"
    },
    "body": "Looks like these two `apply` methods are not used, it would be better to remove them if not used.\n",
    "commit": "9a5ed19f3b397b991794a6852aebb2b14c83d635",
    "createdAt": "2016-08-24T08:07:41Z",
    "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import scala.util.Try\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.datasources.CaseInsensitiveMap\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * User specified options for file streams.\n+ */\n+class FileStreamOptions(@transient private val parameters: Map[String, String])\n+  extends Logging with Serializable {\n+\n+  val maxFilesPerTrigger: Option[Int] = parameters.get(\"maxFilesPerTrigger\").map { str =>\n+    Try(str.toInt).toOption.filter(_ > 0).getOrElse {\n+      throw new IllegalArgumentException(\n+        s\"Invalid value '$str' for option 'maxFilesPerTrigger', must be a positive integer\")\n+    }\n+  }\n+\n+  /**\n+   * Maximum age of a file that can be found in this directory, before it is deleted.\n+   * Default to a week.\n+   */\n+  val maxFileAgeMs: Long =\n+    Utils.timeStringAsMs(parameters.getOrElse(\"maxFileAge\", \"7d\"))\n+\n+  /** Options as specified by the user, in a case-insensitive map, without \"path\" set. */\n+  val optionMapWithoutPath: Map[String, String] =\n+    new CaseInsensitiveMap(parameters).filterKeys(_ != \"path\")\n+}\n+\n+\n+object FileStreamOptions {\n+\n+  def apply(): FileStreamOptions = new FileStreamOptions(Map.empty)\n+\n+  def apply(paramName: String, paramValue: String): FileStreamOptions = {\n+    new FileStreamOptions(Map(paramName -> paramValue))\n+  }"
  }],
  "prId": 14728
}]