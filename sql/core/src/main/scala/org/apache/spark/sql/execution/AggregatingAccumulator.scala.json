[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "We need to set the sql conf because this is executed in the DAGScheduler thread.",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-03T13:22:45Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow, UnsafeProjection}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private var mergeExpressions: Seq[Expression],\n+    @transient private var resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private var conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = SQLConf.withExistingConf(conf) {\n+    initializeProjection {\n+      InterpretedMutableProjection.createProjection(mergeExpressions)\n+    }\n+  }\n+\n+  @transient\n+  private[this] lazy val resultProjection = SQLConf.withExistingConf(conf) {\n+    initializeProjection {\n+      InterpretedUnsafeProjection.createProjection(resultExpressions)\n+    }\n+  }\n+\n+  override def reset(): Unit = {\n+    buffer = null\n+    joinedRow = null\n+  }\n+\n+  override def isZero: Boolean = buffer == null\n+\n+  override def copyAndReset(): AggregatingAccumulator = {\n+    new AggregatingAccumulator(\n+      bufferSchema,\n+      initialValues,\n+      updateExpressions,\n+      mergeExpressions,\n+      resultExpressions,\n+      imperatives,\n+      typedImperatives,\n+      conf)\n+  }\n+\n+  override def copy(): AggregatingAccumulator = {\n+    val copy = copyAndReset()\n+    copy.merge(this)\n+    copy\n+  }\n+\n+  override def add(v: InternalRow): Unit = {\n+    val buffer = getOrCreateBuffer()\n+    updateProjection.target(buffer)(joinedRow.withRight(v))\n+    var i = 0\n+    while (i < imperatives.length) {\n+      imperatives(i).update(buffer, v)\n+      i += 1\n+    }\n+    i = 0\n+    while (i < typedImperatives.length) {\n+      typedImperatives(i).update(buffer, v)\n+      i += 1\n+    }\n+  }\n+\n+  override def merge(other: AccumulatorV2[InternalRow, InternalRow]): Unit = {\n+    SQLConf.withExistingConf(conf) {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "Can we put it as a code comment?",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-03T14:36:04Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow, UnsafeProjection}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private var mergeExpressions: Seq[Expression],\n+    @transient private var resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private var conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = SQLConf.withExistingConf(conf) {\n+    initializeProjection {\n+      InterpretedMutableProjection.createProjection(mergeExpressions)\n+    }\n+  }\n+\n+  @transient\n+  private[this] lazy val resultProjection = SQLConf.withExistingConf(conf) {\n+    initializeProjection {\n+      InterpretedUnsafeProjection.createProjection(resultExpressions)\n+    }\n+  }\n+\n+  override def reset(): Unit = {\n+    buffer = null\n+    joinedRow = null\n+  }\n+\n+  override def isZero: Boolean = buffer == null\n+\n+  override def copyAndReset(): AggregatingAccumulator = {\n+    new AggregatingAccumulator(\n+      bufferSchema,\n+      initialValues,\n+      updateExpressions,\n+      mergeExpressions,\n+      resultExpressions,\n+      imperatives,\n+      typedImperatives,\n+      conf)\n+  }\n+\n+  override def copy(): AggregatingAccumulator = {\n+    val copy = copyAndReset()\n+    copy.merge(this)\n+    copy\n+  }\n+\n+  override def add(v: InternalRow): Unit = {\n+    val buffer = getOrCreateBuffer()\n+    updateProjection.target(buffer)(joinedRow.withRight(v))\n+    var i = 0\n+    while (i < imperatives.length) {\n+      imperatives(i).update(buffer, v)\n+      i += 1\n+    }\n+    i = 0\n+    while (i < typedImperatives.length) {\n+      typedImperatives(i).update(buffer, v)\n+      i += 1\n+    }\n+  }\n+\n+  override def merge(other: AccumulatorV2[InternalRow, InternalRow]): Unit = {\n+    SQLConf.withExistingConf(conf) {"
  }],
  "prId": 26012
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "why it's a var?",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-03T14:32:38Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow, UnsafeProjection}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private var mergeExpressions: Seq[Expression],"
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "Should have been a val, will fix",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-03T14:35:51Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow, UnsafeProjection}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private var mergeExpressions: Seq[Expression],"
  }],
  "prId": 26012
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Note to self we can omit this, mergeProjection is created inside merge...",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-03T15:12:20Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow, UnsafeProjection}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private var mergeExpressions: Seq[Expression],\n+    @transient private var resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private var conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = SQLConf.withExistingConf(conf) {"
  }],
  "prId": 26012
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "nit: !isZero",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-03T22:04:16Z",
    "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private val mergeExpressions: Seq[Expression],\n+    @transient private val resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private val conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(mergeExpressions == null || bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = initializeProjection {\n+    InterpretedMutableProjection.createProjection(mergeExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val resultProjection = initializeProjection {\n+    InterpretedUnsafeProjection.createProjection(resultExpressions)\n+  }\n+\n+  /**\n+   * Driver side operations like `merge` and `value` are executed in the DAGScheduler thread. This\n+   * thread does not have a SQL configuration so we attach our own here. Note that we can't (and\n+   * shouldn't) call `merge` or `value` on an accumulator originating from an executor so we just\n+   * return a default value here.\n+   */\n+  private[this] def withSQLConf[T](default: => T)(body: => T): T = {\n+    if (conf != null) {\n+      SQLConf.withExistingConf(conf)(body)\n+    } else {\n+      default\n+    }\n+  }\n+\n+  override def reset(): Unit = {\n+    buffer = null\n+    joinedRow = null\n+  }\n+\n+  override def isZero: Boolean = buffer == null\n+\n+  override def copyAndReset(): AggregatingAccumulator = {\n+    new AggregatingAccumulator(\n+      bufferSchema,\n+      initialValues,\n+      updateExpressions,\n+      mergeExpressions,\n+      resultExpressions,\n+      imperatives,\n+      typedImperatives,\n+      conf)\n+  }\n+\n+  override def copy(): AggregatingAccumulator = {\n+    val copy = copyAndReset()\n+    copy.merge(this)\n+    copy\n+  }\n+\n+  override def add(v: InternalRow): Unit = {\n+    val buffer = getOrCreateBuffer()\n+    updateProjection.target(buffer)(joinedRow.withRight(v))\n+    var i = 0\n+    while (i < imperatives.length) {\n+      imperatives(i).update(buffer, v)\n+      i += 1\n+    }\n+    i = 0\n+    while (i < typedImperatives.length) {\n+      typedImperatives(i).update(buffer, v)\n+      i += 1\n+    }\n+  }\n+\n+  override def merge(other: AccumulatorV2[InternalRow, InternalRow]): Unit = withSQLConf(()) {\n+    if (!other.isZero) {\n+      other match {\n+        case agg: AggregatingAccumulator =>\n+          val buffer = getOrCreateBuffer()\n+          val otherBuffer = agg.buffer\n+          mergeProjection.target(buffer)(joinedRow.withRight(otherBuffer))\n+          var i = 0\n+          while (i < imperatives.length) {\n+            imperatives(i).merge(buffer, otherBuffer)\n+            i += 1\n+          }\n+          i = 0\n+          while (i < typedImperatives.length) {\n+            typedImperatives(i).mergeBuffersObjects(buffer, otherBuffer)\n+            i += 1\n+          }\n+        case _ =>\n+          throw new UnsupportedOperationException(\n+            s\"Cannot merge ${this.getClass.getName} with ${other.getClass.getName}\")\n+      }\n+    }\n+  }\n+\n+  override def value: InternalRow = withSQLConf(InternalRow.empty) {\n+    // Either use the existing buffer or create a temporary one.\n+    val input = if (buffer != null) {"
  }],
  "prId": 26012
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Out of curious, cannot be MutableProjection too here?",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-03T22:07:33Z",
    "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private val mergeExpressions: Seq[Expression],\n+    @transient private val resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private val conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(mergeExpressions == null || bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = initializeProjection {\n+    InterpretedMutableProjection.createProjection(mergeExpressions)",
    "line": 87
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "We could but it is not really worth it. Code generation is relatively fast but it is not for free, even for situations where merge is called often interpreted execution is probably faster.",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-04T11:28:00Z",
    "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private val mergeExpressions: Seq[Expression],\n+    @transient private val resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private val conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(mergeExpressions == null || bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = initializeProjection {\n+    InterpretedMutableProjection.createProjection(mergeExpressions)",
    "line": 87
  }],
  "prId": 26012
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "shall we be more aggressive and throw exception if `merge` or `value` is called on executor side?",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-04T06:30:39Z",
    "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private val mergeExpressions: Seq[Expression],\n+    @transient private val resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private val conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(mergeExpressions == null || bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = initializeProjection {\n+    InterpretedMutableProjection.createProjection(mergeExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val resultProjection = initializeProjection {\n+    InterpretedUnsafeProjection.createProjection(resultExpressions)\n+  }\n+\n+  /**\n+   * Driver side operations like `merge` and `value` are executed in the DAGScheduler thread. This\n+   * thread does not have a SQL configuration so we attach our own here. Note that we can't (and\n+   * shouldn't) call `merge` or `value` on an accumulator originating from an executor so we just",
    "line": 98
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "Well we will throw a NPE when you do that. Merge and value expressions are not send to the executor.",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-04T11:28:44Z",
    "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private val mergeExpressions: Seq[Expression],\n+    @transient private val resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private val conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(mergeExpressions == null || bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = initializeProjection {\n+    InterpretedMutableProjection.createProjection(mergeExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val resultProjection = initializeProjection {\n+    InterpretedUnsafeProjection.createProjection(resultExpressions)\n+  }\n+\n+  /**\n+   * Driver side operations like `merge` and `value` are executed in the DAGScheduler thread. This\n+   * thread does not have a SQL configuration so we attach our own here. Note that we can't (and\n+   * shouldn't) call `merge` or `value` on an accumulator originating from an executor so we just",
    "line": 98
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "What I mean is, we don't need the default value. We can simply `assert(conf != null)` in the method.",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-04T12:42:15Z",
    "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private val mergeExpressions: Seq[Expression],\n+    @transient private val resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private val conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(mergeExpressions == null || bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = initializeProjection {\n+    InterpretedMutableProjection.createProjection(mergeExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val resultProjection = initializeProjection {\n+    InterpretedUnsafeProjection.createProjection(resultExpressions)\n+  }\n+\n+  /**\n+   * Driver side operations like `merge` and `value` are executed in the DAGScheduler thread. This\n+   * thread does not have a SQL configuration so we attach our own here. Note that we can't (and\n+   * shouldn't) call `merge` or `value` on an accumulator originating from an executor so we just",
    "line": 98
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "In SQL the SQLAppStatusListener calls `merge` and `value` on an accumulator that originates from an executor and which does not carry a `conf` value. I can add the assert but I will probably have to remove it in the follow up PR.",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-09T13:42:44Z",
    "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private val mergeExpressions: Seq[Expression],\n+    @transient private val resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private val conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(mergeExpressions == null || bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = initializeProjection {\n+    InterpretedMutableProjection.createProjection(mergeExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val resultProjection = initializeProjection {\n+    InterpretedUnsafeProjection.createProjection(resultExpressions)\n+  }\n+\n+  /**\n+   * Driver side operations like `merge` and `value` are executed in the DAGScheduler thread. This\n+   * thread does not have a SQL configuration so we attach our own here. Note that we can't (and\n+   * shouldn't) call `merge` or `value` on an accumulator originating from an executor so we just",
    "line": 98
  }],
  "prId": 26012
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "when can `mergeExpressions` be null?",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-04T06:31:26Z",
    "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private val mergeExpressions: Seq[Expression],\n+    @transient private val resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private val conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(mergeExpressions == null || bufferSchema.size == mergeExpressions.size)",
    "line": 44
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "`mergeExpressions` are transient, so they will be null on the executor side.",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-04T11:29:27Z",
    "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private val mergeExpressions: Seq[Expression],\n+    @transient private val resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private val conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(mergeExpressions == null || bufferSchema.size == mergeExpressions.size)",
    "line": 44
  }],
  "prId": 26012
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "take this as an example. If we have a bug and call `value` at executor side. I'd like to fail fast to expose the bug and fix it, instead of returning an empty row which may hide the bug and give undefined behavior.",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-07T07:00:28Z",
    "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private val mergeExpressions: Seq[Expression],\n+    @transient private val resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private val conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(mergeExpressions == null || bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = initializeProjection {\n+    InterpretedMutableProjection.createProjection(mergeExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val resultProjection = initializeProjection {\n+    InterpretedUnsafeProjection.createProjection(resultExpressions)\n+  }\n+\n+  /**\n+   * Driver side operations like `merge` and `value` are executed in the DAGScheduler thread. This\n+   * thread does not have a SQL configuration so we attach our own here. Note that we can't (and\n+   * shouldn't) call `merge` or `value` on an accumulator originating from an executor so we just\n+   * return a default value here.\n+   */\n+  private[this] def withSQLConf[T](default: => T)(body: => T): T = {\n+    if (conf != null) {\n+      SQLConf.withExistingConf(conf)(body)\n+    } else {\n+      default\n+    }\n+  }\n+\n+  override def reset(): Unit = {\n+    buffer = null\n+    joinedRow = null\n+  }\n+\n+  override def isZero: Boolean = buffer == null\n+\n+  override def copyAndReset(): AggregatingAccumulator = {\n+    new AggregatingAccumulator(\n+      bufferSchema,\n+      initialValues,\n+      updateExpressions,\n+      mergeExpressions,\n+      resultExpressions,\n+      imperatives,\n+      typedImperatives,\n+      conf)\n+  }\n+\n+  override def copy(): AggregatingAccumulator = {\n+    val copy = copyAndReset()\n+    copy.merge(this)\n+    copy\n+  }\n+\n+  override def add(v: InternalRow): Unit = {\n+    val buffer = getOrCreateBuffer()\n+    updateProjection.target(buffer)(joinedRow.withRight(v))\n+    var i = 0\n+    while (i < imperatives.length) {\n+      imperatives(i).update(buffer, v)\n+      i += 1\n+    }\n+    i = 0\n+    while (i < typedImperatives.length) {\n+      typedImperatives(i).update(buffer, v)\n+      i += 1\n+    }\n+  }\n+\n+  override def merge(other: AccumulatorV2[InternalRow, InternalRow]): Unit = withSQLConf(()) {\n+    if (!other.isZero) {\n+      other match {\n+        case agg: AggregatingAccumulator =>\n+          val buffer = getOrCreateBuffer()\n+          val otherBuffer = agg.buffer\n+          mergeProjection.target(buffer)(joinedRow.withRight(otherBuffer))\n+          var i = 0\n+          while (i < imperatives.length) {\n+            imperatives(i).merge(buffer, otherBuffer)\n+            i += 1\n+          }\n+          i = 0\n+          while (i < typedImperatives.length) {\n+            typedImperatives(i).mergeBuffersObjects(buffer, otherBuffer)\n+            i += 1\n+          }\n+        case _ =>\n+          throw new UnsupportedOperationException(\n+            s\"Cannot merge ${this.getClass.getName} with ${other.getClass.getName}\")\n+      }\n+    }\n+  }\n+\n+  override def value: InternalRow = withSQLConf(InternalRow.empty) {",
    "line": 173
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "I can add a check based on `isAtDriverSide`",
    "commit": "ebb974e419f786d4f448d340a4ba4a57f7f45feb",
    "createdAt": "2019-10-09T13:45:47Z",
    "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.TaskContext\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, AttributeSeq, BindReferences, Expression, InterpretedMutableProjection, InterpretedUnsafeProjection, JoinedRow, MutableProjection, NamedExpression, Projection, SpecificInternalRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, DeclarativeAggregate, ImperativeAggregate, NoOp, TypedImperativeAggregate}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{DataType, StructField, StructType}\n+import org.apache.spark.util.AccumulatorV2\n+\n+/**\n+ * Accumulator that computes a global aggregate.\n+ */\n+class AggregatingAccumulator private(\n+    bufferSchema: Seq[DataType],\n+    initialValues: Seq[Expression],\n+    updateExpressions: Seq[Expression],\n+    @transient private val mergeExpressions: Seq[Expression],\n+    @transient private val resultExpressions: Seq[Expression],\n+    imperatives: Array[ImperativeAggregate],\n+    typedImperatives: Array[TypedImperativeAggregate[_]],\n+    @transient private val conf: SQLConf)\n+  extends AccumulatorV2[InternalRow, InternalRow] {\n+  assert(bufferSchema.size == initialValues.size)\n+  assert(bufferSchema.size == updateExpressions.size)\n+  assert(mergeExpressions == null || bufferSchema.size == mergeExpressions.size)\n+\n+  private[this] var joinedRow: JoinedRow = _\n+\n+  private var buffer: SpecificInternalRow = _\n+\n+  private def createBuffer(): SpecificInternalRow = {\n+    val buffer = new SpecificInternalRow(bufferSchema)\n+\n+    // Initialize the buffer. Note that we do not use a code generated projection here because\n+    // generating and compiling a projection is probably more expensive than using an interpreted\n+    // projection.\n+    InterpretedMutableProjection.createProjection(initialValues)\n+      .target(buffer)\n+      .apply(InternalRow.empty)\n+    imperatives.foreach(_.initialize(buffer))\n+    typedImperatives.foreach(_.initialize(buffer))\n+    buffer\n+  }\n+\n+  private def getOrCreateBuffer(): SpecificInternalRow = {\n+    if (buffer == null) {\n+      buffer = createBuffer()\n+\n+      // Create the joined row and set the buffer as its 'left' row.\n+      joinedRow = new JoinedRow()\n+      joinedRow.withLeft(buffer)\n+    }\n+    buffer\n+  }\n+\n+  private def initializeProjection[T <: Projection](projection: T): T = {\n+    projection.initialize(TaskContext.getPartitionId())\n+    projection\n+  }\n+\n+  @transient\n+  private[this] lazy val updateProjection = initializeProjection {\n+    MutableProjection.create(updateExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val mergeProjection = initializeProjection {\n+    InterpretedMutableProjection.createProjection(mergeExpressions)\n+  }\n+\n+  @transient\n+  private[this] lazy val resultProjection = initializeProjection {\n+    InterpretedUnsafeProjection.createProjection(resultExpressions)\n+  }\n+\n+  /**\n+   * Driver side operations like `merge` and `value` are executed in the DAGScheduler thread. This\n+   * thread does not have a SQL configuration so we attach our own here. Note that we can't (and\n+   * shouldn't) call `merge` or `value` on an accumulator originating from an executor so we just\n+   * return a default value here.\n+   */\n+  private[this] def withSQLConf[T](default: => T)(body: => T): T = {\n+    if (conf != null) {\n+      SQLConf.withExistingConf(conf)(body)\n+    } else {\n+      default\n+    }\n+  }\n+\n+  override def reset(): Unit = {\n+    buffer = null\n+    joinedRow = null\n+  }\n+\n+  override def isZero: Boolean = buffer == null\n+\n+  override def copyAndReset(): AggregatingAccumulator = {\n+    new AggregatingAccumulator(\n+      bufferSchema,\n+      initialValues,\n+      updateExpressions,\n+      mergeExpressions,\n+      resultExpressions,\n+      imperatives,\n+      typedImperatives,\n+      conf)\n+  }\n+\n+  override def copy(): AggregatingAccumulator = {\n+    val copy = copyAndReset()\n+    copy.merge(this)\n+    copy\n+  }\n+\n+  override def add(v: InternalRow): Unit = {\n+    val buffer = getOrCreateBuffer()\n+    updateProjection.target(buffer)(joinedRow.withRight(v))\n+    var i = 0\n+    while (i < imperatives.length) {\n+      imperatives(i).update(buffer, v)\n+      i += 1\n+    }\n+    i = 0\n+    while (i < typedImperatives.length) {\n+      typedImperatives(i).update(buffer, v)\n+      i += 1\n+    }\n+  }\n+\n+  override def merge(other: AccumulatorV2[InternalRow, InternalRow]): Unit = withSQLConf(()) {\n+    if (!other.isZero) {\n+      other match {\n+        case agg: AggregatingAccumulator =>\n+          val buffer = getOrCreateBuffer()\n+          val otherBuffer = agg.buffer\n+          mergeProjection.target(buffer)(joinedRow.withRight(otherBuffer))\n+          var i = 0\n+          while (i < imperatives.length) {\n+            imperatives(i).merge(buffer, otherBuffer)\n+            i += 1\n+          }\n+          i = 0\n+          while (i < typedImperatives.length) {\n+            typedImperatives(i).mergeBuffersObjects(buffer, otherBuffer)\n+            i += 1\n+          }\n+        case _ =>\n+          throw new UnsupportedOperationException(\n+            s\"Cannot merge ${this.getClass.getName} with ${other.getClass.getName}\")\n+      }\n+    }\n+  }\n+\n+  override def value: InternalRow = withSQLConf(InternalRow.empty) {",
    "line": 173
  }],
  "prId": 26012
}]