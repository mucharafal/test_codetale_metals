[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "i need to take a look at this again to make sure i understand what's happening. conceptually what you are doing is pretty simple and it doesn't seem right it needs so many lines of code, but maybe i'm missing something.\r\n",
    "commit": "7e444868f9dd0ca601c806abbfca7ef219f686d9",
    "createdAt": "2017-10-06T07:16:43Z",
    "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.datasources\n+\n+import org.apache.spark.sql.{AnalysisException, SparkSession}\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedException\n+import org.apache.spark.sql.catalyst.catalog.CatalogTable\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils\n+import org.apache.spark.sql.types.{StringType, TimestampType}\n+\n+/**\n+ * Apply a correction to data loaded from, or saved to, Parquet, so that it timestamps can be read\n+ * like TIMESTAMP WITHOUT TIMEZONE.  This gives correct behavior if you process data with\n+ * machines in different timezones, or if you access the data from multiple SQL engines.\n+ */\n+private[sql] case class TimestampTableTimeZone(sparkSession: SparkSession)"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I'm also trying to see if this can be simplified; I guess the main thing is Imran's comment about not being able to use `transformUp`. I need to take a look at whether that's really the case.\r\n\r\nThis rule also doesn't seem to handle `InsertIntoHiveTable`, which is in the hive module so can't be handled here. Probably will need a new rule based on this one in the hive module.\r\n",
    "commit": "7e444868f9dd0ca601c806abbfca7ef219f686d9",
    "createdAt": "2017-10-06T17:14:47Z",
    "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.datasources\n+\n+import org.apache.spark.sql.{AnalysisException, SparkSession}\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedException\n+import org.apache.spark.sql.catalyst.catalog.CatalogTable\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, Project}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils\n+import org.apache.spark.sql.types.{StringType, TimestampType}\n+\n+/**\n+ * Apply a correction to data loaded from, or saved to, Parquet, so that it timestamps can be read\n+ * like TIMESTAMP WITHOUT TIMEZONE.  This gives correct behavior if you process data with\n+ * machines in different timezones, or if you access the data from multiple SQL engines.\n+ */\n+private[sql] case class TimestampTableTimeZone(sparkSession: SparkSession)"
  }],
  "prId": 19250
}]