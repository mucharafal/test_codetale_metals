[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "add a comment that this rule must be run after `EnsureRequirements`.",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-10T07:12:57Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.sql.execution.command.ExecutedCommandExec\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, Exchange, ShuffleExchangeExec}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * Divide the spark plan into multiple QueryStages. For each Exchange in the plan, it adds a\n+ * QueryStage and a QueryStageInput. If reusing Exchange is enabled, it finds duplicated exchanges\n+ * and uses the same QueryStage for all the references."
  }, {
    "author": {
      "login": "carsonwang"
    },
    "body": "Sure. Will add it and rebase the code.",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-10T09:38:16Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.sql.execution.command.ExecutedCommandExec\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, Exchange, ShuffleExchangeExec}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * Divide the spark plan into multiple QueryStages. For each Exchange in the plan, it adds a\n+ * QueryStage and a QueryStageInput. If reusing Exchange is enabled, it finds duplicated exchanges\n+ * and uses the same QueryStage for all the references."
  }, {
    "author": {
      "login": "gczsjdy"
    },
    "body": "Also that this should be applied at last as it actually divide the tree into multiple sub-trees?",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-12T06:19:49Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.sql.execution.command.ExecutedCommandExec\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, Exchange, ShuffleExchangeExec}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * Divide the spark plan into multiple QueryStages. For each Exchange in the plan, it adds a\n+ * QueryStage and a QueryStageInput. If reusing Exchange is enabled, it finds duplicated exchanges\n+ * and uses the same QueryStage for all the references."
  }, {
    "author": {
      "login": "carsonwang"
    },
    "body": "Yes, this is commented in QueryExecution when using this rule. Let me also add it here.",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-15T09:10:49Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.sql.execution.command.ExecutedCommandExec\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, Exchange, ShuffleExchangeExec}\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * Divide the spark plan into multiple QueryStages. For each Exchange in the plan, it adds a\n+ * QueryStage and a QueryStageInput. If reusing Exchange is enabled, it finds duplicated exchanges\n+ * and uses the same QueryStage for all the references."
  }],
  "prId": 20303
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "I am not sure how hard this guarantee is. You may want to change this to something stronger.",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-22T14:27:43Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, Exchange, ReusedExchangeExec, ShuffleExchangeExec}\n+\n+/**\n+ * Divide the spark plan into multiple QueryStages. For each Exchange in the plan, it wraps it with\n+ * a [[QueryStage]]. At the end it adds an [[AdaptiveSparkPlan]] at the top, which will drive the\n+ * execution of query stages.\n+ */\n+case class PlanQueryStage(session: SparkSession) extends Rule[SparkPlan] {\n+\n+  def apply(plan: SparkPlan): SparkPlan = {\n+    var id = 0\n+    val exchangeToQueryStage = new java.util.IdentityHashMap[Exchange, QueryStage]\n+    val planWithStages = plan.transformUp {\n+      case e: ShuffleExchangeExec =>\n+        val queryStage = ShuffleQueryStage(id, e)\n+        id += 1\n+        exchangeToQueryStage.put(e, queryStage)\n+        queryStage\n+      case e: BroadcastExchangeExec =>\n+        val queryStage = BroadcastQueryStage(id, e)\n+        id += 1\n+        exchangeToQueryStage.put(e, queryStage)\n+        queryStage\n+      // The `ReusedExchangeExec` was added in the rule `ReuseExchange`, via transforming up the\n+      // query plan. This rule also transform up the query plan, so when we hit `ReusedExchangeExec`\n+      // here, the exchange being reused must already be hit before and there should be an entry\n+      // for it in `exchangeToQueryStage`.\n+      case e: ReusedExchangeExec =>\n+        val existingQueryStage = exchangeToQueryStage.get(e.child)\n+        assert(existingQueryStage != null, \"The exchange being reused should be hit before.\")"
  }],
  "prId": 20303
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "We need this wrapper? Can we just return `existingQueryStage`?",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-29T07:18:39Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, Exchange, ReusedExchangeExec, ShuffleExchangeExec}\n+\n+/**\n+ * Divide the spark plan into multiple QueryStages. For each Exchange in the plan, it wraps it with\n+ * a [[QueryStage]]. At the end it adds an [[AdaptiveSparkPlan]] at the top, which will drive the\n+ * execution of query stages.\n+ */\n+case class PlanQueryStage(session: SparkSession) extends Rule[SparkPlan] {\n+\n+  def apply(plan: SparkPlan): SparkPlan = {\n+    var id = 0\n+    val exchangeToQueryStage = new java.util.IdentityHashMap[Exchange, QueryStage]\n+    val planWithStages = plan.transformUp {\n+      case e: ShuffleExchangeExec =>\n+        val queryStage = ShuffleQueryStage(id, e)\n+        id += 1\n+        exchangeToQueryStage.put(e, queryStage)\n+        queryStage\n+      case e: BroadcastExchangeExec =>\n+        val queryStage = BroadcastQueryStage(id, e)\n+        id += 1\n+        exchangeToQueryStage.put(e, queryStage)\n+        queryStage\n+      // The `ReusedExchangeExec` was added in the rule `ReuseExchange`, via transforming up the\n+      // query plan. This rule also transform up the query plan, so when we hit `ReusedExchangeExec`\n+      // here, the exchange being reused must already be hit before and there should be an entry\n+      // for it in `exchangeToQueryStage`.\n+      case e: ReusedExchangeExec =>\n+        val existingQueryStage = exchangeToQueryStage.get(e.child)\n+        assert(existingQueryStage != null, \"The exchange being reused should be hit before.\")\n+        ReusedQueryStage(existingQueryStage, e.output)"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "I think we need the wrapper shares the same reason with ReusedExchangeExec, it's necessary to keep the output of this exhange.",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-29T15:44:31Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, Exchange, ReusedExchangeExec, ShuffleExchangeExec}\n+\n+/**\n+ * Divide the spark plan into multiple QueryStages. For each Exchange in the plan, it wraps it with\n+ * a [[QueryStage]]. At the end it adds an [[AdaptiveSparkPlan]] at the top, which will drive the\n+ * execution of query stages.\n+ */\n+case class PlanQueryStage(session: SparkSession) extends Rule[SparkPlan] {\n+\n+  def apply(plan: SparkPlan): SparkPlan = {\n+    var id = 0\n+    val exchangeToQueryStage = new java.util.IdentityHashMap[Exchange, QueryStage]\n+    val planWithStages = plan.transformUp {\n+      case e: ShuffleExchangeExec =>\n+        val queryStage = ShuffleQueryStage(id, e)\n+        id += 1\n+        exchangeToQueryStage.put(e, queryStage)\n+        queryStage\n+      case e: BroadcastExchangeExec =>\n+        val queryStage = BroadcastQueryStage(id, e)\n+        id += 1\n+        exchangeToQueryStage.put(e, queryStage)\n+        queryStage\n+      // The `ReusedExchangeExec` was added in the rule `ReuseExchange`, via transforming up the\n+      // query plan. This rule also transform up the query plan, so when we hit `ReusedExchangeExec`\n+      // here, the exchange being reused must already be hit before and there should be an entry\n+      // for it in `exchangeToQueryStage`.\n+      case e: ReusedExchangeExec =>\n+        val existingQueryStage = exchangeToQueryStage.get(e.child)\n+        assert(existingQueryStage != null, \"The exchange being reused should be hit before.\")\n+        ReusedQueryStage(existingQueryStage, e.output)"
  }],
  "prId": 20303
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Just a question; I'm not 100% sure about the design though... during runtime, a query stage could change depends on the map output statistics of the child stages, e.g., from `ShuffleQueryStage` to `BroadcastExchangeExec`?",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-29T12:19:50Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, Exchange, ReusedExchangeExec, ShuffleExchangeExec}\n+\n+/**\n+ * Divide the spark plan into multiple QueryStages. For each Exchange in the plan, it wraps it with\n+ * a [[QueryStage]]. At the end it adds an [[AdaptiveSparkPlan]] at the top, which will drive the\n+ * execution of query stages.\n+ */\n+case class PlanQueryStage(session: SparkSession) extends Rule[SparkPlan] {\n+\n+  def apply(plan: SparkPlan): SparkPlan = {\n+    var id = 0\n+    val exchangeToQueryStage = new java.util.IdentityHashMap[Exchange, QueryStage]\n+    val planWithStages = plan.transformUp {\n+      case e: ShuffleExchangeExec =>\n+        val queryStage = ShuffleQueryStage(id, e)"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Yes, you can preview the relative code here, as our plan, the join optimization rule will in a separated PR.\r\nhttps://github.com/Intel-bigdata/spark-adaptive/blob/ae-2.3-08/sql/core/src/main/scala/org/apache/spark/sql/execution/adaptive/OptimizeJoin.scala#L114",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-29T15:37:30Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, Exchange, ReusedExchangeExec, ShuffleExchangeExec}\n+\n+/**\n+ * Divide the spark plan into multiple QueryStages. For each Exchange in the plan, it wraps it with\n+ * a [[QueryStage]]. At the end it adds an [[AdaptiveSparkPlan]] at the top, which will drive the\n+ * execution of query stages.\n+ */\n+case class PlanQueryStage(session: SparkSession) extends Rule[SparkPlan] {\n+\n+  def apply(plan: SparkPlan): SparkPlan = {\n+    var id = 0\n+    val exchangeToQueryStage = new java.util.IdentityHashMap[Exchange, QueryStage]\n+    val planWithStages = plan.transformUp {\n+      case e: ShuffleExchangeExec =>\n+        val queryStage = ShuffleQueryStage(id, e)"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "This might be a comment about the design though, we can't do planning from a logical plan to a physical plan in a query stage on-runtime (e.g., by reusing the `planLater` logic) instead of the current design (replacing from an already-planned physical plan to another physical plan on-runtime)? Or, we need to fix phsical plans in all the query stages before execution?",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-02-05T02:17:58Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, Exchange, ReusedExchangeExec, ShuffleExchangeExec}\n+\n+/**\n+ * Divide the spark plan into multiple QueryStages. For each Exchange in the plan, it wraps it with\n+ * a [[QueryStage]]. At the end it adds an [[AdaptiveSparkPlan]] at the top, which will drive the\n+ * execution of query stages.\n+ */\n+case class PlanQueryStage(session: SparkSession) extends Rule[SparkPlan] {\n+\n+  def apply(plan: SparkPlan): SparkPlan = {\n+    var id = 0\n+    val exchangeToQueryStage = new java.util.IdentityHashMap[Exchange, QueryStage]\n+    val planWithStages = plan.transformUp {\n+      case e: ShuffleExchangeExec =>\n+        val queryStage = ShuffleQueryStage(id, e)"
  }],
  "prId": 20303
}]