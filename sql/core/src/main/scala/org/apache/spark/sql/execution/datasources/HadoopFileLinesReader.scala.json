[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "This should not be optional.",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-23T17:18:02Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Could you elaborate why? `LineRecordReader` without this works differently, covering newline variants by default. I don't know which string I should give for `LineRecordReader` constructor if this is not optional.",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-23T22:40:16Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "We do not know what is the default line separator?",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-24T05:55:47Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "The problem is `LineRecordReader()` here. I think probably we could do `LineRecordReader(null)` to express both `\\r\\n` and `\\n` but I am not sure if we should use `null` to express these.",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-24T07:10:48Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "> When the line delimiter is '\\n', any of the follow sequences will count as a delimiter: \"\\n\", \"\\r\\n\", or \"\\r\".\r\n\r\nCould you check whether this is true here?",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-24T07:57:41Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Do you mean we should use `\\n` to represent those newline variants? Would you mind if I ask the source of your quotation?",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-24T08:44:14Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "I saw a discussion in the Impala. https://issues.apache.org/jira/browse/IMPALA-1578\r\n \r\n> When the line delimiter is '\\n', any of the follow sequences will count as a delimiter: \"\\n\", \"\\r\\n\", or \"\\r\". Accepting a single \"\\r\" is pretty strange, but that's what Hive does so we emulate this behavior.\r\n\r\nCould you check whether Hive is behaving like this?",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-25T16:58:21Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I am willing to do so but I am curious of the purpose of checking so. Do you want some test cases about this concern? ",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-25T17:50:15Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Is Hive using Hadoop's `LineRecordReader`? How does Hive support it?\r\n\r\nIf possible, we always try to behave the same like Hive.",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-25T20:28:22Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Thanks for clarifying it. Here is my investigation:\r\n\r\n> When the line delimiter is '\\n', any of the follow sequences will count as a delimiter: \"\\n\", \"\\r\\n\", or \"\\r\"\r\n\r\nWith this input:\r\n\r\n```\r\na\\nb\\r\\nc\\rd\r\n```\r\n\r\n**Hive**:\r\n\r\nCase with `\\n`:\r\n\r\n```sql\r\nCREATE EXTERNAL TABlE tbl(value STRING)\r\nROW FORMAT DELIMITED LINES TERMINATED BY '\\n'\r\nSTORED AS TEXTFILE LOCATION '...';\r\n```\r\n\r\n```sql\r\nSELECT value FROM tbl;\r\n```\r\n\r\nproduced\r\n\r\n```\r\na\r\nb\r\nc\r\nd\r\n```\r\n\r\n```sql\r\nSELECT count(value) FROM tbl;\r\n```\r\n\r\nproduced\r\n\r\n```\r\n4\r\n```\r\n\r\nThis looks actually incorrect. I guess `\\n` is not being set and it looks working as the default behaviour in `LineRecordReader`.\r\n\r\n\r\n**Spark (after this PR)**:\r\n\r\n```scala\r\nspark.read.schema(\"value STRING\")\r\n  .option(\"lineSep\", \"\\n\")\r\n  .csv(\"...\").show()\r\n```\r\n\r\n```\r\n+-----+\r\n|value|\r\n+-----+\r\n|    a|\r\n|   b\r\nd| c\r\n+-----+\r\n```\r\n\r\ncount on this produce `3`.\r\n\r\nIf this option is not set, it looks working identically with Hive case:\r\n\r\n```\r\n+-----+\r\n|value|\r\n+-----+\r\n|    a|\r\n|    b|\r\n|    c|\r\n|    d|\r\n+-----+\r\n```\r\n\r\ncount on this produce `4`.\r\n\r\n> Accepting a single \"\\r\" is pretty strange, but that's what Hive does so we emulate this behavior.\r\n\r\nCase with `\\r`:\r\n\r\n```sql\r\nCREATE EXTERNAL TABlE tbl(value STRING) \r\nROW FORMAT DELIMITED LINES TERMINATED BY '\\r'\r\nSTORED AS TEXTFILE LOCATION '...';\r\n```\r\n\r\nproduced\r\n\r\n```\r\nFAILED: SemanticException 2:41 LINES TERMINATED BY only supports newline '\\n' right now. Error encountered near token ''\\r''\r\n...\r\norg.apache.hadoop.hive.ql.parse.SemanticException: 2:41 LINES TERMINATED BY only supports newline '\\n' right now. Error encountered near token ''\\r''\r\n```\r\n\r\nThis looks related with https://issues.apache.org/jira/browse/HIVE-5999\r\n\r\nand these lines:\r\n\r\nhttps://github.com/apache/hive/blob/696be9f52dfc6fb59c24de19726b4460100fc9ba/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java#L198-L203\r\n\r\nif I am not mistaken. This looks incomplete and not implemented to me.\r\n\r\nI am curious how this case was tested in the JIRA. If this test used `textinputformat.record.delimiter`, then, this seems Hadoop's property, which is basically the same thing as what I am doing here.\r\n\r\n\r\n> Is Hive using Hadoop's LineRecordReader?\r\n\r\nIn the case above, the input format was `org.apache.hadoop.mapred.TextInputFormat`, which uses `LineRecordReader`. \r\n\r\n> How does Hive support it?\r\n\r\nIt looks Hive tries to support it by `LINES TERMINATED BY '\\r'` https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-CreateTableCreate/Drop/TruncateTable. I could not find other (formal) ways.\r\n",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-26T04:48:57Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "**\\n = LF:**    \r\n> Multics, Unix and Unix-like systems (Linux, macOS, FreeBSD, AIX, Xenix, etc.), BeOS, Amiga, RISC OS, and others[1]\r\n\r\n**\\r\\n CR+LF:** \r\n> Microsoft Windows, DOS (MS-DOS, PC DOS, etc.), DEC TOPS-10, RT-11, CP/M, MP/M, Atari TOS, OS/2, Symbian OS, Palm OS, Amstrad CPC, and most other early non-Unix and non-IBM operating systems\r\n\r\n**\\r = CR:**    \r\n> Commodore 8-bit machines, Acorn BBC, ZX Spectrum, TRS-80, Apple II family, Oberon, the classic Mac OS, MIT Lisp Machine and OS-9",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-27T05:31:55Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "It sounds like Hive's behavior is reasonable. For most external users, `\\n` means a new line. Thus, it should match any of these three options: `LF`, `CR+LF` and `CR`. WDYT?",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-27T05:33:42Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I was thinking `\\n` means the first case of your comment above as it is set by the user explicitly. So, I thought If it is not given, it covers three cases of newlines by default. If we use `\\n` to deal with three cases above, wouldn't we are unable to cover, the arguably corner case of only handling `\\n`?",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-27T05:46:04Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "So far, following Hive is the safest. If users complain about it, we can behave differently from Hive with using a new SQLConf.",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-27T06:44:39Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "OK. Will change this but I should say this way looks incorrect to me and this behaviour should be discussed and possibly updated in the near future.",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-27T08:15:19Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */\n class HadoopFileLinesReader(\n-    file: PartitionedFile, conf: Configuration) extends Iterator[Text] with Closeable {\n+    file: PartitionedFile,\n+    lineSeparator: Option[String],"
  }],
  "prId": 18581
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Add `@parameter`?",
    "commit": "265dd48ce16fd62058f4515a9e91c67942b45ed7",
    "createdAt": "2017-08-27T16:22:18Z",
    "diffHunk": "@@ -32,7 +32,9 @@ import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl\n  * in that file.\n  */"
  }],
  "prId": 18581
}]