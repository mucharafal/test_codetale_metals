[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Shouldn't we split this file into a number of smaller units? \n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T15:45:21Z",
    "diffHunk": "@@ -0,0 +1,533 @@\n+/*",
    "line": 1
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "+1\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T19:08:36Z",
    "diffHunk": "@@ -0,0 +1,533 @@\n+/*",
    "line": 1
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "ok. I've split it to two files.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-23T11:59:20Z",
    "diffHunk": "@@ -0,0 +1,533 @@\n+/*",
    "line": 1
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Nit: A lot of duplicate code here. We could put it in a collection and do a lookup...\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T15:48:21Z",
    "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, Row, SQLConf, SQLContext}\n+import org.apache.spark.sql.catalyst.{CatalystTypeConverters, InternalRow, TableIdentifier}\n+import org.apache.spark.sql.catalyst.errors.TreeNodeException\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.execution._\n+import org.apache.spark.sql.execution.datasources.BucketSpec\n+import org.apache.spark.sql.types._\n+\n+abstract class NativeDDLCommands(val sql: String) extends RunnableCommand {\n+  override def run(sqlContext: SQLContext): Seq[Row] = {\n+    sqlContext.catalog.runNativeCommand(sql)\n+  }\n+\n+  override val output: Seq[Attribute] =\n+    Seq(AttributeReference(\"result\", StringType, nullable = false)())\n+}\n+\n+case class SetCommand(kv: Option[(String, Option[String])]) extends RunnableCommand with Logging {\n+\n+  private def keyValueOutput: Seq[Attribute] = {\n+    val schema = StructType(\n+      StructField(\"key\", StringType, false) ::\n+        StructField(\"value\", StringType, false) :: Nil)\n+    schema.toAttributes\n+  }\n+\n+  private val (_output, runFunc): (Seq[Attribute], SQLContext => Seq[Row]) = kv match {\n+    // Configures the deprecated \"mapred.reduce.tasks\" property.\n+    case Some((SQLConf.Deprecated.MAPRED_REDUCE_TASKS, Some(value))) =>\n+      val runFunc = (sqlContext: SQLContext) => {\n+        logWarning(\n+          s\"Property ${SQLConf.Deprecated.MAPRED_REDUCE_TASKS} is deprecated, \" +\n+            s\"automatically converted to ${SQLConf.SHUFFLE_PARTITIONS.key} instead.\")\n+        if (value.toInt < 1) {\n+          val msg =\n+            s\"Setting negative ${SQLConf.Deprecated.MAPRED_REDUCE_TASKS} for automatically \" +\n+              \"determining the number of reducers is not supported.\"\n+          throw new IllegalArgumentException(msg)\n+        } else {\n+          sqlContext.setConf(SQLConf.SHUFFLE_PARTITIONS.key, value)\n+          Seq(Row(SQLConf.SHUFFLE_PARTITIONS.key, value))\n+        }\n+      }\n+      (keyValueOutput, runFunc)\n+\n+    case Some((SQLConf.Deprecated.EXTERNAL_SORT, Some(value))) =>"
  }],
  "prId": 11048
}]