[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "when will users want to turn it off?\n",
    "commit": "2a965377258d4d77db5a3f00d4257bbacc4a0adb",
    "createdAt": "2016-10-19T03:09:59Z",
    "diffHunk": "@@ -32,13 +32,21 @@ import org.apache.spark.sql.types.StructType\n  * @param table the table's (unqualified) name\n  * @param partitionSchema the schema of a partitioned table's partition columns\n  * @param sizeInBytes the table's data size in bytes\n+ * @param enableFileStatusCache whether to enable file status caching\n  */\n class TableFileCatalog(\n     sparkSession: SparkSession,\n     db: String,\n     table: String,\n     partitionSchema: Option[StructType],\n-    override val sizeInBytes: Long) extends FileCatalog {\n+    override val sizeInBytes: Long,\n+    enableFileStatusCache: Boolean) extends FileCatalog {"
  }, {
    "author": {
      "login": "mallman"
    },
    "body": "I would turn it off if it was taking too much heap space, and I didn't have a better workaround.\n",
    "commit": "2a965377258d4d77db5a3f00d4257bbacc4a0adb",
    "createdAt": "2016-10-19T17:04:23Z",
    "diffHunk": "@@ -32,13 +32,21 @@ import org.apache.spark.sql.types.StructType\n  * @param table the table's (unqualified) name\n  * @param partitionSchema the schema of a partitioned table's partition columns\n  * @param sizeInBytes the table's data size in bytes\n+ * @param enableFileStatusCache whether to enable file status caching\n  */\n class TableFileCatalog(\n     sparkSession: SparkSession,\n     db: String,\n     table: String,\n     partitionSchema: Option[StructType],\n-    override val sizeInBytes: Long) extends FileCatalog {\n+    override val sizeInBytes: Long,\n+    enableFileStatusCache: Boolean) extends FileCatalog {"
  }],
  "prId": 15539
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "`cachedAllPartitions` is useless now.\n",
    "commit": "2a965377258d4d77db5a3f00d4257bbacc4a0adb",
    "createdAt": "2016-10-20T02:24:39Z",
    "diffHunk": "@@ -87,21 +85,13 @@ class TableFileCatalog(\n         }\n         val partitionSpec = PartitionSpec(schema, partitions)\n         new PrunedTableFileCatalog(\n-          sparkSession, new Path(baseLocation.get), partitionSpec)\n+          sparkSession, new Path(baseLocation.get), fileStatusCache, partitionSpec)\n       case None =>\n-        new ListingFileCatalog(sparkSession, rootPaths, parameters, None)\n-    }\n-  }\n-\n-  // Not used in the hot path of queries when metastore partition pruning is enabled\n-  def allPartitions: ListingFileCatalog = synchronized {\n-    if (cachedAllPartitions == null) {",
    "line": 64
  }, {
    "author": {
      "login": "ericl"
    },
    "body": "Removed\n",
    "commit": "2a965377258d4d77db5a3f00d4257bbacc4a0adb",
    "createdAt": "2016-10-20T18:59:00Z",
    "diffHunk": "@@ -87,21 +85,13 @@ class TableFileCatalog(\n         }\n         val partitionSpec = PartitionSpec(schema, partitions)\n         new PrunedTableFileCatalog(\n-          sparkSession, new Path(baseLocation.get), partitionSpec)\n+          sparkSession, new Path(baseLocation.get), fileStatusCache, partitionSpec)\n       case None =>\n-        new ListingFileCatalog(sparkSession, rootPaths, parameters, None)\n-    }\n-  }\n-\n-  // Not used in the hot path of queries when metastore partition pruning is enabled\n-  def allPartitions: ListingFileCatalog = synchronized {\n-    if (cachedAllPartitions == null) {",
    "line": 64
  }],
  "prId": 15539
}, {
  "comments": [{
    "author": {
      "login": "mallman"
    },
    "body": "Does the file status cache need to be private to an instance of `TableFileCatalog`? Can we use the table's qualified name as the key here instead?\n",
    "commit": "2a965377258d4d77db5a3f00d4257bbacc4a0adb",
    "createdAt": "2016-10-21T00:39:47Z",
    "diffHunk": "@@ -42,24 +43,21 @@ class TableFileCatalog(\n \n   protected val hadoopConf = sparkSession.sessionState.newHadoopConf\n \n+  private val fileStatusCache = FileStatusCache.getOrInitializeShared(new Object(), sparkSession)"
  }, {
    "author": {
      "login": "ericl"
    },
    "body": "The way we currently refresh tables is by dropping the reference to TableFileCatalog and letting it get GC'ed. Given this strategy, making it private is the simplest way to ensure refresh actually works correctly -- otherwise you have to carefully test that refresh also invalidates shared cache entries.\n",
    "commit": "2a965377258d4d77db5a3f00d4257bbacc4a0adb",
    "createdAt": "2016-10-21T06:25:24Z",
    "diffHunk": "@@ -42,24 +43,21 @@ class TableFileCatalog(\n \n   protected val hadoopConf = sparkSession.sessionState.newHadoopConf\n \n+  private val fileStatusCache = FileStatusCache.getOrInitializeShared(new Object(), sparkSession)"
  }, {
    "author": {
      "login": "mallman"
    },
    "body": "Odd, I figured we'd call the `refresh` method to refresh the table.\n\nThe reason I suggested using the table's name is so that all references to the same table can use the same cacheâ€”avoid redundant cache entries and provide the ability to inherit cached entries for new instances of the same logical table. Aside from implementation issues, does that make sense?\n\nAnyway, this is something we can explore in a follow up PR if desired.\n",
    "commit": "2a965377258d4d77db5a3f00d4257bbacc4a0adb",
    "createdAt": "2016-10-21T16:03:35Z",
    "diffHunk": "@@ -42,24 +43,21 @@ class TableFileCatalog(\n \n   protected val hadoopConf = sparkSession.sessionState.newHadoopConf\n \n+  private val fileStatusCache = FileStatusCache.getOrInitializeShared(new Object(), sparkSession)"
  }],
  "prId": 15539
}]