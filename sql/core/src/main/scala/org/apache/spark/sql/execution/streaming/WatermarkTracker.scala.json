[{
  "comments": [{
    "author": {
      "login": "brkyvz"
    },
    "body": "I would comment on the contracts. We expect a certain ordering of stateful operators across triggers. therefore we turn off cbo, etc",
    "commit": "da3fd2f8510482e3e71cc37a9da2207e3aef1ef0",
    "createdAt": "2018-05-03T18:17:50Z",
    "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+class WatermarkTracker extends Logging {\n+  private val operatorToWatermarkMap = mutable.HashMap[Int, Long]()\n+  private var watermarkMs: Long = 0\n+  private var updated = false\n+\n+  def setWatermark(newWatermarkMs: Long): Unit = synchronized {\n+    watermarkMs = newWatermarkMs\n+  }\n+\n+  def updateWatermark(executedPlan: SparkPlan): Unit = synchronized {\n+    val watermarkOperators = executedPlan.collect {",
    "line": 35
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "I dont think we do anything that depends on ordering of EventTimeWatermarkExec. We choose to take the minimum watermark calculated across multiple of them independent of the order.",
    "commit": "da3fd2f8510482e3e71cc37a9da2207e3aef1ef0",
    "createdAt": "2018-05-04T00:57:55Z",
    "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+class WatermarkTracker extends Logging {\n+  private val operatorToWatermarkMap = mutable.HashMap[Int, Long]()\n+  private var watermarkMs: Long = 0\n+  private var updated = false\n+\n+  def setWatermark(newWatermarkMs: Long): Unit = synchronized {\n+    watermarkMs = newWatermarkMs\n+  }\n+\n+  def updateWatermark(executedPlan: SparkPlan): Unit = synchronized {\n+    val watermarkOperators = executedPlan.collect {",
    "line": 35
  }],
  "prId": 21220
}, {
  "comments": [{
    "author": {
      "login": "brkyvz"
    },
    "body": "is this used anywhere?",
    "commit": "da3fd2f8510482e3e71cc37a9da2207e3aef1ef0",
    "createdAt": "2018-05-03T18:20:00Z",
    "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+class WatermarkTracker extends Logging {\n+  private val operatorToWatermarkMap = mutable.HashMap[Int, Long]()\n+  private var watermarkMs: Long = 0\n+  private var updated = false\n+\n+  def setWatermark(newWatermarkMs: Long): Unit = synchronized {\n+    watermarkMs = newWatermarkMs\n+  }\n+\n+  def updateWatermark(executedPlan: SparkPlan): Unit = synchronized {\n+    val watermarkOperators = executedPlan.collect {\n+      case e: EventTimeWatermarkExec => e\n+    }\n+    if (watermarkOperators.isEmpty) return\n+\n+\n+    watermarkOperators.zipWithIndex.foreach {\n+      case (e, index) if e.eventTimeStats.value.count > 0 =>\n+        logDebug(s\"Observed event time stats $index: ${e.eventTimeStats.value}\")\n+        val newWatermarkMs = e.eventTimeStats.value.max - e.delayMs\n+        val prevWatermarkMs = operatorToWatermarkMap.get(index)\n+        if (prevWatermarkMs.isEmpty || newWatermarkMs > prevWatermarkMs.get) {\n+          operatorToWatermarkMap.put(index, newWatermarkMs)\n+        }\n+\n+      // Populate 0 if we haven't seen any data yet for this watermark node.\n+      case (_, index) =>\n+        if (!operatorToWatermarkMap.isDefinedAt(index)) {\n+          operatorToWatermarkMap.put(index, 0)\n+        }\n+    }\n+\n+    // Update the global watermark to the minimum of all watermark nodes.\n+    // This is the safest option, because only the global watermark is fault-tolerant. Making\n+    // it the minimum of all individual watermarks guarantees it will never advance past where\n+    // any individual watermark operator would be if it were in a plan by itself.\n+    val newWatermarkMs = operatorToWatermarkMap.minBy(_._2)._2\n+    if (newWatermarkMs > watermarkMs) {\n+      logInfo(s\"Updating eventTime watermark to: $newWatermarkMs ms\")\n+      watermarkMs = newWatermarkMs\n+      updated = true\n+    } else {\n+      logDebug(s\"Event time didn't move: $newWatermarkMs < $watermarkMs\")\n+      updated = false\n+    }\n+  }\n+\n+  def watermarkUpdated: Boolean = synchronized { updated }"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "No. I will remove it. ",
    "commit": "da3fd2f8510482e3e71cc37a9da2207e3aef1ef0",
    "createdAt": "2018-05-04T00:19:43Z",
    "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+class WatermarkTracker extends Logging {\n+  private val operatorToWatermarkMap = mutable.HashMap[Int, Long]()\n+  private var watermarkMs: Long = 0\n+  private var updated = false\n+\n+  def setWatermark(newWatermarkMs: Long): Unit = synchronized {\n+    watermarkMs = newWatermarkMs\n+  }\n+\n+  def updateWatermark(executedPlan: SparkPlan): Unit = synchronized {\n+    val watermarkOperators = executedPlan.collect {\n+      case e: EventTimeWatermarkExec => e\n+    }\n+    if (watermarkOperators.isEmpty) return\n+\n+\n+    watermarkOperators.zipWithIndex.foreach {\n+      case (e, index) if e.eventTimeStats.value.count > 0 =>\n+        logDebug(s\"Observed event time stats $index: ${e.eventTimeStats.value}\")\n+        val newWatermarkMs = e.eventTimeStats.value.max - e.delayMs\n+        val prevWatermarkMs = operatorToWatermarkMap.get(index)\n+        if (prevWatermarkMs.isEmpty || newWatermarkMs > prevWatermarkMs.get) {\n+          operatorToWatermarkMap.put(index, newWatermarkMs)\n+        }\n+\n+      // Populate 0 if we haven't seen any data yet for this watermark node.\n+      case (_, index) =>\n+        if (!operatorToWatermarkMap.isDefinedAt(index)) {\n+          operatorToWatermarkMap.put(index, 0)\n+        }\n+    }\n+\n+    // Update the global watermark to the minimum of all watermark nodes.\n+    // This is the safest option, because only the global watermark is fault-tolerant. Making\n+    // it the minimum of all individual watermarks guarantees it will never advance past where\n+    // any individual watermark operator would be if it were in a plan by itself.\n+    val newWatermarkMs = operatorToWatermarkMap.minBy(_._2)._2\n+    if (newWatermarkMs > watermarkMs) {\n+      logInfo(s\"Updating eventTime watermark to: $newWatermarkMs ms\")\n+      watermarkMs = newWatermarkMs\n+      updated = true\n+    } else {\n+      logDebug(s\"Event time didn't move: $newWatermarkMs < $watermarkMs\")\n+      updated = false\n+    }\n+  }\n+\n+  def watermarkUpdated: Boolean = synchronized { updated }"
  }],
  "prId": 21220
}]