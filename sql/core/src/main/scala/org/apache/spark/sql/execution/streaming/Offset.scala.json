[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: extra lines.\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-25T18:59:33Z",
    "diffHunk": "@@ -23,4 +23,16 @@ package org.apache.spark.sql.execution.streaming\n  * ordering of two [[Offset]] instances.  We do assume that if two offsets are `equal` then no\n  * new data has arrived.\n  */\n-trait Offset extends Serializable {}\n+abstract class Offset {\n+  def json: String\n+}\n+\n+/** Used when loading */\n+class SerializedOffset(override val json: String) extends Offset\n+\n+\n+object SerializedOffset {\n+\n+  def apply(json: String): SerializedOffset = new SerializedOffset(json)\n+\n+}"
  }],
  "prId": 15626
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Add scala docs for the method.\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-25T18:59:47Z",
    "diffHunk": "@@ -23,4 +23,16 @@ package org.apache.spark.sql.execution.streaming\n  * ordering of two [[Offset]] instances.  We do assume that if two offsets are `equal` then no\n  * new data has arrived.\n  */\n-trait Offset extends Serializable {}\n+abstract class Offset {\n+  def json: String"
  }],
  "prId": 15626
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "this can be a `case class` in which case the apply below wont be needed.\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-25T19:21:07Z",
    "diffHunk": "@@ -23,4 +23,16 @@ package org.apache.spark.sql.execution.streaming\n  * ordering of two [[Offset]] instances.  We do assume that if two offsets are `equal` then no\n  * new data has arrived.\n  */\n-trait Offset extends Serializable {}\n+abstract class Offset {\n+  def json: String\n+}\n+\n+/** Used when loading */\n+class SerializedOffset(override val json: String) extends Offset"
  }, {
    "author": {
      "login": "tcondie"
    },
    "body": "Makes sense.\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-25T23:49:21Z",
    "diffHunk": "@@ -23,4 +23,16 @@ package org.apache.spark.sql.execution.streaming\n  * ordering of two [[Offset]] instances.  We do assume that if two offsets are `equal` then no\n  * new data has arrived.\n  */\n-trait Offset extends Serializable {}\n+abstract class Offset {\n+  def json: String\n+}\n+\n+/** Used when loading */\n+class SerializedOffset(override val json: String) extends Offset"
  }],
  "prId": 15626
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Improve the docs to something like \"A JSON-serialized representation of an Offset that is used for saving offsets to the offset log\"\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-25T19:21:35Z",
    "diffHunk": "@@ -23,4 +23,16 @@ package org.apache.spark.sql.execution.streaming\n  * ordering of two [[Offset]] instances.  We do assume that if two offsets are `equal` then no\n  * new data has arrived.\n  */\n-trait Offset extends Serializable {}\n+abstract class Offset {\n+  def json: String\n+}\n+\n+/** Used when loading */"
  }, {
    "author": {
      "login": "tcondie"
    },
    "body": "Got it.\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-25T23:49:07Z",
    "diffHunk": "@@ -23,4 +23,16 @@ package org.apache.spark.sql.execution.streaming\n  * ordering of two [[Offset]] instances.  We do assume that if two offsets are `equal` then no\n  * new data has arrived.\n  */\n-trait Offset extends Serializable {}\n+abstract class Offset {\n+  def json: String\n+}\n+\n+/** Used when loading */"
  }],
  "prId": 15626
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Needs better docs. I think i had commented that earlier.\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-28T20:19:00Z",
    "diffHunk": "@@ -23,4 +23,16 @@ package org.apache.spark.sql.execution.streaming\n  * ordering of two [[Offset]] instances.  We do assume that if two offsets are `equal` then no\n  * new data has arrived.\n  */\n-trait Offset extends Serializable {}\n+abstract class Offset {\n+\n+  /**\n+   * A JSON-serialized representation of an Offset that is\n+   * used for saving offsets to the offset log.\n+   *\n+   * @return JSON string encoding\n+   */\n+  def json: String\n+}\n+\n+/** Used when loading */"
  }, {
    "author": {
      "login": "tcondie"
    },
    "body": "Added.\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-28T21:44:35Z",
    "diffHunk": "@@ -23,4 +23,16 @@ package org.apache.spark.sql.execution.streaming\n  * ordering of two [[Offset]] instances.  We do assume that if two offsets are `equal` then no\n  * new data has arrived.\n  */\n-trait Offset extends Serializable {}\n+abstract class Offset {\n+\n+  /**\n+   * A JSON-serialized representation of an Offset that is\n+   * used for saving offsets to the offset log.\n+   *\n+   * @return JSON string encoding\n+   */\n+  def json: String\n+}\n+\n+/** Used when loading */"
  }],
  "prId": 15626
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "need to add `final`\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-11-02T18:51:35Z",
    "diffHunk": "@@ -23,4 +23,36 @@ package org.apache.spark.sql.execution.streaming\n  * ordering of two [[Offset]] instances.  We do assume that if two offsets are `equal` then no\n  * new data has arrived.\n  */\n-trait Offset extends Serializable {}\n+abstract class Offset {\n+\n+  /**\n+   * Equality based on JSON string representation.\n+   */\n+  override final def equals(obj: Any): Boolean = obj match {\n+    case o: Offset => this.json == o.json\n+    case _ => false\n+  }\n+\n+  override def hashCode(): Int = this.json.hashCode",
    "line": 17
  }],
  "prId": 15626
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "nit: could you document that we only compare the json string, please?\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-11-02T19:02:30Z",
    "diffHunk": "@@ -23,4 +23,36 @@ package org.apache.spark.sql.execution.streaming\n  * ordering of two [[Offset]] instances.  We do assume that if two offsets are `equal` then no\n  * new data has arrived.\n  */\n-trait Offset extends Serializable {}\n+abstract class Offset {",
    "line": 5
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "We should also document in `Source.getBatch` that `start` and `end` may be semantics same but has different json representations and the Source should handle this case. \n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-11-02T19:03:38Z",
    "diffHunk": "@@ -23,4 +23,36 @@ package org.apache.spark.sql.execution.streaming\n  * ordering of two [[Offset]] instances.  We do assume that if two offsets are `equal` then no\n  * new data has arrived.\n  */\n-trait Offset extends Serializable {}\n+abstract class Offset {",
    "line": 5
  }],
  "prId": 15626
}]