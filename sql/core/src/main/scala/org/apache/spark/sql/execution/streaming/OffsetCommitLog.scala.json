[{
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "We should make sure the error here is consistent with the work being done in #17070",
    "commit": "0c3e20c2e3586ad406796014397a1791c2305fe5",
    "createdAt": "2017-03-09T00:35:35Z",
    "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import java.io.{InputStream, OutputStream}\n+import java.nio.charset.StandardCharsets._\n+\n+import scala.io.{Source => IOSource}\n+\n+import org.apache.spark.sql.SparkSession\n+\n+class OffsetCommitLog(sparkSession: SparkSession, path: String)\n+  extends HDFSMetadataLog[Option[String]](sparkSession, path) {\n+\n+  override protected def deserialize(in: InputStream): Option[String] = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+    val lines = IOSource.fromInputStream(in, UTF_8.name()).getLines()\n+    if (!lines.hasNext) {\n+      throw new IllegalStateException(\"Incomplete log file\")\n+    }\n+    val version = lines.next()\n+    if (version != OffsetCommitLog.VERSION) {\n+      throw new IllegalStateException(s\"Unknown log version: ${version}\")"
  }],
  "prId": 17219
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "Why not make this an empty json object? `{}`",
    "commit": "0c3e20c2e3586ad406796014397a1791c2305fe5",
    "createdAt": "2017-03-09T00:36:07Z",
    "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import java.io.{InputStream, OutputStream}\n+import java.nio.charset.StandardCharsets._\n+\n+import scala.io.{Source => IOSource}\n+\n+import org.apache.spark.sql.SparkSession\n+\n+class OffsetCommitLog(sparkSession: SparkSession, path: String)\n+  extends HDFSMetadataLog[Option[String]](sparkSession, path) {\n+\n+  override protected def deserialize(in: InputStream): Option[String] = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+    val lines = IOSource.fromInputStream(in, UTF_8.name()).getLines()\n+    if (!lines.hasNext) {\n+      throw new IllegalStateException(\"Incomplete log file\")\n+    }\n+    val version = lines.next()\n+    if (version != OffsetCommitLog.VERSION) {\n+      throw new IllegalStateException(s\"Unknown log version: ${version}\")\n+    }\n+    // read metadata\n+    lines.next().trim match {\n+      case OffsetCommitLog.SERIALIZED_VOID => None\n+      case metadata => Some(metadata)\n+    }\n+  }\n+\n+  override protected def serialize(metadata: Option[String], out: OutputStream): Unit = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+    out.write(OffsetCommitLog.VERSION.getBytes(UTF_8))\n+    out.write('\\n')\n+\n+    // write metadata or void\n+    out.write(metadata.getOrElse(OffsetCommitLog.SERIALIZED_VOID).getBytes(UTF_8))\n+  }\n+}\n+\n+object OffsetCommitLog {\n+  private val VERSION = \"v1\"\n+  private val SERIALIZED_VOID = \"-\""
  }],
  "prId": 17219
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "Scala doc please",
    "commit": "0c3e20c2e3586ad406796014397a1791c2305fe5",
    "createdAt": "2017-03-09T00:41:34Z",
    "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import java.io.{InputStream, OutputStream}\n+import java.nio.charset.StandardCharsets._\n+\n+import scala.io.{Source => IOSource}\n+\n+import org.apache.spark.sql.SparkSession\n+\n+class OffsetCommitLog(sparkSession: SparkSession, path: String)"
  }],
  "prId": 17219
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "can you say \"incomplete log file in the offset commit log\"",
    "commit": "0c3e20c2e3586ad406796014397a1791c2305fe5",
    "createdAt": "2017-03-17T20:25:46Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import java.io.{InputStream, OutputStream}\n+import java.nio.charset.StandardCharsets._\n+\n+import scala.io.{Source => IOSource}\n+\n+import org.apache.spark.sql.SparkSession\n+\n+/**\n+ * Used to write log files that represent commit points in structured streaming.\n+ * A log file will be written immediately after the successful completion of a\n+ * batch, and before processing the next batch. Here is an execution summary:\n+ * - trigger batch 1\n+ * - obtain batch 1 offsets and write to offset log\n+ * - process batch 1\n+ * - write batch 1 to commit log\n+ * - trigger batch 2\n+ * - obtain bactch 2 offsets and write to offset log\n+ * - process batch 2\n+ * - write batch 2 to commit log\n+ * ....\n+ *\n+ * The current format of the commit log is:\n+ * line 1: version\n+ * line 2: metadata (optional json string)\n+ */\n+class OffsetCommitLog(sparkSession: SparkSession, path: String)\n+  extends HDFSMetadataLog[Option[String]](sparkSession, path) {\n+\n+  override protected def deserialize(in: InputStream): Option[String] = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+    val lines = IOSource.fromInputStream(in, UTF_8.name()).getLines()\n+    if (!lines.hasNext) {\n+      throw new IllegalStateException(\"Incomplete log file\")"
  }],
  "prId": 17219
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Lets be consistent with other logs in writing \"v1\" for version and not \"1\"",
    "commit": "0c3e20c2e3586ad406796014397a1791c2305fe5",
    "createdAt": "2017-03-17T20:32:16Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+import java.io.{InputStream, OutputStream}\n+import java.nio.charset.StandardCharsets._\n+\n+import scala.io.{Source => IOSource}\n+\n+import org.apache.spark.sql.SparkSession\n+\n+/**\n+ * Used to write log files that represent commit points in structured streaming.\n+ * A log file will be written immediately after the successful completion of a\n+ * batch, and before processing the next batch. Here is an execution summary:\n+ * - trigger batch 1\n+ * - obtain batch 1 offsets and write to offset log\n+ * - process batch 1\n+ * - write batch 1 to commit log\n+ * - trigger batch 2\n+ * - obtain bactch 2 offsets and write to offset log\n+ * - process batch 2\n+ * - write batch 2 to commit log\n+ * ....\n+ *\n+ * The current format of the commit log is:\n+ * line 1: version\n+ * line 2: metadata (optional json string)\n+ */\n+class OffsetCommitLog(sparkSession: SparkSession, path: String)\n+  extends HDFSMetadataLog[Option[String]](sparkSession, path) {\n+\n+  override protected def deserialize(in: InputStream): Option[String] = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+    val lines = IOSource.fromInputStream(in, UTF_8.name()).getLines()\n+    if (!lines.hasNext) {\n+      throw new IllegalStateException(\"Incomplete log file\")\n+    }\n+    val version = lines.next().trim.toInt\n+    if (OffsetCommitLog.VERSION < version) {\n+      throw new IllegalStateException(s\"Incompatible log file version ${version}\")\n+    }\n+    // read metadata\n+    lines.next().trim match {\n+      case OffsetCommitLog.SERIALIZED_VOID => None\n+      case metadata => Some(metadata)\n+    }\n+  }\n+\n+  override protected def serialize(metadata: Option[String], out: OutputStream): Unit = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+    out.write(OffsetCommitLog.VERSION.toString.getBytes(UTF_8))\n+    out.write('\\n')\n+\n+    // write metadata or void\n+    out.write(metadata.getOrElse(OffsetCommitLog.SERIALIZED_VOID).getBytes(UTF_8))\n+  }\n+}\n+\n+object OffsetCommitLog {\n+  private val VERSION = 1"
  }],
  "prId": 17219
}]