[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "super nit: to **a** DataSourceV2Writer",
    "commit": "f3c170ed6bf10d2a23f47591d236cd4c5d4d73c2",
    "createdAt": "2018-01-12T20:25:03Z",
    "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.sources\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.sources.v2.writer.{DataWriter, DataWriterFactory, WriterCommitMessage}\n+\n+/**\n+ * A simple [[DataWriterFactory]] whose tasks just pack rows into the commit message for delivery\n+ * to the [[org.apache.spark.sql.sources.v2.writer.DataSourceV2Writer]] on the driver."
  }],
  "prId": 20243
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "add docs.",
    "commit": "f3c170ed6bf10d2a23f47591d236cd4c5d4d73c2",
    "createdAt": "2018-01-17T06:48:43Z",
    "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.sources\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.sources.v2.writer.{DataWriter, DataWriterFactory, WriterCommitMessage}\n+\n+/**\n+ * A simple [[DataWriterFactory]] whose tasks just pack rows into the commit message for delivery\n+ * to a [[org.apache.spark.sql.sources.v2.writer.DataSourceV2Writer]] on the driver.\n+ */\n+case object PackedRowWriterFactory extends DataWriterFactory[Row] {\n+  def createDataWriter(partitionId: Int, attemptNumber: Int): DataWriter[Row] = {\n+    new PackedRowDataWriter()\n+  }\n+}\n+\n+case class PackedRowCommitMessage(rows: Array[Row]) extends WriterCommitMessage\n+\n+class PackedRowDataWriter() extends DataWriter[Row] with Logging {"
  }],
  "prId": 20243
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "add docs.",
    "commit": "f3c170ed6bf10d2a23f47591d236cd4c5d4d73c2",
    "createdAt": "2018-01-17T06:48:48Z",
    "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.sources\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.sources.v2.writer.{DataWriter, DataWriterFactory, WriterCommitMessage}\n+\n+/**\n+ * A simple [[DataWriterFactory]] whose tasks just pack rows into the commit message for delivery\n+ * to a [[org.apache.spark.sql.sources.v2.writer.DataSourceV2Writer]] on the driver.\n+ */\n+case object PackedRowWriterFactory extends DataWriterFactory[Row] {\n+  def createDataWriter(partitionId: Int, attemptNumber: Int): DataWriter[Row] = {\n+    new PackedRowDataWriter()\n+  }\n+}\n+\n+case class PackedRowCommitMessage(rows: Array[Row]) extends WriterCommitMessage"
  }],
  "prId": 20243
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "why are you cloning and then calling toArray? Just `data.toArray` will create an immutable copy.",
    "commit": "f3c170ed6bf10d2a23f47591d236cd4c5d4d73c2",
    "createdAt": "2018-01-17T06:51:23Z",
    "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.sources\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.sources.v2.writer.{DataWriter, DataWriterFactory, WriterCommitMessage}\n+\n+/**\n+ * A simple [[DataWriterFactory]] whose tasks just pack rows into the commit message for delivery\n+ * to a [[org.apache.spark.sql.sources.v2.writer.DataSourceV2Writer]] on the driver.\n+ */\n+case object PackedRowWriterFactory extends DataWriterFactory[Row] {\n+  def createDataWriter(partitionId: Int, attemptNumber: Int): DataWriter[Row] = {\n+    new PackedRowDataWriter()\n+  }\n+}\n+\n+case class PackedRowCommitMessage(rows: Array[Row]) extends WriterCommitMessage\n+\n+class PackedRowDataWriter() extends DataWriter[Row] with Logging {\n+  private val data = mutable.Buffer[Row]()\n+\n+  override def write(row: Row): Unit = data.append(row)\n+\n+  override def commit(): PackedRowCommitMessage = {\n+    val msg = PackedRowCommitMessage(data.clone().toArray)"
  }],
  "prId": 20243
}]