[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "other changes LGTM too but one question is, why is it `QueryExecutionException`? I thought it'd be `SparkException`.",
    "commit": "3bbc2b02d658112a546c5472586b0042075d390b",
    "createdAt": "2018-04-12T08:57:43Z",
    "diffHunk": "@@ -179,7 +182,23 @@ class FileScanRDD(\n             currentIterator = readCurrentFile()\n           }\n \n-          hasNext\n+          try {\n+            hasNext\n+          } catch {\n+            case e: SchemaColumnConvertNotSupportedException =>\n+              val message = \"Parquet column cannot be converted in \" +\n+                s\"file ${currentFile.filePath}. Column: ${e.getColumn}, \" +\n+                s\"Expected: ${e.getLogicalType}, Found: ${e.getPhysicalType}\"\n+              throw new QueryExecutionException(message, e)",
    "line": 27
  }, {
    "author": {
      "login": "yuchenhuo"
    },
    "body": "According to my discussion with @gatorsmile, he thought that we should throw some exception that could be captured and displayed in a better form. And since we already have some exception wrapping at https://github.com/apache/spark/blob/master/python/pyspark/sql/utils.py#L60 it seem appropriate to use QueryExecutionException instead of the original SparkException.",
    "commit": "3bbc2b02d658112a546c5472586b0042075d390b",
    "createdAt": "2018-04-12T22:36:19Z",
    "diffHunk": "@@ -179,7 +182,23 @@ class FileScanRDD(\n             currentIterator = readCurrentFile()\n           }\n \n-          hasNext\n+          try {\n+            hasNext\n+          } catch {\n+            case e: SchemaColumnConvertNotSupportedException =>\n+              val message = \"Parquet column cannot be converted in \" +\n+                s\"file ${currentFile.filePath}. Column: ${e.getColumn}, \" +\n+                s\"Expected: ${e.getLogicalType}, Found: ${e.getPhysicalType}\"\n+              throw new QueryExecutionException(message, e)",
    "line": 27
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I don't think that's captured since it's thrown in execution - the stack trace wouldn't start with \"org.apache.spark.sql.execution.QueryExecutionException\". Can you double check if that's true?",
    "commit": "3bbc2b02d658112a546c5472586b0042075d390b",
    "createdAt": "2018-04-13T01:51:32Z",
    "diffHunk": "@@ -179,7 +182,23 @@ class FileScanRDD(\n             currentIterator = readCurrentFile()\n           }\n \n-          hasNext\n+          try {\n+            hasNext\n+          } catch {\n+            case e: SchemaColumnConvertNotSupportedException =>\n+              val message = \"Parquet column cannot be converted in \" +\n+                s\"file ${currentFile.filePath}. Column: ${e.getColumn}, \" +\n+                s\"Expected: ${e.getLogicalType}, Found: ${e.getPhysicalType}\"\n+              throw new QueryExecutionException(message, e)",
    "line": 27
  }, {
    "author": {
      "login": "yuchenhuo"
    },
    "body": "Yes, you are right. Sorry, I shouldn't say \"use QueryExecutionException instead of the original SparkException\". The final exception would still be wrapped with a SparkException. Inside the SparkException would be QueryExecutionException. But the reason is still the same, they don't want to throw too many different Exceptions which might be hard to capture and display.\r\n\r\n![38043674-a2485370-326c-11e8-82a6-c36691f1e523](https://user-images.githubusercontent.com/37087310/38722077-9e115878-3eb1-11e8-989c-525268c96e3f.png)\r\n",
    "commit": "3bbc2b02d658112a546c5472586b0042075d390b",
    "createdAt": "2018-04-13T07:31:34Z",
    "diffHunk": "@@ -179,7 +182,23 @@ class FileScanRDD(\n             currentIterator = readCurrentFile()\n           }\n \n-          hasNext\n+          try {\n+            hasNext\n+          } catch {\n+            case e: SchemaColumnConvertNotSupportedException =>\n+              val message = \"Parquet column cannot be converted in \" +\n+                s\"file ${currentFile.filePath}. Column: ${e.getColumn}, \" +\n+                s\"Expected: ${e.getLogicalType}, Found: ${e.getPhysicalType}\"\n+              throw new QueryExecutionException(message, e)",
    "line": 27
  }],
  "prId": 20953
}]