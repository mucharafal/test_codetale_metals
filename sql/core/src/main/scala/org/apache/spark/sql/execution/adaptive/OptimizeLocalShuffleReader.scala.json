[{
  "comments": [{
    "author": {
      "login": "maryannxue"
    },
    "body": "nit: maybe we don't need to declare this a method any more. it's used only once anyway.",
    "commit": "28db7b6628d4ef9d7e36439d8275ce2036abca85",
    "createdAt": "2019-11-21T15:44:44Z",
    "diffHunk": "@@ -39,41 +39,24 @@ import org.apache.spark.sql.internal.SQLConf\n case class OptimizeLocalShuffleReader(conf: SQLConf) extends Rule[SparkPlan] {\n   import OptimizeLocalShuffleReader._\n \n-  def withProbeSideLocalReader(plan: SparkPlan): SparkPlan = {\n-    plan.transformDown {\n+  // The build side is a broadcast query stage which should have been optimized using local reader\n+  // already. So we only need to deal with probe side here.\n+  private def createProbeSideLocalReader(plan: SparkPlan): SparkPlan = {\n+    val optimizedPlan = plan.transformDown {\n       case join @ BroadcastJoinWithShuffleLeft(shuffleStage, BuildRight) =>\n         val localReader = createLocalReader(shuffleStage)\n         join.asInstanceOf[BroadcastHashJoinExec].copy(left = localReader)\n       case join @ BroadcastJoinWithShuffleRight(shuffleStage, BuildLeft) =>\n         val localReader = createLocalReader(shuffleStage)\n         join.asInstanceOf[BroadcastHashJoinExec].copy(right = localReader)\n     }\n-  }\n-\n-  def createLocalReader(plan: SparkPlan): LocalShuffleReaderExec = {\n-    plan match {\n-      case c: CoalescedShuffleReaderExec =>\n-        LocalShuffleReaderExec(c.child, Some(c.partitionStartIndices.length))\n-      case q: QueryStageExec => LocalShuffleReaderExec(q)\n-    }\n-  }\n-\n-  override def apply(plan: SparkPlan): SparkPlan = {\n-    if (!conf.getConf(SQLConf.OPTIMIZE_LOCAL_SHUFFLE_READER_ENABLED)) {\n-      return plan\n-    }\n-\n-    val optimizedPlan = plan match {\n-      case s: SparkPlan if canUseLocalShuffleReader(s) =>\n-        createLocalReader(s)\n-      case s: SparkPlan => withProbeSideLocalReader(s)\n-    }\n \n     def numExchanges(plan: SparkPlan): Int = {"
  }],
  "prId": 26625
}]