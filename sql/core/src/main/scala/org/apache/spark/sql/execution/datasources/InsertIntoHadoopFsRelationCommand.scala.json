[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "For append mode, is that possible we can just add the delta, instead of re-calculating the whole table?",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-18T20:32:12Z",
    "diffHunk": "@@ -161,6 +161,11 @@ case class InsertIntoHadoopFsRelationCommand(\n       fileIndex.foreach(_.refresh())\n       // refresh data cache if table is cached\n       sparkSession.catalog.refreshByPath(outputPath.toString)\n+\n+      if (catalogTable.nonEmpty) {\n+        CommandUtils.updateTableStats(sparkSession, catalogTable.get)"
  }, {
    "author": {
      "login": "wzhfy"
    },
    "body": "It's difficult to get the size of `query` in insert command.\r\nBesides, I personally prefer simple implementation here, because usually the overhead of getting file size is negligible compared to the append operation.",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-19T18:42:44Z",
    "diffHunk": "@@ -161,6 +161,11 @@ case class InsertIntoHadoopFsRelationCommand(\n       fileIndex.foreach(_.refresh())\n       // refresh data cache if table is cached\n       sparkSession.catalog.refreshByPath(outputPath.toString)\n+\n+      if (catalogTable.nonEmpty) {\n+        CommandUtils.updateTableStats(sparkSession, catalogTable.get)"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "When the number of files are large, it is very slow. ",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-27T16:16:21Z",
    "diffHunk": "@@ -161,6 +161,11 @@ case class InsertIntoHadoopFsRelationCommand(\n       fileIndex.foreach(_.refresh())\n       // refresh data cache if table is cached\n       sparkSession.catalog.refreshByPath(outputPath.toString)\n+\n+      if (catalogTable.nonEmpty) {\n+        CommandUtils.updateTableStats(sparkSession, catalogTable.get)"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "This is not acceptable in the cloud environment. ",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-27T16:16:53Z",
    "diffHunk": "@@ -161,6 +161,11 @@ case class InsertIntoHadoopFsRelationCommand(\n       fileIndex.foreach(_.refresh())\n       // refresh data cache if table is cached\n       sparkSession.catalog.refreshByPath(outputPath.toString)\n+\n+      if (catalogTable.nonEmpty) {\n+        CommandUtils.updateTableStats(sparkSession, catalogTable.get)"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "> hive.stats.autogather\r\n> Default Value: true\r\n> Added In: Hive 0.7 with HIVE-1361\r\n> A flag to gather statistics automatically during the INSERT OVERWRITE command.",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-27T16:17:18Z",
    "diffHunk": "@@ -161,6 +161,11 @@ case class InsertIntoHadoopFsRelationCommand(\n       fileIndex.foreach(_.refresh())\n       // refresh data cache if table is cached\n       sparkSession.catalog.refreshByPath(outputPath.toString)\n+\n+      if (catalogTable.nonEmpty) {\n+        CommandUtils.updateTableStats(sparkSession, catalogTable.get)"
  }, {
    "author": {
      "login": "wzhfy"
    },
    "body": "We already add a flag to enable/disable auto update, the flag is used inside `CommandUtils.updateTableStats` in order to reduce code redundancy.",
    "commit": "db8a640884b23507f14cecee4fb3661b44874cef",
    "createdAt": "2017-06-28T01:18:05Z",
    "diffHunk": "@@ -161,6 +161,11 @@ case class InsertIntoHadoopFsRelationCommand(\n       fileIndex.foreach(_.refresh())\n       // refresh data cache if table is cached\n       sparkSession.catalog.refreshByPath(outputPath.toString)\n+\n+      if (catalogTable.nonEmpty) {\n+        CommandUtils.updateTableStats(sparkSession, catalogTable.get)"
  }],
  "prId": 18334
}]