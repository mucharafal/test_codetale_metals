[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "need to also pass the stack trace over\n",
    "commit": "7d29c0637222e9a87755a50785c0580c3cf8fcb0",
    "createdAt": "2016-03-10T03:06:44Z",
    "diffHunk": "@@ -31,7 +31,10 @@ import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, ReturnAnswer}\n  */\n class QueryExecution(val sqlContext: SQLContext, val logical: LogicalPlan) {\n \n-  def assertAnalyzed(): Unit = sqlContext.analyzer.checkAnalysis(analyzed)\n+  def assertAnalyzed(): Unit = try sqlContext.analyzer.checkAnalysis(analyzed) catch {\n+    case e: AnalysisException =>\n+      throw new AnalysisException(e.message, e.line, e.startPosition, Some(analyzed))",
    "line": 16
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "the simplest way is to make AnalysisException's plan field mutable\n",
    "commit": "7d29c0637222e9a87755a50785c0580c3cf8fcb0",
    "createdAt": "2016-03-10T03:06:57Z",
    "diffHunk": "@@ -31,7 +31,10 @@ import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, ReturnAnswer}\n  */\n class QueryExecution(val sqlContext: SQLContext, val logical: LogicalPlan) {\n \n-  def assertAnalyzed(): Unit = sqlContext.analyzer.checkAnalysis(analyzed)\n+  def assertAnalyzed(): Unit = try sqlContext.analyzer.checkAnalysis(analyzed) catch {\n+    case e: AnalysisException =>\n+      throw new AnalysisException(e.message, e.line, e.startPosition, Some(analyzed))",
    "line": 16
  }],
  "prId": 11443
}]