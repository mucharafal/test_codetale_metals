[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "`MicroBatchReadSupport` -> `MicroBatchScan`.",
    "commit": "a7d0c55677d519843086f54ef9502e5482ea2765",
    "createdAt": "2019-07-18T21:08:33Z",
    "diffHunk": "@@ -30,16 +30,18 @@ import org.apache.spark.sql.catalyst.InternalRow\n import org.apache.spark.sql.catalyst.util.DateTimeUtils\n import org.apache.spark.sql.execution.streaming.LongOffset\n import org.apache.spark.sql.sources.v2.reader.{InputPartition, PartitionReader, PartitionReaderFactory}\n-import org.apache.spark.sql.sources.v2.reader.streaming.{MicroBatchStream, Offset}\n+import org.apache.spark.sql.sources.v2.reader.streaming.{MicroBatchScan, Offset}\n+import org.apache.spark.sql.types.StructType\n import org.apache.spark.unsafe.types.UTF8String\n \n /**\n- * A MicroBatchReadSupport that reads text lines through a TCP socket, designed only for tutorials\n+ * A [[MicroBatchScan]] that reads text lines through a TCP socket, designed only for tutorials\n  * and debugging. This MicroBatchReadSupport will *not* work in production applications due to"
  }],
  "prId": 25180
}]