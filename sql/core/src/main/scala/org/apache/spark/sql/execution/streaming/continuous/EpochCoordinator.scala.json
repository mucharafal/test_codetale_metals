[{
  "comments": [{
    "author": {
      "login": "jose-torres"
    },
    "body": "There's a bit of duplicated logic here - helper methods would probably be nice.",
    "commit": "b1b9985a5b745625bd7606331fde9b05a9af9442",
    "createdAt": "2018-03-29T16:47:30Z",
    "diffHunk": "@@ -145,18 +149,42 @@ private[continuous] class EpochCoordinator(\n \n     if (thisEpochCommits.size == numWriterPartitions &&\n       nextEpochOffsets.size == numReaderPartitions) {\n-      logDebug(s\"Epoch $epoch has received commits from all partitions. Committing globally.\")\n-      // Sequencing is important here. We must commit to the writer before recording the commit\n-      // in the query, or we will end up dropping the commit if we restart in the middle.\n-      writer.commit(epoch, thisEpochCommits.toArray)\n-      query.commit(epoch)\n-\n-      // Cleanup state from before this epoch, now that we know all partitions are forever past it.\n-      for (k <- partitionCommits.keys.filter { case (e, _) => e < epoch }) {\n-        partitionCommits.remove(k)\n-      }\n-      for (k <- partitionOffsets.keys.filter { case (e, _) => e < epoch }) {\n-        partitionOffsets.remove(k)\n+\n+      // Check that last committed epoch is the previous one for sequencing of committed epochs.\n+      if (lastCommittedEpoch == epoch - 1) {\n+        logDebug(s\"Epoch $epoch has received commits from all partitions. Committing globally.\")\n+        // Sequencing is important here. We must commit to the writer before recording the commit\n+        // in the query, or we will end up dropping the commit if we restart in the middle.\n+        writer.commit(epoch, thisEpochCommits.toArray)\n+        query.commit(epoch)\n+        lastCommittedEpoch = epoch\n+\n+        // Commit subsequent epochs that are waiting to be committed.\n+        var nextEpoch = lastCommittedEpoch + 1\n+        while (epochsWaitingToBeCommitted.contains(nextEpoch)) {\n+          val nextEpochCommits =\n+            partitionCommits.collect { case ((e, _), msg) if e == nextEpoch => msg }\n+          logDebug(s\"Committing epoch $nextEpoch.\")\n+          writer.commit(nextEpoch, nextEpochCommits.toArray)\n+          query.commit(nextEpoch)"
  }],
  "prId": 20936
}, {
  "comments": [{
    "author": {
      "login": "jose-torres"
    },
    "body": "Maybe swap the order of the if else. I'd forgotten what the condition was for after scrolling down here.",
    "commit": "b1b9985a5b745625bd7606331fde9b05a9af9442",
    "createdAt": "2018-03-29T16:48:49Z",
    "diffHunk": "@@ -145,18 +149,42 @@ private[continuous] class EpochCoordinator(\n \n     if (thisEpochCommits.size == numWriterPartitions &&\n       nextEpochOffsets.size == numReaderPartitions) {\n-      logDebug(s\"Epoch $epoch has received commits from all partitions. Committing globally.\")\n-      // Sequencing is important here. We must commit to the writer before recording the commit\n-      // in the query, or we will end up dropping the commit if we restart in the middle.\n-      writer.commit(epoch, thisEpochCommits.toArray)\n-      query.commit(epoch)\n-\n-      // Cleanup state from before this epoch, now that we know all partitions are forever past it.\n-      for (k <- partitionCommits.keys.filter { case (e, _) => e < epoch }) {\n-        partitionCommits.remove(k)\n-      }\n-      for (k <- partitionOffsets.keys.filter { case (e, _) => e < epoch }) {\n-        partitionOffsets.remove(k)\n+\n+      // Check that last committed epoch is the previous one for sequencing of committed epochs.\n+      if (lastCommittedEpoch == epoch - 1) {\n+        logDebug(s\"Epoch $epoch has received commits from all partitions. Committing globally.\")\n+        // Sequencing is important here. We must commit to the writer before recording the commit\n+        // in the query, or we will end up dropping the commit if we restart in the middle.\n+        writer.commit(epoch, thisEpochCommits.toArray)\n+        query.commit(epoch)\n+        lastCommittedEpoch = epoch\n+\n+        // Commit subsequent epochs that are waiting to be committed.\n+        var nextEpoch = lastCommittedEpoch + 1\n+        while (epochsWaitingToBeCommitted.contains(nextEpoch)) {\n+          val nextEpochCommits =\n+            partitionCommits.collect { case ((e, _), msg) if e == nextEpoch => msg }\n+          logDebug(s\"Committing epoch $nextEpoch.\")\n+          writer.commit(nextEpoch, nextEpochCommits.toArray)\n+          query.commit(nextEpoch)\n+\n+          epochsWaitingToBeCommitted.remove(nextEpoch)\n+          lastCommittedEpoch = nextEpoch\n+          nextEpoch += 1\n+        }\n+\n+        // Cleanup state from before last committed epoch,\n+        // now that we know all partitions are forever past it.\n+        for (k <- partitionCommits.keys.filter { case (e, _) => e < lastCommittedEpoch }) {\n+          partitionCommits.remove(k)\n+        }\n+        for (k <- partitionOffsets.keys.filter { case (e, _) => e < lastCommittedEpoch }) {\n+          partitionOffsets.remove(k)\n+        }\n+      } else {\n+        logDebug(s\"Epoch $epoch has received commits from all partitions\" +\n+          s\"and is waiting for epoch ${epoch - 1} to be committed first.\")\n+        epochsWaitingToBeCommitted.add(epoch)"
  }],
  "prId": 20936
}, {
  "comments": [{
    "author": {
      "login": "jose-torres"
    },
    "body": "This is orthogonal to the current PR, but I realized that both this and the commits/offsets maps are unbounded queues. We probably should introduce some SQLConf for the maximum epoch backlog, and report an error when too many stack up. I'll file a JIRA ticket for this.",
    "commit": "b1b9985a5b745625bd7606331fde9b05a9af9442",
    "createdAt": "2018-04-18T21:14:05Z",
    "diffHunk": "@@ -137,30 +137,65 @@ private[continuous] class EpochCoordinator(\n   private val partitionOffsets =\n     mutable.Map[(Long, Int), PartitionOffset]()\n \n+  private var lastCommittedEpoch = startEpoch - 1\n+  // Remembers epochs that have to wait for previous epochs to be committed first.\n+  private val epochsWaitingToBeCommitted = mutable.HashSet.empty[Long]",
    "line": 6
  }],
  "prId": 20936
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Add docs explaining what this does? As is, its hard to distinguish just from the name the difference between `findCommitsForEpoch` and `commitEpoch`. I think the term \"commit\" is overloaded here - `commit` in `findCommitsForEpoch` refers to per-partition commits, whereas `commit` in `commitEpoch` refers to committing the epoch to the offset log. May be its better to differentiate more clearly. `commitEpoch` and `findPartitionCommitsForEpoch`. And add docs to both methods also helps.\r\n",
    "commit": "b1b9985a5b745625bd7606331fde9b05a9af9442",
    "createdAt": "2018-04-23T18:23:36Z",
    "diffHunk": "@@ -137,30 +137,65 @@ private[continuous] class EpochCoordinator(\n   private val partitionOffsets =\n     mutable.Map[(Long, Int), PartitionOffset]()\n \n+  private var lastCommittedEpoch = startEpoch - 1\n+  // Remembers epochs that have to wait for previous epochs to be committed first.\n+  private val epochsWaitingToBeCommitted = mutable.HashSet.empty[Long]\n+\n   private def resolveCommitsAtEpoch(epoch: Long) = {\n-    val thisEpochCommits =\n-      partitionCommits.collect { case ((e, _), msg) if e == epoch => msg }\n+    val thisEpochCommits = findCommitsForEpoch(epoch)\n     val nextEpochOffsets =\n       partitionOffsets.collect { case ((e, _), o) if e == epoch => o }\n \n     if (thisEpochCommits.size == numWriterPartitions &&\n       nextEpochOffsets.size == numReaderPartitions) {\n-      logDebug(s\"Epoch $epoch has received commits from all partitions. Committing globally.\")\n-      // Sequencing is important here. We must commit to the writer before recording the commit\n-      // in the query, or we will end up dropping the commit if we restart in the middle.\n-      writer.commit(epoch, thisEpochCommits.toArray)\n-      query.commit(epoch)\n-\n-      // Cleanup state from before this epoch, now that we know all partitions are forever past it.\n-      for (k <- partitionCommits.keys.filter { case (e, _) => e < epoch }) {\n-        partitionCommits.remove(k)\n-      }\n-      for (k <- partitionOffsets.keys.filter { case (e, _) => e < epoch }) {\n-        partitionOffsets.remove(k)\n+\n+      // Check that last committed epoch is the previous one for sequencing of committed epochs.\n+      // If not, add the epoch being currently processed to epochs waiting to be committed,\n+      // otherwise commit it.\n+      if (lastCommittedEpoch != epoch - 1) {\n+        logDebug(s\"Epoch $epoch has received commits from all partitions \" +\n+          s\"and is waiting for epoch ${epoch - 1} to be committed first.\")\n+        epochsWaitingToBeCommitted.add(epoch)\n+      } else {\n+        commitEpoch(epoch, thisEpochCommits)\n+        lastCommittedEpoch = epoch\n+\n+        // Commit subsequent epochs that are waiting to be committed.\n+        var nextEpoch = lastCommittedEpoch + 1\n+        while (epochsWaitingToBeCommitted.contains(nextEpoch)) {\n+          val nextEpochCommits = findCommitsForEpoch(nextEpoch)\n+          commitEpoch(nextEpoch, nextEpochCommits)\n+\n+          epochsWaitingToBeCommitted.remove(nextEpoch)\n+          lastCommittedEpoch = nextEpoch\n+          nextEpoch += 1\n+        }\n+\n+        // Cleanup state from before last committed epoch,\n+        // now that we know all partitions are forever past it.\n+        for (k <- partitionCommits.keys.filter { case (e, _) => e < lastCommittedEpoch }) {\n+          partitionCommits.remove(k)\n+        }\n+        for (k <- partitionOffsets.keys.filter { case (e, _) => e < lastCommittedEpoch }) {\n+          partitionOffsets.remove(k)\n+        }\n       }\n     }\n   }\n \n+  private def findCommitsForEpoch(epoch: Long): Iterable[WriterCommitMessage] = {"
  }, {
    "author": {
      "login": "efim-poberezkin"
    },
    "body": "@tdas done",
    "commit": "b1b9985a5b745625bd7606331fde9b05a9af9442",
    "createdAt": "2018-04-26T11:55:14Z",
    "diffHunk": "@@ -137,30 +137,65 @@ private[continuous] class EpochCoordinator(\n   private val partitionOffsets =\n     mutable.Map[(Long, Int), PartitionOffset]()\n \n+  private var lastCommittedEpoch = startEpoch - 1\n+  // Remembers epochs that have to wait for previous epochs to be committed first.\n+  private val epochsWaitingToBeCommitted = mutable.HashSet.empty[Long]\n+\n   private def resolveCommitsAtEpoch(epoch: Long) = {\n-    val thisEpochCommits =\n-      partitionCommits.collect { case ((e, _), msg) if e == epoch => msg }\n+    val thisEpochCommits = findCommitsForEpoch(epoch)\n     val nextEpochOffsets =\n       partitionOffsets.collect { case ((e, _), o) if e == epoch => o }\n \n     if (thisEpochCommits.size == numWriterPartitions &&\n       nextEpochOffsets.size == numReaderPartitions) {\n-      logDebug(s\"Epoch $epoch has received commits from all partitions. Committing globally.\")\n-      // Sequencing is important here. We must commit to the writer before recording the commit\n-      // in the query, or we will end up dropping the commit if we restart in the middle.\n-      writer.commit(epoch, thisEpochCommits.toArray)\n-      query.commit(epoch)\n-\n-      // Cleanup state from before this epoch, now that we know all partitions are forever past it.\n-      for (k <- partitionCommits.keys.filter { case (e, _) => e < epoch }) {\n-        partitionCommits.remove(k)\n-      }\n-      for (k <- partitionOffsets.keys.filter { case (e, _) => e < epoch }) {\n-        partitionOffsets.remove(k)\n+\n+      // Check that last committed epoch is the previous one for sequencing of committed epochs.\n+      // If not, add the epoch being currently processed to epochs waiting to be committed,\n+      // otherwise commit it.\n+      if (lastCommittedEpoch != epoch - 1) {\n+        logDebug(s\"Epoch $epoch has received commits from all partitions \" +\n+          s\"and is waiting for epoch ${epoch - 1} to be committed first.\")\n+        epochsWaitingToBeCommitted.add(epoch)\n+      } else {\n+        commitEpoch(epoch, thisEpochCommits)\n+        lastCommittedEpoch = epoch\n+\n+        // Commit subsequent epochs that are waiting to be committed.\n+        var nextEpoch = lastCommittedEpoch + 1\n+        while (epochsWaitingToBeCommitted.contains(nextEpoch)) {\n+          val nextEpochCommits = findCommitsForEpoch(nextEpoch)\n+          commitEpoch(nextEpoch, nextEpochCommits)\n+\n+          epochsWaitingToBeCommitted.remove(nextEpoch)\n+          lastCommittedEpoch = nextEpoch\n+          nextEpoch += 1\n+        }\n+\n+        // Cleanup state from before last committed epoch,\n+        // now that we know all partitions are forever past it.\n+        for (k <- partitionCommits.keys.filter { case (e, _) => e < lastCommittedEpoch }) {\n+          partitionCommits.remove(k)\n+        }\n+        for (k <- partitionOffsets.keys.filter { case (e, _) => e < lastCommittedEpoch }) {\n+          partitionOffsets.remove(k)\n+        }\n       }\n     }\n   }\n \n+  private def findCommitsForEpoch(epoch: Long): Iterable[WriterCommitMessage] = {"
  }],
  "prId": 20936
}]