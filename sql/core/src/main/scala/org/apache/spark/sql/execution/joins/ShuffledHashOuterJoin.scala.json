[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "This is now inherited from `HashOuterJoin` (now `OuterJoin`)\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-05T09:15:19Z",
    "diffHunk": "@@ -39,51 +40,47 @@ case class ShuffledHashOuterJoin(\n     joinType: JoinType,\r\n     condition: Option[Expression],\r\n     left: SparkPlan,\r\n-    right: SparkPlan) extends BinaryNode with HashOuterJoin {\r\n+    right: SparkPlan) extends BinaryNode with OuterJoin {\r\n \r\n   override def requiredChildDistribution: Seq[Distribution] =\r\n     ClusteredDistribution(leftKeys) :: ClusteredDistribution(rightKeys) :: Nil\r\n \r\n-  override def outputPartitioning: Partitioning = joinType match {\r"
  }],
  "prId": 7904
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "since you are changing this already, can we rename streamedKeyGenerator to maybe createKeyProjection()?\n\nRight now it looks like a simple variable assignment.\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-07T06:59:28Z",
    "diffHunk": "@@ -1,97 +1,94 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *    http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-\r\n-package org.apache.spark.sql.execution.joins\r\n-\r\n-import scala.collection.JavaConversions._\r\n-\r\n-import org.apache.spark.annotation.DeveloperApi\r\n-import org.apache.spark.rdd.RDD\r\n-import org.apache.spark.sql.catalyst.InternalRow\r\n-import org.apache.spark.sql.catalyst.expressions._\r\n-import org.apache.spark.sql.catalyst.plans.physical._\r\n-import org.apache.spark.sql.catalyst.plans.{FullOuter, JoinType, LeftOuter, RightOuter}\r\n-import org.apache.spark.sql.execution.{BinaryNode, SparkPlan}\r\n-\r\n-/**\r\n- * :: DeveloperApi ::\r\n- * Performs a hash based outer join for two child relations by shuffling the data using\r\n- * the join keys. This operator requires loading the associated partition in both side into memory.\r\n- */\r\n-@DeveloperApi\r\n-case class ShuffledHashOuterJoin(\r\n-    leftKeys: Seq[Expression],\r\n-    rightKeys: Seq[Expression],\r\n-    joinType: JoinType,\r\n-    condition: Option[Expression],\r\n-    left: SparkPlan,\r\n-    right: SparkPlan) extends BinaryNode with HashOuterJoin {\r\n-\r\n-  override def requiredChildDistribution: Seq[Distribution] =\r\n-    ClusteredDistribution(leftKeys) :: ClusteredDistribution(rightKeys) :: Nil\r\n-\r\n-  override def outputPartitioning: Partitioning = joinType match {\r\n-    case LeftOuter => left.outputPartitioning\r\n-    case RightOuter => right.outputPartitioning\r\n-    case FullOuter => UnknownPartitioning(left.outputPartitioning.numPartitions)\r\n-    case x =>\r\n-      throw new IllegalArgumentException(s\"HashOuterJoin should not take $x as the JoinType\")\r\n-  }\r\n-\r\n-  protected override def doExecute(): RDD[InternalRow] = {\r\n-    val joinedRow = new JoinedRow()\r\n-    left.execute().zipPartitions(right.execute()) { (leftIter, rightIter) =>\r\n-      // TODO this probably can be replaced by external sort (sort merged join?)\r\n-      joinType match {\r\n-        case LeftOuter =>\r\n-          val hashed = HashedRelation(rightIter, buildKeyGenerator)\r\n-          val keyGenerator = streamedKeyGenerator\r\n-          val resultProj = resultProjection\r\n-          leftIter.flatMap( currentRow => {\r\n-            val rowKey = keyGenerator(currentRow)\r\n-            joinedRow.withLeft(currentRow)\r\n-            leftOuterIterator(rowKey, joinedRow, hashed.get(rowKey), resultProj)\r\n-          })\r\n-\r\n-        case RightOuter =>\r\n-          val hashed = HashedRelation(leftIter, buildKeyGenerator)\r\n-          val keyGenerator = streamedKeyGenerator\r\n-          val resultProj = resultProjection\r\n-          rightIter.flatMap ( currentRow => {\r\n-            val rowKey = keyGenerator(currentRow)\r\n-            joinedRow.withRight(currentRow)\r\n-            rightOuterIterator(rowKey, hashed.get(rowKey), joinedRow, resultProj)\r\n-          })\r\n-\r\n-        case FullOuter =>\r\n-          // TODO(davies): use UnsafeRow\r\n-          val leftHashTable = buildHashTable(leftIter, newProjection(leftKeys, left.output))\r\n-          val rightHashTable = buildHashTable(rightIter, newProjection(rightKeys, right.output))\r\n-          (leftHashTable.keySet ++ rightHashTable.keySet).iterator.flatMap { key =>\r\n-            fullOuterIterator(key,\r\n-              leftHashTable.getOrElse(key, EMPTY_LIST),\r\n-              rightHashTable.getOrElse(key, EMPTY_LIST),\r\n-              joinedRow)\r\n-          }\r\n-\r\n-        case x =>\r\n-          throw new IllegalArgumentException(\r\n-            s\"ShuffledHashOuterJoin should not take $x as the JoinType\")\r\n-      }\r\n-    }\r\n-  }\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.physical._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, JoinType, LeftOuter, RightOuter}\n+import org.apache.spark.sql.execution.{BinaryNode, SparkPlan}\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Performs a hash based outer join for two child relations by shuffling the data using\n+ * the join keys. This operator requires loading the associated partition in both side into memory.\n+ */\n+@DeveloperApi\n+case class ShuffledHashOuterJoin(\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    joinType: JoinType,\n+    condition: Option[Expression],\n+    left: SparkPlan,\n+    right: SparkPlan) extends BinaryNode with OuterJoin {\n+\n+  override def requiredChildDistribution: Seq[Distribution] =\n+    ClusteredDistribution(leftKeys) :: ClusteredDistribution(rightKeys) :: Nil\n+\n+  protected override def doExecute(): RDD[InternalRow] = {\n+    val joinedRow = new JoinedRow()\n+    left.execute().zipPartitions(right.execute()) { (leftIter, rightIter) =>\n+      joinType match {\n+        case LeftOuter =>\n+          val hashed = HashedRelation(rightIter, buildKeyGenerator)\n+          val keyGenerator = streamedKeyGenerator"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Ah, good catch.  I already did some similar cleanup for `resultProjection` by renaming it to `createResultProjection()`.\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-07T07:01:06Z",
    "diffHunk": "@@ -1,97 +1,94 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *    http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-\r\n-package org.apache.spark.sql.execution.joins\r\n-\r\n-import scala.collection.JavaConversions._\r\n-\r\n-import org.apache.spark.annotation.DeveloperApi\r\n-import org.apache.spark.rdd.RDD\r\n-import org.apache.spark.sql.catalyst.InternalRow\r\n-import org.apache.spark.sql.catalyst.expressions._\r\n-import org.apache.spark.sql.catalyst.plans.physical._\r\n-import org.apache.spark.sql.catalyst.plans.{FullOuter, JoinType, LeftOuter, RightOuter}\r\n-import org.apache.spark.sql.execution.{BinaryNode, SparkPlan}\r\n-\r\n-/**\r\n- * :: DeveloperApi ::\r\n- * Performs a hash based outer join for two child relations by shuffling the data using\r\n- * the join keys. This operator requires loading the associated partition in both side into memory.\r\n- */\r\n-@DeveloperApi\r\n-case class ShuffledHashOuterJoin(\r\n-    leftKeys: Seq[Expression],\r\n-    rightKeys: Seq[Expression],\r\n-    joinType: JoinType,\r\n-    condition: Option[Expression],\r\n-    left: SparkPlan,\r\n-    right: SparkPlan) extends BinaryNode with HashOuterJoin {\r\n-\r\n-  override def requiredChildDistribution: Seq[Distribution] =\r\n-    ClusteredDistribution(leftKeys) :: ClusteredDistribution(rightKeys) :: Nil\r\n-\r\n-  override def outputPartitioning: Partitioning = joinType match {\r\n-    case LeftOuter => left.outputPartitioning\r\n-    case RightOuter => right.outputPartitioning\r\n-    case FullOuter => UnknownPartitioning(left.outputPartitioning.numPartitions)\r\n-    case x =>\r\n-      throw new IllegalArgumentException(s\"HashOuterJoin should not take $x as the JoinType\")\r\n-  }\r\n-\r\n-  protected override def doExecute(): RDD[InternalRow] = {\r\n-    val joinedRow = new JoinedRow()\r\n-    left.execute().zipPartitions(right.execute()) { (leftIter, rightIter) =>\r\n-      // TODO this probably can be replaced by external sort (sort merged join?)\r\n-      joinType match {\r\n-        case LeftOuter =>\r\n-          val hashed = HashedRelation(rightIter, buildKeyGenerator)\r\n-          val keyGenerator = streamedKeyGenerator\r\n-          val resultProj = resultProjection\r\n-          leftIter.flatMap( currentRow => {\r\n-            val rowKey = keyGenerator(currentRow)\r\n-            joinedRow.withLeft(currentRow)\r\n-            leftOuterIterator(rowKey, joinedRow, hashed.get(rowKey), resultProj)\r\n-          })\r\n-\r\n-        case RightOuter =>\r\n-          val hashed = HashedRelation(leftIter, buildKeyGenerator)\r\n-          val keyGenerator = streamedKeyGenerator\r\n-          val resultProj = resultProjection\r\n-          rightIter.flatMap ( currentRow => {\r\n-            val rowKey = keyGenerator(currentRow)\r\n-            joinedRow.withRight(currentRow)\r\n-            rightOuterIterator(rowKey, hashed.get(rowKey), joinedRow, resultProj)\r\n-          })\r\n-\r\n-        case FullOuter =>\r\n-          // TODO(davies): use UnsafeRow\r\n-          val leftHashTable = buildHashTable(leftIter, newProjection(leftKeys, left.output))\r\n-          val rightHashTable = buildHashTable(rightIter, newProjection(rightKeys, right.output))\r\n-          (leftHashTable.keySet ++ rightHashTable.keySet).iterator.flatMap { key =>\r\n-            fullOuterIterator(key,\r\n-              leftHashTable.getOrElse(key, EMPTY_LIST),\r\n-              rightHashTable.getOrElse(key, EMPTY_LIST),\r\n-              joinedRow)\r\n-          }\r\n-\r\n-        case x =>\r\n-          throw new IllegalArgumentException(\r\n-            s\"ShuffledHashOuterJoin should not take $x as the JoinType\")\r\n-      }\r\n-    }\r\n-  }\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.physical._\n+import org.apache.spark.sql.catalyst.plans.{FullOuter, JoinType, LeftOuter, RightOuter}\n+import org.apache.spark.sql.execution.{BinaryNode, SparkPlan}\n+import org.apache.spark.util.collection.CompactBuffer\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Performs a hash based outer join for two child relations by shuffling the data using\n+ * the join keys. This operator requires loading the associated partition in both side into memory.\n+ */\n+@DeveloperApi\n+case class ShuffledHashOuterJoin(\n+    leftKeys: Seq[Expression],\n+    rightKeys: Seq[Expression],\n+    joinType: JoinType,\n+    condition: Option[Expression],\n+    left: SparkPlan,\n+    right: SparkPlan) extends BinaryNode with OuterJoin {\n+\n+  override def requiredChildDistribution: Seq[Distribution] =\n+    ClusteredDistribution(leftKeys) :: ClusteredDistribution(rightKeys) :: Nil\n+\n+  protected override def doExecute(): RDD[InternalRow] = {\n+    val joinedRow = new JoinedRow()\n+    left.execute().zipPartitions(right.execute()) { (leftIter, rightIter) =>\n+      joinType match {\n+        case LeftOuter =>\n+          val hashed = HashedRelation(rightIter, buildKeyGenerator)\n+          val keyGenerator = streamedKeyGenerator"
  }],
  "prId": 7904
}]