[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Are we ever going to use a different generator? Why not call it `CsvGenerator`?\n",
    "commit": "7abdfc111166f2bf275fc4318c0ffe8836dcbb70",
    "createdAt": "2016-04-27T13:41:49Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.csv\n+\n+import com.univocity.parsers.csv.{CsvWriter, CsvWriterSettings}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * Converts a sequence of string to CSV string\n+ */\n+private[csv] object UnivocityGenerator extends Logging {",
    "line": 29
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "Come to think of it, why not integrate this with the `CsvOutputWriter`?\n",
    "commit": "7abdfc111166f2bf275fc4318c0ffe8836dcbb70",
    "createdAt": "2016-04-27T14:21:54Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.csv\n+\n+import com.univocity.parsers.csv.{CsvWriter, CsvWriterSettings}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * Converts a sequence of string to CSV string\n+ */\n+private[csv] object UnivocityGenerator extends Logging {",
    "line": 29
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Thanks! The name was also taken after from JSON data source, `JacksonGenerator`. Maybe I can rename/integrate them together if this one is merged.\n",
    "commit": "7abdfc111166f2bf275fc4318c0ffe8836dcbb70",
    "createdAt": "2016-04-28T00:23:05Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.csv\n+\n+import com.univocity.parsers.csv.{CsvWriter, CsvWriterSettings}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * Converts a sequence of string to CSV string\n+ */\n+private[csv] object UnivocityGenerator extends Logging {",
    "line": 29
  }],
  "prId": 12268
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Please use a more descriptive name? `writeToCsv`?\n",
    "commit": "7abdfc111166f2bf275fc4318c0ffe8836dcbb70",
    "createdAt": "2016-04-27T13:42:34Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.csv\n+\n+import com.univocity.parsers.csv.{CsvWriter, CsvWriterSettings}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * Converts a sequence of string to CSV string\n+ */\n+private[csv] object UnivocityGenerator extends Logging {\n+  /**\n+   * Transforms a single InternalRow to CSV using Univocity\n+   *\n+   * @param rowSchema the schema object used for conversion\n+   * @param writer a CsvWriter object\n+   * @param headers headers to write\n+   * @param writeHeader true if it needs to write header\n+   * @param options CSVOptions object containing options\n+   * @param row The row to convert\n+   */\n+  def apply(",
    "line": 40
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "The name was also taken after `JacksonGenerator` in JSON data source.\n",
    "commit": "7abdfc111166f2bf275fc4318c0ffe8836dcbb70",
    "createdAt": "2016-04-28T00:23:41Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.csv\n+\n+import com.univocity.parsers.csv.{CsvWriter, CsvWriterSettings}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * Converts a sequence of string to CSV string\n+ */\n+private[csv] object UnivocityGenerator extends Logging {\n+  /**\n+   * Transforms a single InternalRow to CSV using Univocity\n+   *\n+   * @param rowSchema the schema object used for conversion\n+   * @param writer a CsvWriter object\n+   * @param headers headers to write\n+   * @param writeHeader true if it needs to write header\n+   * @param options CSVOptions object containing options\n+   * @param row The row to convert\n+   */\n+  def apply(",
    "line": 40
  }],
  "prId": 12268
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "You are calling this alot right? So it might be better not to rely on functional constructs here. Also take a look at the `InternalRow.toSeq` method there might be some room improvement if you just pass in the `DataType`s directly.\n",
    "commit": "7abdfc111166f2bf275fc4318c0ffe8836dcbb70",
    "createdAt": "2016-04-27T14:19:54Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.csv\n+\n+import com.univocity.parsers.csv.{CsvWriter, CsvWriterSettings}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * Converts a sequence of string to CSV string\n+ */\n+private[csv] object UnivocityGenerator extends Logging {\n+  /**\n+   * Transforms a single InternalRow to CSV using Univocity\n+   *\n+   * @param rowSchema the schema object used for conversion\n+   * @param writer a CsvWriter object\n+   * @param headers headers to write\n+   * @param writeHeader true if it needs to write header\n+   * @param options CSVOptions object containing options\n+   * @param row The row to convert\n+   */\n+  def apply(\n+      rowSchema: StructType,\n+      writer: CsvWriter,\n+      headers: Array[String],\n+      writeHeader: Boolean,\n+      options: CSVOptions)(row: InternalRow): Unit = {\n+    val tokens = {\n+      row.toSeq(rowSchema).map { field =>",
    "line": 47
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Thank you! Could I maybe do this in a separate PR with the purpose of this? This was just copied from original codes.\n",
    "commit": "7abdfc111166f2bf275fc4318c0ffe8836dcbb70",
    "createdAt": "2016-04-28T00:30:30Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.csv\n+\n+import com.univocity.parsers.csv.{CsvWriter, CsvWriterSettings}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * Converts a sequence of string to CSV string\n+ */\n+private[csv] object UnivocityGenerator extends Logging {\n+  /**\n+   * Transforms a single InternalRow to CSV using Univocity\n+   *\n+   * @param rowSchema the schema object used for conversion\n+   * @param writer a CsvWriter object\n+   * @param headers headers to write\n+   * @param writeHeader true if it needs to write header\n+   * @param options CSVOptions object containing options\n+   * @param row The row to convert\n+   */\n+  def apply(\n+      rowSchema: StructType,\n+      writer: CsvWriter,\n+      headers: Array[String],\n+      writeHeader: Boolean,\n+      options: CSVOptions)(row: InternalRow): Unit = {\n+    val tokens = {\n+      row.toSeq(rowSchema).map { field =>",
    "line": 47
  }],
  "prId": 12268
}]