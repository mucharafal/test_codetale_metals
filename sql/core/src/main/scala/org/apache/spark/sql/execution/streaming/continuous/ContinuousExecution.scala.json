[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "with the new abstraction, we should only stop sources when the stream query ends, instead of each reconfiguration.",
    "commit": "9d2ee51c68fc1b6fd780138e4146cb9c5c7c46bc",
    "createdAt": "2019-01-23T02:57:54Z",
    "diffHunk": "@@ -92,6 +104,8 @@ class ContinuousExecution(\n     do {\n       runContinuous(sparkSessionForStream)\n     } while (state.updateAndGet(stateUpdate) == ACTIVE)\n+\n+    stopSources()",
    "line": 81
  }, {
    "author": {
      "login": "jose-torres"
    },
    "body": "As above, this looks like it's correctly implemented to me but we should keep an eye out for flakiness.",
    "commit": "9d2ee51c68fc1b6fd780138e4146cb9c5c7c46bc",
    "createdAt": "2019-01-28T17:41:17Z",
    "diffHunk": "@@ -92,6 +104,8 @@ class ContinuousExecution(\n     do {\n       runContinuous(sparkSessionForStream)\n     } while (state.updateAndGet(stateUpdate) == ACTIVE)\n+\n+    stopSources()",
    "line": 81
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "thanks for reminding! Yea I'll keep an eye on it.\r\n",
    "commit": "9d2ee51c68fc1b6fd780138e4146cb9c5c7c46bc",
    "createdAt": "2019-01-29T04:09:09Z",
    "diffHunk": "@@ -92,6 +104,8 @@ class ContinuousExecution(\n     do {\n       runContinuous(sparkSessionForStream)\n     } while (state.updateAndGet(stateUpdate) == ACTIVE)\n+\n+    stopSources()",
    "line": 81
  }],
  "prId": 23619
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "ditto, with the new abstraction, we should create the `ContinuousStream` at the beginning of the `ContinuousExecution`, instead of each reconfiguration.",
    "commit": "9d2ee51c68fc1b6fd780138e4146cb9c5c7c46bc",
    "createdAt": "2019-01-23T02:58:59Z",
    "diffHunk": "@@ -144,63 +158,33 @@ class ContinuousExecution(\n    * @param sparkSessionForQuery Isolated [[SparkSession]] to run the continuous query with.\n    */\n   private def runContinuous(sparkSessionForQuery: SparkSession): Unit = {\n-    // A list of attributes that will need to be updated.\n-    val replacements = new ArrayBuffer[(Attribute, Attribute)]\n-    // Translate from continuous relation to the underlying data source.\n-    var nextSourceId = 0\n-    continuousSources = logicalPlan.collect {\n-      case ContinuousExecutionRelation(dataSource, extraReaderOptions, output) =>\n-        val metadataPath = s\"$resolvedCheckpointRoot/sources/$nextSourceId\"\n-        nextSourceId += 1\n-\n-        dataSource.createContinuousReadSupport(",
    "line": 107
  }],
  "prId": 23619
}]