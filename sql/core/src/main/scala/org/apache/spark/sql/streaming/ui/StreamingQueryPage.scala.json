[{
  "comments": [{
    "author": {
      "login": "sarutak"
    },
    "body": "This header is wrapped when displayed on browsers.\r\nCan we expand the width of the header cell?",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-11T11:36:22Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {\n+        case Some(_) => \"FAILED\"\n+        case None => \"FINISHED\"\n+      }\n+    }\n+\n+    val duration = if (isActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val end = query.lastProgress.timestamp\n+        val start = query.recentProgress.head.timestamp\n+        SparkUIUtils.formatDurationVerbose(\n+          df.parse(end).getTime - df.parse(start).getTime)\n+      }, \"-\")\n+    }\n+\n+    <tr>\n+      <td> {name} </td>\n+      <td> {status} </td>\n+      <td> {query.id} </td>\n+      <td> <a href={statisticsLink}> {query.runId} </a> </td>\n+      <td> {SparkUIUtils.formatDate(timeSinceStart)} </td>\n+      <td> {duration} </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.inputRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.processedRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query,\n+        { query.getQuerySummary.getMetric(QuerySummary.TOTAL_INPUT_RECORDS, 0L) }, \"NaN\")} </td>\n+      <td> {withNoProgress(query, { query.lastProgress.batchId }, \"NaN\")} </td>\n+      {details(withNoProgress(query, {\n+      s\"== JSON representation of this progress ==\\n${query.lastProgress.prettyJson}\" }, \"-\"))}"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "The \"Last Progress\" column might be a little mess by printing the JSON string directly, how about using another table in this page or in the statistics page to show this info?",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-11T21:18:38Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {\n+        case Some(_) => \"FAILED\"\n+        case None => \"FINISHED\"\n+      }\n+    }\n+\n+    val duration = if (isActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val end = query.lastProgress.timestamp\n+        val start = query.recentProgress.head.timestamp\n+        SparkUIUtils.formatDurationVerbose(\n+          df.parse(end).getTime - df.parse(start).getTime)\n+      }, \"-\")\n+    }\n+\n+    <tr>\n+      <td> {name} </td>\n+      <td> {status} </td>\n+      <td> {query.id} </td>\n+      <td> <a href={statisticsLink}> {query.runId} </a> </td>\n+      <td> {SparkUIUtils.formatDate(timeSinceStart)} </td>\n+      <td> {duration} </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.inputRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.processedRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query,\n+        { query.getQuerySummary.getMetric(QuerySummary.TOTAL_INPUT_RECORDS, 0L) }, \"NaN\")} </td>\n+      <td> {withNoProgress(query, { query.lastProgress.batchId }, \"NaN\")} </td>\n+      {details(withNoProgress(query, {\n+      s\"== JSON representation of this progress ==\\n${query.lastProgress.prettyJson}\" }, \"-\"))}"
  }, {
    "author": {
      "login": "sarutak"
    },
    "body": "It might be better.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-12T01:43:03Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {\n+        case Some(_) => \"FAILED\"\n+        case None => \"FINISHED\"\n+      }\n+    }\n+\n+    val duration = if (isActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val end = query.lastProgress.timestamp\n+        val start = query.recentProgress.head.timestamp\n+        SparkUIUtils.formatDurationVerbose(\n+          df.parse(end).getTime - df.parse(start).getTime)\n+      }, \"-\")\n+    }\n+\n+    <tr>\n+      <td> {name} </td>\n+      <td> {status} </td>\n+      <td> {query.id} </td>\n+      <td> <a href={statisticsLink}> {query.runId} </a> </td>\n+      <td> {SparkUIUtils.formatDate(timeSinceStart)} </td>\n+      <td> {duration} </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.inputRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.processedRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query,\n+        { query.getQuerySummary.getMetric(QuerySummary.TOTAL_INPUT_RECORDS, 0L) }, \"NaN\")} </td>\n+      <td> {withNoProgress(query, { query.lastProgress.batchId }, \"NaN\")} </td>\n+      {details(withNoProgress(query, {\n+      s\"== JSON representation of this progress ==\\n${query.lastProgress.prettyJson}\" }, \"-\"))}"
  }, {
    "author": {
      "login": "uncleGen"
    },
    "body": "I will move the `Last Progress` info to statistics page.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-15T06:06:57Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {\n+        case Some(_) => \"FAILED\"\n+        case None => \"FINISHED\"\n+      }\n+    }\n+\n+    val duration = if (isActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val end = query.lastProgress.timestamp\n+        val start = query.recentProgress.head.timestamp\n+        SparkUIUtils.formatDurationVerbose(\n+          df.parse(end).getTime - df.parse(start).getTime)\n+      }, \"-\")\n+    }\n+\n+    <tr>\n+      <td> {name} </td>\n+      <td> {status} </td>\n+      <td> {query.id} </td>\n+      <td> <a href={statisticsLink}> {query.runId} </a> </td>\n+      <td> {SparkUIUtils.formatDate(timeSinceStart)} </td>\n+      <td> {duration} </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.inputRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.processedRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query,\n+        { query.getQuerySummary.getMetric(QuerySummary.TOTAL_INPUT_RECORDS, 0L) }, \"NaN\")} </td>\n+      <td> {withNoProgress(query, { query.lastProgress.batchId }, \"NaN\")} </td>\n+      {details(withNoProgress(query, {\n+      s\"== JSON representation of this progress ==\\n${query.lastProgress.prettyJson}\" }, \"-\"))}"
  }, {
    "author": {
      "login": "uncleGen"
    },
    "body": "After a short thinking, I decide to remove the `Last Progress` column, and there is no need to  show these information in `statistics page`, as it has main information about each batch, like `durationMs`, `inputRowsPerSecond` and so on. Besides, current `statistics page` lacks the information about each source. I want to complete it in future. What's your opinion? @xuanyuanking @sarutak",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-20T03:46:24Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {\n+        case Some(_) => \"FAILED\"\n+        case None => \"FINISHED\"\n+      }\n+    }\n+\n+    val duration = if (isActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val end = query.lastProgress.timestamp\n+        val start = query.recentProgress.head.timestamp\n+        SparkUIUtils.formatDurationVerbose(\n+          df.parse(end).getTime - df.parse(start).getTime)\n+      }, \"-\")\n+    }\n+\n+    <tr>\n+      <td> {name} </td>\n+      <td> {status} </td>\n+      <td> {query.id} </td>\n+      <td> <a href={statisticsLink}> {query.runId} </a> </td>\n+      <td> {SparkUIUtils.formatDate(timeSinceStart)} </td>\n+      <td> {duration} </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.inputRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.processedRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query,\n+        { query.getQuerySummary.getMetric(QuerySummary.TOTAL_INPUT_RECORDS, 0L) }, \"NaN\")} </td>\n+      <td> {withNoProgress(query, { query.lastProgress.batchId }, \"NaN\")} </td>\n+      {details(withNoProgress(query, {\n+      s\"== JSON representation of this progress ==\\n${query.lastProgress.prettyJson}\" }, \"-\"))}"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "I'd agree that just removing the \"last progress\" column would be OK. End users can still register their custom streaming query listeners and receive the information on their apps.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-20T05:54:06Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {\n+        case Some(_) => \"FAILED\"\n+        case None => \"FINISHED\"\n+      }\n+    }\n+\n+    val duration = if (isActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val end = query.lastProgress.timestamp\n+        val start = query.recentProgress.head.timestamp\n+        SparkUIUtils.formatDurationVerbose(\n+          df.parse(end).getTime - df.parse(start).getTime)\n+      }, \"-\")\n+    }\n+\n+    <tr>\n+      <td> {name} </td>\n+      <td> {status} </td>\n+      <td> {query.id} </td>\n+      <td> <a href={statisticsLink}> {query.runId} </a> </td>\n+      <td> {SparkUIUtils.formatDate(timeSinceStart)} </td>\n+      <td> {duration} </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.inputRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.processedRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query,\n+        { query.getQuerySummary.getMetric(QuerySummary.TOTAL_INPUT_RECORDS, 0L) }, \"NaN\")} </td>\n+      <td> {withNoProgress(query, { query.lastProgress.batchId }, \"NaN\")} </td>\n+      {details(withNoProgress(query, {\n+      s\"== JSON representation of this progress ==\\n${query.lastProgress.prettyJson}\" }, \"-\"))}"
  }, {
    "author": {
      "login": "sarutak"
    },
    "body": "I think that removing it  would be OK too.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-20T11:33:33Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {\n+        case Some(_) => \"FAILED\"\n+        case None => \"FINISHED\"\n+      }\n+    }\n+\n+    val duration = if (isActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val end = query.lastProgress.timestamp\n+        val start = query.recentProgress.head.timestamp\n+        SparkUIUtils.formatDurationVerbose(\n+          df.parse(end).getTime - df.parse(start).getTime)\n+      }, \"-\")\n+    }\n+\n+    <tr>\n+      <td> {name} </td>\n+      <td> {status} </td>\n+      <td> {query.id} </td>\n+      <td> <a href={statisticsLink}> {query.runId} </a> </td>\n+      <td> {SparkUIUtils.formatDate(timeSinceStart)} </td>\n+      <td> {duration} </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.inputRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.processedRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query,\n+        { query.getQuerySummary.getMetric(QuerySummary.TOTAL_INPUT_RECORDS, 0L) }, \"NaN\")} </td>\n+      <td> {withNoProgress(query, { query.lastProgress.batchId }, \"NaN\")} </td>\n+      {details(withNoProgress(query, {\n+      s\"== JSON representation of this progress ==\\n${query.lastProgress.prettyJson}\" }, \"-\"))}"
  }],
  "prId": 26201
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Could you elaborate what this lock will guarantee? I'm not sure I follow, as `store` instance is still accessed without lock (there're bunch of places which don't participate locking, and even this line uses \"Option\" instance to lock).",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-20T08:00:42Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {"
  }, {
    "author": {
      "login": "uncleGen"
    },
    "body": "Looks like redundant, removed.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-21T06:52:04Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {"
  }],
  "prId": 26201
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "`null` sounds unfriendly to the end users. How about rewording to be like `<untitled>`, `<no name>`, etc?",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-20T08:05:18Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\""
  }, {
    "author": {
      "login": "uncleGen"
    },
    "body": "Make sense. ",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-21T06:55:36Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\""
  }],
  "prId": 26201
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "This is duplicated with `ThriftServerPage.errorMessageCell`. Maybe better to have it in SparkUIUtils and reuse.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-20T08:08:31Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {",
    "line": 48
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Just a note: review comment is not addressed yet.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-25T06:26:58Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {",
    "line": 48
  }],
  "prId": 26201
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "`.map(_.message)` looks redundant. If you would prefer one-liner, `query.exception.map(_ => \"FAILED\").getOrElse(\"FINISHED\")`. Otherwise just need to remove redundant part.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-20T08:11:52Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {"
  }, {
    "author": {
      "login": "uncleGen"
    },
    "body": "nice",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-21T07:05:06Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {"
  }],
  "prId": 26201
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "As I commented earlier, `query` is not guarded with lock. (If you want to lock the query, you should add synchronization all the places, but it would bring unintended perf. degrade so I think you shouldn't.)\r\n\r\nIf you would want to have a consistent view during rendering, you should copy (clone) the all necessary information in query from `render` method and only rely on the cloned information.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-20T08:17:09Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {\n+        case Some(_) => \"FAILED\"\n+        case None => \"FINISHED\"\n+      }\n+    }\n+\n+    val duration = if (isActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val end = query.lastProgress.timestamp\n+        val start = query.recentProgress.head.timestamp\n+        SparkUIUtils.formatDurationVerbose(\n+          df.parse(end).getTime - df.parse(start).getTime)\n+      }, \"-\")\n+    }\n+\n+    <tr>\n+      <td> {name} </td>\n+      <td> {status} </td>\n+      <td> {query.id} </td>\n+      <td> <a href={statisticsLink}> {query.runId} </a> </td>\n+      <td> {SparkUIUtils.formatDate(timeSinceStart)} </td>\n+      <td> {duration} </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.inputRowsPerSecond)).sum /",
    "line": 94
  }],
  "prId": 26201
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "\"PerSec\" looks odd. For me, there seem to be better alternatives: \"/sec\", \"per second\", \"per sec.\", and maybe more.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-20T08:23:55Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {\n+        case Some(_) => \"FAILED\"\n+        case None => \"FINISHED\"\n+      }\n+    }\n+\n+    val duration = if (isActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val end = query.lastProgress.timestamp\n+        val start = query.recentProgress.head.timestamp\n+        SparkUIUtils.formatDurationVerbose(\n+          df.parse(end).getTime - df.parse(start).getTime)\n+      }, \"-\")\n+    }\n+\n+    <tr>\n+      <td> {name} </td>\n+      <td> {status} </td>\n+      <td> {query.id} </td>\n+      <td> <a href={statisticsLink}> {query.runId} </a> </td>\n+      <td> {SparkUIUtils.formatDate(timeSinceStart)} </td>\n+      <td> {duration} </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.inputRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.processedRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query,\n+        { query.getQuerySummary.getMetric(QuerySummary.TOTAL_INPUT_RECORDS, 0L) }, \"NaN\")} </td>\n+      <td> {withNoProgress(query, { query.lastProgress.batchId }, \"NaN\")} </td>\n+      {details(withNoProgress(query, {\n+      s\"== JSON representation of this progress ==\\n${query.lastProgress.prettyJson}\" }, \"-\"))}\n+      {details(withNoProgress(query, { query.exception.map(_.message).getOrElse(\"-\") }, \"-\"))}\n+    </tr>\n+  }\n+\n+  private def generateStreamingQueryTable(request: HttpServletRequest): Seq[Node] = {\n+    val (activeQueries, inactiveQueries) =\n+      store.map(_.allStreamQueries.partition(_._1.isActive)).getOrElse((Seq.empty, Seq.empty))\n+    val activeQueryTables = if (activeQueries.nonEmpty) {\n+      val headerRow = Seq(\n+        \"Query Name\", \"Status\", \"Id\", \"Run ID\", \"Submit Time\", \"Duration\", \"Avg Input PerSec\","
  }],
  "prId": 26201
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Same here.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-20T08:24:17Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {\n+        case Some(_) => \"FAILED\"\n+        case None => \"FINISHED\"\n+      }\n+    }\n+\n+    val duration = if (isActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val end = query.lastProgress.timestamp\n+        val start = query.recentProgress.head.timestamp\n+        SparkUIUtils.formatDurationVerbose(\n+          df.parse(end).getTime - df.parse(start).getTime)\n+      }, \"-\")\n+    }\n+\n+    <tr>\n+      <td> {name} </td>\n+      <td> {status} </td>\n+      <td> {query.id} </td>\n+      <td> <a href={statisticsLink}> {query.runId} </a> </td>\n+      <td> {SparkUIUtils.formatDate(timeSinceStart)} </td>\n+      <td> {duration} </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.inputRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.processedRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query,\n+        { query.getQuerySummary.getMetric(QuerySummary.TOTAL_INPUT_RECORDS, 0L) }, \"NaN\")} </td>\n+      <td> {withNoProgress(query, { query.lastProgress.batchId }, \"NaN\")} </td>\n+      {details(withNoProgress(query, {\n+      s\"== JSON representation of this progress ==\\n${query.lastProgress.prettyJson}\" }, \"-\"))}\n+      {details(withNoProgress(query, { query.exception.map(_.message).getOrElse(\"-\") }, \"-\"))}\n+    </tr>\n+  }\n+\n+  private def generateStreamingQueryTable(request: HttpServletRequest): Seq[Node] = {\n+    val (activeQueries, inactiveQueries) =\n+      store.map(_.allStreamQueries.partition(_._1.isActive)).getOrElse((Seq.empty, Seq.empty))\n+    val activeQueryTables = if (activeQueries.nonEmpty) {\n+      val headerRow = Seq(\n+        \"Query Name\", \"Status\", \"Id\", \"Run ID\", \"Submit Time\", \"Duration\", \"Avg Input PerSec\",\n+        \"Avg Process PerSec\", s\"Total Input Rows\", \"Last Batch ID\", \"Last Progress\", \"Error\")\n+\n+      Some(SparkUIUtils.listingTable(headerRow, generateDataRow(request, true), activeQueries,\n+        true, None, Seq(null), false))\n+    } else {\n+      None\n+    }\n+\n+    val inactiveQueryTables = if (inactiveQueries.nonEmpty) {\n+      val headerRow = Seq(\n+        \"Query Name\", \"Status\", \"Id\", \"Run ID\", \"Submit Time\", \"Duration\", \"Avg Input PerSec\","
  }],
  "prId": 26201
}, {
  "comments": [{
    "author": {
      "login": "sarutak"
    },
    "body": "I'm not a native speaker so I'm not sure but `No streaming queries have completed yet` or `No streaming query has completed yet` is grammatically correct?",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-20T10:36:07Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.execution.ui.SQLTab\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: SQLTab, store: Option[StreamQueryStore])\n+  extends WebUIPage(\"streaming\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = store.synchronized {\n+      generateStreamingQueryTable(request)\n+    }\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, isActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) {\n+          s.substring(0, s.indexOf('\\n'))\n+        } else {\n+          s\n+        })\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/streaming/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = if (query.name == null || query.name.isEmpty) {\n+      \"null\"\n+    } else {\n+      query.name\n+    }\n+\n+    val status = if (isActive) {\n+      \"RUNNING\"\n+    } else {\n+      query.exception.map(_.message) match {\n+        case Some(_) => \"FAILED\"\n+        case None => \"FINISHED\"\n+      }\n+    }\n+\n+    val duration = if (isActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val end = query.lastProgress.timestamp\n+        val start = query.recentProgress.head.timestamp\n+        SparkUIUtils.formatDurationVerbose(\n+          df.parse(end).getTime - df.parse(start).getTime)\n+      }, \"-\")\n+    }\n+\n+    <tr>\n+      <td> {name} </td>\n+      <td> {status} </td>\n+      <td> {query.id} </td>\n+      <td> <a href={statisticsLink}> {query.runId} </a> </td>\n+      <td> {SparkUIUtils.formatDate(timeSinceStart)} </td>\n+      <td> {duration} </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.inputRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query, {\n+        (query.recentProgress.map(p => withNumberInvalid(p.processedRowsPerSecond)).sum /\n+          query.recentProgress.length).formatted(\"%.2f\") }, \"NaN\")}\n+      </td>\n+      <td> {withNoProgress(query,\n+        { query.getQuerySummary.getMetric(QuerySummary.TOTAL_INPUT_RECORDS, 0L) }, \"NaN\")} </td>\n+      <td> {withNoProgress(query, { query.lastProgress.batchId }, \"NaN\")} </td>\n+      {details(withNoProgress(query, {\n+      s\"== JSON representation of this progress ==\\n${query.lastProgress.prettyJson}\" }, \"-\"))}\n+      {details(withNoProgress(query, { query.exception.map(_.message).getOrElse(\"-\") }, \"-\"))}\n+    </tr>\n+  }\n+\n+  private def generateStreamingQueryTable(request: HttpServletRequest): Seq[Node] = {\n+    val (activeQueries, inactiveQueries) =\n+      store.map(_.allStreamQueries.partition(_._1.isActive)).getOrElse((Seq.empty, Seq.empty))\n+    val activeQueryTables = if (activeQueries.nonEmpty) {\n+      val headerRow = Seq(\n+        \"Query Name\", \"Status\", \"Id\", \"Run ID\", \"Submit Time\", \"Duration\", \"Avg Input PerSec\",\n+        \"Avg Process PerSec\", s\"Total Input Rows\", \"Last Batch ID\", \"Last Progress\", \"Error\")\n+\n+      Some(SparkUIUtils.listingTable(headerRow, generateDataRow(request, true), activeQueries,\n+        true, None, Seq(null), false))\n+    } else {\n+      None\n+    }\n+\n+    val inactiveQueryTables = if (inactiveQueries.nonEmpty) {\n+      val headerRow = Seq(\n+        \"Query Name\", \"Status\", \"Id\", \"Run ID\", \"Submit Time\", \"Duration\", \"Avg Input PerSec\",\n+        \"Avg Process PerSec\", s\"Total Input Rows\", \"Last Batch ID\", \"Last Progress\", \"Error\")\n+\n+      Some(SparkUIUtils.listingTable(headerRow, generateDataRow(request, false), inactiveQueries,\n+        true, None, Seq(null), false))\n+    } else {\n+      None\n+    }\n+\n+    val content =\n+      <h5 id=\"activequeries\">Active Streaming Queries ({activeQueries.length})</h5> ++\n+        <div>\n+          <ul class=\"unstyled\">\n+            {activeQueryTables.getOrElse(\"No active streaming query have been generated yet.\")}\n+          </ul>\n+        </div> ++\n+        <h5 id=\"completedqueries\">Completed Streaming Queries ({inactiveQueries.length})</h5> ++\n+        <div>\n+          <ul class=\"unstyled\">\n+            {inactiveQueryTables.getOrElse(\"No streaming query have completed yet.\")}"
  }],
  "prId": 26201
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "`recentProgress.head` doesn't denote the first of the query. `timeSinceStart` is also a start time of inactive query, according to `StreamQueryStore.terminate`.",
    "commit": "6de18cc2e20bd8ef0167a52c869c7706f67014a2",
    "createdAt": "2019-11-25T06:36:11Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming.ui\n+\n+import java.text.SimpleDateFormat\n+import java.util.TimeZone\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.execution.streaming.{QuerySummary, StreamQueryStore}\n+import org.apache.spark.sql.streaming.StreamingQuery\n+import org.apache.spark.sql.streaming.ui.UIUtils._\n+import org.apache.spark.ui.{UIUtils => SparkUIUtils, WebUIPage}\n+\n+class StreamingQueryPage(parent: StreamingQueryTab, store: StreamQueryStore)\n+  extends WebUIPage(\"\") with Logging {\n+  val df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n+  df.setTimeZone(TimeZone.getDefault)\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val content = generateStreamingQueryTable(request)\n+    SparkUIUtils.headerSparkPage(request, \"Streaming Query\", content, parent)\n+  }\n+\n+  def generateDataRow(request: HttpServletRequest, queryActive: Boolean)\n+    (streamQuery: (StreamingQuery, Long)): Seq[Node] = {\n+\n+    val (query, timeSinceStart) = streamQuery\n+    def details(detail: Any): Seq[Node] = {\n+      val s = detail.asInstanceOf[String]\n+      val isMultiline = s.indexOf('\\n') >= 0\n+      val summary = StringEscapeUtils.escapeHtml4(\n+        if (isMultiline) s.substring(0, s.indexOf('\\n')) else s\n+      )\n+      val details = if (isMultiline) {\n+        // scalastyle:off\n+        <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+              class=\"expand-details\">\n+          +details\n+        </span> ++\n+          <div class=\"stacktrace-details collapsed\">\n+            <pre>{s}</pre>\n+          </div>\n+        // scalastyle:on\n+      } else {\n+        \"\"\n+      }\n+      <td>{summary}{details}</td>\n+    }\n+\n+    val statisticsLink = \"%s/%s/statistics?id=%s\"\n+      .format(SparkUIUtils.prependBaseUri(request, parent.basePath), parent.prefix, query.runId)\n+\n+    val name = UIUtils.getQueryName(query)\n+    val status = UIUtils.getQueryStatus(query)\n+    val duration = if (queryActive) {\n+      SparkUIUtils.formatDurationVerbose(System.currentTimeMillis() - timeSinceStart)\n+    } else {\n+      withNoProgress(query, {\n+        val endTimeMs = query.lastProgress.timestamp\n+        val startTimeMs = query.recentProgress.head.timestamp",
    "line": 80
  }],
  "prId": 26201
}]