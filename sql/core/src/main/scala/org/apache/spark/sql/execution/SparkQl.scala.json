[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "Why change this? You didn't touch the describe stuff in `SparkSqlParser.g` right?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-13T18:18:53Z",
    "diffHunk": "@@ -52,26 +57,30 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           nodeToDescribeFallback(node)\n         } else {\n           tableType match {\n-            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts :: Nil) :: Nil) =>\n+            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts) :: Nil) =>",
    "line": 107
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Yes. I think it is incorrect from beginning but not be tested it out because we don't reach here before. I've tested it locally. Once all three commands are migrated, we can see this passing tests.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-13T22:11:41Z",
    "diffHunk": "@@ -52,26 +57,30 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           nodeToDescribeFallback(node)\n         } else {\n           tableType match {\n-            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts :: Nil) :: Nil) =>\n+            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts) :: Nil) =>",
    "line": 107
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "if we parse the following SQL using the parse driver `org.apache.spark.sql.catalyst.parser.ParseDriver.parsePlan(\"DESCRIBE EXTENDED tbl.a\", null)`\n\nWe would end up with the following AST:\n\n```\nTOK_DESCTABLE 1, 0, 6, 18\n:- TOK_TABTYPE 1, 4, 6, 18 \n:  +- TOK_TABNAME 1, 4, 6, 18 \n:     :- tbl 1, 4, 4, 18 \n:     +- a 1, 6, 6, 22 \n+- EXTENDED 1, 2, 2, 9 \n```\n\nThis change would pick this up, and old code didn't (I am sure I tested this though :S ). You can disable this in the DDL parser, to see if it works now.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-18T09:11:14Z",
    "diffHunk": "@@ -52,26 +57,30 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           nodeToDescribeFallback(node)\n         } else {\n           tableType match {\n-            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts :: Nil) :: Nil) =>\n+            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts) :: Nil) =>",
    "line": 107
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "Could we add a test for this? The Hive test suite apparently misses this one. I could also address in a different PR.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-23T12:29:59Z",
    "diffHunk": "@@ -52,26 +57,30 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           nodeToDescribeFallback(node)\n         } else {\n           tableType match {\n-            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts :: Nil) :: Nil) =>\n+            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts) :: Nil) =>",
    "line": 107
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Actually we have test for describe table command in HiveQuerySuite. Do we need another test?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-26T03:21:40Z",
    "diffHunk": "@@ -52,26 +57,30 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           nodeToDescribeFallback(node)\n         } else {\n           tableType match {\n-            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts :: Nil) :: Nil) =>\n+            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts) :: Nil) =>",
    "line": 107
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "cleanIdentifier?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-18T09:12:04Z",
    "diffHunk": "@@ -52,26 +130,30 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           nodeToDescribeFallback(node)\n         } else {\n           tableType match {\n-            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts :: Nil) :: Nil) =>\n+            case Token(\"TOK_TABTYPE\", Token(\"TOK_TABNAME\", nameParts) :: Nil) =>\n               nameParts match {\n-                case Token(\".\", dbName :: tableName :: Nil) =>\n+                case Token(dbName, _) :: Token(tableName, _) :: Nil =>\n                   // It is describing a table with the format like \"describe db.table\".\n                   // TODO: Actually, a user may mean tableName.columnName. Need to resolve this\n                   // issue.\n-                  val tableIdent = extractTableIdent(nameParts)\n+                  val tableIdent = TableIdentifier(\n+                    cleanIdentifier(tableName), Some(cleanIdentifier(dbName)))\n                   datasources.DescribeCommand(\n                     UnresolvedRelation(tableIdent, None), isExtended = extended.isDefined)\n-                case Token(\".\", dbName :: tableName :: colName :: Nil) =>\n+                case Token(dbName, _) :: Token(tableName, _) :: Token(colName, _) :: Nil =>\n                   // It is describing a column with the format like \"describe db.table column\".\n                   nodeToDescribeFallback(node)\n-                case tableName =>\n+                case tableName :: Nil =>\n                   // It is describing a table with the format like \"describe table\".\n                   datasources.DescribeCommand(\n                     UnresolvedRelation(TableIdentifier(tableName.text), None),"
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "You could make more use of pattern matching here. For example:\n\n```\nval temp ::\n    allowExisting ::\n    Some(Token(\"TOK_TABNAME\", Token(tableName, Nil)) ::\n    tableCols ::\n    Some(Token(\"TOK_TABLEPROVIDER\", Token(provider, Nil) :: Nil)) ::\n    tableOpts ::\n    tableAs ::\n    Nil =  getClauses(Seq(\n      \"TEMPORARY\",\n      \"TOK_IFNOTEXISTS\",\n      \"TOK_TABNAME\",\n      \"TOK_TABCOLLIST\",\n      \"TOK_TABLEPROVIDER\",\n      \"TOK_TABLEOPTIONS\",\n      \"TOK_QUERY\"), createTableArgs)\n```\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-18T09:26:26Z",
    "diffHunk": "@@ -42,6 +45,81 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val clauses = getClauses(\n+            Seq(\"TEMPORARY\", \"TOK_IFNOTEXISTS\", \"TOK_TABNAME\", \"TOK_TABCOLLIST\", \"TOK_TABLEPROVIDER\",\n+              \"TOK_TABLEOPTIONS\", \"TOK_QUERY\"), createTableArgs)\n+\n+        val temp = clauses(0)\n+        val allowExisting = clauses(1)\n+        val Some(tabName) = clauses(2)\n+        val tableCols = clauses(3)\n+        val Some(tableProvider) = clauses(4)\n+        val tableOpts = clauses(5)\n+        val tableAs = clauses(6)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(tableName, _) :: Nil) => TableIdentifier(tableName)\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = tableProvider match {\n+          case Token(\"TOK_TABLEPROVIDER\", Token(provider, _) :: Nil) => provider\n+        }"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Yeah. I was using that to match. But the compiler continues to throw syntax problem.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-18T09:36:53Z",
    "diffHunk": "@@ -42,6 +45,81 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val clauses = getClauses(\n+            Seq(\"TEMPORARY\", \"TOK_IFNOTEXISTS\", \"TOK_TABNAME\", \"TOK_TABCOLLIST\", \"TOK_TABLEPROVIDER\",\n+              \"TOK_TABLEOPTIONS\", \"TOK_QUERY\"), createTableArgs)\n+\n+        val temp = clauses(0)\n+        val allowExisting = clauses(1)\n+        val Some(tabName) = clauses(2)\n+        val tableCols = clauses(3)\n+        val Some(tableProvider) = clauses(4)\n+        val tableOpts = clauses(5)\n+        val tableAs = clauses(6)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(tableName, _) :: Nil) => TableIdentifier(tableName)\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = tableProvider match {\n+          case Token(\"TOK_TABLEPROVIDER\", Token(provider, _) :: Nil) => provider\n+        }"
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "Just tried this:\n\n```\nval Seq(\n      temp,\n      allowExisting,\n      Some(Token(\"TOK_TABNAME\", Token(tableName, Nil) :: Nil)),\n      tableCols,\n      Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n      tableOpts,\n      tableAs) = getClauses(Seq(\n      \"TEMPORARY\",\n      \"TOK_IFNOTEXISTS\",\n      \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n      \"TOK_TABLEPROVIDER\",\n      \"TOK_TABLEOPTIONS\",\n      \"TOK_QUERY\"), createTableArgs)\n```\n\n...and this compiles.\n\n[edit: posted the wrong code initialy]\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-18T12:14:00Z",
    "diffHunk": "@@ -42,6 +45,81 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val clauses = getClauses(\n+            Seq(\"TEMPORARY\", \"TOK_IFNOTEXISTS\", \"TOK_TABNAME\", \"TOK_TABCOLLIST\", \"TOK_TABLEPROVIDER\",\n+              \"TOK_TABLEOPTIONS\", \"TOK_QUERY\"), createTableArgs)\n+\n+        val temp = clauses(0)\n+        val allowExisting = clauses(1)\n+        val Some(tabName) = clauses(2)\n+        val tableCols = clauses(3)\n+        val Some(tableProvider) = clauses(4)\n+        val tableOpts = clauses(5)\n+        val tableAs = clauses(6)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(tableName, _) :: Nil) => TableIdentifier(tableName)\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = tableProvider match {\n+          case Token(\"TOK_TABLEPROVIDER\", Token(provider, _) :: Nil) => provider\n+        }"
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Can you have a plan inside table options?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-18T09:28:13Z",
    "diffHunk": "@@ -42,6 +45,81 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val clauses = getClauses(\n+            Seq(\"TEMPORARY\", \"TOK_IFNOTEXISTS\", \"TOK_TABNAME\", \"TOK_TABCOLLIST\", \"TOK_TABLEPROVIDER\",\n+              \"TOK_TABLEOPTIONS\", \"TOK_QUERY\"), createTableArgs)\n+\n+        val temp = clauses(0)\n+        val allowExisting = clauses(1)\n+        val Some(tabName) = clauses(2)\n+        val tableCols = clauses(3)\n+        val Some(tableProvider) = clauses(4)\n+        val tableOpts = clauses(5)\n+        val tableAs = clauses(6)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(tableName, _) :: Nil) => TableIdentifier(tableName)\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = tableProvider match {\n+          case Token(\"TOK_TABLEPROVIDER\", Token(provider, _) :: Nil) => provider\n+        }\n+\n+        val options = tableOpts.map { opts =>\n+          opts match {\n+            case Token(\"TOK_TABLEOPTIONS\", options) =>\n+              options.map {\n+                case Token(\"TOK_TABLEOPTION\", Token(key, _) :: Token(value, _) :: Nil) =>\n+                  (key, value)\n+                case _ => super.nodeToPlan(node)"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "No. This line should be removed.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-18T09:44:47Z",
    "diffHunk": "@@ -42,6 +45,81 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val clauses = getClauses(\n+            Seq(\"TEMPORARY\", \"TOK_IFNOTEXISTS\", \"TOK_TABNAME\", \"TOK_TABCOLLIST\", \"TOK_TABLEPROVIDER\",\n+              \"TOK_TABLEOPTIONS\", \"TOK_QUERY\"), createTableArgs)\n+\n+        val temp = clauses(0)\n+        val allowExisting = clauses(1)\n+        val Some(tabName) = clauses(2)\n+        val tableCols = clauses(3)\n+        val Some(tableProvider) = clauses(4)\n+        val tableOpts = clauses(5)\n+        val tableAs = clauses(6)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(tableName, _) :: Nil) => TableIdentifier(tableName)\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = tableProvider match {\n+          case Token(\"TOK_TABLEPROVIDER\", Token(provider, _) :: Nil) => provider\n+        }\n+\n+        val options = tableOpts.map { opts =>\n+          opts match {\n+            case Token(\"TOK_TABLEOPTIONS\", options) =>\n+              options.map {\n+                case Token(\"TOK_TABLEOPTION\", Token(key, _) :: Token(value, _) :: Nil) =>\n+                  (key, value)\n+                case _ => super.nodeToPlan(node)"
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Why not use `unquoteString` this does the same and is easier to read?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-18T09:57:50Z",
    "diffHunk": "@@ -42,6 +45,84 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val clauses = getClauses(\n+            Seq(\"TEMPORARY\", \"TOK_IFNOTEXISTS\", \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+              \"TOK_TABLEPROVIDER\", \"TOK_TABLEOPTIONS\", \"TOK_QUERY\"), createTableArgs)\n+\n+        val temp = clauses(0)\n+        val allowExisting = clauses(1)\n+        val Some(tabName) = clauses(2)\n+        val tableCols = clauses(3)\n+        val Some(tableProvider) = clauses(4)\n+        val tableOpts = clauses(5)\n+        val tableAs = clauses(6)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, _) :: Token(tableName, _) :: Nil) =>\n+            new TableIdentifier(tableName, Some(dbName))\n+          case Token(\"TOK_TABNAME\", Token(tableName, _) :: Nil) =>\n+            TableIdentifier(tableName)\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = tableProvider match {\n+          case Token(\"TOK_TABLEPROVIDER\", Token(provider, _) :: Nil) => provider\n+        }\n+\n+        val options = tableOpts.map { opts =>\n+          opts match {\n+            case Token(\"TOK_TABLEOPTIONS\", options) =>\n+              options.map {\n+                case Token(\"TOK_TABLEOPTION\", Token(key, _) :: Token(value, _) :: Nil) =>\n+                  (key, value.replaceAll(\"^\\'|^\\\"|\\\"$|\\'$\", \"\"))"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Don't know there is `unquoteString`. Thanks.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-19T05:45:45Z",
    "diffHunk": "@@ -42,6 +45,84 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val clauses = getClauses(\n+            Seq(\"TEMPORARY\", \"TOK_IFNOTEXISTS\", \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+              \"TOK_TABLEPROVIDER\", \"TOK_TABLEOPTIONS\", \"TOK_QUERY\"), createTableArgs)\n+\n+        val temp = clauses(0)\n+        val allowExisting = clauses(1)\n+        val Some(tabName) = clauses(2)\n+        val tableCols = clauses(3)\n+        val Some(tableProvider) = clauses(4)\n+        val tableOpts = clauses(5)\n+        val tableAs = clauses(6)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, _) :: Token(tableName, _) :: Nil) =>\n+            new TableIdentifier(tableName, Some(dbName))\n+          case Token(\"TOK_TABNAME\", Token(tableName, _) :: Nil) =>\n+            TableIdentifier(tableName)\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = tableProvider match {\n+          case Token(\"TOK_TABLEPROVIDER\", Token(provider, _) :: Nil) => provider\n+        }\n+\n+        val options = tableOpts.map { opts =>\n+          opts match {\n+            case Token(\"TOK_TABLEOPTIONS\", options) =>\n+              options.map {\n+                case Token(\"TOK_TABLEOPTION\", Token(key, _) :: Token(value, _) :: Nil) =>\n+                  (key, value.replaceAll(\"^\\'|^\\\"|\\\"$|\\'$\", \"\"))"
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "The `TOK_TABLEPROVIDER` will have multiple children if the name is dotted, e.g.:`org.apache.spark.sql.avro`. So we need to handle that case here.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-18T10:01:28Z",
    "diffHunk": "@@ -42,6 +45,83 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val clauses = getClauses(\n+            Seq(\"TEMPORARY\", \"TOK_IFNOTEXISTS\", \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+              \"TOK_TABLEPROVIDER\", \"TOK_TABLEOPTIONS\", \"TOK_QUERY\"), createTableArgs)\n+\n+        val temp = clauses(0)\n+        val allowExisting = clauses(1)\n+        val Some(tabName) = clauses(2)\n+        val tableCols = clauses(3)\n+        val Some(tableProvider) = clauses(4)\n+        val tableOpts = clauses(5)\n+        val tableAs = clauses(6)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, _) :: Token(tableName, _) :: Nil) =>\n+            new TableIdentifier(tableName, Some(dbName))\n+          case Token(\"TOK_TABNAME\", Token(tableName, _) :: Nil) =>\n+            TableIdentifier(tableName)\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = tableProvider match {\n+          case Token(\"TOK_TABLEPROVIDER\", Token(provider, _) :: Nil) => provider"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Yeah. One test failed because of this. I will fix it.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-18T13:08:49Z",
    "diffHunk": "@@ -42,6 +45,83 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val clauses = getClauses(\n+            Seq(\"TEMPORARY\", \"TOK_IFNOTEXISTS\", \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+              \"TOK_TABLEPROVIDER\", \"TOK_TABLEOPTIONS\", \"TOK_QUERY\"), createTableArgs)\n+\n+        val temp = clauses(0)\n+        val allowExisting = clauses(1)\n+        val Some(tabName) = clauses(2)\n+        val tableCols = clauses(3)\n+        val Some(tableProvider) = clauses(4)\n+        val tableOpts = clauses(5)\n+        val tableAs = clauses(6)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, _) :: Token(tableName, _) :: Nil) =>\n+            new TableIdentifier(tableName, Some(dbName))\n+          case Token(\"TOK_TABNAME\", Token(tableName, _) :: Nil) =>\n+            TableIdentifier(tableName)\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = tableProvider match {\n+          case Token(\"TOK_TABLEPROVIDER\", Token(provider, _) :: Nil) => provider"
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Do we still need a DDL exception? Why not throw an analysis exception?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-23T12:24:28Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, _) :: Token(tableName, _) :: Nil) =>\n+            new TableIdentifier(cleanIdentifier(tableName), Some(cleanIdentifier(dbName)))\n+          case Token(\"TOK_TABNAME\", Token(tableName, _) :: Nil) =>\n+            TableIdentifier(cleanIdentifier(tableName))\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = providerNameParts.map {\n+          case Token(name, _) => name\n+        }.mkString(\".\")\n+\n+        val options = tableOpts.map { opts =>\n+          opts match {\n+            case Token(\"TOK_TABLEOPTIONS\", options) =>\n+              options.map {\n+                case Token(\"TOK_TABLEOPTION\", keysAndValue) =>\n+                  val key = keysAndValue.init.map {\n+                    case Token(k, _) => k\n+                  }.mkString(\".\")\n+                  val value = unquoteString(keysAndValue.last.text)\n+                  (key, unquoteString(value))\n+              }.asInstanceOf[Seq[(String, String)]].toMap\n+          }\n+        }.getOrElse(Map.empty[String, String])\n+\n+        val asClause = tableAs.map(nodeToPlan(_))\n+\n+        if (temp.isDefined && allowExisting.isDefined) {\n+          throw new DDLException("
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Actually here the thrown exception will be caught in `CatalystQl` which will then throw an `AnalysisException`.  But I agreed that we can remove `DDLException`. Only `DDLParser` uses it.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-25T07:55:36Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, _) :: Token(tableName, _) :: Nil) =>\n+            new TableIdentifier(cleanIdentifier(tableName), Some(cleanIdentifier(dbName)))\n+          case Token(\"TOK_TABNAME\", Token(tableName, _) :: Nil) =>\n+            TableIdentifier(cleanIdentifier(tableName))\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = providerNameParts.map {\n+          case Token(name, _) => name\n+        }.mkString(\".\")\n+\n+        val options = tableOpts.map { opts =>\n+          opts match {\n+            case Token(\"TOK_TABLEOPTIONS\", options) =>\n+              options.map {\n+                case Token(\"TOK_TABLEOPTION\", keysAndValue) =>\n+                  val key = keysAndValue.init.map {\n+                    case Token(k, _) => k\n+                  }.mkString(\".\")\n+                  val value = unquoteString(keysAndValue.last.text)\n+                  (key, unquoteString(value))\n+              }.asInstanceOf[Seq[(String, String)]].toMap\n+          }\n+        }.getOrElse(Map.empty[String, String])\n+\n+        val asClause = tableAs.map(nodeToPlan(_))\n+\n+        if (temp.isDefined && allowExisting.isDefined) {\n+          throw new DDLException("
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "I am personally not big on using wildcards in pattern matches. This prevents us from catching a grammar problem early. Since most of the wildcards are actually empty lists, why not match these?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-23T12:27:53Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, _) :: Token(tableName, _) :: Nil) =>"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "I don't get understood. I think I don't use wildcards in pattern matches here?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-25T07:58:28Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, _) :: Token(tableName, _) :: Nil) =>"
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "As soon as you use an underscore in a pattern match, for example: `Token(dbName, _)`, you are using a wildcard in the second position.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-25T11:02:54Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, _) :: Token(tableName, _) :: Nil) =>"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "ah, I see, just not sure where you are pointing to. I was wondering I don't have case _ branch. Thanks.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-25T11:55:46Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, _) :: Token(tableName, _) :: Nil) =>"
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Why don't we use `extractTableIdent`?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-27T17:20:57Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {"
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Do we actually need a `TOK_TABLEOPTION`? We know that a `TOK_TABLEOPTIONS` contains options. It'll save an intermediate node.\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-27T17:26:01Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, Nil) :: Token(tableName, Nil) :: Nil) =>\n+            new TableIdentifier(cleanIdentifier(tableName), Some(cleanIdentifier(dbName)))\n+          case Token(\"TOK_TABNAME\", Token(tableName, Nil) :: Nil) =>\n+            TableIdentifier(cleanIdentifier(tableName))\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = providerNameParts.map {\n+          case Token(name, Nil) => name\n+        }.mkString(\".\")\n+\n+        val options = tableOpts.map { opts =>\n+          opts match {\n+            case Token(\"TOK_TABLEOPTIONS\", options) =>\n+              options.map {\n+                case Token(\"TOK_TABLEOPTION\", keysAndValue) =>"
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "Nevermind. The name can have multiple parts. We could try to solve this in the lexer (make it one name again).\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-27T17:34:45Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, Nil) :: Token(tableName, Nil) :: Nil) =>\n+            new TableIdentifier(cleanIdentifier(tableName), Some(cleanIdentifier(dbName)))\n+          case Token(\"TOK_TABNAME\", Token(tableName, Nil) :: Nil) =>\n+            TableIdentifier(cleanIdentifier(tableName))\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = providerNameParts.map {\n+          case Token(name, Nil) => name\n+        }.mkString(\".\")\n+\n+        val options = tableOpts.map { opts =>\n+          opts match {\n+            case Token(\"TOK_TABLEOPTIONS\", options) =>\n+              options.map {\n+                case Token(\"TOK_TABLEOPTION\", keysAndValue) =>"
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": " `keysAndValue.init.map.(_.text).mkString(\".\")` ?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-27T17:33:37Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, Nil) :: Token(tableName, Nil) :: Nil) =>\n+            new TableIdentifier(cleanIdentifier(tableName), Some(cleanIdentifier(dbName)))\n+          case Token(\"TOK_TABNAME\", Token(tableName, Nil) :: Nil) =>\n+            TableIdentifier(cleanIdentifier(tableName))\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = providerNameParts.map {\n+          case Token(name, Nil) => name\n+        }.mkString(\".\")\n+\n+        val options = tableOpts.map { opts =>\n+          opts match {\n+            case Token(\"TOK_TABLEOPTIONS\", options) =>\n+              options.map {\n+                case Token(\"TOK_TABLEOPTION\", keysAndValue) =>\n+                  val key = keysAndValue.init.map {\n+                    case Token(k, Nil) => k"
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Why is this cast needed?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-27T17:35:57Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, Nil) :: Token(tableName, Nil) :: Nil) =>\n+            new TableIdentifier(cleanIdentifier(tableName), Some(cleanIdentifier(dbName)))\n+          case Token(\"TOK_TABNAME\", Token(tableName, Nil) :: Nil) =>\n+            TableIdentifier(cleanIdentifier(tableName))\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = providerNameParts.map {\n+          case Token(name, Nil) => name\n+        }.mkString(\".\")\n+\n+        val options = tableOpts.map { opts =>\n+          opts match {\n+            case Token(\"TOK_TABLEOPTIONS\", options) =>\n+              options.map {\n+                case Token(\"TOK_TABLEOPTION\", keysAndValue) =>\n+                  val key = keysAndValue.init.map {\n+                    case Token(k, Nil) => k\n+                  }.mkString(\".\")\n+                  val value = unquoteString(keysAndValue.last.text)\n+                  (key, unquoteString(value))\n+              }.asInstanceOf[Seq[(String, String)]].toMap"
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Unquoting twice?\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-27T17:46:30Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, Nil) :: Token(tableName, Nil) :: Nil) =>\n+            new TableIdentifier(cleanIdentifier(tableName), Some(cleanIdentifier(dbName)))\n+          case Token(\"TOK_TABNAME\", Token(tableName, Nil) :: Nil) =>\n+            TableIdentifier(cleanIdentifier(tableName))\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = providerNameParts.map {\n+          case Token(name, Nil) => name\n+        }.mkString(\".\")\n+\n+        val options = tableOpts.map { opts =>\n+          opts match {\n+            case Token(\"TOK_TABLEOPTIONS\", options) =>\n+              options.map {\n+                case Token(\"TOK_TABLEOPTION\", keysAndValue) =>\n+                  val key = keysAndValue.init.map {\n+                    case Token(k, Nil) => k\n+                  }.mkString(\".\")\n+                  val value = unquoteString(keysAndValue.last.text)\n+                  (key, unquoteString(value))"
  }],
  "prId": 10723
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Nit: You could also turn the option into a sequence, flatMap over it, and create the Map as a result:\n\n```\nval options = tableOpts.toSeq.flatMap {\n  case Token(\"TOK_TABLEOPTIONS\", options) =>\n    options.map {\n      case Token(\"TOK_TABLEOPTION\", keysAndValue) =>\n        val key = keysAndValue.init.map.(_.text).mkString(\".\")\n        val value = unquoteString(keysAndValue.last.text)\n        key -> value\n    }\n}.toMap\n```\n\n(note: code is not tested)\n",
    "commit": "8b7086e85c10d537cd21e926d9129f9edf853445",
    "createdAt": "2016-01-27T17:48:53Z",
    "diffHunk": "@@ -42,6 +45,95 @@ private[sql] class SparkQl(conf: ParserConf = SimpleParserConf()) extends Cataly\n           getClauses(Seq(\"TOK_QUERY\", \"FORMATTED\", \"EXTENDED\"), explainArgs)\n         ExplainCommand(nodeToPlan(query), extended = extended.isDefined)\n \n+      case Token(\"TOK_REFRESHTABLE\", nameParts :: Nil) =>\n+        val tableIdent = extractTableIdent(nameParts)\n+        RefreshTable(tableIdent)\n+\n+      case Token(\"TOK_CREATETABLEUSING\", createTableArgs) =>\n+        val Seq(\n+          temp,\n+          allowExisting,\n+          Some(tabName),\n+          tableCols,\n+          Some(Token(\"TOK_TABLEPROVIDER\", providerNameParts)),\n+          tableOpts,\n+          tableAs) = getClauses(Seq(\n+          \"TEMPORARY\",\n+          \"TOK_IFNOTEXISTS\",\n+          \"TOK_TABNAME\", \"TOK_TABCOLLIST\",\n+          \"TOK_TABLEPROVIDER\",\n+          \"TOK_TABLEOPTIONS\",\n+          \"TOK_QUERY\"), createTableArgs)\n+\n+        val tableIdent: TableIdentifier = tabName match {\n+          case Token(\"TOK_TABNAME\", Token(dbName, Nil) :: Token(tableName, Nil) :: Nil) =>\n+            new TableIdentifier(cleanIdentifier(tableName), Some(cleanIdentifier(dbName)))\n+          case Token(\"TOK_TABNAME\", Token(tableName, Nil) :: Nil) =>\n+            TableIdentifier(cleanIdentifier(tableName))\n+        }\n+\n+        val columns = tableCols.map {\n+          case Token(\"TOK_TABCOLLIST\", fields) => StructType(fields.map(nodeToStructField))\n+        }\n+\n+        val provider = providerNameParts.map {\n+          case Token(name, Nil) => name\n+        }.mkString(\".\")\n+\n+        val options = tableOpts.map { opts =>"
  }],
  "prId": 10723
}]