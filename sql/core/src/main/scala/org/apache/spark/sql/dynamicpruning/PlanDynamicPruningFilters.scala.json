[{
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Move this into line 74?",
    "commit": "06ec1198acd5dcd39f8c1ea4e1ae94d99b345618",
    "createdAt": "2019-11-29T01:08:47Z",
    "diffHunk": "@@ -55,22 +55,24 @@ case class PlanDynamicPruningFilters(sparkSession: SparkSession)\n     plan transformAllExpressions {\n       case DynamicPruningSubquery(\n           value, buildPlan, buildKeys, broadcastKeyIndex, onlyInBroadcast, exprId) =>\n-        val qe = new QueryExecution(sparkSession, buildPlan)\n+        val sparkPlan = QueryExecution.createSparkPlan(\n+          sparkSession, sparkSession.sessionState.planner, buildPlan)\n         // Using `sparkPlan` is a little hacky as it is based on the assumption that this rule is\n         // the first to be applied (apart from `InsertAdaptiveSparkPlan`).\n         val canReuseExchange = reuseBroadcast && buildKeys.nonEmpty &&\n           plan.find {\n             case BroadcastHashJoinExec(_, _, _, BuildLeft, _, left, _) =>\n-              left.sameResult(qe.sparkPlan)\n+              left.sameResult(sparkPlan)\n             case BroadcastHashJoinExec(_, _, _, BuildRight, _, _, right) =>\n-              right.sameResult(qe.sparkPlan)\n+              right.sameResult(sparkPlan)\n             case _ => false\n           }.isDefined\n \n+        val executedPlan = QueryExecution.planSubquery(sparkSession, sparkPlan)"
  }],
  "prId": 26705
}]