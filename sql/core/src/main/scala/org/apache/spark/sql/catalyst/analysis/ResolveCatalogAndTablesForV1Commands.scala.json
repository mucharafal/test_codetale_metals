[{
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "Looks like this will prevent all v2 tables from from working with the session catalog because the `V2SessionCatalog` currently always returns a `V1Table`. Is this the plan, at least until we get `TableProvider` fixed?",
    "commit": "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "createdAt": "2019-09-25T19:15:52Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.plans.logical.sql.{AlterTableAddColumnsStatement, AlterTableAlterColumnStatement, AlterTableDropColumnsStatement, AlterTableRenameColumnStatement, AlterTableSetLocationStatement, AlterTableSetPropertiesStatement, AlterTableUnsetPropertiesStatement, AlterViewSetPropertiesStatement, AlterViewUnsetPropertiesStatement, DeleteFromStatement, DescribeColumnStatement, DescribeTableStatement, QualifiedColType}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.connector.catalog.{CatalogManager, LookupCatalog, V1Table}\n+import org.apache.spark.sql.execution.command.{AlterTableAddColumnsCommand, AlterTableSetLocationCommand, AlterTableSetPropertiesCommand, AlterTableUnsetPropertiesCommand, DescribeColumnCommand, DescribeTableCommand}\n+import org.apache.spark.sql.types.{HIVE_TYPE_STRING, HiveStringType, MetadataBuilder, StructField}\n+\n+/**\n+ * Resolves catalogs and tables from the multi-part identifiers in SQL statements, and convert the\n+ * statements to the corresponding v1 commands if the resolved table is a [[V1Table]].\n+ *\n+ * We can remove this rule once we implement all the catalog functionality in `V2SessionCatalog`.\n+ */\n+class ResolveCatalogAndTablesForV1Commands(\n+    val catalogManager: CatalogManager, isTempView: Seq[String] => Boolean)\n+  extends Rule[LogicalPlan] with LookupCatalog {\n+  import org.apache.spark.sql.connector.catalog.CatalogV2Implicits._\n+\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan.resolveOperatorsUp {\n+    case AlterTableAddColumnsStatement(\n+         CatalogAndTable(catalog, tblName, _: V1Table), cols) =>"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "This is the existing behavior. The session catalog only contains v1 tables which don't support ALTER TABLE. After `TableProvider` is fixed in https://github.com/apache/spark/pull/25651 , then session catalog can return v2 tables if the provider is v2.",
    "commit": "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "createdAt": "2019-09-26T01:45:31Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.plans.logical.sql.{AlterTableAddColumnsStatement, AlterTableAlterColumnStatement, AlterTableDropColumnsStatement, AlterTableRenameColumnStatement, AlterTableSetLocationStatement, AlterTableSetPropertiesStatement, AlterTableUnsetPropertiesStatement, AlterViewSetPropertiesStatement, AlterViewUnsetPropertiesStatement, DeleteFromStatement, DescribeColumnStatement, DescribeTableStatement, QualifiedColType}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.connector.catalog.{CatalogManager, LookupCatalog, V1Table}\n+import org.apache.spark.sql.execution.command.{AlterTableAddColumnsCommand, AlterTableSetLocationCommand, AlterTableSetPropertiesCommand, AlterTableUnsetPropertiesCommand, DescribeColumnCommand, DescribeTableCommand}\n+import org.apache.spark.sql.types.{HIVE_TYPE_STRING, HiveStringType, MetadataBuilder, StructField}\n+\n+/**\n+ * Resolves catalogs and tables from the multi-part identifiers in SQL statements, and convert the\n+ * statements to the corresponding v1 commands if the resolved table is a [[V1Table]].\n+ *\n+ * We can remove this rule once we implement all the catalog functionality in `V2SessionCatalog`.\n+ */\n+class ResolveCatalogAndTablesForV1Commands(\n+    val catalogManager: CatalogManager, isTempView: Seq[String] => Boolean)\n+  extends Rule[LogicalPlan] with LookupCatalog {\n+  import org.apache.spark.sql.connector.catalog.CatalogV2Implicits._\n+\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan.resolveOperatorsUp {\n+    case AlterTableAddColumnsStatement(\n+         CatalogAndTable(catalog, tblName, _: V1Table), cols) =>"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "How does the session catalog only contain v1 tables? V2 providers were supported in previous versions and there could be v2 tables in the session catalog that are loaded as V1Table.",
    "commit": "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "createdAt": "2019-09-26T21:57:39Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.plans.logical.sql.{AlterTableAddColumnsStatement, AlterTableAlterColumnStatement, AlterTableDropColumnsStatement, AlterTableRenameColumnStatement, AlterTableSetLocationStatement, AlterTableSetPropertiesStatement, AlterTableUnsetPropertiesStatement, AlterViewSetPropertiesStatement, AlterViewUnsetPropertiesStatement, DeleteFromStatement, DescribeColumnStatement, DescribeTableStatement, QualifiedColType}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.connector.catalog.{CatalogManager, LookupCatalog, V1Table}\n+import org.apache.spark.sql.execution.command.{AlterTableAddColumnsCommand, AlterTableSetLocationCommand, AlterTableSetPropertiesCommand, AlterTableUnsetPropertiesCommand, DescribeColumnCommand, DescribeTableCommand}\n+import org.apache.spark.sql.types.{HIVE_TYPE_STRING, HiveStringType, MetadataBuilder, StructField}\n+\n+/**\n+ * Resolves catalogs and tables from the multi-part identifiers in SQL statements, and convert the\n+ * statements to the corresponding v1 commands if the resolved table is a [[V1Table]].\n+ *\n+ * We can remove this rule once we implement all the catalog functionality in `V2SessionCatalog`.\n+ */\n+class ResolveCatalogAndTablesForV1Commands(\n+    val catalogManager: CatalogManager, isTempView: Seq[String] => Boolean)\n+  extends Rule[LogicalPlan] with LookupCatalog {\n+  import org.apache.spark.sql.connector.catalog.CatalogV2Implicits._\n+\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan.resolveOperatorsUp {\n+    case AlterTableAddColumnsStatement(\n+         CatalogAndTable(catalog, tblName, _: V1Table), cols) =>"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "Sorry I didn't make it clear. Yes session catalog may contain v2 tables as we can create table with v2 provider. However, session catalog never return v2 tables. So all the v2 commands that need to resolve tables never work for v2 tables in session catalog.\r\n\r\nThis is the existing behavior. If you take a look at `ResolveAlterTable`, it calls `lookupV2RelationAndCatalog` which ignores `V1Table`.\r\n\r\nThe code here is future-proof. Once #25651 is merged, we will create v2 commands for v2 tables in session catalog without any changes.",
    "commit": "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "createdAt": "2019-09-27T02:05:52Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.plans.logical.sql.{AlterTableAddColumnsStatement, AlterTableAlterColumnStatement, AlterTableDropColumnsStatement, AlterTableRenameColumnStatement, AlterTableSetLocationStatement, AlterTableSetPropertiesStatement, AlterTableUnsetPropertiesStatement, AlterViewSetPropertiesStatement, AlterViewUnsetPropertiesStatement, DeleteFromStatement, DescribeColumnStatement, DescribeTableStatement, QualifiedColType}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.connector.catalog.{CatalogManager, LookupCatalog, V1Table}\n+import org.apache.spark.sql.execution.command.{AlterTableAddColumnsCommand, AlterTableSetLocationCommand, AlterTableSetPropertiesCommand, AlterTableUnsetPropertiesCommand, DescribeColumnCommand, DescribeTableCommand}\n+import org.apache.spark.sql.types.{HIVE_TYPE_STRING, HiveStringType, MetadataBuilder, StructField}\n+\n+/**\n+ * Resolves catalogs and tables from the multi-part identifiers in SQL statements, and convert the\n+ * statements to the corresponding v1 commands if the resolved table is a [[V1Table]].\n+ *\n+ * We can remove this rule once we implement all the catalog functionality in `V2SessionCatalog`.\n+ */\n+class ResolveCatalogAndTablesForV1Commands(\n+    val catalogManager: CatalogManager, isTempView: Seq[String] => Boolean)\n+  extends Rule[LogicalPlan] with LookupCatalog {\n+  import org.apache.spark.sql.connector.catalog.CatalogV2Implicits._\n+\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan.resolveOperatorsUp {\n+    case AlterTableAddColumnsStatement(\n+         CatalogAndTable(catalog, tblName, _: V1Table), cols) =>"
  }],
  "prId": 25747
}]