[{
  "comments": [{
    "author": {
      "login": "albertusk95"
    },
    "body": "it seems that based on my experience, aliasing the dataset before joining still results in an `ambiguous reference exception` when a certain column is selected. For instance, `joined_df = df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")` and then `joined_df.select('certain_column')` gave an exception.\r\n\r\nProviding the alias name didn't help as well -> `joined_df.select(a.certain_column)`.\r\n\r\nHowever, by deep copying the dataframes gave the correct result.",
    "commit": "62228e8ffbb5d54ad2ec5a85dd2450cd1dec5ae2",
    "createdAt": "2019-07-20T08:45:57Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.analysis\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.{AnalysisException, Column, Dataset}\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, Cast, Equality, Expression, ExprId}\n+import org.apache.spark.sql.catalyst.plans.logical.{Join, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Detects ambiguous self-joins, so that we can fail the query instead of returning confusing\n+ * results.\n+ *\n+ * Dataset column reference is simply an [[AttributeReference]] that is returned by `Dataset#col`.\n+ * Most of time we don't need to do anything special, as [[AttributeReference]] can point to\n+ * the column precisely. However, in case of self-join, the analyzer generates\n+ * [[AttributeReference]] with new expr IDs for the right side plan of the join. If the Dataset\n+ * column reference points to a column in the right side plan of a self-join, users will get\n+ * unexpected result because the column reference can't match the newly generated\n+ * [[AttributeReference]].\n+ */\n+class DetectAmbiguousSelfJoin(conf: SQLConf) extends Rule[LogicalPlan] {\n+\n+  // Dataset column reference is an `AttributeReference` with 2 special metadata.\n+  private def isColumnReference(a: AttributeReference): Boolean = {\n+    a.metadata.contains(Dataset.ID_PREFIX) && a.metadata.contains(Dataset.COL_POS_PREFIX)\n+  }\n+\n+  private case class ColumnReference(datasetId: Long, colPos: Int, exprId: ExprId)\n+\n+  private def toColumnReference(a: AttributeReference): ColumnReference = {\n+    ColumnReference(\n+      a.metadata.getLong(Dataset.ID_PREFIX),\n+      a.metadata.getLong(Dataset.COL_POS_PREFIX).toInt,\n+      a.exprId)\n+  }\n+\n+  object LogicalPlanWithDatasetId {\n+    def unapply(p: LogicalPlan): Option[(LogicalPlan, Long)] = {\n+      p.getTagValue(Dataset.DATASET_ID_TAG).map(id => p -> id)\n+    }\n+  }\n+\n+  object AttrWithCast {\n+    def unapply(expr: Expression): Option[AttributeReference] = expr match {\n+      case Cast(child, _, _) => unapply(child)\n+      case a: AttributeReference => Some(a)\n+      case _ => None\n+    }\n+  }\n+\n+  override def apply(plan: LogicalPlan): LogicalPlan = {\n+    if (!conf.getConf(SQLConf.FAIL_AMBIGUOUS_SELF_JOIN)) return plan\n+\n+    // We always remove the special metadata from `AttributeReference` at the end of this rule, so\n+    // Dataset column reference only exists in the root node via Dataset transformations like\n+    // `Dataset#select`.\n+    val colRefAttrs = plan.expressions.flatMap(_.collect {\n+      case a: AttributeReference if isColumnReference(a) => a\n+    })\n+\n+    if (colRefAttrs.nonEmpty) {\n+      val colRefs = colRefAttrs.map(toColumnReference).distinct\n+      val ambiguousColRefs = mutable.HashSet.empty[ColumnReference]\n+      val dsIdSet = colRefs.map(_.datasetId).toSet\n+\n+      plan.foreach {\n+        case LogicalPlanWithDatasetId(p, id) if dsIdSet.contains(id) =>\n+          colRefs.foreach { ref =>\n+            if (id == ref.datasetId) {\n+              if (ref.colPos < 0 || ref.colPos >= p.output.length) {\n+                throw new IllegalStateException(\"[BUG] Hit an invalid Dataset column reference: \" +\n+                  s\"$ref. Please open a JIRA ticket to report it.\")\n+              } else {\n+                // When self-join happens, the analyzer asks the right side plan to generate\n+                // attributes with new exprIds. If a plan of a Dataset outputs an attribute which\n+                // is referred by a column reference, and this attribute has different exprId than\n+                // the attribute of column reference, then the column reference is ambiguous, as it\n+                // refers to a column that gets regenerated by self-join.\n+                val actualAttr = p.output(ref.colPos).asInstanceOf[AttributeReference]\n+                if (actualAttr.exprId != ref.exprId) {\n+                  ambiguousColRefs += ref\n+                }\n+              }\n+            }\n+          }\n+\n+        case _ =>\n+      }\n+\n+      val ambiguousAttrs: Seq[AttributeReference] = plan match {\n+        case Join(\n+            LogicalPlanWithDatasetId(_, leftId),\n+            LogicalPlanWithDatasetId(_, rightId),\n+            _, condition, _) =>\n+          // If we are dealing with root join node, we need to take care of SPARK-6231:\n+          //  1. We can de-ambiguous `df(\"col\") === df(\"col\")` in the join condition.\n+          //  2. There is no ambiguity in direct self join like\n+          //     `df.join(df, df(\"col\") === 1)`, because it doesn't matter which side the\n+          //     column comes from.\n+          def getAmbiguousAttrs(expr: Expression): Seq[AttributeReference] = expr match {\n+            case Equality(AttrWithCast(a), AttrWithCast(b)) if a.sameRef(b) =>\n+              Nil\n+            case Equality(AttrWithCast(a), b) if leftId == rightId && b.foldable =>\n+              Nil\n+            case Equality(a, AttrWithCast(b)) if leftId == rightId && a.foldable =>\n+              Nil\n+            case a: AttributeReference =>\n+              if (isColumnReference(a)) {\n+                val colRef = toColumnReference(a)\n+                if (ambiguousColRefs.contains(colRef)) Seq(a) else Nil\n+              } else {\n+                Nil\n+              }\n+            case _ => expr.children.flatMap(getAmbiguousAttrs)\n+          }\n+          condition.toSeq.flatMap(getAmbiguousAttrs)\n+\n+        case _ => ambiguousColRefs.toSeq.map { ref =>\n+          colRefAttrs.find(attr => toColumnReference(attr) == ref).get\n+        }\n+      }\n+\n+      if (ambiguousAttrs.nonEmpty) {\n+        throw new AnalysisException(s\"Column ${ambiguousAttrs.mkString(\", \")} are ambiguous. \" +\n+          \"It's probably because you joined several Datasets together, and some of these \" +\n+          \"Datasets are the same. This column points to one of the Datasets but Spark is unable \" +\n+          \"to figure out which one. Please alias the Datasets with different names via \" +\n+          \"`Dataset.as` before joining them, and specify the column using qualified name, e.g. \" +\n+          \"\"\"`df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set \"\"\" +\n+          s\"${SQLConf.FAIL_AMBIGUOUS_SELF_JOIN} to false to disable this check.\")"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "Can you give a concrete example? It looks to me that `joined_df.select($\"a.certain_column\")` should work.",
    "commit": "62228e8ffbb5d54ad2ec5a85dd2450cd1dec5ae2",
    "createdAt": "2019-07-24T04:41:34Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.analysis\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.{AnalysisException, Column, Dataset}\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, Cast, Equality, Expression, ExprId}\n+import org.apache.spark.sql.catalyst.plans.logical.{Join, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Detects ambiguous self-joins, so that we can fail the query instead of returning confusing\n+ * results.\n+ *\n+ * Dataset column reference is simply an [[AttributeReference]] that is returned by `Dataset#col`.\n+ * Most of time we don't need to do anything special, as [[AttributeReference]] can point to\n+ * the column precisely. However, in case of self-join, the analyzer generates\n+ * [[AttributeReference]] with new expr IDs for the right side plan of the join. If the Dataset\n+ * column reference points to a column in the right side plan of a self-join, users will get\n+ * unexpected result because the column reference can't match the newly generated\n+ * [[AttributeReference]].\n+ */\n+class DetectAmbiguousSelfJoin(conf: SQLConf) extends Rule[LogicalPlan] {\n+\n+  // Dataset column reference is an `AttributeReference` with 2 special metadata.\n+  private def isColumnReference(a: AttributeReference): Boolean = {\n+    a.metadata.contains(Dataset.ID_PREFIX) && a.metadata.contains(Dataset.COL_POS_PREFIX)\n+  }\n+\n+  private case class ColumnReference(datasetId: Long, colPos: Int, exprId: ExprId)\n+\n+  private def toColumnReference(a: AttributeReference): ColumnReference = {\n+    ColumnReference(\n+      a.metadata.getLong(Dataset.ID_PREFIX),\n+      a.metadata.getLong(Dataset.COL_POS_PREFIX).toInt,\n+      a.exprId)\n+  }\n+\n+  object LogicalPlanWithDatasetId {\n+    def unapply(p: LogicalPlan): Option[(LogicalPlan, Long)] = {\n+      p.getTagValue(Dataset.DATASET_ID_TAG).map(id => p -> id)\n+    }\n+  }\n+\n+  object AttrWithCast {\n+    def unapply(expr: Expression): Option[AttributeReference] = expr match {\n+      case Cast(child, _, _) => unapply(child)\n+      case a: AttributeReference => Some(a)\n+      case _ => None\n+    }\n+  }\n+\n+  override def apply(plan: LogicalPlan): LogicalPlan = {\n+    if (!conf.getConf(SQLConf.FAIL_AMBIGUOUS_SELF_JOIN)) return plan\n+\n+    // We always remove the special metadata from `AttributeReference` at the end of this rule, so\n+    // Dataset column reference only exists in the root node via Dataset transformations like\n+    // `Dataset#select`.\n+    val colRefAttrs = plan.expressions.flatMap(_.collect {\n+      case a: AttributeReference if isColumnReference(a) => a\n+    })\n+\n+    if (colRefAttrs.nonEmpty) {\n+      val colRefs = colRefAttrs.map(toColumnReference).distinct\n+      val ambiguousColRefs = mutable.HashSet.empty[ColumnReference]\n+      val dsIdSet = colRefs.map(_.datasetId).toSet\n+\n+      plan.foreach {\n+        case LogicalPlanWithDatasetId(p, id) if dsIdSet.contains(id) =>\n+          colRefs.foreach { ref =>\n+            if (id == ref.datasetId) {\n+              if (ref.colPos < 0 || ref.colPos >= p.output.length) {\n+                throw new IllegalStateException(\"[BUG] Hit an invalid Dataset column reference: \" +\n+                  s\"$ref. Please open a JIRA ticket to report it.\")\n+              } else {\n+                // When self-join happens, the analyzer asks the right side plan to generate\n+                // attributes with new exprIds. If a plan of a Dataset outputs an attribute which\n+                // is referred by a column reference, and this attribute has different exprId than\n+                // the attribute of column reference, then the column reference is ambiguous, as it\n+                // refers to a column that gets regenerated by self-join.\n+                val actualAttr = p.output(ref.colPos).asInstanceOf[AttributeReference]\n+                if (actualAttr.exprId != ref.exprId) {\n+                  ambiguousColRefs += ref\n+                }\n+              }\n+            }\n+          }\n+\n+        case _ =>\n+      }\n+\n+      val ambiguousAttrs: Seq[AttributeReference] = plan match {\n+        case Join(\n+            LogicalPlanWithDatasetId(_, leftId),\n+            LogicalPlanWithDatasetId(_, rightId),\n+            _, condition, _) =>\n+          // If we are dealing with root join node, we need to take care of SPARK-6231:\n+          //  1. We can de-ambiguous `df(\"col\") === df(\"col\")` in the join condition.\n+          //  2. There is no ambiguity in direct self join like\n+          //     `df.join(df, df(\"col\") === 1)`, because it doesn't matter which side the\n+          //     column comes from.\n+          def getAmbiguousAttrs(expr: Expression): Seq[AttributeReference] = expr match {\n+            case Equality(AttrWithCast(a), AttrWithCast(b)) if a.sameRef(b) =>\n+              Nil\n+            case Equality(AttrWithCast(a), b) if leftId == rightId && b.foldable =>\n+              Nil\n+            case Equality(a, AttrWithCast(b)) if leftId == rightId && a.foldable =>\n+              Nil\n+            case a: AttributeReference =>\n+              if (isColumnReference(a)) {\n+                val colRef = toColumnReference(a)\n+                if (ambiguousColRefs.contains(colRef)) Seq(a) else Nil\n+              } else {\n+                Nil\n+              }\n+            case _ => expr.children.flatMap(getAmbiguousAttrs)\n+          }\n+          condition.toSeq.flatMap(getAmbiguousAttrs)\n+\n+        case _ => ambiguousColRefs.toSeq.map { ref =>\n+          colRefAttrs.find(attr => toColumnReference(attr) == ref).get\n+        }\n+      }\n+\n+      if (ambiguousAttrs.nonEmpty) {\n+        throw new AnalysisException(s\"Column ${ambiguousAttrs.mkString(\", \")} are ambiguous. \" +\n+          \"It's probably because you joined several Datasets together, and some of these \" +\n+          \"Datasets are the same. This column points to one of the Datasets but Spark is unable \" +\n+          \"to figure out which one. Please alias the Datasets with different names via \" +\n+          \"`Dataset.as` before joining them, and specify the column using qualified name, e.g. \" +\n+          \"\"\"`df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set \"\"\" +\n+          s\"${SQLConf.FAIL_AMBIGUOUS_SELF_JOIN} to false to disable this check.\")"
  }],
  "prId": 25107
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "In the description, we need to also document the metadata are removed by this rule. ",
    "commit": "62228e8ffbb5d54ad2ec5a85dd2450cd1dec5ae2",
    "createdAt": "2019-08-04T07:42:17Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.analysis\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.sql.{AnalysisException, Column, Dataset}\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, Cast, Equality, Expression, ExprId}\n+import org.apache.spark.sql.catalyst.plans.logical.{Join, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Detects ambiguous self-joins, so that we can fail the query instead of returning confusing\n+ * results.\n+ *\n+ * Dataset column reference is simply an [[AttributeReference]] that is returned by `Dataset#col`.\n+ * Most of time we don't need to do anything special, as [[AttributeReference]] can point to\n+ * the column precisely. However, in case of self-join, the analyzer generates\n+ * [[AttributeReference]] with new expr IDs for the right side plan of the join. If the Dataset\n+ * column reference points to a column in the right side plan of a self-join, users will get\n+ * unexpected result because the column reference can't match the newly generated\n+ * [[AttributeReference]].",
    "line": 38
  }],
  "prId": 25107
}]