[{
  "comments": [{
    "author": {
      "login": "icexelloss"
    },
    "body": "Some of these comments are removed after the refactor. Is it accidental or is it because those don't apply any more?",
    "commit": "1b966fda46c5334cf7963bae0bece159c9568622",
    "createdAt": "2019-08-07T19:08:26Z",
    "diffHunk": "@@ -75,88 +71,23 @@ case class FlatMapGroupsInPandasExec(\n   override protected def doExecute(): RDD[InternalRow] = {\n     val inputRDD = child.execute()\n \n-    val chainedFunc = Seq(ChainedPythonFunctions(Seq(pandasFunction)))\n-    val sessionLocalTimeZone = conf.sessionLocalTimeZone\n-    val pythonRunnerConf = ArrowUtils.getPythonRunnerConfMap(conf)\n-\n-    // Deduplicate the grouping attributes.\n-    // If a grouping attribute also appears in data attributes, then we don't need to send the\n-    // grouping attribute to Python worker. If a grouping attribute is not in data attributes,\n-    // then we need to send this grouping attribute to python worker.\n-    //\n-    // We use argOffsets to distinguish grouping attributes and data attributes as following:\n-    //\n-    // argOffsets[0] is the length of grouping attributes\n-    // argOffsets[1 .. argOffsets[0]+1] is the arg offsets for grouping attributes\n-    // argOffsets[argOffsets[0]+1 .. ] is the arg offsets for data attributes\n-\n-    val dataAttributes = child.output.drop(groupingAttributes.length)\n-    val groupingIndicesInData = groupingAttributes.map { attribute =>\n-      dataAttributes.indexWhere(attribute.semanticEquals)\n-    }\n-\n-    val groupingArgOffsets = new ArrayBuffer[Int]\n-    val nonDupGroupingAttributes = new ArrayBuffer[Attribute]\n-    val nonDupGroupingSize = groupingIndicesInData.count(_ == -1)\n-\n-    // Non duplicate grouping attributes are added to nonDupGroupingAttributes and",
    "line": 67
  }, {
    "author": {
      "login": "d80tb7"
    },
    "body": "So the comments are definitely still needed as the mechanism is essentially the same and this is somewhat complex.  These comments have moved to BasePandasGroupExec.resolveArgOffsets- the wording has changed slightly but I think all the same information is there.  If you think anything is missing or not clear please let me know and I'll be happy to amend.",
    "commit": "1b966fda46c5334cf7963bae0bece159c9568622",
    "createdAt": "2019-08-20T15:36:21Z",
    "diffHunk": "@@ -75,88 +71,23 @@ case class FlatMapGroupsInPandasExec(\n   override protected def doExecute(): RDD[InternalRow] = {\n     val inputRDD = child.execute()\n \n-    val chainedFunc = Seq(ChainedPythonFunctions(Seq(pandasFunction)))\n-    val sessionLocalTimeZone = conf.sessionLocalTimeZone\n-    val pythonRunnerConf = ArrowUtils.getPythonRunnerConfMap(conf)\n-\n-    // Deduplicate the grouping attributes.\n-    // If a grouping attribute also appears in data attributes, then we don't need to send the\n-    // grouping attribute to Python worker. If a grouping attribute is not in data attributes,\n-    // then we need to send this grouping attribute to python worker.\n-    //\n-    // We use argOffsets to distinguish grouping attributes and data attributes as following:\n-    //\n-    // argOffsets[0] is the length of grouping attributes\n-    // argOffsets[1 .. argOffsets[0]+1] is the arg offsets for grouping attributes\n-    // argOffsets[argOffsets[0]+1 .. ] is the arg offsets for data attributes\n-\n-    val dataAttributes = child.output.drop(groupingAttributes.length)\n-    val groupingIndicesInData = groupingAttributes.map { attribute =>\n-      dataAttributes.indexWhere(attribute.semanticEquals)\n-    }\n-\n-    val groupingArgOffsets = new ArrayBuffer[Int]\n-    val nonDupGroupingAttributes = new ArrayBuffer[Attribute]\n-    val nonDupGroupingSize = groupingIndicesInData.count(_ == -1)\n-\n-    // Non duplicate grouping attributes are added to nonDupGroupingAttributes and",
    "line": 67
  }],
  "prId": 24981
}, {
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "nit: remove an extra space between `extends` and `BasePandasGroupExec`.",
    "commit": "1b966fda46c5334cf7963bae0bece159c9568622",
    "createdAt": "2019-08-27T20:41:03Z",
    "diffHunk": "@@ -53,14 +53,10 @@ case class FlatMapGroupsInPandasExec(\n     func: Expression,\n     output: Seq[Attribute],\n     child: SparkPlan)\n-  extends UnaryExecNode {\n-\n-  private val pandasFunction = func.asInstanceOf[PythonUDF].func\n+  extends  BasePandasGroupExec(func, output) with UnaryExecNode {"
  }],
  "prId": 24981
}, {
  "comments": [{
    "author": {
      "login": "BryanCutler"
    },
    "body": "I think you need to remove unused imports here as well",
    "commit": "1b966fda46c5334cf7963bae0bece159c9568622",
    "createdAt": "2019-08-29T20:39:18Z",
    "diffHunk": "@@ -75,88 +71,23 @@ case class FlatMapGroupsInPandasExec(\n   override protected def doExecute(): RDD[InternalRow] = {\n     val inputRDD = child.execute()\n \n-    val chainedFunc = Seq(ChainedPythonFunctions(Seq(pandasFunction)))\n-    val sessionLocalTimeZone = conf.sessionLocalTimeZone\n-    val pythonRunnerConf = ArrowUtils.getPythonRunnerConfMap(conf)\n-\n-    // Deduplicate the grouping attributes.\n-    // If a grouping attribute also appears in data attributes, then we don't need to send the\n-    // grouping attribute to Python worker. If a grouping attribute is not in data attributes,\n-    // then we need to send this grouping attribute to python worker.\n-    //\n-    // We use argOffsets to distinguish grouping attributes and data attributes as following:\n-    //\n-    // argOffsets[0] is the length of grouping attributes\n-    // argOffsets[1 .. argOffsets[0]+1] is the arg offsets for grouping attributes\n-    // argOffsets[argOffsets[0]+1 .. ] is the arg offsets for data attributes\n-\n-    val dataAttributes = child.output.drop(groupingAttributes.length)\n-    val groupingIndicesInData = groupingAttributes.map { attribute =>\n-      dataAttributes.indexWhere(attribute.semanticEquals)\n-    }\n-\n-    val groupingArgOffsets = new ArrayBuffer[Int]\n-    val nonDupGroupingAttributes = new ArrayBuffer[Attribute]\n-    val nonDupGroupingSize = groupingIndicesInData.count(_ == -1)\n-\n-    // Non duplicate grouping attributes are added to nonDupGroupingAttributes and\n-    // their offsets are 0, 1, 2 ...\n-    // Duplicate grouping attributes are NOT added to nonDupGroupingAttributes and\n-    // their offsets are n + index, where n is the total number of non duplicate grouping\n-    // attributes and index is the index in the data attributes that the grouping attribute\n-    // is a duplicate of.\n-\n-    groupingAttributes.zip(groupingIndicesInData).foreach {\n-      case (attribute, index) =>\n-        if (index == -1) {\n-          groupingArgOffsets += nonDupGroupingAttributes.length\n-          nonDupGroupingAttributes += attribute\n-        } else {\n-          groupingArgOffsets += index + nonDupGroupingSize\n-        }\n-    }\n-\n-    val dataArgOffsets = nonDupGroupingAttributes.length until\n-      (nonDupGroupingAttributes.length + dataAttributes.length)\n-\n-    val argOffsets = Array(Array(groupingAttributes.length) ++ groupingArgOffsets ++ dataArgOffsets)\n-\n-    // Attributes after deduplication\n-    val dedupAttributes = nonDupGroupingAttributes ++ dataAttributes\n-    val dedupSchema = StructType.fromAttributes(dedupAttributes)\n+    val (dedupAttributes, argOffsets) = resolveArgOffsets(child, groupingAttributes)\n \n     // Map grouped rows to ArrowPythonRunner results, Only execute if partition is not empty\n     inputRDD.mapPartitionsInternal { iter => if (iter.isEmpty) iter else {\n-      val grouped = if (groupingAttributes.isEmpty) {\n-        Iterator(iter)\n-      } else {\n-        val groupedIter = GroupedIterator(iter, groupingAttributes, child.output)",
    "line": 99
  }],
  "prId": 24981
}]