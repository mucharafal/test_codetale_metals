[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "double n",
    "commit": "52923296a946ac734c988fe10725921ea3c2b313",
    "createdAt": "2017-12-08T02:43:49Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.regex.Pattern\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.immutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.sources.v2.ConfigSupport\n+\n+private[sql] object DataSourceV2ConfigSupport extends Logging {\n+\n+  /**\n+   * Helper method to propagate session configs with config key that matches at least one of the\n+   * given prefixes to the corresponding data source options.\n+   *\n+   * @param cs the session config propagate help class\n+   * @param source the data source format\n+   * @param conf the session conf\n+   * @return an immutable map that contains all the session configs that should be propagated to\n+   *         the data source.\n+   */\n+  def withSessionConfig(\n+      cs: ConfigSupport,\n+      source: String,\n+      conf: SQLConf): immutable.Map[String, String] = {\n+    val prefixes = cs.getConfigPrefixes\n+    require(prefixes != null, \"The config key-prefixes cann't be null.\")"
  }],
  "prId": 19861
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "double n",
    "commit": "52923296a946ac734c988fe10725921ea3c2b313",
    "createdAt": "2017-12-08T02:43:57Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.regex.Pattern\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.immutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.sources.v2.ConfigSupport\n+\n+private[sql] object DataSourceV2ConfigSupport extends Logging {\n+\n+  /**\n+   * Helper method to propagate session configs with config key that matches at least one of the\n+   * given prefixes to the corresponding data source options.\n+   *\n+   * @param cs the session config propagate help class\n+   * @param source the data source format\n+   * @param conf the session conf\n+   * @return an immutable map that contains all the session configs that should be propagated to\n+   *         the data source.\n+   */\n+  def withSessionConfig(\n+      cs: ConfigSupport,\n+      source: String,\n+      conf: SQLConf): immutable.Map[String, String] = {\n+    val prefixes = cs.getConfigPrefixes\n+    require(prefixes != null, \"The config key-prefixes cann't be null.\")\n+    val mapping = cs.getConfigMapping.asScala\n+    val validOptions = cs.getValidOptions\n+    require(validOptions != null, \"The valid options list cann't be null.\")"
  }],
  "prId": 19861
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "how about just naming it `Utils`? We may add more functions in it for other purpose in the future.",
    "commit": "52923296a946ac734c988fe10725921ea3c2b313",
    "createdAt": "2017-12-13T13:12:12Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.regex.Pattern\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.immutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.sources.v2.ConfigSupport\n+\n+private[sql] object DataSourceV2ConfigSupport extends Logging {"
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "How about rename it to `DataSourceV2Utils`, since the name `Utils` may conflict with `org.apache.spark.util.Utils`?",
    "commit": "52923296a946ac734c988fe10725921ea3c2b313",
    "createdAt": "2017-12-14T09:07:00Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.regex.Pattern\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.immutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.sources.v2.ConfigSupport\n+\n+private[sql] object DataSourceV2ConfigSupport extends Logging {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "yea good idea",
    "commit": "52923296a946ac734c988fe10725921ea3c2b313",
    "createdAt": "2017-12-14T11:38:22Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.regex.Pattern\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.immutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.sources.v2.ConfigSupport\n+\n+private[sql] object DataSourceV2ConfigSupport extends Logging {"
  }],
  "prId": 19861
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "in Scala `Map` by default refers to `immutable.Map`",
    "commit": "52923296a946ac734c988fe10725921ea3c2b313",
    "createdAt": "2017-12-13T13:13:02Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.regex.Pattern\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.immutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.sources.v2.ConfigSupport\n+\n+private[sql] object DataSourceV2ConfigSupport extends Logging {\n+\n+  /**\n+   * Helper method that turns session configs with config keys that start with\n+   * `spark.datasource.$name` into k/v pairs, the k/v pairs will be used to create data source\n+   * options.\n+   * A session config `spark.datasource.$name.xxx -> yyy` will be transformed into\n+   * `xxx -> yyy`.\n+   *\n+   * @param name the data source name\n+   * @param conf the session conf\n+   * @return an immutable map that contains all the extracted and transformed k/v pairs.\n+   */\n+  def withSessionConfig(\n+      name: String,\n+      conf: SQLConf): immutable.Map[String, String] = {"
  }],
  "prId": 19861
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "this can be a member variable to avoid re-compile it everytime.",
    "commit": "52923296a946ac734c988fe10725921ea3c2b313",
    "createdAt": "2017-12-13T13:13:37Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.regex.Pattern\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.immutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.sources.v2.ConfigSupport\n+\n+private[sql] object DataSourceV2ConfigSupport extends Logging {\n+\n+  /**\n+   * Helper method that turns session configs with config keys that start with\n+   * `spark.datasource.$name` into k/v pairs, the k/v pairs will be used to create data source\n+   * options.\n+   * A session config `spark.datasource.$name.xxx -> yyy` will be transformed into\n+   * `xxx -> yyy`.\n+   *\n+   * @param name the data source name\n+   * @param conf the session conf\n+   * @return an immutable map that contains all the extracted and transformed k/v pairs.\n+   */\n+  def withSessionConfig(\n+      name: String,\n+      conf: SQLConf): immutable.Map[String, String] = {\n+    require(name != null, \"The data source name can't be null.\")\n+\n+    val pattern = Pattern.compile(s\"spark\\\\.datasource\\\\.$name\\\\.(.*)\")"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit: s\"^spark...\" to make sure the matched string starts with `spark...`",
    "commit": "52923296a946ac734c988fe10725921ea3c2b313",
    "createdAt": "2017-12-13T13:15:28Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.regex.Pattern\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.immutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.sources.v2.ConfigSupport\n+\n+private[sql] object DataSourceV2ConfigSupport extends Logging {\n+\n+  /**\n+   * Helper method that turns session configs with config keys that start with\n+   * `spark.datasource.$name` into k/v pairs, the k/v pairs will be used to create data source\n+   * options.\n+   * A session config `spark.datasource.$name.xxx -> yyy` will be transformed into\n+   * `xxx -> yyy`.\n+   *\n+   * @param name the data source name\n+   * @param conf the session conf\n+   * @return an immutable map that contains all the extracted and transformed k/v pairs.\n+   */\n+  def withSessionConfig(\n+      name: String,\n+      conf: SQLConf): immutable.Map[String, String] = {\n+    require(name != null, \"The data source name can't be null.\")\n+\n+    val pattern = Pattern.compile(s\"spark\\\\.datasource\\\\.$name\\\\.(.*)\")"
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "The regex contains `$keyPrefix`, so we are not able to remove it from the method.",
    "commit": "52923296a946ac734c988fe10725921ea3c2b313",
    "createdAt": "2017-12-14T07:59:24Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.regex.Pattern\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.immutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.sources.v2.ConfigSupport\n+\n+private[sql] object DataSourceV2ConfigSupport extends Logging {\n+\n+  /**\n+   * Helper method that turns session configs with config keys that start with\n+   * `spark.datasource.$name` into k/v pairs, the k/v pairs will be used to create data source\n+   * options.\n+   * A session config `spark.datasource.$name.xxx -> yyy` will be transformed into\n+   * `xxx -> yyy`.\n+   *\n+   * @param name the data source name\n+   * @param conf the session conf\n+   * @return an immutable map that contains all the extracted and transformed k/v pairs.\n+   */\n+  def withSessionConfig(\n+      name: String,\n+      conf: SQLConf): immutable.Map[String, String] = {\n+    require(name != null, \"The data source name can't be null.\")\n+\n+    val pattern = Pattern.compile(s\"spark\\\\.datasource\\\\.$name\\\\.(.*)\")"
  }],
  "prId": 19861
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "can we use a `flatMap` to just loop the input once?",
    "commit": "52923296a946ac734c988fe10725921ea3c2b313",
    "createdAt": "2017-12-13T13:16:00Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.regex.Pattern\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.immutable\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.sources.v2.ConfigSupport\n+\n+private[sql] object DataSourceV2ConfigSupport extends Logging {\n+\n+  /**\n+   * Helper method that turns session configs with config keys that start with\n+   * `spark.datasource.$name` into k/v pairs, the k/v pairs will be used to create data source\n+   * options.\n+   * A session config `spark.datasource.$name.xxx -> yyy` will be transformed into\n+   * `xxx -> yyy`.\n+   *\n+   * @param name the data source name\n+   * @param conf the session conf\n+   * @return an immutable map that contains all the extracted and transformed k/v pairs.\n+   */\n+  def withSessionConfig(\n+      name: String,\n+      conf: SQLConf): immutable.Map[String, String] = {\n+    require(name != null, \"The data source name can't be null.\")\n+\n+    val pattern = Pattern.compile(s\"spark\\\\.datasource\\\\.$name\\\\.(.*)\")\n+    val filteredConfigs = conf.getAllConfs.filterKeys { confKey =>\n+      confKey.startsWith(s\"spark.datasource.$name\")\n+    }\n+    filteredConfigs.map { entry =>"
  }],
  "prId": 19861
}]