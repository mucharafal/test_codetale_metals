[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "sorry to come up with this at the last minute: can we create a `PhysicalWriteInfo` interface? In case we want to add more physical information in the future.",
    "commit": "f3dba5ea7823f593d4d75d933ffd2603ec75475f",
    "createdAt": "2019-11-15T02:34:42Z",
    "diffHunk": "@@ -36,8 +36,8 @@ class MicroBatchWrite(eppchId: Long, val writeSupport: StreamingWrite) extends B\n     writeSupport.abort(eppchId, messages)\n   }\n \n-  override def createBatchWriterFactory(): DataWriterFactory = {\n-    new MicroBatchWriterFactory(eppchId, writeSupport.createStreamingWriterFactory())\n+  override def createBatchWriterFactory(numPartitions: Int): DataWriterFactory = {",
    "line": 6
  }, {
    "author": {
      "login": "edrevo"
    },
    "body": "No problem! Since we still want to move forward with the interface-based approach, I've decided to evolve https://github.com/apache/spark/pull/25990/ to include both the `PhysicalWriteInfo` as well as `WriteInfo`",
    "commit": "f3dba5ea7823f593d4d75d933ffd2603ec75475f",
    "createdAt": "2019-11-15T07:25:40Z",
    "diffHunk": "@@ -36,8 +36,8 @@ class MicroBatchWrite(eppchId: Long, val writeSupport: StreamingWrite) extends B\n     writeSupport.abort(eppchId, messages)\n   }\n \n-  override def createBatchWriterFactory(): DataWriterFactory = {\n-    new MicroBatchWriterFactory(eppchId, writeSupport.createStreamingWriterFactory())\n+  override def createBatchWriterFactory(numPartitions: Int): DataWriterFactory = {",
    "line": 6
  }],
  "prId": 25945
}]