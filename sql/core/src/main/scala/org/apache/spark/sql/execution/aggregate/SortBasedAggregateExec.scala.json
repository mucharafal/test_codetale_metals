[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "hm I think createLongMetric makes more sense than createSumMetric here ...\n",
    "commit": "124568b3eeb7e0a657b2fbe4f54bb85543b7ffa3",
    "createdAt": "2016-04-28T04:01:12Z",
    "diffHunk": "@@ -46,7 +46,7 @@ case class SortBasedAggregateExec(\n       AttributeSet(aggregateBufferAttributes)\n \n   override private[sql] lazy val metrics = Map(\n-    \"numOutputRows\" -> SQLMetrics.createLongMetric(sparkContext, \"number of output rows\"))\n+    \"numOutputRows\" -> SQLMetrics.createSumMetric(sparkContext, \"number of output rows\"))"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "`SQLMetric` are all long accumulator, so I chose the name `sum` to describe the behaviour, not type...\n",
    "commit": "124568b3eeb7e0a657b2fbe4f54bb85543b7ffa3",
    "createdAt": "2016-04-28T04:06:12Z",
    "diffHunk": "@@ -46,7 +46,7 @@ case class SortBasedAggregateExec(\n       AttributeSet(aggregateBufferAttributes)\n \n   override private[sql] lazy val metrics = Map(\n-    \"numOutputRows\" -> SQLMetrics.createLongMetric(sparkContext, \"number of output rows\"))\n+    \"numOutputRows\" -> SQLMetrics.createSumMetric(sparkContext, \"number of output rows\"))"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "maybe just createMetric?\n",
    "commit": "124568b3eeb7e0a657b2fbe4f54bb85543b7ffa3",
    "createdAt": "2016-04-28T04:13:10Z",
    "diffHunk": "@@ -46,7 +46,7 @@ case class SortBasedAggregateExec(\n       AttributeSet(aggregateBufferAttributes)\n \n   override private[sql] lazy val metrics = Map(\n-    \"numOutputRows\" -> SQLMetrics.createLongMetric(sparkContext, \"number of output rows\"))\n+    \"numOutputRows\" -> SQLMetrics.createSumMetric(sparkContext, \"number of output rows\"))"
  }],
  "prId": 12612
}]