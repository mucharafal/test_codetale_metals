[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "minor suggestion: you could have a private sealed trait `SparkPlanGraphElement` that defines a `def makeDotString`, and have all of these edges and nodes override that one. Seems a little cleaner.\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:11:26Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.AccumulatorParam\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * A graph used for storing information of an executionPlan of DataFrame.\n+ *\n+ * Each graph is defined with a set of nodes and a set of edges. Each node represents a node in the\n+ * SparkPlan tree, and each edge represents a parent-child relationship between two nodes.\n+ */\n+private[ui] case class SparkPlanGraph(\n+    nodes: Seq[SparkPlanGraphNode], edges: Seq[SparkPlanGraphEdge]) {\n+\n+  def makeDotFile(metrics: Map[Long, Any]): String = {\n+    val dotFile = new StringBuilder\n+    dotFile.append(\"digraph G {\\n\")\n+    nodes.foreach(node => dotFile.append(node.makeDotNode(metrics) + \"\\n\"))\n+    edges.foreach(edge => dotFile.append(edge.makeDotEdge + \"\\n\"))\n+    dotFile.append(\"}\")\n+    dotFile.toString()\n+  }\n+}\n+\n+private[ui] object SparkPlanGraph {\n+\n+  /**\n+   * Build a SparkPlanGraph from the root of a SparkPlan tree.\n+   */\n+  def apply(plan: SparkPlan): SparkPlanGraph = {\n+    val nodeIdGenerator = new AtomicLong(0)\n+    val nodes = mutable.ArrayBuffer[SparkPlanGraphNode]()\n+    val edges = mutable.ArrayBuffer[SparkPlanGraphEdge]()\n+    buildSparkPlanGraphNode(plan, nodeIdGenerator, nodes, edges)\n+    new SparkPlanGraph(nodes, edges)\n+  }\n+\n+  private def buildSparkPlanGraphNode(\n+      plan: SparkPlan,\n+      nodeIdGenerator: AtomicLong,\n+      nodes: mutable.ArrayBuffer[SparkPlanGraphNode],\n+      edges: mutable.ArrayBuffer[SparkPlanGraphEdge]): SparkPlanGraphNode = {\n+    val metrics = plan.accumulators.toSeq.map { case (key, accumulator) =>\n+      SQLPlanMetric(accumulator.name.getOrElse(key), accumulator.id,\n+        accumulator.param.asInstanceOf[AccumulatorParam[Any]])\n+    }\n+    val node = SparkPlanGraphNode(\n+      nodeIdGenerator.getAndIncrement(), plan.nodeName, plan.simpleString, metrics)\n+    nodes += node\n+    val childrenNodes = plan.children.map(\n+      child => buildSparkPlanGraphNode(child, nodeIdGenerator, nodes, edges))\n+    for (child <- childrenNodes) {\n+      edges += SparkPlanGraphEdge(child.id, node.id)\n+    }\n+    node\n+  }\n+}\n+\n+/**\n+ * Represent a node in the SparkPlan tree, along with its metrics.\n+ *\n+ * @param id generated by \"SparkPlanGraph\". There is no duplicate id in a graph\n+ * @param name the name of this SparkPlan node\n+ * @param metrics metrics that this SparkPlan node will track\n+ */\n+private[ui] case class SparkPlanGraphNode(\n+    id: Long, name: String, desc: String, metrics: Seq[SQLPlanMetric]) {\n+\n+  def makeDotNode(metricsValue: Map[Long, Any]): String = {\n+    val values =\n+      for (metric <- metrics;\n+           value <- metricsValue.get(metric.accumulatorId))\n+        yield metric.name + \": \" + value\n+    val label = if (values.isEmpty) {\n+        name\n+      } else {\n+        name + \"\\\\n \\\\n\" + values.mkString(\"\\\\n\")\n+      }\n+    s\"\"\"  $id [label=\"$label\"];\"\"\"\n+  }\n+}\n+\n+/**\n+ * Represent an edge in the SparkPlan tree. `fromId` is the parent node id, and `toId` is the child\n+ * node id.\n+ */\n+private[ui] case class SparkPlanGraphEdge(fromId: Long, toId: Long) {\n+\n+  def makeDotEdge: String = s\"\"\"  $fromId->$toId;\\n\"\"\"",
    "line": 117
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "I don't get it. Can you explain what this is doing? Maybe add a comment?\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:12:04Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.AccumulatorParam\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * A graph used for storing information of an executionPlan of DataFrame.\n+ *\n+ * Each graph is defined with a set of nodes and a set of edges. Each node represents a node in the\n+ * SparkPlan tree, and each edge represents a parent-child relationship between two nodes.\n+ */\n+private[ui] case class SparkPlanGraph(\n+    nodes: Seq[SparkPlanGraphNode], edges: Seq[SparkPlanGraphEdge]) {\n+\n+  def makeDotFile(metrics: Map[Long, Any]): String = {\n+    val dotFile = new StringBuilder\n+    dotFile.append(\"digraph G {\\n\")\n+    nodes.foreach(node => dotFile.append(node.makeDotNode(metrics) + \"\\n\"))\n+    edges.foreach(edge => dotFile.append(edge.makeDotEdge + \"\\n\"))\n+    dotFile.append(\"}\")\n+    dotFile.toString()\n+  }\n+}\n+\n+private[ui] object SparkPlanGraph {\n+\n+  /**\n+   * Build a SparkPlanGraph from the root of a SparkPlan tree.\n+   */\n+  def apply(plan: SparkPlan): SparkPlanGraph = {\n+    val nodeIdGenerator = new AtomicLong(0)\n+    val nodes = mutable.ArrayBuffer[SparkPlanGraphNode]()\n+    val edges = mutable.ArrayBuffer[SparkPlanGraphEdge]()\n+    buildSparkPlanGraphNode(plan, nodeIdGenerator, nodes, edges)\n+    new SparkPlanGraph(nodes, edges)\n+  }\n+\n+  private def buildSparkPlanGraphNode(\n+      plan: SparkPlan,\n+      nodeIdGenerator: AtomicLong,\n+      nodes: mutable.ArrayBuffer[SparkPlanGraphNode],\n+      edges: mutable.ArrayBuffer[SparkPlanGraphEdge]): SparkPlanGraphNode = {\n+    val metrics = plan.accumulators.toSeq.map { case (key, accumulator) =>\n+      SQLPlanMetric(accumulator.name.getOrElse(key), accumulator.id,\n+        accumulator.param.asInstanceOf[AccumulatorParam[Any]])\n+    }\n+    val node = SparkPlanGraphNode(\n+      nodeIdGenerator.getAndIncrement(), plan.nodeName, plan.simpleString, metrics)\n+    nodes += node\n+    val childrenNodes = plan.children.map(\n+      child => buildSparkPlanGraphNode(child, nodeIdGenerator, nodes, edges))\n+    for (child <- childrenNodes) {\n+      edges += SparkPlanGraphEdge(child.id, node.id)\n+    }\n+    node\n+  }\n+}\n+\n+/**\n+ * Represent a node in the SparkPlan tree, along with its metrics.\n+ *\n+ * @param id generated by \"SparkPlanGraph\". There is no duplicate id in a graph\n+ * @param name the name of this SparkPlan node\n+ * @param metrics metrics that this SparkPlan node will track\n+ */\n+private[ui] case class SparkPlanGraphNode(\n+    id: Long, name: String, desc: String, metrics: Seq[SQLPlanMetric]) {\n+\n+  def makeDotNode(metricsValue: Map[Long, Any]): String = {\n+    val values =\n+      for (metric <- metrics;\n+           value <- metricsValue.get(metric.accumulatorId))\n+        yield metric.name + \": \" + value\n+    val label = if (values.isEmpty) {\n+        name\n+      } else {\n+        name + \"\\\\n \\\\n\" + values.mkString(\"\\\\n\")"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "style: need `{ } around the for loop body\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:12:20Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.AccumulatorParam\n+import org.apache.spark.sql.execution.SparkPlan\n+\n+/**\n+ * A graph used for storing information of an executionPlan of DataFrame.\n+ *\n+ * Each graph is defined with a set of nodes and a set of edges. Each node represents a node in the\n+ * SparkPlan tree, and each edge represents a parent-child relationship between two nodes.\n+ */\n+private[ui] case class SparkPlanGraph(\n+    nodes: Seq[SparkPlanGraphNode], edges: Seq[SparkPlanGraphEdge]) {\n+\n+  def makeDotFile(metrics: Map[Long, Any]): String = {\n+    val dotFile = new StringBuilder\n+    dotFile.append(\"digraph G {\\n\")\n+    nodes.foreach(node => dotFile.append(node.makeDotNode(metrics) + \"\\n\"))\n+    edges.foreach(edge => dotFile.append(edge.makeDotEdge + \"\\n\"))\n+    dotFile.append(\"}\")\n+    dotFile.toString()\n+  }\n+}\n+\n+private[ui] object SparkPlanGraph {\n+\n+  /**\n+   * Build a SparkPlanGraph from the root of a SparkPlan tree.\n+   */\n+  def apply(plan: SparkPlan): SparkPlanGraph = {\n+    val nodeIdGenerator = new AtomicLong(0)\n+    val nodes = mutable.ArrayBuffer[SparkPlanGraphNode]()\n+    val edges = mutable.ArrayBuffer[SparkPlanGraphEdge]()\n+    buildSparkPlanGraphNode(plan, nodeIdGenerator, nodes, edges)\n+    new SparkPlanGraph(nodes, edges)\n+  }\n+\n+  private def buildSparkPlanGraphNode(\n+      plan: SparkPlan,\n+      nodeIdGenerator: AtomicLong,\n+      nodes: mutable.ArrayBuffer[SparkPlanGraphNode],\n+      edges: mutable.ArrayBuffer[SparkPlanGraphEdge]): SparkPlanGraphNode = {\n+    val metrics = plan.accumulators.toSeq.map { case (key, accumulator) =>\n+      SQLPlanMetric(accumulator.name.getOrElse(key), accumulator.id,\n+        accumulator.param.asInstanceOf[AccumulatorParam[Any]])\n+    }\n+    val node = SparkPlanGraphNode(\n+      nodeIdGenerator.getAndIncrement(), plan.nodeName, plan.simpleString, metrics)\n+    nodes += node\n+    val childrenNodes = plan.children.map(\n+      child => buildSparkPlanGraphNode(child, nodeIdGenerator, nodes, edges))\n+    for (child <- childrenNodes) {\n+      edges += SparkPlanGraphEdge(child.id, node.id)\n+    }\n+    node\n+  }\n+}\n+\n+/**\n+ * Represent a node in the SparkPlan tree, along with its metrics.\n+ *\n+ * @param id generated by \"SparkPlanGraph\". There is no duplicate id in a graph\n+ * @param name the name of this SparkPlan node\n+ * @param metrics metrics that this SparkPlan node will track\n+ */\n+private[ui] case class SparkPlanGraphNode(\n+    id: Long, name: String, desc: String, metrics: Seq[SQLPlanMetric]) {\n+\n+  def makeDotNode(metricsValue: Map[Long, Any]): String = {\n+    val values =\n+      for (metric <- metrics;\n+           value <- metricsValue.get(metric.accumulatorId))\n+        yield metric.name + \": \" + value"
  }],
  "prId": 7774
}]