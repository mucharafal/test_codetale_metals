[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "waiting for https://github.com/apache/spark/pull/23208 ? cc @cloud-fan @gengliangwang \r\n\r\nAlso, do we want to have a NULL data source for streaming?\r\n",
    "commit": "d561ab0238ed323087e1bbb9eb8097daf1b562b4",
    "createdAt": "2019-01-05T22:19:59Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.none\n+\n+import java.util.Optional\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SaveMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.sources.DataSourceRegister\n+import org.apache.spark.sql.sources.v2._\n+import org.apache.spark.sql.sources.v2.writer._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * The datasource can be used in benchmarking because it forces materialization\n+ * of each written row of a dataset without converting fields to other types.\n+ * This can be used in caching of datasets without additional overhead of an actions.\n+ */\n+class NoneDataSource extends DataSourceV2 with BatchWriteSupportProvider with DataSourceRegister {"
  }, {
    "author": {
      "login": "MaxGekk"
    },
    "body": "For the purpose of the PR, it doesn't matter on which API this datasource is based. I can rewrite it on API v1\r\n\r\n> Also, do we want to have a NULL data source for streaming?\r\n\r\n It addresses benchmarking of batch processing. Not sure about streaming. @hvanhovell WDYT?",
    "commit": "d561ab0238ed323087e1bbb9eb8097daf1b562b4",
    "createdAt": "2019-01-05T22:43:13Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.none\n+\n+import java.util.Optional\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SaveMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.sources.DataSourceRegister\n+import org.apache.spark.sql.sources.v2._\n+import org.apache.spark.sql.sources.v2.writer._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * The datasource can be used in benchmarking because it forces materialization\n+ * of each written row of a dataset without converting fields to other types.\n+ * This can be used in caching of datasets without additional overhead of an actions.\n+ */\n+class NoneDataSource extends DataSourceV2 with BatchWriteSupportProvider with DataSourceRegister {"
  }, {
    "author": {
      "login": "MaxGekk"
    },
    "body": "Just in case, I cannot use `null` as the name of the datasource because it is prohibited as package name.",
    "commit": "d561ab0238ed323087e1bbb9eb8097daf1b562b4",
    "createdAt": "2019-01-05T22:45:38Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.none\n+\n+import java.util.Optional\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SaveMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.sources.DataSourceRegister\n+import org.apache.spark.sql.sources.v2._\n+import org.apache.spark.sql.sources.v2.writer._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * The datasource can be used in benchmarking because it forces materialization\n+ * of each written row of a dataset without converting fields to other types.\n+ * This can be used in caching of datasets without additional overhead of an actions.\n+ */\n+class NoneDataSource extends DataSourceV2 with BatchWriteSupportProvider with DataSourceRegister {"
  }],
  "prId": 23471
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Not a big deal but how about naming noop?",
    "commit": "d561ab0238ed323087e1bbb9eb8097daf1b562b4",
    "createdAt": "2019-01-06T03:35:24Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.none\n+\n+import java.util.Optional\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SaveMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.sources.DataSourceRegister\n+import org.apache.spark.sql.sources.v2._\n+import org.apache.spark.sql.sources.v2.writer._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * The datasource can be used in benchmarking because it forces materialization\n+ * of each written row of a dataset without converting fields to other types.\n+ * This can be used in caching of datasets without additional overhead of an actions.\n+ */\n+class NoneDataSource extends DataSourceV2 with BatchWriteSupportProvider with DataSourceRegister {\n+  override def shortName(): String = \"none\""
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "IMO \"noop\" or \"dummy\" seems better. ",
    "commit": "d561ab0238ed323087e1bbb9eb8097daf1b562b4",
    "createdAt": "2019-01-06T06:43:08Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.none\n+\n+import java.util.Optional\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SaveMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.sources.DataSourceRegister\n+import org.apache.spark.sql.sources.v2._\n+import org.apache.spark.sql.sources.v2.writer._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * The datasource can be used in benchmarking because it forces materialization\n+ * of each written row of a dataset without converting fields to other types.\n+ * This can be used in caching of datasets without additional overhead of an actions.\n+ */\n+class NoneDataSource extends DataSourceV2 with BatchWriteSupportProvider with DataSourceRegister {\n+  override def shortName(): String = \"none\""
  }, {
    "author": {
      "login": "MaxGekk"
    },
    "body": "I renamed it to noop",
    "commit": "d561ab0238ed323087e1bbb9eb8097daf1b562b4",
    "createdAt": "2019-01-06T12:14:09Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.none\n+\n+import java.util.Optional\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SaveMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.sources.DataSourceRegister\n+import org.apache.spark.sql.sources.v2._\n+import org.apache.spark.sql.sources.v2.writer._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * The datasource can be used in benchmarking because it forces materialization\n+ * of each written row of a dataset without converting fields to other types.\n+ * This can be used in caching of datasets without additional overhead of an actions.\n+ */\n+class NoneDataSource extends DataSourceV2 with BatchWriteSupportProvider with DataSourceRegister {\n+  override def shortName(): String = \"none\""
  }],
  "prId": 23471
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "So looks like this data source just materializes rows and logs them now?",
    "commit": "d561ab0238ed323087e1bbb9eb8097daf1b562b4",
    "createdAt": "2019-01-06T04:44:55Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.none\n+\n+import java.util.Optional\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SaveMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.sources.DataSourceRegister\n+import org.apache.spark.sql.sources.v2._\n+import org.apache.spark.sql.sources.v2.writer._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * The datasource can be used in benchmarking because it forces materialization\n+ * of each written row of a dataset without converting fields to other types.\n+ * This can be used in caching of datasets without additional overhead of an actions.\n+ */\n+class NoneDataSource extends DataSourceV2 with BatchWriteSupportProvider with DataSourceRegister {\n+  override def shortName(): String = \"none\"\n+\n+  override def createBatchWriteSupport(\n+      queryId: String,\n+      schema: StructType,\n+      mode: SaveMode,\n+      options: DataSourceOptions): Optional[BatchWriteSupport] = {\n+    Optional.of(new NoneWriteSupport())\n+  }\n+}\n+\n+class NoneWriteSupport extends BatchWriteSupport {\n+  override def createBatchWriterFactory(): DataWriterFactory = {\n+    new NoneWriterFactory()\n+  }\n+\n+  override def useCommitCoordinator(): Boolean = false\n+  override def commit(messages: Array[WriterCommitMessage]): Unit = ()\n+  override def abort(messages: Array[WriterCommitMessage]): Unit = ()\n+}\n+\n+class NoneWriterFactory extends DataWriterFactory {\n+  override def createWriter(partitionId: Int, taskId: Long): DataWriter[InternalRow] = {\n+    new NoneWriter()\n+  }\n+}\n+\n+class NoneWriter extends DataWriter[InternalRow] with Logging {\n+  override def write(record: InternalRow): Unit = {\n+    logTrace(record.toString)"
  }, {
    "author": {
      "login": "MaxGekk"
    },
    "body": "Yes, main purpose of this datasource is relatively cheap materialization  of a dataset without additional overhead of type conversion.",
    "commit": "d561ab0238ed323087e1bbb9eb8097daf1b562b4",
    "createdAt": "2019-01-06T11:12:16Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.none\n+\n+import java.util.Optional\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SaveMode\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.sources.DataSourceRegister\n+import org.apache.spark.sql.sources.v2._\n+import org.apache.spark.sql.sources.v2.writer._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * The datasource can be used in benchmarking because it forces materialization\n+ * of each written row of a dataset without converting fields to other types.\n+ * This can be used in caching of datasets without additional overhead of an actions.\n+ */\n+class NoneDataSource extends DataSourceV2 with BatchWriteSupportProvider with DataSourceRegister {\n+  override def shortName(): String = \"none\"\n+\n+  override def createBatchWriteSupport(\n+      queryId: String,\n+      schema: StructType,\n+      mode: SaveMode,\n+      options: DataSourceOptions): Optional[BatchWriteSupport] = {\n+    Optional.of(new NoneWriteSupport())\n+  }\n+}\n+\n+class NoneWriteSupport extends BatchWriteSupport {\n+  override def createBatchWriterFactory(): DataWriterFactory = {\n+    new NoneWriterFactory()\n+  }\n+\n+  override def useCommitCoordinator(): Boolean = false\n+  override def commit(messages: Array[WriterCommitMessage]): Unit = ()\n+  override def abort(messages: Array[WriterCommitMessage]): Unit = ()\n+}\n+\n+class NoneWriterFactory extends DataWriterFactory {\n+  override def createWriter(partitionId: Int, taskId: Long): DataWriter[InternalRow] = {\n+    new NoneWriter()\n+  }\n+}\n+\n+class NoneWriter extends DataWriter[InternalRow] with Logging {\n+  override def write(record: InternalRow): Unit = {\n+    logTrace(record.toString)"
  }],
  "prId": 23471
}]