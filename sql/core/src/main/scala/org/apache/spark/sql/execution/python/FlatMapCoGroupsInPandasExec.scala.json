[{
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "nit: need a space between `BinaryExecNode` and `{`.",
    "commit": "1b966fda46c5334cf7963bae0bece159c9568622",
    "createdAt": "2019-08-27T20:38:37Z",
    "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.python\n+\n+import org.apache.spark.api.python.PythonEvalType\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.plans.physical.{AllTuples, ClusteredDistribution, Distribution, Partitioning}\n+import org.apache.spark.sql.execution.{BinaryExecNode, CoGroupedIterator, SparkPlan}\n+import org.apache.spark.sql.types.StructType\n+\n+\n+/**\n+ * Physical node for [[org.apache.spark.sql.catalyst.plans.logical.FlatMapCoGroupsInPandas]]\n+ *\n+ * The input dataframes are first Cogrouped.  Rows from each side of the cogroup are passed to the\n+ * Python worker via Arrow.  As each side of the cogroup may have a different schema we send every\n+ * group in its own Arrow stream.\n+ * The Python worker turns the resulting record batches to `pandas.DataFrame`s, invokes the\n+ * user-defined function, and passes the resulting `pandas.DataFrame`\n+ * as an Arrow record batch. Finally, each record batch is turned to\n+ * Iterator[InternalRow] using ColumnarBatch.\n+ *\n+ * Note on memory usage:\n+ * Both the Python worker and the Java executor need to have enough memory to\n+ * hold the largest cogroup. The memory on the Java side is used to construct the\n+ * record batches (off heap memory). The memory on the Python side is used for\n+ * holding the `pandas.DataFrame`. It's possible to further split one group into\n+ * multiple record batches to reduce the memory footprint on the Java side, this\n+ * is left as future work.\n+ */\n+case class FlatMapCoGroupsInPandasExec(\n+    leftGroup: Seq[Attribute],\n+    rightGroup: Seq[Attribute],\n+    func: Expression,\n+    output: Seq[Attribute],\n+    left: SparkPlan,\n+    right: SparkPlan)\n+  extends BasePandasGroupExec(func, output) with BinaryExecNode{"
  }],
  "prId": 24981
}]