[{
  "comments": [{
    "author": {
      "login": "arunmahadevan"
    },
    "body": "may be good to add who the senders and receivers are to get an idea of where this fits in. ",
    "commit": "00f910ea39b76a24e1e21acdf3d6a20fd7784fa9",
    "createdAt": "2018-05-15T18:49:23Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous.shuffle\n+\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+\n+/**\n+ * Messages for the UnsafeRowReceiver endpoint. Either an incoming row or an epoch marker.\n+ */\n+private[shuffle] sealed trait UnsafeRowReceiverMessage extends Serializable\n+private[shuffle] case class ReceiverRow(row: UnsafeRow) extends UnsafeRowReceiverMessage\n+private[shuffle] case class ReceiverEpochMarker() extends UnsafeRowReceiverMessage\n+\n+/**\n+ * RPC endpoint for receiving rows into a continuous processing shuffle task."
  }],
  "prId": 21337
}, {
  "comments": [{
    "author": {
      "login": "arunmahadevan"
    },
    "body": "1. may be good to state the assumption that the queue will be continuously drained irrespective of the markers etc.\r\n2. can the queue size be made configurable?\r\n\r\n",
    "commit": "00f910ea39b76a24e1e21acdf3d6a20fd7784fa9",
    "createdAt": "2018-05-15T18:51:59Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous.shuffle\n+\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+\n+/**\n+ * Messages for the UnsafeRowReceiver endpoint. Either an incoming row or an epoch marker.\n+ */\n+private[shuffle] sealed trait UnsafeRowReceiverMessage extends Serializable\n+private[shuffle] case class ReceiverRow(row: UnsafeRow) extends UnsafeRowReceiverMessage\n+private[shuffle] case class ReceiverEpochMarker() extends UnsafeRowReceiverMessage\n+\n+/**\n+ * RPC endpoint for receiving rows into a continuous processing shuffle task.\n+ */\n+private[shuffle] class UnsafeRowReceiver(val rpcEnv: RpcEnv)\n+    extends ThreadSafeRpcEndpoint with Logging {\n+  private val queue = new ArrayBlockingQueue[UnsafeRowReceiverMessage](1024)"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "I guess we can handle 2 as TODO if we would like to focus on proposed patch.",
    "commit": "00f910ea39b76a24e1e21acdf3d6a20fd7784fa9",
    "createdAt": "2018-05-16T14:01:36Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous.shuffle\n+\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+\n+/**\n+ * Messages for the UnsafeRowReceiver endpoint. Either an incoming row or an epoch marker.\n+ */\n+private[shuffle] sealed trait UnsafeRowReceiverMessage extends Serializable\n+private[shuffle] case class ReceiverRow(row: UnsafeRow) extends UnsafeRowReceiverMessage\n+private[shuffle] case class ReceiverEpochMarker() extends UnsafeRowReceiverMessage\n+\n+/**\n+ * RPC endpoint for receiving rows into a continuous processing shuffle task.\n+ */\n+private[shuffle] class UnsafeRowReceiver(val rpcEnv: RpcEnv)\n+    extends ThreadSafeRpcEndpoint with Logging {\n+  private val queue = new ArrayBlockingQueue[UnsafeRowReceiverMessage](1024)"
  }, {
    "author": {
      "login": "jose-torres"
    },
    "body": "There's actually an existing config I forgot to pull in. (I think it makes sense to use the same config for all continuous read buffers unless and until we see a need to split it.)",
    "commit": "00f910ea39b76a24e1e21acdf3d6a20fd7784fa9",
    "createdAt": "2018-05-17T03:23:41Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous.shuffle\n+\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+\n+/**\n+ * Messages for the UnsafeRowReceiver endpoint. Either an incoming row or an epoch marker.\n+ */\n+private[shuffle] sealed trait UnsafeRowReceiverMessage extends Serializable\n+private[shuffle] case class ReceiverRow(row: UnsafeRow) extends UnsafeRowReceiverMessage\n+private[shuffle] case class ReceiverEpochMarker() extends UnsafeRowReceiverMessage\n+\n+/**\n+ * RPC endpoint for receiving rows into a continuous processing shuffle task.\n+ */\n+private[shuffle] class UnsafeRowReceiver(val rpcEnv: RpcEnv)\n+    extends ThreadSafeRpcEndpoint with Logging {\n+  private val queue = new ArrayBlockingQueue[UnsafeRowReceiverMessage](1024)"
  }],
  "prId": 21337
}, {
  "comments": [{
    "author": {
      "login": "xuanyuanking"
    },
    "body": "override val rpcEnv here?",
    "commit": "00f910ea39b76a24e1e21acdf3d6a20fd7784fa9",
    "createdAt": "2018-05-16T12:12:19Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous.shuffle\n+\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+\n+/**\n+ * Messages for the UnsafeRowReceiver endpoint. Either an incoming row or an epoch marker.\n+ */\n+private[shuffle] sealed trait UnsafeRowReceiverMessage extends Serializable\n+private[shuffle] case class ReceiverRow(row: UnsafeRow) extends UnsafeRowReceiverMessage\n+private[shuffle] case class ReceiverEpochMarker() extends UnsafeRowReceiverMessage\n+\n+/**\n+ * RPC endpoint for receiving rows into a continuous processing shuffle task.\n+ */\n+private[shuffle] class UnsafeRowReceiver(val rpcEnv: RpcEnv)"
  }],
  "prId": 21337
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "why is this a var? and public?",
    "commit": "00f910ea39b76a24e1e21acdf3d6a20fd7784fa9",
    "createdAt": "2018-05-17T23:13:03Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous.shuffle\n+\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+\n+/**\n+ * Messages for the UnsafeRowReceiver endpoint. Either an incoming row or an epoch marker.\n+ */\n+private[shuffle] sealed trait UnsafeRowReceiverMessage extends Serializable\n+private[shuffle] case class ReceiverRow(row: UnsafeRow) extends UnsafeRowReceiverMessage\n+private[shuffle] case class ReceiverEpochMarker() extends UnsafeRowReceiverMessage\n+\n+/**\n+ * RPC endpoint for receiving rows into a continuous processing shuffle task. Continuous shuffle\n+ * writers will send rows here, with continuous shuffle readers polling for new rows as needed.\n+ *\n+ * TODO: Support multiple source tasks. We need to output a single epoch marker once all\n+ * source tasks have sent one.\n+ */\n+private[shuffle] class UnsafeRowReceiver(\n+      queueSize: Int,\n+      override val rpcEnv: RpcEnv)\n+    extends ThreadSafeRpcEndpoint with Logging {\n+  // Note that this queue will be drained from the main task thread and populated in the RPC\n+  // response thread.\n+  private val queue = new ArrayBlockingQueue[UnsafeRowReceiverMessage](queueSize)\n+  var stopped = new AtomicBoolean(false)"
  }, {
    "author": {
      "login": "jose-torres"
    },
    "body": "Restricted visibility and made it a proper val.",
    "commit": "00f910ea39b76a24e1e21acdf3d6a20fd7784fa9",
    "createdAt": "2018-05-18T00:02:25Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous.shuffle\n+\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+\n+/**\n+ * Messages for the UnsafeRowReceiver endpoint. Either an incoming row or an epoch marker.\n+ */\n+private[shuffle] sealed trait UnsafeRowReceiverMessage extends Serializable\n+private[shuffle] case class ReceiverRow(row: UnsafeRow) extends UnsafeRowReceiverMessage\n+private[shuffle] case class ReceiverEpochMarker() extends UnsafeRowReceiverMessage\n+\n+/**\n+ * RPC endpoint for receiving rows into a continuous processing shuffle task. Continuous shuffle\n+ * writers will send rows here, with continuous shuffle readers polling for new rows as needed.\n+ *\n+ * TODO: Support multiple source tasks. We need to output a single epoch marker once all\n+ * source tasks have sent one.\n+ */\n+private[shuffle] class UnsafeRowReceiver(\n+      queueSize: Int,\n+      override val rpcEnv: RpcEnv)\n+    extends ThreadSafeRpcEndpoint with Logging {\n+  // Note that this queue will be drained from the main task thread and populated in the RPC\n+  // response thread.\n+  private val queue = new ArrayBlockingQueue[UnsafeRowReceiverMessage](queueSize)\n+  var stopped = new AtomicBoolean(false)"
  }],
  "prId": 21337
}]