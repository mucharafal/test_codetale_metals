[{
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Maybe better to just call `close` if `this` is visible.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-01T10:24:07Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceRDDPartition\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * For performance reasons, this is very weakly encapsulated. There are six handles for the RDD:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ *  * queue - the queue of incoming rows (row, offset) or epoch markers (null, null). The\n+ *    ContinuousQueuedDataReader writes into this queue, and RDD.compute() will read from it.\n+ *  * {epochPoll|dataReader}Failed - flags to check if the epoch poll and data reader threads are\n+ *    still running. These threads won't be restarted if they fail, so the RDD should intercept\n+ *    this state when convenient to fail the query.\n+ *  * close() - to close this reader when the query is going to shut down.\n+ */\n+class ContinuousQueuedDataReader(\n+    split: Partition,\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = split.asInstanceOf[DataSourceRDDPartition[UnsafeRow]]\n+    .readerFactory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  // This queue contains two types of messages:\n+  // * (null, null) representing an epoch boundary.\n+  // * (row, off) containing a data row and its corresponding PartitionOffset.\n+  val queue = new ArrayBlockingQueue[(UnsafeRow, PartitionOffset)](dataQueueSize)\n+\n+  val epochPollFailed = new AtomicBoolean(false)\n+  val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochPollExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  val epochPollRunnable = new EpochPollRunnable(queue, context, epochPollFailed)\n+  epochPollExecutor.scheduleWithFixedDelay(\n+    epochPollRunnable, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {"
  }, {
    "author": {
      "login": "jose-torres"
    },
    "body": "Good point.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-01T16:36:23Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceRDDPartition\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * For performance reasons, this is very weakly encapsulated. There are six handles for the RDD:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ *  * queue - the queue of incoming rows (row, offset) or epoch markers (null, null). The\n+ *    ContinuousQueuedDataReader writes into this queue, and RDD.compute() will read from it.\n+ *  * {epochPoll|dataReader}Failed - flags to check if the epoch poll and data reader threads are\n+ *    still running. These threads won't be restarted if they fail, so the RDD should intercept\n+ *    this state when convenient to fail the query.\n+ *  * close() - to close this reader when the query is going to shut down.\n+ */\n+class ContinuousQueuedDataReader(\n+    split: Partition,\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = split.asInstanceOf[DataSourceRDDPartition[UnsafeRow]]\n+    .readerFactory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  // This queue contains two types of messages:\n+  // * (null, null) representing an epoch boundary.\n+  // * (row, off) containing a data row and its corresponding PartitionOffset.\n+  val queue = new ArrayBlockingQueue[(UnsafeRow, PartitionOffset)](dataQueueSize)\n+\n+  val epochPollFailed = new AtomicBoolean(false)\n+  val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochPollExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  val epochPollRunnable = new EpochPollRunnable(queue, context, epochPollFailed)\n+  epochPollExecutor.scheduleWithFixedDelay(\n+    epochPollRunnable, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "How is this synchronized? Isnt this accessed from the task iterator thread and the data reader thread?",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-01T23:54:11Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceRDDPartition\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * For performance reasons, this is very weakly encapsulated. There are six handles for the RDD:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ *  * queue - the queue of incoming rows (row, offset) or epoch markers (null, null). The\n+ *    ContinuousQueuedDataReader writes into this queue, and RDD.compute() will read from it.\n+ *  * {epochPoll|dataReader}Failed - flags to check if the epoch poll and data reader threads are\n+ *    still running. These threads won't be restarted if they fail, so the RDD should intercept\n+ *    this state when convenient to fail the query.\n+ *  * close() - to close this reader when the query is going to shut down.\n+ */\n+class ContinuousQueuedDataReader(\n+    split: Partition,\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = split.asInstanceOf[DataSourceRDDPartition[UnsafeRow]]\n+    .readerFactory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset"
  }, {
    "author": {
      "login": "jose-torres"
    },
    "body": "The data reader thread doesn't access this. As mentioned in the top-level comment, the task iterator thread is responsible for advancing it as it sees new rows.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T03:47:37Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceRDDPartition\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * For performance reasons, this is very weakly encapsulated. There are six handles for the RDD:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ *  * queue - the queue of incoming rows (row, offset) or epoch markers (null, null). The\n+ *    ContinuousQueuedDataReader writes into this queue, and RDD.compute() will read from it.\n+ *  * {epochPoll|dataReader}Failed - flags to check if the epoch poll and data reader threads are\n+ *    still running. These threads won't be restarted if they fail, so the RDD should intercept\n+ *    this state when convenient to fail the query.\n+ *  * close() - to close this reader when the query is going to shut down.\n+ */\n+class ContinuousQueuedDataReader(\n+    split: Partition,\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = split.asInstanceOf[DataSourceRDDPartition[UnsafeRow]]\n+    .readerFactory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Why is this public val?",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-01T23:55:50Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceRDDPartition\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * For performance reasons, this is very weakly encapsulated. There are six handles for the RDD:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ *  * queue - the queue of incoming rows (row, offset) or epoch markers (null, null). The\n+ *    ContinuousQueuedDataReader writes into this queue, and RDD.compute() will read from it.\n+ *  * {epochPoll|dataReader}Failed - flags to check if the epoch poll and data reader threads are\n+ *    still running. These threads won't be restarted if they fail, so the RDD should intercept\n+ *    this state when convenient to fail the query.\n+ *  * close() - to close this reader when the query is going to shut down.\n+ */\n+class ContinuousQueuedDataReader(\n+    split: Partition,\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = split.asInstanceOf[DataSourceRDDPartition[UnsafeRow]]\n+    .readerFactory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  // This queue contains two types of messages:\n+  // * (null, null) representing an epoch boundary.\n+  // * (row, off) containing a data row and its corresponding PartitionOffset.\n+  val queue = new ArrayBlockingQueue[(UnsafeRow, PartitionOffset)](dataQueueSize)\n+\n+  val epochPollFailed = new AtomicBoolean(false)\n+  val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochPollExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  val epochPollRunnable = new EpochPollRunnable(queue, context, epochPollFailed)"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This can be much more strongly encapsulated. There is no need to expose `queue`, `epochPollFailed` and `dataReaderFailed`. See comment in the RDD class.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T00:02:56Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceRDDPartition\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * For performance reasons, this is very weakly encapsulated. There are six handles for the RDD:"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Commented above, this does not need to be public. \r\n",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T00:40:48Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceRDDPartition\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * For performance reasons, this is very weakly encapsulated. There are six handles for the RDD:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ *  * queue - the queue of incoming rows (row, offset) or epoch markers (null, null). The\n+ *    ContinuousQueuedDataReader writes into this queue, and RDD.compute() will read from it.\n+ *  * {epochPoll|dataReader}Failed - flags to check if the epoch poll and data reader threads are\n+ *    still running. These threads won't be restarted if they fail, so the RDD should intercept\n+ *    this state when convenient to fail the query.\n+ *  * close() - to close this reader when the query is going to shut down.\n+ */\n+class ContinuousQueuedDataReader(\n+    split: Partition,\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = split.asInstanceOf[DataSourceRDDPartition[UnsafeRow]]\n+    .readerFactory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  // This queue contains two types of messages:\n+  // * (null, null) representing an epoch boundary.\n+  // * (row, off) containing a data row and its corresponding PartitionOffset.\n+  val queue = new ArrayBlockingQueue[(UnsafeRow, PartitionOffset)](dataQueueSize)"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This class is best understood only when you see both `DataReaderThread` and `EpochPollRunnable` code. And these classes share a lot of objects between themselves (flags, taskcontext, etc.). So I think it makes more sense to have the `DataReaderThread` and `EpochPollRunnable` as inner classes of this `ContinuousQueuedDataReader` class. Would make the logic easier to follow.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T00:45:36Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceRDDPartition\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * For performance reasons, this is very weakly encapsulated. There are six handles for the RDD:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ *  * queue - the queue of incoming rows (row, offset) or epoch markers (null, null). The\n+ *    ContinuousQueuedDataReader writes into this queue, and RDD.compute() will read from it.\n+ *  * {epochPoll|dataReader}Failed - flags to check if the epoch poll and data reader threads are\n+ *    still running. These threads won't be restarted if they fail, so the RDD should intercept\n+ *    this state when convenient to fail the query.\n+ *  * close() - to close this reader when the query is going to shut down.\n+ */\n+class ContinuousQueuedDataReader("
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: I think should ideally just extend Runnable",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T22:50:26Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    override def run(): Unit = {\n+      TaskContext.setTaskContext(context)\n+      val baseReader = ContinuousDataSourceRDD.getBaseReader(reader)\n+      try {\n+        while (!context.isInterrupted && !context.isCompleted()) {\n+          if (!reader.next()) {\n+            // Check again, since reader.next() might have blocked through an incoming interrupt.\n+            if (!context.isInterrupted && !context.isCompleted()) {\n+              throw new IllegalStateException(\n+                \"Continuous reader reported no elements! Reader should have blocked waiting.\")\n+            } else {\n+              return\n+            }\n+          }\n+\n+          queue.put(ContinuousRow(reader.get().copy(), baseReader.getOffset))\n+        }\n+      } catch {\n+        case _: InterruptedException if context.isInterrupted() =>\n+          // Continuous shutdown always involves an interrupt; do nothing and shut down quietly.\n+\n+        case t: Throwable =>\n+          failureReason = t\n+          failedFlag.set(true)\n+          // Don't rethrow the exception in this thread. It's not needed, and the default Spark\n+          // exception handler will kill the executor.\n+      } finally {\n+        reader.close()\n+      }\n+    }\n+  }\n+\n+  /**\n+   * The epoch marker component of [[ContinuousQueuedDataReader]]. Populates the queue with\n+   * (null, null) when a new epoch marker arrives.\n+   */\n+  class EpochMarkerGenerator(\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread with Logging {"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "update docs, not (null, null) any more.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T22:51:01Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    override def run(): Unit = {\n+      TaskContext.setTaskContext(context)\n+      val baseReader = ContinuousDataSourceRDD.getBaseReader(reader)\n+      try {\n+        while (!context.isInterrupted && !context.isCompleted()) {\n+          if (!reader.next()) {\n+            // Check again, since reader.next() might have blocked through an incoming interrupt.\n+            if (!context.isInterrupted && !context.isCompleted()) {\n+              throw new IllegalStateException(\n+                \"Continuous reader reported no elements! Reader should have blocked waiting.\")\n+            } else {\n+              return\n+            }\n+          }\n+\n+          queue.put(ContinuousRow(reader.get().copy(), baseReader.getOffset))\n+        }\n+      } catch {\n+        case _: InterruptedException if context.isInterrupted() =>\n+          // Continuous shutdown always involves an interrupt; do nothing and shut down quietly.\n+\n+        case t: Throwable =>\n+          failureReason = t\n+          failedFlag.set(true)\n+          // Don't rethrow the exception in this thread. It's not needed, and the default Spark\n+          // exception handler will kill the executor.\n+      } finally {\n+        reader.close()\n+      }\n+    }\n+  }\n+\n+  /**\n+   * The epoch marker component of [[ContinuousQueuedDataReader]]. Populates the queue with\n+   * (null, null) when a new epoch marker arrives."
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "As I commented above, currentOffset does not need to be exposed at all. ",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T22:59:45Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: data -> Data",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:03:23Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: epoch poll -> Epoch marker generation ",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:03:33Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "maybe worth joining on the dataReaderThread, so that we are sure the thread has terminated?",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:04:28Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This thread is also interrupted when the ContinuousQueuedDataReader is stopped. In that case, it will get an InterruptedException but context.isInterrupted() may not be true. So I think the condition here should just be \r\n`case _: InterruptedException =>`\r\n\r\nAlso, log this with info level.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:07:23Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    override def run(): Unit = {\n+      TaskContext.setTaskContext(context)\n+      val baseReader = ContinuousDataSourceRDD.getBaseReader(reader)\n+      try {\n+        while (!context.isInterrupted && !context.isCompleted()) {\n+          if (!reader.next()) {\n+            // Check again, since reader.next() might have blocked through an incoming interrupt.\n+            if (!context.isInterrupted && !context.isCompleted()) {\n+              throw new IllegalStateException(\n+                \"Continuous reader reported no elements! Reader should have blocked waiting.\")\n+            } else {\n+              return\n+            }\n+          }\n+\n+          queue.put(ContinuousRow(reader.get().copy(), baseReader.getOffset))\n+        }\n+      } catch {\n+        case _: InterruptedException if context.isInterrupted() =>\n+          // Continuous shutdown always involves an interrupt; do nothing and shut down quietly."
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "It's not okay catch and ignore all throwables. E.g. OOMs should NEVER be ignored as it leads absolutely unexpected situations.\r\n\r\nAt best, you can catch `NonFatal(ex)` and ignore those (only after logging as a warning). For other throwables, log as a warning, and rethrow.\r\n\r\n\r\n",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:11:02Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    override def run(): Unit = {\n+      TaskContext.setTaskContext(context)\n+      val baseReader = ContinuousDataSourceRDD.getBaseReader(reader)\n+      try {\n+        while (!context.isInterrupted && !context.isCompleted()) {\n+          if (!reader.next()) {\n+            // Check again, since reader.next() might have blocked through an incoming interrupt.\n+            if (!context.isInterrupted && !context.isCompleted()) {\n+              throw new IllegalStateException(\n+                \"Continuous reader reported no elements! Reader should have blocked waiting.\")\n+            } else {\n+              return\n+            }\n+          }\n+\n+          queue.put(ContinuousRow(reader.get().copy(), baseReader.getOffset))\n+        }\n+      } catch {\n+        case _: InterruptedException if context.isInterrupted() =>\n+          // Continuous shutdown always involves an interrupt; do nothing and shut down quietly.\n+\n+        case t: Throwable =>\n+          failureReason = t\n+          failedFlag.set(true)\n+          // Don't rethrow the exception in this thread. It's not needed, and the default Spark\n+          // exception handler will kill the executor."
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "log as warning.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:13:34Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    override def run(): Unit = {\n+      TaskContext.setTaskContext(context)\n+      val baseReader = ContinuousDataSourceRDD.getBaseReader(reader)\n+      try {\n+        while (!context.isInterrupted && !context.isCompleted()) {\n+          if (!reader.next()) {\n+            // Check again, since reader.next() might have blocked through an incoming interrupt.\n+            if (!context.isInterrupted && !context.isCompleted()) {\n+              throw new IllegalStateException(\n+                \"Continuous reader reported no elements! Reader should have blocked waiting.\")\n+            } else {\n+              return\n+            }\n+          }\n+\n+          queue.put(ContinuousRow(reader.get().copy(), baseReader.getOffset))\n+        }\n+      } catch {\n+        case _: InterruptedException if context.isInterrupted() =>\n+          // Continuous shutdown always involves an interrupt; do nothing and shut down quietly.\n+\n+        case t: Throwable =>\n+          failureReason = t\n+          failedFlag.set(true)\n+          // Don't rethrow the exception in this thread. It's not needed, and the default Spark\n+          // exception handler will kill the executor.\n+      } finally {\n+        reader.close()\n+      }\n+    }\n+  }\n+\n+  /**\n+   * The epoch marker component of [[ContinuousQueuedDataReader]]. Populates the queue with\n+   * (null, null) when a new epoch marker arrives.\n+   */\n+  class EpochMarkerGenerator(\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread with Logging {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    private val epochEndpoint = EpochCoordinatorRef.get(\n+      context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY), SparkEnv.get)\n+    // Note that this is *not* the same as the currentEpoch in [[ContinuousDataQueuedReader]]! That\n+    // field represents the epoch wrt the data being processed. The currentEpoch here is just a\n+    // counter to ensure we send the appropriate number of markers if we fall behind the driver.\n+    private var currentEpoch = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+    override def run(): Unit = {\n+      try {\n+        val newEpoch = epochEndpoint.askSync[Long](GetCurrentEpoch)\n+        // It's possible to fall more than 1 epoch behind if a GetCurrentEpoch RPC ends up taking\n+        // a while. We catch up by injecting enough epoch markers immediately to catch up. This will\n+        // result in some epochs being empty for this partition, but that's fine.\n+        for (i <- currentEpoch to newEpoch - 1) {\n+          queue.put(EpochMarker)\n+          logDebug(s\"Sent marker to start epoch ${i + 1}\")\n+        }\n+        currentEpoch = newEpoch\n+      } catch {\n+        case t: Throwable =>\n+          failureReason = t",
    "line": 206
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "epochEndpoint -> epochCoordEndpoint",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:15:21Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    override def run(): Unit = {\n+      TaskContext.setTaskContext(context)\n+      val baseReader = ContinuousDataSourceRDD.getBaseReader(reader)\n+      try {\n+        while (!context.isInterrupted && !context.isCompleted()) {\n+          if (!reader.next()) {\n+            // Check again, since reader.next() might have blocked through an incoming interrupt.\n+            if (!context.isInterrupted && !context.isCompleted()) {\n+              throw new IllegalStateException(\n+                \"Continuous reader reported no elements! Reader should have blocked waiting.\")\n+            } else {\n+              return\n+            }\n+          }\n+\n+          queue.put(ContinuousRow(reader.get().copy(), baseReader.getOffset))\n+        }\n+      } catch {\n+        case _: InterruptedException if context.isInterrupted() =>\n+          // Continuous shutdown always involves an interrupt; do nothing and shut down quietly.\n+\n+        case t: Throwable =>\n+          failureReason = t\n+          failedFlag.set(true)\n+          // Don't rethrow the exception in this thread. It's not needed, and the default Spark\n+          // exception handler will kill the executor.\n+      } finally {\n+        reader.close()\n+      }\n+    }\n+  }\n+\n+  /**\n+   * The epoch marker component of [[ContinuousQueuedDataReader]]. Populates the queue with\n+   * (null, null) when a new epoch marker arrives.\n+   */\n+  class EpochMarkerGenerator(\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread with Logging {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    private val epochEndpoint = EpochCoordinatorRef.get("
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "epochPoll -> epochGenerator",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:19:24Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "volatile",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:20:35Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    override def run(): Unit = {\n+      TaskContext.setTaskContext(context)\n+      val baseReader = ContinuousDataSourceRDD.getBaseReader(reader)\n+      try {\n+        while (!context.isInterrupted && !context.isCompleted()) {\n+          if (!reader.next()) {\n+            // Check again, since reader.next() might have blocked through an incoming interrupt.\n+            if (!context.isInterrupted && !context.isCompleted()) {\n+              throw new IllegalStateException(\n+                \"Continuous reader reported no elements! Reader should have blocked waiting.\")\n+            } else {\n+              return\n+            }\n+          }\n+\n+          queue.put(ContinuousRow(reader.get().copy(), baseReader.getOffset))\n+        }\n+      } catch {\n+        case _: InterruptedException if context.isInterrupted() =>\n+          // Continuous shutdown always involves an interrupt; do nothing and shut down quietly.\n+\n+        case t: Throwable =>\n+          failureReason = t\n+          failedFlag.set(true)\n+          // Don't rethrow the exception in this thread. It's not needed, and the default Spark\n+          // exception handler will kill the executor.\n+      } finally {\n+        reader.close()\n+      }\n+    }\n+  }\n+\n+  /**\n+   * The epoch marker component of [[ContinuousQueuedDataReader]]. Populates the queue with\n+   * (null, null) when a new epoch marker arrives.\n+   */\n+  class EpochMarkerGenerator(\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread with Logging {\n+    private[continuous] var failureReason: Throwable = _"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "volatile",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:20:51Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Are these flags really needed? Cant we simply check `dataReader.failureReason != null`?",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:21:39Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "is `currentEpoch` is used any where?",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:22:39Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong"
  }, {
    "author": {
      "login": "jose-torres"
    },
    "body": "yes",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-03T18:46:27Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Mentioned this above, we can simply check `dataReaderThread.failureReason` here instead of having another flag.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:33:12Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "this condition can be deduped into a method with a smaller name like \"shouldStop`.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:34:38Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "why do you need this if you are using the `context` object directly.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-02T23:52:28Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    override def run(): Unit = {\n+      TaskContext.setTaskContext(context)"
  }, {
    "author": {
      "login": "jose-torres"
    },
    "body": "Some user code expects/needs to be able to see the task context.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-03T18:43:23Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    override def run(): Unit = {\n+      TaskContext.setTaskContext(context)"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This condition can be deduped. Mentioned earlier in this class as well.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-03T00:02:36Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    override def run(): Unit = {\n+      TaskContext.setTaskContext(context)\n+      val baseReader = ContinuousDataSourceRDD.getBaseReader(reader)\n+      try {\n+        while (!context.isInterrupted && !context.isCompleted()) {"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "why do you need to pass these, they are available in the enclosing class.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-03T00:04:30Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)\n+    extends Thread(\n+      s\"continuous-reader--${context.partitionId()}--\" +\n+        s\"${context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)}\") {\n+    private[continuous] var failureReason: Throwable = _\n+\n+    override def run(): Unit = {\n+      TaskContext.setTaskContext(context)\n+      val baseReader = ContinuousDataSourceRDD.getBaseReader(reader)\n+      try {\n+        while (!context.isInterrupted && !context.isCompleted()) {\n+          if (!reader.next()) {\n+            // Check again, since reader.next() might have blocked through an incoming interrupt.\n+            if (!context.isInterrupted && !context.isCompleted()) {\n+              throw new IllegalStateException(\n+                \"Continuous reader reported no elements! Reader should have blocked waiting.\")\n+            } else {\n+              return\n+            }\n+          }\n+\n+          queue.put(ContinuousRow(reader.get().copy(), baseReader.getOffset))\n+        }\n+      } catch {\n+        case _: InterruptedException if context.isInterrupted() =>\n+          // Continuous shutdown always involves an interrupt; do nothing and shut down quietly.\n+\n+        case t: Throwable =>\n+          failureReason = t\n+          failedFlag.set(true)\n+          // Don't rethrow the exception in this thread. It's not needed, and the default Spark\n+          // exception handler will kill the executor.\n+      } finally {\n+        reader.close()\n+      }\n+    }\n+  }\n+\n+  /**\n+   * The epoch marker component of [[ContinuousQueuedDataReader]]. Populates the queue with\n+   * (null, null) when a new epoch marker arrives.\n+   */\n+  class EpochMarkerGenerator(\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)"
  }],
  "prId": 21200
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Why do you need to pass these, they are available in the enclosing class.",
    "commit": "75c0b78f924d9c2f70b737c105e6f3cbc85d3b6e",
    "createdAt": "2018-05-03T00:05:18Z",
    "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.continuous\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ArrayBlockingQueue, BlockingQueue, TimeUnit}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import org.apache.spark.{Partition, SparkEnv, SparkException, TaskContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.sources.v2.reader.{DataReader, DataReaderFactory}\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * The record types in a continuous processing buffer.\n+ */\n+sealed trait ContinuousRecord\n+case object EpochMarker extends ContinuousRecord\n+case class ContinuousRow(row: UnsafeRow, offset: PartitionOffset) extends ContinuousRecord\n+\n+/**\n+ * A wrapper for a continuous processing data reader, including a reading queue and epoch markers.\n+ *\n+ * This will be instantiated once per partition - successive calls to compute() in the\n+ * [[ContinuousDataSourceRDD]] will reuse the same reader. This is required to get continuity of\n+ * offsets across epochs.\n+ *\n+ * The RDD is responsible for advancing two fields here, since they need to be updated in line\n+ * with the data flow:\n+ *  * currentOffset - contains the offset of the most recent row which a compute() iterator has sent\n+ *    upwards. The RDD is responsible for advancing this.\n+ *  * currentEpoch - the epoch which is currently occurring. The RDD is responsible for incrementing\n+ *    this before ending the compute() iterator.\n+ */\n+class ContinuousQueuedDataReader(\n+    factory: DataReaderFactory[UnsafeRow],\n+    context: TaskContext,\n+    dataQueueSize: Int,\n+    epochPollIntervalMs: Long) extends Closeable {\n+  private val reader = factory.createDataReader()\n+\n+  // Important sequencing - we must get our starting point before the provider threads start running\n+  var currentOffset: PartitionOffset = ContinuousDataSourceRDD.getBaseReader(reader).getOffset\n+  var currentEpoch: Long = context.getLocalProperty(ContinuousExecution.START_EPOCH_KEY).toLong\n+\n+  private val queue = new ArrayBlockingQueue[ContinuousRecord](dataQueueSize)\n+\n+  private val epochPollFailed = new AtomicBoolean(false)\n+  private val dataReaderFailed = new AtomicBoolean(false)\n+\n+  private val coordinatorId = context.getLocalProperty(ContinuousExecution.EPOCH_COORDINATOR_ID_KEY)\n+\n+  private val epochMarkerExecutor = ThreadUtils.newDaemonSingleThreadScheduledExecutor(\n+    s\"epoch-poll--$coordinatorId--${context.partitionId()}\")\n+  private val epochMarkerGenerator = new EpochMarkerGenerator(queue, context, epochPollFailed)\n+  epochMarkerExecutor.scheduleWithFixedDelay(\n+    epochMarkerGenerator, 0, epochPollIntervalMs, TimeUnit.MILLISECONDS)\n+\n+  private val dataReaderThread = new DataReaderThread(reader, queue, context, dataReaderFailed)\n+  dataReaderThread.setDaemon(true)\n+  dataReaderThread.start()\n+\n+  context.addTaskCompletionListener(_ => {\n+    this.close()\n+  })\n+\n+  def next(): ContinuousRecord = {\n+    val POLL_TIMEOUT_MS = 1000\n+    var currentEntry: ContinuousRecord = null\n+\n+    while (currentEntry == null) {\n+      if (context.isInterrupted() || context.isCompleted()) {\n+        // Force the epoch to end here. The writer will notice the context is interrupted\n+        // or completed and not start a new one. This makes it possible to achieve clean\n+        // shutdown of the streaming query.\n+        // TODO: The obvious generalization of this logic to multiple stages won't work. It's\n+        // invalid to send an epoch marker from the bottom of a task if all its child tasks\n+        // haven't sent one.\n+        currentEntry = EpochMarker\n+      } else {\n+        if (dataReaderFailed.get()) {\n+          throw new SparkException(\"data read failed\", dataReaderThread.failureReason)\n+        }\n+        if (epochPollFailed.get()) {\n+          throw new SparkException(\"epoch poll failed\", epochMarkerGenerator.failureReason)\n+        }\n+        currentEntry = queue.poll(POLL_TIMEOUT_MS, TimeUnit.MILLISECONDS)\n+      }\n+    }\n+\n+    currentEntry\n+  }\n+\n+  override def close(): Unit = {\n+    dataReaderThread.interrupt()\n+    epochMarkerExecutor.shutdown()\n+  }\n+\n+  /**\n+   * The data component of [[ContinuousQueuedDataReader]]. Pushes (row, offset) to the queue when\n+   * a new row arrives to the [[DataReader]].\n+   */\n+  class DataReaderThread(\n+      reader: DataReader[UnsafeRow],\n+      queue: BlockingQueue[ContinuousRecord],\n+      context: TaskContext,\n+      failedFlag: AtomicBoolean)"
  }],
  "prId": 21200
}]