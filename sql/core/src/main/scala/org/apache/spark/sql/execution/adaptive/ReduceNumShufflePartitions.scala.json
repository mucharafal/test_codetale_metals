[{
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "Do not remove this line.",
    "commit": "9c1dc5538afce26c4e693e353d8d4ef4231bb78c",
    "createdAt": "2019-07-30T05:12:38Z",
    "diffHunk": "@@ -19,15 +19,14 @@ package org.apache.spark.sql.execution.adaptive.rule\n \n import scala.collection.mutable.ArrayBuffer\n import scala.concurrent.duration.Duration\n-"
  }, {
    "author": {
      "login": "JkSelf"
    },
    "body": "updated.",
    "commit": "9c1dc5538afce26c4e693e353d8d4ef4231bb78c",
    "createdAt": "2019-08-05T05:37:10Z",
    "diffHunk": "@@ -19,15 +19,14 @@ package org.apache.spark.sql.execution.adaptive.rule\n \n import scala.collection.mutable.ArrayBuffer\n import scala.concurrent.duration.Duration\n-"
  }],
  "prId": 25295
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "`ReduceNumShufflePartitions` and local shuffle reader are two different optimizations, and they are conflicting:\r\n`ReduceNumShufflePartitions` adjusts the numPartitions by assuming the partitions are post-shuffle partitions. Their data size depends on the shuffle blocks they need to read. If we change the shuffle to local shuffle reader, then the partitions become pre-shuffle partitions, and their data size is different.",
    "commit": "9c1dc5538afce26c4e693e353d8d4ef4231bb78c",
    "createdAt": "2019-09-11T12:55:12Z",
    "diffHunk": "@@ -180,25 +180,45 @@ case class ReduceNumShufflePartitions(conf: SQLConf) extends Rule[SparkPlan] {\n \n case class CoalescedShuffleReaderExec(\n     child: QueryStageExec,\n-    partitionStartIndices: Array[Int]) extends UnaryExecNode {\n+    partitionStartIndices: Array[Int],\n+    var isLocal: Boolean = false) extends UnaryExecNode {"
  }, {
    "author": {
      "login": "JkSelf"
    },
    "body": "`If we change the shuffle to local shuffle reader, then the partitions become pre-shuffle partitions, and their data size is different.`\r\n@cloud-fan Here the local shuffle reader is still optimize the post-shuffle partitions. And I don't understand why the partitions become pre-shuffle partitions?",
    "commit": "9c1dc5538afce26c4e693e353d8d4ef4231bb78c",
    "createdAt": "2019-09-12T02:40:09Z",
    "diffHunk": "@@ -180,25 +180,45 @@ case class ReduceNumShufflePartitions(conf: SQLConf) extends Rule[SparkPlan] {\n \n case class CoalescedShuffleReaderExec(\n     child: QueryStageExec,\n-    partitionStartIndices: Array[Int]) extends UnaryExecNode {\n+    partitionStartIndices: Array[Int],\n+    var isLocal: Boolean = false) extends UnaryExecNode {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "without local shuffle reader, a task of `ShuffledRDD` reads the shuffle blocks `map1-reduce1`, `map2-reduce1`, etc. With local shuffle reader, the task reads `map1-reduce1`, `map1-reduce2`, etc. The task output data size is different and we can't use the algorithm in `ReduceNumShufflePartitions` anymore.\r\n\r\nFurthermore, the RDD numPartitions also becomes different after switching to local shuffle reader, how can we apply the `ReduceNumShufflePartitions`?",
    "commit": "9c1dc5538afce26c4e693e353d8d4ef4231bb78c",
    "createdAt": "2019-09-12T08:11:30Z",
    "diffHunk": "@@ -180,25 +180,45 @@ case class ReduceNumShufflePartitions(conf: SQLConf) extends Rule[SparkPlan] {\n \n case class CoalescedShuffleReaderExec(\n     child: QueryStageExec,\n-    partitionStartIndices: Array[Int]) extends UnaryExecNode {\n+    partitionStartIndices: Array[Int],\n+    var isLocal: Boolean = false) extends UnaryExecNode {"
  }, {
    "author": {
      "login": "JkSelf"
    },
    "body": "Ok, Got it. In order to make code more clear, I will create `LocalShuffleReaderExec` later. Thanks.",
    "commit": "9c1dc5538afce26c4e693e353d8d4ef4231bb78c",
    "createdAt": "2019-09-16T03:05:58Z",
    "diffHunk": "@@ -180,25 +180,45 @@ case class ReduceNumShufflePartitions(conf: SQLConf) extends Rule[SparkPlan] {\n \n case class CoalescedShuffleReaderExec(\n     child: QueryStageExec,\n-    partitionStartIndices: Array[Int]) extends UnaryExecNode {\n+    partitionStartIndices: Array[Int],\n+    var isLocal: Boolean = false) extends UnaryExecNode {"
  }],
  "prId": 25295
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Don't we need to override requiredChildDistribution, if isLocal is true?\r\n\r\nI saw you check if there are additional shuffle exchange added by EnsureRequirements, to decide if local shuffle reader works or not. If don't change requiredChildDistribution, will EnsureRequirements bring additional shuffle exchange?\r\n\r\nMaybe I miss anything here?\r\n",
    "commit": "9c1dc5538afce26c4e693e353d8d4ef4231bb78c",
    "createdAt": "2019-09-11T20:47:53Z",
    "diffHunk": "@@ -180,25 +180,45 @@ case class ReduceNumShufflePartitions(conf: SQLConf) extends Rule[SparkPlan] {\n \n case class CoalescedShuffleReaderExec(\n     child: QueryStageExec,\n-    partitionStartIndices: Array[Int]) extends UnaryExecNode {\n+    partitionStartIndices: Array[Int],\n+    var isLocal: Boolean = false) extends UnaryExecNode {\n \n   override def output: Seq[Attribute] = child.output\n \n   override def doCanonicalize(): SparkPlan = child.canonicalized\n \n   override def outputPartitioning: Partitioning = {"
  }, {
    "author": {
      "login": "JkSelf"
    },
    "body": "@viirya \r\nMaybe not override `requiredChildDistribution`. Because the `requiredChildDistribution` of `CoalescedShuffleReaderExec` is `UnspecificedDistribution` whether the `isLocal ` is `true `or `false`, the `EnsureRequirements ` will not introduce the additional shuffle exchange.",
    "commit": "9c1dc5538afce26c4e693e353d8d4ef4231bb78c",
    "createdAt": "2019-09-12T04:46:37Z",
    "diffHunk": "@@ -180,25 +180,45 @@ case class ReduceNumShufflePartitions(conf: SQLConf) extends Rule[SparkPlan] {\n \n case class CoalescedShuffleReaderExec(\n     child: QueryStageExec,\n-    partitionStartIndices: Array[Int]) extends UnaryExecNode {\n+    partitionStartIndices: Array[Int],\n+    var isLocal: Boolean = false) extends UnaryExecNode {\n \n   override def output: Seq[Attribute] = child.output\n \n   override def doCanonicalize(): SparkPlan = child.canonicalized\n \n   override def outputPartitioning: Partitioning = {"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Ur, don't you rely on see if EnsureRequirements introduces additional shuffle exchange, to decide doing local shuffle reader or not?",
    "commit": "9c1dc5538afce26c4e693e353d8d4ef4231bb78c",
    "createdAt": "2019-09-12T05:31:28Z",
    "diffHunk": "@@ -180,25 +180,45 @@ case class ReduceNumShufflePartitions(conf: SQLConf) extends Rule[SparkPlan] {\n \n case class CoalescedShuffleReaderExec(\n     child: QueryStageExec,\n-    partitionStartIndices: Array[Int]) extends UnaryExecNode {\n+    partitionStartIndices: Array[Int],\n+    var isLocal: Boolean = false) extends UnaryExecNode {\n \n   override def output: Seq[Attribute] = child.output\n \n   override def doCanonicalize(): SparkPlan = child.canonicalized\n \n   override def outputPartitioning: Partitioning = {"
  }, {
    "author": {
      "login": "JkSelf"
    },
    "body": "Yes I need.",
    "commit": "9c1dc5538afce26c4e693e353d8d4ef4231bb78c",
    "createdAt": "2019-09-12T05:38:39Z",
    "diffHunk": "@@ -180,25 +180,45 @@ case class ReduceNumShufflePartitions(conf: SQLConf) extends Rule[SparkPlan] {\n \n case class CoalescedShuffleReaderExec(\n     child: QueryStageExec,\n-    partitionStartIndices: Array[Int]) extends UnaryExecNode {\n+    partitionStartIndices: Array[Int],\n+    var isLocal: Boolean = false) extends UnaryExecNode {\n \n   override def output: Seq[Attribute] = child.output\n \n   override def doCanonicalize(): SparkPlan = child.canonicalized\n \n   override def outputPartitioning: Partitioning = {"
  }],
  "prId": 25295
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "why change this?",
    "commit": "9c1dc5538afce26c4e693e353d8d4ef4231bb78c",
    "createdAt": "2019-10-08T10:08:29Z",
    "diffHunk": "@@ -190,7 +190,7 @@ case class CoalescedShuffleReaderExec(\n     UnknownPartitioning(partitionStartIndices.length)\n   }\n \n-  private var cachedShuffleRDD: ShuffledRowRDD = null\n+  private var cachedShuffleRDD: RDD[InternalRow] = null"
  }],
  "prId": 25295
}]