[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Isn't this the same as using `wait()...notify()`?",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-22T14:05:16Z",
    "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import java.util.concurrent.CountDownLatch\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.execution.{LeafExecNode, SparkPlan, SparkPlanInfo, SQLExecution}\n+import org.apache.spark.sql.execution.ui.SparkListenerSQLAdaptiveExecutionUpdate\n+\n+/**\n+ * A root node to trigger query stages and execute the query plan adaptively. It incrementally\n+ * updates the query plan when a query stage is materialized and provides accurate runtime\n+ * statistics.\n+ */\n+case class AdaptiveSparkPlan(initialPlan: ResultQueryStage, session: SparkSession)\n+  extends LeafExecNode{\n+\n+  override def output: Seq[Attribute] = initialPlan.output\n+\n+  @volatile private var currentQueryStage: QueryStage = initialPlan\n+  @volatile private var error: Throwable = null\n+  private val readyLock = new CountDownLatch(1)"
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "I can answer that myself, the countdown stuff is useful to figure out if the computation has completed. Please add some doc here.",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-22T14:23:07Z",
    "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import java.util.concurrent.CountDownLatch\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.execution.{LeafExecNode, SparkPlan, SparkPlanInfo, SQLExecution}\n+import org.apache.spark.sql.execution.ui.SparkListenerSQLAdaptiveExecutionUpdate\n+\n+/**\n+ * A root node to trigger query stages and execute the query plan adaptively. It incrementally\n+ * updates the query plan when a query stage is materialized and provides accurate runtime\n+ * statistics.\n+ */\n+case class AdaptiveSparkPlan(initialPlan: ResultQueryStage, session: SparkSession)\n+  extends LeafExecNode{\n+\n+  override def output: Seq[Attribute] = initialPlan.output\n+\n+  @volatile private var currentQueryStage: QueryStage = initialPlan\n+  @volatile private var error: Throwable = null\n+  private val readyLock = new CountDownLatch(1)"
  }],
  "prId": 20303
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Use `SparkException`?",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-22T14:15:51Z",
    "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import java.util.concurrent.CountDownLatch\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.execution.{LeafExecNode, SparkPlan, SparkPlanInfo, SQLExecution}\n+import org.apache.spark.sql.execution.ui.SparkListenerSQLAdaptiveExecutionUpdate\n+\n+/**\n+ * A root node to trigger query stages and execute the query plan adaptively. It incrementally\n+ * updates the query plan when a query stage is materialized and provides accurate runtime\n+ * statistics.\n+ */\n+case class AdaptiveSparkPlan(initialPlan: ResultQueryStage, session: SparkSession)\n+  extends LeafExecNode{\n+\n+  override def output: Seq[Attribute] = initialPlan.output\n+\n+  @volatile private var currentQueryStage: QueryStage = initialPlan\n+  @volatile private var error: Throwable = null\n+  private val readyLock = new CountDownLatch(1)\n+\n+  private def replaceStage(oldStage: QueryStage, newStage: QueryStage): QueryStage = {\n+    if (oldStage.id == newStage.id) {\n+      newStage\n+    } else {\n+      val newPlanForOldStage = oldStage.plan.transform {\n+        case q: QueryStage => replaceStage(q, newStage)\n+      }\n+      oldStage.withNewPlan(newPlanForOldStage)\n+    }\n+  }\n+\n+  private def createCallback(executionId: Option[Long]): QueryStageTriggerCallback = {\n+    new QueryStageTriggerCallback {\n+      override def onStageUpdated(stage: QueryStage): Unit = {\n+        updateCurrentQueryStage(stage, executionId)\n+        if (stage.isInstanceOf[ResultQueryStage]) readyLock.countDown()\n+      }\n+\n+      override def onStagePlanningFailed(stage: QueryStage, e: Throwable): Unit = {\n+        error = new RuntimeException("
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Make sense, RuntimeException will kill the whole executor.",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-29T15:47:48Z",
    "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import java.util.concurrent.CountDownLatch\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.execution.{LeafExecNode, SparkPlan, SparkPlanInfo, SQLExecution}\n+import org.apache.spark.sql.execution.ui.SparkListenerSQLAdaptiveExecutionUpdate\n+\n+/**\n+ * A root node to trigger query stages and execute the query plan adaptively. It incrementally\n+ * updates the query plan when a query stage is materialized and provides accurate runtime\n+ * statistics.\n+ */\n+case class AdaptiveSparkPlan(initialPlan: ResultQueryStage, session: SparkSession)\n+  extends LeafExecNode{\n+\n+  override def output: Seq[Attribute] = initialPlan.output\n+\n+  @volatile private var currentQueryStage: QueryStage = initialPlan\n+  @volatile private var error: Throwable = null\n+  private val readyLock = new CountDownLatch(1)\n+\n+  private def replaceStage(oldStage: QueryStage, newStage: QueryStage): QueryStage = {\n+    if (oldStage.id == newStage.id) {\n+      newStage\n+    } else {\n+      val newPlanForOldStage = oldStage.plan.transform {\n+        case q: QueryStage => replaceStage(q, newStage)\n+      }\n+      oldStage.withNewPlan(newPlanForOldStage)\n+    }\n+  }\n+\n+  private def createCallback(executionId: Option[Long]): QueryStageTriggerCallback = {\n+    new QueryStageTriggerCallback {\n+      override def onStageUpdated(stage: QueryStage): Unit = {\n+        updateCurrentQueryStage(stage, executionId)\n+        if (stage.isInstanceOf[ResultQueryStage]) readyLock.countDown()\n+      }\n+\n+      override def onStagePlanningFailed(stage: QueryStage, e: Throwable): Unit = {\n+        error = new RuntimeException("
  }],
  "prId": 20303
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "This is this supposed to recurse twice? Once in the `transform` and once in the `replaceStage`? Would this suffice:\r\n```scala\r\noldStage.plan.transform {\r\n  case q: QueryStage if q.id == newStage.id => newStage\r\n}\r\n```",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-22T14:19:59Z",
    "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import java.util.concurrent.CountDownLatch\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.execution.{LeafExecNode, SparkPlan, SparkPlanInfo, SQLExecution}\n+import org.apache.spark.sql.execution.ui.SparkListenerSQLAdaptiveExecutionUpdate\n+\n+/**\n+ * A root node to trigger query stages and execute the query plan adaptively. It incrementally\n+ * updates the query plan when a query stage is materialized and provides accurate runtime\n+ * statistics.\n+ */\n+case class AdaptiveSparkPlan(initialPlan: ResultQueryStage, session: SparkSession)\n+  extends LeafExecNode{\n+\n+  override def output: Seq[Attribute] = initialPlan.output\n+\n+  @volatile private var currentQueryStage: QueryStage = initialPlan\n+  @volatile private var error: Throwable = null\n+  private val readyLock = new CountDownLatch(1)\n+\n+  private def replaceStage(oldStage: QueryStage, newStage: QueryStage): QueryStage = {\n+    if (oldStage.id == newStage.id) {\n+      newStage\n+    } else {\n+      val newPlanForOldStage = oldStage.plan.transform {"
  }],
  "prId": 20303
}, {
  "comments": [{
    "author": {
      "login": "jerrychenhf"
    },
    "body": "Is finalPlan be called/used concurrently in multiple threads? If yes, the use of readyLock.getCount may cause problem. For example, two thread will both find getCount > 0 and each thread will create a QueryStageCreator before readyLock.countDown is called. ",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-02-15T08:51:43Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import java.util.concurrent.CountDownLatch\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.execution.{LeafExecNode, SparkPlan, SparkPlanInfo, SQLExecution}\n+import org.apache.spark.sql.execution.ui.SparkListenerSQLAdaptiveExecutionUpdate\n+\n+/**\n+ * A root node to execute the query plan adaptively. It creates query stages, and incrementally\n+ * updates the query plan when a query stage is materialized and provides accurate runtime\n+ * data statistics.\n+ */\n+case class AdaptiveSparkPlan(initialPlan: SparkPlan, session: SparkSession)\n+  extends LeafExecNode{\n+\n+  override def output: Seq[Attribute] = initialPlan.output\n+\n+  @volatile private var currentPlan: SparkPlan = initialPlan\n+  @volatile private var error: Throwable = null\n+\n+  // We will release the lock when we finish planning query stages, or we fail to do the planning.\n+  // Getting `resultStage` will be blocked until the lock is release.\n+  // This is better than wait()/notify(), as we can easily check if the computation has completed,\n+  // by calling `readyLock.getCount()`.\n+  private val readyLock = new CountDownLatch(1)\n+\n+  private def createCallback(executionId: Option[Long]): QueryStageCreatorCallback = {\n+    new QueryStageCreatorCallback {\n+      override def onPlanUpdate(updatedPlan: SparkPlan): Unit = {\n+        updateCurrentPlan(updatedPlan, executionId)\n+        if (updatedPlan.isInstanceOf[ResultQueryStage]) readyLock.countDown()\n+      }\n+\n+      override def onStageMaterializingFailed(stage: QueryStage, e: Throwable): Unit = {\n+        error = new SparkException(\n+          s\"\"\"\n+             |Fail to materialize stage ${stage.id}:\n+             |${stage.plan.treeString}\n+           \"\"\".stripMargin, e)\n+        readyLock.countDown()\n+      }\n+\n+      override def onError(e: Throwable): Unit = {\n+        error = e\n+        readyLock.countDown()\n+      }\n+    }\n+  }\n+\n+  private def updateCurrentPlan(newPlan: SparkPlan, executionId: Option[Long]): Unit = {\n+    currentPlan = newPlan\n+    executionId.foreach { id =>\n+      session.sparkContext.listenerBus.post(SparkListenerSQLAdaptiveExecutionUpdate(\n+        id,\n+        SQLExecution.getQueryExecution(id).toString,\n+        SparkPlanInfo.fromSparkPlan(currentPlan)))\n+    }\n+  }\n+\n+  def finalPlan: ResultQueryStage = {\n+    if (readyLock.getCount > 0) {"
  }, {
    "author": {
      "login": "carsonwang"
    },
    "body": "It should only be called in a single thread. @cloud-fan may confirm it.",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-02-25T08:45:10Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import java.util.concurrent.CountDownLatch\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.sql.execution.{LeafExecNode, SparkPlan, SparkPlanInfo, SQLExecution}\n+import org.apache.spark.sql.execution.ui.SparkListenerSQLAdaptiveExecutionUpdate\n+\n+/**\n+ * A root node to execute the query plan adaptively. It creates query stages, and incrementally\n+ * updates the query plan when a query stage is materialized and provides accurate runtime\n+ * data statistics.\n+ */\n+case class AdaptiveSparkPlan(initialPlan: SparkPlan, session: SparkSession)\n+  extends LeafExecNode{\n+\n+  override def output: Seq[Attribute] = initialPlan.output\n+\n+  @volatile private var currentPlan: SparkPlan = initialPlan\n+  @volatile private var error: Throwable = null\n+\n+  // We will release the lock when we finish planning query stages, or we fail to do the planning.\n+  // Getting `resultStage` will be blocked until the lock is release.\n+  // This is better than wait()/notify(), as we can easily check if the computation has completed,\n+  // by calling `readyLock.getCount()`.\n+  private val readyLock = new CountDownLatch(1)\n+\n+  private def createCallback(executionId: Option[Long]): QueryStageCreatorCallback = {\n+    new QueryStageCreatorCallback {\n+      override def onPlanUpdate(updatedPlan: SparkPlan): Unit = {\n+        updateCurrentPlan(updatedPlan, executionId)\n+        if (updatedPlan.isInstanceOf[ResultQueryStage]) readyLock.countDown()\n+      }\n+\n+      override def onStageMaterializingFailed(stage: QueryStage, e: Throwable): Unit = {\n+        error = new SparkException(\n+          s\"\"\"\n+             |Fail to materialize stage ${stage.id}:\n+             |${stage.plan.treeString}\n+           \"\"\".stripMargin, e)\n+        readyLock.countDown()\n+      }\n+\n+      override def onError(e: Throwable): Unit = {\n+        error = e\n+        readyLock.countDown()\n+      }\n+    }\n+  }\n+\n+  private def updateCurrentPlan(newPlan: SparkPlan, executionId: Option[Long]): Unit = {\n+    currentPlan = newPlan\n+    executionId.foreach { id =>\n+      session.sparkContext.listenerBus.post(SparkListenerSQLAdaptiveExecutionUpdate(\n+        id,\n+        SQLExecution.getQueryExecution(id).toString,\n+        SparkPlanInfo.fromSparkPlan(currentPlan)))\n+    }\n+  }\n+\n+  def finalPlan: ResultQueryStage = {\n+    if (readyLock.getCount > 0) {"
  }],
  "prId": 20303
}]