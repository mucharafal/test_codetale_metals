[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "is this really a `RunningExecutionTable` if it shows everything? Maybe this should be `AllExecutionsTable` or something\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-02T05:58:40Z",
    "diffHunk": "@@ -0,0 +1,230 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.ui.{UIUtils, WebUIPage}\n+\n+private[ui] class AllExecutionsPage(parent: SQLTab) extends WebUIPage(\"\") with Logging {\n+\n+  private val listener = parent.listener\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val currentTime = System.currentTimeMillis()\n+    val content = listener.synchronized {\n+      var _content: Seq[Node] = Nil\n+      if (listener.getRunningExecutions.nonEmpty) {\n+        _content ++=\n+          new RunningExecutionTable(\n+            parent, \"Running Queries\", currentTime,\n+            listener.getRunningExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      if (listener.getCompletedExecutions.nonEmpty) {\n+        _content ++=\n+          new CompletedExecutionTable(\n+            parent, \"Completed Queries\", currentTime,\n+            listener.getCompletedExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      if (listener.getFailedExecutions.nonEmpty) {\n+        _content ++=\n+          new FailedExecutionTable(\n+            parent, \"Failed Queries\", currentTime,\n+            listener.getFailedExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      _content\n+    }\n+    UIUtils.headerSparkPage(\"SQL\", content, parent, Some(5000))\n+  }\n+}\n+\n+private[ui] abstract class ExecutionTable(\n+    parent: SQLTab,\n+    tableName: String,\n+    currentTime: Long,\n+    executionUIDatas: Seq[SparkSQLExecutionUIData],\n+    showRunningJobs: Boolean,\n+    showSucceededJobs: Boolean,\n+    showFailedJobs: Boolean) {\n+\n+  protected def baseHeader: Seq[String] = Seq(\n+    \"ID\",\n+    \"Description\",\n+    \"Submitted\",\n+    \"Duration\")\n+\n+  protected def header: Seq[String]\n+\n+  protected def row(currentTime: Long, executionUIData: SparkSQLExecutionUIData): Seq[Node] = {\n+    val submissionTime = executionUIData.submissionTime\n+    val duration = executionUIData.completionTime.getOrElse(currentTime) - submissionTime\n+\n+    val runningJobs = executionUIData.runningJobs.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    val succeededJobs = executionUIData.succeededJobs.sorted.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    val failedJobs = executionUIData.failedJobs.sorted.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    <tr>\n+      <td>\n+        {executionUIData.executionId.toString}\n+      </td>\n+      <td>\n+        {descriptionCell(executionUIData)}\n+      </td>\n+      <td sorttable_customkey={submissionTime.toString}>\n+        {UIUtils.formatDate(submissionTime)}\n+      </td>\n+      <td sorttable_customkey={duration.toString}>\n+        {UIUtils.formatDuration(duration)}\n+      </td>\n+      {if (showRunningJobs) {\n+        <td>\n+          {runningJobs}\n+        </td>\n+      }}\n+      {if (showSucceededJobs) {\n+        <td>\n+          {succeededJobs}\n+        </td>\n+      }}\n+      {if (showFailedJobs) {\n+        <td>\n+          {failedJobs}\n+        </td>\n+      }}\n+      {detailCell(executionUIData.physicalPlanDescription)}\n+    </tr>\n+  }\n+\n+  private def descriptionCell(execution: SparkSQLExecutionUIData): Seq[Node] = {\n+    val details = if (execution.details.nonEmpty) {\n+      <span onclick=\"this.parentNode.querySelector('.stage-details').classList.toggle('collapsed')\"\n+            class=\"expand-details\">\n+        +details\n+      </span> ++\n+      <div class=\"stage-details collapsed\">\n+        <pre>{execution.details}</pre>\n+      </div>\n+    }\n+\n+    val desc = {\n+      <a href={executionURL(execution.executionId)}>{execution.description}</a>\n+    }\n+\n+    <div>{desc} {details}</div>\n+  }\n+\n+  private def detailCell(physicalPlan: String): Seq[Node] = {\n+    val isMultiline = physicalPlan.indexOf('\\n') >= 0\n+    val summary = StringEscapeUtils.escapeHtml4(\n+      if (isMultiline) {\n+        physicalPlan.substring(0, physicalPlan.indexOf('\\n'))\n+      } else {\n+        physicalPlan\n+      })\n+    val details = if (isMultiline) {\n+      // scalastyle:off\n+      <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+            class=\"expand-details\">\n+        + details\n+      </span> ++\n+        <div class=\"stacktrace-details collapsed\">\n+          <pre>{physicalPlan}</pre>\n+        </div>\n+      // scalastyle:on\n+    } else {\n+      \"\"\n+    }\n+    <td>{summary}{details}</td>\n+  }\n+\n+  def toNodeSeq: Seq[Node] = {\n+    <div>\n+      <h4>{tableName}</h4>\n+      {UIUtils.listingTable[SparkSQLExecutionUIData](header, row(currentTime, _), executionUIDatas)}\n+    </div>\n+  }\n+\n+  private def jobURL(jobId: Long): String =\n+    \"%s/jobs/job?id=%s\".format(UIUtils.prependBaseUri(parent.basePath), jobId)\n+\n+  private def executionURL(executionID: Long): String =\n+    \"%s/sql/execution?id=%s\".format(UIUtils.prependBaseUri(parent.basePath), executionID)\n+}\n+\n+private[ui] class RunningExecutionTable(\n+    parent: SQLTab,\n+    tableName: String,\n+    currentTime: Long,\n+    executionUIDatas: Seq[SparkSQLExecutionUIData])\n+  extends ExecutionTable(\n+    parent,\n+    tableName,\n+    currentTime,\n+    executionUIDatas,\n+    showRunningJobs = true,\n+    showSucceededJobs = true,\n+    showFailedJobs = true) {",
    "line": 197
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "> is this really a RunningExecutionTable if it shows everything? Maybe this should be AllExecutionsTable or something\n\nYes. This is a table only for executions that have running jobs. It means the execution is still running.\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T06:20:46Z",
    "diffHunk": "@@ -0,0 +1,230 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.ui.{UIUtils, WebUIPage}\n+\n+private[ui] class AllExecutionsPage(parent: SQLTab) extends WebUIPage(\"\") with Logging {\n+\n+  private val listener = parent.listener\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val currentTime = System.currentTimeMillis()\n+    val content = listener.synchronized {\n+      var _content: Seq[Node] = Nil\n+      if (listener.getRunningExecutions.nonEmpty) {\n+        _content ++=\n+          new RunningExecutionTable(\n+            parent, \"Running Queries\", currentTime,\n+            listener.getRunningExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      if (listener.getCompletedExecutions.nonEmpty) {\n+        _content ++=\n+          new CompletedExecutionTable(\n+            parent, \"Completed Queries\", currentTime,\n+            listener.getCompletedExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      if (listener.getFailedExecutions.nonEmpty) {\n+        _content ++=\n+          new FailedExecutionTable(\n+            parent, \"Failed Queries\", currentTime,\n+            listener.getFailedExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      _content\n+    }\n+    UIUtils.headerSparkPage(\"SQL\", content, parent, Some(5000))\n+  }\n+}\n+\n+private[ui] abstract class ExecutionTable(\n+    parent: SQLTab,\n+    tableName: String,\n+    currentTime: Long,\n+    executionUIDatas: Seq[SparkSQLExecutionUIData],\n+    showRunningJobs: Boolean,\n+    showSucceededJobs: Boolean,\n+    showFailedJobs: Boolean) {\n+\n+  protected def baseHeader: Seq[String] = Seq(\n+    \"ID\",\n+    \"Description\",\n+    \"Submitted\",\n+    \"Duration\")\n+\n+  protected def header: Seq[String]\n+\n+  protected def row(currentTime: Long, executionUIData: SparkSQLExecutionUIData): Seq[Node] = {\n+    val submissionTime = executionUIData.submissionTime\n+    val duration = executionUIData.completionTime.getOrElse(currentTime) - submissionTime\n+\n+    val runningJobs = executionUIData.runningJobs.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    val succeededJobs = executionUIData.succeededJobs.sorted.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    val failedJobs = executionUIData.failedJobs.sorted.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    <tr>\n+      <td>\n+        {executionUIData.executionId.toString}\n+      </td>\n+      <td>\n+        {descriptionCell(executionUIData)}\n+      </td>\n+      <td sorttable_customkey={submissionTime.toString}>\n+        {UIUtils.formatDate(submissionTime)}\n+      </td>\n+      <td sorttable_customkey={duration.toString}>\n+        {UIUtils.formatDuration(duration)}\n+      </td>\n+      {if (showRunningJobs) {\n+        <td>\n+          {runningJobs}\n+        </td>\n+      }}\n+      {if (showSucceededJobs) {\n+        <td>\n+          {succeededJobs}\n+        </td>\n+      }}\n+      {if (showFailedJobs) {\n+        <td>\n+          {failedJobs}\n+        </td>\n+      }}\n+      {detailCell(executionUIData.physicalPlanDescription)}\n+    </tr>\n+  }\n+\n+  private def descriptionCell(execution: SparkSQLExecutionUIData): Seq[Node] = {\n+    val details = if (execution.details.nonEmpty) {\n+      <span onclick=\"this.parentNode.querySelector('.stage-details').classList.toggle('collapsed')\"\n+            class=\"expand-details\">\n+        +details\n+      </span> ++\n+      <div class=\"stage-details collapsed\">\n+        <pre>{execution.details}</pre>\n+      </div>\n+    }\n+\n+    val desc = {\n+      <a href={executionURL(execution.executionId)}>{execution.description}</a>\n+    }\n+\n+    <div>{desc} {details}</div>\n+  }\n+\n+  private def detailCell(physicalPlan: String): Seq[Node] = {\n+    val isMultiline = physicalPlan.indexOf('\\n') >= 0\n+    val summary = StringEscapeUtils.escapeHtml4(\n+      if (isMultiline) {\n+        physicalPlan.substring(0, physicalPlan.indexOf('\\n'))\n+      } else {\n+        physicalPlan\n+      })\n+    val details = if (isMultiline) {\n+      // scalastyle:off\n+      <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+            class=\"expand-details\">\n+        + details\n+      </span> ++\n+        <div class=\"stacktrace-details collapsed\">\n+          <pre>{physicalPlan}</pre>\n+        </div>\n+      // scalastyle:on\n+    } else {\n+      \"\"\n+    }\n+    <td>{summary}{details}</td>\n+  }\n+\n+  def toNodeSeq: Seq[Node] = {\n+    <div>\n+      <h4>{tableName}</h4>\n+      {UIUtils.listingTable[SparkSQLExecutionUIData](header, row(currentTime, _), executionUIDatas)}\n+    </div>\n+  }\n+\n+  private def jobURL(jobId: Long): String =\n+    \"%s/jobs/job?id=%s\".format(UIUtils.prependBaseUri(parent.basePath), jobId)\n+\n+  private def executionURL(executionID: Long): String =\n+    \"%s/sql/execution?id=%s\".format(UIUtils.prependBaseUri(parent.basePath), executionID)\n+}\n+\n+private[ui] class RunningExecutionTable(\n+    parent: SQLTab,\n+    tableName: String,\n+    currentTime: Long,\n+    executionUIDatas: Seq[SparkSQLExecutionUIData])\n+  extends ExecutionTable(\n+    parent,\n+    tableName,\n+    currentTime,\n+    executionUIDatas,\n+    showRunningJobs = true,\n+    showSucceededJobs = true,\n+    showFailedJobs = true) {",
    "line": 197
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "oh I see, it shows failed jobs not failed executions.\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T20:54:51Z",
    "diffHunk": "@@ -0,0 +1,230 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.ui.{UIUtils, WebUIPage}\n+\n+private[ui] class AllExecutionsPage(parent: SQLTab) extends WebUIPage(\"\") with Logging {\n+\n+  private val listener = parent.listener\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val currentTime = System.currentTimeMillis()\n+    val content = listener.synchronized {\n+      var _content: Seq[Node] = Nil\n+      if (listener.getRunningExecutions.nonEmpty) {\n+        _content ++=\n+          new RunningExecutionTable(\n+            parent, \"Running Queries\", currentTime,\n+            listener.getRunningExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      if (listener.getCompletedExecutions.nonEmpty) {\n+        _content ++=\n+          new CompletedExecutionTable(\n+            parent, \"Completed Queries\", currentTime,\n+            listener.getCompletedExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      if (listener.getFailedExecutions.nonEmpty) {\n+        _content ++=\n+          new FailedExecutionTable(\n+            parent, \"Failed Queries\", currentTime,\n+            listener.getFailedExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      _content\n+    }\n+    UIUtils.headerSparkPage(\"SQL\", content, parent, Some(5000))\n+  }\n+}\n+\n+private[ui] abstract class ExecutionTable(\n+    parent: SQLTab,\n+    tableName: String,\n+    currentTime: Long,\n+    executionUIDatas: Seq[SparkSQLExecutionUIData],\n+    showRunningJobs: Boolean,\n+    showSucceededJobs: Boolean,\n+    showFailedJobs: Boolean) {\n+\n+  protected def baseHeader: Seq[String] = Seq(\n+    \"ID\",\n+    \"Description\",\n+    \"Submitted\",\n+    \"Duration\")\n+\n+  protected def header: Seq[String]\n+\n+  protected def row(currentTime: Long, executionUIData: SparkSQLExecutionUIData): Seq[Node] = {\n+    val submissionTime = executionUIData.submissionTime\n+    val duration = executionUIData.completionTime.getOrElse(currentTime) - submissionTime\n+\n+    val runningJobs = executionUIData.runningJobs.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    val succeededJobs = executionUIData.succeededJobs.sorted.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    val failedJobs = executionUIData.failedJobs.sorted.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    <tr>\n+      <td>\n+        {executionUIData.executionId.toString}\n+      </td>\n+      <td>\n+        {descriptionCell(executionUIData)}\n+      </td>\n+      <td sorttable_customkey={submissionTime.toString}>\n+        {UIUtils.formatDate(submissionTime)}\n+      </td>\n+      <td sorttable_customkey={duration.toString}>\n+        {UIUtils.formatDuration(duration)}\n+      </td>\n+      {if (showRunningJobs) {\n+        <td>\n+          {runningJobs}\n+        </td>\n+      }}\n+      {if (showSucceededJobs) {\n+        <td>\n+          {succeededJobs}\n+        </td>\n+      }}\n+      {if (showFailedJobs) {\n+        <td>\n+          {failedJobs}\n+        </td>\n+      }}\n+      {detailCell(executionUIData.physicalPlanDescription)}\n+    </tr>\n+  }\n+\n+  private def descriptionCell(execution: SparkSQLExecutionUIData): Seq[Node] = {\n+    val details = if (execution.details.nonEmpty) {\n+      <span onclick=\"this.parentNode.querySelector('.stage-details').classList.toggle('collapsed')\"\n+            class=\"expand-details\">\n+        +details\n+      </span> ++\n+      <div class=\"stage-details collapsed\">\n+        <pre>{execution.details}</pre>\n+      </div>\n+    }\n+\n+    val desc = {\n+      <a href={executionURL(execution.executionId)}>{execution.description}</a>\n+    }\n+\n+    <div>{desc} {details}</div>\n+  }\n+\n+  private def detailCell(physicalPlan: String): Seq[Node] = {\n+    val isMultiline = physicalPlan.indexOf('\\n') >= 0\n+    val summary = StringEscapeUtils.escapeHtml4(\n+      if (isMultiline) {\n+        physicalPlan.substring(0, physicalPlan.indexOf('\\n'))\n+      } else {\n+        physicalPlan\n+      })\n+    val details = if (isMultiline) {\n+      // scalastyle:off\n+      <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+            class=\"expand-details\">\n+        + details\n+      </span> ++\n+        <div class=\"stacktrace-details collapsed\">\n+          <pre>{physicalPlan}</pre>\n+        </div>\n+      // scalastyle:on\n+    } else {\n+      \"\"\n+    }\n+    <td>{summary}{details}</td>\n+  }\n+\n+  def toNodeSeq: Seq[Node] = {\n+    <div>\n+      <h4>{tableName}</h4>\n+      {UIUtils.listingTable[SparkSQLExecutionUIData](header, row(currentTime, _), executionUIDatas)}\n+    </div>\n+  }\n+\n+  private def jobURL(jobId: Long): String =\n+    \"%s/jobs/job?id=%s\".format(UIUtils.prependBaseUri(parent.basePath), jobId)\n+\n+  private def executionURL(executionID: Long): String =\n+    \"%s/sql/execution?id=%s\".format(UIUtils.prependBaseUri(parent.basePath), executionID)\n+}\n+\n+private[ui] class RunningExecutionTable(\n+    parent: SQLTab,\n+    tableName: String,\n+    currentTime: Long,\n+    executionUIDatas: Seq[SparkSQLExecutionUIData])\n+  extends ExecutionTable(\n+    parent,\n+    tableName,\n+    currentTime,\n+    executionUIDatas,\n+    showRunningJobs = true,\n+    showSucceededJobs = true,\n+    showFailedJobs = true) {",
    "line": 197
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "`protected override`, in other classes in this file as well\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T20:56:14Z",
    "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.ui.{UIUtils, WebUIPage}\n+\n+private[ui] class AllExecutionsPage(parent: SQLTab) extends WebUIPage(\"\") with Logging {\n+\n+  private val listener = parent.listener\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val currentTime = System.currentTimeMillis()\n+    val content = listener.synchronized {\n+      var _content: Seq[Node] = Nil\n+      if (listener.getRunningExecutions.nonEmpty) {\n+        _content ++=\n+          new RunningExecutionTable(\n+            parent, \"Running Queries\", currentTime,\n+            listener.getRunningExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      if (listener.getCompletedExecutions.nonEmpty) {\n+        _content ++=\n+          new CompletedExecutionTable(\n+            parent, \"Completed Queries\", currentTime,\n+            listener.getCompletedExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      if (listener.getFailedExecutions.nonEmpty) {\n+        _content ++=\n+          new FailedExecutionTable(\n+            parent, \"Failed Queries\", currentTime,\n+            listener.getFailedExecutions.sortBy(_.submissionTime).reverse).toNodeSeq\n+      }\n+      _content\n+    }\n+    UIUtils.headerSparkPage(\"SQL\", content, parent, Some(5000))\n+  }\n+}\n+\n+private[ui] abstract class ExecutionTable(\n+    parent: SQLTab,\n+    tableId: String,\n+    tableName: String,\n+    currentTime: Long,\n+    executionUIDatas: Seq[SQLExecutionUIData],\n+    showRunningJobs: Boolean,\n+    showSucceededJobs: Boolean,\n+    showFailedJobs: Boolean) {\n+\n+  protected def baseHeader: Seq[String] = Seq(\n+    \"ID\",\n+    \"Description\",\n+    \"Submitted\",\n+    \"Duration\")\n+\n+  protected def header: Seq[String]\n+\n+  protected def row(currentTime: Long, executionUIData: SQLExecutionUIData): Seq[Node] = {\n+    val submissionTime = executionUIData.submissionTime\n+    val duration = executionUIData.completionTime.getOrElse(currentTime) - submissionTime\n+\n+    val runningJobs = executionUIData.runningJobs.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    val succeededJobs = executionUIData.succeededJobs.sorted.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    val failedJobs = executionUIData.failedJobs.sorted.map { jobId =>\n+      <a href={jobURL(jobId)}>{jobId.toString}</a><br/>\n+    }\n+    <tr>\n+      <td>\n+        {executionUIData.executionId.toString}\n+      </td>\n+      <td>\n+        {descriptionCell(executionUIData)}\n+      </td>\n+      <td sorttable_customkey={submissionTime.toString}>\n+        {UIUtils.formatDate(submissionTime)}\n+      </td>\n+      <td sorttable_customkey={duration.toString}>\n+        {UIUtils.formatDuration(duration)}\n+      </td>\n+      {if (showRunningJobs) {\n+        <td>\n+          {runningJobs}\n+        </td>\n+      }}\n+      {if (showSucceededJobs) {\n+        <td>\n+          {succeededJobs}\n+        </td>\n+      }}\n+      {if (showFailedJobs) {\n+        <td>\n+          {failedJobs}\n+        </td>\n+      }}\n+      {detailCell(executionUIData.physicalPlanDescription)}\n+    </tr>\n+  }\n+\n+  private def descriptionCell(execution: SQLExecutionUIData): Seq[Node] = {\n+    val details = if (execution.details.nonEmpty) {\n+      <span onclick=\"this.parentNode.querySelector('.stage-details').classList.toggle('collapsed')\"\n+            class=\"expand-details\">\n+        +details\n+      </span> ++\n+      <div class=\"stage-details collapsed\">\n+        <pre>{execution.details}</pre>\n+      </div>\n+    }\n+\n+    val desc = {\n+      <a href={executionURL(execution.executionId)}>{execution.description}</a>\n+    }\n+\n+    <div>{desc} {details}</div>\n+  }\n+\n+  private def detailCell(physicalPlan: String): Seq[Node] = {\n+    val isMultiline = physicalPlan.indexOf('\\n') >= 0\n+    val summary = StringEscapeUtils.escapeHtml4(\n+      if (isMultiline) {\n+        physicalPlan.substring(0, physicalPlan.indexOf('\\n'))\n+      } else {\n+        physicalPlan\n+      })\n+    val details = if (isMultiline) {\n+      // scalastyle:off\n+      <span onclick=\"this.parentNode.querySelector('.stacktrace-details').classList.toggle('collapsed')\"\n+            class=\"expand-details\">\n+        + details\n+      </span> ++\n+        <div class=\"stacktrace-details collapsed\">\n+          <pre>{physicalPlan}</pre>\n+        </div>\n+      // scalastyle:on\n+    } else {\n+      \"\"\n+    }\n+    <td>{summary}{details}</td>\n+  }\n+\n+  def toNodeSeq: Seq[Node] = {\n+    <div>\n+      <h4>{tableName}</h4>\n+      {UIUtils.listingTable[SQLExecutionUIData](\n+        header, row(currentTime, _), executionUIDatas, id = Some(tableId))}\n+    </div>\n+  }\n+\n+  private def jobURL(jobId: Long): String =\n+    \"%s/jobs/job?id=%s\".format(UIUtils.prependBaseUri(parent.basePath), jobId)\n+\n+  private def executionURL(executionID: Long): String =\n+    \"%s/sql/execution?id=%s\".format(UIUtils.prependBaseUri(parent.basePath), executionID)\n+}\n+\n+private[ui] class RunningExecutionTable(\n+    parent: SQLTab,\n+    tableName: String,\n+    currentTime: Long,\n+    executionUIDatas: Seq[SQLExecutionUIData])\n+  extends ExecutionTable(\n+    parent,\n+    \"running-execution-table\",\n+    tableName,\n+    currentTime,\n+    executionUIDatas,\n+    showRunningJobs = true,\n+    showSucceededJobs = true,\n+    showFailedJobs = true) {\n+\n+  protected def header: Seq[String] ="
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "I would make this `val _content: mutable.ListBuffer[Node]` instead to avoid all the copying\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:01:35Z",
    "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import javax.servlet.http.HttpServletRequest\n+\n+import scala.xml.Node\n+\n+import org.apache.commons.lang3.StringEscapeUtils\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.ui.{UIUtils, WebUIPage}\n+\n+private[ui] class AllExecutionsPage(parent: SQLTab) extends WebUIPage(\"\") with Logging {\n+\n+  private val listener = parent.listener\n+\n+  override def render(request: HttpServletRequest): Seq[Node] = {\n+    val currentTime = System.currentTimeMillis()\n+    val content = listener.synchronized {\n+      var _content: Seq[Node] = Nil"
  }],
  "prId": 7774
}]