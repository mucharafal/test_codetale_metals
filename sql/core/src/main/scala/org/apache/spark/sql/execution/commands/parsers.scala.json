[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Can there be more than one location? You could do a direct pattern match, i.e:\n\n```\nval Seq(Token(\"TOK_SKEWED_LOCATIONS\", Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) :: Nil)) = args\n```\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T16:00:28Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "The pattern `unquoteString(cleanIdentifier(...))` is used often. Create a method?\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T16:07:58Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "use `rest`? Is it possible to defer partition parsing until later on?\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T16:38:41Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Some alter table commands have partition spec defined. We should parse it at one place instead of doing this parsing at many places.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-22T07:34:14Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Don't need rename variable. Rest is Nil?\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T16:39:49Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "`rest` here is not alway Nil, it is possibly partition spec for alter table commands. This optional partition spec is after alter table command. Actually as we parse it before here, we don't need to use `rest` to catch it and can ignore it. I will update this.\n\nFor example, `ALTER TABLE table_name PARTITION (dt='2008-08-08', country='us') COMPACT 'MAJOR'` would be represented as tree:\n\n```\nTOK_ALTERTABLE 2, 1, 22, 12 \n:- TOK_TABNAME 2, 5, 5, 12 \n:  +- table_name 2, 5, 5, 12 \n:- TOK_ALTERTABLE_COMPACT 3, 20, 22, 8 \n:  +- 'MAJOR' 3, 22, 22, 8 \n+- TOK_PARTSPEC 2, 7, 18, 34 \n   :- TOK_PARTVAL 2, 10, 12, 34 \n   :  :- dt 2, 10, 10, 34 \n   :  +- '2008-08-08' 2, 12, 12, 37 \n   +- TOK_PARTVAL 2, 15, 17, 51 \n      :- country 2, 15, 15, 51 \n      +- 'us' 2, 17, 17, 59 \n```\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-22T07:37:31Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Rest is Nil? Same goes for every other rest instance....\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T16:40:19Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Yeah, as above. I will update this.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-22T07:37:59Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Map over serdeArgs.tail.headOption?\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T16:45:24Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "We can split out the serdeClassName already.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T16:47:12Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "This seems redundant. We can do this in the initial match.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T16:49:01Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "we know that we are getting 2-3 here: bucketCols, sortCols & numBuckets. We could also change the parse rule and reverse the order in which arguments are passed, i.e. numBucktets before sortCols....\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T16:52:13Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Because that rule `tableBuckets` is used in other places, I'd like not to touch it.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-22T09:34:46Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "cols unzip?\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T16:54:46Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Maybe it is easier to separate the skewed/not-skewed cases here... Why not extract the children, and do a match on those?\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:01:16Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Doesn't the existence of skewedArgs imply the value of notStoredAsDirs?\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:04:22Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Is TOK_IFNOTEXISTS the first of the children when it is defined? Is so we could just pattern match this.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:14:58Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Yes. But it is optional.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-22T07:48:20Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "You are using side effects, foreach is preferred. Is the problem you are trying to solve that partition locations are not nested?\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:18:37Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {",
    "line": 230
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Yes, it is not nested, just a sequence of partition spec and partition location. It looks like `Token(\"TOK_PARTSPEC\", _) :: Token(\"TOK_PARTITIONLOCATION\", _) :: Token(\"TOK_PARTSPEC\", _) :: Token(\"TOK_PARTITIONLOCATION\", _) :: ...`.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-22T07:57:41Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {",
    "line": 230
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Make the match more concise. You are expecting only 1 argument.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:20:01Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "val Some(partition) = parsePartitionSpec(partSpec)\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:21:18Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) =\n+        base.getClauses(Seq(\"TOK_PARTSPEC\", \"TOK_TABNAME\"), args)\n+      val partition = parsePartitionSpec(partSpec).get"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Do we know the sequence in which elements are defined here?\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:21:46Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) ="
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Yes. I will use pattern match here.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-22T08:05:19Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) ="
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Why collect? What else can we expect in DROPPARTS?\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:23:04Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) =\n+        base.getClauses(Seq(\"TOK_PARTSPEC\", \"TOK_TABNAME\"), args)\n+      val partition = parsePartitionSpec(partSpec).get\n+      val fromTableIdent = base.extractTableIdent(fromTable)\n+      AlterTableExchangePartition(tableIdent, fromTableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPARTS\", args) :: rest =>\n+      val parts = args.collect {"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Yes. After a sequence of `TOK_PARTSPEC`, there is an optional `TOK_IFEXISTS`.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-22T08:19:49Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) =\n+        base.getClauses(Seq(\"TOK_PARTSPEC\", \"TOK_TABNAME\"), args)\n+      val partition = parsePartitionSpec(partSpec).get\n+      val fromTableIdent = base.extractTableIdent(fromTable)\n+      AlterTableExchangePartition(tableIdent, fromTableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPARTS\", args) :: rest =>\n+      val parts = args.collect {"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "We could simplify the pattern match, i.e.: \n\n```\ncase Token(\"TOK_REPLICATION\", replId :: metadata) =>\n  (unquoteString(cleanIdentifier(replId.text)), metadata.nonEmpty)\n```\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:39:01Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) =\n+        base.getClauses(Seq(\"TOK_PARTSPEC\", \"TOK_TABNAME\"), args)\n+      val partition = parsePartitionSpec(partSpec).get\n+      val fromTableIdent = base.extractTableIdent(fromTable)\n+      AlterTableExchangePartition(tableIdent, fromTableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPARTS\", args) :: rest =>\n+      val parts = args.collect {\n+        case Token(\"TOK_PARTSPEC\", partitions) =>\n+          partitions.map {\n+            case Token(\"TOK_PARTVAL\", ident :: op :: constant :: Nil) =>\n+              (unquoteString(cleanIdentifier(ident.text)),\n+                op.text, unquoteString(cleanIdentifier(constant.text)))\n+          }\n+      }\n+\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      val purge = base.getClauseOption(\"PURGE\", args)\n+\n+      val replication = base.getClauseOption(\"TOK_REPLICATION\", args).map {"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Make the match more concise. You are expecting only 1 argument.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:40:58Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) =\n+        base.getClauses(Seq(\"TOK_PARTSPEC\", \"TOK_TABNAME\"), args)\n+      val partition = parsePartitionSpec(partSpec).get\n+      val fromTableIdent = base.extractTableIdent(fromTable)\n+      AlterTableExchangePartition(tableIdent, fromTableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPARTS\", args) :: rest =>\n+      val parts = args.collect {\n+        case Token(\"TOK_PARTSPEC\", partitions) =>\n+          partitions.map {\n+            case Token(\"TOK_PARTVAL\", ident :: op :: constant :: Nil) =>\n+              (unquoteString(cleanIdentifier(ident.text)),\n+                op.text, unquoteString(cleanIdentifier(constant.text)))\n+          }\n+      }\n+\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      val purge = base.getClauseOption(\"PURGE\", args)\n+\n+      val replication = base.getClauseOption(\"TOK_REPLICATION\", args).map {\n+        case Token(\"TOK_REPLICATION\", replId :: metadata :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), true)\n+        case Token(\"TOK_REPLICATION\", replId :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), false)\n+      }\n+\n+      AlterTableDropPartition(\n+        tableIdent,\n+        parts,\n+        allowExisting.isDefined,\n+        purge.isDefined,\n+        replication)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ARCHIVE\", args) :: rest =>\n+      val partition = parsePartitionSpec(args(0)).get"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Make the match more concise. You are expecting only 1 argument.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:41:03Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) =\n+        base.getClauses(Seq(\"TOK_PARTSPEC\", \"TOK_TABNAME\"), args)\n+      val partition = parsePartitionSpec(partSpec).get\n+      val fromTableIdent = base.extractTableIdent(fromTable)\n+      AlterTableExchangePartition(tableIdent, fromTableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPARTS\", args) :: rest =>\n+      val parts = args.collect {\n+        case Token(\"TOK_PARTSPEC\", partitions) =>\n+          partitions.map {\n+            case Token(\"TOK_PARTVAL\", ident :: op :: constant :: Nil) =>\n+              (unquoteString(cleanIdentifier(ident.text)),\n+                op.text, unquoteString(cleanIdentifier(constant.text)))\n+          }\n+      }\n+\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      val purge = base.getClauseOption(\"PURGE\", args)\n+\n+      val replication = base.getClauseOption(\"TOK_REPLICATION\", args).map {\n+        case Token(\"TOK_REPLICATION\", replId :: metadata :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), true)\n+        case Token(\"TOK_REPLICATION\", replId :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), false)\n+      }\n+\n+      AlterTableDropPartition(\n+        tableIdent,\n+        parts,\n+        allowExisting.isDefined,\n+        purge.isDefined,\n+        replication)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ARCHIVE\", args) :: rest =>\n+      val partition = parsePartitionSpec(args(0)).get\n+      AlterTableArchivePartition(tableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_UNARCHIVE\", args) :: rest =>\n+      val partition = parsePartitionSpec(args(0)).get"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Are we only expecting a single optional PartSpec?\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T17:46:44Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) =\n+        base.getClauses(Seq(\"TOK_PARTSPEC\", \"TOK_TABNAME\"), args)\n+      val partition = parsePartitionSpec(partSpec).get\n+      val fromTableIdent = base.extractTableIdent(fromTable)\n+      AlterTableExchangePartition(tableIdent, fromTableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPARTS\", args) :: rest =>\n+      val parts = args.collect {\n+        case Token(\"TOK_PARTSPEC\", partitions) =>\n+          partitions.map {\n+            case Token(\"TOK_PARTVAL\", ident :: op :: constant :: Nil) =>\n+              (unquoteString(cleanIdentifier(ident.text)),\n+                op.text, unquoteString(cleanIdentifier(constant.text)))\n+          }\n+      }\n+\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      val purge = base.getClauseOption(\"PURGE\", args)\n+\n+      val replication = base.getClauseOption(\"TOK_REPLICATION\", args).map {\n+        case Token(\"TOK_REPLICATION\", replId :: metadata :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), true)\n+        case Token(\"TOK_REPLICATION\", replId :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), false)\n+      }\n+\n+      AlterTableDropPartition(\n+        tableIdent,\n+        parts,\n+        allowExisting.isDefined,\n+        purge.isDefined,\n+        replication)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ARCHIVE\", args) :: rest =>\n+      val partition = parsePartitionSpec(args(0)).get\n+      AlterTableArchivePartition(tableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_UNARCHIVE\", args) :: rest =>\n+      val partition = parsePartitionSpec(args(0)).get\n+      AlterTableUnarchivePartition(tableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_FILEFORMAT\", args) :: rest =>\n+      val Seq(fileFormat, genericFormat) =\n+        base.getClauses(Seq(\"TOK_TABLEFILEFORMAT\", \"TOK_FILEFORMAT_GENERIC\"),\n+          args)\n+      val fFormat = fileFormat.map(_.children.map(n => unquoteString(cleanIdentifier(n.text))))\n+      val gFormat = genericFormat.map(f => unquoteString(cleanIdentifier(f.children(0).text)))\n+      AlterTableSetFileFormat(tableIdent, partition, fFormat, gFormat)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_LOCATION\", Token(loc, Nil) :: Nil) :: rest =>\n+      AlterTableSetLocation(tableIdent, partition, unquoteString(cleanIdentifier(loc)))(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_TOUCH\", args) :: rest =>\n+      val part = base.getClauseOption(\"TOK_PARTSPEC\", args).flatMap(parsePartitionSpec)"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Yes.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-22T07:25:28Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) =\n+        base.getClauses(Seq(\"TOK_PARTSPEC\", \"TOK_TABNAME\"), args)\n+      val partition = parsePartitionSpec(partSpec).get\n+      val fromTableIdent = base.extractTableIdent(fromTable)\n+      AlterTableExchangePartition(tableIdent, fromTableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPARTS\", args) :: rest =>\n+      val parts = args.collect {\n+        case Token(\"TOK_PARTSPEC\", partitions) =>\n+          partitions.map {\n+            case Token(\"TOK_PARTVAL\", ident :: op :: constant :: Nil) =>\n+              (unquoteString(cleanIdentifier(ident.text)),\n+                op.text, unquoteString(cleanIdentifier(constant.text)))\n+          }\n+      }\n+\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      val purge = base.getClauseOption(\"PURGE\", args)\n+\n+      val replication = base.getClauseOption(\"TOK_REPLICATION\", args).map {\n+        case Token(\"TOK_REPLICATION\", replId :: metadata :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), true)\n+        case Token(\"TOK_REPLICATION\", replId :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), false)\n+      }\n+\n+      AlterTableDropPartition(\n+        tableIdent,\n+        parts,\n+        allowExisting.isDefined,\n+        purge.isDefined,\n+        replication)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ARCHIVE\", args) :: rest =>\n+      val partition = parsePartitionSpec(args(0)).get\n+      AlterTableArchivePartition(tableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_UNARCHIVE\", args) :: rest =>\n+      val partition = parsePartitionSpec(args(0)).get\n+      AlterTableUnarchivePartition(tableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_FILEFORMAT\", args) :: rest =>\n+      val Seq(fileFormat, genericFormat) =\n+        base.getClauses(Seq(\"TOK_TABLEFILEFORMAT\", \"TOK_FILEFORMAT_GENERIC\"),\n+          args)\n+      val fFormat = fileFormat.map(_.children.map(n => unquoteString(cleanIdentifier(n.text))))\n+      val gFormat = genericFormat.map(f => unquoteString(cleanIdentifier(f.children(0).text)))\n+      AlterTableSetFileFormat(tableIdent, partition, fFormat, gFormat)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_LOCATION\", Token(loc, Nil) :: Nil) :: rest =>\n+      AlterTableSetLocation(tableIdent, partition, unquoteString(cleanIdentifier(loc)))(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_TOUCH\", args) :: rest =>\n+      val part = base.getClauseOption(\"TOK_PARTSPEC\", args).flatMap(parsePartitionSpec)"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "We know that at least 3 arguments will be returned... Lets use a pattern match\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T19:03:43Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) =\n+        base.getClauses(Seq(\"TOK_PARTSPEC\", \"TOK_TABNAME\"), args)\n+      val partition = parsePartitionSpec(partSpec).get\n+      val fromTableIdent = base.extractTableIdent(fromTable)\n+      AlterTableExchangePartition(tableIdent, fromTableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPARTS\", args) :: rest =>\n+      val parts = args.collect {\n+        case Token(\"TOK_PARTSPEC\", partitions) =>\n+          partitions.map {\n+            case Token(\"TOK_PARTVAL\", ident :: op :: constant :: Nil) =>\n+              (unquoteString(cleanIdentifier(ident.text)),\n+                op.text, unquoteString(cleanIdentifier(constant.text)))\n+          }\n+      }\n+\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      val purge = base.getClauseOption(\"PURGE\", args)\n+\n+      val replication = base.getClauseOption(\"TOK_REPLICATION\", args).map {\n+        case Token(\"TOK_REPLICATION\", replId :: metadata :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), true)\n+        case Token(\"TOK_REPLICATION\", replId :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), false)\n+      }\n+\n+      AlterTableDropPartition(\n+        tableIdent,\n+        parts,\n+        allowExisting.isDefined,\n+        purge.isDefined,\n+        replication)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ARCHIVE\", args) :: rest =>\n+      val partition = parsePartitionSpec(args(0)).get\n+      AlterTableArchivePartition(tableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_UNARCHIVE\", args) :: rest =>\n+      val partition = parsePartitionSpec(args(0)).get\n+      AlterTableUnarchivePartition(tableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_FILEFORMAT\", args) :: rest =>\n+      val Seq(fileFormat, genericFormat) =\n+        base.getClauses(Seq(\"TOK_TABLEFILEFORMAT\", \"TOK_FILEFORMAT_GENERIC\"),\n+          args)\n+      val fFormat = fileFormat.map(_.children.map(n => unquoteString(cleanIdentifier(n.text))))\n+      val gFormat = genericFormat.map(f => unquoteString(cleanIdentifier(f.children(0).text)))\n+      AlterTableSetFileFormat(tableIdent, partition, fFormat, gFormat)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_LOCATION\", Token(loc, Nil) :: Nil) :: rest =>\n+      AlterTableSetLocation(tableIdent, partition, unquoteString(cleanIdentifier(loc)))(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_TOUCH\", args) :: rest =>\n+      val part = base.getClauseOption(\"TOK_PARTSPEC\", args).flatMap(parsePartitionSpec)\n+      AlterTableTouch(tableIdent, part)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_COMPACT\", Token(compactType, Nil) :: Nil) :: rest =>\n+      AlterTableCompact(tableIdent, partition,\n+        unquoteString(cleanIdentifier(compactType)))(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_MERGEFILES\", _) :: rest =>\n+      AlterTableMerge(tableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMECOL\", args) :: rest =>"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "This code is repeated a few times. We could move this into a separate method.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-02-21T19:04:27Z",
    "diffHunk": "@@ -0,0 +1,420 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.{CatalystQl, PlanParser, TableIdentifier}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, ParserConf, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+case class AlterTableCommandParser(base: CatalystQl) extends PlanParser {\n+\n+  def parsePartitionSpec(node: ASTNode): Option[Map[String, Option[String]]] = {\n+    node match {\n+      case Token(\"TOK_PARTSPEC\", partitions) =>\n+        val spec = partitions.map {\n+          case Token(\"TOK_PARTVAL\", ident :: constant :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)),\n+              Some(unquoteString(cleanIdentifier(constant.text))))\n+          case Token(\"TOK_PARTVAL\", ident :: Nil) =>\n+            (unquoteString(cleanIdentifier(ident.text)), None)\n+        }.toMap\n+        Some(spec)\n+      case _ => None\n+    }\n+  }\n+\n+  def extractTableProps(node: ASTNode): Map[String, Option[String]] = node match {\n+    case Token(\"TOK_TABLEPROPERTIES\", propsList) =>\n+      propsList.flatMap {\n+        case Token(\"TOK_TABLEPROPLIST\", props) =>\n+          props.map {\n+            case Token(\"TOK_TABLEPROPERTY\", key :: Token(\"TOK_NULL\", Nil) :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              (k, None)\n+            case Token(\"TOK_TABLEPROPERTY\", key :: value :: Nil) =>\n+              val k = unquoteString(cleanIdentifier(key.text))\n+              val v = unquoteString(cleanIdentifier(value.text))\n+              (k, Some(v))\n+          }\n+      }.toMap\n+  }\n+\n+  override def isDefinedAt(node: ASTNode): Boolean = node.text == \"TOK_ALTERTABLE\"\n+\n+  override def apply(v1: ASTNode): LogicalPlan = v1.children match {\n+    case (tabName @ Token(\"TOK_TABNAME\", _)) :: rest =>\n+      val tableIdent: TableIdentifier = base.extractTableIdent(tabName)\n+      val partitionSpec = base.getClauseOption(\"TOK_PARTSPEC\", v1.children)\n+      val partition = partitionSpec.flatMap(parsePartitionSpec)\n+      matchAlterTableCommands(v1, rest, tableIdent, partition)\n+    case _ =>\n+      throw new NotImplementedError(v1.text)\n+  }\n+\n+  def matchAlterTableCommands(\n+      node: ASTNode,\n+      nodes: Seq[ASTNode],\n+      tableIdent: TableIdentifier,\n+      partition: Option[Map[String, Option[String]]]): LogicalPlan = nodes match {\n+    case rename @ Token(\"TOK_ALTERTABLE_RENAME\", renameArgs) :: rest =>\n+      val renamedTable = base.getClause(\"TOK_TABNAME\", renameArgs)\n+      val renamedTableIdent: TableIdentifier = base.extractTableIdent(renamedTable)\n+      AlterTableRename(tableIdent, renamedTableIdent)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_PROPERTIES\", args) :: rest =>\n+      val setTableProperties = extractTableProps(args.head)\n+      AlterTableSetProperties(\n+        tableIdent,\n+        setTableProperties)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPROPERTIES\", args) :: rest =>\n+      val dropTableProperties = extractTableProps(args.head)\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      AlterTableDropProperties(\n+        tableIdent,\n+        dropTableProperties, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERIALIZER\", serdeArgs) :: rest =>\n+      val serdeClassName = unquoteString(cleanIdentifier(serdeArgs.head.text))\n+\n+      val serdeProperties: Option[Map[String, Option[String]]] = Option(\n+        // SET SERDE serde_classname WITH SERDEPROPERTIES\n+        if (serdeArgs.tail.isEmpty) {\n+          null\n+        } else {\n+          extractTableProps(serdeArgs.tail.head)\n+        }\n+      )\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        Some(serdeClassName),\n+        serdeProperties,\n+        partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_SERDEPROPERTIES\", args) :: rest =>\n+      val serdeProperties: Map[String, Option[String]] = extractTableProps(args.head)\n+\n+      AlterTableSerDeProperties(\n+        tableIdent,\n+        None,\n+        Some(serdeProperties),\n+        partition)(node.source)\n+\n+    case (bucketSpec @ Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", _)) :: rest =>\n+      val (buckets, noClustered, noSorted) = bucketSpec match {\n+        case Token(\"TOK_ALTERTABLE_CLUSTER_SORT\", clusterAndSoryByArgs :: Nil) =>\n+          clusterAndSoryByArgs match {\n+              case Token(\"TOK_ALTERTABLE_BUCKETS\", bucketArgs) =>\n+                val bucketCols = bucketArgs.head.children.map(_.text)\n+\n+                val (sortCols, sortDirections, numBuckets) = {\n+                  if (bucketArgs(1).text == \"TOK_TABCOLNAME\") {\n+                    val cols = bucketArgs(1).children.map {\n+                      case Token(\"TOK_TABSORTCOLNAMEASC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Ascending)\n+                      case Token(\"TOK_TABSORTCOLNAMEDESC\", Token(colName, Nil) :: Nil) =>\n+                        (colName, Descending)\n+                    }\n+                    (cols.map(_._1), cols.map(_._2), bucketArgs(2).text.toInt)\n+                  } else {\n+                    (Nil, Nil, bucketArgs(1).text.toInt)\n+                  }\n+                }\n+\n+                (Some(BucketSpec(numBuckets, bucketCols, sortCols, sortDirections)),\n+                  false, false)\n+              case Token(\"TOK_NOT_CLUSTERED\", Nil) =>\n+                (None, true, false)\n+              case Token(\"TOK_NOT_SORTED\", Nil) =>\n+                (None, false, true)\n+          }\n+      }\n+\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        noClustered,\n+        noSorted)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_BUCKETS\", Token(bucketNum, Nil) :: Nil) :: rest =>\n+      val num = bucketNum.toInt\n+      val buckets = Some(BucketSpec(num, Nil, Nil, Nil))\n+      AlterTableStoreProperties(\n+        tableIdent,\n+        buckets,\n+        false,\n+        false)(node.source)\n+\n+    case (tableSkewed @ Token(\"TOK_ALTERTABLE_SKEWED\", _)) :: rest =>\n+      // Alter Table not skewed\n+      // Token(\"TOK_ALTERTABLE_SKEWED\", Nil) means not skewed.\n+      val notSkewed = if (tableSkewed.children.size == 0) {\n+        true\n+      } else {\n+        false\n+      }\n+\n+      val (notStoredAsDirs, skewedArgs) = tableSkewed match {\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", Token(\"TOK_STOREDASDIRS\", Nil) :: Nil) =>\n+          // Alter Table not stored as directories\n+          (true, None)\n+        case Token(\"TOK_ALTERTABLE_SKEWED\", skewedArgs :: Nil) =>\n+          val (cols, values, storedAsDirs) = skewedArgs match {\n+            case Token(\"TOK_TABLESKEWED\", skewedCols :: skewedValues :: stored) =>\n+              val cols = skewedCols.children.map(n => unquoteString(cleanIdentifier(n.text)))\n+              val values = skewedValues match {\n+                case Token(\"TOK_TABCOLVALUE\", values) =>\n+                  Seq(values.map(n => unquoteString(cleanIdentifier(n.text))))\n+                case Token(\"TOK_TABCOLVALUE_PAIR\", pairs) =>\n+                  pairs.map {\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+              }\n+\n+              val storedAsDirs = stored match {\n+                case Token(\"TOK_STOREDASDIRS\", Nil) :: Nil => true\n+                case _ => false\n+              }\n+\n+              (cols, values, storedAsDirs)\n+          }\n+          (false, Some((cols, values, storedAsDirs)))\n+      }\n+\n+      if (skewedArgs.isDefined) {\n+        AlterTableSkewed(\n+          tableIdent,\n+          skewedArgs.get._1, /* cols */\n+          skewedArgs.get._2, /* values */\n+          skewedArgs.get._3, /* storedAsDirs */\n+          notSkewed, notStoredAsDirs)(node.source)\n+      } else {\n+        AlterTableSkewed(tableIdent, Nil, Nil, false, notSkewed, notStoredAsDirs)(node.source)\n+      }\n+\n+    case Token(\"TOK_ALTERTABLE_SKEWED_LOCATION\", args) :: rest =>\n+      val skewedMaps = args(0) match {\n+        case Token(\"TOK_SKEWED_LOCATIONS\", locationList :: Nil) =>\n+          locationList match {\n+            case Token(\"TOK_SKEWED_LOCATION_LIST\", locationMaps) =>\n+              locationMaps.map {\n+                case Token(\"TOK_SKEWED_LOCATION_MAP\", key :: value :: Nil) =>\n+                  val k = key match {\n+                    case Token(const, Nil) => Seq(unquoteString(cleanIdentifier(const)))\n+                    case Token(\"TOK_TABCOLVALUES\", values :: Nil) =>\n+                      values match {\n+                        case Token(\"TOK_TABCOLVALUE\", vals) =>\n+                          vals.map(n => unquoteString(cleanIdentifier(n.text)))\n+                      }\n+                  }\n+                  (k, unquoteString(cleanIdentifier(value.text)))\n+              }.toMap\n+          }\n+      }\n+      AlterTableSkewedLocation(tableIdent, skewedMaps)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ADDPARTS\", addPartsArgs) :: rest =>\n+      val allowExisting = base.getClauseOption(\"TOK_IFNOTEXISTS\", addPartsArgs)\n+      val parts = if (allowExisting.isDefined) {\n+        addPartsArgs.tail\n+      } else {\n+        addPartsArgs\n+      }\n+\n+      val partitions: ArrayBuffer[(Map[String, Option[String]], Option[String])] =\n+        new ArrayBuffer()\n+      var currentPart: Map[String, Option[String]] = null\n+      parts.map {\n+        case t @ Token(\"TOK_PARTSPEC\", partArgs) =>\n+          if (currentPart != null) {\n+            partitions += ((currentPart, None))\n+          }\n+          currentPart = parsePartitionSpec(t).get\n+        case Token(\"TOK_PARTITIONLOCATION\", loc :: Nil) =>\n+          val location = unquoteString(loc.text)\n+          if (currentPart != null) {\n+            partitions += ((currentPart, Some(location)))\n+            currentPart = null\n+          } else {\n+            // We should not reach here\n+            throw new AnalysisException(\"Partition location must follow a partition spec.\")\n+          }\n+      }\n+\n+      if (currentPart != null) {\n+        partitions += ((currentPart, None))\n+      }\n+      AlterTableAddPartition(tableIdent, partitions, allowExisting.isDefined)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMEPART\", args) :: rest =>\n+      val newPartition = parsePartitionSpec(args(0))\n+      AlterTableRenamePartition(tableIdent, partition.get, newPartition.get)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_EXCHANGEPARTITION\", args) :: rest =>\n+      val Seq(Some(partSpec), Some(fromTable)) =\n+        base.getClauses(Seq(\"TOK_PARTSPEC\", \"TOK_TABNAME\"), args)\n+      val partition = parsePartitionSpec(partSpec).get\n+      val fromTableIdent = base.extractTableIdent(fromTable)\n+      AlterTableExchangePartition(tableIdent, fromTableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_DROPPARTS\", args) :: rest =>\n+      val parts = args.collect {\n+        case Token(\"TOK_PARTSPEC\", partitions) =>\n+          partitions.map {\n+            case Token(\"TOK_PARTVAL\", ident :: op :: constant :: Nil) =>\n+              (unquoteString(cleanIdentifier(ident.text)),\n+                op.text, unquoteString(cleanIdentifier(constant.text)))\n+          }\n+      }\n+\n+      val allowExisting = base.getClauseOption(\"TOK_IFEXISTS\", args)\n+      val purge = base.getClauseOption(\"PURGE\", args)\n+\n+      val replication = base.getClauseOption(\"TOK_REPLICATION\", args).map {\n+        case Token(\"TOK_REPLICATION\", replId :: metadata :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), true)\n+        case Token(\"TOK_REPLICATION\", replId :: Nil) =>\n+          (unquoteString(cleanIdentifier(replId.text)), false)\n+      }\n+\n+      AlterTableDropPartition(\n+        tableIdent,\n+        parts,\n+        allowExisting.isDefined,\n+        purge.isDefined,\n+        replication)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_ARCHIVE\", args) :: rest =>\n+      val partition = parsePartitionSpec(args(0)).get\n+      AlterTableArchivePartition(tableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_UNARCHIVE\", args) :: rest =>\n+      val partition = parsePartitionSpec(args(0)).get\n+      AlterTableUnarchivePartition(tableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_FILEFORMAT\", args) :: rest =>\n+      val Seq(fileFormat, genericFormat) =\n+        base.getClauses(Seq(\"TOK_TABLEFILEFORMAT\", \"TOK_FILEFORMAT_GENERIC\"),\n+          args)\n+      val fFormat = fileFormat.map(_.children.map(n => unquoteString(cleanIdentifier(n.text))))\n+      val gFormat = genericFormat.map(f => unquoteString(cleanIdentifier(f.children(0).text)))\n+      AlterTableSetFileFormat(tableIdent, partition, fFormat, gFormat)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_LOCATION\", Token(loc, Nil) :: Nil) :: rest =>\n+      AlterTableSetLocation(tableIdent, partition, unquoteString(cleanIdentifier(loc)))(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_TOUCH\", args) :: rest =>\n+      val part = base.getClauseOption(\"TOK_PARTSPEC\", args).flatMap(parsePartitionSpec)\n+      AlterTableTouch(tableIdent, part)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_COMPACT\", Token(compactType, Nil) :: Nil) :: rest =>\n+      AlterTableCompact(tableIdent, partition,\n+        unquoteString(cleanIdentifier(compactType)))(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_MERGEFILES\", _) :: rest =>\n+      AlterTableMerge(tableIdent, partition)(node.source)\n+\n+    case Token(\"TOK_ALTERTABLE_RENAMECOL\", args) :: rest =>\n+      val oldName = args(0).text\n+      val newName = args(1).text\n+      val dataType = base.nodeToDataType(args(2))\n+      val afterPos =\n+        base.getClauseOption(\"TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION\", args)\n+      val afterPosCol = afterPos.map { ap =>\n+        ap.children match {\n+          case Token(col, Nil) :: Nil => col\n+          case _ => null\n+        }\n+      }\n+\n+      val restrict = base.getClauseOption(\"TOK_RESTRICT\", args)"
  }],
  "prId": 11048
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "this should probably be under `o.a.s.sql.catalyst.parser`. Also this is a big enough object for the file to be called `AlterTableCommandParser.scala` instead of just `parsers.scala`. You only have 1 parser anyway.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-03-03T01:04:43Z",
    "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, CatalystQl, ParserConf, ParserSupport, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+object AlterTableCommandParser {",
    "line": 33
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "by the way, almost everything in this class can be private. This will make the code a lot more readable.\n",
    "commit": "603226830dc8aee52ca957c60f15cb164f10fb90",
    "createdAt": "2016-03-03T01:26:20Z",
    "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.commands\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.sql.{AnalysisException, SaveMode}\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.{Ascending, Descending}\n+import org.apache.spark.sql.catalyst.parser.{ASTNode, CatalystQl, ParserConf, ParserSupport, SimpleParserConf}\n+import org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, OneRowRelation}\n+import org.apache.spark.sql.catalyst.plans.logical\n+import org.apache.spark.sql.execution.commands._\n+import org.apache.spark.sql.execution.datasources._\n+import org.apache.spark.sql.types.StructType\n+\n+object AlterTableCommandParser {",
    "line": 33
  }],
  "prId": 11048
}]