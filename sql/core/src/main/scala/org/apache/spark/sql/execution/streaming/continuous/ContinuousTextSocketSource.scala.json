[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "`ContinuousStream` -> `ContinuousScan`",
    "commit": "a7d0c55677d519843086f54ef9502e5482ea2765",
    "createdAt": "2019-07-18T21:06:59Z",
    "diffHunk": "@@ -36,21 +36,26 @@ import org.apache.spark.sql.execution.streaming.{Offset => _, _}\n import org.apache.spark.sql.execution.streaming.sources.TextSocketReader\n import org.apache.spark.sql.sources.v2.reader._\n import org.apache.spark.sql.sources.v2.reader.streaming._\n+import org.apache.spark.sql.types.StructType\n import org.apache.spark.sql.util.CaseInsensitiveStringMap\n import org.apache.spark.util.RpcUtils\n \n \n /**\n- * A [[ContinuousStream]] that reads text lines through a TCP socket, designed only for tutorials\n+ * A [[ContinuousScan]] that reads text lines through a TCP socket, designed only for tutorials\n  * and debugging. This ContinuousStream will *not* work in production applications due to"
  }],
  "prId": 25180
}]