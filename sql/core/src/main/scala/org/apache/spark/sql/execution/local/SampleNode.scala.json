[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "hm, why not just use the provided seed? It will allow us to test this more deterministically. We can just have the seed in the constructor default to `Utils.random.nextLong` just like how `PartitionwiseSampledRDD` does it.\n",
    "commit": "a3270b0e8470e09cafffcc18579e8b0febdc0ef6",
    "createdAt": "2015-09-10T20:58:04Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import java.util.Random\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.util.random.{BernoulliCellSampler, PoissonSampler}\n+\n+/**\n+ * Sample the dataset.\n+ *\n+ * @param lowerBound Lower-bound of the sampling probability (usually 0.0)\n+ * @param upperBound Upper-bound of the sampling probability. The expected fraction sampled\n+ *                   will be ub - lb.\n+ * @param withReplacement Whether to sample with replacement.\n+ * @param seed the random seed\n+ * @param child the LocalNode\n+ */\n+case class SampleNode(\n+    lowerBound: Double,\n+    upperBound: Double,\n+    withReplacement: Boolean,\n+    seed: Long,\n+    child: LocalNode) extends UnaryLocalNode {\n+\n+  override def output: Seq[Attribute] = child.output\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  override def open(): Unit = {\n+    child.open()\n+    val (sampler, _seed) = if (withReplacement) {\n+        val random = new Random(seed)\n+        // Disable gap sampling since the gap sampling method buffers two rows internally,\n+        // requiring us to copy the row, which is more expensive than the random number generator.\n+        (new PoissonSampler[InternalRow](upperBound - lowerBound, useGapSamplingIfPossible = false),\n+          // Use the seed for partition 0 like PartitionwiseSampledRDD to generate the same result\n+          // of DataFrame\n+          random.nextLong())",
    "line": 61
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "[PartitionwiseSampledRDD](https://github.com/apache/spark/blob/c1bc4f439f54625c01a585691e5293cd9961eb0c/core/src/main/scala/org/apache/spark/rdd/PartitionwiseSampledRDD.scala#L57) doesn't use the provided seed directly, it calls `random.nextLong` to create `seed` for each partition. Here I want to make `SampleNode` generate the same result like the first partition of `PartitionwiseSampledRDD`, so I don't use the provided seed directly.\n",
    "commit": "a3270b0e8470e09cafffcc18579e8b0febdc0ef6",
    "createdAt": "2015-09-11T09:44:15Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import java.util.Random\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.util.random.{BernoulliCellSampler, PoissonSampler}\n+\n+/**\n+ * Sample the dataset.\n+ *\n+ * @param lowerBound Lower-bound of the sampling probability (usually 0.0)\n+ * @param upperBound Upper-bound of the sampling probability. The expected fraction sampled\n+ *                   will be ub - lb.\n+ * @param withReplacement Whether to sample with replacement.\n+ * @param seed the random seed\n+ * @param child the LocalNode\n+ */\n+case class SampleNode(\n+    lowerBound: Double,\n+    upperBound: Double,\n+    withReplacement: Boolean,\n+    seed: Long,\n+    child: LocalNode) extends UnaryLocalNode {\n+\n+  override def output: Seq[Attribute] = child.output\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  override def open(): Unit = {\n+    child.open()\n+    val (sampler, _seed) = if (withReplacement) {\n+        val random = new Random(seed)\n+        // Disable gap sampling since the gap sampling method buffers two rows internally,\n+        // requiring us to copy the row, which is more expensive than the random number generator.\n+        (new PoissonSampler[InternalRow](upperBound - lowerBound, useGapSamplingIfPossible = false),\n+          // Use the seed for partition 0 like PartitionwiseSampledRDD to generate the same result\n+          // of DataFrame\n+          random.nextLong())",
    "line": 61
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "I see, it uses the seed to generate a random seed\n",
    "commit": "a3270b0e8470e09cafffcc18579e8b0febdc0ef6",
    "createdAt": "2015-09-11T19:07:01Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.local\n+\n+import java.util.Random\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.Attribute\n+import org.apache.spark.util.random.{BernoulliCellSampler, PoissonSampler}\n+\n+/**\n+ * Sample the dataset.\n+ *\n+ * @param lowerBound Lower-bound of the sampling probability (usually 0.0)\n+ * @param upperBound Upper-bound of the sampling probability. The expected fraction sampled\n+ *                   will be ub - lb.\n+ * @param withReplacement Whether to sample with replacement.\n+ * @param seed the random seed\n+ * @param child the LocalNode\n+ */\n+case class SampleNode(\n+    lowerBound: Double,\n+    upperBound: Double,\n+    withReplacement: Boolean,\n+    seed: Long,\n+    child: LocalNode) extends UnaryLocalNode {\n+\n+  override def output: Seq[Attribute] = child.output\n+\n+  private[this] var iterator: Iterator[InternalRow] = _\n+\n+  private[this] var currentRow: InternalRow = _\n+\n+  override def open(): Unit = {\n+    child.open()\n+    val (sampler, _seed) = if (withReplacement) {\n+        val random = new Random(seed)\n+        // Disable gap sampling since the gap sampling method buffers two rows internally,\n+        // requiring us to copy the row, which is more expensive than the random number generator.\n+        (new PoissonSampler[InternalRow](upperBound - lowerBound, useGapSamplingIfPossible = false),\n+          // Use the seed for partition 0 like PartitionwiseSampledRDD to generate the same result\n+          // of DataFrame\n+          random.nextLong())",
    "line": 61
  }],
  "prId": 8573
}]