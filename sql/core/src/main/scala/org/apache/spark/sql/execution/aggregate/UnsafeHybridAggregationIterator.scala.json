[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "we should just remove this function and inline it. We don't want an extra iterator overhead to process the rows.\n\nEach iterator actually adds a lot of overhead, and here it doesn't buy you any code reduction (on the contrary it increases complexity due to the extra abstraction).\n",
    "commit": "e317e2bb175ea69e6cbf6e8b1a6165046b07dabd",
    "createdAt": "2015-08-03T08:03:26Z",
    "diffHunk": "@@ -0,0 +1,398 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.aggregate\n+\n+import org.apache.spark.sql.execution.{UnsafeKeyValueSorter, UnsafeFixedWidthAggregationMap}\n+import org.apache.spark.unsafe.KVIterator\n+import org.apache.spark.{SparkEnv, TaskContext}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.aggregate._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * An iterator used to evaluate [[AggregateFunction2]].\n+ * It first tries to use in-memory hash-based aggregation. If we cannot allocate more\n+ * space for the hash map, we spill the sorted map entries, free the map, and then\n+ * switch to sort-based aggregation.\n+ */\n+class UnsafeHybridAggregationIterator(\n+    groupingKeyAttributes: Seq[Attribute],\n+    valueAttributes: Seq[Attribute],\n+    inputKVIterator: KVIterator[UnsafeRow, InternalRow],\n+    nonCompleteAggregateExpressions: Seq[AggregateExpression2],\n+    nonCompleteAggregateAttributes: Seq[Attribute],\n+    completeAggregateExpressions: Seq[AggregateExpression2],\n+    completeAggregateAttributes: Seq[Attribute],\n+    initialInputBufferOffset: Int,\n+    resultExpressions: Seq[NamedExpression],\n+    newMutableProjection: (Seq[Expression], Seq[Attribute]) => (() => MutableProjection),\n+    outputsUnsafeRows: Boolean)\n+  extends AggregationIterator(\n+    groupingKeyAttributes,\n+    valueAttributes,\n+    nonCompleteAggregateExpressions,\n+    nonCompleteAggregateAttributes,\n+    completeAggregateExpressions,\n+    completeAggregateAttributes,\n+    initialInputBufferOffset,\n+    resultExpressions,\n+    newMutableProjection,\n+    outputsUnsafeRows) {\n+\n+  require(groupingKeyAttributes.nonEmpty)\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Unsafe Aggregation buffers\n+  ///////////////////////////////////////////////////////////////////////////\n+\n+  // This is the Unsafe Aggregation Map used to store all buffers.\n+  private[this] val buffers = new UnsafeFixedWidthAggregationMap(\n+    newBuffer,\n+    StructType.fromAttributes(allAggregateFunctions.flatMap(_.bufferAttributes)),\n+    StructType.fromAttributes(groupingKeyAttributes),\n+    TaskContext.get.taskMemoryManager(),\n+    SparkEnv.get.shuffleMemoryManager,\n+    1024 * 16, // initial capacity\n+    SparkEnv.get.conf.getSizeAsBytes(\"spark.buffer.pageSize\", \"64m\"),\n+    false // disable tracking of performance metrics\n+  )\n+\n+  override protected def newBuffer: UnsafeRow = {\n+    val bufferSchema = allAggregateFunctions.flatMap(_.bufferAttributes)\n+    val bufferRowSize: Int = bufferSchema.length\n+\n+    val genericMutableBuffer = new GenericMutableRow(bufferRowSize)\n+    val unsafeProjection =\n+      UnsafeProjection.create(bufferSchema.map(_.dataType))\n+    val buffer = unsafeProjection.apply(genericMutableBuffer)\n+    initializeBuffer(buffer)\n+    buffer\n+  }\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Methods and variables related to switching to sort-based aggregation\n+  ///////////////////////////////////////////////////////////////////////////\n+  private[this] var sortBased = false\n+\n+  private[this] var sortBasedAggregationIterator: SortBasedAggregationIterator = _\n+\n+  // The value part of the input KV iterator is used to store original input values of\n+  // aggregate functions, we need to convert them to aggregation buffers.\n+  private def processOriginalInput(\n+      firstKey: UnsafeRow,\n+      firstValue: InternalRow): KVIterator[UnsafeRow, UnsafeRow] = {\n+    new KVIterator[UnsafeRow, UnsafeRow] {\n+      private[this] var isFirstRow = true\n+\n+      private[this] var groupingKey: UnsafeRow = _\n+\n+      private[this] val buffer: UnsafeRow = newBuffer\n+\n+      override def next(): Boolean = {\n+        initializeBuffer(buffer)\n+        if (isFirstRow) {\n+          isFirstRow = false\n+          groupingKey = firstKey\n+          processRow(buffer, firstValue)\n+\n+          true\n+        } else if (inputKVIterator.next()) {\n+          groupingKey = inputKVIterator.getKey()\n+          val value = inputKVIterator.getValue()\n+          processRow(buffer, value)\n+\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+\n+      override def getKey(): UnsafeRow = {\n+        groupingKey\n+      }\n+\n+      override def getValue(): UnsafeRow = {\n+        buffer\n+      }\n+\n+      override def close(): Unit = {\n+        // Do nothing.\n+      }\n+    }\n+  }\n+\n+  // The value of the input KV Iterator has the format of groupingExprs + aggregation buffer.\n+  // We need to project the aggregation buffer out.\n+  private def projectInputBufferToUnsafe(",
    "line": 142
  }, {
    "author": {
      "login": "yhuai"
    },
    "body": "Done.\n",
    "commit": "e317e2bb175ea69e6cbf6e8b1a6165046b07dabd",
    "createdAt": "2015-08-05T01:08:51Z",
    "diffHunk": "@@ -0,0 +1,398 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.aggregate\n+\n+import org.apache.spark.sql.execution.{UnsafeKeyValueSorter, UnsafeFixedWidthAggregationMap}\n+import org.apache.spark.unsafe.KVIterator\n+import org.apache.spark.{SparkEnv, TaskContext}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.aggregate._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * An iterator used to evaluate [[AggregateFunction2]].\n+ * It first tries to use in-memory hash-based aggregation. If we cannot allocate more\n+ * space for the hash map, we spill the sorted map entries, free the map, and then\n+ * switch to sort-based aggregation.\n+ */\n+class UnsafeHybridAggregationIterator(\n+    groupingKeyAttributes: Seq[Attribute],\n+    valueAttributes: Seq[Attribute],\n+    inputKVIterator: KVIterator[UnsafeRow, InternalRow],\n+    nonCompleteAggregateExpressions: Seq[AggregateExpression2],\n+    nonCompleteAggregateAttributes: Seq[Attribute],\n+    completeAggregateExpressions: Seq[AggregateExpression2],\n+    completeAggregateAttributes: Seq[Attribute],\n+    initialInputBufferOffset: Int,\n+    resultExpressions: Seq[NamedExpression],\n+    newMutableProjection: (Seq[Expression], Seq[Attribute]) => (() => MutableProjection),\n+    outputsUnsafeRows: Boolean)\n+  extends AggregationIterator(\n+    groupingKeyAttributes,\n+    valueAttributes,\n+    nonCompleteAggregateExpressions,\n+    nonCompleteAggregateAttributes,\n+    completeAggregateExpressions,\n+    completeAggregateAttributes,\n+    initialInputBufferOffset,\n+    resultExpressions,\n+    newMutableProjection,\n+    outputsUnsafeRows) {\n+\n+  require(groupingKeyAttributes.nonEmpty)\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Unsafe Aggregation buffers\n+  ///////////////////////////////////////////////////////////////////////////\n+\n+  // This is the Unsafe Aggregation Map used to store all buffers.\n+  private[this] val buffers = new UnsafeFixedWidthAggregationMap(\n+    newBuffer,\n+    StructType.fromAttributes(allAggregateFunctions.flatMap(_.bufferAttributes)),\n+    StructType.fromAttributes(groupingKeyAttributes),\n+    TaskContext.get.taskMemoryManager(),\n+    SparkEnv.get.shuffleMemoryManager,\n+    1024 * 16, // initial capacity\n+    SparkEnv.get.conf.getSizeAsBytes(\"spark.buffer.pageSize\", \"64m\"),\n+    false // disable tracking of performance metrics\n+  )\n+\n+  override protected def newBuffer: UnsafeRow = {\n+    val bufferSchema = allAggregateFunctions.flatMap(_.bufferAttributes)\n+    val bufferRowSize: Int = bufferSchema.length\n+\n+    val genericMutableBuffer = new GenericMutableRow(bufferRowSize)\n+    val unsafeProjection =\n+      UnsafeProjection.create(bufferSchema.map(_.dataType))\n+    val buffer = unsafeProjection.apply(genericMutableBuffer)\n+    initializeBuffer(buffer)\n+    buffer\n+  }\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Methods and variables related to switching to sort-based aggregation\n+  ///////////////////////////////////////////////////////////////////////////\n+  private[this] var sortBased = false\n+\n+  private[this] var sortBasedAggregationIterator: SortBasedAggregationIterator = _\n+\n+  // The value part of the input KV iterator is used to store original input values of\n+  // aggregate functions, we need to convert them to aggregation buffers.\n+  private def processOriginalInput(\n+      firstKey: UnsafeRow,\n+      firstValue: InternalRow): KVIterator[UnsafeRow, UnsafeRow] = {\n+    new KVIterator[UnsafeRow, UnsafeRow] {\n+      private[this] var isFirstRow = true\n+\n+      private[this] var groupingKey: UnsafeRow = _\n+\n+      private[this] val buffer: UnsafeRow = newBuffer\n+\n+      override def next(): Boolean = {\n+        initializeBuffer(buffer)\n+        if (isFirstRow) {\n+          isFirstRow = false\n+          groupingKey = firstKey\n+          processRow(buffer, firstValue)\n+\n+          true\n+        } else if (inputKVIterator.next()) {\n+          groupingKey = inputKVIterator.getKey()\n+          val value = inputKVIterator.getValue()\n+          processRow(buffer, value)\n+\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+\n+      override def getKey(): UnsafeRow = {\n+        groupingKey\n+      }\n+\n+      override def getValue(): UnsafeRow = {\n+        buffer\n+      }\n+\n+      override def close(): Unit = {\n+        // Do nothing.\n+      }\n+    }\n+  }\n+\n+  // The value of the input KV Iterator has the format of groupingExprs + aggregation buffer.\n+  // We need to project the aggregation buffer out.\n+  private def projectInputBufferToUnsafe(",
    "line": 142
  }],
  "prId": 7813
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "add explicit type here\n",
    "commit": "e317e2bb175ea69e6cbf6e8b1a6165046b07dabd",
    "createdAt": "2015-08-03T08:04:59Z",
    "diffHunk": "@@ -0,0 +1,398 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.aggregate\n+\n+import org.apache.spark.sql.execution.{UnsafeKeyValueSorter, UnsafeFixedWidthAggregationMap}\n+import org.apache.spark.unsafe.KVIterator\n+import org.apache.spark.{SparkEnv, TaskContext}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.aggregate._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * An iterator used to evaluate [[AggregateFunction2]].\n+ * It first tries to use in-memory hash-based aggregation. If we cannot allocate more\n+ * space for the hash map, we spill the sorted map entries, free the map, and then\n+ * switch to sort-based aggregation.\n+ */\n+class UnsafeHybridAggregationIterator(\n+    groupingKeyAttributes: Seq[Attribute],\n+    valueAttributes: Seq[Attribute],\n+    inputKVIterator: KVIterator[UnsafeRow, InternalRow],\n+    nonCompleteAggregateExpressions: Seq[AggregateExpression2],\n+    nonCompleteAggregateAttributes: Seq[Attribute],\n+    completeAggregateExpressions: Seq[AggregateExpression2],\n+    completeAggregateAttributes: Seq[Attribute],\n+    initialInputBufferOffset: Int,\n+    resultExpressions: Seq[NamedExpression],\n+    newMutableProjection: (Seq[Expression], Seq[Attribute]) => (() => MutableProjection),\n+    outputsUnsafeRows: Boolean)\n+  extends AggregationIterator(\n+    groupingKeyAttributes,\n+    valueAttributes,\n+    nonCompleteAggregateExpressions,\n+    nonCompleteAggregateAttributes,\n+    completeAggregateExpressions,\n+    completeAggregateAttributes,\n+    initialInputBufferOffset,\n+    resultExpressions,\n+    newMutableProjection,\n+    outputsUnsafeRows) {\n+\n+  require(groupingKeyAttributes.nonEmpty)\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Unsafe Aggregation buffers\n+  ///////////////////////////////////////////////////////////////////////////\n+\n+  // This is the Unsafe Aggregation Map used to store all buffers.\n+  private[this] val buffers = new UnsafeFixedWidthAggregationMap(\n+    newBuffer,\n+    StructType.fromAttributes(allAggregateFunctions.flatMap(_.bufferAttributes)),\n+    StructType.fromAttributes(groupingKeyAttributes),\n+    TaskContext.get.taskMemoryManager(),\n+    SparkEnv.get.shuffleMemoryManager,\n+    1024 * 16, // initial capacity\n+    SparkEnv.get.conf.getSizeAsBytes(\"spark.buffer.pageSize\", \"64m\"),\n+    false // disable tracking of performance metrics\n+  )\n+\n+  override protected def newBuffer: UnsafeRow = {\n+    val bufferSchema = allAggregateFunctions.flatMap(_.bufferAttributes)\n+    val bufferRowSize: Int = bufferSchema.length\n+\n+    val genericMutableBuffer = new GenericMutableRow(bufferRowSize)\n+    val unsafeProjection =\n+      UnsafeProjection.create(bufferSchema.map(_.dataType))\n+    val buffer = unsafeProjection.apply(genericMutableBuffer)\n+    initializeBuffer(buffer)\n+    buffer\n+  }\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Methods and variables related to switching to sort-based aggregation\n+  ///////////////////////////////////////////////////////////////////////////\n+  private[this] var sortBased = false\n+\n+  private[this] var sortBasedAggregationIterator: SortBasedAggregationIterator = _\n+\n+  // The value part of the input KV iterator is used to store original input values of\n+  // aggregate functions, we need to convert them to aggregation buffers.\n+  private def processOriginalInput(\n+      firstKey: UnsafeRow,\n+      firstValue: InternalRow): KVIterator[UnsafeRow, UnsafeRow] = {\n+    new KVIterator[UnsafeRow, UnsafeRow] {\n+      private[this] var isFirstRow = true\n+\n+      private[this] var groupingKey: UnsafeRow = _\n+\n+      private[this] val buffer: UnsafeRow = newBuffer\n+\n+      override def next(): Boolean = {\n+        initializeBuffer(buffer)\n+        if (isFirstRow) {\n+          isFirstRow = false\n+          groupingKey = firstKey\n+          processRow(buffer, firstValue)\n+\n+          true\n+        } else if (inputKVIterator.next()) {\n+          groupingKey = inputKVIterator.getKey()\n+          val value = inputKVIterator.getValue()\n+          processRow(buffer, value)\n+\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+\n+      override def getKey(): UnsafeRow = {\n+        groupingKey\n+      }\n+\n+      override def getValue(): UnsafeRow = {\n+        buffer\n+      }\n+\n+      override def close(): Unit = {\n+        // Do nothing.\n+      }\n+    }\n+  }\n+\n+  // The value of the input KV Iterator has the format of groupingExprs + aggregation buffer.\n+  // We need to project the aggregation buffer out.\n+  private def projectInputBufferToUnsafe(\n+      firstKey: UnsafeRow,\n+      firstValue: InternalRow): KVIterator[UnsafeRow, UnsafeRow] = {\n+    new KVIterator[UnsafeRow, UnsafeRow] {\n+      private[this] var isFirstRow = true\n+\n+      private[this] var groupingKey: UnsafeRow = _\n+\n+      private[this] val bufferSchema = allAggregateFunctions.flatMap(_.bufferAttributes)\n+\n+      private[this] val value: UnsafeRow = {\n+        val genericMutableRow = new GenericMutableRow(bufferSchema.length)\n+        UnsafeProjection.create(bufferSchema.map(_.dataType)).apply(genericMutableRow)\n+      }\n+\n+      private[this] val projectInputBuffer = {\n+        newMutableProjection(bufferSchema, valueAttributes)().target(value)\n+      }\n+\n+      override def next(): Boolean = {\n+        if (isFirstRow) {\n+          isFirstRow = false\n+          groupingKey = firstKey\n+          projectInputBuffer(firstValue)\n+\n+          true\n+        } else if (inputKVIterator.next()) {\n+          groupingKey = inputKVIterator.getKey()\n+          projectInputBuffer(inputKVIterator.getValue())\n+\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+\n+      override def getKey(): UnsafeRow = {\n+        groupingKey\n+      }\n+\n+      override def getValue(): UnsafeRow = {\n+        value\n+      }\n+\n+      override def close(): Unit = {\n+        // Do nothing.\n+      }\n+    }\n+  }\n+\n+  /**\n+   * We need to fall back to sort based aggregation because we do not have enough memory\n+   * for our in-memory hash map (i.e. `buffers`).\n+   */\n+  private def switchToSortBasedAggregation(\n+      currentGroupingKey: UnsafeRow,\n+      currentRow: InternalRow): Unit = {\n+    logInfo(\"falling back to sort based aggregation.\")\n+\n+    // Step 1: Get the ExternalSorter containing entries of the map.\n+    val externalSorter = buffers.destructAndCreateExternalSorter()\n+\n+    // Step 2: Free the memory used by the map.\n+    buffers.free()\n+\n+    // Step 3: If we have aggregate function with mode Partial or Complete,\n+    // we need to process them to get aggregation buffer.\n+    // So, later in the sort-based aggregation iterator, we can do merge.\n+    // If aggregate functions are with mode Final and PartialMerge,\n+    // we just need to project the aggregation buffer from the input.\n+    val needsProcess = aggregationMode match {\n+      case (Some(Partial), None) => true\n+      case (None, Some(Complete)) => true\n+      case (Some(Final), Some(Complete)) => true\n+      case _ => false\n+    }\n+\n+    val processedIterator = if (needsProcess) {\n+      processOriginalInput(currentGroupingKey, currentRow)\n+    } else {\n+      // The input value's format is groupingExprs + buffer.\n+      // We need to project the buffer part out.\n+      projectInputBufferToUnsafe(currentGroupingKey, currentRow)\n+    }\n+\n+    // Step 4: Redirect processedIterator to externalSorter.\n+    while (processedIterator.next()) {\n+      externalSorter.insertKV(processedIterator.getKey(), processedIterator.getValue())\n+    }\n+\n+    // Step 5: Get the sorted iterator from the externalSorter.\n+    val sortedKVIterator: KVIterator[UnsafeRow, UnsafeRow] = externalSorter.sortedIterator()\n+\n+    // Step 6: We now create a SortBasedAggregationIterator based on sortedKVIterator.\n+    // For a aggregate function with mode Partial, its mode in the SortBasedAggregationIterator\n+    // will be PartialMerge. For a aggregate function with mode Complete,\n+    // its mode in the SortBasedAggregationIterator will be Final.\n+    val newNonCompleteAggregateExpressions = allAggregateExpressions.map {\n+        case AggregateExpression2(func, Partial, isDistinct) =>\n+          AggregateExpression2(func, PartialMerge, isDistinct)\n+        case AggregateExpression2(func, Complete, isDistinct) =>\n+          AggregateExpression2(func, Final, isDistinct)\n+        case other => other\n+      }\n+    val newNonCompleteAggregateAttributes =\n+      nonCompleteAggregateAttributes ++ completeAggregateAttributes\n+\n+    val newValueAttributes =",
    "line": 249
  }, {
    "author": {
      "login": "yhuai"
    },
    "body": "Done.\n",
    "commit": "e317e2bb175ea69e6cbf6e8b1a6165046b07dabd",
    "createdAt": "2015-08-05T01:09:38Z",
    "diffHunk": "@@ -0,0 +1,398 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.aggregate\n+\n+import org.apache.spark.sql.execution.{UnsafeKeyValueSorter, UnsafeFixedWidthAggregationMap}\n+import org.apache.spark.unsafe.KVIterator\n+import org.apache.spark.{SparkEnv, TaskContext}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.aggregate._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * An iterator used to evaluate [[AggregateFunction2]].\n+ * It first tries to use in-memory hash-based aggregation. If we cannot allocate more\n+ * space for the hash map, we spill the sorted map entries, free the map, and then\n+ * switch to sort-based aggregation.\n+ */\n+class UnsafeHybridAggregationIterator(\n+    groupingKeyAttributes: Seq[Attribute],\n+    valueAttributes: Seq[Attribute],\n+    inputKVIterator: KVIterator[UnsafeRow, InternalRow],\n+    nonCompleteAggregateExpressions: Seq[AggregateExpression2],\n+    nonCompleteAggregateAttributes: Seq[Attribute],\n+    completeAggregateExpressions: Seq[AggregateExpression2],\n+    completeAggregateAttributes: Seq[Attribute],\n+    initialInputBufferOffset: Int,\n+    resultExpressions: Seq[NamedExpression],\n+    newMutableProjection: (Seq[Expression], Seq[Attribute]) => (() => MutableProjection),\n+    outputsUnsafeRows: Boolean)\n+  extends AggregationIterator(\n+    groupingKeyAttributes,\n+    valueAttributes,\n+    nonCompleteAggregateExpressions,\n+    nonCompleteAggregateAttributes,\n+    completeAggregateExpressions,\n+    completeAggregateAttributes,\n+    initialInputBufferOffset,\n+    resultExpressions,\n+    newMutableProjection,\n+    outputsUnsafeRows) {\n+\n+  require(groupingKeyAttributes.nonEmpty)\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Unsafe Aggregation buffers\n+  ///////////////////////////////////////////////////////////////////////////\n+\n+  // This is the Unsafe Aggregation Map used to store all buffers.\n+  private[this] val buffers = new UnsafeFixedWidthAggregationMap(\n+    newBuffer,\n+    StructType.fromAttributes(allAggregateFunctions.flatMap(_.bufferAttributes)),\n+    StructType.fromAttributes(groupingKeyAttributes),\n+    TaskContext.get.taskMemoryManager(),\n+    SparkEnv.get.shuffleMemoryManager,\n+    1024 * 16, // initial capacity\n+    SparkEnv.get.conf.getSizeAsBytes(\"spark.buffer.pageSize\", \"64m\"),\n+    false // disable tracking of performance metrics\n+  )\n+\n+  override protected def newBuffer: UnsafeRow = {\n+    val bufferSchema = allAggregateFunctions.flatMap(_.bufferAttributes)\n+    val bufferRowSize: Int = bufferSchema.length\n+\n+    val genericMutableBuffer = new GenericMutableRow(bufferRowSize)\n+    val unsafeProjection =\n+      UnsafeProjection.create(bufferSchema.map(_.dataType))\n+    val buffer = unsafeProjection.apply(genericMutableBuffer)\n+    initializeBuffer(buffer)\n+    buffer\n+  }\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Methods and variables related to switching to sort-based aggregation\n+  ///////////////////////////////////////////////////////////////////////////\n+  private[this] var sortBased = false\n+\n+  private[this] var sortBasedAggregationIterator: SortBasedAggregationIterator = _\n+\n+  // The value part of the input KV iterator is used to store original input values of\n+  // aggregate functions, we need to convert them to aggregation buffers.\n+  private def processOriginalInput(\n+      firstKey: UnsafeRow,\n+      firstValue: InternalRow): KVIterator[UnsafeRow, UnsafeRow] = {\n+    new KVIterator[UnsafeRow, UnsafeRow] {\n+      private[this] var isFirstRow = true\n+\n+      private[this] var groupingKey: UnsafeRow = _\n+\n+      private[this] val buffer: UnsafeRow = newBuffer\n+\n+      override def next(): Boolean = {\n+        initializeBuffer(buffer)\n+        if (isFirstRow) {\n+          isFirstRow = false\n+          groupingKey = firstKey\n+          processRow(buffer, firstValue)\n+\n+          true\n+        } else if (inputKVIterator.next()) {\n+          groupingKey = inputKVIterator.getKey()\n+          val value = inputKVIterator.getValue()\n+          processRow(buffer, value)\n+\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+\n+      override def getKey(): UnsafeRow = {\n+        groupingKey\n+      }\n+\n+      override def getValue(): UnsafeRow = {\n+        buffer\n+      }\n+\n+      override def close(): Unit = {\n+        // Do nothing.\n+      }\n+    }\n+  }\n+\n+  // The value of the input KV Iterator has the format of groupingExprs + aggregation buffer.\n+  // We need to project the aggregation buffer out.\n+  private def projectInputBufferToUnsafe(\n+      firstKey: UnsafeRow,\n+      firstValue: InternalRow): KVIterator[UnsafeRow, UnsafeRow] = {\n+    new KVIterator[UnsafeRow, UnsafeRow] {\n+      private[this] var isFirstRow = true\n+\n+      private[this] var groupingKey: UnsafeRow = _\n+\n+      private[this] val bufferSchema = allAggregateFunctions.flatMap(_.bufferAttributes)\n+\n+      private[this] val value: UnsafeRow = {\n+        val genericMutableRow = new GenericMutableRow(bufferSchema.length)\n+        UnsafeProjection.create(bufferSchema.map(_.dataType)).apply(genericMutableRow)\n+      }\n+\n+      private[this] val projectInputBuffer = {\n+        newMutableProjection(bufferSchema, valueAttributes)().target(value)\n+      }\n+\n+      override def next(): Boolean = {\n+        if (isFirstRow) {\n+          isFirstRow = false\n+          groupingKey = firstKey\n+          projectInputBuffer(firstValue)\n+\n+          true\n+        } else if (inputKVIterator.next()) {\n+          groupingKey = inputKVIterator.getKey()\n+          projectInputBuffer(inputKVIterator.getValue())\n+\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+\n+      override def getKey(): UnsafeRow = {\n+        groupingKey\n+      }\n+\n+      override def getValue(): UnsafeRow = {\n+        value\n+      }\n+\n+      override def close(): Unit = {\n+        // Do nothing.\n+      }\n+    }\n+  }\n+\n+  /**\n+   * We need to fall back to sort based aggregation because we do not have enough memory\n+   * for our in-memory hash map (i.e. `buffers`).\n+   */\n+  private def switchToSortBasedAggregation(\n+      currentGroupingKey: UnsafeRow,\n+      currentRow: InternalRow): Unit = {\n+    logInfo(\"falling back to sort based aggregation.\")\n+\n+    // Step 1: Get the ExternalSorter containing entries of the map.\n+    val externalSorter = buffers.destructAndCreateExternalSorter()\n+\n+    // Step 2: Free the memory used by the map.\n+    buffers.free()\n+\n+    // Step 3: If we have aggregate function with mode Partial or Complete,\n+    // we need to process them to get aggregation buffer.\n+    // So, later in the sort-based aggregation iterator, we can do merge.\n+    // If aggregate functions are with mode Final and PartialMerge,\n+    // we just need to project the aggregation buffer from the input.\n+    val needsProcess = aggregationMode match {\n+      case (Some(Partial), None) => true\n+      case (None, Some(Complete)) => true\n+      case (Some(Final), Some(Complete)) => true\n+      case _ => false\n+    }\n+\n+    val processedIterator = if (needsProcess) {\n+      processOriginalInput(currentGroupingKey, currentRow)\n+    } else {\n+      // The input value's format is groupingExprs + buffer.\n+      // We need to project the buffer part out.\n+      projectInputBufferToUnsafe(currentGroupingKey, currentRow)\n+    }\n+\n+    // Step 4: Redirect processedIterator to externalSorter.\n+    while (processedIterator.next()) {\n+      externalSorter.insertKV(processedIterator.getKey(), processedIterator.getValue())\n+    }\n+\n+    // Step 5: Get the sorted iterator from the externalSorter.\n+    val sortedKVIterator: KVIterator[UnsafeRow, UnsafeRow] = externalSorter.sortedIterator()\n+\n+    // Step 6: We now create a SortBasedAggregationIterator based on sortedKVIterator.\n+    // For a aggregate function with mode Partial, its mode in the SortBasedAggregationIterator\n+    // will be PartialMerge. For a aggregate function with mode Complete,\n+    // its mode in the SortBasedAggregationIterator will be Final.\n+    val newNonCompleteAggregateExpressions = allAggregateExpressions.map {\n+        case AggregateExpression2(func, Partial, isDistinct) =>\n+          AggregateExpression2(func, PartialMerge, isDistinct)\n+        case AggregateExpression2(func, Complete, isDistinct) =>\n+          AggregateExpression2(func, Final, isDistinct)\n+        case other => other\n+      }\n+    val newNonCompleteAggregateAttributes =\n+      nonCompleteAggregateAttributes ++ completeAggregateAttributes\n+\n+    val newValueAttributes =",
    "line": 249
  }],
  "prId": 7813
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "this one too -- it increases the complexity with extra abstraction but doesn't really reduce code. it also hurts performance.\n",
    "commit": "e317e2bb175ea69e6cbf6e8b1a6165046b07dabd",
    "createdAt": "2015-08-03T08:06:13Z",
    "diffHunk": "@@ -0,0 +1,398 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.aggregate\n+\n+import org.apache.spark.sql.execution.{UnsafeKeyValueSorter, UnsafeFixedWidthAggregationMap}\n+import org.apache.spark.unsafe.KVIterator\n+import org.apache.spark.{SparkEnv, TaskContext}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.aggregate._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * An iterator used to evaluate [[AggregateFunction2]].\n+ * It first tries to use in-memory hash-based aggregation. If we cannot allocate more\n+ * space for the hash map, we spill the sorted map entries, free the map, and then\n+ * switch to sort-based aggregation.\n+ */\n+class UnsafeHybridAggregationIterator(\n+    groupingKeyAttributes: Seq[Attribute],\n+    valueAttributes: Seq[Attribute],\n+    inputKVIterator: KVIterator[UnsafeRow, InternalRow],\n+    nonCompleteAggregateExpressions: Seq[AggregateExpression2],\n+    nonCompleteAggregateAttributes: Seq[Attribute],\n+    completeAggregateExpressions: Seq[AggregateExpression2],\n+    completeAggregateAttributes: Seq[Attribute],\n+    initialInputBufferOffset: Int,\n+    resultExpressions: Seq[NamedExpression],\n+    newMutableProjection: (Seq[Expression], Seq[Attribute]) => (() => MutableProjection),\n+    outputsUnsafeRows: Boolean)\n+  extends AggregationIterator(\n+    groupingKeyAttributes,\n+    valueAttributes,\n+    nonCompleteAggregateExpressions,\n+    nonCompleteAggregateAttributes,\n+    completeAggregateExpressions,\n+    completeAggregateAttributes,\n+    initialInputBufferOffset,\n+    resultExpressions,\n+    newMutableProjection,\n+    outputsUnsafeRows) {\n+\n+  require(groupingKeyAttributes.nonEmpty)\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Unsafe Aggregation buffers\n+  ///////////////////////////////////////////////////////////////////////////\n+\n+  // This is the Unsafe Aggregation Map used to store all buffers.\n+  private[this] val buffers = new UnsafeFixedWidthAggregationMap(\n+    newBuffer,\n+    StructType.fromAttributes(allAggregateFunctions.flatMap(_.bufferAttributes)),\n+    StructType.fromAttributes(groupingKeyAttributes),\n+    TaskContext.get.taskMemoryManager(),\n+    SparkEnv.get.shuffleMemoryManager,\n+    1024 * 16, // initial capacity\n+    SparkEnv.get.conf.getSizeAsBytes(\"spark.buffer.pageSize\", \"64m\"),\n+    false // disable tracking of performance metrics\n+  )\n+\n+  override protected def newBuffer: UnsafeRow = {\n+    val bufferSchema = allAggregateFunctions.flatMap(_.bufferAttributes)\n+    val bufferRowSize: Int = bufferSchema.length\n+\n+    val genericMutableBuffer = new GenericMutableRow(bufferRowSize)\n+    val unsafeProjection =\n+      UnsafeProjection.create(bufferSchema.map(_.dataType))\n+    val buffer = unsafeProjection.apply(genericMutableBuffer)\n+    initializeBuffer(buffer)\n+    buffer\n+  }\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Methods and variables related to switching to sort-based aggregation\n+  ///////////////////////////////////////////////////////////////////////////\n+  private[this] var sortBased = false\n+\n+  private[this] var sortBasedAggregationIterator: SortBasedAggregationIterator = _\n+\n+  // The value part of the input KV iterator is used to store original input values of\n+  // aggregate functions, we need to convert them to aggregation buffers.\n+  private def processOriginalInput(",
    "line": 97
  }, {
    "author": {
      "login": "yhuai"
    },
    "body": "Done.\n",
    "commit": "e317e2bb175ea69e6cbf6e8b1a6165046b07dabd",
    "createdAt": "2015-08-05T01:09:43Z",
    "diffHunk": "@@ -0,0 +1,398 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.aggregate\n+\n+import org.apache.spark.sql.execution.{UnsafeKeyValueSorter, UnsafeFixedWidthAggregationMap}\n+import org.apache.spark.unsafe.KVIterator\n+import org.apache.spark.{SparkEnv, TaskContext}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.aggregate._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * An iterator used to evaluate [[AggregateFunction2]].\n+ * It first tries to use in-memory hash-based aggregation. If we cannot allocate more\n+ * space for the hash map, we spill the sorted map entries, free the map, and then\n+ * switch to sort-based aggregation.\n+ */\n+class UnsafeHybridAggregationIterator(\n+    groupingKeyAttributes: Seq[Attribute],\n+    valueAttributes: Seq[Attribute],\n+    inputKVIterator: KVIterator[UnsafeRow, InternalRow],\n+    nonCompleteAggregateExpressions: Seq[AggregateExpression2],\n+    nonCompleteAggregateAttributes: Seq[Attribute],\n+    completeAggregateExpressions: Seq[AggregateExpression2],\n+    completeAggregateAttributes: Seq[Attribute],\n+    initialInputBufferOffset: Int,\n+    resultExpressions: Seq[NamedExpression],\n+    newMutableProjection: (Seq[Expression], Seq[Attribute]) => (() => MutableProjection),\n+    outputsUnsafeRows: Boolean)\n+  extends AggregationIterator(\n+    groupingKeyAttributes,\n+    valueAttributes,\n+    nonCompleteAggregateExpressions,\n+    nonCompleteAggregateAttributes,\n+    completeAggregateExpressions,\n+    completeAggregateAttributes,\n+    initialInputBufferOffset,\n+    resultExpressions,\n+    newMutableProjection,\n+    outputsUnsafeRows) {\n+\n+  require(groupingKeyAttributes.nonEmpty)\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Unsafe Aggregation buffers\n+  ///////////////////////////////////////////////////////////////////////////\n+\n+  // This is the Unsafe Aggregation Map used to store all buffers.\n+  private[this] val buffers = new UnsafeFixedWidthAggregationMap(\n+    newBuffer,\n+    StructType.fromAttributes(allAggregateFunctions.flatMap(_.bufferAttributes)),\n+    StructType.fromAttributes(groupingKeyAttributes),\n+    TaskContext.get.taskMemoryManager(),\n+    SparkEnv.get.shuffleMemoryManager,\n+    1024 * 16, // initial capacity\n+    SparkEnv.get.conf.getSizeAsBytes(\"spark.buffer.pageSize\", \"64m\"),\n+    false // disable tracking of performance metrics\n+  )\n+\n+  override protected def newBuffer: UnsafeRow = {\n+    val bufferSchema = allAggregateFunctions.flatMap(_.bufferAttributes)\n+    val bufferRowSize: Int = bufferSchema.length\n+\n+    val genericMutableBuffer = new GenericMutableRow(bufferRowSize)\n+    val unsafeProjection =\n+      UnsafeProjection.create(bufferSchema.map(_.dataType))\n+    val buffer = unsafeProjection.apply(genericMutableBuffer)\n+    initializeBuffer(buffer)\n+    buffer\n+  }\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Methods and variables related to switching to sort-based aggregation\n+  ///////////////////////////////////////////////////////////////////////////\n+  private[this] var sortBased = false\n+\n+  private[this] var sortBasedAggregationIterator: SortBasedAggregationIterator = _\n+\n+  // The value part of the input KV iterator is used to store original input values of\n+  // aggregate functions, we need to convert them to aggregation buffers.\n+  private def processOriginalInput(",
    "line": 97
  }],
  "prId": 7813
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "we should think about all of these function reuse -- i think they do make things more complicated, and they are bad for performance because there is nothing the compiler can do here about inlining them. \n\nit's actually more expensive than using if branches inline because the branch predictor usually does a pretty good job with fixed conditions for an operator (e.g. for a particular period of time, this operator will always be in a specific mode).\n",
    "commit": "e317e2bb175ea69e6cbf6e8b1a6165046b07dabd",
    "createdAt": "2015-08-03T08:26:39Z",
    "diffHunk": "@@ -0,0 +1,398 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.aggregate\n+\n+import org.apache.spark.sql.execution.{UnsafeKeyValueSorter, UnsafeFixedWidthAggregationMap}\n+import org.apache.spark.unsafe.KVIterator\n+import org.apache.spark.{SparkEnv, TaskContext}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions._\n+import org.apache.spark.sql.catalyst.expressions.aggregate._\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * An iterator used to evaluate [[AggregateFunction2]].\n+ * It first tries to use in-memory hash-based aggregation. If we cannot allocate more\n+ * space for the hash map, we spill the sorted map entries, free the map, and then\n+ * switch to sort-based aggregation.\n+ */\n+class UnsafeHybridAggregationIterator(\n+    groupingKeyAttributes: Seq[Attribute],\n+    valueAttributes: Seq[Attribute],\n+    inputKVIterator: KVIterator[UnsafeRow, InternalRow],\n+    nonCompleteAggregateExpressions: Seq[AggregateExpression2],\n+    nonCompleteAggregateAttributes: Seq[Attribute],\n+    completeAggregateExpressions: Seq[AggregateExpression2],\n+    completeAggregateAttributes: Seq[Attribute],\n+    initialInputBufferOffset: Int,\n+    resultExpressions: Seq[NamedExpression],\n+    newMutableProjection: (Seq[Expression], Seq[Attribute]) => (() => MutableProjection),\n+    outputsUnsafeRows: Boolean)\n+  extends AggregationIterator(\n+    groupingKeyAttributes,\n+    valueAttributes,\n+    nonCompleteAggregateExpressions,\n+    nonCompleteAggregateAttributes,\n+    completeAggregateExpressions,\n+    completeAggregateAttributes,\n+    initialInputBufferOffset,\n+    resultExpressions,\n+    newMutableProjection,\n+    outputsUnsafeRows) {\n+\n+  require(groupingKeyAttributes.nonEmpty)\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Unsafe Aggregation buffers\n+  ///////////////////////////////////////////////////////////////////////////\n+\n+  // This is the Unsafe Aggregation Map used to store all buffers.\n+  private[this] val buffers = new UnsafeFixedWidthAggregationMap(\n+    newBuffer,\n+    StructType.fromAttributes(allAggregateFunctions.flatMap(_.bufferAttributes)),\n+    StructType.fromAttributes(groupingKeyAttributes),\n+    TaskContext.get.taskMemoryManager(),\n+    SparkEnv.get.shuffleMemoryManager,\n+    1024 * 16, // initial capacity\n+    SparkEnv.get.conf.getSizeAsBytes(\"spark.buffer.pageSize\", \"64m\"),\n+    false // disable tracking of performance metrics\n+  )\n+\n+  override protected def newBuffer: UnsafeRow = {\n+    val bufferSchema = allAggregateFunctions.flatMap(_.bufferAttributes)\n+    val bufferRowSize: Int = bufferSchema.length\n+\n+    val genericMutableBuffer = new GenericMutableRow(bufferRowSize)\n+    val unsafeProjection =\n+      UnsafeProjection.create(bufferSchema.map(_.dataType))\n+    val buffer = unsafeProjection.apply(genericMutableBuffer)\n+    initializeBuffer(buffer)\n+    buffer\n+  }\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Methods and variables related to switching to sort-based aggregation\n+  ///////////////////////////////////////////////////////////////////////////\n+  private[this] var sortBased = false\n+\n+  private[this] var sortBasedAggregationIterator: SortBasedAggregationIterator = _\n+\n+  // The value part of the input KV iterator is used to store original input values of\n+  // aggregate functions, we need to convert them to aggregation buffers.\n+  private def processOriginalInput(\n+      firstKey: UnsafeRow,\n+      firstValue: InternalRow): KVIterator[UnsafeRow, UnsafeRow] = {\n+    new KVIterator[UnsafeRow, UnsafeRow] {\n+      private[this] var isFirstRow = true\n+\n+      private[this] var groupingKey: UnsafeRow = _\n+\n+      private[this] val buffer: UnsafeRow = newBuffer\n+\n+      override def next(): Boolean = {\n+        initializeBuffer(buffer)\n+        if (isFirstRow) {\n+          isFirstRow = false\n+          groupingKey = firstKey\n+          processRow(buffer, firstValue)\n+\n+          true\n+        } else if (inputKVIterator.next()) {\n+          groupingKey = inputKVIterator.getKey()\n+          val value = inputKVIterator.getValue()\n+          processRow(buffer, value)\n+\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+\n+      override def getKey(): UnsafeRow = {\n+        groupingKey\n+      }\n+\n+      override def getValue(): UnsafeRow = {\n+        buffer\n+      }\n+\n+      override def close(): Unit = {\n+        // Do nothing.\n+      }\n+    }\n+  }\n+\n+  // The value of the input KV Iterator has the format of groupingExprs + aggregation buffer.\n+  // We need to project the aggregation buffer out.\n+  private def projectInputBufferToUnsafe(\n+      firstKey: UnsafeRow,\n+      firstValue: InternalRow): KVIterator[UnsafeRow, UnsafeRow] = {\n+    new KVIterator[UnsafeRow, UnsafeRow] {\n+      private[this] var isFirstRow = true\n+\n+      private[this] var groupingKey: UnsafeRow = _\n+\n+      private[this] val bufferSchema = allAggregateFunctions.flatMap(_.bufferAttributes)\n+\n+      private[this] val value: UnsafeRow = {\n+        val genericMutableRow = new GenericMutableRow(bufferSchema.length)\n+        UnsafeProjection.create(bufferSchema.map(_.dataType)).apply(genericMutableRow)\n+      }\n+\n+      private[this] val projectInputBuffer = {\n+        newMutableProjection(bufferSchema, valueAttributes)().target(value)\n+      }\n+\n+      override def next(): Boolean = {\n+        if (isFirstRow) {\n+          isFirstRow = false\n+          groupingKey = firstKey\n+          projectInputBuffer(firstValue)\n+\n+          true\n+        } else if (inputKVIterator.next()) {\n+          groupingKey = inputKVIterator.getKey()\n+          projectInputBuffer(inputKVIterator.getValue())\n+\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+\n+      override def getKey(): UnsafeRow = {\n+        groupingKey\n+      }\n+\n+      override def getValue(): UnsafeRow = {\n+        value\n+      }\n+\n+      override def close(): Unit = {\n+        // Do nothing.\n+      }\n+    }\n+  }\n+\n+  /**\n+   * We need to fall back to sort based aggregation because we do not have enough memory\n+   * for our in-memory hash map (i.e. `buffers`).\n+   */\n+  private def switchToSortBasedAggregation(\n+      currentGroupingKey: UnsafeRow,\n+      currentRow: InternalRow): Unit = {\n+    logInfo(\"falling back to sort based aggregation.\")\n+\n+    // Step 1: Get the ExternalSorter containing entries of the map.\n+    val externalSorter = buffers.destructAndCreateExternalSorter()\n+\n+    // Step 2: Free the memory used by the map.\n+    buffers.free()\n+\n+    // Step 3: If we have aggregate function with mode Partial or Complete,\n+    // we need to process them to get aggregation buffer.\n+    // So, later in the sort-based aggregation iterator, we can do merge.\n+    // If aggregate functions are with mode Final and PartialMerge,\n+    // we just need to project the aggregation buffer from the input.\n+    val needsProcess = aggregationMode match {\n+      case (Some(Partial), None) => true\n+      case (None, Some(Complete)) => true\n+      case (Some(Final), Some(Complete)) => true\n+      case _ => false\n+    }\n+\n+    val processedIterator = if (needsProcess) {\n+      processOriginalInput(currentGroupingKey, currentRow)\n+    } else {\n+      // The input value's format is groupingExprs + buffer.\n+      // We need to project the buffer part out.\n+      projectInputBufferToUnsafe(currentGroupingKey, currentRow)\n+    }\n+\n+    // Step 4: Redirect processedIterator to externalSorter.\n+    while (processedIterator.next()) {\n+      externalSorter.insertKV(processedIterator.getKey(), processedIterator.getValue())\n+    }\n+\n+    // Step 5: Get the sorted iterator from the externalSorter.\n+    val sortedKVIterator: KVIterator[UnsafeRow, UnsafeRow] = externalSorter.sortedIterator()\n+\n+    // Step 6: We now create a SortBasedAggregationIterator based on sortedKVIterator.\n+    // For a aggregate function with mode Partial, its mode in the SortBasedAggregationIterator\n+    // will be PartialMerge. For a aggregate function with mode Complete,\n+    // its mode in the SortBasedAggregationIterator will be Final.\n+    val newNonCompleteAggregateExpressions = allAggregateExpressions.map {\n+        case AggregateExpression2(func, Partial, isDistinct) =>\n+          AggregateExpression2(func, PartialMerge, isDistinct)\n+        case AggregateExpression2(func, Complete, isDistinct) =>\n+          AggregateExpression2(func, Final, isDistinct)\n+        case other => other\n+      }\n+    val newNonCompleteAggregateAttributes =\n+      nonCompleteAggregateAttributes ++ completeAggregateAttributes\n+\n+    val newValueAttributes =\n+      allAggregateExpressions.flatMap(_.aggregateFunction.cloneBufferAttributes)\n+\n+    sortBasedAggregationIterator = SortBasedAggregationIterator.createFromKVIterator(\n+      groupingKeyAttributes = groupingKeyAttributes,\n+      valueAttributes = newValueAttributes,\n+      inputKVIterator = sortedKVIterator.asInstanceOf[KVIterator[InternalRow, InternalRow]],\n+      nonCompleteAggregateExpressions = newNonCompleteAggregateExpressions,\n+      nonCompleteAggregateAttributes = newNonCompleteAggregateAttributes,\n+      completeAggregateExpressions = Nil,\n+      completeAggregateAttributes = Nil,\n+      initialInputBufferOffset = 0,\n+      resultExpressions = resultExpressions,\n+      newMutableProjection = newMutableProjection,\n+      outputsUnsafeRows = outputsUnsafeRows)\n+  }\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Methods used to initialize this iterator.\n+  ///////////////////////////////////////////////////////////////////////////\n+\n+  /** Starts to read input rows and falls back to sort-based aggregation if necessary. */\n+  protected def initialize(): Unit = {\n+    var hasNext = inputKVIterator.next()\n+    while (!sortBased && hasNext) {\n+      val groupingKey = inputKVIterator.getKey()\n+      val currentRow = inputKVIterator.getValue()\n+      val buffer = buffers.getAggregationBuffer(groupingKey)\n+      if (buffer == null) {\n+        // buffer == null means that we could not allocate more memory.\n+        // Now, we need to spill the map and switch to sort-based aggregation.\n+        switchToSortBasedAggregation(groupingKey, currentRow)\n+        sortBased = true\n+      } else {\n+        processRow(buffer, currentRow)\n+        hasNext = inputKVIterator.next()\n+      }\n+    }\n+  }\n+\n+  // This is the starting point of this iterator.\n+  initialize()\n+\n+  // Creates the iterator for the Hash Aggregation Map after we have populated\n+  // contents of that map.\n+  private[this] val aggregationBufferMapIterator = buffers.iterator()\n+\n+  private[this] var _mapIteratorHasNext = false\n+\n+  // Pre-load the first key-value pair from the map to make hasNext idempotent.\n+  if (!sortBased) {\n+    _mapIteratorHasNext = aggregationBufferMapIterator.next()\n+    // If the map is empty, we just free it.\n+    if (!_mapIteratorHasNext) {\n+      buffers.free()\n+    }\n+  }\n+\n+  ///////////////////////////////////////////////////////////////////////////\n+  // Iterator's public methods\n+  ///////////////////////////////////////////////////////////////////////////\n+\n+  override final def hasNext: Boolean = {\n+    (sortBased && sortBasedAggregationIterator.hasNext) || (!sortBased && _mapIteratorHasNext)\n+  }\n+\n+\n+  override final def next(): InternalRow = {\n+    if (hasNext) {\n+      if (sortBased) {\n+        sortBasedAggregationIterator.next()\n+      } else {\n+        // We did not fall back to the sort-based aggregation.\n+        val result =\n+          generateOutput(",
    "line": 323
  }],
  "prId": 7813
}]