[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "why not just use the annotation?\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T20:58:31Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting",
    "line": 40
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "This has a lot of mutable fields so it shouldn't be a case class. I would just make it a normal class.\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:03:10Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the\n+          // accumulator updates. However, if there are two same task are running, such as\n+          // speculation, the accumulator updates will be overriding by different task attempts,\n+          // the results will be weird.\n+          stageMetrics.taskIdToMetricUpdates.get(taskId) match {\n+            case Some(taskMetrics) =>\n+              if (finishTask) {\n+                taskMetrics.finished = true\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              } else if (!taskMetrics.finished){\n+                // If a task is finished, we should not override with accumulator updates from\n+                // heartbeat reports\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              }\n+            case None =>\n+              // TODO Now just set attemptId to 0. Should fix here when we can get the attempt\n+              // id from SparkListenerExecutorMetricsUpdate\n+              stageMetrics.taskIdToMetricUpdates(taskId) =\n+                SQLTaskMetrics(attemptId = 0, finished = finishTask, metrics.accumulatorUpdates())\n+          }\n+        }\n+      case None =>\n+      // This execution and its stage have been dropped\n+    }\n+  }\n+\n+  def onExecutionStart(\n+      executionId: Long,\n+      description: String,\n+      details: String,\n+      df: DataFrame,\n+      time: Long): Unit = {\n+    val physicalPlanDescription = df.queryExecution.toString\n+    val physicalPlanGraph = SparkPlanGraph(df.queryExecution.executedPlan)\n+    val metrics = physicalPlanGraph.nodes.flatMap { node =>\n+      node.metrics.map(metric => metric.accumulatorId -> metric)\n+    }\n+\n+    val executionUIData = SQLExecutionUIData(executionId, description, details,\n+      physicalPlanDescription, physicalPlanGraph, metrics.toMap, time)\n+\n+    synchronized {\n+      activeExecutions(executionId) = executionUIData\n+      executionIdToData(executionId) = executionUIData\n+    }\n+  }\n+\n+  def onExecutionEnd(executionId: Long, time: Long): Unit = synchronized {\n+    executionIdToData.get(executionId).foreach { executionUIData =>\n+      executionUIData.completionTime = Some(time)\n+      if (!executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens after all \"onJobEnd\"s\n+        // So we should update the execution lists.\n+        updateExecutionLists(executionId)\n+      } else {\n+        // There are some running jobs, onExecutionEnd happens before some \"onJobEnd\"s.\n+        // Then we don't if the execution is successful, so let the last onJobEnd updates the\n+        // execution lists.\n+      }\n+    }\n+  }\n+\n+  private def updateExecutionLists(executionId: Long): Unit = {\n+    activeExecutions.remove(executionId).foreach { executionUIData =>\n+      if (executionUIData.isFailed) {\n+        failedExecutions += executionUIData\n+        trimExecutionsIfNecessary(failedExecutions)\n+      } else {\n+        completedExecutions += executionUIData\n+        trimExecutionsIfNecessary(completedExecutions)\n+      }\n+    }\n+  }\n+\n+  def getRunningExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    activeExecutions.values.toSeq\n+  }\n+\n+  def getFailedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    failedExecutions\n+  }\n+\n+  def getCompletedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    completedExecutions\n+  }\n+\n+  def getExecution(executionId: Long): Option[SQLExecutionUIData] = synchronized {\n+    executionIdToData.get(executionId)\n+  }\n+\n+  def getExecutionMetrics(executionId: Long): Map[Long, Any] = synchronized {\n+    executionIdToData.get(executionId) match {\n+      case Some(executionUIData) =>\n+        // Get all accumulator updates from all tasks which belong to this execution and merge them\n+        val accumulatorUpdates = {\n+          for (stageId <- executionUIData.stages;\n+               stageMetrics <- stageIdToStageMetrics.get(stageId).toIterable;\n+               taskMetrics <- stageMetrics.taskIdToMetricUpdates.values;\n+               accumulatorUpdate <- taskMetrics.accumulatorUpdates.toSeq)\n+            yield accumulatorUpdate\n+        }\n+        mergeAccumulatorUpdates(accumulatorUpdates, accumulatorId =>\n+          executionUIData.accumulatorMetrics(accumulatorId).accumulatorParam)\n+      case None =>\n+        // This execution has been dropped\n+        Map.empty\n+    }\n+  }\n+\n+  private def mergeAccumulatorUpdates(\n+     accumulatorUpdates: Seq[(Long, Any)],\n+     paramFunc: Long => AccumulatorParam[Any]): Map[Long, Any] = {\n+    accumulatorUpdates.groupBy(_._1).map { case (accumulatorId, values) =>\n+      val param = paramFunc(accumulatorId)\n+      (accumulatorId, values.map(_._2).reduceLeft(param.addInPlace))\n+    }\n+  }\n+\n+}\n+\n+/**\n+ * Represent all necessary data for an execution that will be used in Web UI.\n+ */\n+private[ui] case class SQLExecutionUIData("
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "same in other case classes in this file\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:03:44Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the\n+          // accumulator updates. However, if there are two same task are running, such as\n+          // speculation, the accumulator updates will be overriding by different task attempts,\n+          // the results will be weird.\n+          stageMetrics.taskIdToMetricUpdates.get(taskId) match {\n+            case Some(taskMetrics) =>\n+              if (finishTask) {\n+                taskMetrics.finished = true\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              } else if (!taskMetrics.finished){\n+                // If a task is finished, we should not override with accumulator updates from\n+                // heartbeat reports\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              }\n+            case None =>\n+              // TODO Now just set attemptId to 0. Should fix here when we can get the attempt\n+              // id from SparkListenerExecutorMetricsUpdate\n+              stageMetrics.taskIdToMetricUpdates(taskId) =\n+                SQLTaskMetrics(attemptId = 0, finished = finishTask, metrics.accumulatorUpdates())\n+          }\n+        }\n+      case None =>\n+      // This execution and its stage have been dropped\n+    }\n+  }\n+\n+  def onExecutionStart(\n+      executionId: Long,\n+      description: String,\n+      details: String,\n+      df: DataFrame,\n+      time: Long): Unit = {\n+    val physicalPlanDescription = df.queryExecution.toString\n+    val physicalPlanGraph = SparkPlanGraph(df.queryExecution.executedPlan)\n+    val metrics = physicalPlanGraph.nodes.flatMap { node =>\n+      node.metrics.map(metric => metric.accumulatorId -> metric)\n+    }\n+\n+    val executionUIData = SQLExecutionUIData(executionId, description, details,\n+      physicalPlanDescription, physicalPlanGraph, metrics.toMap, time)\n+\n+    synchronized {\n+      activeExecutions(executionId) = executionUIData\n+      executionIdToData(executionId) = executionUIData\n+    }\n+  }\n+\n+  def onExecutionEnd(executionId: Long, time: Long): Unit = synchronized {\n+    executionIdToData.get(executionId).foreach { executionUIData =>\n+      executionUIData.completionTime = Some(time)\n+      if (!executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens after all \"onJobEnd\"s\n+        // So we should update the execution lists.\n+        updateExecutionLists(executionId)\n+      } else {\n+        // There are some running jobs, onExecutionEnd happens before some \"onJobEnd\"s.\n+        // Then we don't if the execution is successful, so let the last onJobEnd updates the\n+        // execution lists.\n+      }\n+    }\n+  }\n+\n+  private def updateExecutionLists(executionId: Long): Unit = {\n+    activeExecutions.remove(executionId).foreach { executionUIData =>\n+      if (executionUIData.isFailed) {\n+        failedExecutions += executionUIData\n+        trimExecutionsIfNecessary(failedExecutions)\n+      } else {\n+        completedExecutions += executionUIData\n+        trimExecutionsIfNecessary(completedExecutions)\n+      }\n+    }\n+  }\n+\n+  def getRunningExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    activeExecutions.values.toSeq\n+  }\n+\n+  def getFailedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    failedExecutions\n+  }\n+\n+  def getCompletedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    completedExecutions\n+  }\n+\n+  def getExecution(executionId: Long): Option[SQLExecutionUIData] = synchronized {\n+    executionIdToData.get(executionId)\n+  }\n+\n+  def getExecutionMetrics(executionId: Long): Map[Long, Any] = synchronized {\n+    executionIdToData.get(executionId) match {\n+      case Some(executionUIData) =>\n+        // Get all accumulator updates from all tasks which belong to this execution and merge them\n+        val accumulatorUpdates = {\n+          for (stageId <- executionUIData.stages;\n+               stageMetrics <- stageIdToStageMetrics.get(stageId).toIterable;\n+               taskMetrics <- stageMetrics.taskIdToMetricUpdates.values;\n+               accumulatorUpdate <- taskMetrics.accumulatorUpdates.toSeq)\n+            yield accumulatorUpdate\n+        }\n+        mergeAccumulatorUpdates(accumulatorUpdates, accumulatorId =>\n+          executionUIData.accumulatorMetrics(accumulatorId).accumulatorParam)\n+      case None =>\n+        // This execution has been dropped\n+        Map.empty\n+    }\n+  }\n+\n+  private def mergeAccumulatorUpdates(\n+     accumulatorUpdates: Seq[(Long, Any)],\n+     paramFunc: Long => AccumulatorParam[Any]): Map[Long, Any] = {\n+    accumulatorUpdates.groupBy(_._1).map { case (accumulatorId, values) =>\n+      val param = paramFunc(accumulatorId)\n+      (accumulatorId, values.map(_._2).reduceLeft(param.addInPlace))\n+    }\n+  }\n+\n+}\n+\n+/**\n+ * Represent all necessary data for an execution that will be used in Web UI.\n+ */\n+private[ui] case class SQLExecutionUIData("
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "we should probably make this fully `private val _executionIdToData`, and then have a public getter `def executionIdToData: Map[Long, SQLExecutionUIData]`. I would recommend that we do it for other data structures in this class too instead of just exposing the size, so we can assert something stronger.\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:15:59Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "as mentioned up there, it would be good to expose the map itself as an immutable `Map[Long, SQLStageMetrics]` so we can assert something stronger in the tests. Same in other methods in this class.\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:17:09Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "Return whether there are running jobs in this execution.\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:21:32Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the\n+          // accumulator updates. However, if there are two same task are running, such as\n+          // speculation, the accumulator updates will be overriding by different task attempts,\n+          // the results will be weird.\n+          stageMetrics.taskIdToMetricUpdates.get(taskId) match {\n+            case Some(taskMetrics) =>\n+              if (finishTask) {\n+                taskMetrics.finished = true\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              } else if (!taskMetrics.finished){\n+                // If a task is finished, we should not override with accumulator updates from\n+                // heartbeat reports\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              }\n+            case None =>\n+              // TODO Now just set attemptId to 0. Should fix here when we can get the attempt\n+              // id from SparkListenerExecutorMetricsUpdate\n+              stageMetrics.taskIdToMetricUpdates(taskId) =\n+                SQLTaskMetrics(attemptId = 0, finished = finishTask, metrics.accumulatorUpdates())\n+          }\n+        }\n+      case None =>\n+      // This execution and its stage have been dropped\n+    }\n+  }\n+\n+  def onExecutionStart(\n+      executionId: Long,\n+      description: String,\n+      details: String,\n+      df: DataFrame,\n+      time: Long): Unit = {\n+    val physicalPlanDescription = df.queryExecution.toString\n+    val physicalPlanGraph = SparkPlanGraph(df.queryExecution.executedPlan)\n+    val metrics = physicalPlanGraph.nodes.flatMap { node =>\n+      node.metrics.map(metric => metric.accumulatorId -> metric)\n+    }\n+\n+    val executionUIData = SQLExecutionUIData(executionId, description, details,\n+      physicalPlanDescription, physicalPlanGraph, metrics.toMap, time)\n+\n+    synchronized {\n+      activeExecutions(executionId) = executionUIData\n+      executionIdToData(executionId) = executionUIData\n+    }\n+  }\n+\n+  def onExecutionEnd(executionId: Long, time: Long): Unit = synchronized {\n+    executionIdToData.get(executionId).foreach { executionUIData =>\n+      executionUIData.completionTime = Some(time)\n+      if (!executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens after all \"onJobEnd\"s\n+        // So we should update the execution lists.\n+        updateExecutionLists(executionId)\n+      } else {\n+        // There are some running jobs, onExecutionEnd happens before some \"onJobEnd\"s.\n+        // Then we don't if the execution is successful, so let the last onJobEnd updates the\n+        // execution lists.\n+      }\n+    }\n+  }\n+\n+  private def updateExecutionLists(executionId: Long): Unit = {\n+    activeExecutions.remove(executionId).foreach { executionUIData =>\n+      if (executionUIData.isFailed) {\n+        failedExecutions += executionUIData\n+        trimExecutionsIfNecessary(failedExecutions)\n+      } else {\n+        completedExecutions += executionUIData\n+        trimExecutionsIfNecessary(completedExecutions)\n+      }\n+    }\n+  }\n+\n+  def getRunningExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    activeExecutions.values.toSeq\n+  }\n+\n+  def getFailedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    failedExecutions\n+  }\n+\n+  def getCompletedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    completedExecutions\n+  }\n+\n+  def getExecution(executionId: Long): Option[SQLExecutionUIData] = synchronized {\n+    executionIdToData.get(executionId)\n+  }\n+\n+  def getExecutionMetrics(executionId: Long): Map[Long, Any] = synchronized {\n+    executionIdToData.get(executionId) match {\n+      case Some(executionUIData) =>\n+        // Get all accumulator updates from all tasks which belong to this execution and merge them\n+        val accumulatorUpdates = {\n+          for (stageId <- executionUIData.stages;\n+               stageMetrics <- stageIdToStageMetrics.get(stageId).toIterable;\n+               taskMetrics <- stageMetrics.taskIdToMetricUpdates.values;\n+               accumulatorUpdate <- taskMetrics.accumulatorUpdates.toSeq)\n+            yield accumulatorUpdate\n+        }\n+        mergeAccumulatorUpdates(accumulatorUpdates, accumulatorId =>\n+          executionUIData.accumulatorMetrics(accumulatorId).accumulatorParam)\n+      case None =>\n+        // This execution has been dropped\n+        Map.empty\n+    }\n+  }\n+\n+  private def mergeAccumulatorUpdates(\n+     accumulatorUpdates: Seq[(Long, Any)],\n+     paramFunc: Long => AccumulatorParam[Any]): Map[Long, Any] = {\n+    accumulatorUpdates.groupBy(_._1).map { case (accumulatorId, values) =>\n+      val param = paramFunc(accumulatorId)\n+      (accumulatorId, values.map(_._2).reduceLeft(param.addInPlace))\n+    }\n+  }\n+\n+}\n+\n+/**\n+ * Represent all necessary data for an execution that will be used in Web UI.\n+ */\n+private[ui] case class SQLExecutionUIData(\n+    executionId: Long,\n+    description: String,\n+    details: String,\n+    physicalPlanDescription: String,\n+    physicalPlanGraph: SparkPlanGraph,\n+    accumulatorMetrics: Map[Long, SQLPlanMetric],\n+    submissionTime: Long,\n+    var completionTime: Option[Long] = None,\n+    jobs: mutable.HashMap[Long, JobExecutionStatus] = mutable.HashMap.empty,\n+    stages: mutable.ArrayBuffer[Int] = mutable.ArrayBuffer()) {\n+\n+  /**\n+   * Return if there is no running job."
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "Return whether there are any failed jobs in this execution.\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:48:11Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the\n+          // accumulator updates. However, if there are two same task are running, such as\n+          // speculation, the accumulator updates will be overriding by different task attempts,\n+          // the results will be weird.\n+          stageMetrics.taskIdToMetricUpdates.get(taskId) match {\n+            case Some(taskMetrics) =>\n+              if (finishTask) {\n+                taskMetrics.finished = true\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              } else if (!taskMetrics.finished){\n+                // If a task is finished, we should not override with accumulator updates from\n+                // heartbeat reports\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              }\n+            case None =>\n+              // TODO Now just set attemptId to 0. Should fix here when we can get the attempt\n+              // id from SparkListenerExecutorMetricsUpdate\n+              stageMetrics.taskIdToMetricUpdates(taskId) =\n+                SQLTaskMetrics(attemptId = 0, finished = finishTask, metrics.accumulatorUpdates())\n+          }\n+        }\n+      case None =>\n+      // This execution and its stage have been dropped\n+    }\n+  }\n+\n+  def onExecutionStart(\n+      executionId: Long,\n+      description: String,\n+      details: String,\n+      df: DataFrame,\n+      time: Long): Unit = {\n+    val physicalPlanDescription = df.queryExecution.toString\n+    val physicalPlanGraph = SparkPlanGraph(df.queryExecution.executedPlan)\n+    val metrics = physicalPlanGraph.nodes.flatMap { node =>\n+      node.metrics.map(metric => metric.accumulatorId -> metric)\n+    }\n+\n+    val executionUIData = SQLExecutionUIData(executionId, description, details,\n+      physicalPlanDescription, physicalPlanGraph, metrics.toMap, time)\n+\n+    synchronized {\n+      activeExecutions(executionId) = executionUIData\n+      executionIdToData(executionId) = executionUIData\n+    }\n+  }\n+\n+  def onExecutionEnd(executionId: Long, time: Long): Unit = synchronized {\n+    executionIdToData.get(executionId).foreach { executionUIData =>\n+      executionUIData.completionTime = Some(time)\n+      if (!executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens after all \"onJobEnd\"s\n+        // So we should update the execution lists.\n+        updateExecutionLists(executionId)\n+      } else {\n+        // There are some running jobs, onExecutionEnd happens before some \"onJobEnd\"s.\n+        // Then we don't if the execution is successful, so let the last onJobEnd updates the\n+        // execution lists.\n+      }\n+    }\n+  }\n+\n+  private def updateExecutionLists(executionId: Long): Unit = {\n+    activeExecutions.remove(executionId).foreach { executionUIData =>\n+      if (executionUIData.isFailed) {\n+        failedExecutions += executionUIData\n+        trimExecutionsIfNecessary(failedExecutions)\n+      } else {\n+        completedExecutions += executionUIData\n+        trimExecutionsIfNecessary(completedExecutions)\n+      }\n+    }\n+  }\n+\n+  def getRunningExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    activeExecutions.values.toSeq\n+  }\n+\n+  def getFailedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    failedExecutions\n+  }\n+\n+  def getCompletedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    completedExecutions\n+  }\n+\n+  def getExecution(executionId: Long): Option[SQLExecutionUIData] = synchronized {\n+    executionIdToData.get(executionId)\n+  }\n+\n+  def getExecutionMetrics(executionId: Long): Map[Long, Any] = synchronized {\n+    executionIdToData.get(executionId) match {\n+      case Some(executionUIData) =>\n+        // Get all accumulator updates from all tasks which belong to this execution and merge them\n+        val accumulatorUpdates = {\n+          for (stageId <- executionUIData.stages;\n+               stageMetrics <- stageIdToStageMetrics.get(stageId).toIterable;\n+               taskMetrics <- stageMetrics.taskIdToMetricUpdates.values;\n+               accumulatorUpdate <- taskMetrics.accumulatorUpdates.toSeq)\n+            yield accumulatorUpdate\n+        }\n+        mergeAccumulatorUpdates(accumulatorUpdates, accumulatorId =>\n+          executionUIData.accumulatorMetrics(accumulatorId).accumulatorParam)\n+      case None =>\n+        // This execution has been dropped\n+        Map.empty\n+    }\n+  }\n+\n+  private def mergeAccumulatorUpdates(\n+     accumulatorUpdates: Seq[(Long, Any)],\n+     paramFunc: Long => AccumulatorParam[Any]): Map[Long, Any] = {\n+    accumulatorUpdates.groupBy(_._1).map { case (accumulatorId, values) =>\n+      val param = paramFunc(accumulatorId)\n+      (accumulatorId, values.map(_._2).reduceLeft(param.addInPlace))\n+    }\n+  }\n+\n+}\n+\n+/**\n+ * Represent all necessary data for an execution that will be used in Web UI.\n+ */\n+private[ui] case class SQLExecutionUIData(\n+    executionId: Long,\n+    description: String,\n+    details: String,\n+    physicalPlanDescription: String,\n+    physicalPlanGraph: SparkPlanGraph,\n+    accumulatorMetrics: Map[Long, SQLPlanMetric],\n+    submissionTime: Long,\n+    var completionTime: Option[Long] = None,\n+    jobs: mutable.HashMap[Long, JobExecutionStatus] = mutable.HashMap.empty,\n+    stages: mutable.ArrayBuffer[Int] = mutable.ArrayBuffer()) {\n+\n+  /**\n+   * Return if there is no running job.\n+   */\n+  def hasRunningJobs: Boolean = jobs.values.exists(_ == JobExecutionStatus.RUNNING)\n+\n+  /**\n+   * Return if there is any failed job."
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "these need to be indented 1 more space?\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:48:36Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the\n+          // accumulator updates. However, if there are two same task are running, such as\n+          // speculation, the accumulator updates will be overriding by different task attempts,\n+          // the results will be weird.\n+          stageMetrics.taskIdToMetricUpdates.get(taskId) match {\n+            case Some(taskMetrics) =>\n+              if (finishTask) {\n+                taskMetrics.finished = true\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              } else if (!taskMetrics.finished){\n+                // If a task is finished, we should not override with accumulator updates from\n+                // heartbeat reports\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              }\n+            case None =>\n+              // TODO Now just set attemptId to 0. Should fix here when we can get the attempt\n+              // id from SparkListenerExecutorMetricsUpdate\n+              stageMetrics.taskIdToMetricUpdates(taskId) =\n+                SQLTaskMetrics(attemptId = 0, finished = finishTask, metrics.accumulatorUpdates())\n+          }\n+        }\n+      case None =>\n+      // This execution and its stage have been dropped\n+    }\n+  }\n+\n+  def onExecutionStart(\n+      executionId: Long,\n+      description: String,\n+      details: String,\n+      df: DataFrame,\n+      time: Long): Unit = {\n+    val physicalPlanDescription = df.queryExecution.toString\n+    val physicalPlanGraph = SparkPlanGraph(df.queryExecution.executedPlan)\n+    val metrics = physicalPlanGraph.nodes.flatMap { node =>\n+      node.metrics.map(metric => metric.accumulatorId -> metric)\n+    }\n+\n+    val executionUIData = SQLExecutionUIData(executionId, description, details,\n+      physicalPlanDescription, physicalPlanGraph, metrics.toMap, time)\n+\n+    synchronized {\n+      activeExecutions(executionId) = executionUIData\n+      executionIdToData(executionId) = executionUIData\n+    }\n+  }\n+\n+  def onExecutionEnd(executionId: Long, time: Long): Unit = synchronized {\n+    executionIdToData.get(executionId).foreach { executionUIData =>\n+      executionUIData.completionTime = Some(time)\n+      if (!executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens after all \"onJobEnd\"s\n+        // So we should update the execution lists.\n+        updateExecutionLists(executionId)\n+      } else {\n+        // There are some running jobs, onExecutionEnd happens before some \"onJobEnd\"s.\n+        // Then we don't if the execution is successful, so let the last onJobEnd updates the\n+        // execution lists.\n+      }\n+    }\n+  }\n+\n+  private def updateExecutionLists(executionId: Long): Unit = {\n+    activeExecutions.remove(executionId).foreach { executionUIData =>\n+      if (executionUIData.isFailed) {\n+        failedExecutions += executionUIData\n+        trimExecutionsIfNecessary(failedExecutions)\n+      } else {\n+        completedExecutions += executionUIData\n+        trimExecutionsIfNecessary(completedExecutions)\n+      }\n+    }\n+  }\n+\n+  def getRunningExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    activeExecutions.values.toSeq\n+  }\n+\n+  def getFailedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    failedExecutions\n+  }\n+\n+  def getCompletedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    completedExecutions\n+  }\n+\n+  def getExecution(executionId: Long): Option[SQLExecutionUIData] = synchronized {\n+    executionIdToData.get(executionId)\n+  }\n+\n+  def getExecutionMetrics(executionId: Long): Map[Long, Any] = synchronized {\n+    executionIdToData.get(executionId) match {\n+      case Some(executionUIData) =>\n+        // Get all accumulator updates from all tasks which belong to this execution and merge them\n+        val accumulatorUpdates = {\n+          for (stageId <- executionUIData.stages;\n+               stageMetrics <- stageIdToStageMetrics.get(stageId).toIterable;\n+               taskMetrics <- stageMetrics.taskIdToMetricUpdates.values;\n+               accumulatorUpdate <- taskMetrics.accumulatorUpdates.toSeq)\n+            yield accumulatorUpdate\n+        }\n+        mergeAccumulatorUpdates(accumulatorUpdates, accumulatorId =>\n+          executionUIData.accumulatorMetrics(accumulatorId).accumulatorParam)\n+      case None =>\n+        // This execution has been dropped\n+        Map.empty\n+    }\n+  }\n+\n+  private def mergeAccumulatorUpdates(\n+     accumulatorUpdates: Seq[(Long, Any)],\n+     paramFunc: Long => AccumulatorParam[Any]): Map[Long, Any] = {"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "style: need `{ }` around for loop body\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:48:59Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the\n+          // accumulator updates. However, if there are two same task are running, such as\n+          // speculation, the accumulator updates will be overriding by different task attempts,\n+          // the results will be weird.\n+          stageMetrics.taskIdToMetricUpdates.get(taskId) match {\n+            case Some(taskMetrics) =>\n+              if (finishTask) {\n+                taskMetrics.finished = true\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              } else if (!taskMetrics.finished){\n+                // If a task is finished, we should not override with accumulator updates from\n+                // heartbeat reports\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              }\n+            case None =>\n+              // TODO Now just set attemptId to 0. Should fix here when we can get the attempt\n+              // id from SparkListenerExecutorMetricsUpdate\n+              stageMetrics.taskIdToMetricUpdates(taskId) =\n+                SQLTaskMetrics(attemptId = 0, finished = finishTask, metrics.accumulatorUpdates())\n+          }\n+        }\n+      case None =>\n+      // This execution and its stage have been dropped\n+    }\n+  }\n+\n+  def onExecutionStart(\n+      executionId: Long,\n+      description: String,\n+      details: String,\n+      df: DataFrame,\n+      time: Long): Unit = {\n+    val physicalPlanDescription = df.queryExecution.toString\n+    val physicalPlanGraph = SparkPlanGraph(df.queryExecution.executedPlan)\n+    val metrics = physicalPlanGraph.nodes.flatMap { node =>\n+      node.metrics.map(metric => metric.accumulatorId -> metric)\n+    }\n+\n+    val executionUIData = SQLExecutionUIData(executionId, description, details,\n+      physicalPlanDescription, physicalPlanGraph, metrics.toMap, time)\n+\n+    synchronized {\n+      activeExecutions(executionId) = executionUIData\n+      executionIdToData(executionId) = executionUIData\n+    }\n+  }\n+\n+  def onExecutionEnd(executionId: Long, time: Long): Unit = synchronized {\n+    executionIdToData.get(executionId).foreach { executionUIData =>\n+      executionUIData.completionTime = Some(time)\n+      if (!executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens after all \"onJobEnd\"s\n+        // So we should update the execution lists.\n+        updateExecutionLists(executionId)\n+      } else {\n+        // There are some running jobs, onExecutionEnd happens before some \"onJobEnd\"s.\n+        // Then we don't if the execution is successful, so let the last onJobEnd updates the\n+        // execution lists.\n+      }\n+    }\n+  }\n+\n+  private def updateExecutionLists(executionId: Long): Unit = {\n+    activeExecutions.remove(executionId).foreach { executionUIData =>\n+      if (executionUIData.isFailed) {\n+        failedExecutions += executionUIData\n+        trimExecutionsIfNecessary(failedExecutions)\n+      } else {\n+        completedExecutions += executionUIData\n+        trimExecutionsIfNecessary(completedExecutions)\n+      }\n+    }\n+  }\n+\n+  def getRunningExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    activeExecutions.values.toSeq\n+  }\n+\n+  def getFailedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    failedExecutions\n+  }\n+\n+  def getCompletedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    completedExecutions\n+  }\n+\n+  def getExecution(executionId: Long): Option[SQLExecutionUIData] = synchronized {\n+    executionIdToData.get(executionId)\n+  }\n+\n+  def getExecutionMetrics(executionId: Long): Map[Long, Any] = synchronized {\n+    executionIdToData.get(executionId) match {\n+      case Some(executionUIData) =>\n+        // Get all accumulator updates from all tasks which belong to this execution and merge them\n+        val accumulatorUpdates = {\n+          for (stageId <- executionUIData.stages;\n+               stageMetrics <- stageIdToStageMetrics.get(stageId).toIterable;\n+               taskMetrics <- stageMetrics.taskIdToMetricUpdates.values;\n+               accumulatorUpdate <- taskMetrics.accumulatorUpdates.toSeq)\n+            yield accumulatorUpdate"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "can you add a java doc to this one? It's really returning the values of the metrics, right? Then it merges the accumulators values from all the updates.\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T21:50:16Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the\n+          // accumulator updates. However, if there are two same task are running, such as\n+          // speculation, the accumulator updates will be overriding by different task attempts,\n+          // the results will be weird.\n+          stageMetrics.taskIdToMetricUpdates.get(taskId) match {\n+            case Some(taskMetrics) =>\n+              if (finishTask) {\n+                taskMetrics.finished = true\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              } else if (!taskMetrics.finished){\n+                // If a task is finished, we should not override with accumulator updates from\n+                // heartbeat reports\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              }\n+            case None =>\n+              // TODO Now just set attemptId to 0. Should fix here when we can get the attempt\n+              // id from SparkListenerExecutorMetricsUpdate\n+              stageMetrics.taskIdToMetricUpdates(taskId) =\n+                SQLTaskMetrics(attemptId = 0, finished = finishTask, metrics.accumulatorUpdates())\n+          }\n+        }\n+      case None =>\n+      // This execution and its stage have been dropped\n+    }\n+  }\n+\n+  def onExecutionStart(\n+      executionId: Long,\n+      description: String,\n+      details: String,\n+      df: DataFrame,\n+      time: Long): Unit = {\n+    val physicalPlanDescription = df.queryExecution.toString\n+    val physicalPlanGraph = SparkPlanGraph(df.queryExecution.executedPlan)\n+    val metrics = physicalPlanGraph.nodes.flatMap { node =>\n+      node.metrics.map(metric => metric.accumulatorId -> metric)\n+    }\n+\n+    val executionUIData = SQLExecutionUIData(executionId, description, details,\n+      physicalPlanDescription, physicalPlanGraph, metrics.toMap, time)\n+\n+    synchronized {\n+      activeExecutions(executionId) = executionUIData\n+      executionIdToData(executionId) = executionUIData\n+    }\n+  }\n+\n+  def onExecutionEnd(executionId: Long, time: Long): Unit = synchronized {\n+    executionIdToData.get(executionId).foreach { executionUIData =>\n+      executionUIData.completionTime = Some(time)\n+      if (!executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens after all \"onJobEnd\"s\n+        // So we should update the execution lists.\n+        updateExecutionLists(executionId)\n+      } else {\n+        // There are some running jobs, onExecutionEnd happens before some \"onJobEnd\"s.\n+        // Then we don't if the execution is successful, so let the last onJobEnd updates the\n+        // execution lists.\n+      }\n+    }\n+  }\n+\n+  private def updateExecutionLists(executionId: Long): Unit = {\n+    activeExecutions.remove(executionId).foreach { executionUIData =>\n+      if (executionUIData.isFailed) {\n+        failedExecutions += executionUIData\n+        trimExecutionsIfNecessary(failedExecutions)\n+      } else {\n+        completedExecutions += executionUIData\n+        trimExecutionsIfNecessary(completedExecutions)\n+      }\n+    }\n+  }\n+\n+  def getRunningExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    activeExecutions.values.toSeq\n+  }\n+\n+  def getFailedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    failedExecutions\n+  }\n+\n+  def getCompletedExecutions: Seq[SQLExecutionUIData] = synchronized {\n+    completedExecutions\n+  }\n+\n+  def getExecution(executionId: Long): Option[SQLExecutionUIData] = synchronized {\n+    executionIdToData.get(executionId)\n+  }\n+\n+  def getExecutionMetrics(executionId: Long): Map[Long, Any] = synchronized {"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "nit: this can just be `executionId`, right?\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T22:16:54Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "yes\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T22:17:00Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "this should really be `markExecutionFinished`\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T22:19:58Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the\n+          // accumulator updates. However, if there are two same task are running, such as\n+          // speculation, the accumulator updates will be overriding by different task attempts,\n+          // the results will be weird.\n+          stageMetrics.taskIdToMetricUpdates.get(taskId) match {\n+            case Some(taskMetrics) =>\n+              if (finishTask) {\n+                taskMetrics.finished = true\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              } else if (!taskMetrics.finished){\n+                // If a task is finished, we should not override with accumulator updates from\n+                // heartbeat reports\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              }\n+            case None =>\n+              // TODO Now just set attemptId to 0. Should fix here when we can get the attempt\n+              // id from SparkListenerExecutorMetricsUpdate\n+              stageMetrics.taskIdToMetricUpdates(taskId) =\n+                SQLTaskMetrics(attemptId = 0, finished = finishTask, metrics.accumulatorUpdates())\n+          }\n+        }\n+      case None =>\n+      // This execution and its stage have been dropped\n+    }\n+  }\n+\n+  def onExecutionStart(\n+      executionId: Long,\n+      description: String,\n+      details: String,\n+      df: DataFrame,\n+      time: Long): Unit = {\n+    val physicalPlanDescription = df.queryExecution.toString\n+    val physicalPlanGraph = SparkPlanGraph(df.queryExecution.executedPlan)\n+    val metrics = physicalPlanGraph.nodes.flatMap { node =>\n+      node.metrics.map(metric => metric.accumulatorId -> metric)\n+    }\n+\n+    val executionUIData = SQLExecutionUIData(executionId, description, details,\n+      physicalPlanDescription, physicalPlanGraph, metrics.toMap, time)\n+\n+    synchronized {\n+      activeExecutions(executionId) = executionUIData\n+      executionIdToData(executionId) = executionUIData\n+    }\n+  }\n+\n+  def onExecutionEnd(executionId: Long, time: Long): Unit = synchronized {\n+    executionIdToData.get(executionId).foreach { executionUIData =>\n+      executionUIData.completionTime = Some(time)\n+      if (!executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens after all \"onJobEnd\"s\n+        // So we should update the execution lists.\n+        updateExecutionLists(executionId)\n+      } else {\n+        // There are some running jobs, onExecutionEnd happens before some \"onJobEnd\"s.\n+        // Then we don't if the execution is successful, so let the last onJobEnd updates the\n+        // execution lists.\n+      }\n+    }\n+  }\n+\n+  private def updateExecutionLists(executionId: Long): Unit = {"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "I would just say\n\n```\n// We are the last job of this execution, so mark the execution as finished. Note that\n// `onExecutionEnd` also does this, but currently that can be called before `onJobEnd`\n// since these are called on different threads.\n```\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T22:23:00Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists."
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "we should probably log a warning here instead of having the TODO here. I don't think this is expected.\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T22:29:06Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "is this because the information is not propagated from `onExecutorMetricsUpdate`? \n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T22:31:03Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "ah, the answer to my question is yes (I just saw the TODO comment in L174 down there).\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T22:33:55Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "space before `{`\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T22:31:18Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the\n+          // accumulator updates. However, if there are two same task are running, such as\n+          // speculation, the accumulator updates will be overriding by different task attempts,\n+          // the results will be weird.\n+          stageMetrics.taskIdToMetricUpdates.get(taskId) match {\n+            case Some(taskMetrics) =>\n+              if (finishTask) {\n+                taskMetrics.finished = true\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              } else if (!taskMetrics.finished){"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "looks like in both cases you update the task metrics' accumulators, so can you rewrite this as:\n\n```\ncase Some(taskMetrics) =>\n  if (finishTask) {\n    taskMetrics.finished = true\n  }\n  taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n```\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T22:32:41Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the\n+          // accumulator updates. However, if there are two same task are running, such as\n+          // speculation, the accumulator updates will be overriding by different task attempts,\n+          // the results will be weird.\n+          stageMetrics.taskIdToMetricUpdates.get(taskId) match {\n+            case Some(taskMetrics) =>\n+              if (finishTask) {\n+                taskMetrics.finished = true\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              } else if (!taskMetrics.finished){\n+                // If a task is finished, we should not override with accumulator updates from\n+                // heartbeat reports\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              }"
  }],
  "prId": 7774
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "Is the following a valid race condition:\n(1) Executor sends heartbeat\n(2) The task finishes, and we call `onTaskEnd`\n(3) We get the heartbeat, and we call `onExecutorMetricsUpdate`\n\nSo the result is that even though the task is finished it may still be marked as incomplete. Should we just ignore all heartbeat updates if the task has already finished?\n",
    "commit": "5a2bc9937bc26e014842b720fd2096294c9272b7",
    "createdAt": "2015-08-03T22:37:04Z",
    "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.ui\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{AccumulatorParam, JobExecutionStatus}\n+import org.apache.spark.executor.TaskMetrics\n+import org.apache.spark.scheduler._\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.SQLExecution\n+\n+private[sql] class SQLListener(sqlContext: SQLContext) extends SparkListener {\n+\n+  private val retainedExecutions =\n+    sqlContext.sparkContext.conf.getInt(\"spark.sql.ui.retainedExecutions\", 1000)\n+\n+  private val activeExecutions = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  // Old data in the following fields must be removed in \"trimExecutionsIfNecessary\".\n+  // If adding new fields, make sure \"trimExecutionsIfNecessary\" can clean up old data\n+\n+  // VisibleForTesting\n+  val executionIdToData = mutable.HashMap[Long, SQLExecutionUIData]()\n+\n+  /**\n+   * Maintain the relation between job id and execution id so that we can get the execution id in\n+   * the \"onJobEnd\" method.\n+   */\n+  private val jobIdToExecutionId = mutable.HashMap[Long, Long]()\n+\n+  private val stageIdToStageMetrics = mutable.HashMap[Long, SQLStageMetrics]()\n+\n+  private val failedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  private val completedExecutions = mutable.ListBuffer[SQLExecutionUIData]()\n+\n+  // VisibleForTesting\n+  def executionIdToDataSize: Int = synchronized {\n+    executionIdToData.size\n+  }\n+\n+  // VisibleForTesting\n+  def jobIdToExecutionIdSize: Int = synchronized {\n+    jobIdToExecutionId.size\n+  }\n+\n+  // VisibleForTesting\n+  def stageIdToStageMetricsSize: Int = synchronized {\n+    stageIdToStageMetrics.size\n+  }\n+\n+  private def trimExecutionsIfNecessary(\n+      executions: mutable.ListBuffer[SQLExecutionUIData]): Unit = {\n+    if (executions.size > retainedExecutions) {\n+      val toRemove = math.max(retainedExecutions / 10, 1)\n+      executions.take(toRemove).foreach { execution =>\n+        for (executionUIData <- executionIdToData.remove(execution.executionId)) {\n+          for (jobId <- executionUIData.jobs.keys) {\n+            jobIdToExecutionId.remove(jobId)\n+          }\n+          for (stageId <- executionUIData.stages) {\n+            stageIdToStageMetrics.remove(stageId)\n+          }\n+        }\n+      }\n+      executions.trimStart(toRemove)\n+    }\n+  }\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val executionId = jobStart.properties.getProperty(SQLExecution.EXECUTION_ID_KEY)\n+    if (executionId == null) {\n+      // This is not a job created by SQL\n+      return\n+    }\n+    val jobId = jobStart.jobId\n+    val stageIds = jobStart.stageIds\n+\n+    synchronized {\n+      activeExecutions.get(executionId.toLong).foreach { executionUIData =>\n+        executionUIData.jobs(jobId) = JobExecutionStatus.RUNNING\n+        executionUIData.stages ++= stageIds\n+        // attemptId must be 0. Right?\n+        stageIds.foreach(stageId =>\n+          stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId = 0))\n+        jobIdToExecutionId(jobId) = executionUIData.executionId\n+      }\n+    }\n+  }\n+\n+  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = synchronized {\n+    val jobId = jobEnd.jobId\n+    for (executionId <- jobIdToExecutionId.get(jobId);\n+         executionUIData <- executionIdToData.get(executionId)) {\n+      jobEnd.jobResult match {\n+        case JobSucceeded => executionUIData.jobs(jobId) = JobExecutionStatus.SUCCEEDED\n+        case JobFailed(_) => executionUIData.jobs(jobId) = JobExecutionStatus.FAILED\n+      }\n+      if (executionUIData.completionTime.nonEmpty && !executionUIData.hasRunningJobs) {\n+        // onExecutionEnd happens before this onJobEnd and we are the last job, so we should update\n+        // the execution lists.\n+        updateExecutionLists(executionId)\n+      }\n+    }\n+  }\n+\n+  override def onExecutorMetricsUpdate(\n+      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = synchronized {\n+    for ((taskId, stageId, stageAttemptID, metrics) <- executorMetricsUpdate.taskMetrics) {\n+      updateTaskMetrics(taskId, stageId, stageAttemptID, metrics, false)\n+    }\n+  }\n+\n+  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = synchronized {\n+    val stageId = stageSubmitted.stageInfo.stageId\n+    val stageAttemptId = stageSubmitted.stageInfo.attemptId\n+    // Always override metrics for old stage attempt\n+    stageIdToStageMetrics(stageId) = SQLStageMetrics(stageAttemptId)\n+  }\n+\n+  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = synchronized {\n+    updateTaskMetrics(\n+      taskEnd.taskInfo.taskId, taskEnd.stageId, taskEnd.stageAttemptId, taskEnd.taskMetrics, true)\n+  }\n+\n+  private def updateTaskMetrics(\n+      taskId: Long,\n+      stageId: Int,\n+      stageAttemptID: Int,\n+      metrics: TaskMetrics,\n+      finishTask: Boolean): Unit = {\n+    if (metrics == null) {\n+      return\n+    }\n+\n+    stageIdToStageMetrics.get(stageId) match {\n+      case Some(stageMetrics) =>\n+        if (stageAttemptID < stageMetrics.stageAttemptId) {\n+          // A task of an old stage attempt. Because a new stage is submitted, we can ignore it.\n+        } else if (stageAttemptID > stageMetrics.stageAttemptId) {\n+          // TODO A running task with a higher stageAttemptID??\n+        } else {\n+          // TODO We don't know the attemptId. Currently, what we can do is overriding the\n+          // accumulator updates. However, if there are two same task are running, such as\n+          // speculation, the accumulator updates will be overriding by different task attempts,\n+          // the results will be weird.\n+          stageMetrics.taskIdToMetricUpdates.get(taskId) match {\n+            case Some(taskMetrics) =>\n+              if (finishTask) {\n+                taskMetrics.finished = true\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              } else if (!taskMetrics.finished){\n+                // If a task is finished, we should not override with accumulator updates from\n+                // heartbeat reports\n+                taskMetrics.accumulatorUpdates = metrics.accumulatorUpdates()\n+              }\n+            case None =>\n+              // TODO Now just set attemptId to 0. Should fix here when we can get the attempt\n+              // id from SparkListenerExecutorMetricsUpdate\n+              stageMetrics.taskIdToMetricUpdates(taskId) =\n+                SQLTaskMetrics(attemptId = 0, finished = finishTask, metrics.accumulatorUpdates())"
  }],
  "prId": 7774
}]