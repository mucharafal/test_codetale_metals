[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "We should add some documentation to explain what the return value is.",
    "commit": "00bb14b0145a2bd42c8b4c8a9d4f108322804f71",
    "createdAt": "2018-01-19T07:16:19Z",
    "diffHunk": "@@ -220,45 +220,76 @@ case class EnsureRequirements(conf: SQLConf) extends Rule[SparkPlan] {\n     operator.withNewChildren(children)\n   }\n \n+  private def isSubset(biggerSet: Seq[Expression], smallerSet: Seq[Expression]): Boolean =\n+    smallerSet.length <= biggerSet.length &&\n+      smallerSet.forall(x => biggerSet.exists(_.semanticEquals(x)))\n+\n   private def reorder(\n       leftKeys: Seq[Expression],\n       rightKeys: Seq[Expression],\n-      expectedOrderOfKeys: Seq[Expression],\n-      currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression]) = {\n-    val leftKeysBuffer = ArrayBuffer[Expression]()\n-    val rightKeysBuffer = ArrayBuffer[Expression]()\n+      expectedOrderOfKeys: Seq[Expression], // comes from child's output partitioning\n+      currentOrderOfKeys: Seq[Expression]): // comes from join predicate\n+  (Seq[Expression], Seq[Expression], Seq[Expression], Seq[Expression]) = {\n+\n+    assert(leftKeys.length == rightKeys.length)\n+\n+    val allLeftKeys = ArrayBuffer[Expression]()\n+    val allRightKeys = ArrayBuffer[Expression]()\n+    val reorderedLeftKeys = ArrayBuffer[Expression]()\n+    val reorderedRightKeys = ArrayBuffer[Expression]()\n+    val processedIndicies = mutable.Set[Int]()\n \n     expectedOrderOfKeys.foreach(expression => {\n-      val index = currentOrderOfKeys.indexWhere(e => e.semanticEquals(expression))\n-      leftKeysBuffer.append(leftKeys(index))\n-      rightKeysBuffer.append(rightKeys(index))\n+      val index = currentOrderOfKeys.zipWithIndex.find { case (currKey, i) =>\n+        !processedIndicies.contains(i) && currKey.semanticEquals(expression)\n+      }.get._2\n+      processedIndicies.add(index)\n+\n+      reorderedLeftKeys.append(leftKeys(index))\n+      allLeftKeys.append(leftKeys(index))\n+\n+      reorderedRightKeys.append(rightKeys(index))\n+      allRightKeys.append(rightKeys(index))\n     })\n-    (leftKeysBuffer, rightKeysBuffer)\n+\n+    // If len(currentOrderOfKeys) > len(expectedOrderOfKeys), then the re-ordering won't have\n+    // all the keys. Append the remaining keys to the end so that we are covering all the keys\n+    for (i <- leftKeys.indices) {\n+      if (!processedIndicies.contains(i)) {\n+        allLeftKeys.append(leftKeys(i))\n+        allRightKeys.append(rightKeys(i))\n+      }\n+    }\n+\n+    assert(allLeftKeys.length == leftKeys.length)\n+    assert(allRightKeys.length == rightKeys.length)\n+    assert(reorderedLeftKeys.length == reorderedRightKeys.length)\n+\n+    (allLeftKeys, reorderedLeftKeys, allRightKeys, reorderedRightKeys)\n   }\n \n   private def reorderJoinKeys(\n       leftKeys: Seq[Expression],\n       rightKeys: Seq[Expression],\n       leftPartitioning: Partitioning,\n-      rightPartitioning: Partitioning): (Seq[Expression], Seq[Expression]) = {\n+      rightPartitioning: Partitioning):\n+  (Seq[Expression], Seq[Expression], Seq[Expression], Seq[Expression]) = {",
    "line": 106
  }, {
    "author": {
      "login": "tejasapatil"
    },
    "body": "added more doc. I wasn't sure how to make it easier to understand. Hope that the example helps with that",
    "commit": "00bb14b0145a2bd42c8b4c8a9d4f108322804f71",
    "createdAt": "2018-01-20T01:36:29Z",
    "diffHunk": "@@ -220,45 +220,76 @@ case class EnsureRequirements(conf: SQLConf) extends Rule[SparkPlan] {\n     operator.withNewChildren(children)\n   }\n \n+  private def isSubset(biggerSet: Seq[Expression], smallerSet: Seq[Expression]): Boolean =\n+    smallerSet.length <= biggerSet.length &&\n+      smallerSet.forall(x => biggerSet.exists(_.semanticEquals(x)))\n+\n   private def reorder(\n       leftKeys: Seq[Expression],\n       rightKeys: Seq[Expression],\n-      expectedOrderOfKeys: Seq[Expression],\n-      currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression]) = {\n-    val leftKeysBuffer = ArrayBuffer[Expression]()\n-    val rightKeysBuffer = ArrayBuffer[Expression]()\n+      expectedOrderOfKeys: Seq[Expression], // comes from child's output partitioning\n+      currentOrderOfKeys: Seq[Expression]): // comes from join predicate\n+  (Seq[Expression], Seq[Expression], Seq[Expression], Seq[Expression]) = {\n+\n+    assert(leftKeys.length == rightKeys.length)\n+\n+    val allLeftKeys = ArrayBuffer[Expression]()\n+    val allRightKeys = ArrayBuffer[Expression]()\n+    val reorderedLeftKeys = ArrayBuffer[Expression]()\n+    val reorderedRightKeys = ArrayBuffer[Expression]()\n+    val processedIndicies = mutable.Set[Int]()\n \n     expectedOrderOfKeys.foreach(expression => {\n-      val index = currentOrderOfKeys.indexWhere(e => e.semanticEquals(expression))\n-      leftKeysBuffer.append(leftKeys(index))\n-      rightKeysBuffer.append(rightKeys(index))\n+      val index = currentOrderOfKeys.zipWithIndex.find { case (currKey, i) =>\n+        !processedIndicies.contains(i) && currKey.semanticEquals(expression)\n+      }.get._2\n+      processedIndicies.add(index)\n+\n+      reorderedLeftKeys.append(leftKeys(index))\n+      allLeftKeys.append(leftKeys(index))\n+\n+      reorderedRightKeys.append(rightKeys(index))\n+      allRightKeys.append(rightKeys(index))\n     })\n-    (leftKeysBuffer, rightKeysBuffer)\n+\n+    // If len(currentOrderOfKeys) > len(expectedOrderOfKeys), then the re-ordering won't have\n+    // all the keys. Append the remaining keys to the end so that we are covering all the keys\n+    for (i <- leftKeys.indices) {\n+      if (!processedIndicies.contains(i)) {\n+        allLeftKeys.append(leftKeys(i))\n+        allRightKeys.append(rightKeys(i))\n+      }\n+    }\n+\n+    assert(allLeftKeys.length == leftKeys.length)\n+    assert(allRightKeys.length == rightKeys.length)\n+    assert(reorderedLeftKeys.length == reorderedRightKeys.length)\n+\n+    (allLeftKeys, reorderedLeftKeys, allRightKeys, reorderedRightKeys)\n   }\n \n   private def reorderJoinKeys(\n       leftKeys: Seq[Expression],\n       rightKeys: Seq[Expression],\n       leftPartitioning: Partitioning,\n-      rightPartitioning: Partitioning): (Seq[Expression], Seq[Expression]) = {\n+      rightPartitioning: Partitioning):\n+  (Seq[Expression], Seq[Expression], Seq[Expression], Seq[Expression]) = {",
    "line": 106
  }],
  "prId": 19054
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "if `leftPartitioning` is `HashPartitioning`, we don't need to care about `rightPartitioning` at all?",
    "commit": "00bb14b0145a2bd42c8b4c8a9d4f108322804f71",
    "createdAt": "2018-01-19T07:20:41Z",
    "diffHunk": "@@ -220,45 +220,76 @@ case class EnsureRequirements(conf: SQLConf) extends Rule[SparkPlan] {\n     operator.withNewChildren(children)\n   }\n \n+  private def isSubset(biggerSet: Seq[Expression], smallerSet: Seq[Expression]): Boolean =\n+    smallerSet.length <= biggerSet.length &&\n+      smallerSet.forall(x => biggerSet.exists(_.semanticEquals(x)))\n+\n   private def reorder(\n       leftKeys: Seq[Expression],\n       rightKeys: Seq[Expression],\n-      expectedOrderOfKeys: Seq[Expression],\n-      currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression]) = {\n-    val leftKeysBuffer = ArrayBuffer[Expression]()\n-    val rightKeysBuffer = ArrayBuffer[Expression]()\n+      expectedOrderOfKeys: Seq[Expression], // comes from child's output partitioning\n+      currentOrderOfKeys: Seq[Expression]): // comes from join predicate\n+  (Seq[Expression], Seq[Expression], Seq[Expression], Seq[Expression]) = {\n+\n+    assert(leftKeys.length == rightKeys.length)\n+\n+    val allLeftKeys = ArrayBuffer[Expression]()\n+    val allRightKeys = ArrayBuffer[Expression]()\n+    val reorderedLeftKeys = ArrayBuffer[Expression]()\n+    val reorderedRightKeys = ArrayBuffer[Expression]()\n+    val processedIndicies = mutable.Set[Int]()\n \n     expectedOrderOfKeys.foreach(expression => {\n-      val index = currentOrderOfKeys.indexWhere(e => e.semanticEquals(expression))\n-      leftKeysBuffer.append(leftKeys(index))\n-      rightKeysBuffer.append(rightKeys(index))\n+      val index = currentOrderOfKeys.zipWithIndex.find { case (currKey, i) =>\n+        !processedIndicies.contains(i) && currKey.semanticEquals(expression)\n+      }.get._2\n+      processedIndicies.add(index)\n+\n+      reorderedLeftKeys.append(leftKeys(index))\n+      allLeftKeys.append(leftKeys(index))\n+\n+      reorderedRightKeys.append(rightKeys(index))\n+      allRightKeys.append(rightKeys(index))\n     })\n-    (leftKeysBuffer, rightKeysBuffer)\n+\n+    // If len(currentOrderOfKeys) > len(expectedOrderOfKeys), then the re-ordering won't have\n+    // all the keys. Append the remaining keys to the end so that we are covering all the keys\n+    for (i <- leftKeys.indices) {\n+      if (!processedIndicies.contains(i)) {\n+        allLeftKeys.append(leftKeys(i))\n+        allRightKeys.append(rightKeys(i))\n+      }\n+    }\n+\n+    assert(allLeftKeys.length == leftKeys.length)\n+    assert(allRightKeys.length == rightKeys.length)\n+    assert(reorderedLeftKeys.length == reorderedRightKeys.length)\n+\n+    (allLeftKeys, reorderedLeftKeys, allRightKeys, reorderedRightKeys)\n   }\n \n   private def reorderJoinKeys(\n       leftKeys: Seq[Expression],\n       rightKeys: Seq[Expression],\n       leftPartitioning: Partitioning,\n-      rightPartitioning: Partitioning): (Seq[Expression], Seq[Expression]) = {\n+      rightPartitioning: Partitioning):\n+  (Seq[Expression], Seq[Expression], Seq[Expression], Seq[Expression]) = {\n+\n     if (leftKeys.forall(_.deterministic) && rightKeys.forall(_.deterministic)) {\n       leftPartitioning match {\n-        case HashPartitioning(leftExpressions, _)\n-          if leftExpressions.length == leftKeys.length &&\n-            leftKeys.forall(x => leftExpressions.exists(_.semanticEquals(x))) =>\n+        case HashPartitioning(leftExpressions, _) if isSubset(leftKeys, leftExpressions) =>\n           reorder(leftKeys, rightKeys, leftExpressions, leftKeys)"
  }, {
    "author": {
      "login": "tejasapatil"
    },
    "body": "given that this was only done over `SortMergeJoinExec` and `ShuffledHashJoinExec` where both the partitionings are `HashPartitioning`, things worked fine. I have changed this to have a stricter check.",
    "commit": "00bb14b0145a2bd42c8b4c8a9d4f108322804f71",
    "createdAt": "2018-01-20T01:37:43Z",
    "diffHunk": "@@ -220,45 +220,76 @@ case class EnsureRequirements(conf: SQLConf) extends Rule[SparkPlan] {\n     operator.withNewChildren(children)\n   }\n \n+  private def isSubset(biggerSet: Seq[Expression], smallerSet: Seq[Expression]): Boolean =\n+    smallerSet.length <= biggerSet.length &&\n+      smallerSet.forall(x => biggerSet.exists(_.semanticEquals(x)))\n+\n   private def reorder(\n       leftKeys: Seq[Expression],\n       rightKeys: Seq[Expression],\n-      expectedOrderOfKeys: Seq[Expression],\n-      currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression]) = {\n-    val leftKeysBuffer = ArrayBuffer[Expression]()\n-    val rightKeysBuffer = ArrayBuffer[Expression]()\n+      expectedOrderOfKeys: Seq[Expression], // comes from child's output partitioning\n+      currentOrderOfKeys: Seq[Expression]): // comes from join predicate\n+  (Seq[Expression], Seq[Expression], Seq[Expression], Seq[Expression]) = {\n+\n+    assert(leftKeys.length == rightKeys.length)\n+\n+    val allLeftKeys = ArrayBuffer[Expression]()\n+    val allRightKeys = ArrayBuffer[Expression]()\n+    val reorderedLeftKeys = ArrayBuffer[Expression]()\n+    val reorderedRightKeys = ArrayBuffer[Expression]()\n+    val processedIndicies = mutable.Set[Int]()\n \n     expectedOrderOfKeys.foreach(expression => {\n-      val index = currentOrderOfKeys.indexWhere(e => e.semanticEquals(expression))\n-      leftKeysBuffer.append(leftKeys(index))\n-      rightKeysBuffer.append(rightKeys(index))\n+      val index = currentOrderOfKeys.zipWithIndex.find { case (currKey, i) =>\n+        !processedIndicies.contains(i) && currKey.semanticEquals(expression)\n+      }.get._2\n+      processedIndicies.add(index)\n+\n+      reorderedLeftKeys.append(leftKeys(index))\n+      allLeftKeys.append(leftKeys(index))\n+\n+      reorderedRightKeys.append(rightKeys(index))\n+      allRightKeys.append(rightKeys(index))\n     })\n-    (leftKeysBuffer, rightKeysBuffer)\n+\n+    // If len(currentOrderOfKeys) > len(expectedOrderOfKeys), then the re-ordering won't have\n+    // all the keys. Append the remaining keys to the end so that we are covering all the keys\n+    for (i <- leftKeys.indices) {\n+      if (!processedIndicies.contains(i)) {\n+        allLeftKeys.append(leftKeys(i))\n+        allRightKeys.append(rightKeys(i))\n+      }\n+    }\n+\n+    assert(allLeftKeys.length == leftKeys.length)\n+    assert(allRightKeys.length == rightKeys.length)\n+    assert(reorderedLeftKeys.length == reorderedRightKeys.length)\n+\n+    (allLeftKeys, reorderedLeftKeys, allRightKeys, reorderedRightKeys)\n   }\n \n   private def reorderJoinKeys(\n       leftKeys: Seq[Expression],\n       rightKeys: Seq[Expression],\n       leftPartitioning: Partitioning,\n-      rightPartitioning: Partitioning): (Seq[Expression], Seq[Expression]) = {\n+      rightPartitioning: Partitioning):\n+  (Seq[Expression], Seq[Expression], Seq[Expression], Seq[Expression]) = {\n+\n     if (leftKeys.forall(_.deterministic) && rightKeys.forall(_.deterministic)) {\n       leftPartitioning match {\n-        case HashPartitioning(leftExpressions, _)\n-          if leftExpressions.length == leftKeys.length &&\n-            leftKeys.forall(x => leftExpressions.exists(_.semanticEquals(x))) =>\n+        case HashPartitioning(leftExpressions, _) if isSubset(leftKeys, leftExpressions) =>\n           reorder(leftKeys, rightKeys, leftExpressions, leftKeys)"
  }],
  "prId": 19054
}, {
  "comments": [{
    "author": {
      "login": "tejasapatil"
    },
    "body": "Removal of `BroadcastHashJoinExec` is intentional. The children are expected to have `BroadcastDistribution` or `UnspecifiedDistribution` so this method wont help here (this optimization only helps in case of shuffle based joins)",
    "commit": "00bb14b0145a2bd42c8b4c8a9d4f108322804f71",
    "createdAt": "2018-01-20T01:41:47Z",
    "diffHunk": "@@ -271,23 +325,24 @@ case class EnsureRequirements(conf: SQLConf) extends Rule[SparkPlan] {\n    */\n   private def reorderJoinPredicates(plan: SparkPlan): SparkPlan = {\n     plan.transformUp {\n-      case BroadcastHashJoinExec(leftKeys, rightKeys, joinType, buildSide, condition, left,",
    "line": 142
  }],
  "prId": 19054
}, {
  "comments": [{
    "author": {
      "login": "eyalfa"
    },
    "body": "can you please add a comment describing the return type? a tuple4 is not such a descriptive type :smiley: ",
    "commit": "00bb14b0145a2bd42c8b4c8a9d4f108322804f71",
    "createdAt": "2018-02-04T22:19:24Z",
    "diffHunk": "@@ -220,45 +220,99 @@ case class EnsureRequirements(conf: SQLConf) extends Rule[SparkPlan] {\n     operator.withNewChildren(children)\n   }\n \n+  private def isSubset(biggerSet: Seq[Expression], smallerSet: Seq[Expression]): Boolean =\n+    smallerSet.length <= biggerSet.length &&\n+      smallerSet.forall(x => biggerSet.exists(_.semanticEquals(x)))\n+\n+  /**\n+   * Reorders `leftKeys` and `rightKeys` by aligning `currentOrderOfKeys` to be a prefix of\n+   * `expectedOrderOfKeys`\n+   */\n   private def reorder(\n       leftKeys: Seq[Expression],\n       rightKeys: Seq[Expression],\n-      expectedOrderOfKeys: Seq[Expression],\n-      currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression]) = {\n-    val leftKeysBuffer = ArrayBuffer[Expression]()\n-    val rightKeysBuffer = ArrayBuffer[Expression]()\n+      expectedOrderOfKeys: Seq[Expression], // comes from child's output partitioning\n+      currentOrderOfKeys: Seq[Expression]): // comes from join predicate\n+  (Seq[Expression], Seq[Expression], Seq[Expression], Seq[Expression]) = {",
    "line": 38
  }],
  "prId": 19054
}, {
  "comments": [{
    "author": {
      "login": "eyalfa"
    },
    "body": "is the find guaranteed to always succeed?\r\nif so, worth a comment on method's pre/post conditions.\r\n\r\na getOrElse(sys error \"...\") might also be a good way of documenting this.",
    "commit": "00bb14b0145a2bd42c8b4c8a9d4f108322804f71",
    "createdAt": "2018-02-04T22:56:06Z",
    "diffHunk": "@@ -220,45 +220,99 @@ case class EnsureRequirements(conf: SQLConf) extends Rule[SparkPlan] {\n     operator.withNewChildren(children)\n   }\n \n+  private def isSubset(biggerSet: Seq[Expression], smallerSet: Seq[Expression]): Boolean =\n+    smallerSet.length <= biggerSet.length &&\n+      smallerSet.forall(x => biggerSet.exists(_.semanticEquals(x)))\n+\n+  /**\n+   * Reorders `leftKeys` and `rightKeys` by aligning `currentOrderOfKeys` to be a prefix of\n+   * `expectedOrderOfKeys`\n+   */\n   private def reorder(\n       leftKeys: Seq[Expression],\n       rightKeys: Seq[Expression],\n-      expectedOrderOfKeys: Seq[Expression],\n-      currentOrderOfKeys: Seq[Expression]): (Seq[Expression], Seq[Expression]) = {\n-    val leftKeysBuffer = ArrayBuffer[Expression]()\n-    val rightKeysBuffer = ArrayBuffer[Expression]()\n+      expectedOrderOfKeys: Seq[Expression], // comes from child's output partitioning\n+      currentOrderOfKeys: Seq[Expression]): // comes from join predicate\n+  (Seq[Expression], Seq[Expression], Seq[Expression], Seq[Expression]) = {\n+\n+    assert(leftKeys.length == rightKeys.length)\n+\n+    val allLeftKeys = ArrayBuffer[Expression]()\n+    val allRightKeys = ArrayBuffer[Expression]()\n+    val reorderedLeftKeys = ArrayBuffer[Expression]()\n+    val reorderedRightKeys = ArrayBuffer[Expression]()\n+\n+    // Tracking indicies here to track to which keys are accounted. Using a set based approach\n+    // won't work because its possible that some keys are repeated in the join clause\n+    // eg. a.key1 = b.key1 AND a.key1 = b.key2\n+    val processedIndicies = mutable.Set[Int]()\n \n     expectedOrderOfKeys.foreach(expression => {\n-      val index = currentOrderOfKeys.indexWhere(e => e.semanticEquals(expression))\n-      leftKeysBuffer.append(leftKeys(index))\n-      rightKeysBuffer.append(rightKeys(index))\n+      val index = currentOrderOfKeys.zipWithIndex.find { case (currKey, i) =>\n+        !processedIndicies.contains(i) && currKey.semanticEquals(expression)\n+      }.get._2",
    "line": 58
  }],
  "prId": 19054
}]