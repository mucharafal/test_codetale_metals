[{
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "What's the benefit of RowIterator if we need to copy for every row?\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T16:01:45Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }, {
    "author": {
      "login": "davies"
    },
    "body": "I think we could do something like this to avoid this copy\n\n```\nclass RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\nprivate[this] var nextRow: InternalRow = rowIter.advanceNext() ? rowIter.getRow : null\noverride def hasNext: Boolean = {\n  if (nextRow == null && rowIter.advanceNext()) {\n   nextRow = rowIter.getRow\n }\n  nextRow != null\n}\noverride def next(): InernalRow = {\n  val r =  nextRow\n  nextRow = null\n  r\n}\n}\n```\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T16:10:54Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "I'm going to comment this file to explain what's going on here, but in a nutshell:\n\nThe Scala iterator exposes separate `hasNext()` and `next()` methods. This creates the potential for a user to call `hasNext()` two times in a row without calling `next()` in between those calls.  For some iterators, like `iterator.filter(...)`, non-trivial work must be performed to figure out whether there's a next tuple and this may cause our mutable row objects to be mutated. This is the reason that we needed the copying in the `.collect()` call in `leftOuterIterator`, even after changing that method to call `collect` on an iterator instead of an iterable.\n\nThis wrapper class, `RowIteratorToScala`, makes this safe by adding the required copying at the last possible moment.\n\nIn the long run, we can probably remove this copying. The `RowIteratorFromScala` is designed to help with this: that wrapper class takes a Scala iterator and hides it behind our `RowIterator` interface, which prevents the double `hasNext` issue. Therefore, if an operator can use `RowIterators` then it doesn't need to immediately copy its incoming rows. This is the reason that I was able to safely remove the immediate `left.execute.map(_.copy())` and `right.execute.map(_.copy())` calls from SortMergeJoin.\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T16:12:34Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Come to think of it, we could quickly figure out whether this copying is necessary by adding an assertion to detect whether `hasNext()` is ever called two times in a row. If it's not, then we shouldn't need the copy. We can still keep the `RowIteratorToScala` class as a wrapper to enforce this guarantee and can plan to remove it when / if we transition all of our internal iterator interfaces to use something more like `RowIterator`.\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T16:20:18Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }, {
    "author": {
      "login": "davies"
    },
    "body": "I think we could provide the Iterator interface without introducing RowIterator, while still do the dirty work in hasNext(), and hasNext() could be call multiple times without calling next() between them.\n\nFrom the doc of Scala Iterator or Java.util.Iterator, `hasNext` should always be idempotent, and we could satisfy this even we read data in hasNext() (by making it stateful)\n\nsee this as an example: https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala#L91\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T16:41:09Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "I was a little inprecise in describing the problem: what if, while processing the current row, we want to see whether there is another row, so we call `hasNext()` but do _not_ want to do the work of mutating the current value from the iterator (e.g. we want the mutable value to only be updated by next calls, not `hasNext()`) and we also want to have an idempotent `hasNext()`?\n\nIn principle, I suppose that `HashJoin` is vulnerable to problem: what if the row returned by the iterator points to the last value for a particular left row and we call `hasNext()` without intending to immediately call `next()`? In that case, I think that we'll wind up advancing the row as a result of the `hasNext()` call.\n\nMaybe this concern is moot. I was just trying to figure out why the copy was necessary here and this was the only explanation that I could come up with. \n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T18:33:16Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }, {
    "author": {
      "login": "davies"
    },
    "body": "We're moving to let consumer to do the copy, before we check all the existing usage, I agreed that it's safe to have a copy here.\n\nIn this case, the consume of iterator may want to call `hasNext()` before finish the current row (before return it, as it wants to do some cleanup), in long term, I think it's better to not do this, or do the copy itself.\n\nRight now, it's safe to have this copy here (we already have this). The reason I want to raise this question is that, it's really cheap to call `copy()` on a GenericInternalRow (if it's already copied from MutableRow, it's read-only now, just return itself), but right now we have UnsafeRow everywhere, it's not cheap anymore. If we have multiple chained iterator like this, we will copy multiples times.\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T20:42:22Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }, {
    "author": {
      "login": "davies"
    },
    "body": "Also the copy() will allocate unmanaged memory, will increase the GC pressure.\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T20:43:37Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "I'm going to try to remove this copy and will add some assertions that will fail in the cases where the copy would have been necessary. This will make it easy to spot whether it's necessary as of this release. If it does turn out to be a problem and looks like it will take a long time to fix, then I'll defer the removal of the copy to a smaller followup patch.\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T20:45:31Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }, {
    "author": {
      "login": "davies"
    },
    "body": "That make sense, just leave the copy, add a TODO or JIRA for it (try to remove it or optimize in another way).\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T20:48:55Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Yep, leaving it for now.  Added some comments to explain why `RowIterator` exists.\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T22:00:19Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }, {
    "author": {
      "login": "davies"
    },
    "body": "Do you have an example that will call hasNext() before finish current now? I just want to learn a bit more on this, thanks!\n",
    "commit": "eabacca9864e609a1b085a2acbe10907929700a4",
    "createdAt": "2015-08-08T22:03:59Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.joins\n+\n+import java.util.NoSuchElementException\n+\n+import org.apache.spark.sql.catalyst.InternalRow\n+\n+private[sql] abstract class RowIterator {\n+  def advanceNext(): Boolean\n+  def getRow: InternalRow\n+  def toScala: Iterator[InternalRow] = new RowIteratorToScala(this)\n+}\n+\n+object RowIterator {\n+  def fromScala(scalaIter: Iterator[InternalRow]): RowIterator = {\n+    scalaIter match {\n+      case wrappedRowIter: RowIteratorToScala => wrappedRowIter.rowIter\n+      case _ => new RowIteratorFromScala(scalaIter)\n+    }\n+  }\n+}\n+\n+private final class RowIteratorToScala(val rowIter: RowIterator) extends Iterator[InternalRow] {\n+  private [this] var _hasNext: Boolean = rowIter.advanceNext()\n+  override def hasNext: Boolean = _hasNext\n+  override def next(): InternalRow = {\n+    if (!_hasNext) throw new NoSuchElementException\n+    val row: InternalRow = rowIter.getRow.copy()"
  }],
  "prId": 7904
}]