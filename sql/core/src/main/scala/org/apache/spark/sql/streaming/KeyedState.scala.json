[{
  "comments": [{
    "author": {
      "login": "amitsela"
    },
    "body": "If a timeout was previously set, and an update (new input value for a key) comes, the user would still have to re-set the timeout ? why not leave it as it was (if he didn't explicitly re-set it) ?\r\nI guess that even with this implementation, this could still be sugar-coated by doing something like:\r\n```\r\nif (user not set timeout)\r\n  timeout = prevTimeout\r\n``` \r\nno ?",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-09T17:52:46Z",
    "diffHunk": "@@ -61,25 +65,49 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "its intuitive to ensure there is always a timeout. no matter what updates you make to the state and what you return, you can always call `keyedState.setTimeoutDuration(...)`.",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-10T01:41:57Z",
    "diffHunk": "@@ -61,25 +65,49 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,"
  }, {
    "author": {
      "login": "amitsela"
    },
    "body": "Got it.\r\nHow about adding a `KeyedState#keepTimeout()` just to allow users to avoid:\r\n```\r\nval priorTimeout = keyedState.getTimeoutDuration()\r\nkeyedState.setTimeoutDuration(priorTimeout)\r\n```\r\nand instead simply call:\r\n```\r\nkeyedState.keepTimeoutDuration()\r\n```\r\nWell, I'm not so sure about it... sometimes it is better to be explicit.. but I'll persist my thoughts here anyway. ",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-10T13:32:55Z",
    "diffHunk": "@@ -61,25 +65,49 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,"
  }],
  "prId": 17179
}, {
  "comments": [{
    "author": {
      "login": "amitsela"
    },
    "body": "I understand it's expensive to \"scan-through\" the state, but why not enable it periodically ? it could be useful for sparse streams.\r\nSomething a-la-updateStateByKey, but only if no data already triggered the state store for a configured time period. ",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-09T17:55:39Z",
    "diffHunk": "@@ -61,25 +65,49 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger with any data in it"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Note that there is a fundamental difference between Spark Streaming and Structured Streaming. Unlike the former, Structured Streaming queries will not execute any batch if there is no new data. So as long as there is some data and batch kicks off, timeouts will be processed.\r\n\r\nI think \"a trigger with any data\" is confusing. A trigger by definition has data. I will rewrite. Thank for pointing it out though. ",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-10T01:45:40Z",
    "diffHunk": "@@ -61,25 +65,49 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger with any data in it"
  }, {
    "author": {
      "login": "amitsela"
    },
    "body": "Using a `ProcessingTime` timeout could be confusing this way - a user would expect to fire on timeout (+ system latency). Adding system latency, wether it's batch-long, or 10Xbatch-long (like with checkpointing in Spark 1.x for example) is still something pre-set that could also be configurable, giving users the control to do the trade-off between accuracy in firings vs. performance.\r\nUsing the `EventTime` timeout in the future, I assume the \"clock\" would be watermark based instead of wall-time, and I see two use-cases where this would matter:\r\n1. Testing - being able to move the clock forward to end-of-time to force firing everything that still awaits for the closing of windows.\r\n2. A pipeline where there is a filter before the stateful op. such that there is data, and the watermark advances, but some of the events are dropped and don't reach the stateful operator so it will hold off firing until the \"proper\" data (that passes filter) comes along - this again could cause an unknown delay to emitting results out of the stateful operator.  ",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-10T13:27:57Z",
    "diffHunk": "@@ -61,25 +65,49 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger with any data in it"
  }],
  "prId": 17179
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "Could you update this comment to describe the timeout behavior of the function?",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-14T03:37:26Z",
    "diffHunk": "@@ -61,25 +65,50 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger in the query\n+ *      (i.e. after D ms). So there is a no strict upper bound on when the timeout would occur.\n+ *      For example, the trigger interval of the query will affect when the timeout is actually hit.\n+ *      If there is no data in the stream (for any key) for a while, then their will not be\n+ *      any trigger and timeout will not be hit until there is data.\n+ *\n  * Scala example of using KeyedState in `mapGroupsWithState`:\n  * {{{\n  * // A mapping function that maintains an integer state for string keys and returns a string."
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "added",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-17T01:46:43Z",
    "diffHunk": "@@ -61,25 +65,50 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger in the query\n+ *      (i.e. after D ms). So there is a no strict upper bound on when the timeout would occur.\n+ *      For example, the trigger interval of the query will affect when the timeout is actually hit.\n+ *      If there is no data in the stream (for any key) for a while, then their will not be\n+ *      any trigger and timeout will not be hit until there is data.\n+ *\n  * Scala example of using KeyedState in `mapGroupsWithState`:\n  * {{{\n  * // A mapping function that maintains an integer state for string keys and returns a string."
  }],
  "prId": 17179
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "Does this set a timeout on a removed state?  What does that do?",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-14T03:37:51Z",
    "diffHunk": "@@ -61,25 +65,50 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger in the query\n+ *      (i.e. after D ms). So there is a no strict upper bound on when the timeout would occur.\n+ *      For example, the trigger interval of the query will affect when the timeout is actually hit.\n+ *      If there is no data in the stream (for any key) for a while, then their will not be\n+ *      any trigger and timeout will not be hit until there is data.\n+ *\n  * Scala example of using KeyedState in `mapGroupsWithState`:\n  * {{{\n  * // A mapping function that maintains an integer state for string keys and returns a string.\n  * def mappingFunction(key: String, value: Iterator[Int], state: KeyedState[Int]): String = {\n- *   // Check if state exists\n- *   if (state.exists) {\n- *     val existingState = state.get  // Get the existing state\n- *     val shouldRemove = ...         // Decide whether to remove the state\n+ *\n+ *   if (state.isTimingOut) {                // If called when timing out, remove the state\n+ *     state.remove()\n+ *\n+ *   } else if (state.exists) {              // If state exists, use it for processing\n+ *     val existingState = state.get         // Get the existing state\n+ *     val shouldRemove = ...                // Decide whether to remove the state\n  *     if (shouldRemove) {\n- *       state.remove()     // Remove the state\n+ *       state.remove()                      // Remove the state\n+ *\n  *     } else {\n  *       val newState = ...\n- *       state.update(newState)    // Set the new state\n+ *       state.update(newState)              // Set the new state\n  *     }\n+ *\n  *   } else {\n  *     val initialState = ...\n- *     state.update(initialState)  // Set the initial state\n+ *     state.update(initialState)            // Set the initial state\n  *   }\n- *   ... // return something\n+ *   state.setTimeoutDuration(\"1 hour\")      // Set the timeout"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "It does not. Once state is remove, timeouts are disabled. I will add this to the docs.",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-14T18:21:48Z",
    "diffHunk": "@@ -61,25 +65,50 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger in the query\n+ *      (i.e. after D ms). So there is a no strict upper bound on when the timeout would occur.\n+ *      For example, the trigger interval of the query will affect when the timeout is actually hit.\n+ *      If there is no data in the stream (for any key) for a while, then their will not be\n+ *      any trigger and timeout will not be hit until there is data.\n+ *\n  * Scala example of using KeyedState in `mapGroupsWithState`:\n  * {{{\n  * // A mapping function that maintains an integer state for string keys and returns a string.\n  * def mappingFunction(key: String, value: Iterator[Int], state: KeyedState[Int]): String = {\n- *   // Check if state exists\n- *   if (state.exists) {\n- *     val existingState = state.get  // Get the existing state\n- *     val shouldRemove = ...         // Decide whether to remove the state\n+ *\n+ *   if (state.isTimingOut) {                // If called when timing out, remove the state\n+ *     state.remove()\n+ *\n+ *   } else if (state.exists) {              // If state exists, use it for processing\n+ *     val existingState = state.get         // Get the existing state\n+ *     val shouldRemove = ...                // Decide whether to remove the state\n  *     if (shouldRemove) {\n- *       state.remove()     // Remove the state\n+ *       state.remove()                      // Remove the state\n+ *\n  *     } else {\n  *       val newState = ...\n- *       state.update(newState)    // Set the new state\n+ *       state.update(newState)              // Set the new state\n  *     }\n+ *\n  *   } else {\n  *     val initialState = ...\n- *     state.update(initialState)  // Set the initial state\n+ *     state.update(initialState)            // Set the initial state\n  *   }\n- *   ... // return something\n+ *   state.setTimeoutDuration(\"1 hour\")      // Set the timeout"
  }, {
    "author": {
      "login": "marmbrus"
    },
    "body": "Hmm, I wonder if we should throw an exception here.  I was pretty confused what this function would do just looking at it.",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-14T18:29:58Z",
    "diffHunk": "@@ -61,25 +65,50 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger in the query\n+ *      (i.e. after D ms). So there is a no strict upper bound on when the timeout would occur.\n+ *      For example, the trigger interval of the query will affect when the timeout is actually hit.\n+ *      If there is no data in the stream (for any key) for a while, then their will not be\n+ *      any trigger and timeout will not be hit until there is data.\n+ *\n  * Scala example of using KeyedState in `mapGroupsWithState`:\n  * {{{\n  * // A mapping function that maintains an integer state for string keys and returns a string.\n  * def mappingFunction(key: String, value: Iterator[Int], state: KeyedState[Int]): String = {\n- *   // Check if state exists\n- *   if (state.exists) {\n- *     val existingState = state.get  // Get the existing state\n- *     val shouldRemove = ...         // Decide whether to remove the state\n+ *\n+ *   if (state.isTimingOut) {                // If called when timing out, remove the state\n+ *     state.remove()\n+ *\n+ *   } else if (state.exists) {              // If state exists, use it for processing\n+ *     val existingState = state.get         // Get the existing state\n+ *     val shouldRemove = ...                // Decide whether to remove the state\n  *     if (shouldRemove) {\n- *       state.remove()     // Remove the state\n+ *       state.remove()                      // Remove the state\n+ *\n  *     } else {\n  *       val newState = ...\n- *       state.update(newState)    // Set the new state\n+ *       state.update(newState)              // Set the new state\n  *     }\n+ *\n  *   } else {\n  *     val initialState = ...\n- *     state.update(initialState)  // Set the initial state\n+ *     state.update(initialState)            // Set the initial state\n  *   }\n- *   ... // return something\n+ *   state.setTimeoutDuration(\"1 hour\")      // Set the timeout"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "added exception",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-17T01:28:37Z",
    "diffHunk": "@@ -61,25 +65,50 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger in the query\n+ *      (i.e. after D ms). So there is a no strict upper bound on when the timeout would occur.\n+ *      For example, the trigger interval of the query will affect when the timeout is actually hit.\n+ *      If there is no data in the stream (for any key) for a while, then their will not be\n+ *      any trigger and timeout will not be hit until there is data.\n+ *\n  * Scala example of using KeyedState in `mapGroupsWithState`:\n  * {{{\n  * // A mapping function that maintains an integer state for string keys and returns a string.\n  * def mappingFunction(key: String, value: Iterator[Int], state: KeyedState[Int]): String = {\n- *   // Check if state exists\n- *   if (state.exists) {\n- *     val existingState = state.get  // Get the existing state\n- *     val shouldRemove = ...         // Decide whether to remove the state\n+ *\n+ *   if (state.isTimingOut) {                // If called when timing out, remove the state\n+ *     state.remove()\n+ *\n+ *   } else if (state.exists) {              // If state exists, use it for processing\n+ *     val existingState = state.get         // Get the existing state\n+ *     val shouldRemove = ...                // Decide whether to remove the state\n  *     if (shouldRemove) {\n- *       state.remove()     // Remove the state\n+ *       state.remove()                      // Remove the state\n+ *\n  *     } else {\n  *       val newState = ...\n- *       state.update(newState)    // Set the new state\n+ *       state.update(newState)              // Set the new state\n  *     }\n+ *\n  *   } else {\n  *     val initialState = ...\n- *     state.update(initialState)  // Set the initial state\n+ *     state.update(initialState)            // Set the initial state\n  *   }\n- *   ... // return something\n+ *   state.setTimeoutDuration(\"1 hour\")      // Set the timeout"
  }],
  "prId": 17179
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "How hard to remove this limitation?  It seems like its very hard to build reliable monitoring applications on this API unless we fix this.",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-14T03:40:33Z",
    "diffHunk": "@@ -61,25 +65,50 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger in the query\n+ *      (i.e. after D ms). So there is a no strict upper bound on when the timeout would occur.\n+ *      For example, the trigger interval of the query will affect when the timeout is actually hit.\n+ *      If there is no data in the stream (for any key) for a while, then their will not be\n+ *      any trigger and timeout will not be hit until there is data.",
    "line": 84
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Shouldnt be tough. We will have to occasionally and periodically run a trigger with an empty batch DF. I think that should be a separate PR as that touch the StreamExecution, and we need figure out what the policy and the APIs to specify the policy should be. ",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-14T18:21:11Z",
    "diffHunk": "@@ -61,25 +65,50 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger in the query\n+ *      (i.e. after D ms). So there is a no strict upper bound on when the timeout would occur.\n+ *      For example, the trigger interval of the query will affect when the timeout is actually hit.\n+ *      If there is no data in the stream (for any key) for a while, then their will not be\n+ *      any trigger and timeout will not be hit until there is data.",
    "line": 84
  }, {
    "author": {
      "login": "marmbrus"
    },
    "body": "I think that you just find the nearest timeout with an accumulator and set the trigger duration to the min of the default and that nearest timeout.",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-14T18:29:02Z",
    "diffHunk": "@@ -61,25 +65,50 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger in the query\n+ *      (i.e. after D ms). So there is a no strict upper bound on when the timeout would occur.\n+ *      For example, the trigger interval of the query will affect when the timeout is actually hit.\n+ *      If there is no data in the stream (for any key) for a while, then their will not be\n+ *      any trigger and timeout will not be hit until there is data.",
    "line": 84
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "We can do this in a future PR.",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-17T01:46:53Z",
    "diffHunk": "@@ -61,25 +65,50 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *  - After that, if `update(newState)` is called, then `exists()` will again return `true`,\n  *    `get()` and `getOption()`will return the updated value.\n  *\n+ * Important points to note about using `KeyedStateTimeout`.\n+ *  - The timeout type is a global param across all the keys (set as `timeout` param in\n+ *    `[map|flatMap]GroupsWithState`, but the exact timeout duration is configurable per key\n+ *    (by calling `setTimeout...()` in `KeyedState`).\n+ *  - When the timeout occurs for a key, the function is called with no values, and\n+ *    `KeyedState.isTimingOut()` set to true.\n+ *  - The timeout is reset for key every time the function is called on the key, that is,\n+ *    when the key has new data, or the key has timed out. So the user has to set the timeout\n+ *    duration every time the function is called, otherwise there will not be any timeout set.\n+ *  - Guarantees provided on processing-time-based timeout of key, when timeout duration is D ms:\n+ *    - Timeout will never be called before real clock time has advanced by D ms\n+ *    - Timeout will be called eventually when there is a trigger in the query\n+ *      (i.e. after D ms). So there is a no strict upper bound on when the timeout would occur.\n+ *      For example, the trigger interval of the query will affect when the timeout is actually hit.\n+ *      If there is no data in the stream (for any key) for a while, then their will not be\n+ *      any trigger and timeout will not be hit until there is data.",
    "line": 84
  }],
  "prId": 17179
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "nit: `isTimingOut()`",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-14T22:35:47Z",
    "diffHunk": "@@ -92,27 +121,33 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *\n  *      @Override\n  *      public String call(String key, Iterator<Integer> value, KeyedState<Integer> state) {\n- *        if (state.exists()) {\n+ *        if (state.isTimingOut) {           // If called when timing out, remove the state"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "done.",
    "commit": "497646e8c7243b062ac63587c55d0b0da51abab2",
    "createdAt": "2017-03-17T01:28:02Z",
    "diffHunk": "@@ -92,27 +121,33 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalKeyedState\n  *\n  *      @Override\n  *      public String call(String key, Iterator<Integer> value, KeyedState<Integer> state) {\n- *        if (state.exists()) {\n+ *        if (state.isTimingOut) {           // If called when timing out, remove the state"
  }],
  "prId": 17179
}]