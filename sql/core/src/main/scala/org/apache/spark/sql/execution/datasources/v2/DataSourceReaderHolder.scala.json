[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "`defines` -> `with customized`",
    "commit": "200cd204aa25c1571216047ba2da523fb14a612b",
    "createdAt": "2017-10-11T19:17:03Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.Objects\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference}\n+import org.apache.spark.sql.sources.v2.reader._\n+\n+/**\n+ * A base class for data source reader holder and defines equals/hashCode methods."
  }],
  "prId": 19424
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "The evaluation order of these filters must be the same? If the orders are different, they are still the same, right?",
    "commit": "200cd204aa25c1571216047ba2da523fb14a612b",
    "createdAt": "2017-10-11T19:25:22Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.Objects\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference}\n+import org.apache.spark.sql.sources.v2.reader._\n+\n+/**\n+ * A base class for data source reader holder and defines equals/hashCode methods.\n+ */\n+trait DataSourceReaderHolder {\n+  def fullOutput: Seq[AttributeReference]\n+  def reader: DataSourceV2Reader\n+\n+  override def equals(other: Any): Boolean = other match {\n+    case other: DataSourceV2Relation =>\n+      val basicEquals = this.fullOutput == other.fullOutput &&\n+        this.reader.getClass == other.reader.getClass &&\n+        this.reader.readSchema() == other.reader.readSchema()\n+\n+      val samePushedFilters = (this.reader, other.reader) match {\n+        case (l: SupportsPushDownCatalystFilters, r: SupportsPushDownCatalystFilters) =>\n+          l.pushedCatalystFilters().toSeq == r.pushedCatalystFilters().toSeq\n+        case (l: SupportsPushDownFilters, r: SupportsPushDownFilters) =>\n+          l.pushedFilters().toSeq == r.pushedFilters().toSeq"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "good catch!",
    "commit": "200cd204aa25c1571216047ba2da523fb14a612b",
    "createdAt": "2017-10-12T07:10:01Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.Objects\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference}\n+import org.apache.spark.sql.sources.v2.reader._\n+\n+/**\n+ * A base class for data source reader holder and defines equals/hashCode methods.\n+ */\n+trait DataSourceReaderHolder {\n+  def fullOutput: Seq[AttributeReference]\n+  def reader: DataSourceV2Reader\n+\n+  override def equals(other: Any): Boolean = other match {\n+    case other: DataSourceV2Relation =>\n+      val basicEquals = this.fullOutput == other.fullOutput &&\n+        this.reader.getClass == other.reader.getClass &&\n+        this.reader.readSchema() == other.reader.readSchema()\n+\n+      val samePushedFilters = (this.reader, other.reader) match {\n+        case (l: SupportsPushDownCatalystFilters, r: SupportsPushDownCatalystFilters) =>\n+          l.pushedCatalystFilters().toSeq == r.pushedCatalystFilters().toSeq\n+        case (l: SupportsPushDownFilters, r: SupportsPushDownFilters) =>\n+          l.pushedFilters().toSeq == r.pushedFilters().toSeq"
  }],
  "prId": 19424
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Shall we use resolver instead of string comparison?",
    "commit": "200cd204aa25c1571216047ba2da523fb14a612b",
    "createdAt": "2017-10-12T09:12:32Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.Objects\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference}\n+import org.apache.spark.sql.sources.v2.reader._\n+\n+/**\n+ * A base class for data source reader holder with customized equals/hashCode methods.\n+ */\n+trait DataSourceReaderHolder {\n+\n+  /**\n+   * The full output of the data source reader, without column pruning.\n+   */\n+  def fullOutput: Seq[AttributeReference]\n+\n+  /**\n+   * The held data source reader.\n+   */\n+  def reader: DataSourceV2Reader\n+\n+  /**\n+   * The metadata of this data source reader that can be used for equality test.\n+   */\n+  private def metadata: Seq[Any] = {\n+    val filters: Any = reader match {\n+      case s: SupportsPushDownCatalystFilters => s.pushedCatalystFilters().toSet\n+      case s: SupportsPushDownFilters => s.pushedFilters().toSet\n+      case _ => Nil\n+    }\n+    Seq(fullOutput, reader.getClass, reader.readSchema(), filters)\n+  }\n+\n+  def canEqual(other: Any): Boolean\n+\n+  override def equals(other: Any): Boolean = other match {\n+    case other: DataSourceReaderHolder =>\n+      canEqual(other) && metadata.length == other.metadata.length &&\n+        metadata.zip(other.metadata).forall { case (l, r) => l == r }\n+    case _ => false\n+  }\n+\n+  override def hashCode(): Int = {\n+    metadata.map(Objects.hashCode).foldLeft(0)((a, b) => 31 * a + b)\n+  }\n+\n+  lazy val output: Seq[Attribute] = reader.readSchema().map(_.name).map { name =>\n+    fullOutput.find(_.name == name).get",
    "line": 66
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "These names should already be normalized before reaching here.",
    "commit": "200cd204aa25c1571216047ba2da523fb14a612b",
    "createdAt": "2017-10-12T12:31:37Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.util.Objects\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference}\n+import org.apache.spark.sql.sources.v2.reader._\n+\n+/**\n+ * A base class for data source reader holder with customized equals/hashCode methods.\n+ */\n+trait DataSourceReaderHolder {\n+\n+  /**\n+   * The full output of the data source reader, without column pruning.\n+   */\n+  def fullOutput: Seq[AttributeReference]\n+\n+  /**\n+   * The held data source reader.\n+   */\n+  def reader: DataSourceV2Reader\n+\n+  /**\n+   * The metadata of this data source reader that can be used for equality test.\n+   */\n+  private def metadata: Seq[Any] = {\n+    val filters: Any = reader match {\n+      case s: SupportsPushDownCatalystFilters => s.pushedCatalystFilters().toSet\n+      case s: SupportsPushDownFilters => s.pushedFilters().toSet\n+      case _ => Nil\n+    }\n+    Seq(fullOutput, reader.getClass, reader.readSchema(), filters)\n+  }\n+\n+  def canEqual(other: Any): Boolean\n+\n+  override def equals(other: Any): Boolean = other match {\n+    case other: DataSourceReaderHolder =>\n+      canEqual(other) && metadata.length == other.metadata.length &&\n+        metadata.zip(other.metadata).forall { case (l, r) => l == r }\n+    case _ => false\n+  }\n+\n+  override def hashCode(): Int = {\n+    metadata.map(Objects.hashCode).foldLeft(0)((a, b) => 31 * a + b)\n+  }\n+\n+  lazy val output: Seq[Attribute] = reader.readSchema().map(_.name).map { name =>\n+    fullOutput.find(_.name == name).get",
    "line": 66
  }],
  "prId": 19424
}]