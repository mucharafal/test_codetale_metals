[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "override\n",
    "commit": "1ed60106b05bd39d5a29fa0e1ac8f98c19d2412a",
    "createdAt": "2014-09-27T05:43:27Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import org.apache.avro.Schema\n+import org.apache.avro.file.DataFileReader\n+import org.apache.avro.generic.{GenericRecord, GenericDatumReader}\n+import org.apache.avro.mapred.FsInput\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.sql.foreign._\n+import org.apache.spark.sql.test.TestSQLContext\n+\n+import scala.collection.JavaConversions._\n+\n+/**\n+ * An example of a Spark SQL foreign data source for reading data stored in Avro.  Currently this\n+ * is only for illustrative purposes and much of the data type conversion logic still needs to be\n+ * written.\n+ */\n+package object avro extends DataSource {\n+\n+  /**\n+   * Creates a new relation for data store in avro given a `path` as a parameter.\n+   */\n+  def createRelation(sqlContext: SQLContext, parameters: Map[String, String]) = {"
  }],
  "prId": 2475
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "i think it is slightly confusing to make this a package object that extends DataSource for a few reasons\n1. it is less common for a package object to implement a lot of stuff\n2. based on the fact that you have an implicit class AvroContext, I'm assuming users would usually import avro._. in this case, createRelation is exposed as well\n",
    "commit": "1ed60106b05bd39d5a29fa0e1ac8f98c19d2412a",
    "createdAt": "2014-09-27T05:44:27Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import org.apache.avro.Schema\n+import org.apache.avro.file.DataFileReader\n+import org.apache.avro.generic.{GenericRecord, GenericDatumReader}\n+import org.apache.avro.mapred.FsInput\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.sql.foreign._\n+import org.apache.spark.sql.test.TestSQLContext\n+\n+import scala.collection.JavaConversions._\n+\n+/**\n+ * An example of a Spark SQL foreign data source for reading data stored in Avro.  Currently this\n+ * is only for illustrative purposes and much of the data type conversion logic still needs to be\n+ * written.\n+ */\n+package object avro extends DataSource {"
  }],
  "prId": 2475
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "declare the type explicitly for schema and buildScan. I think that's much more important here because this is going to be an example where people learn to use this ...\n",
    "commit": "1ed60106b05bd39d5a29fa0e1ac8f98c19d2412a",
    "createdAt": "2014-09-27T05:45:38Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import org.apache.avro.Schema\n+import org.apache.avro.file.DataFileReader\n+import org.apache.avro.generic.{GenericRecord, GenericDatumReader}\n+import org.apache.avro.mapred.FsInput\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.sql.foreign._\n+import org.apache.spark.sql.test.TestSQLContext\n+\n+import scala.collection.JavaConversions._\n+\n+/**\n+ * An example of a Spark SQL foreign data source for reading data stored in Avro.  Currently this\n+ * is only for illustrative purposes and much of the data type conversion logic still needs to be\n+ * written.\n+ */\n+package object avro extends DataSource {\n+\n+  /**\n+   * Creates a new relation for data store in avro given a `path` as a parameter.\n+   */\n+  def createRelation(sqlContext: SQLContext, parameters: Map[String, String]) = {\n+    AvroRelation(parameters(\"path\"))(sqlContext)\n+  }\n+\n+  /**\n+   * Adds a method, `avroFile`, to SQLContext that allows reading data stored in Avro.\n+   */\n+  implicit class AvroContext(sqlContext: SQLContext) {\n+    def avroFile(filePath: String) = AvroRelation(filePath)(sqlContext)\n+  }\n+\n+  case class AvroRelation(location: String)(val sqlContext: SQLContext)\n+    extends BaseRelation with TableScan {\n+\n+    val schema = {"
  }],
  "prId": 2475
}]