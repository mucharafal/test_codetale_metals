[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "This method and below methods are moved from the old `DataSourceResolution`.",
    "commit": "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "createdAt": "2019-09-17T14:51:19Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.plans.logical.{AlterTable, DeleteFromTable, DescribeTable, LogicalPlan, SubqueryAlias}\n+import org.apache.spark.sql.catalyst.plans.logical.sql.{AlterTableAddColumnsStatement, AlterTableAlterColumnStatement, AlterTableDropColumnsStatement, AlterTableRenameColumnStatement, AlterTableSetLocationStatement, AlterTableSetPropertiesStatement, AlterTableUnsetPropertiesStatement, AlterViewSetPropertiesStatement, AlterViewUnsetPropertiesStatement, DeleteFromStatement, DescribeTableStatement, QualifiedColType}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.connector.catalog.{CatalogManager, LookupCatalog, TableChange}\n+import org.apache.spark.sql.execution.command.{AlterTableAddColumnsCommand, AlterTableSetLocationCommand, AlterTableSetPropertiesCommand, AlterTableUnsetPropertiesCommand, DescribeTableCommand}\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceV2Relation\n+import org.apache.spark.sql.types.{HIVE_TYPE_STRING, HiveStringType, MetadataBuilder, StructField}\n+\n+/**\n+ * Resolves tables from the multi-part identifiers in DDL/DML commands.\n+ *\n+ * For each SQL statement, this rule has 2 different code paths for v1 and v2 tables.\n+ */\n+class ResolveTables(val catalogManager: CatalogManager)\n+  extends Rule[LogicalPlan] with LookupCatalog {\n+  import org.apache.spark.sql.connector.catalog.CatalogV2Implicits._\n+\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan.resolveOperatorsUp {\n+    case AlterTableAddColumnsStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), cols) =>\n+      cols.foreach(c => assertTopLeveColumn(c.name, \"AlterTableAddColumnsCommand\"))\n+      AlterTableAddColumnsCommand(tblName.toV1Identifier, cols.map(convertToStructField))\n+\n+    case AlterTableAddColumnsStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), cols) =>\n+      val changes = cols.map { col =>\n+        TableChange.addColumn(col.name.toArray, col.dataType, true, col.comment.orNull)\n+      }\n+      AlterTable(catalog, tblName.toIdentifier, table, changes)\n+\n+    // The v1 `AlterTableAddColumnsCommand` will check temp view and provide better error message.\n+    // Here we convert the statement to the v1 command to get the better error message.\n+    // TODO: apply the temp view check for all ALTER TABLE statements.\n+    case AlterTableAddColumnsStatement(tblName, cols) =>\n+      cols.foreach(c => assertTopLeveColumn(c.name, \"AlterTableAddColumnsCommand\"))\n+      AlterTableAddColumnsCommand(tblName.toV1Identifier, cols.map(convertToStructField))\n+\n+    // TODO: we should fallback to the v1 `AlterTableChangeColumnCommand`.\n+    case AlterTableAlterColumnStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), colName, dataType, comment) =>\n+      throw new AnalysisException(\"ALTER COLUMN is not supported with v1 table.\")\n+\n+    case AlterTableAlterColumnStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), colName, dataType, comment) =>\n+      val typeChange = dataType.map { newDataType =>\n+        TableChange.updateColumnType(colName.toArray, newDataType, true)\n+      }\n+      val commentChange = comment.map { newComment =>\n+        TableChange.updateColumnComment(colName.toArray, newComment)\n+      }\n+      AlterTable(catalog, tblName.toIdentifier, table, typeChange.toSeq ++ commentChange)\n+\n+    case AlterTableRenameColumnStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), col, newName) =>\n+      throw new AnalysisException(\"RENAME COLUMN is not supported with v1 table.\")\n+\n+    case AlterTableRenameColumnStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), col, newName) =>\n+      val changes = Seq(TableChange.renameColumn(col.toArray, newName))\n+      AlterTable(catalog, tblName.toIdentifier, table, changes)\n+\n+    case AlterTableDropColumnsStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), cols) =>\n+      throw new AnalysisException(\"DROP COLUMN is not supported with v1 table.\")\n+\n+    case AlterTableDropColumnsStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), cols) =>\n+      val changes = cols.map(col => TableChange.deleteColumn(col.toArray))\n+      AlterTable(catalog, tblName.toIdentifier, table, changes)\n+\n+    case AlterTableSetPropertiesStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), props) =>\n+      AlterTableSetPropertiesCommand(tblName.toV1Identifier, props, isView = false)\n+\n+    case AlterTableSetPropertiesStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), props) =>\n+      val changes = props.map { case (key, value) =>\n+        TableChange.setProperty(key, value)\n+      }\n+      AlterTable(catalog.asTableCatalog, tblName.toIdentifier, table, changes.toSeq)\n+\n+    case AlterTableUnsetPropertiesStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), keys, ifExists) =>\n+      AlterTableUnsetPropertiesCommand(tblName.toV1Identifier, keys, ifExists, isView = false)\n+\n+    // TODO: v2 `UNSET TBLPROPERTIES` should respect the ifExists flag.\n+    case AlterTableUnsetPropertiesStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), keys, _) =>\n+      val changes = keys.map(key => TableChange.removeProperty(key))\n+      AlterTable(catalog, tblName.toIdentifier, table, changes)\n+\n+    case AlterTableSetLocationStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), newLoc) =>\n+      AlterTableSetLocationCommand(tblName.toV1Identifier, None, newLoc)\n+\n+    case AlterTableSetLocationStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), newLoc) =>\n+      val changes = Seq(TableChange.setProperty(\"location\", newLoc))\n+      AlterTable(catalog.asTableCatalog, tblName.toIdentifier, table, changes)\n+\n+    // The v1 `AlterTableSetLocationCommand` throws NuSuchTable exception at runtime, while the v2\n+    // command throws AnalysisException at analysis time. Here we convert to the v1 command to keep\n+    // the exception type unchanged.\n+    // TODO: unify the table not found exception for all ALTER TABLE commands.\n+    case AlterTableSetLocationStatement(tblName, newLoc) =>\n+      AlterTableSetLocationCommand(tblName.toV1Identifier, None, newLoc)\n+\n+    case AlterViewSetPropertiesStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), props) =>\n+      throw new AnalysisException(\n+        s\"Can not specify catalog `${catalog.name}` for view ${tblName.quoted} \" +\n+          s\"because view support in catalog has not been implemented yet\")\n+\n+    case AlterViewSetPropertiesStatement(tblName, props) =>\n+      AlterTableSetPropertiesCommand(tblName.toV1Identifier, props, isView = true)\n+\n+    case AlterViewUnsetPropertiesStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), keys, ifExists) =>\n+      throw new AnalysisException(\n+        s\"Can not specify catalog `${catalog.name}` for view ${tblName.quoted} \" +\n+          s\"because view support in catalog has not been implemented yet\")\n+\n+    case AlterViewUnsetPropertiesStatement(tblName, keys, ifExists) =>\n+      AlterTableUnsetPropertiesCommand(tblName.toV1Identifier, keys, ifExists, isView = true)\n+\n+    case DeleteFromStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), tableAlias, condition) =>\n+      throw new AnalysisException(\"DELETE FROM is not supported with v1 table.\")\n+\n+    case DeleteFromStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), tableAlias, condition) =>\n+      val relation = DataSourceV2Relation.create(table)\n+      val aliased = tableAlias.map(SubqueryAlias(_, relation)).getOrElse(relation)\n+      DeleteFromTable(aliased, condition)\n+\n+    case DescribeTableStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), partitionSpec, isExtended) =>\n+      if (partitionSpec.nonEmpty) {\n+        throw new AnalysisException(\"DESC TABLE does not support partition for v2 tables.\")\n+      }\n+      DescribeTable(table, isExtended)\n+\n+    // If we can't convert `DescribeTableStatement` to v2 `DescribeTable`, blindly convert it to\n+    // v1 `DescribeTableCommand` because it can describe view/temp view as well.\n+    case DescribeTableStatement(tblName, partitionSpec, isExtended) =>\n+      DescribeTableCommand(tblName.toV1Identifier, partitionSpec, isExtended)\n+  }\n+\n+  private def assertTopLeveColumn(colName: Seq[String], command: String): Unit = {"
  }],
  "prId": 25747
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "It's very weird that only `ALTER ADD COLUMN` checks temp view. This is an existing behavior so I don't want to change it in this refactor PR.",
    "commit": "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "createdAt": "2019-09-17T14:52:20Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.plans.logical.{AlterTable, DeleteFromTable, DescribeTable, LogicalPlan, SubqueryAlias}\n+import org.apache.spark.sql.catalyst.plans.logical.sql.{AlterTableAddColumnsStatement, AlterTableAlterColumnStatement, AlterTableDropColumnsStatement, AlterTableRenameColumnStatement, AlterTableSetLocationStatement, AlterTableSetPropertiesStatement, AlterTableUnsetPropertiesStatement, AlterViewSetPropertiesStatement, AlterViewUnsetPropertiesStatement, DeleteFromStatement, DescribeTableStatement, QualifiedColType}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.connector.catalog.{CatalogManager, LookupCatalog, TableChange}\n+import org.apache.spark.sql.execution.command.{AlterTableAddColumnsCommand, AlterTableSetLocationCommand, AlterTableSetPropertiesCommand, AlterTableUnsetPropertiesCommand, DescribeTableCommand}\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceV2Relation\n+import org.apache.spark.sql.types.{HIVE_TYPE_STRING, HiveStringType, MetadataBuilder, StructField}\n+\n+/**\n+ * Resolves tables from the multi-part identifiers in DDL/DML commands.\n+ *\n+ * For each SQL statement, this rule has 2 different code paths for v1 and v2 tables.\n+ */\n+class ResolveTables(val catalogManager: CatalogManager)\n+  extends Rule[LogicalPlan] with LookupCatalog {\n+  import org.apache.spark.sql.connector.catalog.CatalogV2Implicits._\n+\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan.resolveOperatorsUp {\n+    case AlterTableAddColumnsStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), cols) =>\n+      cols.foreach(c => assertTopLeveColumn(c.name, \"AlterTableAddColumnsCommand\"))\n+      AlterTableAddColumnsCommand(tblName.toV1Identifier, cols.map(convertToStructField))\n+\n+    case AlterTableAddColumnsStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), cols) =>\n+      val changes = cols.map { col =>\n+        TableChange.addColumn(col.name.toArray, col.dataType, true, col.comment.orNull)\n+      }\n+      AlterTable(catalog, tblName.toIdentifier, table, changes)\n+\n+    // The v1 `AlterTableAddColumnsCommand` will check temp view and provide better error message.\n+    // Here we convert the statement to the v1 command to get the better error message.\n+    // TODO: apply the temp view check for all ALTER TABLE statements.\n+    case AlterTableAddColumnsStatement(tblName, cols) =>"
  }],
  "prId": 25747
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "This is a general problem that, when table not found, v1 ALTER TABLE commands do table lookup at runtime and throw `NuSuchTable` exception, while v2 ALTER TABLE commands do table lookup at analysis time and throw `AnalysisException`.\r\n\r\nI think the v2 behavior is more reasonable, but I'd like to avoid behavior changes in this refactor PR.",
    "commit": "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "createdAt": "2019-09-17T14:55:38Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.catalyst.analysis\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.catalyst.plans.logical.{AlterTable, DeleteFromTable, DescribeTable, LogicalPlan, SubqueryAlias}\n+import org.apache.spark.sql.catalyst.plans.logical.sql.{AlterTableAddColumnsStatement, AlterTableAlterColumnStatement, AlterTableDropColumnsStatement, AlterTableRenameColumnStatement, AlterTableSetLocationStatement, AlterTableSetPropertiesStatement, AlterTableUnsetPropertiesStatement, AlterViewSetPropertiesStatement, AlterViewUnsetPropertiesStatement, DeleteFromStatement, DescribeTableStatement, QualifiedColType}\n+import org.apache.spark.sql.catalyst.rules.Rule\n+import org.apache.spark.sql.connector.catalog.{CatalogManager, LookupCatalog, TableChange}\n+import org.apache.spark.sql.execution.command.{AlterTableAddColumnsCommand, AlterTableSetLocationCommand, AlterTableSetPropertiesCommand, AlterTableUnsetPropertiesCommand, DescribeTableCommand}\n+import org.apache.spark.sql.execution.datasources.v2.DataSourceV2Relation\n+import org.apache.spark.sql.types.{HIVE_TYPE_STRING, HiveStringType, MetadataBuilder, StructField}\n+\n+/**\n+ * Resolves tables from the multi-part identifiers in DDL/DML commands.\n+ *\n+ * For each SQL statement, this rule has 2 different code paths for v1 and v2 tables.\n+ */\n+class ResolveTables(val catalogManager: CatalogManager)\n+  extends Rule[LogicalPlan] with LookupCatalog {\n+  import org.apache.spark.sql.connector.catalog.CatalogV2Implicits._\n+\n+  override def apply(plan: LogicalPlan): LogicalPlan = plan.resolveOperatorsUp {\n+    case AlterTableAddColumnsStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), cols) =>\n+      cols.foreach(c => assertTopLeveColumn(c.name, \"AlterTableAddColumnsCommand\"))\n+      AlterTableAddColumnsCommand(tblName.toV1Identifier, cols.map(convertToStructField))\n+\n+    case AlterTableAddColumnsStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), cols) =>\n+      val changes = cols.map { col =>\n+        TableChange.addColumn(col.name.toArray, col.dataType, true, col.comment.orNull)\n+      }\n+      AlterTable(catalog, tblName.toIdentifier, table, changes)\n+\n+    // The v1 `AlterTableAddColumnsCommand` will check temp view and provide better error message.\n+    // Here we convert the statement to the v1 command to get the better error message.\n+    // TODO: apply the temp view check for all ALTER TABLE statements.\n+    case AlterTableAddColumnsStatement(tblName, cols) =>\n+      cols.foreach(c => assertTopLeveColumn(c.name, \"AlterTableAddColumnsCommand\"))\n+      AlterTableAddColumnsCommand(tblName.toV1Identifier, cols.map(convertToStructField))\n+\n+    // TODO: we should fallback to the v1 `AlterTableChangeColumnCommand`.\n+    case AlterTableAlterColumnStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), colName, dataType, comment) =>\n+      throw new AnalysisException(\"ALTER COLUMN is not supported with v1 table.\")\n+\n+    case AlterTableAlterColumnStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), colName, dataType, comment) =>\n+      val typeChange = dataType.map { newDataType =>\n+        TableChange.updateColumnType(colName.toArray, newDataType, true)\n+      }\n+      val commentChange = comment.map { newComment =>\n+        TableChange.updateColumnComment(colName.toArray, newComment)\n+      }\n+      AlterTable(catalog, tblName.toIdentifier, table, typeChange.toSeq ++ commentChange)\n+\n+    case AlterTableRenameColumnStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), col, newName) =>\n+      throw new AnalysisException(\"RENAME COLUMN is not supported with v1 table.\")\n+\n+    case AlterTableRenameColumnStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), col, newName) =>\n+      val changes = Seq(TableChange.renameColumn(col.toArray, newName))\n+      AlterTable(catalog, tblName.toIdentifier, table, changes)\n+\n+    case AlterTableDropColumnsStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), cols) =>\n+      throw new AnalysisException(\"DROP COLUMN is not supported with v1 table.\")\n+\n+    case AlterTableDropColumnsStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), cols) =>\n+      val changes = cols.map(col => TableChange.deleteColumn(col.toArray))\n+      AlterTable(catalog, tblName.toIdentifier, table, changes)\n+\n+    case AlterTableSetPropertiesStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), props) =>\n+      AlterTableSetPropertiesCommand(tblName.toV1Identifier, props, isView = false)\n+\n+    case AlterTableSetPropertiesStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), props) =>\n+      val changes = props.map { case (key, value) =>\n+        TableChange.setProperty(key, value)\n+      }\n+      AlterTable(catalog.asTableCatalog, tblName.toIdentifier, table, changes.toSeq)\n+\n+    case AlterTableUnsetPropertiesStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), keys, ifExists) =>\n+      AlterTableUnsetPropertiesCommand(tblName.toV1Identifier, keys, ifExists, isView = false)\n+\n+    // TODO: v2 `UNSET TBLPROPERTIES` should respect the ifExists flag.\n+    case AlterTableUnsetPropertiesStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), keys, _) =>\n+      val changes = keys.map(key => TableChange.removeProperty(key))\n+      AlterTable(catalog, tblName.toIdentifier, table, changes)\n+\n+    case AlterTableSetLocationStatement(\n+         CatalogAndTable(catalog, tblName, Left(v1Table)), newLoc) =>\n+      AlterTableSetLocationCommand(tblName.toV1Identifier, None, newLoc)\n+\n+    case AlterTableSetLocationStatement(\n+         CatalogAndTable(catalog, tblName, Right(table)), newLoc) =>\n+      val changes = Seq(TableChange.setProperty(\"location\", newLoc))\n+      AlterTable(catalog.asTableCatalog, tblName.toIdentifier, table, changes)\n+\n+    // The v1 `AlterTableSetLocationCommand` throws NuSuchTable exception at runtime, while the v2\n+    // command throws AnalysisException at analysis time. Here we convert to the v1 command to keep\n+    // the exception type unchanged.\n+    // TODO: unify the table not found exception for all ALTER TABLE commands.\n+    case AlterTableSetLocationStatement(tblName, newLoc) =>"
  }],
  "prId": 25747
}]