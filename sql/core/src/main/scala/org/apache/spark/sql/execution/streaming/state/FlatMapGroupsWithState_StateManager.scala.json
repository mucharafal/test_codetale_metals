[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Add docs to this class and methods.",
    "commit": "ee0b81a148c892e0f27191c31dbef1c42424b6e1",
    "createdAt": "2017-10-03T02:58:26Z",
    "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, BoundReference, CaseWhen, CreateNamedStruct, GetStructField, IsNull, Literal, UnsafeRow}\n+import org.apache.spark.sql.execution.ObjectOperator\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl.NO_TIMESTAMP\n+import org.apache.spark.sql.types.{IntegerType, LongType, StructType}\n+\n+\n+class FlatMapGroupsWithState_StateManager("
  }, {
    "author": {
      "login": "yssharma"
    },
    "body": "Is the underscore in the file name for clarity ?",
    "commit": "ee0b81a148c892e0f27191c31dbef1c42424b6e1",
    "createdAt": "2017-10-03T10:45:22Z",
    "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, BoundReference, CaseWhen, CreateNamedStruct, GetStructField, IsNull, Literal, UnsafeRow}\n+import org.apache.spark.sql.execution.ObjectOperator\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl.NO_TIMESTAMP\n+import org.apache.spark.sql.types.{IntegerType, LongType, StructType}\n+\n+\n+class FlatMapGroupsWithState_StateManager("
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Yes it is.",
    "commit": "ee0b81a148c892e0f27191c31dbef1c42424b6e1",
    "createdAt": "2017-10-04T01:09:57Z",
    "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, BoundReference, CaseWhen, CreateNamedStruct, GetStructField, IsNull, Literal, UnsafeRow}\n+import org.apache.spark.sql.execution.ObjectOperator\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl.NO_TIMESTAMP\n+import org.apache.spark.sql.types.{IntegerType, LongType, StructType}\n+\n+\n+class FlatMapGroupsWithState_StateManager("
  }],
  "prId": 19416
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "add docs",
    "commit": "ee0b81a148c892e0f27191c31dbef1c42424b6e1",
    "createdAt": "2017-10-03T02:59:02Z",
    "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, BoundReference, CaseWhen, CreateNamedStruct, GetStructField, IsNull, Literal, UnsafeRow}\n+import org.apache.spark.sql.execution.ObjectOperator\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl.NO_TIMESTAMP\n+import org.apache.spark.sql.types.{IntegerType, LongType, StructType}\n+\n+\n+class FlatMapGroupsWithState_StateManager(\n+    stateEncoder: ExpressionEncoder[Any],\n+    shouldStoreTimestamp: Boolean) extends Serializable {\n+\n+  val stateSchema = {\n+    val schema = new StructType().add(\"groupState\", stateEncoder.schema, nullable = true)\n+    if (shouldStoreTimestamp) schema.add(\"timeoutTimestamp\", LongType) else schema\n+  }\n+\n+  def getState(store: StateStore, keyRow: UnsafeRow): FlatMapGroupsWithState_StateData = {\n+    val stateRow = store.get(keyRow)\n+    stateDataForGets.withNew(\n+      keyRow, stateRow, getStateObj(stateRow), getTimestamp(stateRow))\n+  }\n+\n+  def putState(store: StateStore, keyRow: UnsafeRow, state: Any, timestamp: Long): Unit = {\n+    val stateRow = getStateRow(state)\n+    setTimestamp(stateRow, timestamp)\n+    store.put(keyRow, stateRow)\n+  }\n+\n+  def removeState(store: StateStore, keyRow: UnsafeRow): Unit = {\n+    store.remove(keyRow)\n+  }\n+\n+  def getAllState(store: StateStore): Iterator[FlatMapGroupsWithState_StateData] = {\n+    val stateDataForGetAllState = FlatMapGroupsWithState_StateData()\n+    store.getRange(None, None).map { pair =>\n+      stateDataForGetAllState.withNew(\n+        pair.key, pair.value, getStateObjFromRow(pair.value), getTimestamp(pair.value))\n+    }\n+  }\n+\n+  private val stateAttributes: Seq[Attribute] = stateSchema.toAttributes\n+\n+  // Get the serializer for the state, taking into account whether we need to save timestamps\n+  private val stateSerializer = {\n+    val nestedStateExpr = CreateNamedStruct(\n+      stateEncoder.namedExpressions.flatMap(e => Seq(Literal(e.name), e)))\n+    if (shouldStoreTimestamp) {\n+      Seq(nestedStateExpr, Literal(GroupStateImpl.NO_TIMESTAMP))\n+    } else {\n+      Seq(nestedStateExpr)\n+    }\n+  }\n+\n+  // Get the deserializer for the state. Note that this must be done in the driver, as\n+  // resolving and binding of deserializer expressions to the encoded type can be safely done\n+  // only in the driver.\n+  private val stateDeserializer = {\n+    val boundRefToNestedState = BoundReference(nestedStateOrdinal, stateEncoder.schema, true)\n+    val deser = stateEncoder.resolveAndBind().deserializer.transformUp {\n+      case BoundReference(ordinal, _, _) => GetStructField(boundRefToNestedState, ordinal)\n+    }\n+    CaseWhen(Seq(IsNull(boundRefToNestedState) -> Literal(null)), elseValue = deser).toCodegen()\n+  }\n+\n+  private lazy val nestedStateOrdinal = 0\n+  private lazy val timeoutTimestampOrdinal = 1\n+\n+  // Converters for translating state between rows and Java objects\n+  private lazy val getStateObjFromRow = ObjectOperator.deserializeRowToObject(\n+    stateDeserializer, stateAttributes)\n+  private lazy val getStateRowFromObj = ObjectOperator.serializeObjectToRow(stateSerializer)\n+\n+  private lazy val stateDataForGets = FlatMapGroupsWithState_StateData()\n+\n+  /** Returns the state as Java object if defined */\n+  private def getStateObj(stateRow: UnsafeRow): Any = {\n+    if (stateRow == null) null\n+    // else if (stateRow.isNullAt(nestedStateOrdinal)) null\n+    else getStateObjFromRow(stateRow)\n+  }\n+\n+  /** Returns the row for an updated state */\n+  private def getStateRow(obj: Any): UnsafeRow = {\n+    val row = getStateRowFromObj(obj)\n+    if (obj == null) {\n+      row.setNullAt(nestedStateOrdinal)\n+    }\n+    row\n+  }\n+\n+  /** Returns the timeout timestamp of a state row is set */\n+  private def getTimestamp(stateRow: UnsafeRow): Long = {\n+    if (shouldStoreTimestamp && stateRow != null) {\n+      stateRow.getLong(timeoutTimestampOrdinal)\n+    } else NO_TIMESTAMP\n+  }\n+\n+  /** Set the timestamp in a state row */\n+  private def setTimestamp(stateRow: UnsafeRow, timeoutTimestamps: Long): Unit = {\n+    if (shouldStoreTimestamp) stateRow.setLong(timeoutTimestampOrdinal, timeoutTimestamps)\n+  }\n+\n+}\n+\n+\n+case class FlatMapGroupsWithState_StateData("
  }],
  "prId": 19416
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This part needs work. The current serializer expressions does not set the top level `groupState` column (pointing to nested state columns) in the unsaferow to null. So i am explicitly setting it to null. However, the saved nested columns are still set to a value. Its possible that nested unsaferow can be removed, thus saving space. For this, I have to encode this conditional logic in the serializer.",
    "commit": "ee0b81a148c892e0f27191c31dbef1c42424b6e1",
    "createdAt": "2017-10-03T03:12:37Z",
    "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, BoundReference, CaseWhen, CreateNamedStruct, GetStructField, IsNull, Literal, UnsafeRow}\n+import org.apache.spark.sql.execution.ObjectOperator\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl.NO_TIMESTAMP\n+import org.apache.spark.sql.types.{IntegerType, LongType, StructType}\n+\n+\n+class FlatMapGroupsWithState_StateManager(\n+    stateEncoder: ExpressionEncoder[Any],\n+    shouldStoreTimestamp: Boolean) extends Serializable {\n+\n+  val stateSchema = {\n+    val schema = new StructType().add(\"groupState\", stateEncoder.schema, nullable = true)\n+    if (shouldStoreTimestamp) schema.add(\"timeoutTimestamp\", LongType) else schema\n+  }\n+\n+  def getState(store: StateStore, keyRow: UnsafeRow): FlatMapGroupsWithState_StateData = {\n+    val stateRow = store.get(keyRow)\n+    stateDataForGets.withNew(\n+      keyRow, stateRow, getStateObj(stateRow), getTimestamp(stateRow))\n+  }\n+\n+  def putState(store: StateStore, keyRow: UnsafeRow, state: Any, timestamp: Long): Unit = {\n+    val stateRow = getStateRow(state)\n+    setTimestamp(stateRow, timestamp)\n+    store.put(keyRow, stateRow)\n+  }\n+\n+  def removeState(store: StateStore, keyRow: UnsafeRow): Unit = {\n+    store.remove(keyRow)\n+  }\n+\n+  def getAllState(store: StateStore): Iterator[FlatMapGroupsWithState_StateData] = {\n+    val stateDataForGetAllState = FlatMapGroupsWithState_StateData()\n+    store.getRange(None, None).map { pair =>\n+      stateDataForGetAllState.withNew(\n+        pair.key, pair.value, getStateObjFromRow(pair.value), getTimestamp(pair.value))\n+    }\n+  }\n+\n+  private val stateAttributes: Seq[Attribute] = stateSchema.toAttributes\n+\n+  // Get the serializer for the state, taking into account whether we need to save timestamps\n+  private val stateSerializer = {\n+    val nestedStateExpr = CreateNamedStruct(\n+      stateEncoder.namedExpressions.flatMap(e => Seq(Literal(e.name), e)))\n+    if (shouldStoreTimestamp) {\n+      Seq(nestedStateExpr, Literal(GroupStateImpl.NO_TIMESTAMP))\n+    } else {\n+      Seq(nestedStateExpr)\n+    }\n+  }\n+\n+  // Get the deserializer for the state. Note that this must be done in the driver, as\n+  // resolving and binding of deserializer expressions to the encoded type can be safely done\n+  // only in the driver.\n+  private val stateDeserializer = {\n+    val boundRefToNestedState = BoundReference(nestedStateOrdinal, stateEncoder.schema, true)\n+    val deser = stateEncoder.resolveAndBind().deserializer.transformUp {\n+      case BoundReference(ordinal, _, _) => GetStructField(boundRefToNestedState, ordinal)\n+    }\n+    CaseWhen(Seq(IsNull(boundRefToNestedState) -> Literal(null)), elseValue = deser).toCodegen()\n+  }\n+\n+  private lazy val nestedStateOrdinal = 0\n+  private lazy val timeoutTimestampOrdinal = 1\n+\n+  // Converters for translating state between rows and Java objects\n+  private lazy val getStateObjFromRow = ObjectOperator.deserializeRowToObject(\n+    stateDeserializer, stateAttributes)\n+  private lazy val getStateRowFromObj = ObjectOperator.serializeObjectToRow(stateSerializer)\n+\n+  private lazy val stateDataForGets = FlatMapGroupsWithState_StateData()\n+\n+  /** Returns the state as Java object if defined */\n+  private def getStateObj(stateRow: UnsafeRow): Any = {\n+    if (stateRow == null) null\n+    // else if (stateRow.isNullAt(nestedStateOrdinal)) null\n+    else getStateObjFromRow(stateRow)\n+  }\n+\n+  /** Returns the row for an updated state */\n+  private def getStateRow(obj: Any): UnsafeRow = {\n+    val row = getStateRowFromObj(obj)",
    "line": 112
  }],
  "prId": 19416
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "nit: remove this",
    "commit": "ee0b81a148c892e0f27191c31dbef1c42424b6e1",
    "createdAt": "2017-10-04T05:25:02Z",
    "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, AttributeReference, BoundReference, CaseWhen, CreateNamedStruct, GetStructField, IsNull, Literal, UnsafeRow}\n+import org.apache.spark.sql.execution.ObjectOperator\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl\n+import org.apache.spark.sql.execution.streaming.GroupStateImpl.NO_TIMESTAMP\n+import org.apache.spark.sql.types.{IntegerType, LongType, StructType}\n+\n+\n+class FlatMapGroupsWithState_StateManager(\n+    stateEncoder: ExpressionEncoder[Any],\n+    shouldStoreTimestamp: Boolean) extends Serializable {\n+\n+  val stateSchema = {\n+    val schema = new StructType().add(\"groupState\", stateEncoder.schema, nullable = true)\n+    if (shouldStoreTimestamp) schema.add(\"timeoutTimestamp\", LongType) else schema\n+  }\n+\n+  def getState(store: StateStore, keyRow: UnsafeRow): FlatMapGroupsWithState_StateData = {\n+    val stateRow = store.get(keyRow)\n+    stateDataForGets.withNew(\n+      keyRow, stateRow, getStateObj(stateRow), getTimestamp(stateRow))\n+  }\n+\n+  def putState(store: StateStore, keyRow: UnsafeRow, state: Any, timestamp: Long): Unit = {\n+    val stateRow = getStateRow(state)\n+    setTimestamp(stateRow, timestamp)\n+    store.put(keyRow, stateRow)\n+  }\n+\n+  def removeState(store: StateStore, keyRow: UnsafeRow): Unit = {\n+    store.remove(keyRow)\n+  }\n+\n+  def getAllState(store: StateStore): Iterator[FlatMapGroupsWithState_StateData] = {\n+    val stateDataForGetAllState = FlatMapGroupsWithState_StateData()\n+    store.getRange(None, None).map { pair =>\n+      stateDataForGetAllState.withNew(\n+        pair.key, pair.value, getStateObjFromRow(pair.value), getTimestamp(pair.value))\n+    }\n+  }\n+\n+  private val stateAttributes: Seq[Attribute] = stateSchema.toAttributes\n+\n+  // Get the serializer for the state, taking into account whether we need to save timestamps\n+  private val stateSerializer = {\n+    val nestedStateExpr = CreateNamedStruct(\n+      stateEncoder.namedExpressions.flatMap(e => Seq(Literal(e.name), e)))\n+    if (shouldStoreTimestamp) {\n+      Seq(nestedStateExpr, Literal(GroupStateImpl.NO_TIMESTAMP))\n+    } else {\n+      Seq(nestedStateExpr)\n+    }\n+  }\n+\n+  // Get the deserializer for the state. Note that this must be done in the driver, as\n+  // resolving and binding of deserializer expressions to the encoded type can be safely done\n+  // only in the driver.\n+  private val stateDeserializer = {\n+    val boundRefToNestedState = BoundReference(nestedStateOrdinal, stateEncoder.schema, true)\n+    val deser = stateEncoder.resolveAndBind().deserializer.transformUp {\n+      case BoundReference(ordinal, _, _) => GetStructField(boundRefToNestedState, ordinal)\n+    }\n+    CaseWhen(Seq(IsNull(boundRefToNestedState) -> Literal(null)), elseValue = deser).toCodegen()\n+  }\n+\n+  private lazy val nestedStateOrdinal = 0\n+  private lazy val timeoutTimestampOrdinal = 1\n+\n+  // Converters for translating state between rows and Java objects\n+  private lazy val getStateObjFromRow = ObjectOperator.deserializeRowToObject(\n+    stateDeserializer, stateAttributes)\n+  private lazy val getStateRowFromObj = ObjectOperator.serializeObjectToRow(stateSerializer)\n+\n+  private lazy val stateDataForGets = FlatMapGroupsWithState_StateData()\n+\n+  /** Returns the state as Java object if defined */\n+  private def getStateObj(stateRow: UnsafeRow): Any = {\n+    if (stateRow == null) null\n+    // else if (stateRow.isNullAt(nestedStateOrdinal)) null"
  }],
  "prId": 19416
}]