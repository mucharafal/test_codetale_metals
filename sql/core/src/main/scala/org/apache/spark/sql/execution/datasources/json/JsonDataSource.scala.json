[{
  "comments": [{
    "author": {
      "login": "wzhfy"
    },
    "body": "don't need to check duplication here?",
    "commit": "5ed2c0d68be372304bc8a46046d28d5b7aadcb97",
    "createdAt": "2017-06-18T05:10:53Z",
    "diffHunk": "@@ -59,9 +59,7 @@ abstract class JsonDataSource extends Serializable {\n       inputPaths: Seq[FileStatus],\n       parsedOptions: JSONOptions): Option[StructType] = {\n     if (inputPaths.nonEmpty) {\n-      val jsonSchema = infer(sparkSession, inputPaths, parsedOptions)\n-      checkConstraints(jsonSchema)\n-      Some(jsonSchema)\n+      Some(infer(sparkSession, inputPaths, parsedOptions))",
    "line": 7
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "I think we do not need to check the duplication in each datasource because it will be checked in `DataSource`. https://github.com/apache/spark/pull/17758/files#diff-7a6cb188d2ae31eb3347b5629a679cecR187",
    "commit": "5ed2c0d68be372304bc8a46046d28d5b7aadcb97",
    "createdAt": "2017-06-18T07:51:21Z",
    "diffHunk": "@@ -59,9 +59,7 @@ abstract class JsonDataSource extends Serializable {\n       inputPaths: Seq[FileStatus],\n       parsedOptions: JSONOptions): Option[StructType] = {\n     if (inputPaths.nonEmpty) {\n-      val jsonSchema = infer(sparkSession, inputPaths, parsedOptions)\n-      checkConstraints(jsonSchema)\n-      Some(jsonSchema)\n+      Some(infer(sparkSession, inputPaths, parsedOptions))",
    "line": 7
  }],
  "prId": 17758
}]