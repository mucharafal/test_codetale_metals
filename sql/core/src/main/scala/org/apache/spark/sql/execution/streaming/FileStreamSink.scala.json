[{
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "I removed `try-catch` from `fs.exists(metadataPath)`. We should not ignore random errors when failing to access `metadataPath` as it may make Spark ignore `_spark_metadata` and return wrong answers.",
    "commit": "91542ff777cd4ef213082d699ee55132c4527d35",
    "createdAt": "2019-02-11T22:18:32Z",
    "diffHunk": "@@ -37,23 +39,47 @@ object FileStreamSink extends Logging {\n    * Returns true if there is a single path that has a metadata log indicating which files should\n    * be read.\n    */\n-  def hasMetadata(path: Seq[String], hadoopConf: Configuration): Boolean = {\n+  def hasMetadata(path: Seq[String], hadoopConf: Configuration, sqlConf: SQLConf): Boolean = {\n     path match {\n       case Seq(singlePath) =>\n+        val hdfsPath = new Path(singlePath)\n+        val fs = hdfsPath.getFileSystem(hadoopConf)\n+        if (fs.isDirectory(hdfsPath)) {\n+          val metadataPath = new Path(hdfsPath, metadataDir)\n+          checkEscapedMetadataPath(fs, metadataPath, sqlConf)\n+          fs.exists(metadataPath)",
    "line": 30
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "+1",
    "commit": "91542ff777cd4ef213082d699ee55132c4527d35",
    "createdAt": "2019-02-12T11:32:37Z",
    "diffHunk": "@@ -37,23 +39,47 @@ object FileStreamSink extends Logging {\n    * Returns true if there is a single path that has a metadata log indicating which files should\n    * be read.\n    */\n-  def hasMetadata(path: Seq[String], hadoopConf: Configuration): Boolean = {\n+  def hasMetadata(path: Seq[String], hadoopConf: Configuration, sqlConf: SQLConf): Boolean = {\n     path match {\n       case Seq(singlePath) =>\n+        val hdfsPath = new Path(singlePath)\n+        val fs = hdfsPath.getFileSystem(hadoopConf)\n+        if (fs.isDirectory(hdfsPath)) {\n+          val metadataPath = new Path(hdfsPath, metadataDir)\n+          checkEscapedMetadataPath(fs, metadataPath, sqlConf)\n+          fs.exists(metadataPath)",
    "line": 30
  }],
  "prId": 23733
}, {
  "comments": [{
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "This means the directory may exist but some other (maybe intermittent) exception other than `FileNotFoundException` came isn't it?",
    "commit": "91542ff777cd4ef213082d699ee55132c4527d35",
    "createdAt": "2019-02-12T09:16:06Z",
    "diffHunk": "@@ -37,23 +39,47 @@ object FileStreamSink extends Logging {\n    * Returns true if there is a single path that has a metadata log indicating which files should\n    * be read.\n    */\n-  def hasMetadata(path: Seq[String], hadoopConf: Configuration): Boolean = {\n+  def hasMetadata(path: Seq[String], hadoopConf: Configuration, sqlConf: SQLConf): Boolean = {\n     path match {\n       case Seq(singlePath) =>\n+        val hdfsPath = new Path(singlePath)\n+        val fs = hdfsPath.getFileSystem(hadoopConf)\n+        if (fs.isDirectory(hdfsPath)) {\n+          val metadataPath = new Path(hdfsPath, metadataDir)\n+          checkEscapedMetadataPath(fs, metadataPath, sqlConf)\n+          fs.exists(metadataPath)\n+        } else {\n+          false\n+        }\n+      case _ => false\n+    }\n+  }\n+\n+  def checkEscapedMetadataPath(fs: FileSystem, metadataPath: Path, sqlConf: SQLConf): Unit = {\n+    if (sqlConf.getConf(SQLConf.STREAMING_CHECKPOINT_ESCAPED_PATH_CHECK_ENABLED)\n+        && StreamExecution.containsSpecialCharsInPath(metadataPath)) {\n+      val legacyMetadataPath = new Path(metadataPath.toUri.toString)\n+      val legacyMetadataPathExists =\n         try {\n-          val hdfsPath = new Path(singlePath)\n-          val fs = hdfsPath.getFileSystem(hadoopConf)\n-          if (fs.isDirectory(hdfsPath)) {\n-            fs.exists(new Path(hdfsPath, metadataDir))\n-          } else {\n-            false\n-          }\n+          fs.exists(legacyMetadataPath)\n         } catch {\n           case NonFatal(e) =>\n-            logWarning(s\"Error while looking for metadata directory.\")\n+            // We may not have access to this directory. Don't fail the query if that happens.\n+            logWarning(e.getMessage, e)",
    "line": 56
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "That's correct.\r\n\r\nThe reason I chose to ignore the error here is we may not have the permission to check the directory. For example, if I have some special chars in my user name such as `foo bar`. Then I try to write into my home directory `/user/foo bar/a/b/c` in **Spark 3.0.0**, it's likely I don't have access to `/user/foo%20bar/a/b/c` since that's in a different user home directory. Since checking the directory should be best effort and should not impact any users that don't hit this path issue, I prefer to ignore the error for safety.\r\n\r\nThis is different than `try-catch` in `hasMetadata` which is checking a sub directory in the current directory. In this case, the directory is usually accessible and the error is probably a real issue.",
    "commit": "91542ff777cd4ef213082d699ee55132c4527d35",
    "createdAt": "2019-02-12T19:31:34Z",
    "diffHunk": "@@ -37,23 +39,47 @@ object FileStreamSink extends Logging {\n    * Returns true if there is a single path that has a metadata log indicating which files should\n    * be read.\n    */\n-  def hasMetadata(path: Seq[String], hadoopConf: Configuration): Boolean = {\n+  def hasMetadata(path: Seq[String], hadoopConf: Configuration, sqlConf: SQLConf): Boolean = {\n     path match {\n       case Seq(singlePath) =>\n+        val hdfsPath = new Path(singlePath)\n+        val fs = hdfsPath.getFileSystem(hadoopConf)\n+        if (fs.isDirectory(hdfsPath)) {\n+          val metadataPath = new Path(hdfsPath, metadataDir)\n+          checkEscapedMetadataPath(fs, metadataPath, sqlConf)\n+          fs.exists(metadataPath)\n+        } else {\n+          false\n+        }\n+      case _ => false\n+    }\n+  }\n+\n+  def checkEscapedMetadataPath(fs: FileSystem, metadataPath: Path, sqlConf: SQLConf): Unit = {\n+    if (sqlConf.getConf(SQLConf.STREAMING_CHECKPOINT_ESCAPED_PATH_CHECK_ENABLED)\n+        && StreamExecution.containsSpecialCharsInPath(metadataPath)) {\n+      val legacyMetadataPath = new Path(metadataPath.toUri.toString)\n+      val legacyMetadataPathExists =\n         try {\n-          val hdfsPath = new Path(singlePath)\n-          val fs = hdfsPath.getFileSystem(hadoopConf)\n-          if (fs.isDirectory(hdfsPath)) {\n-            fs.exists(new Path(hdfsPath, metadataDir))\n-          } else {\n-            false\n-          }\n+          fs.exists(legacyMetadataPath)\n         } catch {\n           case NonFatal(e) =>\n-            logWarning(s\"Error while looking for metadata directory.\")\n+            // We may not have access to this directory. Don't fail the query if that happens.\n+            logWarning(e.getMessage, e)",
    "line": 56
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "That's a good edge case which I've not considered. I think user with name `foo%20bar` or something similar which contains escaped URI parts is junk which may highlight error in some application code. Wouldn't it be better to let the user decide what to do? For example:\r\n* delete/move the dir\r\n* add right to read\r\n* ignore the escaped path check with the added config\r\n",
    "commit": "91542ff777cd4ef213082d699ee55132c4527d35",
    "createdAt": "2019-02-13T12:19:59Z",
    "diffHunk": "@@ -37,23 +39,47 @@ object FileStreamSink extends Logging {\n    * Returns true if there is a single path that has a metadata log indicating which files should\n    * be read.\n    */\n-  def hasMetadata(path: Seq[String], hadoopConf: Configuration): Boolean = {\n+  def hasMetadata(path: Seq[String], hadoopConf: Configuration, sqlConf: SQLConf): Boolean = {\n     path match {\n       case Seq(singlePath) =>\n+        val hdfsPath = new Path(singlePath)\n+        val fs = hdfsPath.getFileSystem(hadoopConf)\n+        if (fs.isDirectory(hdfsPath)) {\n+          val metadataPath = new Path(hdfsPath, metadataDir)\n+          checkEscapedMetadataPath(fs, metadataPath, sqlConf)\n+          fs.exists(metadataPath)\n+        } else {\n+          false\n+        }\n+      case _ => false\n+    }\n+  }\n+\n+  def checkEscapedMetadataPath(fs: FileSystem, metadataPath: Path, sqlConf: SQLConf): Unit = {\n+    if (sqlConf.getConf(SQLConf.STREAMING_CHECKPOINT_ESCAPED_PATH_CHECK_ENABLED)\n+        && StreamExecution.containsSpecialCharsInPath(metadataPath)) {\n+      val legacyMetadataPath = new Path(metadataPath.toUri.toString)\n+      val legacyMetadataPathExists =\n         try {\n-          val hdfsPath = new Path(singlePath)\n-          val fs = hdfsPath.getFileSystem(hadoopConf)\n-          if (fs.isDirectory(hdfsPath)) {\n-            fs.exists(new Path(hdfsPath, metadataDir))\n-          } else {\n-            false\n-          }\n+          fs.exists(legacyMetadataPath)\n         } catch {\n           case NonFatal(e) =>\n-            logWarning(s\"Error while looking for metadata directory.\")\n+            // We may not have access to this directory. Don't fail the query if that happens.\n+            logWarning(e.getMessage, e)",
    "line": 56
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "@gaborgsomogyi Making this check best effort is safer. I don't want to force people that don't hit this issue to use the config until we remove this check in future.",
    "commit": "91542ff777cd4ef213082d699ee55132c4527d35",
    "createdAt": "2019-02-19T19:22:29Z",
    "diffHunk": "@@ -37,23 +39,47 @@ object FileStreamSink extends Logging {\n    * Returns true if there is a single path that has a metadata log indicating which files should\n    * be read.\n    */\n-  def hasMetadata(path: Seq[String], hadoopConf: Configuration): Boolean = {\n+  def hasMetadata(path: Seq[String], hadoopConf: Configuration, sqlConf: SQLConf): Boolean = {\n     path match {\n       case Seq(singlePath) =>\n+        val hdfsPath = new Path(singlePath)\n+        val fs = hdfsPath.getFileSystem(hadoopConf)\n+        if (fs.isDirectory(hdfsPath)) {\n+          val metadataPath = new Path(hdfsPath, metadataDir)\n+          checkEscapedMetadataPath(fs, metadataPath, sqlConf)\n+          fs.exists(metadataPath)\n+        } else {\n+          false\n+        }\n+      case _ => false\n+    }\n+  }\n+\n+  def checkEscapedMetadataPath(fs: FileSystem, metadataPath: Path, sqlConf: SQLConf): Unit = {\n+    if (sqlConf.getConf(SQLConf.STREAMING_CHECKPOINT_ESCAPED_PATH_CHECK_ENABLED)\n+        && StreamExecution.containsSpecialCharsInPath(metadataPath)) {\n+      val legacyMetadataPath = new Path(metadataPath.toUri.toString)\n+      val legacyMetadataPathExists =\n         try {\n-          val hdfsPath = new Path(singlePath)\n-          val fs = hdfsPath.getFileSystem(hadoopConf)\n-          if (fs.isDirectory(hdfsPath)) {\n-            fs.exists(new Path(hdfsPath, metadataDir))\n-          } else {\n-            false\n-          }\n+          fs.exists(legacyMetadataPath)\n         } catch {\n           case NonFatal(e) =>\n-            logWarning(s\"Error while looking for metadata directory.\")\n+            // We may not have access to this directory. Don't fail the query if that happens.\n+            logWarning(e.getMessage, e)",
    "line": 56
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "@gaborgsomogyi By the way, the user name may be weird. Another more possible permission error case is an admin can set a S3 bucket to allow Spark accessing only paths matching some specified patterns, and a Spark user may not be able to change this.",
    "commit": "91542ff777cd4ef213082d699ee55132c4527d35",
    "createdAt": "2019-02-19T19:26:41Z",
    "diffHunk": "@@ -37,23 +39,47 @@ object FileStreamSink extends Logging {\n    * Returns true if there is a single path that has a metadata log indicating which files should\n    * be read.\n    */\n-  def hasMetadata(path: Seq[String], hadoopConf: Configuration): Boolean = {\n+  def hasMetadata(path: Seq[String], hadoopConf: Configuration, sqlConf: SQLConf): Boolean = {\n     path match {\n       case Seq(singlePath) =>\n+        val hdfsPath = new Path(singlePath)\n+        val fs = hdfsPath.getFileSystem(hadoopConf)\n+        if (fs.isDirectory(hdfsPath)) {\n+          val metadataPath = new Path(hdfsPath, metadataDir)\n+          checkEscapedMetadataPath(fs, metadataPath, sqlConf)\n+          fs.exists(metadataPath)\n+        } else {\n+          false\n+        }\n+      case _ => false\n+    }\n+  }\n+\n+  def checkEscapedMetadataPath(fs: FileSystem, metadataPath: Path, sqlConf: SQLConf): Unit = {\n+    if (sqlConf.getConf(SQLConf.STREAMING_CHECKPOINT_ESCAPED_PATH_CHECK_ENABLED)\n+        && StreamExecution.containsSpecialCharsInPath(metadataPath)) {\n+      val legacyMetadataPath = new Path(metadataPath.toUri.toString)\n+      val legacyMetadataPathExists =\n         try {\n-          val hdfsPath = new Path(singlePath)\n-          val fs = hdfsPath.getFileSystem(hadoopConf)\n-          if (fs.isDirectory(hdfsPath)) {\n-            fs.exists(new Path(hdfsPath, metadataDir))\n-          } else {\n-            false\n-          }\n+          fs.exists(legacyMetadataPath)\n         } catch {\n           case NonFatal(e) =>\n-            logWarning(s\"Error while looking for metadata directory.\")\n+            // We may not have access to this directory. Don't fail the query if that happens.\n+            logWarning(e.getMessage, e)",
    "line": 56
  }],
  "prId": 23733
}]