[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: extra line\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-28T20:19:57Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+\n+import java.io.{InputStream, OutputStream}\n+import java.nio.charset.StandardCharsets._\n+\n+import scala.io.{Source => IOSource}\n+\n+import org.json4s.NoTypeHints\n+import org.json4s.jackson.Serialization\n+\n+import org.apache.spark.sql.SparkSession\n+\n+class OffsetSeqLog(offsetLogVersion: String, sparkSession: SparkSession, path: String)\n+  extends HDFSMetadataLog[OffsetSeq](sparkSession, path) {\n+\n+  override protected def deserialize(in: InputStream): OffsetSeq = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+\n+    val lines = IOSource.fromInputStream(in, UTF_8.name()).getLines()\n+    if (!lines.hasNext) {\n+      throw new IllegalStateException(\"Incomplete log file\")\n+    }\n+    val version = lines.next()\n+    if (version != offsetLogVersion) {\n+      throw new IllegalStateException(s\"Unknown log version: ${version}\")\n+    }\n+    OffsetSeq.fill(lines.map(offset => SerializedOffset(offset)).toArray: _*)\n+  }\n+\n+  override protected def serialize(metadata: OffsetSeq, out: OutputStream): Unit = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+"
  }, {
    "author": {
      "login": "tcondie"
    },
    "body": "right.\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-28T21:44:22Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+\n+import java.io.{InputStream, OutputStream}\n+import java.nio.charset.StandardCharsets._\n+\n+import scala.io.{Source => IOSource}\n+\n+import org.json4s.NoTypeHints\n+import org.json4s.jackson.Serialization\n+\n+import org.apache.spark.sql.SparkSession\n+\n+class OffsetSeqLog(offsetLogVersion: String, sparkSession: SparkSession, path: String)\n+  extends HDFSMetadataLog[OffsetSeq](sparkSession, path) {\n+\n+  override protected def deserialize(in: InputStream): OffsetSeq = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+\n+    val lines = IOSource.fromInputStream(in, UTF_8.name()).getLines()\n+    if (!lines.hasNext) {\n+      throw new IllegalStateException(\"Incomplete log file\")\n+    }\n+    val version = lines.next()\n+    if (version != offsetLogVersion) {\n+      throw new IllegalStateException(s\"Unknown log version: ${version}\")\n+    }\n+    OffsetSeq.fill(lines.map(offset => SerializedOffset(offset)).toArray: _*)\n+  }\n+\n+  override protected def serialize(metadata: OffsetSeq, out: OutputStream): Unit = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+"
  }],
  "prId": 15626
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: extra line.\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-28T20:20:26Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+\n+import java.io.{InputStream, OutputStream}\n+import java.nio.charset.StandardCharsets._\n+\n+import scala.io.{Source => IOSource}\n+\n+import org.json4s.NoTypeHints\n+import org.json4s.jackson.Serialization\n+\n+import org.apache.spark.sql.SparkSession\n+\n+class OffsetSeqLog(offsetLogVersion: String, sparkSession: SparkSession, path: String)\n+  extends HDFSMetadataLog[OffsetSeq](sparkSession, path) {\n+\n+  override protected def deserialize(in: InputStream): OffsetSeq = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+"
  }, {
    "author": {
      "login": "tcondie"
    },
    "body": "right.\n",
    "commit": "dabb628d0f39aeea94fd1afbad816b856b0a0eae",
    "createdAt": "2016-10-28T21:44:27Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.execution.streaming\n+\n+\n+import java.io.{InputStream, OutputStream}\n+import java.nio.charset.StandardCharsets._\n+\n+import scala.io.{Source => IOSource}\n+\n+import org.json4s.NoTypeHints\n+import org.json4s.jackson.Serialization\n+\n+import org.apache.spark.sql.SparkSession\n+\n+class OffsetSeqLog(offsetLogVersion: String, sparkSession: SparkSession, path: String)\n+  extends HDFSMetadataLog[OffsetSeq](sparkSession, path) {\n+\n+  override protected def deserialize(in: InputStream): OffsetSeq = {\n+    // called inside a try-finally where the underlying stream is closed in the caller\n+"
  }],
  "prId": 15626
}]