[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "This implementation triggers multiple jobs. I'm thinking about the following approach:\n1. get distinct values from col2 and create a value-to-index map\n2. aggregate by col1. for each value in col1, generate a Row object and fill in counts\n3. assign table schema\n",
    "commit": "a07c01e07f17935f3729185f6be507971b4a4561",
    "createdAt": "2015-05-01T19:47:12Z",
    "diffHunk": "@@ -0,0 +1,38 @@\n+package org.apache.spark.sql.execution.stat\n+\n+import org.apache.spark.sql.{Row, DataFrame}\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.types._\n+import org.apache.spark.sql.functions._\n+\n+\n+private[sql] object ContingencyTable {\n+\n+  /** Generate a table of frequencies for the elements of two columns. */\n+  private[sql] def crossTabulate(df: DataFrame, col1: String, col2: String): DataFrame = {\n+    val tableName = s\"${col1}_$col2\"\n+    val distinctVals = df.select(countDistinct(col1), countDistinct(col2)).collect().head"
  }],
  "prId": 5842
}]