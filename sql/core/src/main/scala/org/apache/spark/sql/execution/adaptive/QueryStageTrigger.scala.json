[{
  "comments": [{
    "author": {
      "login": "justinuang"
    },
    "body": "We found when applying this to our fork that we needed to preserve all local properties since we are now changing the threading model.\r\n\r\nhttps://github.com/palantir/spark/pull/443/commits/f477a242d00c5ddcea5c5d29eb3c6926d2bff3a0",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-29T21:08:28Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import scala.collection.mutable.{HashMap, HashSet, ListBuffer}\n+import scala.concurrent.{ExecutionContext, ExecutionContextExecutorService, Future}\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.util.{EventLoop, ThreadUtils}\n+\n+/**\n+ * This class triggers [[QueryStage]] bottom-up, apply planner rules for query stages and\n+ * materialize them. It triggers as many query stages as possible at the same time, and triggers\n+ * the parent query stage when all its child stages are materialized.\n+ */\n+class QueryStageTrigger(session: SparkSession, callback: QueryStageTriggerCallback)\n+  extends EventLoop[QueryStageTriggerEvent](\"QueryStageTrigger\") {\n+\n+  private val stageToParentStages = HashMap.empty[Int, ListBuffer[QueryStage]]\n+\n+  private val idToUpdatedStage = HashMap.empty[Int, QueryStage]\n+\n+  private val stageToNumPendingChildStages = HashMap.empty[Int, Int]\n+\n+  private val submittedStages = HashSet.empty[Int]\n+\n+  private val readyStages = HashSet.empty[Int]\n+\n+  private val planner = new QueryStagePlanner(session.sessionState.conf)\n+\n+  def trigger(stage: QueryStage): Unit = {\n+    post(SubmitStage(stage))\n+  }\n+\n+  private implicit def executionContext: ExecutionContextExecutorService = {\n+    QueryStageTrigger.executionContext\n+  }\n+\n+  override protected def onReceive(event: QueryStageTriggerEvent): Unit = event match {\n+    case SubmitStage(stage) =>\n+      // We may submit a query stage multiple times, because of stage reuse. Here we avoid\n+      // re-submitting a query stage.\n+      if (!submittedStages.contains(stage.id)) {\n+        submittedStages += stage.id\n+        val pendingChildStages = stage.plan.collect {\n+          // The stage being submitted may have child stages that are already ready, if the child\n+          // stage is a reused stage.\n+          case stage: QueryStage if !readyStages.contains(stage.id) => stage\n+        }\n+        if (pendingChildStages.isEmpty) {\n+          // This is a leaf stage, or all its child stages are ready, we can plan it now.\n+          post(PlanStage(stage))\n+        } else {\n+          // This stage has some pending child stages, we store the connection of this stage and\n+          // its child stages, and submit all the child stages, so that we can plan this stage\n+          // later when all its child stages are ready.\n+          stageToNumPendingChildStages(stage.id) = pendingChildStages.length\n+          pendingChildStages.foreach { child =>\n+            // a child may have multiple parents, because of query stage reuse.\n+            val parentStages = stageToParentStages.getOrElseUpdate(child.id, new ListBuffer)\n+            parentStages += stage\n+            post(SubmitStage(child))\n+          }\n+        }\n+      }\n+\n+    case PlanStage(stage) =>\n+      Future {"
  }, {
    "author": {
      "login": "carsonwang"
    },
    "body": "Thanks @justinuang , yes we need preserve the local properties in the new thread.",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-30T05:59:42Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import scala.collection.mutable.{HashMap, HashSet, ListBuffer}\n+import scala.concurrent.{ExecutionContext, ExecutionContextExecutorService, Future}\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.util.{EventLoop, ThreadUtils}\n+\n+/**\n+ * This class triggers [[QueryStage]] bottom-up, apply planner rules for query stages and\n+ * materialize them. It triggers as many query stages as possible at the same time, and triggers\n+ * the parent query stage when all its child stages are materialized.\n+ */\n+class QueryStageTrigger(session: SparkSession, callback: QueryStageTriggerCallback)\n+  extends EventLoop[QueryStageTriggerEvent](\"QueryStageTrigger\") {\n+\n+  private val stageToParentStages = HashMap.empty[Int, ListBuffer[QueryStage]]\n+\n+  private val idToUpdatedStage = HashMap.empty[Int, QueryStage]\n+\n+  private val stageToNumPendingChildStages = HashMap.empty[Int, Int]\n+\n+  private val submittedStages = HashSet.empty[Int]\n+\n+  private val readyStages = HashSet.empty[Int]\n+\n+  private val planner = new QueryStagePlanner(session.sessionState.conf)\n+\n+  def trigger(stage: QueryStage): Unit = {\n+    post(SubmitStage(stage))\n+  }\n+\n+  private implicit def executionContext: ExecutionContextExecutorService = {\n+    QueryStageTrigger.executionContext\n+  }\n+\n+  override protected def onReceive(event: QueryStageTriggerEvent): Unit = event match {\n+    case SubmitStage(stage) =>\n+      // We may submit a query stage multiple times, because of stage reuse. Here we avoid\n+      // re-submitting a query stage.\n+      if (!submittedStages.contains(stage.id)) {\n+        submittedStages += stage.id\n+        val pendingChildStages = stage.plan.collect {\n+          // The stage being submitted may have child stages that are already ready, if the child\n+          // stage is a reused stage.\n+          case stage: QueryStage if !readyStages.contains(stage.id) => stage\n+        }\n+        if (pendingChildStages.isEmpty) {\n+          // This is a leaf stage, or all its child stages are ready, we can plan it now.\n+          post(PlanStage(stage))\n+        } else {\n+          // This stage has some pending child stages, we store the connection of this stage and\n+          // its child stages, and submit all the child stages, so that we can plan this stage\n+          // later when all its child stages are ready.\n+          stageToNumPendingChildStages(stage.id) = pendingChildStages.length\n+          pendingChildStages.foreach { child =>\n+            // a child may have multiple parents, because of query stage reuse.\n+            val parentStages = stageToParentStages.getOrElseUpdate(child.id, new ListBuffer)\n+            parentStages += stage\n+            post(SubmitStage(child))\n+          }\n+        }\n+      }\n+\n+    case PlanStage(stage) =>\n+      Future {"
  }],
  "prId": 20303
}, {
  "comments": [{
    "author": {
      "login": "JkSelf"
    },
    "body": "Here the same query stage may be executed more than once when multi threads concurrency, for example the subqueries reuse. ",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-01-30T07:31:18Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import scala.collection.mutable.{HashMap, HashSet, ListBuffer}\n+import scala.concurrent.{ExecutionContext, ExecutionContextExecutorService, Future}\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.util.{EventLoop, ThreadUtils}\n+\n+/**\n+ * This class triggers [[QueryStage]] bottom-up, apply planner rules for query stages and\n+ * materialize them. It triggers as many query stages as possible at the same time, and triggers\n+ * the parent query stage when all its child stages are materialized.\n+ */\n+class QueryStageTrigger(session: SparkSession, callback: QueryStageTriggerCallback)\n+  extends EventLoop[QueryStageTriggerEvent](\"QueryStageTrigger\") {\n+\n+  private val stageToParentStages = HashMap.empty[Int, ListBuffer[QueryStage]]\n+\n+  private val idToUpdatedStage = HashMap.empty[Int, QueryStage]\n+\n+  private val stageToNumPendingChildStages = HashMap.empty[Int, Int]\n+\n+  private val submittedStages = HashSet.empty[Int]\n+\n+  private val readyStages = HashSet.empty[Int]\n+\n+  private val planner = new QueryStagePlanner(session.sessionState.conf)\n+\n+  def trigger(stage: QueryStage): Unit = {\n+    post(SubmitStage(stage))\n+  }\n+\n+  private implicit def executionContext: ExecutionContextExecutorService = {\n+    QueryStageTrigger.executionContext\n+  }\n+\n+  override protected def onReceive(event: QueryStageTriggerEvent): Unit = event match {\n+    case SubmitStage(stage) =>\n+      // We may submit a query stage multiple times, because of stage reuse. Here we avoid\n+      // re-submitting a query stage.\n+      if (!submittedStages.contains(stage.id)) {"
  }, {
    "author": {
      "login": "carsonwang"
    },
    "body": "@JkSelf , in the new code, only one `MaterializeStage` message will be sent for a single query stage. can you please take a look and feedback if you still see an issue?",
    "commit": "2e087785d754dfabc84b333fffcf98c39d2fd497",
    "createdAt": "2019-02-01T07:12:23Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.adaptive\n+\n+import scala.collection.mutable.{HashMap, HashSet, ListBuffer}\n+import scala.concurrent.{ExecutionContext, ExecutionContextExecutorService, Future}\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.execution.SparkPlan\n+import org.apache.spark.util.{EventLoop, ThreadUtils}\n+\n+/**\n+ * This class triggers [[QueryStage]] bottom-up, apply planner rules for query stages and\n+ * materialize them. It triggers as many query stages as possible at the same time, and triggers\n+ * the parent query stage when all its child stages are materialized.\n+ */\n+class QueryStageTrigger(session: SparkSession, callback: QueryStageTriggerCallback)\n+  extends EventLoop[QueryStageTriggerEvent](\"QueryStageTrigger\") {\n+\n+  private val stageToParentStages = HashMap.empty[Int, ListBuffer[QueryStage]]\n+\n+  private val idToUpdatedStage = HashMap.empty[Int, QueryStage]\n+\n+  private val stageToNumPendingChildStages = HashMap.empty[Int, Int]\n+\n+  private val submittedStages = HashSet.empty[Int]\n+\n+  private val readyStages = HashSet.empty[Int]\n+\n+  private val planner = new QueryStagePlanner(session.sessionState.conf)\n+\n+  def trigger(stage: QueryStage): Unit = {\n+    post(SubmitStage(stage))\n+  }\n+\n+  private implicit def executionContext: ExecutionContextExecutorService = {\n+    QueryStageTrigger.executionContext\n+  }\n+\n+  override protected def onReceive(event: QueryStageTriggerEvent): Unit = event match {\n+    case SubmitStage(stage) =>\n+      // We may submit a query stage multiple times, because of stage reuse. Here we avoid\n+      // re-submitting a query stage.\n+      if (!submittedStages.contains(stage.id)) {"
  }],
  "prId": 20303
}]