[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "I don't know why this method is public at the first place... I have to break it here.\r\n\r\n",
    "commit": "c42b4999d79447d12f9bd751e13a1083dd451648",
    "createdAt": "2018-10-08T17:35:37Z",
    "diffHunk": "@@ -75,95 +76,70 @@ trait QueryExecutionListener {\n  */\n @Experimental\n @InterfaceStability.Evolving\n-class ExecutionListenerManager private extends Logging {\n+class ExecutionListenerManager private[sql](session: SparkSession, loadExtensions: Boolean)\n+  extends SparkListener with Logging {\n \n-  private[sql] def this(conf: SparkConf) = {\n-    this()\n+  private[this] val listeners = new CopyOnWriteArrayList[QueryExecutionListener]\n+\n+  if (loadExtensions) {\n+    val conf = session.sparkContext.conf\n     conf.get(QUERY_EXECUTION_LISTENERS).foreach { classNames =>\n       Utils.loadExtensions(classOf[QueryExecutionListener], classNames, conf).foreach(register)\n     }\n   }\n \n+  session.sparkContext.listenerBus.addToSharedQueue(this)\n+\n   /**\n    * Registers the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def register(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners += listener\n+  def register(listener: QueryExecutionListener): Unit = {\n+    listeners.add(listener)\n   }\n \n   /**\n    * Unregisters the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def unregister(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners -= listener\n+  def unregister(listener: QueryExecutionListener): Unit = {\n+    listeners.remove(listener)\n   }\n \n   /**\n    * Removes all the registered [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def clear(): Unit = writeLock {\n+  def clear(): Unit = {\n     listeners.clear()\n   }\n \n   /**\n    * Get an identical copy of this listener manager.\n    */\n   @DeveloperApi\n-  override def clone(): ExecutionListenerManager = writeLock {\n-    val newListenerManager = new ExecutionListenerManager\n-    listeners.foreach(newListenerManager.register)\n+  def clone(session: SparkSession): ExecutionListenerManager = {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Could you add MiMa exclusion rule?",
    "commit": "c42b4999d79447d12f9bd751e13a1083dd451648",
    "createdAt": "2018-10-08T17:58:58Z",
    "diffHunk": "@@ -75,95 +76,70 @@ trait QueryExecutionListener {\n  */\n @Experimental\n @InterfaceStability.Evolving\n-class ExecutionListenerManager private extends Logging {\n+class ExecutionListenerManager private[sql](session: SparkSession, loadExtensions: Boolean)\n+  extends SparkListener with Logging {\n \n-  private[sql] def this(conf: SparkConf) = {\n-    this()\n+  private[this] val listeners = new CopyOnWriteArrayList[QueryExecutionListener]\n+\n+  if (loadExtensions) {\n+    val conf = session.sparkContext.conf\n     conf.get(QUERY_EXECUTION_LISTENERS).foreach { classNames =>\n       Utils.loadExtensions(classOf[QueryExecutionListener], classNames, conf).foreach(register)\n     }\n   }\n \n+  session.sparkContext.listenerBus.addToSharedQueue(this)\n+\n   /**\n    * Registers the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def register(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners += listener\n+  def register(listener: QueryExecutionListener): Unit = {\n+    listeners.add(listener)\n   }\n \n   /**\n    * Unregisters the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def unregister(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners -= listener\n+  def unregister(listener: QueryExecutionListener): Unit = {\n+    listeners.remove(listener)\n   }\n \n   /**\n    * Removes all the registered [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def clear(): Unit = writeLock {\n+  def clear(): Unit = {\n     listeners.clear()\n   }\n \n   /**\n    * Get an identical copy of this listener manager.\n    */\n   @DeveloperApi\n-  override def clone(): ExecutionListenerManager = writeLock {\n-    val newListenerManager = new ExecutionListenerManager\n-    listeners.foreach(newListenerManager.register)\n+  def clone(session: SparkSession): ExecutionListenerManager = {"
  }],
  "prId": 22674
}, {
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "nit: we shall add param comments.",
    "commit": "c42b4999d79447d12f9bd751e13a1083dd451648",
    "createdAt": "2018-10-09T14:37:25Z",
    "diffHunk": "@@ -75,95 +76,69 @@ trait QueryExecutionListener {\n  */\n @Experimental\n @InterfaceStability.Evolving\n-class ExecutionListenerManager private extends Logging {\n+class ExecutionListenerManager private[sql](session: SparkSession, loadExtensions: Boolean)",
    "line": 36
  }],
  "prId": 22674
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Why is this not a class doc?",
    "commit": "c42b4999d79447d12f9bd751e13a1083dd451648",
    "createdAt": "2018-10-09T21:41:26Z",
    "diffHunk": "@@ -75,95 +76,74 @@ trait QueryExecutionListener {\n  */\n @Experimental\n @InterfaceStability.Evolving\n-class ExecutionListenerManager private extends Logging {\n-\n-  private[sql] def this(conf: SparkConf) = {\n-    this()\n+// The `session` is used to indicate which session carries this listener manager, and we only",
    "line": 31
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "The constructor is private, so we should not make it visible in the class doc",
    "commit": "c42b4999d79447d12f9bd751e13a1083dd451648",
    "createdAt": "2018-10-10T01:05:52Z",
    "diffHunk": "@@ -75,95 +76,74 @@ trait QueryExecutionListener {\n  */\n @Experimental\n @InterfaceStability.Evolving\n-class ExecutionListenerManager private extends Logging {\n-\n-  private[sql] def this(conf: SparkConf) = {\n-    this()\n+// The `session` is used to indicate which session carries this listener manager, and we only",
    "line": 31
  }],
  "prId": 22674
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "So this is what bugs me. You are adding separation between the SparkSession and its listeners, to undo that here. It seems like a bit of a hassle to go through because you basically need async execution.\r\n",
    "commit": "c42b4999d79447d12f9bd751e13a1083dd451648",
    "createdAt": "2018-10-09T22:33:04Z",
    "diffHunk": "@@ -75,95 +76,74 @@ trait QueryExecutionListener {\n  */\n @Experimental\n @InterfaceStability.Evolving\n-class ExecutionListenerManager private extends Logging {\n-\n-  private[sql] def this(conf: SparkConf) = {\n-    this()\n+// The `session` is used to indicate which session carries this listener manager, and we only\n+// catch SQL executions which are launched by the same session.\n+// The `loadExtensions` flag is used to indicate whether we should load the pre-defined,\n+// user-specified listeners during construction. We should not do it when cloning this listener\n+// manager, as we will copy all listeners to the cloned listener manager.\n+class ExecutionListenerManager private[sql](session: SparkSession, loadExtensions: Boolean)\n+  extends SparkListener with Logging {\n+\n+  private[this] val listeners = new CopyOnWriteArrayList[QueryExecutionListener]\n+\n+  if (loadExtensions) {\n+    val conf = session.sparkContext.conf\n     conf.get(QUERY_EXECUTION_LISTENERS).foreach { classNames =>\n       Utils.loadExtensions(classOf[QueryExecutionListener], classNames, conf).foreach(register)\n     }\n   }\n \n+  session.sparkContext.listenerBus.addToSharedQueue(this)\n+\n   /**\n    * Registers the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def register(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners += listener\n+  def register(listener: QueryExecutionListener): Unit = {\n+    listeners.add(listener)\n   }\n \n   /**\n    * Unregisters the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def unregister(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners -= listener\n+  def unregister(listener: QueryExecutionListener): Unit = {\n+    listeners.remove(listener)\n   }\n \n   /**\n    * Removes all the registered [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def clear(): Unit = writeLock {\n+  def clear(): Unit = {\n     listeners.clear()\n   }\n \n   /**\n    * Get an identical copy of this listener manager.\n    */\n-  @DeveloperApi\n-  override def clone(): ExecutionListenerManager = writeLock {\n-    val newListenerManager = new ExecutionListenerManager\n-    listeners.foreach(newListenerManager.register)\n+  private[sql] def clone(session: SparkSession): ExecutionListenerManager = {\n+    val newListenerManager = new ExecutionListenerManager(session, loadExtensions = false)\n+    listeners.iterator().asScala.foreach(newListenerManager.register)\n     newListenerManager\n   }\n \n-  private[sql] def onSuccess(funcName: String, qe: QueryExecution, duration: Long): Unit = {\n-    readLock {\n-      withErrorHandling { listener =>\n-        listener.onSuccess(funcName, qe, duration)\n+  override def onOtherEvent(event: SparkListenerEvent): Unit = event match {\n+    case e: SparkListenerSQLExecutionEnd if shouldCatchEvent(e) =>\n+      val funcName = e.executionName.get\n+      e.executionFailure match {\n+        case Some(ex) =>\n+          listeners.iterator().asScala.foreach(_.onFailure(funcName, e.qe, ex))\n+        case _ =>\n+          listeners.iterator().asScala.foreach(_.onSuccess(funcName, e.qe, e.duration))\n       }\n-    }\n-  }\n \n-  private[sql] def onFailure(funcName: String, qe: QueryExecution, exception: Exception): Unit = {\n-    readLock {\n-      withErrorHandling { listener =>\n-        listener.onFailure(funcName, qe, exception)\n-      }\n-    }\n+    case _ => // Ignore\n   }\n \n-  private[this] val listeners = ListBuffer.empty[QueryExecutionListener]\n-\n-  /** A lock to prevent updating the list of listeners while we are traversing through them. */\n-  private[this] val lock = new ReentrantReadWriteLock()\n-\n-  private def withErrorHandling(f: QueryExecutionListener => Unit): Unit = {\n-    for (listener <- listeners) {\n-      try {\n-        f(listener)\n-      } catch {\n-        case NonFatal(e) => logWarning(\"Error executing query execution listener\", e)\n-      }\n-    }\n-  }\n-\n-  /** Acquires a read lock on the cache for the duration of `f`. */\n-  private def readLock[A](f: => A): A = {\n-    val rl = lock.readLock()\n-    rl.lock()\n-    try f finally {\n-      rl.unlock()\n-    }\n-  }\n-\n-  /** Acquires a write lock on the cache for the duration of `f`. */\n-  private def writeLock[A](f: => A): A = {\n-    val wl = lock.writeLock()\n-    wl.lock()\n-    try f finally {\n-      wl.unlock()\n-    }\n+  private def shouldCatchEvent(e: SparkListenerSQLExecutionEnd): Boolean = {\n+    // Only catch SQL execution with a name, and triggered by the same spark session that this",
    "line": 155
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "yea. Assuming we have many spark sessions, running queries at the same time. Each session sends query execution events to the central event bus, and sets up a listener to watch its own query execution events, asynchronously.\r\n\r\nTo make it work, the most straightforward way is to carry the session identifier in the events, and the listener only watch events with the expected session identifier.\r\n\r\nMaybe a better way is to introduce session in the Spark core, so the listener framework can dispatch events w.r.t. session automatically. But that's a lot of work.",
    "commit": "c42b4999d79447d12f9bd751e13a1083dd451648",
    "createdAt": "2018-10-10T01:15:04Z",
    "diffHunk": "@@ -75,95 +76,74 @@ trait QueryExecutionListener {\n  */\n @Experimental\n @InterfaceStability.Evolving\n-class ExecutionListenerManager private extends Logging {\n-\n-  private[sql] def this(conf: SparkConf) = {\n-    this()\n+// The `session` is used to indicate which session carries this listener manager, and we only\n+// catch SQL executions which are launched by the same session.\n+// The `loadExtensions` flag is used to indicate whether we should load the pre-defined,\n+// user-specified listeners during construction. We should not do it when cloning this listener\n+// manager, as we will copy all listeners to the cloned listener manager.\n+class ExecutionListenerManager private[sql](session: SparkSession, loadExtensions: Boolean)\n+  extends SparkListener with Logging {\n+\n+  private[this] val listeners = new CopyOnWriteArrayList[QueryExecutionListener]\n+\n+  if (loadExtensions) {\n+    val conf = session.sparkContext.conf\n     conf.get(QUERY_EXECUTION_LISTENERS).foreach { classNames =>\n       Utils.loadExtensions(classOf[QueryExecutionListener], classNames, conf).foreach(register)\n     }\n   }\n \n+  session.sparkContext.listenerBus.addToSharedQueue(this)\n+\n   /**\n    * Registers the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def register(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners += listener\n+  def register(listener: QueryExecutionListener): Unit = {\n+    listeners.add(listener)\n   }\n \n   /**\n    * Unregisters the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def unregister(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners -= listener\n+  def unregister(listener: QueryExecutionListener): Unit = {\n+    listeners.remove(listener)\n   }\n \n   /**\n    * Removes all the registered [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def clear(): Unit = writeLock {\n+  def clear(): Unit = {\n     listeners.clear()\n   }\n \n   /**\n    * Get an identical copy of this listener manager.\n    */\n-  @DeveloperApi\n-  override def clone(): ExecutionListenerManager = writeLock {\n-    val newListenerManager = new ExecutionListenerManager\n-    listeners.foreach(newListenerManager.register)\n+  private[sql] def clone(session: SparkSession): ExecutionListenerManager = {\n+    val newListenerManager = new ExecutionListenerManager(session, loadExtensions = false)\n+    listeners.iterator().asScala.foreach(newListenerManager.register)\n     newListenerManager\n   }\n \n-  private[sql] def onSuccess(funcName: String, qe: QueryExecution, duration: Long): Unit = {\n-    readLock {\n-      withErrorHandling { listener =>\n-        listener.onSuccess(funcName, qe, duration)\n+  override def onOtherEvent(event: SparkListenerEvent): Unit = event match {\n+    case e: SparkListenerSQLExecutionEnd if shouldCatchEvent(e) =>\n+      val funcName = e.executionName.get\n+      e.executionFailure match {\n+        case Some(ex) =>\n+          listeners.iterator().asScala.foreach(_.onFailure(funcName, e.qe, ex))\n+        case _ =>\n+          listeners.iterator().asScala.foreach(_.onSuccess(funcName, e.qe, e.duration))\n       }\n-    }\n-  }\n \n-  private[sql] def onFailure(funcName: String, qe: QueryExecution, exception: Exception): Unit = {\n-    readLock {\n-      withErrorHandling { listener =>\n-        listener.onFailure(funcName, qe, exception)\n-      }\n-    }\n+    case _ => // Ignore\n   }\n \n-  private[this] val listeners = ListBuffer.empty[QueryExecutionListener]\n-\n-  /** A lock to prevent updating the list of listeners while we are traversing through them. */\n-  private[this] val lock = new ReentrantReadWriteLock()\n-\n-  private def withErrorHandling(f: QueryExecutionListener => Unit): Unit = {\n-    for (listener <- listeners) {\n-      try {\n-        f(listener)\n-      } catch {\n-        case NonFatal(e) => logWarning(\"Error executing query execution listener\", e)\n-      }\n-    }\n-  }\n-\n-  /** Acquires a read lock on the cache for the duration of `f`. */\n-  private def readLock[A](f: => A): A = {\n-    val rl = lock.readLock()\n-    rl.lock()\n-    try f finally {\n-      rl.unlock()\n-    }\n-  }\n-\n-  /** Acquires a write lock on the cache for the duration of `f`. */\n-  private def writeLock[A](f: => A): A = {\n-    val wl = lock.writeLock()\n-    wl.lock()\n-    try f finally {\n-      wl.unlock()\n-    }\n+  private def shouldCatchEvent(e: SparkListenerSQLExecutionEnd): Boolean = {\n+    // Only catch SQL execution with a name, and triggered by the same spark session that this",
    "line": 155
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "we had the same problem in the StreamingQueryListener. You can check how we solved it in `StreamExecution`. Since each SparkSession will have its own ExecutionListenerManager, you may be able to only have the proper ExecutionListenerManager deal with its own messages.",
    "commit": "c42b4999d79447d12f9bd751e13a1083dd451648",
    "createdAt": "2018-10-10T09:41:18Z",
    "diffHunk": "@@ -75,95 +76,74 @@ trait QueryExecutionListener {\n  */\n @Experimental\n @InterfaceStability.Evolving\n-class ExecutionListenerManager private extends Logging {\n-\n-  private[sql] def this(conf: SparkConf) = {\n-    this()\n+// The `session` is used to indicate which session carries this listener manager, and we only\n+// catch SQL executions which are launched by the same session.\n+// The `loadExtensions` flag is used to indicate whether we should load the pre-defined,\n+// user-specified listeners during construction. We should not do it when cloning this listener\n+// manager, as we will copy all listeners to the cloned listener manager.\n+class ExecutionListenerManager private[sql](session: SparkSession, loadExtensions: Boolean)\n+  extends SparkListener with Logging {\n+\n+  private[this] val listeners = new CopyOnWriteArrayList[QueryExecutionListener]\n+\n+  if (loadExtensions) {\n+    val conf = session.sparkContext.conf\n     conf.get(QUERY_EXECUTION_LISTENERS).foreach { classNames =>\n       Utils.loadExtensions(classOf[QueryExecutionListener], classNames, conf).foreach(register)\n     }\n   }\n \n+  session.sparkContext.listenerBus.addToSharedQueue(this)\n+\n   /**\n    * Registers the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def register(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners += listener\n+  def register(listener: QueryExecutionListener): Unit = {\n+    listeners.add(listener)\n   }\n \n   /**\n    * Unregisters the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def unregister(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners -= listener\n+  def unregister(listener: QueryExecutionListener): Unit = {\n+    listeners.remove(listener)\n   }\n \n   /**\n    * Removes all the registered [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def clear(): Unit = writeLock {\n+  def clear(): Unit = {\n     listeners.clear()\n   }\n \n   /**\n    * Get an identical copy of this listener manager.\n    */\n-  @DeveloperApi\n-  override def clone(): ExecutionListenerManager = writeLock {\n-    val newListenerManager = new ExecutionListenerManager\n-    listeners.foreach(newListenerManager.register)\n+  private[sql] def clone(session: SparkSession): ExecutionListenerManager = {\n+    val newListenerManager = new ExecutionListenerManager(session, loadExtensions = false)\n+    listeners.iterator().asScala.foreach(newListenerManager.register)\n     newListenerManager\n   }\n \n-  private[sql] def onSuccess(funcName: String, qe: QueryExecution, duration: Long): Unit = {\n-    readLock {\n-      withErrorHandling { listener =>\n-        listener.onSuccess(funcName, qe, duration)\n+  override def onOtherEvent(event: SparkListenerEvent): Unit = event match {\n+    case e: SparkListenerSQLExecutionEnd if shouldCatchEvent(e) =>\n+      val funcName = e.executionName.get\n+      e.executionFailure match {\n+        case Some(ex) =>\n+          listeners.iterator().asScala.foreach(_.onFailure(funcName, e.qe, ex))\n+        case _ =>\n+          listeners.iterator().asScala.foreach(_.onSuccess(funcName, e.qe, e.duration))\n       }\n-    }\n-  }\n \n-  private[sql] def onFailure(funcName: String, qe: QueryExecution, exception: Exception): Unit = {\n-    readLock {\n-      withErrorHandling { listener =>\n-        listener.onFailure(funcName, qe, exception)\n-      }\n-    }\n+    case _ => // Ignore\n   }\n \n-  private[this] val listeners = ListBuffer.empty[QueryExecutionListener]\n-\n-  /** A lock to prevent updating the list of listeners while we are traversing through them. */\n-  private[this] val lock = new ReentrantReadWriteLock()\n-\n-  private def withErrorHandling(f: QueryExecutionListener => Unit): Unit = {\n-    for (listener <- listeners) {\n-      try {\n-        f(listener)\n-      } catch {\n-        case NonFatal(e) => logWarning(\"Error executing query execution listener\", e)\n-      }\n-    }\n-  }\n-\n-  /** Acquires a read lock on the cache for the duration of `f`. */\n-  private def readLock[A](f: => A): A = {\n-    val rl = lock.readLock()\n-    rl.lock()\n-    try f finally {\n-      rl.unlock()\n-    }\n-  }\n-\n-  /** Acquires a write lock on the cache for the duration of `f`. */\n-  private def writeLock[A](f: => A): A = {\n-    val wl = lock.writeLock()\n-    wl.lock()\n-    try f finally {\n-      wl.unlock()\n-    }\n+  private def shouldCatchEvent(e: SparkListenerSQLExecutionEnd): Boolean = {\n+    // Only catch SQL execution with a name, and triggered by the same spark session that this",
    "line": 155
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "@brkyvz thanks for the information! It seems the `StreamingQueryListener` framework picks the same idea but the implementation is better. I'll update my PR accordingly.",
    "commit": "c42b4999d79447d12f9bd751e13a1083dd451648",
    "createdAt": "2018-10-10T09:57:10Z",
    "diffHunk": "@@ -75,95 +76,74 @@ trait QueryExecutionListener {\n  */\n @Experimental\n @InterfaceStability.Evolving\n-class ExecutionListenerManager private extends Logging {\n-\n-  private[sql] def this(conf: SparkConf) = {\n-    this()\n+// The `session` is used to indicate which session carries this listener manager, and we only\n+// catch SQL executions which are launched by the same session.\n+// The `loadExtensions` flag is used to indicate whether we should load the pre-defined,\n+// user-specified listeners during construction. We should not do it when cloning this listener\n+// manager, as we will copy all listeners to the cloned listener manager.\n+class ExecutionListenerManager private[sql](session: SparkSession, loadExtensions: Boolean)\n+  extends SparkListener with Logging {\n+\n+  private[this] val listeners = new CopyOnWriteArrayList[QueryExecutionListener]\n+\n+  if (loadExtensions) {\n+    val conf = session.sparkContext.conf\n     conf.get(QUERY_EXECUTION_LISTENERS).foreach { classNames =>\n       Utils.loadExtensions(classOf[QueryExecutionListener], classNames, conf).foreach(register)\n     }\n   }\n \n+  session.sparkContext.listenerBus.addToSharedQueue(this)\n+\n   /**\n    * Registers the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def register(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners += listener\n+  def register(listener: QueryExecutionListener): Unit = {\n+    listeners.add(listener)\n   }\n \n   /**\n    * Unregisters the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def unregister(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners -= listener\n+  def unregister(listener: QueryExecutionListener): Unit = {\n+    listeners.remove(listener)\n   }\n \n   /**\n    * Removes all the registered [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def clear(): Unit = writeLock {\n+  def clear(): Unit = {\n     listeners.clear()\n   }\n \n   /**\n    * Get an identical copy of this listener manager.\n    */\n-  @DeveloperApi\n-  override def clone(): ExecutionListenerManager = writeLock {\n-    val newListenerManager = new ExecutionListenerManager\n-    listeners.foreach(newListenerManager.register)\n+  private[sql] def clone(session: SparkSession): ExecutionListenerManager = {\n+    val newListenerManager = new ExecutionListenerManager(session, loadExtensions = false)\n+    listeners.iterator().asScala.foreach(newListenerManager.register)\n     newListenerManager\n   }\n \n-  private[sql] def onSuccess(funcName: String, qe: QueryExecution, duration: Long): Unit = {\n-    readLock {\n-      withErrorHandling { listener =>\n-        listener.onSuccess(funcName, qe, duration)\n+  override def onOtherEvent(event: SparkListenerEvent): Unit = event match {\n+    case e: SparkListenerSQLExecutionEnd if shouldCatchEvent(e) =>\n+      val funcName = e.executionName.get\n+      e.executionFailure match {\n+        case Some(ex) =>\n+          listeners.iterator().asScala.foreach(_.onFailure(funcName, e.qe, ex))\n+        case _ =>\n+          listeners.iterator().asScala.foreach(_.onSuccess(funcName, e.qe, e.duration))\n       }\n-    }\n-  }\n \n-  private[sql] def onFailure(funcName: String, qe: QueryExecution, exception: Exception): Unit = {\n-    readLock {\n-      withErrorHandling { listener =>\n-        listener.onFailure(funcName, qe, exception)\n-      }\n-    }\n+    case _ => // Ignore\n   }\n \n-  private[this] val listeners = ListBuffer.empty[QueryExecutionListener]\n-\n-  /** A lock to prevent updating the list of listeners while we are traversing through them. */\n-  private[this] val lock = new ReentrantReadWriteLock()\n-\n-  private def withErrorHandling(f: QueryExecutionListener => Unit): Unit = {\n-    for (listener <- listeners) {\n-      try {\n-        f(listener)\n-      } catch {\n-        case NonFatal(e) => logWarning(\"Error executing query execution listener\", e)\n-      }\n-    }\n-  }\n-\n-  /** Acquires a read lock on the cache for the duration of `f`. */\n-  private def readLock[A](f: => A): A = {\n-    val rl = lock.readLock()\n-    rl.lock()\n-    try f finally {\n-      rl.unlock()\n-    }\n-  }\n-\n-  /** Acquires a write lock on the cache for the duration of `f`. */\n-  private def writeLock[A](f: => A): A = {\n-    val wl = lock.writeLock()\n-    wl.lock()\n-    try f finally {\n-      wl.unlock()\n-    }\n+  private def shouldCatchEvent(e: SparkListenerSQLExecutionEnd): Boolean = {\n+    // Only catch SQL execution with a name, and triggered by the same spark session that this",
    "line": 155
  }],
  "prId": 22674
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "This is a bit of high level thought, you could consider making the calling event queue responsible for the dispatch of these events. That way you can leverage any improvement to the underlying event bus.",
    "commit": "c42b4999d79447d12f9bd751e13a1083dd451648",
    "createdAt": "2018-10-09T22:38:05Z",
    "diffHunk": "@@ -75,95 +76,74 @@ trait QueryExecutionListener {\n  */\n @Experimental\n @InterfaceStability.Evolving\n-class ExecutionListenerManager private extends Logging {\n-\n-  private[sql] def this(conf: SparkConf) = {\n-    this()\n+// The `session` is used to indicate which session carries this listener manager, and we only\n+// catch SQL executions which are launched by the same session.\n+// The `loadExtensions` flag is used to indicate whether we should load the pre-defined,\n+// user-specified listeners during construction. We should not do it when cloning this listener\n+// manager, as we will copy all listeners to the cloned listener manager.\n+class ExecutionListenerManager private[sql](session: SparkSession, loadExtensions: Boolean)\n+  extends SparkListener with Logging {\n+\n+  private[this] val listeners = new CopyOnWriteArrayList[QueryExecutionListener]\n+\n+  if (loadExtensions) {\n+    val conf = session.sparkContext.conf\n     conf.get(QUERY_EXECUTION_LISTENERS).foreach { classNames =>\n       Utils.loadExtensions(classOf[QueryExecutionListener], classNames, conf).foreach(register)\n     }\n   }\n \n+  session.sparkContext.listenerBus.addToSharedQueue(this)\n+\n   /**\n    * Registers the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def register(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners += listener\n+  def register(listener: QueryExecutionListener): Unit = {\n+    listeners.add(listener)\n   }\n \n   /**\n    * Unregisters the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def unregister(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners -= listener\n+  def unregister(listener: QueryExecutionListener): Unit = {\n+    listeners.remove(listener)\n   }\n \n   /**\n    * Removes all the registered [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def clear(): Unit = writeLock {\n+  def clear(): Unit = {\n     listeners.clear()\n   }\n \n   /**\n    * Get an identical copy of this listener manager.\n    */\n-  @DeveloperApi\n-  override def clone(): ExecutionListenerManager = writeLock {\n-    val newListenerManager = new ExecutionListenerManager\n-    listeners.foreach(newListenerManager.register)\n+  private[sql] def clone(session: SparkSession): ExecutionListenerManager = {\n+    val newListenerManager = new ExecutionListenerManager(session, loadExtensions = false)\n+    listeners.iterator().asScala.foreach(newListenerManager.register)\n     newListenerManager\n   }\n \n-  private[sql] def onSuccess(funcName: String, qe: QueryExecution, duration: Long): Unit = {\n-    readLock {\n-      withErrorHandling { listener =>\n-        listener.onSuccess(funcName, qe, duration)\n+  override def onOtherEvent(event: SparkListenerEvent): Unit = event match {\n+    case e: SparkListenerSQLExecutionEnd if shouldCatchEvent(e) =>\n+      val funcName = e.executionName.get\n+      e.executionFailure match {\n+        case Some(ex) =>\n+          listeners.iterator().asScala.foreach(_.onFailure(funcName, e.qe, ex))"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "`ExecutionListenerManager` is already a listener, which is running in a separated thread, receiving events from `LiveListenerBus`",
    "commit": "c42b4999d79447d12f9bd751e13a1083dd451648",
    "createdAt": "2018-10-10T01:08:47Z",
    "diffHunk": "@@ -75,95 +76,74 @@ trait QueryExecutionListener {\n  */\n @Experimental\n @InterfaceStability.Evolving\n-class ExecutionListenerManager private extends Logging {\n-\n-  private[sql] def this(conf: SparkConf) = {\n-    this()\n+// The `session` is used to indicate which session carries this listener manager, and we only\n+// catch SQL executions which are launched by the same session.\n+// The `loadExtensions` flag is used to indicate whether we should load the pre-defined,\n+// user-specified listeners during construction. We should not do it when cloning this listener\n+// manager, as we will copy all listeners to the cloned listener manager.\n+class ExecutionListenerManager private[sql](session: SparkSession, loadExtensions: Boolean)\n+  extends SparkListener with Logging {\n+\n+  private[this] val listeners = new CopyOnWriteArrayList[QueryExecutionListener]\n+\n+  if (loadExtensions) {\n+    val conf = session.sparkContext.conf\n     conf.get(QUERY_EXECUTION_LISTENERS).foreach { classNames =>\n       Utils.loadExtensions(classOf[QueryExecutionListener], classNames, conf).foreach(register)\n     }\n   }\n \n+  session.sparkContext.listenerBus.addToSharedQueue(this)\n+\n   /**\n    * Registers the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def register(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners += listener\n+  def register(listener: QueryExecutionListener): Unit = {\n+    listeners.add(listener)\n   }\n \n   /**\n    * Unregisters the specified [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def unregister(listener: QueryExecutionListener): Unit = writeLock {\n-    listeners -= listener\n+  def unregister(listener: QueryExecutionListener): Unit = {\n+    listeners.remove(listener)\n   }\n \n   /**\n    * Removes all the registered [[QueryExecutionListener]].\n    */\n   @DeveloperApi\n-  def clear(): Unit = writeLock {\n+  def clear(): Unit = {\n     listeners.clear()\n   }\n \n   /**\n    * Get an identical copy of this listener manager.\n    */\n-  @DeveloperApi\n-  override def clone(): ExecutionListenerManager = writeLock {\n-    val newListenerManager = new ExecutionListenerManager\n-    listeners.foreach(newListenerManager.register)\n+  private[sql] def clone(session: SparkSession): ExecutionListenerManager = {\n+    val newListenerManager = new ExecutionListenerManager(session, loadExtensions = false)\n+    listeners.iterator().asScala.foreach(newListenerManager.register)\n     newListenerManager\n   }\n \n-  private[sql] def onSuccess(funcName: String, qe: QueryExecution, duration: Long): Unit = {\n-    readLock {\n-      withErrorHandling { listener =>\n-        listener.onSuccess(funcName, qe, duration)\n+  override def onOtherEvent(event: SparkListenerEvent): Unit = event match {\n+    case e: SparkListenerSQLExecutionEnd if shouldCatchEvent(e) =>\n+      val funcName = e.executionName.get\n+      e.executionFailure match {\n+        case Some(ex) =>\n+          listeners.iterator().asScala.foreach(_.onFailure(funcName, e.qe, ex))"
  }],
  "prId": 22674
}]