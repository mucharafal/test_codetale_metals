[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This also looks like a good example which is irrelevant to ORC V2 migration.",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-10T17:01:13Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "I can do it. But the reason to create a signle PR for this is kind of weak. I prefer to put it here with the whole context. cc @cloud-fan ",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-10T17:27:55Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Yep. Please. Your commit will be referenced by many developers.\r\n\r\nIt's a design issue instead of `size`. The kind of framework classes for DSv2 should be outside of this ORC specific PR (`[SPARK-23817][SQL] Migrate ORC file format read path to data source V2`).",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-10T17:40:54Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "how about we change the PR title to `create file format v2 migration infra and migrate ORC`? If we only commit specific code to migrate orc, it's useless and will be refactored right away when we migrate the next file format.",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-11T05:35:04Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "What about just making another PR containing a subset of this PR?\r\nIt's good to demonstrate the framework's feasibility, but it's too big in a single PR.\r\nAfter merging the framework PR, what we need in this PR is just simple rebasing.",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-11T05:42:27Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "@cloud-fan thanks, I have updated the title and description.\r\n@dongjoon-hyun my concern is: if we create a PR for the framework only, then it would be hard to prove the framework works, even with some dummy data source in the unit test. \r\n",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-11T05:54:15Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "No, what I suggested is keeping this PR with the framework code.\r\nThe framework code PR consists of just a subset of code from here.\r\nAnd you can give the pointer to this PR (for full demonstration). After merging framework PR, you can rebase this PR in order to remove the framework code.",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-11T06:06:32Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "To be clear, I'm not suggesting additional test code for the framework PR.",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-11T06:08:20Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "We need someting to prove the framework works, I think ORC is a good example, as it has filter pushdown and columnar scan. It may be too wasteful to write a lot of dummy examples in the framework only PR.",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-11T06:16:08Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "? Why do we need a new code. My suggestion is making a PR containing the following files, and give a pointer to this PR.\r\n```\r\nDataSourceStrategy.scala\r\nEmptyPartitionReader.scala\r\nFileDataSourceV2.scala\r\nFileDataSourceV2FallBackSuite.scala\r\nFilePartitionReader.scala\r\nFilePartitionReaderFactory.scala\r\nFilePartitionUtil.scala\r\nFileScan.scala\r\nFileScanBuilder.scala\r\nFileScanRDD.scala\r\nFileTable.scala\r\nHiveSessionStateBuilder.scala\r\nPartitionFileUtil.scala\r\nPartitionRecordReader.scala\r\n```",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-11T06:17:21Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "If you want, I can make a PR with @gengliangwang 's authorship as an example.",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-11T06:18:03Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "I've talked with @cloud-fan . Got it. Please ignore my previous comment. Let's use ORC as an example. Sorry for the delay, @gengliangwang .",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-11T07:04:30Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "@dongjoon-hyun great! I think both approaches are OK. Let's keep it in the current way. ",
    "commit": "6e875323a430cee190a458b8842adea44bb4e0b7",
    "createdAt": "2019-01-11T07:08:24Z",
    "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.v2\n+\n+import java.io.IOException\n+\n+import org.apache.spark.sql.sources.v2.reader.PartitionReader\n+\n+/**\n+ * A [[PartitionReader]] with empty output.\n+ */\n+class EmptyPartitionReader[T] extends PartitionReader[T] {\n+  override def next(): Boolean = false\n+\n+  override def get(): T =\n+    throw new IOException(\"No records should be returned from EmptyDataReader\")\n+\n+  override def close(): Unit = {}\n+}",
    "line": 34
  }],
  "prId": 23383
}]