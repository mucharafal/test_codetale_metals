[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Nits: braces and newline for the `if`; use `a += 1` instead of `a = a + 1` in the two lines below; extra blank line above near the imports.\n\nYou should probably also make this more idiomatic and compact. For example this `while` loop collapses to `rddSchema.fields.map(_.name).mkString(\", \")`, I believe. Similarly for the final `while`. And then the entire method doesn't need to manually build it up with `StringBuilder`. This is probably a couple lines of code.\n",
    "commit": "cac053696fef6fe326c9855ab57f13899a9e7e82",
    "createdAt": "2015-12-01T12:16:22Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.jdbc\n+\n+import java.sql.Types\n+\n+import org.apache.spark.sql.types._\n+\n+\n+private case object CassandraDialect extends JdbcDialect {\n+\n+  override def canHandle(url: String): Boolean =\n+    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n+    url.startsWith(\"jdbc:weblogic:cassandra\")\n+\n+  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n+    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n+    var fieldsLeft = rddSchema.fields.length\n+    var i = 0\n+    // Build list of column names\n+    while (fieldsLeft > 0) {\n+      sql.append(rddSchema.fields(i).name)\n+      if (fieldsLeft > 1) sql.append(\", \")",
    "line": 38
  }, {
    "author": {
      "login": "CK50"
    },
    "body": "@Sean: I am working on your suggested changes. Looks like the code can \nbe collapsed into one or two lines.\n\nMeanwhile I have found that inserting into an Oracle table having more \ncolumns than columns in the dataframe results in\n\njava.sql.BatchUpdateException: ORA-00947: not enough values if there are \nany unmapped columns.\n\nThis does not matter, as long as the table matches exactly the \ndataframe. But as soon as someone wants to insert into an existing table \nwith more columns than the dataframe has, this is a problem.\n\nSo it may indeed be better to include the suggested change for other \ntechnologies as well.\n\nThe key question I see is: Is it okay to rely on the dataframe column \nnames matching the target table column names?\n\nIf so, do you suggest changing the default behaviour to include column \nnames for all dialects?\n\nDoes Spark automated tests have coverage for different databases? / \nWould any regression be caught prior to merge?\n\nbtw,\nre squashing commits: I will try, but for now I need to better \nunderstand how all of this works in GitHub.\n\nOn 01.12.2015 13:17, Sean Owen wrote:\n\n> In \n> sql/core/src/main/scala/org/apache/spark/sql/jdbc/CassandraDialect.scala \n> https://github.com/apache/spark/pull/10066#discussion_r46270863:\n> \n> > +\n> > +\n> > +private case object CassandraDialect extends JdbcDialect {\n> > +\n> > -  override def canHandle(url: String): Boolean =\n> > -    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n> > -    url.startsWith(\"jdbc:weblogic:cassandra\")\n> >   +\n> > -  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n> > -    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n> > -    var fieldsLeft = rddSchema.fields.length\n> > -    var i = 0\n> > -    // Build list of column names\n> > -    while (fieldsLeft > 0) {\n> > -      sql.append(rddSchema.fields(i).name)\n> > -      if (fieldsLeft > 1) sql.append(\", \")\n> \n> Nits: braces and newline for the |if|; use |a += 1| instead of |a = a \n> - 1| in the two lines below; extra blank line above near the imports.\n> \n> You should probably also make this more idiomatic and compact. For \n> example this |while| loop collapses to \n> |rddSchema.fields.map(_.name).mkString(\", \")|, I believe. Similarly \n> for the final |while|. And then the entire method doesn't need to \n> manually build it up with |StringBuilder|. This is probably a couple \n> lines of code.\n> \n> —\n> Reply to this email directly or view it on GitHub \n> https://github.com/apache/spark/pull/10066/files#r46270863.\n\n## \n\nOracle http://www.oracle.com\nChristian Kurz | Consulting Member of Technical Staff\nPhone: +49 228 30899431 tel:+49%20228%2030899431 | Mobile: +49 170 \n2964124 tel:+49%20170%202964124\nOracle Product Development\n\nORACLE Deutschland B.V. & Co. KG | Hamborner Str. 51 | 40472 Düsseldorf\n\nORACLE Deutschland B.V. & Co. KG\nHauptverwaltung: Riesstr. 25, D-80992 München\nRegistergericht: Amtsgericht München, HRA 95603\n\nKomplementärin: ORACLE Deutschland Verwaltung B.V.\nHertogswetering 163/167, 3543 AS Utrecht, Niederlande\nHandelsregister der Handelskammer Midden-Niederlande, Nr. 30143697\nGeschäftsführer: Alexander van der Ven, Astrid Kepper, Val Maher\n\nGreen Oracle http://www.oracle.com/commitment Oracle is committed to \ndeveloping practices and products that help protect the environment\n",
    "commit": "cac053696fef6fe326c9855ab57f13899a9e7e82",
    "createdAt": "2015-12-02T10:26:29Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.jdbc\n+\n+import java.sql.Types\n+\n+import org.apache.spark.sql.types._\n+\n+\n+private case object CassandraDialect extends JdbcDialect {\n+\n+  override def canHandle(url: String): Boolean =\n+    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n+    url.startsWith(\"jdbc:weblogic:cassandra\")\n+\n+  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n+    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n+    var fieldsLeft = rddSchema.fields.length\n+    var i = 0\n+    // Build list of column names\n+    while (fieldsLeft > 0) {\n+      sql.append(rddSchema.fields(i).name)\n+      if (fieldsLeft > 1) sql.append(\", \")",
    "line": 38
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "You're just saying that inserting a DataFrame of m columns into a table of n > m columns doesn't work, right? Yes without column name mappings, I expect this to fail anytime m != n, for any database. Right now this assumes m = n implicitly.\n\nYou're right that adding names requires a mapping from data frame column names to DB column names. Hm, I wonder if this needs an optional `Map` allowing for overrides.\n\nI don't think the regression tests cover all databases, no. I also don't think this can be specific to Oracle anyway.\n\nMy workflow for squashing N of the last commits is:\n- `git rebase -i HEAD~N`\n- Change all but the first \"pick\" to \"squash\" in the editor and save\n- Edit the commit message down to just 1 logical message and save\n- `git push --force origin [your branch]`\n",
    "commit": "cac053696fef6fe326c9855ab57f13899a9e7e82",
    "createdAt": "2015-12-02T10:45:12Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.jdbc\n+\n+import java.sql.Types\n+\n+import org.apache.spark.sql.types._\n+\n+\n+private case object CassandraDialect extends JdbcDialect {\n+\n+  override def canHandle(url: String): Boolean =\n+    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n+    url.startsWith(\"jdbc:weblogic:cassandra\")\n+\n+  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n+    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n+    var fieldsLeft = rddSchema.fields.length\n+    var i = 0\n+    // Build list of column names\n+    while (fieldsLeft > 0) {\n+      sql.append(rddSchema.fields(i).name)\n+      if (fieldsLeft > 1) sql.append(\", \")",
    "line": 38
  }, {
    "author": {
      "login": "CK50"
    },
    "body": "Yes, this is exactly the problem encountered.\n\nWhat if we drop the new Dialect and add a new signature on \nDataFrameWriter instead (new columnMapping param):\n\ndef jdbc(url: String, table: String, connectionProperties: Properties, \ncolumnMapping: Map<String,String>): Unit\n\nThe old signature then continues using the column-name-free INSERT \nsyntax, but for any advanced use-cases (or technologies, which do not \nsupport column-name-free syntax) the new API can be used.\n\nThis ensures full backwards compatibility for all technologies\n\nIf this is the way to go, I'd better start a new PR?\n\nMy preference would still to keep the refactoring of moving generation \nof INSERT statement into the Dialect (instead of in JDBCUtils). Does \nthis make sense?\n\nOn 02.12.2015 11:46, Sean Owen wrote:\n\n> In \n> sql/core/src/main/scala/org/apache/spark/sql/jdbc/CassandraDialect.scala \n> https://github.com/apache/spark/pull/10066#discussion_r46399876:\n> \n> > +\n> > +\n> > +private case object CassandraDialect extends JdbcDialect {\n> > +\n> > -  override def canHandle(url: String): Boolean =\n> > -    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n> > -    url.startsWith(\"jdbc:weblogic:cassandra\")\n> >   +\n> > -  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n> > -    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n> > -    var fieldsLeft = rddSchema.fields.length\n> > -    var i = 0\n> > -    // Build list of column names\n> > -    while (fieldsLeft > 0) {\n> > -      sql.append(rddSchema.fields(i).name)\n> > -      if (fieldsLeft > 1) sql.append(\", \")\n> \n> You're just saying that inserting a DataFrame of m columns into a \n> table of n > m columns doesn't work, right? Yes without column name \n> mappings, I expect this to fail anytime m != n, for any database. \n> Right now this assumes m = n implicitly.\n> \n> You're right that adding names requires a mapping from data frame \n> column names to DB column names. Hm, I wonder if this needs an \n> optional |Map| allowing for overrides.\n> \n> I don't think the regression tests cover all databases, no. I also \n> don't think this can be specific to Oracle anyway.\n> \n> My workflow for squashing N of the last commits is:\n> - |git rebase -i HEAD~N|\n> - Change all but the first \"pick\" to \"squash\" in the editor and save\n> - Edit the commit message down to just 1 logical message and save\n> - |git push --force origin [your branch]|\n> \n> —\n> Reply to this email directly or view it on GitHub \n> https://github.com/apache/spark/pull/10066/files#r46399876.\n\n## \n\nOracle http://www.oracle.com\nChristian Kurz | Consulting Member of Technical Staff\nPhone: +49 228 30899431 tel:+49%20228%2030899431 | Mobile: +49 170 \n2964124 tel:+49%20170%202964124\nOracle Product Development\n\nORACLE Deutschland B.V. & Co. KG | Hamborner Str. 51 | 40472 Düsseldorf\n\nORACLE Deutschland B.V. & Co. KG\nHauptverwaltung: Riesstr. 25, D-80992 München\nRegistergericht: Amtsgericht München, HRA 95603\n\nKomplementärin: ORACLE Deutschland Verwaltung B.V.\nHertogswetering 163/167, 3543 AS Utrecht, Niederlande\nHandelsregister der Handelskammer Midden-Niederlande, Nr. 30143697\nGeschäftsführer: Alexander van der Ven, Astrid Kepper, Val Maher\n\nGreen Oracle http://www.oracle.com/commitment Oracle is committed to \ndeveloping practices and products that help protect the environment\n",
    "commit": "cac053696fef6fe326c9855ab57f13899a9e7e82",
    "createdAt": "2015-12-02T11:53:06Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.jdbc\n+\n+import java.sql.Types\n+\n+import org.apache.spark.sql.types._\n+\n+\n+private case object CassandraDialect extends JdbcDialect {\n+\n+  override def canHandle(url: String): Boolean =\n+    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n+    url.startsWith(\"jdbc:weblogic:cassandra\")\n+\n+  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n+    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n+    var fieldsLeft = rddSchema.fields.length\n+    var i = 0\n+    // Build list of column names\n+    while (fieldsLeft > 0) {\n+      sql.append(rddSchema.fields(i).name)\n+      if (fieldsLeft > 1) sql.append(\", \")",
    "line": 38
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "@rxin are you the best person to ask about overloading `DataFrameWriter.jdbc()`?\n\nInteresting question about maintaining the current behavior when no column name mapping is specified. In a way it still seems suboptimal to allow this behavior. What if there are the same number of columns, and all are the same type, but the ordering is different? you'd silently insert the wrong data in the wrong column.\n\nAlthough specifying the DataFrame-to-table column name mapping can be optional (or, the caller can override only the names they want to) I think the SQL statement should be explicit. It does mean that someone who has a DataFrame with differently-named columns somehow might now encounter an exception, but I wonder if that's actually the right thing to enforce going forward. If it doesn't match up by name, don't proceed.\n\nThe API changes will take some care to make sure it's unintrusive and backwards compatible.\n\nI suspect it doesn't do much harm to keep the insert statement logic in `JdbcDialects` though I imagine this behavior, whatever we decide, will be the right thing for all dialects, so it can be a default implementation there.\n",
    "commit": "cac053696fef6fe326c9855ab57f13899a9e7e82",
    "createdAt": "2015-12-02T12:12:30Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.jdbc\n+\n+import java.sql.Types\n+\n+import org.apache.spark.sql.types._\n+\n+\n+private case object CassandraDialect extends JdbcDialect {\n+\n+  override def canHandle(url: String): Boolean =\n+    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n+    url.startsWith(\"jdbc:weblogic:cassandra\")\n+\n+  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n+    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n+    var fieldsLeft = rddSchema.fields.length\n+    var i = 0\n+    // Build list of column names\n+    while (fieldsLeft > 0) {\n+      sql.append(rddSchema.fields(i).name)\n+      if (fieldsLeft > 1) sql.append(\", \")",
    "line": 38
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "I would just go ahead and add the new overload of `jdbc()`.\n",
    "commit": "cac053696fef6fe326c9855ab57f13899a9e7e82",
    "createdAt": "2015-12-10T22:43:35Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.jdbc\n+\n+import java.sql.Types\n+\n+import org.apache.spark.sql.types._\n+\n+\n+private case object CassandraDialect extends JdbcDialect {\n+\n+  override def canHandle(url: String): Boolean =\n+    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n+    url.startsWith(\"jdbc:weblogic:cassandra\")\n+\n+  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n+    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n+    var fieldsLeft = rddSchema.fields.length\n+    var i = 0\n+    // Build list of column names\n+    while (fieldsLeft > 0) {\n+      sql.append(rddSchema.fields(i).name)\n+      if (fieldsLeft > 1) sql.append(\", \")",
    "line": 38
  }, {
    "author": {
      "login": "CK50"
    },
    "body": "Ok, will provide PR shortly\n\nOn 10.12.2015 23:44, Sean Owen wrote:\n\n> In \n> sql/core/src/main/scala/org/apache/spark/sql/jdbc/CassandraDialect.scala \n> https://github.com/apache/spark/pull/10066#discussion_r47298240:\n> \n> > +\n> > +\n> > +private case object CassandraDialect extends JdbcDialect {\n> > +\n> > -  override def canHandle(url: String): Boolean =\n> > -    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n> > -    url.startsWith(\"jdbc:weblogic:cassandra\")\n> >   +\n> > -  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n> > -    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n> > -    var fieldsLeft = rddSchema.fields.length\n> > -    var i = 0\n> > -    // Build list of column names\n> > -    while (fieldsLeft > 0) {\n> > -      sql.append(rddSchema.fields(i).name)\n> > -      if (fieldsLeft > 1) sql.append(\", \")\n> \n> I would just go ahead and add the new overload of |jdbc()|.\n> \n> —\n> Reply to this email directly or view it on GitHub \n> https://github.com/apache/spark/pull/10066/files#r47298240.\n",
    "commit": "cac053696fef6fe326c9855ab57f13899a9e7e82",
    "createdAt": "2015-12-14T16:26:38Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.jdbc\n+\n+import java.sql.Types\n+\n+import org.apache.spark.sql.types._\n+\n+\n+private case object CassandraDialect extends JdbcDialect {\n+\n+  override def canHandle(url: String): Boolean =\n+    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n+    url.startsWith(\"jdbc:weblogic:cassandra\")\n+\n+  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n+    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n+    var fieldsLeft = rddSchema.fields.length\n+    var i = 0\n+    // Build list of column names\n+    while (fieldsLeft > 0) {\n+      sql.append(rddSchema.fields(i).name)\n+      if (fieldsLeft > 1) sql.append(\", \")",
    "line": 38
  }, {
    "author": {
      "login": "CK50"
    },
    "body": "Opened PR #10312. - Please let me know your thoughts. - Thanks, Christian\n\nOn 10.12.2015 23:44, Sean Owen wrote:\n\n> In \n> sql/core/src/main/scala/org/apache/spark/sql/jdbc/CassandraDialect.scala \n> https://github.com/apache/spark/pull/10066#discussion_r47298240:\n> \n> > +\n> > +\n> > +private case object CassandraDialect extends JdbcDialect {\n> > +\n> > -  override def canHandle(url: String): Boolean =\n> > -    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n> > -    url.startsWith(\"jdbc:weblogic:cassandra\")\n> >   +\n> > -  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n> > -    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n> > -    var fieldsLeft = rddSchema.fields.length\n> > -    var i = 0\n> > -    // Build list of column names\n> > -    while (fieldsLeft > 0) {\n> > -      sql.append(rddSchema.fields(i).name)\n> > -      if (fieldsLeft > 1) sql.append(\", \")\n> \n> I would just go ahead and add the new overload of |jdbc()|.\n> \n> —\n> Reply to this email directly or view it on GitHub \n> https://github.com/apache/spark/pull/10066/files#r47298240.\n",
    "commit": "cac053696fef6fe326c9855ab57f13899a9e7e82",
    "createdAt": "2015-12-15T17:45:53Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.jdbc\n+\n+import java.sql.Types\n+\n+import org.apache.spark.sql.types._\n+\n+\n+private case object CassandraDialect extends JdbcDialect {\n+\n+  override def canHandle(url: String): Boolean =\n+    url.startsWith(\"jdbc:datadirect:cassandra\") ||\n+    url.startsWith(\"jdbc:weblogic:cassandra\")\n+\n+  override def getInsertStatement(table: String, rddSchema: StructType): String = {\n+    val sql = new StringBuilder(s\"INSERT INTO $table ( \")\n+    var fieldsLeft = rddSchema.fields.length\n+    var i = 0\n+    // Build list of column names\n+    while (fieldsLeft > 0) {\n+      sql.append(rddSchema.fields(i).name)\n+      if (fieldsLeft > 1) sql.append(\", \")",
    "line": 38
  }],
  "prId": 10066
}]