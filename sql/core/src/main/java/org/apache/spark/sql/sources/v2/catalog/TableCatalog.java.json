[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "why it's expressions? In current Spark we only support PARTITION BY columns.",
    "commit": "6b45a119df8e6382fa2503f854b4a85aed3e3785",
    "createdAt": "2018-07-05T05:24:25Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.catalog;\n+\n+import org.apache.spark.sql.catalyst.TableIdentifier;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException;\n+import org.apache.spark.sql.catalyst.expressions.Expression;\n+import org.apache.spark.sql.types.StructType;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+public interface TableCatalog {\n+  /**\n+   * Load table metadata by {@link TableIdentifier identifier} from the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @return the table's metadata\n+   * @throws NoSuchTableException If the table doesn't exist.\n+   */\n+  Table loadTable(TableIdentifier ident) throws NoSuchTableException;\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), Collections.emptyMap());\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema,\n+                            Map<String, String> properties) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), properties);\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param partitions a list of expressions to use for partitioning data in the table\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  Table createTable(TableIdentifier ident,\n+                    StructType schema,\n+                    List<Expression> partitions,"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "I recommend reading the proposal SPIP's \"Proposed Changes\" section, which goes into more detail than this comment can. In short, you're thinking of partitions as columns like Hive tables, but that is a narrow definition that prevents the underlying format from optimizing queries.\r\n\r\nPartitions of a table are derived from the column data through some transform. For example, partitioning by day uses a day transform from a timestamp column: `day(ts)`. Hive doesn't keep track of that transform and requires queries to handle it by inserting both `ts` and `day` columns. This leads to a few problems, including:\r\n* Hive has no ability to transform `ts > X` to the partition predicate `day >= day(X)`. Queries that don't take into account the table's physical storage by adding partition predicates by hand will result in full table scans.\r\n* Users can insert any data they choose into the `day` partition and it is up to them to do it correctly.\r\n\r\nAlso, consider bucketing. Bucketing is also a transform that is effectively a partitioning of the table's files: `bucket=hash(col) % N`. The reason why bucketing is handled as a special case in Hive is that using it _requires_ knowing the transform and relationship between the bucket number and its column. If we think of partitioning as grouping data by common values of a set of transforms, then buckets are just another partition that we can use for purposes like bucketed joins or limiting scans when looking for specific values.\r\n\r\nIf the transform is _identity_ -- just copy the value into partition data -- then you have the same functionality that Hive provides. But by building the transformations into the partitioning layer, we can do more to optimize queries, while hiding the physical layout of a table.\r\n\r\nUsing Expression allows Spark to pass `day(ts)` to the data source. It is up to the source which expressions are supported. The current FS tables would reject any expression that isn't just a column reference. Iceberg supports `identity`, `year`, `month`, `day`, `hour`, `truncate`, and `bucket` transforms.",
    "commit": "6b45a119df8e6382fa2503f854b4a85aed3e3785",
    "createdAt": "2018-07-05T16:41:44Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.catalog;\n+\n+import org.apache.spark.sql.catalyst.TableIdentifier;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException;\n+import org.apache.spark.sql.catalyst.expressions.Expression;\n+import org.apache.spark.sql.types.StructType;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+public interface TableCatalog {\n+  /**\n+   * Load table metadata by {@link TableIdentifier identifier} from the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @return the table's metadata\n+   * @throws NoSuchTableException If the table doesn't exist.\n+   */\n+  Table loadTable(TableIdentifier ident) throws NoSuchTableException;\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), Collections.emptyMap());\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema,\n+                            Map<String, String> properties) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), properties);\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param partitions a list of expressions to use for partitioning data in the table\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  Table createTable(TableIdentifier ident,\n+                    StructType schema,\n+                    List<Expression> partitions,"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "I read the SPIP but I still can't figure it out. How can Spark pass these \"partition transform\" to data source? The current end-user API only allows users to specify partition columns.\r\n\r\nAnd why does the \"partition transform\" belong to a table definition? I think it's reasonable to say that a table is partition by column `timestamp`, and supports pushing partition predicates like `year(timestamp) > 2000`.",
    "commit": "6b45a119df8e6382fa2503f854b4a85aed3e3785",
    "createdAt": "2018-07-06T12:34:47Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.catalog;\n+\n+import org.apache.spark.sql.catalyst.TableIdentifier;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException;\n+import org.apache.spark.sql.catalyst.expressions.Expression;\n+import org.apache.spark.sql.types.StructType;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+public interface TableCatalog {\n+  /**\n+   * Load table metadata by {@link TableIdentifier identifier} from the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @return the table's metadata\n+   * @throws NoSuchTableException If the table doesn't exist.\n+   */\n+  Table loadTable(TableIdentifier ident) throws NoSuchTableException;\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), Collections.emptyMap());\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema,\n+                            Map<String, String> properties) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), properties);\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param partitions a list of expressions to use for partitioning data in the table\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  Table createTable(TableIdentifier ident,\n+                    StructType schema,\n+                    List<Expression> partitions,"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "> The current end-user API only allows users to specify partition columns.\r\n\r\nI think an example would help understand the use of expression here. Right now, I can create a table partitioned by day like this:\r\n```\r\nCREATE TABLE t (ts timestamp, data string, day string) PARTITIONED BY (day)\r\n```\r\n\r\nThen it's up to queries to supply the right values for `day` in their queries. I'm proposing we change that to something like the following that uses expressions in the PARTITIONED BY clause instead of only allowing column names:\r\n```\r\nCREATE TABLE t (ts timestamp, data string) PARTITIONED BY (date(ts));\r\n```\r\n\r\nThis can handle all identity partitioning in Hive tables today and it can handle bucketing.\r\n\r\n> And why does the \"partition transform\" belong to a table definition?\r\n\r\nTransforms should be passed to the table so the source can use them for the physical layout. In DataSourceV2, the source could be anything so it needs to be the component that handles the physical layout. Because we want distributed data sources, we need some way of telling them how to distribute data.\r\n\r\nFor example, I could use a partitioning expression to tell a source how to shard across PostgreSQL instances. I could also use it to define the keys in an HBase connector. Those are uses of partitioning that Spark can't handle internally.\r\n\r\nLike Hive, Spark has only supported a limited definition of partitioning up to now, but I'd like to be able to put tables using Hive's layout behind this API eventually. I think this way of configuring partitioning is a good way to do that, while supporting what Iceberg and other sources will need.",
    "commit": "6b45a119df8e6382fa2503f854b4a85aed3e3785",
    "createdAt": "2018-07-06T16:46:39Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.catalog;\n+\n+import org.apache.spark.sql.catalyst.TableIdentifier;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException;\n+import org.apache.spark.sql.catalyst.expressions.Expression;\n+import org.apache.spark.sql.types.StructType;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+public interface TableCatalog {\n+  /**\n+   * Load table metadata by {@link TableIdentifier identifier} from the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @return the table's metadata\n+   * @throws NoSuchTableException If the table doesn't exist.\n+   */\n+  Table loadTable(TableIdentifier ident) throws NoSuchTableException;\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), Collections.emptyMap());\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema,\n+                            Map<String, String> properties) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), properties);\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param partitions a list of expressions to use for partitioning data in the table\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  Table createTable(TableIdentifier ident,\n+                    StructType schema,\n+                    List<Expression> partitions,"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "Another benefit: this would allow us to translate `BUCKETED BY` clauses into something we can actually pass to data sources.",
    "commit": "6b45a119df8e6382fa2503f854b4a85aed3e3785",
    "createdAt": "2018-07-06T16:48:40Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.catalog;\n+\n+import org.apache.spark.sql.catalyst.TableIdentifier;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException;\n+import org.apache.spark.sql.catalyst.expressions.Expression;\n+import org.apache.spark.sql.types.StructType;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+public interface TableCatalog {\n+  /**\n+   * Load table metadata by {@link TableIdentifier identifier} from the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @return the table's metadata\n+   * @throws NoSuchTableException If the table doesn't exist.\n+   */\n+  Table loadTable(TableIdentifier ident) throws NoSuchTableException;\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), Collections.emptyMap());\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema,\n+                            Map<String, String> properties) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), properties);\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param partitions a list of expressions to use for partitioning data in the table\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  Table createTable(TableIdentifier ident,\n+                    StructType schema,\n+                    List<Expression> partitions,"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "I see, and this seems a very cool feature. My only concern is that, this new feature is not being discussed in dev list yet, and no JIRA ticket is tracking it. I feel a little weird to support a non-existing feature in data source v2 API. Shall we start a thread in dev list for this new feature? And see if we can make it before 2.4.",
    "commit": "6b45a119df8e6382fa2503f854b4a85aed3e3785",
    "createdAt": "2018-07-07T02:53:58Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.catalog;\n+\n+import org.apache.spark.sql.catalyst.TableIdentifier;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException;\n+import org.apache.spark.sql.catalyst.expressions.Expression;\n+import org.apache.spark.sql.types.StructType;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+public interface TableCatalog {\n+  /**\n+   * Load table metadata by {@link TableIdentifier identifier} from the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @return the table's metadata\n+   * @throws NoSuchTableException If the table doesn't exist.\n+   */\n+  Table loadTable(TableIdentifier ident) throws NoSuchTableException;\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), Collections.emptyMap());\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema,\n+                            Map<String, String> properties) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), properties);\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param partitions a list of expressions to use for partitioning data in the table\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  Table createTable(TableIdentifier ident,\n+                    StructType schema,\n+                    List<Expression> partitions,"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "I wouldn't say this way of passing partitioning is a new feature. It's just a generalization of the existing partitioning that allows us to pass any type of partition, whether it is bucketing or column-based.\r\n\r\nAs for open discussion, this was proposed in the SPIP that was fairly widely read and commented on. That SPIP was posted to the dev list a few times, too. I do appreciate you wanting to make sure there's been a chance for the community to discuss it, but there has been plenty of opportunity to comment. At this point, I think it's reasonable to move forward with the implementation.",
    "commit": "6b45a119df8e6382fa2503f854b4a85aed3e3785",
    "createdAt": "2018-07-07T23:09:35Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.catalog;\n+\n+import org.apache.spark.sql.catalyst.TableIdentifier;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException;\n+import org.apache.spark.sql.catalyst.expressions.Expression;\n+import org.apache.spark.sql.types.StructType;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+public interface TableCatalog {\n+  /**\n+   * Load table metadata by {@link TableIdentifier identifier} from the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @return the table's metadata\n+   * @throws NoSuchTableException If the table doesn't exist.\n+   */\n+  Table loadTable(TableIdentifier ident) throws NoSuchTableException;\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), Collections.emptyMap());\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  default Table createTable(TableIdentifier ident,\n+                            StructType schema,\n+                            Map<String, String> properties) throws TableAlreadyExistsException {\n+    return createTable(ident, schema, Collections.emptyList(), properties);\n+  }\n+\n+  /**\n+   * Create a table in the catalog.\n+   *\n+   * @param ident a table identifier\n+   * @param schema the schema of the new table, as a struct type\n+   * @param partitions a list of expressions to use for partitioning data in the table\n+   * @param properties a string map of table properties\n+   * @return metadata for the new table\n+   * @throws TableAlreadyExistsException If a table already exists for the identifier\n+   */\n+  Table createTable(TableIdentifier ident,\n+                    StructType schema,\n+                    List<Expression> partitions,"
  }],
  "prId": 21306
}]