[{
  "comments": [{
    "author": {
      "login": "jose-torres"
    },
    "body": "I don't know if we want a default here - it seems like subclasses should always be able to provide an implementation, and thus that we should always require them to.",
    "commit": "992e2c1de84b9e82875f47ecc21aad2a299038a7",
    "createdAt": "2018-02-28T18:03:17Z",
    "diffHunk": "@@ -0,0 +1,38 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset;\n+\n+/**\n+ * A mix-in interface for {@link DataReaderFactory}. Continuous data reader factories can\n+ * implement this interface to provide creating {@link DataReader} with particular offset.\n+ */\n+@InterfaceStability.Evolving\n+public interface ContinuousDataReaderFactory<T> extends DataReaderFactory<T> {\n+  /**\n+   * Create a DataReader with particular offset as its startOffset.\n+   *\n+   * @param offset offset want to set as the DataReader's startOffset.\n+   */\n+  default DataReader<T> createDataReaderWithOffset(PartitionOffset offset) {\n+    throw new IllegalStateException("
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "+1 to make this one just abstract.",
    "commit": "992e2c1de84b9e82875f47ecc21aad2a299038a7",
    "createdAt": "2018-03-14T19:36:37Z",
    "diffHunk": "@@ -0,0 +1,38 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset;\n+\n+/**\n+ * A mix-in interface for {@link DataReaderFactory}. Continuous data reader factories can\n+ * implement this interface to provide creating {@link DataReader} with particular offset.\n+ */\n+@InterfaceStability.Evolving\n+public interface ContinuousDataReaderFactory<T> extends DataReaderFactory<T> {\n+  /**\n+   * Create a DataReader with particular offset as its startOffset.\n+   *\n+   * @param offset offset want to set as the DataReader's startOffset.\n+   */\n+  default DataReader<T> createDataReaderWithOffset(PartitionOffset offset) {\n+    throw new IllegalStateException("
  }],
  "prId": 20689
}]