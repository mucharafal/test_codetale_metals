[{
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "`InputStream` conflicts with a well-known JVM class, [`java.io.InputStream`](https://docs.oracle.com/javase/9/docs/api/java/io/InputStream.html). I think this should be renamed to be more specific to a streaming table scan.",
    "commit": "9f63721677cea627f43f7d536bb32b588cee30a3",
    "createdAt": "2018-10-19T21:46:51Z",
    "diffHunk": "@@ -17,14 +17,18 @@\n \n package org.apache.spark.sql.sources.v2.reader.streaming;\n \n-import org.apache.spark.sql.sources.v2.reader.ReadSupport;\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.execution.streaming.BaseStreamingSource;\n \n /**\n- * A base interface for streaming read support. This is package private and is invisible to data\n- * sources. Data sources should implement concrete streaming read support interfaces:\n- * {@link MicroBatchReadSupport} or {@link ContinuousReadSupport}.\n+ * An interface representing a readable data stream in a streaming query. It's responsible to manage\n+ * the offsets of the streaming source in this streaming query.\n+ *\n+ * Data sources should implement concrete input stream interfaces: {@link MicroBatchInputStream} and\n+ * {@link ContinuousInputStream}.\n  */\n-interface StreamingReadSupport extends ReadSupport {\n+@InterfaceStability.Evolving\n+public interface InputStream extends BaseStreamingSource {",
    "line": 20
  }],
  "prId": 22547
}]