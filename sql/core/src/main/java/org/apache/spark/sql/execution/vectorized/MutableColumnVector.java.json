[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "You are allowed to pass `null` as a cause to the `RuntimeException` constructor.",
    "commit": "8330870ef18b12dfeb51e5003c68aaff9dabb7a3",
    "createdAt": "2017-08-16T11:06:09Z",
    "diffHunk": "@@ -0,0 +1,599 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.vectorized;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import org.apache.spark.sql.internal.SQLConf;\n+import org.apache.spark.sql.types.*;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+/**\n+ * This class adds write APIs to ColumnVector.\n+ * It supports all the types and contains put APIs as well as their batched versions.\n+ * The batched versions are preferable whenever possible.\n+ *\n+ * Capacity: The data stored is dense but the arrays are not fixed capacity. It is the\n+ * responsibility of the caller to call reserve() to ensure there is enough room before adding\n+ * elements. This means that the put() APIs do not check as in common cases (i.e. flat schemas),\n+ * the lengths are known up front.\n+ *\n+ * A ColumnVector should be considered immutable once originally created. In other words, it is not\n+ * valid to call put APIs after reads until reset() is called.\n+ */\n+public abstract class MutableColumnVector extends ColumnVector {\n+\n+  /**\n+   * Resets this column for writing. The currently stored values are no longer accessible.\n+   */\n+  @Override\n+  public void reset() {\n+    if (isConstant) return;\n+\n+    if (childColumns != null) {\n+      for (ColumnVector c: childColumns) {\n+        c.reset();\n+      }\n+    }\n+    numNulls = 0;\n+    elementsAppended = 0;\n+    if (anyNullsSet) {\n+      putNotNulls(0, capacity);\n+      anyNullsSet = false;\n+    }\n+  }\n+\n+  public void reserve(int requiredCapacity) {\n+    if (requiredCapacity > capacity) {\n+      int newCapacity = (int) Math.min(MAX_CAPACITY, requiredCapacity * 2L);\n+      if (requiredCapacity <= newCapacity) {\n+        try {\n+          reserveInternal(newCapacity);\n+        } catch (OutOfMemoryError outOfMemoryError) {\n+          throwUnsupportedException(requiredCapacity, outOfMemoryError);\n+        }\n+      } else {\n+        throwUnsupportedException(requiredCapacity, null);\n+      }\n+    }\n+  }\n+\n+  private void throwUnsupportedException(int requiredCapacity, Throwable cause) {\n+    String message = \"Cannot reserve additional contiguous bytes in the vectorized reader \" +\n+        \"(requested = \" + requiredCapacity + \" bytes). As a workaround, you can disable the \" +\n+        \"vectorized reader by setting \" + SQLConf.PARQUET_VECTORIZED_READER_ENABLED().key() +\n+        \" to false.\";\n+\n+    if (cause != null) {\n+      throw new RuntimeException(message, cause);"
  }, {
    "author": {
      "login": "ueshin"
    },
    "body": "Thanks. I'll update it.",
    "commit": "8330870ef18b12dfeb51e5003c68aaff9dabb7a3",
    "createdAt": "2017-08-17T03:35:37Z",
    "diffHunk": "@@ -0,0 +1,599 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.vectorized;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import org.apache.spark.sql.internal.SQLConf;\n+import org.apache.spark.sql.types.*;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+/**\n+ * This class adds write APIs to ColumnVector.\n+ * It supports all the types and contains put APIs as well as their batched versions.\n+ * The batched versions are preferable whenever possible.\n+ *\n+ * Capacity: The data stored is dense but the arrays are not fixed capacity. It is the\n+ * responsibility of the caller to call reserve() to ensure there is enough room before adding\n+ * elements. This means that the put() APIs do not check as in common cases (i.e. flat schemas),\n+ * the lengths are known up front.\n+ *\n+ * A ColumnVector should be considered immutable once originally created. In other words, it is not\n+ * valid to call put APIs after reads until reset() is called.\n+ */\n+public abstract class MutableColumnVector extends ColumnVector {\n+\n+  /**\n+   * Resets this column for writing. The currently stored values are no longer accessible.\n+   */\n+  @Override\n+  public void reset() {\n+    if (isConstant) return;\n+\n+    if (childColumns != null) {\n+      for (ColumnVector c: childColumns) {\n+        c.reset();\n+      }\n+    }\n+    numNulls = 0;\n+    elementsAppended = 0;\n+    if (anyNullsSet) {\n+      putNotNulls(0, capacity);\n+      anyNullsSet = false;\n+    }\n+  }\n+\n+  public void reserve(int requiredCapacity) {\n+    if (requiredCapacity > capacity) {\n+      int newCapacity = (int) Math.min(MAX_CAPACITY, requiredCapacity * 2L);\n+      if (requiredCapacity <= newCapacity) {\n+        try {\n+          reserveInternal(newCapacity);\n+        } catch (OutOfMemoryError outOfMemoryError) {\n+          throwUnsupportedException(requiredCapacity, outOfMemoryError);\n+        }\n+      } else {\n+        throwUnsupportedException(requiredCapacity, null);\n+      }\n+    }\n+  }\n+\n+  private void throwUnsupportedException(int requiredCapacity, Throwable cause) {\n+    String message = \"Cannot reserve additional contiguous bytes in the vectorized reader \" +\n+        \"(requested = \" + requiredCapacity + \" bytes). As a workaround, you can disable the \" +\n+        \"vectorized reader by setting \" + SQLConf.PARQUET_VECTORIZED_READER_ENABLED().key() +\n+        \" to false.\";\n+\n+    if (cause != null) {\n+      throw new RuntimeException(message, cause);"
  }],
  "prId": 18958
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "This contradicts the name of this class. Maybe reuseable is a better way of describing what is going on here. Also cc @michal-databricks ",
    "commit": "8330870ef18b12dfeb51e5003c68aaff9dabb7a3",
    "createdAt": "2017-08-16T12:32:03Z",
    "diffHunk": "@@ -0,0 +1,599 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.vectorized;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import org.apache.spark.sql.internal.SQLConf;\n+import org.apache.spark.sql.types.*;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+/**\n+ * This class adds write APIs to ColumnVector.\n+ * It supports all the types and contains put APIs as well as their batched versions.\n+ * The batched versions are preferable whenever possible.\n+ *\n+ * Capacity: The data stored is dense but the arrays are not fixed capacity. It is the\n+ * responsibility of the caller to call reserve() to ensure there is enough room before adding\n+ * elements. This means that the put() APIs do not check as in common cases (i.e. flat schemas),\n+ * the lengths are known up front.\n+ *\n+ * A ColumnVector should be considered immutable once originally created. In other words, it is not"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "How about `WritableColumnVector`?",
    "commit": "8330870ef18b12dfeb51e5003c68aaff9dabb7a3",
    "createdAt": "2017-08-20T13:00:18Z",
    "diffHunk": "@@ -0,0 +1,599 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.vectorized;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import org.apache.spark.sql.internal.SQLConf;\n+import org.apache.spark.sql.types.*;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+/**\n+ * This class adds write APIs to ColumnVector.\n+ * It supports all the types and contains put APIs as well as their batched versions.\n+ * The batched versions are preferable whenever possible.\n+ *\n+ * Capacity: The data stored is dense but the arrays are not fixed capacity. It is the\n+ * responsibility of the caller to call reserve() to ensure there is enough room before adding\n+ * elements. This means that the put() APIs do not check as in common cases (i.e. flat schemas),\n+ * the lengths are known up front.\n+ *\n+ * A ColumnVector should be considered immutable once originally created. In other words, it is not"
  }],
  "prId": 18958
}]