[{
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "I know that this is from prior DataSourceV2 semantics, but what's the difference between providing the `schema` here and the column pruning aspect of `ScanBuilder`?",
    "commit": "eecb161075720aec0c496576fe6b6ad749c3a726",
    "createdAt": "2018-11-19T18:45:50Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.sources.DataSourceRegister;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * The base interface for v2 data sources which don't have a real catalog. Implementations must\n+ * have a public, 0-arg constructor.\n+ *\n+ * The major responsibility of this interface is to return a {@link Table} for read/write.\n+ */\n+@InterfaceStability.Evolving\n+// TODO: do not extend `DataSourceV2`, after we finish the API refactor completely.\n+public interface TableProvider extends DataSourceV2 {\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified options.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   */\n+  Table getTable(DataSourceOptions options);\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified schema and options.\n+   *\n+   * By default this method throws {@link UnsupportedOperationException}, implementations should\n+   * override this method to handle user-specified schema.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   * @param schema the user-specified schema.\n+   */\n+  default Table getTable(DataSourceOptions options, StructType schema) {",
    "line": 54
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "Basically just saying we should just push down this requested schema into the `ScanBuilder`.",
    "commit": "eecb161075720aec0c496576fe6b6ad749c3a726",
    "createdAt": "2018-11-19T21:45:47Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.sources.DataSourceRegister;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * The base interface for v2 data sources which don't have a real catalog. Implementations must\n+ * have a public, 0-arg constructor.\n+ *\n+ * The major responsibility of this interface is to return a {@link Table} for read/write.\n+ */\n+@InterfaceStability.Evolving\n+// TODO: do not extend `DataSourceV2`, after we finish the API refactor completely.\n+public interface TableProvider extends DataSourceV2 {\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified options.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   */\n+  Table getTable(DataSourceOptions options);\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified schema and options.\n+   *\n+   * By default this method throws {@link UnsupportedOperationException}, implementations should\n+   * override this method to handle user-specified schema.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   * @param schema the user-specified schema.\n+   */\n+  default Table getTable(DataSourceOptions options, StructType schema) {",
    "line": 54
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "It's a different thing. Think about you are reading a parquet file, and you know exactly what its physical schema is, and you don't want Spark to waste a job to infer the schema. Then you can specify the schema when reading.\r\n\r\nNext, Spark will analyze the query, and figure out what the required schema is. This step is automatic and driven by Spark.",
    "commit": "eecb161075720aec0c496576fe6b6ad749c3a726",
    "createdAt": "2018-11-20T01:43:10Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.sources.DataSourceRegister;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * The base interface for v2 data sources which don't have a real catalog. Implementations must\n+ * have a public, 0-arg constructor.\n+ *\n+ * The major responsibility of this interface is to return a {@link Table} for read/write.\n+ */\n+@InterfaceStability.Evolving\n+// TODO: do not extend `DataSourceV2`, after we finish the API refactor completely.\n+public interface TableProvider extends DataSourceV2 {\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified options.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   */\n+  Table getTable(DataSourceOptions options);\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified schema and options.\n+   *\n+   * By default this method throws {@link UnsupportedOperationException}, implementations should\n+   * override this method to handle user-specified schema.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   * @param schema the user-specified schema.\n+   */\n+  default Table getTable(DataSourceOptions options, StructType schema) {",
    "line": 54
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "I agree with @cloud-fan. These are slightly different uses.\r\n\r\nHere, it is supplying a schema for how to interpret data files. Say you have CSV files with columns `id`, `ts`, and `data` and no headers. This tells the CSV reader what the columns are and how to convert the data to useful types (bigint, timestamp, and string). Column projection will later request those columns, maybe just `id` and `data`. If you only passed the projection schema, then the `ts` values would be returned for the `data` column.",
    "commit": "eecb161075720aec0c496576fe6b6ad749c3a726",
    "createdAt": "2018-11-27T19:43:48Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.sources.DataSourceRegister;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * The base interface for v2 data sources which don't have a real catalog. Implementations must\n+ * have a public, 0-arg constructor.\n+ *\n+ * The major responsibility of this interface is to return a {@link Table} for read/write.\n+ */\n+@InterfaceStability.Evolving\n+// TODO: do not extend `DataSourceV2`, after we finish the API refactor completely.\n+public interface TableProvider extends DataSourceV2 {\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified options.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   */\n+  Table getTable(DataSourceOptions options);\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified schema and options.\n+   *\n+   * By default this method throws {@link UnsupportedOperationException}, implementations should\n+   * override this method to handle user-specified schema.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   * @param schema the user-specified schema.\n+   */\n+  default Table getTable(DataSourceOptions options, StructType schema) {",
    "line": 54
  }],
  "prId": 23086
}, {
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "Javadoc would normally also add `@throws` with this information. I agree it should be here as well.",
    "commit": "eecb161075720aec0c496576fe6b6ad749c3a726",
    "createdAt": "2018-11-27T19:47:05Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import org.apache.spark.annotation.Evolving;\n+import org.apache.spark.sql.sources.DataSourceRegister;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * The base interface for v2 data sources which don't have a real catalog. Implementations must\n+ * have a public, 0-arg constructor.\n+ *\n+ * The major responsibility of this interface is to return a {@link Table} for read/write.\n+ */\n+@Evolving\n+// TODO: do not extend `DataSourceV2`, after we finish the API refactor completely.\n+public interface TableProvider extends DataSourceV2 {\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified options.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   */\n+  Table getTable(DataSourceOptions options);\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified schema and options.\n+   *\n+   * By default this method throws {@link UnsupportedOperationException}, implementations should",
    "line": 46
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "what I learned is that, we should only declare checked exceptions. See http://www.javapractices.com/topic/TopicAction.do?Id=171",
    "commit": "eecb161075720aec0c496576fe6b6ad749c3a726",
    "createdAt": "2018-11-28T13:17:25Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import org.apache.spark.annotation.Evolving;\n+import org.apache.spark.sql.sources.DataSourceRegister;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * The base interface for v2 data sources which don't have a real catalog. Implementations must\n+ * have a public, 0-arg constructor.\n+ *\n+ * The major responsibility of this interface is to return a {@link Table} for read/write.\n+ */\n+@Evolving\n+// TODO: do not extend `DataSourceV2`, after we finish the API refactor completely.\n+public interface TableProvider extends DataSourceV2 {\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified options.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   */\n+  Table getTable(DataSourceOptions options);\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified schema and options.\n+   *\n+   * By default this method throws {@link UnsupportedOperationException}, implementations should",
    "line": 46
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "Strange, that page links to one with the opposite advice: http://www.javapractices.com/topic/TopicAction.do?Id=44\r\n\r\nI think that `@throws` is a good idea whenever you want to document an exception type as part of the method contract. Since it is expected that this method isn't always implemented and may throw this exception, I think you were right to document it. And documenting exceptions is best done with `@throws` to highlight them in Javadoc.\r\n\r\nThe page you linked to makes the argument that unchecked exceptions aren't part of the method contract and cannot be relied on. But documenting this shows that it is part of the contract or expected behavior, so I think docs are appropriate.",
    "commit": "eecb161075720aec0c496576fe6b6ad749c3a726",
    "createdAt": "2018-11-28T17:03:55Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import org.apache.spark.annotation.Evolving;\n+import org.apache.spark.sql.sources.DataSourceRegister;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * The base interface for v2 data sources which don't have a real catalog. Implementations must\n+ * have a public, 0-arg constructor.\n+ *\n+ * The major responsibility of this interface is to return a {@link Table} for read/write.\n+ */\n+@Evolving\n+// TODO: do not extend `DataSourceV2`, after we finish the API refactor completely.\n+public interface TableProvider extends DataSourceV2 {\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified options.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   */\n+  Table getTable(DataSourceOptions options);\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified schema and options.\n+   *\n+   * By default this method throws {@link UnsupportedOperationException}, implementations should",
    "line": 46
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "added the throw clause.",
    "commit": "eecb161075720aec0c496576fe6b6ad749c3a726",
    "createdAt": "2018-11-29T03:55:39Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import org.apache.spark.annotation.Evolving;\n+import org.apache.spark.sql.sources.DataSourceRegister;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * The base interface for v2 data sources which don't have a real catalog. Implementations must\n+ * have a public, 0-arg constructor.\n+ *\n+ * The major responsibility of this interface is to return a {@link Table} for read/write.\n+ */\n+@Evolving\n+// TODO: do not extend `DataSourceV2`, after we finish the API refactor completely.\n+public interface TableProvider extends DataSourceV2 {\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified options.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   */\n+  Table getTable(DataSourceOptions options);\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified schema and options.\n+   *\n+   * By default this method throws {@link UnsupportedOperationException}, implementations should",
    "line": 46
  }],
  "prId": 23086
}, {
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "Minor: Javadoc doesn't automatically parse empty lines as new paragraphs. If you want to have one in documentation, then use `<p>`.",
    "commit": "eecb161075720aec0c496576fe6b6ad749c3a726",
    "createdAt": "2018-11-27T19:47:48Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import org.apache.spark.annotation.Evolving;\n+import org.apache.spark.sql.sources.DataSourceRegister;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * The base interface for v2 data sources which don't have a real catalog. Implementations must\n+ * have a public, 0-arg constructor.\n+ *\n+ * The major responsibility of this interface is to return a {@link Table} for read/write.\n+ */\n+@Evolving\n+// TODO: do not extend `DataSourceV2`, after we finish the API refactor completely.\n+public interface TableProvider extends DataSourceV2 {\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified options.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   */\n+  Table getTable(DataSourceOptions options);\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified schema and options.\n+   *"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "thanks for the hint about new paragraph!",
    "commit": "eecb161075720aec0c496576fe6b6ad749c3a726",
    "createdAt": "2018-11-28T13:21:55Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import org.apache.spark.annotation.Evolving;\n+import org.apache.spark.sql.sources.DataSourceRegister;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * The base interface for v2 data sources which don't have a real catalog. Implementations must\n+ * have a public, 0-arg constructor.\n+ *\n+ * The major responsibility of this interface is to return a {@link Table} for read/write.\n+ */\n+@Evolving\n+// TODO: do not extend `DataSourceV2`, after we finish the API refactor completely.\n+public interface TableProvider extends DataSourceV2 {\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified options.\n+   *\n+   * @param options the user-specified options that can identify a table, e.g. file path, Kafka\n+   *                topic name, etc. It's an immutable case-insensitive string-to-string map.\n+   */\n+  Table getTable(DataSourceOptions options);\n+\n+  /**\n+   * Return a {@link Table} instance to do read/write with user-specified schema and options.\n+   *"
  }],
  "prId": 23086
}]