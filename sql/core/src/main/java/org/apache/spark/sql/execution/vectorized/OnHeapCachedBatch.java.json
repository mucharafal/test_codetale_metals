[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "this looks weird that we put the value to a row and then read that value from the row, can we return that value directly? e.g. `columnAccessor.extractTo` should be able to take a `ColumnVector` as input and set value to it.",
    "commit": "a26dc150f6b95cc42558561cd2548de04a89f041",
    "createdAt": "2017-07-04T02:47:25Z",
    "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.vectorized;\n+\n+import java.nio.ByteBuffer;\n+\n+import org.apache.spark.memory.MemoryMode;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder;\n+import org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter;\n+import org.apache.spark.sql.execution.columnar.*;\n+import org.apache.spark.sql.types.*;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+/**\n+ * A column backed by an in memory JVM array.\n+ */\n+public final class OnHeapCachedBatch extends ColumnVector implements java.io.Serializable {\n+\n+  // keep compressed data\n+  private byte[] buffer;\n+\n+  // whether a row is already extracted or not. If extractTo() is called, set true\n+  // e.g. when isNullAt() and getInt() ara called, extractTo() must be called only once\n+  private boolean[] calledExtractTo;\n+\n+  // a row where the compressed data is extracted\n+  private transient UnsafeRow unsafeRow;\n+  private transient BufferHolder bufferHolder;\n+  private transient UnsafeRowWriter rowWriter;\n+  private transient MutableUnsafeRow mutableRow;\n+\n+  // accesssor for a column\n+  private transient ColumnAccessor columnAccessor;\n+\n+  // an accessor uses only column 0\n+  private final int ORDINAL = 0;\n+\n+  protected OnHeapCachedBatch(int capacity, DataType type) {\n+    super(capacity, type, MemoryMode.ON_HEAP_CACHEDBATCH);\n+    reserveInternal(capacity);\n+    reset();\n+  }\n+\n+  @Override\n+  public long valuesNativeAddress() {\n+    throw new RuntimeException(\"Cannot get native address for on heap column\");\n+  }\n+  @Override\n+  public long nullsNativeAddress() {\n+    throw new RuntimeException(\"Cannot get native address for on heap column\");\n+  }\n+\n+  @Override\n+  public void close() {\n+  }\n+\n+  private void initialize() {\n+    if (columnAccessor == null) {\n+      setColumnAccessor();\n+    }\n+    if (mutableRow == null) {\n+      setRowSetter();\n+    }\n+  }\n+\n+  private void setColumnAccessor() {\n+    ByteBuffer byteBuffer = ByteBuffer.wrap(buffer);\n+    columnAccessor = ColumnAccessor$.MODULE$.apply(type, byteBuffer);\n+    calledExtractTo = new boolean[capacity];\n+  }\n+\n+  private void setRowSetter() {\n+    unsafeRow = new UnsafeRow(1);\n+    bufferHolder = new BufferHolder(unsafeRow);\n+    rowWriter = new UnsafeRowWriter(bufferHolder, 1);\n+    mutableRow = new MutableUnsafeRow(rowWriter);\n+  }\n+\n+  // call extractTo() before getting actual data\n+  private void prepareRowAccess(int rowId) {"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "I agree with you. We can optimize these access by enhancing existing APIs.\r\nShould we address these extensions in this PR? In my original plan, I will address such an optimization in another PR.\r\n\r\nWhat do you think?",
    "commit": "a26dc150f6b95cc42558561cd2548de04a89f041",
    "createdAt": "2017-07-04T04:41:36Z",
    "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.vectorized;\n+\n+import java.nio.ByteBuffer;\n+\n+import org.apache.spark.memory.MemoryMode;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder;\n+import org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter;\n+import org.apache.spark.sql.execution.columnar.*;\n+import org.apache.spark.sql.types.*;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+/**\n+ * A column backed by an in memory JVM array.\n+ */\n+public final class OnHeapCachedBatch extends ColumnVector implements java.io.Serializable {\n+\n+  // keep compressed data\n+  private byte[] buffer;\n+\n+  // whether a row is already extracted or not. If extractTo() is called, set true\n+  // e.g. when isNullAt() and getInt() ara called, extractTo() must be called only once\n+  private boolean[] calledExtractTo;\n+\n+  // a row where the compressed data is extracted\n+  private transient UnsafeRow unsafeRow;\n+  private transient BufferHolder bufferHolder;\n+  private transient UnsafeRowWriter rowWriter;\n+  private transient MutableUnsafeRow mutableRow;\n+\n+  // accesssor for a column\n+  private transient ColumnAccessor columnAccessor;\n+\n+  // an accessor uses only column 0\n+  private final int ORDINAL = 0;\n+\n+  protected OnHeapCachedBatch(int capacity, DataType type) {\n+    super(capacity, type, MemoryMode.ON_HEAP_CACHEDBATCH);\n+    reserveInternal(capacity);\n+    reset();\n+  }\n+\n+  @Override\n+  public long valuesNativeAddress() {\n+    throw new RuntimeException(\"Cannot get native address for on heap column\");\n+  }\n+  @Override\n+  public long nullsNativeAddress() {\n+    throw new RuntimeException(\"Cannot get native address for on heap column\");\n+  }\n+\n+  @Override\n+  public void close() {\n+  }\n+\n+  private void initialize() {\n+    if (columnAccessor == null) {\n+      setColumnAccessor();\n+    }\n+    if (mutableRow == null) {\n+      setRowSetter();\n+    }\n+  }\n+\n+  private void setColumnAccessor() {\n+    ByteBuffer byteBuffer = ByteBuffer.wrap(buffer);\n+    columnAccessor = ColumnAccessor$.MODULE$.apply(type, byteBuffer);\n+    calledExtractTo = new boolean[capacity];\n+  }\n+\n+  private void setRowSetter() {\n+    unsafeRow = new UnsafeRow(1);\n+    bufferHolder = new BufferHolder(unsafeRow);\n+    rowWriter = new UnsafeRowWriter(bufferHolder, 1);\n+    mutableRow = new MutableUnsafeRow(rowWriter);\n+  }\n+\n+  // call extractTo() before getting actual data\n+  private void prepareRowAccess(int rowId) {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "This PR is building the infrastructure that not being used yet, so I think we don't need to rush.",
    "commit": "a26dc150f6b95cc42558561cd2548de04a89f041",
    "createdAt": "2017-07-04T06:10:11Z",
    "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.vectorized;\n+\n+import java.nio.ByteBuffer;\n+\n+import org.apache.spark.memory.MemoryMode;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder;\n+import org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter;\n+import org.apache.spark.sql.execution.columnar.*;\n+import org.apache.spark.sql.types.*;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+/**\n+ * A column backed by an in memory JVM array.\n+ */\n+public final class OnHeapCachedBatch extends ColumnVector implements java.io.Serializable {\n+\n+  // keep compressed data\n+  private byte[] buffer;\n+\n+  // whether a row is already extracted or not. If extractTo() is called, set true\n+  // e.g. when isNullAt() and getInt() ara called, extractTo() must be called only once\n+  private boolean[] calledExtractTo;\n+\n+  // a row where the compressed data is extracted\n+  private transient UnsafeRow unsafeRow;\n+  private transient BufferHolder bufferHolder;\n+  private transient UnsafeRowWriter rowWriter;\n+  private transient MutableUnsafeRow mutableRow;\n+\n+  // accesssor for a column\n+  private transient ColumnAccessor columnAccessor;\n+\n+  // an accessor uses only column 0\n+  private final int ORDINAL = 0;\n+\n+  protected OnHeapCachedBatch(int capacity, DataType type) {\n+    super(capacity, type, MemoryMode.ON_HEAP_CACHEDBATCH);\n+    reserveInternal(capacity);\n+    reset();\n+  }\n+\n+  @Override\n+  public long valuesNativeAddress() {\n+    throw new RuntimeException(\"Cannot get native address for on heap column\");\n+  }\n+  @Override\n+  public long nullsNativeAddress() {\n+    throw new RuntimeException(\"Cannot get native address for on heap column\");\n+  }\n+\n+  @Override\n+  public void close() {\n+  }\n+\n+  private void initialize() {\n+    if (columnAccessor == null) {\n+      setColumnAccessor();\n+    }\n+    if (mutableRow == null) {\n+      setRowSetter();\n+    }\n+  }\n+\n+  private void setColumnAccessor() {\n+    ByteBuffer byteBuffer = ByteBuffer.wrap(buffer);\n+    columnAccessor = ColumnAccessor$.MODULE$.apply(type, byteBuffer);\n+    calledExtractTo = new boolean[capacity];\n+  }\n+\n+  private void setRowSetter() {\n+    unsafeRow = new UnsafeRow(1);\n+    bufferHolder = new BufferHolder(unsafeRow);\n+    rowWriter = new UnsafeRowWriter(bufferHolder, 1);\n+    mutableRow = new MutableUnsafeRow(rowWriter);\n+  }\n+\n+  // call extractTo() before getting actual data\n+  private void prepareRowAccess(int rowId) {"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "I tried to make a set of pull request for ease of reviews.\r\nHowever, I will add the optimization to directly return the value without `UnsafeRow`.",
    "commit": "a26dc150f6b95cc42558561cd2548de04a89f041",
    "createdAt": "2017-07-04T07:05:04Z",
    "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.vectorized;\n+\n+import java.nio.ByteBuffer;\n+\n+import org.apache.spark.memory.MemoryMode;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder;\n+import org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter;\n+import org.apache.spark.sql.execution.columnar.*;\n+import org.apache.spark.sql.types.*;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+/**\n+ * A column backed by an in memory JVM array.\n+ */\n+public final class OnHeapCachedBatch extends ColumnVector implements java.io.Serializable {\n+\n+  // keep compressed data\n+  private byte[] buffer;\n+\n+  // whether a row is already extracted or not. If extractTo() is called, set true\n+  // e.g. when isNullAt() and getInt() ara called, extractTo() must be called only once\n+  private boolean[] calledExtractTo;\n+\n+  // a row where the compressed data is extracted\n+  private transient UnsafeRow unsafeRow;\n+  private transient BufferHolder bufferHolder;\n+  private transient UnsafeRowWriter rowWriter;\n+  private transient MutableUnsafeRow mutableRow;\n+\n+  // accesssor for a column\n+  private transient ColumnAccessor columnAccessor;\n+\n+  // an accessor uses only column 0\n+  private final int ORDINAL = 0;\n+\n+  protected OnHeapCachedBatch(int capacity, DataType type) {\n+    super(capacity, type, MemoryMode.ON_HEAP_CACHEDBATCH);\n+    reserveInternal(capacity);\n+    reset();\n+  }\n+\n+  @Override\n+  public long valuesNativeAddress() {\n+    throw new RuntimeException(\"Cannot get native address for on heap column\");\n+  }\n+  @Override\n+  public long nullsNativeAddress() {\n+    throw new RuntimeException(\"Cannot get native address for on heap column\");\n+  }\n+\n+  @Override\n+  public void close() {\n+  }\n+\n+  private void initialize() {\n+    if (columnAccessor == null) {\n+      setColumnAccessor();\n+    }\n+    if (mutableRow == null) {\n+      setRowSetter();\n+    }\n+  }\n+\n+  private void setColumnAccessor() {\n+    ByteBuffer byteBuffer = ByteBuffer.wrap(buffer);\n+    columnAccessor = ColumnAccessor$.MODULE$.apply(type, byteBuffer);\n+    calledExtractTo = new boolean[capacity];\n+  }\n+\n+  private void setRowSetter() {\n+    unsafeRow = new UnsafeRow(1);\n+    bufferHolder = new BufferHolder(unsafeRow);\n+    rowWriter = new UnsafeRowWriter(bufferHolder, 1);\n+    mutableRow = new MutableUnsafeRow(rowWriter);\n+  }\n+\n+  // call extractTo() before getting actual data\n+  private void prepareRowAccess(int rowId) {"
  }],
  "prId": 18468
}]