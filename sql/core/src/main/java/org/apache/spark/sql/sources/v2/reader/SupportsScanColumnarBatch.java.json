[{
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "`enableColumnarRead()` or `enableColumnarBatchRead()`?",
    "commit": "d6661104f314c88ff84057fd4830e7a5fbe964d9",
    "createdAt": "2018-01-09T17:47:00Z",
    "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader;\n+\n+import java.util.List;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.vectorized.ColumnarBatch;\n+\n+/**\n+ * A mix-in interface for {@link DataSourceV2Reader}. Data source readers can implement this\n+ * interface to output {@link ColumnarBatch} and make the scan faster.\n+ */\n+@InterfaceStability.Evolving\n+public interface SupportsScanColumnarBatch extends DataSourceV2Reader {\n+  @Override\n+  default List<ReadTask<Row>> createReadTasks() {\n+    throw new IllegalStateException(\n+      \"createReadTasks should not be called with SupportsScanColumnarBatch.\");\n+  }\n+\n+  /**\n+   * Similar to {@link DataSourceV2Reader#createReadTasks()}, but returns columnar data in batches.\n+   */\n+  List<ReadTask<ColumnarBatch>> createBatchReadTasks();\n+\n+  /**\n+   * A safety door for columnar batch reader. It's possible that the implementation can only support\n+   * some certain columns with certain types. Users can overwrite this method and\n+   * {@link #createReadTasks()} to fallback to normal read path under some conditions.\n+   */\n+  default boolean enableBatchRead() {"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "This name is more general. It looks fine to me. In the future, if we support another batch read mode, we can add the extra function to further identify the batch mode.",
    "commit": "d6661104f314c88ff84057fd4830e7a5fbe964d9",
    "createdAt": "2018-01-10T17:34:26Z",
    "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader;\n+\n+import java.util.List;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.vectorized.ColumnarBatch;\n+\n+/**\n+ * A mix-in interface for {@link DataSourceV2Reader}. Data source readers can implement this\n+ * interface to output {@link ColumnarBatch} and make the scan faster.\n+ */\n+@InterfaceStability.Evolving\n+public interface SupportsScanColumnarBatch extends DataSourceV2Reader {\n+  @Override\n+  default List<ReadTask<Row>> createReadTasks() {\n+    throw new IllegalStateException(\n+      \"createReadTasks should not be called with SupportsScanColumnarBatch.\");\n+  }\n+\n+  /**\n+   * Similar to {@link DataSourceV2Reader#createReadTasks()}, but returns columnar data in batches.\n+   */\n+  List<ReadTask<ColumnarBatch>> createBatchReadTasks();\n+\n+  /**\n+   * A safety door for columnar batch reader. It's possible that the implementation can only support\n+   * some certain columns with certain types. Users can overwrite this method and\n+   * {@link #createReadTasks()} to fallback to normal read path under some conditions.\n+   */\n+  default boolean enableBatchRead() {"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "If it controls batch mode or non-batch mode, I agree.  \r\n\r\nIIUC, this value is used to show whether we enable to read data from column-oriented storage (e.g. `ColumnarVector`) or  row-oriented storage (e.g. `UnsafeRow`). I feel that it is not a batch mode.",
    "commit": "d6661104f314c88ff84057fd4830e7a5fbe964d9",
    "createdAt": "2018-01-10T18:44:21Z",
    "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader;\n+\n+import java.util.List;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.vectorized.ColumnarBatch;\n+\n+/**\n+ * A mix-in interface for {@link DataSourceV2Reader}. Data source readers can implement this\n+ * interface to output {@link ColumnarBatch} and make the scan faster.\n+ */\n+@InterfaceStability.Evolving\n+public interface SupportsScanColumnarBatch extends DataSourceV2Reader {\n+  @Override\n+  default List<ReadTask<Row>> createReadTasks() {\n+    throw new IllegalStateException(\n+      \"createReadTasks should not be called with SupportsScanColumnarBatch.\");\n+  }\n+\n+  /**\n+   * Similar to {@link DataSourceV2Reader#createReadTasks()}, but returns columnar data in batches.\n+   */\n+  List<ReadTask<ColumnarBatch>> createBatchReadTasks();\n+\n+  /**\n+   * A safety door for columnar batch reader. It's possible that the implementation can only support\n+   * some certain columns with certain types. Users can overwrite this method and\n+   * {@link #createReadTasks()} to fallback to normal read path under some conditions.\n+   */\n+  default boolean enableBatchRead() {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "Yea you can interpret it in this way (read data from columnar storage or row storage), but we can also interpret it as reading a batch of records at a time or one record at a time.",
    "commit": "d6661104f314c88ff84057fd4830e7a5fbe964d9",
    "createdAt": "2018-01-11T13:32:15Z",
    "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader;\n+\n+import java.util.List;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.vectorized.ColumnarBatch;\n+\n+/**\n+ * A mix-in interface for {@link DataSourceV2Reader}. Data source readers can implement this\n+ * interface to output {@link ColumnarBatch} and make the scan faster.\n+ */\n+@InterfaceStability.Evolving\n+public interface SupportsScanColumnarBatch extends DataSourceV2Reader {\n+  @Override\n+  default List<ReadTask<Row>> createReadTasks() {\n+    throw new IllegalStateException(\n+      \"createReadTasks should not be called with SupportsScanColumnarBatch.\");\n+  }\n+\n+  /**\n+   * Similar to {@link DataSourceV2Reader#createReadTasks()}, but returns columnar data in batches.\n+   */\n+  List<ReadTask<ColumnarBatch>> createBatchReadTasks();\n+\n+  /**\n+   * A safety door for columnar batch reader. It's possible that the implementation can only support\n+   * some certain columns with certain types. Users can overwrite this method and\n+   * {@link #createReadTasks()} to fallback to normal read path under some conditions.\n+   */\n+  default boolean enableBatchRead() {"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "I see. It would be good to clarify it in the comment.\r\nFor example, Is this true? `A safety door for [[ColumnarBatch]] reader.`",
    "commit": "d6661104f314c88ff84057fd4830e7a5fbe964d9",
    "createdAt": "2018-01-13T03:24:27Z",
    "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader;\n+\n+import java.util.List;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.vectorized.ColumnarBatch;\n+\n+/**\n+ * A mix-in interface for {@link DataSourceV2Reader}. Data source readers can implement this\n+ * interface to output {@link ColumnarBatch} and make the scan faster.\n+ */\n+@InterfaceStability.Evolving\n+public interface SupportsScanColumnarBatch extends DataSourceV2Reader {\n+  @Override\n+  default List<ReadTask<Row>> createReadTasks() {\n+    throw new IllegalStateException(\n+      \"createReadTasks should not be called with SupportsScanColumnarBatch.\");\n+  }\n+\n+  /**\n+   * Similar to {@link DataSourceV2Reader#createReadTasks()}, but returns columnar data in batches.\n+   */\n+  List<ReadTask<ColumnarBatch>> createBatchReadTasks();\n+\n+  /**\n+   * A safety door for columnar batch reader. It's possible that the implementation can only support\n+   * some certain columns with certain types. Users can overwrite this method and\n+   * {@link #createReadTasks()} to fallback to normal read path under some conditions.\n+   */\n+  default boolean enableBatchRead() {"
  }],
  "prId": 20153
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "We need to explain the precedence of `SupportsScanColumnarBatch ` and `SupportsScanUnsafeRow`",
    "commit": "d6661104f314c88ff84057fd4830e7a5fbe964d9",
    "createdAt": "2018-01-10T17:32:19Z",
    "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader;\n+\n+import java.util.List;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.vectorized.ColumnarBatch;\n+\n+/**\n+ * A mix-in interface for {@link DataSourceV2Reader}. Data source readers can implement this\n+ * interface to output {@link ColumnarBatch} and make the scan faster.",
    "line": 28
  }],
  "prId": 20153
}, {
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "`createReadTasks not supported by default within SupportsScanColumnarBatch.`, since we allow users to fallback to normal read path.",
    "commit": "d6661104f314c88ff84057fd4830e7a5fbe964d9",
    "createdAt": "2018-01-11T07:04:05Z",
    "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader;\n+\n+import java.util.List;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.vectorized.ColumnarBatch;\n+\n+/**\n+ * A mix-in interface for {@link DataSourceV2Reader}. Data source readers can implement this\n+ * interface to output {@link ColumnarBatch} and make the scan faster.\n+ */\n+@InterfaceStability.Evolving\n+public interface SupportsScanColumnarBatch extends DataSourceV2Reader {\n+  @Override\n+  default List<ReadTask<Row>> createReadTasks() {\n+    throw new IllegalStateException(\n+      \"createReadTasks should not be called with SupportsScanColumnarBatch.\");"
  }],
  "prId": 20153
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "I feel it is hard to tell from the document that if this method is used to enable batch reading or to know if this reader support batch reading.",
    "commit": "d6661104f314c88ff84057fd4830e7a5fbe964d9",
    "createdAt": "2018-01-13T03:02:37Z",
    "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader;\n+\n+import java.util.List;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.vectorized.ColumnarBatch;\n+\n+/**\n+ * A mix-in interface for {@link DataSourceV2Reader}. Data source readers can implement this\n+ * interface to output {@link ColumnarBatch} and make the scan faster.\n+ */\n+@InterfaceStability.Evolving\n+public interface SupportsScanColumnarBatch extends DataSourceV2Reader {\n+  @Override\n+  default List<ReadTask<Row>> createReadTasks() {\n+    throw new IllegalStateException(\n+      \"createReadTasks not supported by default within SupportsScanColumnarBatch.\");\n+  }\n+\n+  /**\n+   * Similar to {@link DataSourceV2Reader#createReadTasks()}, but returns columnar data in batches.\n+   */\n+  List<ReadTask<ColumnarBatch>> createBatchReadTasks();\n+\n+  /**\n+   * A safety door for columnar batch reader. It's possible that the implementation can only support\n+   * some certain columns with certain types. Users can overwrite this method and\n+   * {@link #createReadTasks()} to fallback to normal read path under some conditions.\n+   */\n+  default boolean enableBatchRead() {"
  }],
  "prId": 20153
}]