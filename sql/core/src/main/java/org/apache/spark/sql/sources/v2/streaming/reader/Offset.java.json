[{
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "ditto",
    "commit": "3b3029bdaf6f36e02cfc3c493c42e39cc86c3057",
    "createdAt": "2018-01-17T07:53:28Z",
    "diffHunk": "@@ -17,12 +17,20 @@\n \n package org.apache.spark.sql.sources.v2.streaming.reader;\n \n+import org.apache.spark.annotation.InterfaceStability;\n+\n /**\n- * An abstract representation of progress through a [[MicroBatchReader]] or [[ContinuousReader]].\n- * During execution, Offsets provided by the data source implementation will be logged and used as\n- * restart checkpoints. Sources should provide an Offset implementation which they can use to\n- * reconstruct the stream position where the offset was taken.\n+ * An abstract representation of progress through a {@link MicroBatchReader} or\n+ * {@link ContinuousReader}.\n+ * During execution, offsets provided by the data source implementation will be logged and used as\n+ * restart checkpoints. Each source should provide an offset implementation which the source can use\n+ * to reconstruct a position in the stream up to which data has been seen/processed.\n+ *\n+ * Note: This class currently extends {@link org.apache.spark.sql.execution.streaming.Offset} to\n+ * maintain compatibility with DataSource V1 APIs. This will be extension will be removed once we"
  }],
  "prId": 20286
}]