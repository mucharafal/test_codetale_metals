[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "not a big deal, but this is old c++ habit :)\n",
    "commit": "e0f427f9d4083068fefaed6a29719f0a7eeb22b3",
    "createdAt": "2016-01-15T05:26:29Z",
    "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet;\n+\n+import org.apache.parquet.Preconditions;\n+import org.apache.parquet.bytes.BytesUtils;\n+import org.apache.parquet.column.values.ValuesReader;\n+import org.apache.parquet.column.values.bitpacking.BytePacker;\n+import org.apache.parquet.column.values.bitpacking.Packer;\n+import org.apache.parquet.io.ParquetDecodingException;\n+import org.apache.spark.sql.execution.vectorized.ColumnVector;\n+\n+/**\n+ * A values reader for Parquet's run-length encoded data. This is based off of the version in\n+ * parquet-mr with these changes:\n+ *  - Supports the vectorized interface.\n+ *  - Works on byte arrays(byte[]) instead of making byte streams.\n+ *\n+ * This encoding is used in multiple places:\n+ *  - Definition/Repetition levels\n+ *  - Dictionary ids.\n+ */\n+public final class VectorizedRleValuesReader extends ValuesReader {\n+  // Current decoding mode.\n+  private enum MODE {\n+    RLE,\n+    PACKED\n+  }\n+\n+  // Encoded data.\n+  private byte[] in;\n+  private int end;\n+  private int offset;\n+\n+  // bit/byte width of decoded data and utility to batch unpack them.\n+  private int bitWidth;\n+  private int bytesWidth;\n+  private BytePacker packer;\n+\n+  // Current decoding mode and values\n+  private MODE mode;\n+  private int currentCount;\n+  private int currentValue;\n+\n+  // Buffer of decoded values if the values are PACKED.\n+  private int[] currentBuffer = new int[16];\n+  private int currentBufferIdx = 0;\n+\n+  // If true, the bit width is fixed. This decoder is used in different places and this also\n+  // controls if we need to read the bitwidth from the beginning of the data stream.\n+  private final boolean fixedWidth;\n+\n+  public VectorizedRleValuesReader() {\n+    fixedWidth = false;\n+  }\n+\n+  public VectorizedRleValuesReader(int bitWidth) {\n+    fixedWidth = true;\n+    init(bitWidth);\n+  }\n+\n+  @Override\n+  public void initFromPage(int valueCount, byte[] page, int start) {\n+    this.offset = start;\n+    this.in = page;\n+    if (fixedWidth) {\n+      int length = readIntLittleEndian();\n+      this.end = this.offset + length;\n+    } else {\n+      this.end = page.length;\n+      if (this.end != this.offset) init(page[this.offset++] & 255);\n+    }\n+    this.currentCount = 0;\n+  }\n+\n+  /**\n+   * Initializes the internal state for decoding ints of `bitWidth`.\n+   */\n+  private void init(int bitWidth) {\n+    Preconditions.checkArgument(bitWidth >= 0 && bitWidth <= 32, \"bitWidth must be >= 0 and <= 32\");\n+    this.bitWidth = bitWidth;\n+    this.bytesWidth = BytesUtils.paddedByteCountFromBits(bitWidth);\n+    this.packer = Packer.LITTLE_ENDIAN.newBytePacker(bitWidth);\n+  }\n+\n+  @Override\n+  public int getNextOffset() {\n+    return this.end;\n+  }\n+\n+  @Override\n+  public boolean readBoolean() {\n+    return this.readInteger() != 0;\n+  }\n+\n+  @Override\n+  public void skip() {\n+    this.readInteger();\n+  }\n+\n+  @Override\n+  public int readValueDictionaryId() {\n+    return readInteger();\n+  }\n+\n+  @Override\n+  public int readInteger() {\n+    if (this.currentCount == 0) { this.readNextGroup(); }\n+\n+    --this.currentCount;"
  }],
  "prId": 10593
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "add some comment to explain the difference between RLE and PACKED? for people that are not as familiar with Parquet.\n",
    "commit": "e0f427f9d4083068fefaed6a29719f0a7eeb22b3",
    "createdAt": "2016-01-15T05:27:02Z",
    "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet;\n+\n+import org.apache.parquet.Preconditions;\n+import org.apache.parquet.bytes.BytesUtils;\n+import org.apache.parquet.column.values.ValuesReader;\n+import org.apache.parquet.column.values.bitpacking.BytePacker;\n+import org.apache.parquet.column.values.bitpacking.Packer;\n+import org.apache.parquet.io.ParquetDecodingException;\n+import org.apache.spark.sql.execution.vectorized.ColumnVector;\n+\n+/**\n+ * A values reader for Parquet's run-length encoded data. This is based off of the version in\n+ * parquet-mr with these changes:\n+ *  - Supports the vectorized interface.\n+ *  - Works on byte arrays(byte[]) instead of making byte streams.\n+ *\n+ * This encoding is used in multiple places:\n+ *  - Definition/Repetition levels\n+ *  - Dictionary ids.\n+ */\n+public final class VectorizedRleValuesReader extends ValuesReader {\n+  // Current decoding mode.\n+  private enum MODE {\n+    RLE,"
  }],
  "prId": 10593
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "question: does parquet always pass byte arrays around for pages?\n",
    "commit": "e0f427f9d4083068fefaed6a29719f0a7eeb22b3",
    "createdAt": "2016-01-15T05:28:19Z",
    "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet;\n+\n+import org.apache.parquet.Preconditions;\n+import org.apache.parquet.bytes.BytesUtils;\n+import org.apache.parquet.column.values.ValuesReader;\n+import org.apache.parquet.column.values.bitpacking.BytePacker;\n+import org.apache.parquet.column.values.bitpacking.Packer;\n+import org.apache.parquet.io.ParquetDecodingException;\n+import org.apache.spark.sql.execution.vectorized.ColumnVector;\n+\n+/**\n+ * A values reader for Parquet's run-length encoded data. This is based off of the version in\n+ * parquet-mr with these changes:\n+ *  - Supports the vectorized interface.\n+ *  - Works on byte arrays(byte[]) instead of making byte streams.\n+ *\n+ * This encoding is used in multiple places:\n+ *  - Definition/Repetition levels\n+ *  - Dictionary ids.\n+ */\n+public final class VectorizedRleValuesReader extends ValuesReader {\n+  // Current decoding mode.\n+  private enum MODE {\n+    RLE,\n+    PACKED\n+  }\n+\n+  // Encoded data.\n+  private byte[] in;\n+  private int end;\n+  private int offset;\n+\n+  // bit/byte width of decoded data and utility to batch unpack them.\n+  private int bitWidth;\n+  private int bytesWidth;\n+  private BytePacker packer;\n+\n+  // Current decoding mode and values\n+  private MODE mode;\n+  private int currentCount;\n+  private int currentValue;\n+\n+  // Buffer of decoded values if the values are PACKED.\n+  private int[] currentBuffer = new int[16];\n+  private int currentBufferIdx = 0;\n+\n+  // If true, the bit width is fixed. This decoder is used in different places and this also\n+  // controls if we need to read the bitwidth from the beginning of the data stream.\n+  private final boolean fixedWidth;\n+\n+  public VectorizedRleValuesReader() {\n+    fixedWidth = false;\n+  }\n+\n+  public VectorizedRleValuesReader(int bitWidth) {\n+    fixedWidth = true;\n+    init(bitWidth);\n+  }\n+\n+  @Override\n+  public void initFromPage(int valueCount, byte[] page, int start) {",
    "line": 81
  }, {
    "author": {
      "login": "nongli"
    },
    "body": "I'm not sure what it is in master. There was some effort to use ByteBuffer that was merged recently.\n",
    "commit": "e0f427f9d4083068fefaed6a29719f0a7eeb22b3",
    "createdAt": "2016-01-15T19:30:26Z",
    "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet;\n+\n+import org.apache.parquet.Preconditions;\n+import org.apache.parquet.bytes.BytesUtils;\n+import org.apache.parquet.column.values.ValuesReader;\n+import org.apache.parquet.column.values.bitpacking.BytePacker;\n+import org.apache.parquet.column.values.bitpacking.Packer;\n+import org.apache.parquet.io.ParquetDecodingException;\n+import org.apache.spark.sql.execution.vectorized.ColumnVector;\n+\n+/**\n+ * A values reader for Parquet's run-length encoded data. This is based off of the version in\n+ * parquet-mr with these changes:\n+ *  - Supports the vectorized interface.\n+ *  - Works on byte arrays(byte[]) instead of making byte streams.\n+ *\n+ * This encoding is used in multiple places:\n+ *  - Definition/Repetition levels\n+ *  - Dictionary ids.\n+ */\n+public final class VectorizedRleValuesReader extends ValuesReader {\n+  // Current decoding mode.\n+  private enum MODE {\n+    RLE,\n+    PACKED\n+  }\n+\n+  // Encoded data.\n+  private byte[] in;\n+  private int end;\n+  private int offset;\n+\n+  // bit/byte width of decoded data and utility to batch unpack them.\n+  private int bitWidth;\n+  private int bytesWidth;\n+  private BytePacker packer;\n+\n+  // Current decoding mode and values\n+  private MODE mode;\n+  private int currentCount;\n+  private int currentValue;\n+\n+  // Buffer of decoded values if the values are PACKED.\n+  private int[] currentBuffer = new int[16];\n+  private int currentBufferIdx = 0;\n+\n+  // If true, the bit width is fixed. This decoder is used in different places and this also\n+  // controls if we need to read the bitwidth from the beginning of the data stream.\n+  private final boolean fixedWidth;\n+\n+  public VectorizedRleValuesReader() {\n+    fixedWidth = false;\n+  }\n+\n+  public VectorizedRleValuesReader(int bitWidth) {\n+    fixedWidth = true;\n+    init(bitWidth);\n+  }\n+\n+  @Override\n+  public void initFromPage(int valueCount, byte[] page, int start) {",
    "line": 81
  }],
  "prId": 10593
}]