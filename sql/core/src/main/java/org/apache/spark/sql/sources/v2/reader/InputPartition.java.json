[{
  "comments": [{
    "author": {
      "login": "jose-torres"
    },
    "body": "I'm not sure we need to talk about \"data split\" - I don't think people will try to implement data sources without knowing what a partition is in Spark.\r\n\r\nI'd suggest saying \"A serializable representation of an input partition...\", to make it clear that this should just contain metadata required to identify what the partition is and not the actual data.",
    "commit": "51cda76897353344427aaa666e29be408263eeb1",
    "createdAt": "2018-08-09T16:02:57Z",
    "diffHunk": "@@ -22,18 +22,16 @@\n import org.apache.spark.annotation.InterfaceStability;\n \n /**\n- * An input partition returned by {@link DataSourceReader#planInputPartitions()} and is\n- * responsible for creating the actual data reader of one RDD partition.\n- * The relationship between {@link InputPartition} and {@link InputPartitionReader}\n- * is similar to the relationship between {@link Iterable} and {@link java.util.Iterator}.\n+ * An input partition returned by {@link ReadSupport#planInputPartitions(ScanConfig)}, which\n+ * represents a data split that should be processed by one Spark task."
  }],
  "prId": 22009
}]