[{
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "Could you please let us know which test cases are failed due to this code on `s390x`?",
    "commit": "9aa423f7e1e82cfc9b3046637ae35140ece6c960",
    "createdAt": "2019-06-04T09:35:49Z",
    "diffHunk": "@@ -396,7 +396,7 @@ public void putFloats(int rowId, int count, byte[] src, int srcIndex) {\n       Platform.copyMemory(src, Platform.BYTE_ARRAY_OFFSET + srcIndex, floatData,\n           Platform.DOUBLE_ARRAY_OFFSET + rowId * 4L, count * 4L);\n     } else {\n-      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.LITTLE_ENDIAN);\n+      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.BIG_ENDIAN);",
    "line": 5
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "This change looks risky. Any reason?",
    "commit": "9aa423f7e1e82cfc9b3046637ae35140ece6c960",
    "createdAt": "2019-06-04T21:36:58Z",
    "diffHunk": "@@ -396,7 +396,7 @@ public void putFloats(int rowId, int count, byte[] src, int srcIndex) {\n       Platform.copyMemory(src, Platform.BYTE_ARRAY_OFFSET + srcIndex, floatData,\n           Platform.DOUBLE_ARRAY_OFFSET + rowId * 4L, count * 4L);\n     } else {\n-      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.LITTLE_ENDIAN);\n+      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.BIG_ENDIAN);",
    "line": 5
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "I agree. Once we know the test cases that cause failures, I will double-check by running them on another big endian environment.",
    "commit": "9aa423f7e1e82cfc9b3046637ae35140ece6c960",
    "createdAt": "2019-06-05T02:29:26Z",
    "diffHunk": "@@ -396,7 +396,7 @@ public void putFloats(int rowId, int count, byte[] src, int srcIndex) {\n       Platform.copyMemory(src, Platform.BYTE_ARRAY_OFFSET + srcIndex, floatData,\n           Platform.DOUBLE_ARRAY_OFFSET + rowId * 4L, count * 4L);\n     } else {\n-      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.LITTLE_ENDIAN);\n+      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.BIG_ENDIAN);",
    "line": 5
  }, {
    "author": {
      "login": "ketank-new"
    },
    "body": "below are the test suites which had some test failing initially and then passed on doing the above source code changes\r\n\r\nspark/sql/core/src/test/scala/org/apache/spark/sql/execution/columnar/compression/PassThroughEncodingSuite.scala\r\n\r\nspark/sql/core/src/test/scala/org/apache/spark/sql/execution/vectorized/ColumnVectorSuite.scala\r\n\r\nspark/sql/core/src/test/scala/org/apache/spark/sql/execution/columnar/InMemoryColumnarQuerySuite.scala\r\n\r\nspark/sql/core/src/test/scala/org/apache/spark/sql/DataFrameTungstenSuite.scala",
    "commit": "9aa423f7e1e82cfc9b3046637ae35140ece6c960",
    "createdAt": "2019-06-06T14:54:15Z",
    "diffHunk": "@@ -396,7 +396,7 @@ public void putFloats(int rowId, int count, byte[] src, int srcIndex) {\n       Platform.copyMemory(src, Platform.BYTE_ARRAY_OFFSET + srcIndex, floatData,\n           Platform.DOUBLE_ARRAY_OFFSET + rowId * 4L, count * 4L);\n     } else {\n-      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.LITTLE_ENDIAN);\n+      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.BIG_ENDIAN);",
    "line": 5
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Hm, I guess the changes make sense? we don't test the big-endian branch on Jenkins, so I'm not surprised it still passes Jenkins. For a big-endian platform, indeed, wouldn't you have to read floats from the ByteBuffer as big-endian?",
    "commit": "9aa423f7e1e82cfc9b3046637ae35140ece6c960",
    "createdAt": "2019-06-06T15:27:17Z",
    "diffHunk": "@@ -396,7 +396,7 @@ public void putFloats(int rowId, int count, byte[] src, int srcIndex) {\n       Platform.copyMemory(src, Platform.BYTE_ARRAY_OFFSET + srcIndex, floatData,\n           Platform.DOUBLE_ARRAY_OFFSET + rowId * 4L, count * 4L);\n     } else {\n-      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.LITTLE_ENDIAN);\n+      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.BIG_ENDIAN);",
    "line": 5
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "Thanks, I will test them on ppc64 linux (BE).",
    "commit": "9aa423f7e1e82cfc9b3046637ae35140ece6c960",
    "createdAt": "2019-06-06T16:39:29Z",
    "diffHunk": "@@ -396,7 +396,7 @@ public void putFloats(int rowId, int count, byte[] src, int srcIndex) {\n       Platform.copyMemory(src, Platform.BYTE_ARRAY_OFFSET + srcIndex, floatData,\n           Platform.DOUBLE_ARRAY_OFFSET + rowId * 4L, count * 4L);\n     } else {\n-      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.LITTLE_ENDIAN);\n+      ByteBuffer bb = ByteBuffer.wrap(src).order(ByteOrder.BIG_ENDIAN);",
    "line": 5
  }],
  "prId": 24788
}]