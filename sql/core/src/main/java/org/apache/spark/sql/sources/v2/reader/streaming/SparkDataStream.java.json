[{
  "comments": [{
    "author": {
      "login": "arunmahadevan"
    },
    "body": "Why do we need an additional level? Cant this be part of the micro batch physical scan (MicroBatchStream)",
    "commit": "5a4047e84a1e46a247a962137e77cf83390200aa",
    "createdAt": "2019-01-02T23:09:38Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader.streaming;\n+\n+import org.apache.spark.annotation.Evolving;\n+import org.apache.spark.sql.execution.streaming.BaseStreamingSource;\n+\n+/**\n+ * The base interface representing a readable data stream in a Spark streaming query. It's\n+ * responsible to manage the offsets of the streaming source in the streaming query.\n+ *\n+ * Data sources should implement concrete data stream interfaces: {@link MicroBatchStream}.\n+ */\n+@Evolving\n+public interface SparkDataStream extends BaseStreamingSource {",
    "line": 30
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "This is for `ContinuousStream` which will be added later. Please refer to the [doc](https://docs.google.com/document/d/1uUmKCpWLdh9vHxP7AWJ9EgbwB_U6T3EJYNjhISGmiQg/edit#) for more details.",
    "commit": "5a4047e84a1e46a247a962137e77cf83390200aa",
    "createdAt": "2019-01-03T02:59:24Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader.streaming;\n+\n+import org.apache.spark.annotation.Evolving;\n+import org.apache.spark.sql.execution.streaming.BaseStreamingSource;\n+\n+/**\n+ * The base interface representing a readable data stream in a Spark streaming query. It's\n+ * responsible to manage the offsets of the streaming source in the streaming query.\n+ *\n+ * Data sources should implement concrete data stream interfaces: {@link MicroBatchStream}.\n+ */\n+@Evolving\n+public interface SparkDataStream extends BaseStreamingSource {",
    "line": 30
  }, {
    "author": {
      "login": "arunmahadevan"
    },
    "body": "Makes sense. A Stream (a stream of events) and Source typically imply different things. In this case the `SparkDataStream` looks to be more of a source specific thing than a stream.",
    "commit": "5a4047e84a1e46a247a962137e77cf83390200aa",
    "createdAt": "2019-01-03T18:40:04Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2.reader.streaming;\n+\n+import org.apache.spark.annotation.Evolving;\n+import org.apache.spark.sql.execution.streaming.BaseStreamingSource;\n+\n+/**\n+ * The base interface representing a readable data stream in a Spark streaming query. It's\n+ * responsible to manage the offsets of the streaming source in the streaming query.\n+ *\n+ * Data sources should implement concrete data stream interfaces: {@link MicroBatchStream}.\n+ */\n+@Evolving\n+public interface SparkDataStream extends BaseStreamingSource {",
    "line": 30
  }],
  "prId": 23430
}]