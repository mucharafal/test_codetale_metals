[{
  "comments": [{
    "author": {
      "login": "brkyvz"
    },
    "body": "to this **sink**? not source",
    "commit": "3cb6ceec48b34523ac0c58e39a4825d629b56938",
    "createdAt": "2017-12-08T17:47:40Z",
    "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import java.util.Optional;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.execution.streaming.BaseStreamingSink;\n+import org.apache.spark.sql.sources.v2.writer.DataSourceV2Writer;\n+import org.apache.spark.sql.streaming.OutputMode;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * A mix-in interface for {@link DataSourceV2}. Data sources can implement this interface to\n+ * provide data writing ability and save the data from a microbatch to the data source.\n+ */\n+@InterfaceStability.Evolving\n+public interface MicroBatchWriteSupport extends BaseStreamingSink {\n+\n+  /**\n+   * Creates an optional {@link DataSourceV2Writer} to save the data to this data source. Data\n+   * sources can return None if there is no writing needed to be done.\n+   *\n+   * @param queryId A unique string for the writing query. It's possible that there are many writing\n+   *                queries running at the same time, and the returned {@link DataSourceV2Writer}\n+   *                can use this id to distinguish itself from others.\n+   * @param epochId The uniquenumeric ID of the batch within this writing query. This is an\n+   *                incrementing counter representing a consistent set of data; the same batch may\n+   *                be started multiple times in failure recovery scenarios, but it will always\n+   *                contain the same records.\n+   * @param schema the schema of the data to be written.\n+   * @param mode the output mode which determines what successive batch output means to this\n+   *             source, please refer to {@link OutputMode} for more details."
  }, {
    "author": {
      "login": "jose-torres"
    },
    "body": "Good point. Fixed here and in ContinuousWriteSupport.",
    "commit": "3cb6ceec48b34523ac0c58e39a4825d629b56938",
    "createdAt": "2017-12-08T20:20:12Z",
    "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import java.util.Optional;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.execution.streaming.BaseStreamingSink;\n+import org.apache.spark.sql.sources.v2.writer.DataSourceV2Writer;\n+import org.apache.spark.sql.streaming.OutputMode;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * A mix-in interface for {@link DataSourceV2}. Data sources can implement this interface to\n+ * provide data writing ability and save the data from a microbatch to the data source.\n+ */\n+@InterfaceStability.Evolving\n+public interface MicroBatchWriteSupport extends BaseStreamingSink {\n+\n+  /**\n+   * Creates an optional {@link DataSourceV2Writer} to save the data to this data source. Data\n+   * sources can return None if there is no writing needed to be done.\n+   *\n+   * @param queryId A unique string for the writing query. It's possible that there are many writing\n+   *                queries running at the same time, and the returned {@link DataSourceV2Writer}\n+   *                can use this id to distinguish itself from others.\n+   * @param epochId The uniquenumeric ID of the batch within this writing query. This is an\n+   *                incrementing counter representing a consistent set of data; the same batch may\n+   *                be started multiple times in failure recovery scenarios, but it will always\n+   *                contain the same records.\n+   * @param schema the schema of the data to be written.\n+   * @param mode the output mode which determines what successive batch output means to this\n+   *             source, please refer to {@link OutputMode} for more details."
  }],
  "prId": 19925
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "typo: `unique numeric`",
    "commit": "3cb6ceec48b34523ac0c58e39a4825d629b56938",
    "createdAt": "2017-12-14T07:33:29Z",
    "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.sources.v2;\n+\n+import java.util.Optional;\n+\n+import org.apache.spark.annotation.InterfaceStability;\n+import org.apache.spark.sql.execution.streaming.BaseStreamingSink;\n+import org.apache.spark.sql.sources.v2.writer.DataSourceV2Writer;\n+import org.apache.spark.sql.streaming.OutputMode;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * A mix-in interface for {@link DataSourceV2}. Data sources can implement this interface to\n+ * provide data writing ability and save the data from a microbatch to the data source.\n+ */\n+@InterfaceStability.Evolving\n+public interface MicroBatchWriteSupport extends BaseStreamingSink {\n+\n+  /**\n+   * Creates an optional {@link DataSourceV2Writer} to save the data to this data source. Data\n+   * sources can return None if there is no writing needed to be done.\n+   *\n+   * @param queryId A unique string for the writing query. It's possible that there are many writing\n+   *                queries running at the same time, and the returned {@link DataSourceV2Writer}\n+   *                can use this id to distinguish itself from others.\n+   * @param epochId The uniquenumeric ID of the batch within this writing query. This is an",
    "line": 42
  }],
  "prId": 19925
}]