[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "what's the rationale behind this renaming?",
    "commit": "42d86e1553f345c9879b40b1c20a2addbaf69781",
    "createdAt": "2018-07-07T04:51:06Z",
    "diffHunk": "@@ -38,15 +38,16 @@\n    * If this method fails (by throwing an exception), the action will fail and no Spark job will be\n    * submitted.\n    *\n-   * @param jobId A unique string for the writing job. It's possible that there are many writing\n-   *              jobs running at the same time, and the returned {@link DataSourceWriter} can\n-   *              use this job id to distinguish itself from other jobs.\n+   * @param writeUUID A unique string for the writing job. It's possible that there are many writing",
    "line": 7
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "This is not the ID of the Spark job that is writing. I think the UUID name is more clear about what is actually passed, a unique string that identifies the write. There's also no need to make the string more complicated than a UUID since there are no guarantees about it.",
    "commit": "42d86e1553f345c9879b40b1c20a2addbaf69781",
    "createdAt": "2018-07-07T23:20:50Z",
    "diffHunk": "@@ -38,15 +38,16 @@\n    * If this method fails (by throwing an exception), the action will fail and no Spark job will be\n    * submitted.\n    *\n-   * @param jobId A unique string for the writing job. It's possible that there are many writing\n-   *              jobs running at the same time, and the returned {@link DataSourceWriter} can\n-   *              use this job id to distinguish itself from other jobs.\n+   * @param writeUUID A unique string for the writing job. It's possible that there are many writing",
    "line": 7
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "This is removed in the v2 API redesign.",
    "commit": "42d86e1553f345c9879b40b1c20a2addbaf69781",
    "createdAt": "2018-08-01T18:07:48Z",
    "diffHunk": "@@ -38,15 +38,16 @@\n    * If this method fails (by throwing an exception), the action will fail and no Spark job will be\n    * submitted.\n    *\n-   * @param jobId A unique string for the writing job. It's possible that there are many writing\n-   *              jobs running at the same time, and the returned {@link DataSourceWriter} can\n-   *              use this job id to distinguish itself from other jobs.\n+   * @param writeUUID A unique string for the writing job. It's possible that there are many writing",
    "line": 7
  }],
  "prId": 21305
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "non-append cases also call this `createWriter`, shall we remove this line?",
    "commit": "42d86e1553f345c9879b40b1c20a2addbaf69781",
    "createdAt": "2018-08-01T03:48:06Z",
    "diffHunk": "@@ -38,15 +38,16 @@\n    * If this method fails (by throwing an exception), the action will fail and no Spark job will be\n    * submitted.\n    *\n-   * @param jobId A unique string for the writing job. It's possible that there are many writing\n-   *              jobs running at the same time, and the returned {@link DataSourceWriter} can\n-   *              use this job id to distinguish itself from other jobs.\n+   * @param writeUUID A unique string for the writing job. It's possible that there are many writing\n+   *                  jobs running at the same time, and the returned {@link DataSourceWriter} can\n+   *                  use this job id to distinguish itself from other jobs.\n    * @param schema the schema of the data to be written.\n    * @param mode the save mode which determines what to do when the data are already in this data\n    *             source, please refer to {@link SaveMode} for more details.\n    * @param options the options for the returned data source writer, which is an immutable\n    *                case-insensitive string-to-string map.\n+   * @return a writer to append data to this data source",
    "line": 15
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "The data source API only handles writes/appends and reads. The high-level logical combine append writes with other operations.",
    "commit": "42d86e1553f345c9879b40b1c20a2addbaf69781",
    "createdAt": "2018-08-01T18:09:13Z",
    "diffHunk": "@@ -38,15 +38,16 @@\n    * If this method fails (by throwing an exception), the action will fail and no Spark job will be\n    * submitted.\n    *\n-   * @param jobId A unique string for the writing job. It's possible that there are many writing\n-   *              jobs running at the same time, and the returned {@link DataSourceWriter} can\n-   *              use this job id to distinguish itself from other jobs.\n+   * @param writeUUID A unique string for the writing job. It's possible that there are many writing\n+   *                  jobs running at the same time, and the returned {@link DataSourceWriter} can\n+   *                  use this job id to distinguish itself from other jobs.\n    * @param schema the schema of the data to be written.\n    * @param mode the save mode which determines what to do when the data are already in this data\n    *             source, please refer to {@link SaveMode} for more details.\n    * @param options the options for the returned data source writer, which is an immutable\n    *                case-insensitive string-to-string map.\n+   * @return a writer to append data to this data source",
    "line": 15
  }],
  "prId": 21305
}]