[{
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "`assertCached` `joined` here.\n",
    "commit": "b8d287a84f354bcf59e7c258f912c55bff3da32a",
    "createdAt": "2015-11-30T23:50:35Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import scala.language.postfixOps\n+\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+\n+class CacheSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  test(\"persist and unpersist\") {\n+    val ds = Seq((\"a\", 1) , (\"b\", 2), (\"c\", 3)).toDS().select(expr(\"_2 + 1\").as[Int])\n+    val cached = ds.cache()\n+    // count triggers the caching action. It should not throw.\n+    cached.count()\n+    // Make sure, the Dataset is indeed cached.\n+    assertCached(cached)\n+    // Check result.\n+    checkAnswer(\n+      cached,\n+      2, 3, 4)\n+    // Drop the cache.\n+    cached.unpersist()\n+    assert(!sqlContext.isCached(cached), \"The Dataset should not be cached.\")\n+  }\n+\n+  test(\"persist and then rebind right encoder when join 2 datasets\") {\n+    val ds1 = Seq(\"1\", \"2\").toDS().as(\"a\")\n+    val ds2 = Seq(2, 3).toDS().as(\"b\")\n+\n+    ds1.persist()\n+    assertCached(ds1)\n+    ds2.persist()\n+    assertCached(ds2)\n+\n+    val joined = ds1.joinWith(ds2, $\"a.value\" === $\"b.value\")"
  }],
  "prId": 9889
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "`assertCached` `agged.filter(_._1 == \"b\")` here.\n",
    "commit": "b8d287a84f354bcf59e7c258f912c55bff3da32a",
    "createdAt": "2015-11-30T23:51:07Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import scala.language.postfixOps\n+\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+\n+class CacheSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  test(\"persist and unpersist\") {\n+    val ds = Seq((\"a\", 1) , (\"b\", 2), (\"c\", 3)).toDS().select(expr(\"_2 + 1\").as[Int])\n+    val cached = ds.cache()\n+    // count triggers the caching action. It should not throw.\n+    cached.count()\n+    // Make sure, the Dataset is indeed cached.\n+    assertCached(cached)\n+    // Check result.\n+    checkAnswer(\n+      cached,\n+      2, 3, 4)\n+    // Drop the cache.\n+    cached.unpersist()\n+    assert(!sqlContext.isCached(cached), \"The Dataset should not be cached.\")\n+  }\n+\n+  test(\"persist and then rebind right encoder when join 2 datasets\") {\n+    val ds1 = Seq(\"1\", \"2\").toDS().as(\"a\")\n+    val ds2 = Seq(2, 3).toDS().as(\"b\")\n+\n+    ds1.persist()\n+    assertCached(ds1)\n+    ds2.persist()\n+    assertCached(ds2)\n+\n+    val joined = ds1.joinWith(ds2, $\"a.value\" === $\"b.value\")\n+    checkAnswer(joined, (\"2\", 2))\n+\n+    ds1.unpersist()\n+    assert(!sqlContext.isCached(ds1), \"The Dataset ds1 should not be cached.\")\n+    ds2.unpersist()\n+    assert(!sqlContext.isCached(ds2), \"The Dataset ds2 should not be cached.\")\n+  }\n+\n+  test(\"persist and then groupBy columns asKey, map\") {\n+    val ds = Seq((\"a\", 10), (\"a\", 20), (\"b\", 1), (\"b\", 2), (\"c\", 1)).toDS()\n+    val grouped = ds.groupBy($\"_1\").keyAs[String]\n+    val agged = grouped.mapGroups { case (g, iter) => (g, iter.map(_._2).sum) }\n+    agged.persist()\n+\n+    checkAnswer(\n+      agged.filter(_._1 == \"b\"),"
  }],
  "prId": 9889
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "We should probably just make a JIRA for this and put this test case there.\n",
    "commit": "b8d287a84f354bcf59e7c258f912c55bff3da32a",
    "createdAt": "2015-11-30T23:52:11Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import scala.language.postfixOps\n+\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+\n+class CacheSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  test(\"persist and unpersist\") {\n+    val ds = Seq((\"a\", 1) , (\"b\", 2), (\"c\", 3)).toDS().select(expr(\"_2 + 1\").as[Int])\n+    val cached = ds.cache()\n+    // count triggers the caching action. It should not throw.\n+    cached.count()\n+    // Make sure, the Dataset is indeed cached.\n+    assertCached(cached)\n+    // Check result.\n+    checkAnswer(\n+      cached,\n+      2, 3, 4)\n+    // Drop the cache.\n+    cached.unpersist()\n+    assert(!sqlContext.isCached(cached), \"The Dataset should not be cached.\")\n+  }\n+\n+  test(\"persist and then rebind right encoder when join 2 datasets\") {\n+    val ds1 = Seq(\"1\", \"2\").toDS().as(\"a\")\n+    val ds2 = Seq(2, 3).toDS().as(\"b\")\n+\n+    ds1.persist()\n+    assertCached(ds1)\n+    ds2.persist()\n+    assertCached(ds2)\n+\n+    val joined = ds1.joinWith(ds2, $\"a.value\" === $\"b.value\")\n+    checkAnswer(joined, (\"2\", 2))\n+\n+    ds1.unpersist()\n+    assert(!sqlContext.isCached(ds1), \"The Dataset ds1 should not be cached.\")\n+    ds2.unpersist()\n+    assert(!sqlContext.isCached(ds2), \"The Dataset ds2 should not be cached.\")\n+  }\n+\n+  test(\"persist and then groupBy columns asKey, map\") {\n+    val ds = Seq((\"a\", 10), (\"a\", 20), (\"b\", 1), (\"b\", 2), (\"c\", 1)).toDS()\n+    val grouped = ds.groupBy($\"_1\").keyAs[String]\n+    val agged = grouped.mapGroups { case (g, iter) => (g, iter.map(_._2).sum) }\n+    agged.persist()\n+\n+    checkAnswer(\n+      agged.filter(_._1 == \"b\"),\n+      (\"b\", 3))\n+\n+    ds.unpersist()\n+    assert(!sqlContext.isCached(ds), \"The Dataset ds should not be cached.\")\n+    agged.unpersist()\n+    assert(!sqlContext.isCached(agged), \"The Dataset agged should not be cached.\")\n+  }\n+\n+  ignore(\"persist and then map/filter with lambda functions\") {"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Just opened a new JIRA https://issues.apache.org/jira/browse/SPARK-12061\n",
    "commit": "b8d287a84f354bcf59e7c258f912c55bff3da32a",
    "createdAt": "2015-12-01T01:48:18Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import scala.language.postfixOps\n+\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+\n+class CacheSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  test(\"persist and unpersist\") {\n+    val ds = Seq((\"a\", 1) , (\"b\", 2), (\"c\", 3)).toDS().select(expr(\"_2 + 1\").as[Int])\n+    val cached = ds.cache()\n+    // count triggers the caching action. It should not throw.\n+    cached.count()\n+    // Make sure, the Dataset is indeed cached.\n+    assertCached(cached)\n+    // Check result.\n+    checkAnswer(\n+      cached,\n+      2, 3, 4)\n+    // Drop the cache.\n+    cached.unpersist()\n+    assert(!sqlContext.isCached(cached), \"The Dataset should not be cached.\")\n+  }\n+\n+  test(\"persist and then rebind right encoder when join 2 datasets\") {\n+    val ds1 = Seq(\"1\", \"2\").toDS().as(\"a\")\n+    val ds2 = Seq(2, 3).toDS().as(\"b\")\n+\n+    ds1.persist()\n+    assertCached(ds1)\n+    ds2.persist()\n+    assertCached(ds2)\n+\n+    val joined = ds1.joinWith(ds2, $\"a.value\" === $\"b.value\")\n+    checkAnswer(joined, (\"2\", 2))\n+\n+    ds1.unpersist()\n+    assert(!sqlContext.isCached(ds1), \"The Dataset ds1 should not be cached.\")\n+    ds2.unpersist()\n+    assert(!sqlContext.isCached(ds2), \"The Dataset ds2 should not be cached.\")\n+  }\n+\n+  test(\"persist and then groupBy columns asKey, map\") {\n+    val ds = Seq((\"a\", 10), (\"a\", 20), (\"b\", 1), (\"b\", 2), (\"c\", 1)).toDS()\n+    val grouped = ds.groupBy($\"_1\").keyAs[String]\n+    val agged = grouped.mapGroups { case (g, iter) => (g, iter.map(_._2).sum) }\n+    agged.persist()\n+\n+    checkAnswer(\n+      agged.filter(_._1 == \"b\"),\n+      (\"b\", 3))\n+\n+    ds.unpersist()\n+    assert(!sqlContext.isCached(ds), \"The Dataset ds should not be cached.\")\n+    agged.unpersist()\n+    assert(!sqlContext.isCached(agged), \"The Dataset agged should not be cached.\")\n+  }\n+\n+  ignore(\"persist and then map/filter with lambda functions\") {"
  }],
  "prId": 9889
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "`DatasetCacheSuite`\n",
    "commit": "b8d287a84f354bcf59e7c258f912c55bff3da32a",
    "createdAt": "2015-11-30T23:52:19Z",
    "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import scala.language.postfixOps\n+\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+\n+class CacheSuite extends QueryTest with SharedSQLContext {"
  }],
  "prId": 9889
}]