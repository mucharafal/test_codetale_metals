[{
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "I feel its a bit hard to tell the difference between the tests at a glance, so how about defining a helper function below for these tests?\r\n```\r\n  \r\n  private def doTest(df1: DataFrame, df2: DataFrame, expectedRows: Seq[Row]): Unit = {\r\n     withTempPath { dir =>\r\n      val path = dir.getCanonicalPath\r\n\r\n      val dir1 = s\"$path${File.separator}part=one\"\r\n      val dir2 = s\"$path${File.separator}part=two\"\r\n\r\n      df1.write.format(format).options(options).save(dir1)\r\n      df2.write.format(format).options(options).save(dir2)\r\n\r\n      val df = spark.read\r\n        .schema(df2.schema)\r\n        .format(format)\r\n        .options(options)\r\n        .load(path)\r\n\r\n      checkAnswer(df, expectedRows)\r\n    }\r\n  }\r\n\r\n  test(\"add a nested column at the end of the leaf struct column\") {\r\n    doTest(\r\n      df1 = sql(\"SELECT 1 c1, named_struct('c3', 2, 'c4', named_struct('c5', 3, 'c6', 4)) c2\"),\r\n      df2 = sql(\"SELECT 1 c1, named_struct('c3', 2, 'c4', named_struct('c5', 3, 'c6', 4, 'c7', 5)) c2\"),\r\n      expectedRows = Seq(\r\n        Row(1, Row(2, Row(3, 4, null)), \"one\"),\r\n        Row(1, Row(2, Row(3, 4, 5)), \"two\"))\r\n      )\r\n  }\r\n...\r\n```",
    "commit": "4f148b9e402dd6b86d347d439b7ee1921c9b98be",
    "createdAt": "2019-03-19T11:27:22Z",
    "diffHunk": "@@ -0,0 +1,244 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.File\n+\n+import org.apache.spark.sql.Row\n+\n+\n+/**\n+ * Add a nested column.\n+ */\n+trait AddNestedColumnTest extends ReadSchemaTest {\n+\n+  test(\"add a nested column at the end of the leaf struct column\") {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thanks. It's updated like that.",
    "commit": "4f148b9e402dd6b86d347d439b7ee1921c9b98be",
    "createdAt": "2019-03-19T16:26:27Z",
    "diffHunk": "@@ -0,0 +1,244 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.File\n+\n+import org.apache.spark.sql.Row\n+\n+\n+/**\n+ * Add a nested column.\n+ */\n+trait AddNestedColumnTest extends ReadSchemaTest {\n+\n+  test(\"add a nested column at the end of the leaf struct column\") {"
  }],
  "prId": 24139
}]