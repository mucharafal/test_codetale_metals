[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "This is for IDE case. `spark.test.home` can be missing if we run the tests in IDE without any other settings. In that case, it falls back to `SPARK_HOME`.",
    "commit": "8fe247435ff278f62eec39cdcdc0c20d07af31f9",
    "createdAt": "2019-06-24T03:26:35Z",
    "diffHunk": "@@ -40,32 +40,37 @@ import org.apache.spark.sql.types.StringType\n  *\n  * To register Scala UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalaUDF(name = \"udf_name\"), spark)\n+ *   val scalaTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(scalaTestUDF, spark)\n  * }}}\n  *\n  * To register Python UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestPythonUDF(name = \"udf_name\"), spark)\n+ *   val pythonTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(pythonTestUDF, spark)\n  * }}}\n  *\n  * To register Scalar Pandas UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalarPandasUDF(name = \"udf_name\"), spark)\n+ *   val pandasTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(pandasTestUDF, spark)\n  * }}}\n  *\n  * To use it in Scala API and SQL:\n  * {{{\n  *   sql(\"SELECT udf_name(1)\")\n- *   spark.select(expr(\"udf_name(1)\")\n+ *   spark.range(10).select(expr(\"udf_name(id)\")\n+ *   spark.range(10).select(pandasTestUDF($\"id\"))\n  * }}}\n  */\n object IntegratedUDFTestUtils extends SQLHelper {\n   import scala.sys.process._\n \n   private lazy val pythonPath = sys.env.getOrElse(\"PYTHONPATH\", \"\")\n   private lazy val sparkHome = if (sys.props.contains(Tests.IS_TESTING.key)) {\n-    assert(sys.props.contains(\"spark.test.home\"), \"spark.test.home is not set.\")\n-    sys.props(\"spark.test.home\")\n+    assert(sys.props.contains(\"spark.test.home\") ||\n+      sys.env.contains(\"SPARK_HOME\"), \"spark.test.home or SPARK_HOME is not set.\")\n+    sys.props.getOrElse(\"spark.test.home\", sys.env(\"SPARK_HOME\"))",
    "line": 40
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Should we add a comment for this reason?",
    "commit": "8fe247435ff278f62eec39cdcdc0c20d07af31f9",
    "createdAt": "2019-06-25T02:31:11Z",
    "diffHunk": "@@ -40,32 +40,37 @@ import org.apache.spark.sql.types.StringType\n  *\n  * To register Scala UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalaUDF(name = \"udf_name\"), spark)\n+ *   val scalaTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(scalaTestUDF, spark)\n  * }}}\n  *\n  * To register Python UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestPythonUDF(name = \"udf_name\"), spark)\n+ *   val pythonTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(pythonTestUDF, spark)\n  * }}}\n  *\n  * To register Scalar Pandas UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalarPandasUDF(name = \"udf_name\"), spark)\n+ *   val pandasTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(pandasTestUDF, spark)\n  * }}}\n  *\n  * To use it in Scala API and SQL:\n  * {{{\n  *   sql(\"SELECT udf_name(1)\")\n- *   spark.select(expr(\"udf_name(1)\")\n+ *   spark.range(10).select(expr(\"udf_name(id)\")\n+ *   spark.range(10).select(pandasTestUDF($\"id\"))\n  * }}}\n  */\n object IntegratedUDFTestUtils extends SQLHelper {\n   import scala.sys.process._\n \n   private lazy val pythonPath = sys.env.getOrElse(\"PYTHONPATH\", \"\")\n   private lazy val sparkHome = if (sys.props.contains(Tests.IS_TESTING.key)) {\n-    assert(sys.props.contains(\"spark.test.home\"), \"spark.test.home is not set.\")\n-    sys.props(\"spark.test.home\")\n+    assert(sys.props.contains(\"spark.test.home\") ||\n+      sys.env.contains(\"SPARK_HOME\"), \"spark.test.home or SPARK_HOME is not set.\")\n+    sys.props.getOrElse(\"spark.test.home\", sys.env(\"SPARK_HOME\"))",
    "line": 40
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "oops, I missed this. Actually there are multiple places like this. Let me fix them together later separately.",
    "commit": "8fe247435ff278f62eec39cdcdc0c20d07af31f9",
    "createdAt": "2019-06-25T03:00:02Z",
    "diffHunk": "@@ -40,32 +40,37 @@ import org.apache.spark.sql.types.StringType\n  *\n  * To register Scala UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalaUDF(name = \"udf_name\"), spark)\n+ *   val scalaTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(scalaTestUDF, spark)\n  * }}}\n  *\n  * To register Python UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestPythonUDF(name = \"udf_name\"), spark)\n+ *   val pythonTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(pythonTestUDF, spark)\n  * }}}\n  *\n  * To register Scalar Pandas UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalarPandasUDF(name = \"udf_name\"), spark)\n+ *   val pandasTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(pandasTestUDF, spark)\n  * }}}\n  *\n  * To use it in Scala API and SQL:\n  * {{{\n  *   sql(\"SELECT udf_name(1)\")\n- *   spark.select(expr(\"udf_name(1)\")\n+ *   spark.range(10).select(expr(\"udf_name(id)\")\n+ *   spark.range(10).select(pandasTestUDF($\"id\"))\n  * }}}\n  */\n object IntegratedUDFTestUtils extends SQLHelper {\n   import scala.sys.process._\n \n   private lazy val pythonPath = sys.env.getOrElse(\"PYTHONPATH\", \"\")\n   private lazy val sparkHome = if (sys.props.contains(Tests.IS_TESTING.key)) {\n-    assert(sys.props.contains(\"spark.test.home\"), \"spark.test.home is not set.\")\n-    sys.props(\"spark.test.home\")\n+    assert(sys.props.contains(\"spark.test.home\") ||\n+      sys.env.contains(\"SPARK_HOME\"), \"spark.test.home or SPARK_HOME is not set.\")\n+    sys.props.getOrElse(\"spark.test.home\", sys.env(\"SPARK_HOME\"))",
    "line": 40
  }],
  "prId": 24945
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "`TestScalaUDF` -> `TestPythonUDF`?",
    "commit": "8fe247435ff278f62eec39cdcdc0c20d07af31f9",
    "createdAt": "2019-06-24T15:17:22Z",
    "diffHunk": "@@ -40,32 +40,37 @@ import org.apache.spark.sql.types.StringType\n  *\n  * To register Scala UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalaUDF(name = \"udf_name\"), spark)\n+ *   val scalaTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(scalaTestUDF, spark)\n  * }}}\n  *\n  * To register Python UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestPythonUDF(name = \"udf_name\"), spark)\n+ *   val pythonTestUDF = TestScalaUDF(name = \"udf_name\")"
  }],
  "prId": 24945
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "`TestScalaUDF` -> `TestScalarPandasUDF`?",
    "commit": "8fe247435ff278f62eec39cdcdc0c20d07af31f9",
    "createdAt": "2019-06-24T15:17:37Z",
    "diffHunk": "@@ -40,32 +40,37 @@ import org.apache.spark.sql.types.StringType\n  *\n  * To register Scala UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalaUDF(name = \"udf_name\"), spark)\n+ *   val scalaTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(scalaTestUDF, spark)\n  * }}}\n  *\n  * To register Python UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestPythonUDF(name = \"udf_name\"), spark)\n+ *   val pythonTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(pythonTestUDF, spark)\n  * }}}\n  *\n  * To register Scalar Pandas UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalarPandasUDF(name = \"udf_name\"), spark)\n+ *   val pandasTestUDF = TestScalaUDF(name = \"udf_name\")"
  }],
  "prId": 24945
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Will we use it? In `SQLQueryTestSuite`,  I think udfs are all registered for `UDFTestCase`?",
    "commit": "8fe247435ff278f62eec39cdcdc0c20d07af31f9",
    "createdAt": "2019-06-24T15:35:24Z",
    "diffHunk": "@@ -40,32 +40,37 @@ import org.apache.spark.sql.types.StringType\n  *\n  * To register Scala UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalaUDF(name = \"udf_name\"), spark)\n+ *   val scalaTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(scalaTestUDF, spark)\n  * }}}\n  *\n  * To register Python UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestPythonUDF(name = \"udf_name\"), spark)\n+ *   val pythonTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(pythonTestUDF, spark)\n  * }}}\n  *\n  * To register Scalar Pandas UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalarPandasUDF(name = \"udf_name\"), spark)\n+ *   val pandasTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(pandasTestUDF, spark)\n  * }}}\n  *\n  * To use it in Scala API and SQL:\n  * {{{\n  *   sql(\"SELECT udf_name(1)\")\n- *   spark.select(expr(\"udf_name(1)\")\n+ *   spark.range(10).select(expr(\"udf_name(id)\")\n+ *   spark.range(10).select(pandasTestUDF($\"id\"))",
    "line": 28
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Ah this one will be used at #24946",
    "commit": "8fe247435ff278f62eec39cdcdc0c20d07af31f9",
    "createdAt": "2019-06-24T16:08:41Z",
    "diffHunk": "@@ -40,32 +40,37 @@ import org.apache.spark.sql.types.StringType\n  *\n  * To register Scala UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalaUDF(name = \"udf_name\"), spark)\n+ *   val scalaTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(scalaTestUDF, spark)\n  * }}}\n  *\n  * To register Python UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestPythonUDF(name = \"udf_name\"), spark)\n+ *   val pythonTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(pythonTestUDF, spark)\n  * }}}\n  *\n  * To register Scalar Pandas UDF in SQL:\n  * {{{\n- *   registerTestUDF(TestScalarPandasUDF(name = \"udf_name\"), spark)\n+ *   val pandasTestUDF = TestScalaUDF(name = \"udf_name\")\n+ *   registerTestUDF(pandasTestUDF, spark)\n  * }}}\n  *\n  * To use it in Scala API and SQL:\n  * {{{\n  *   sql(\"SELECT udf_name(1)\")\n- *   spark.select(expr(\"udf_name(1)\")\n+ *   spark.range(10).select(expr(\"udf_name(id)\")\n+ *   spark.range(10).select(pandasTestUDF($\"id\"))",
    "line": 28
  }],
  "prId": 24945
}]