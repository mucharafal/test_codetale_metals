[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "if these are always used together, then these functions can be merged .. right?",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-14T22:24:54Z",
    "diffHunk": "@@ -300,6 +300,67 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstAggregation = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondAggregation = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val union = firstAggregation.union(secondAggregation)\n+      .writeStream\n+      .format(\"memory\")\n+      .queryName(\"test\")\n+      .start()\n+\n+    def populateNewWatermarkFromData(stream: MemoryStream[Int], data: Int*): Unit = {\n+      stream.addData(data)\n+      union.processAllAvailable()\n+      // add a dummy batch so lastExecution has the new watermark\n+      stream.addData(0)\n+      union.processAllAvailable()\n+    }\n+\n+    def assertQueryWatermark(watermark: Int): Unit = {\n+      assert(union.asInstanceOf[StreamingQueryWrapper].streamingQuery\n+        .lastExecution.offsetSeqMetadata.batchWatermarkMs\n+        == watermark)\n+    }\n+\n+    populateNewWatermarkFromData(first, 11)"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Also, I think you can use the `testStream..AddData... AssertOnQuery` pattern. its cleaner.\r\nhttps://github.com/apache/spark/blob/master/sql/core/src/test/scala/org/apache/spark/sql/streaming/StreamingAggregationSuite.scala#L180",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-14T22:26:38Z",
    "diffHunk": "@@ -300,6 +300,67 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstAggregation = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondAggregation = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val union = firstAggregation.union(secondAggregation)\n+      .writeStream\n+      .format(\"memory\")\n+      .queryName(\"test\")\n+      .start()\n+\n+    def populateNewWatermarkFromData(stream: MemoryStream[Int], data: Int*): Unit = {\n+      stream.addData(data)\n+      union.processAllAvailable()\n+      // add a dummy batch so lastExecution has the new watermark\n+      stream.addData(0)\n+      union.processAllAvailable()\n+    }\n+\n+    def assertQueryWatermark(watermark: Int): Unit = {\n+      assert(union.asInstanceOf[StreamingQueryWrapper].streamingQuery\n+        .lastExecution.offsetSeqMetadata.batchWatermarkMs\n+        == watermark)\n+    }\n+\n+    populateNewWatermarkFromData(first, 11)"
  }, {
    "author": {
      "login": "jose-torres"
    },
    "body": "The problem is that watermark recalculation happens at the beginning of each batch, and to sequence executions I have to call CheckData or CheckLastBatch. So that method ends up producing a test multiple times longer, since a single entry is:\r\n\r\nAddData(realData)\r\nCheckLastBatch\r\nAddData(0)\r\nCheckLastBatch\r\nAssertOnQuery",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-14T22:41:32Z",
    "diffHunk": "@@ -300,6 +300,67 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstAggregation = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondAggregation = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val union = firstAggregation.union(secondAggregation)\n+      .writeStream\n+      .format(\"memory\")\n+      .queryName(\"test\")\n+      .start()\n+\n+    def populateNewWatermarkFromData(stream: MemoryStream[Int], data: Int*): Unit = {\n+      stream.addData(data)\n+      union.processAllAvailable()\n+      // add a dummy batch so lastExecution has the new watermark\n+      stream.addData(0)\n+      union.processAllAvailable()\n+    }\n+\n+    def assertQueryWatermark(watermark: Int): Unit = {\n+      assert(union.asInstanceOf[StreamingQueryWrapper].streamingQuery\n+        .lastExecution.offsetSeqMetadata.batchWatermarkMs\n+        == watermark)\n+    }\n+\n+    populateNewWatermarkFromData(first, 11)"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "even better example - https://github.com/apache/spark/blob/master/sql/core/src/test/scala/org/apache/spark/sql/streaming/EventTimeWatermarkSuite.scala#L107\r\n",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-14T23:17:55Z",
    "diffHunk": "@@ -300,6 +300,67 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstAggregation = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondAggregation = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val union = firstAggregation.union(secondAggregation)\n+      .writeStream\n+      .format(\"memory\")\n+      .queryName(\"test\")\n+      .start()\n+\n+    def populateNewWatermarkFromData(stream: MemoryStream[Int], data: Int*): Unit = {\n+      stream.addData(data)\n+      union.processAllAvailable()\n+      // add a dummy batch so lastExecution has the new watermark\n+      stream.addData(0)\n+      union.processAllAvailable()\n+    }\n+\n+    def assertQueryWatermark(watermark: Int): Unit = {\n+      assert(union.asInstanceOf[StreamingQueryWrapper].streamingQuery\n+        .lastExecution.offsetSeqMetadata.batchWatermarkMs\n+        == watermark)\n+    }\n+\n+    populateNewWatermarkFromData(first, 11)"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "You are right. what you have is better. \r\n",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-14T23:39:55Z",
    "diffHunk": "@@ -300,6 +300,67 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstAggregation = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondAggregation = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val union = firstAggregation.union(secondAggregation)\n+      .writeStream\n+      .format(\"memory\")\n+      .queryName(\"test\")\n+      .start()\n+\n+    def populateNewWatermarkFromData(stream: MemoryStream[Int], data: Int*): Unit = {\n+      stream.addData(data)\n+      union.processAllAvailable()\n+      // add a dummy batch so lastExecution has the new watermark\n+      stream.addData(0)\n+      union.processAllAvailable()\n+    }\n+\n+    def assertQueryWatermark(watermark: Int): Unit = {\n+      assert(union.asInstanceOf[StreamingQueryWrapper].streamingQuery\n+        .lastExecution.offsetSeqMetadata.batchWatermarkMs\n+        == watermark)\n+    }\n+\n+    populateNewWatermarkFromData(first, 11)"
  }],
  "prId": 19239
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "there is no aggregation here.",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-14T23:15:44Z",
    "diffHunk": "@@ -300,6 +300,67 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstAggregation = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondAggregation = second.toDF()"
  }],
  "prId": 19239
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: assertWatermark.",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-14T23:37:05Z",
    "diffHunk": "@@ -300,6 +300,67 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstAggregation = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondAggregation = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val union = firstAggregation.union(secondAggregation)\n+      .writeStream\n+      .format(\"memory\")\n+      .queryName(\"test\")\n+      .start()\n+\n+    def populateNewWatermarkFromData(stream: MemoryStream[Int], data: Int*): Unit = {\n+      stream.addData(data)\n+      union.processAllAvailable()\n+      // add a dummy batch so lastExecution has the new watermark\n+      stream.addData(0)\n+      union.processAllAvailable()\n+    }\n+\n+    def assertQueryWatermark(watermark: Int): Unit = {"
  }],
  "prId": 19239
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "this line break is hard to read. how about you break it with an intermediate variable (e.g. `val lastExecution = ... ; assert(...) `",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-14T23:38:22Z",
    "diffHunk": "@@ -300,6 +300,67 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstAggregation = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondAggregation = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val union = firstAggregation.union(secondAggregation)\n+      .writeStream\n+      .format(\"memory\")\n+      .queryName(\"test\")\n+      .start()\n+\n+    def populateNewWatermarkFromData(stream: MemoryStream[Int], data: Int*): Unit = {\n+      stream.addData(data)\n+      union.processAllAvailable()\n+      // add a dummy batch so lastExecution has the new watermark\n+      stream.addData(0)\n+      union.processAllAvailable()\n+    }\n+\n+    def assertQueryWatermark(watermark: Int): Unit = {\n+      assert(union.asInstanceOf[StreamingQueryWrapper].streamingQuery"
  }],
  "prId": 19239
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Can you update the test to have different watermark delays, so that we test that we are choosing min delay, but the min watermark?",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-14T23:40:49Z",
    "diffHunk": "@@ -300,6 +300,67 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstAggregation = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondAggregation = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")"
  }],
  "prId": 19239
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: Watermark to \"global watermark\" .. to differentiate from \"right watermark\" later in the sentence.",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-14T23:42:34Z",
    "diffHunk": "@@ -300,6 +300,67 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstAggregation = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondAggregation = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val union = firstAggregation.union(secondAggregation)\n+      .writeStream\n+      .format(\"memory\")\n+      .queryName(\"test\")\n+      .start()\n+\n+    def populateNewWatermarkFromData(stream: MemoryStream[Int], data: Int*): Unit = {\n+      stream.addData(data)\n+      union.processAllAvailable()\n+      // add a dummy batch so lastExecution has the new watermark\n+      stream.addData(0)\n+      union.processAllAvailable()\n+    }\n+\n+    def assertQueryWatermark(watermark: Int): Unit = {\n+      assert(union.asInstanceOf[StreamingQueryWrapper].streamingQuery\n+        .lastExecution.offsetSeqMetadata.batchWatermarkMs\n+        == watermark)\n+    }\n+\n+    populateNewWatermarkFromData(first, 11)\n+    assertQueryWatermark(1000)\n+\n+    // Watermark stays at 1 from the left when right watermark moves to 2"
  }],
  "prId": 19239
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "instead of having two variations for handing single input and double inputs, you can do something like this. \r\n```\r\ndef getWatermarkAfterData(firstData: Seq[Int] = Seq.empty, secondData: Seq[Int] = Seq.empty): Long = {\r\n   if (firstData.nonEmpty) first.add(firstData)\r\n   if (secondData.nonEmpty) second.add(secondData)\r\n   union.processAllAvailable()\r\n   // add a dummy batch so lastExecution has the new watermark\r\n    first.addData(0)\r\n    union.processAllAvailable()\r\n    // get updated watermark\r\n    val lastExecution = union.asInstanceOf[StreamingQueryWrapper].streamingQuery.lastExecution\r\n    lastExecution.offsetSeqMetadata.batchWatermarkMs\r\n}\r\n\r\nassert(getWatermarkAfterData(firstData = Seq(...)) === 10000)\r\nassert(getWatermarkAfterData(secondData = Seq(...)) === 10000)\r\nassert(getWatermarkAfterData(firstData = Seq(...), secondData = Seq(...)) === 10000)\r\n\r\n```\r\n",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-15T07:07:57Z",
    "diffHunk": "@@ -300,6 +300,85 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstDf = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondDf = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"5 seconds\")\n+      .select('value)\n+\n+    val union = firstDf.union(secondDf)\n+      .writeStream\n+      .format(\"memory\")\n+      .queryName(\"test\")\n+      .start()\n+\n+    def generateAndAssertNewWatermark(\n+        stream: MemoryStream[Int],\n+        data: Seq[Int],\n+        watermark: Int): Unit = {\n+      stream.addData(data)\n+      assertWatermark(watermark)\n+    }\n+\n+    def assertWatermark(watermark: Int) {\n+      union.processAllAvailable()\n+      // add a dummy batch so lastExecution has the new watermark\n+      first.addData(0)\n+      union.processAllAvailable()\n+\n+      val lastExecution = union.asInstanceOf[StreamingQueryWrapper].streamingQuery.lastExecution\n+      assert(lastExecution.offsetSeqMetadata.batchWatermarkMs == watermark)\n+    }\n+\n+    generateAndAssertNewWatermark(first, Seq(11), 1000)"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "BTW, why is the first watermark at 1000?",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-15T07:10:26Z",
    "diffHunk": "@@ -300,6 +300,85 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstDf = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondDf = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"5 seconds\")\n+      .select('value)\n+\n+    val union = firstDf.union(secondDf)\n+      .writeStream\n+      .format(\"memory\")\n+      .queryName(\"test\")\n+      .start()\n+\n+    def generateAndAssertNewWatermark(\n+        stream: MemoryStream[Int],\n+        data: Seq[Int],\n+        watermark: Int): Unit = {\n+      stream.addData(data)\n+      assertWatermark(watermark)\n+    }\n+\n+    def assertWatermark(watermark: Int) {\n+      union.processAllAvailable()\n+      // add a dummy batch so lastExecution has the new watermark\n+      first.addData(0)\n+      union.processAllAvailable()\n+\n+      val lastExecution = union.asInstanceOf[StreamingQueryWrapper].streamingQuery.lastExecution\n+      assert(lastExecution.offsetSeqMetadata.batchWatermarkMs == watermark)\n+    }\n+\n+    generateAndAssertNewWatermark(first, Seq(11), 1000)"
  }],
  "prId": 19239
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "test recovery of the minimum after a restart.",
    "commit": "cdf4361f6065e4e1d891992ebc30289957a6262f",
    "createdAt": "2017-09-15T22:09:17Z",
    "diffHunk": "@@ -300,6 +300,67 @@ class EventTimeWatermarkSuite extends StreamTest with BeforeAndAfter with Matche\n     )\n   }\n \n+  test(\"watermark with 2 streams\") {\n+    val first = MemoryStream[Int]\n+\n+    val firstDf = first.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"10 seconds\")\n+      .select('value)\n+\n+    val second = MemoryStream[Int]\n+\n+    val secondDf = second.toDF()\n+      .withColumn(\"eventTime\", $\"value\".cast(\"timestamp\"))\n+      .withWatermark(\"eventTime\", \"5 seconds\")\n+      .select('value)\n+\n+    val union = firstDf.union(secondDf)\n+      .writeStream\n+      .format(\"memory\")\n+      .queryName(\"test\")\n+      .start()\n+\n+    def getWatermarkAfterData(\n+        firstData: Seq[Int] = Seq.empty,\n+        secondData: Seq[Int] = Seq.empty): Long = {\n+      if (firstData.nonEmpty) first.addData(firstData)\n+      if (secondData.nonEmpty) second.addData(secondData)\n+      union.processAllAvailable()\n+      // add a dummy batch so lastExecution has the new watermark\n+      first.addData(0)\n+      union.processAllAvailable()\n+      // get last watermark\n+      val lastExecution = union.asInstanceOf[StreamingQueryWrapper].streamingQuery.lastExecution\n+      lastExecution.offsetSeqMetadata.batchWatermarkMs\n+    }\n+\n+    // Global watermark starts at 0 until we get data from both sides\n+    assert(getWatermarkAfterData(firstData = Seq(11)) == 0)\n+    assert(getWatermarkAfterData(secondData = Seq(6)) == 1000)\n+    // Global watermark stays at left watermark 1 when right watermark moves to 2\n+    assert(getWatermarkAfterData(secondData = Seq(8)) == 1000)\n+    // Global watermark switches to right side value 2 when left watermark goes higher\n+    assert(getWatermarkAfterData(firstData = Seq(21)) == 3000)\n+    // Global watermark goes back to left\n+    assert(getWatermarkAfterData(secondData = Seq(17, 28, 39)) == 11000)\n+    // Global watermark stays on left as long as it's below right\n+    assert(getWatermarkAfterData(firstData = Seq(31)) == 21000)\n+    assert(getWatermarkAfterData(firstData = Seq(41)) == 31000)\n+    // Global watermark switches back to right again\n+    assert(getWatermarkAfterData(firstData = Seq(51)) == 34000)\n+\n+    // Global watermark is updated correctly with simultaneous data from both sides\n+    assert(getWatermarkAfterData(firstData = Seq(100), secondData = Seq(100)) == 90000)\n+    assert(getWatermarkAfterData(firstData = Seq(120), secondData = Seq(110)) == 105000)\n+    assert(getWatermarkAfterData(firstData = Seq(130), secondData = Seq(125)) == 120000)\n+\n+    // Global watermark doesn't decrement with simultaneous data\n+    assert(getWatermarkAfterData(firstData = Seq(100), secondData = Seq(100)) == 120000)\n+    assert(getWatermarkAfterData(firstData = Seq(140), secondData = Seq(100)) == 120000)\n+    assert(getWatermarkAfterData(firstData = Seq(100), secondData = Seq(135)) == 130000)"
  }],
  "prId": 19239
}]