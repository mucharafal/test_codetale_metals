[{
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "```bin/spark-submit --class <this class> <spark sql test jar>``` -> ```bin/spark-submit --class <this class> --jars <spark core test jar> <spark sql test jar>```",
    "commit": "610fc315c60b5caec241d7c7774aac1fb683a019",
    "createdAt": "2018-10-25T10:45:40Z",
    "diffHunk": "@@ -21,32 +21,30 @@ import org.apache.spark.benchmark.Benchmark\n \n /**\n  * Benchmark to measure performance for wide table.\n- * To run this:\n- *  build/sbt \"sql/test-only *benchmark.BenchmarkWideTable\"\n- *\n- * Benchmarks in this file are skipped in normal builds.\n+ * {{{\n+ *   To run this benchmark:\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>"
  }],
  "prId": 22823
}, {
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "```\"10\", \"100\", \"1024\", \"8196\", \"65536\"``` -> ```\"10\", \"100\", \"1024\", \"2048\", \"4096\", \"8196\", \"65536\"```?",
    "commit": "610fc315c60b5caec241d7c7774aac1fb683a019",
    "createdAt": "2018-10-25T13:00:54Z",
    "diffHunk": "@@ -21,32 +21,30 @@ import org.apache.spark.benchmark.Benchmark\n \n /**\n  * Benchmark to measure performance for wide table.\n- * To run this:\n- *  build/sbt \"sql/test-only *benchmark.BenchmarkWideTable\"\n- *\n- * Benchmarks in this file are skipped in normal builds.\n+ * {{{\n+ *   To run this benchmark:\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/BenchmarkWideTable-results.txt\".\n+ * }}}\n  */\n-class BenchmarkWideTable extends BenchmarkWithCodegen {\n+object BenchmarkWideTable extends SqlBasedBenchmark {\n \n-  ignore(\"project on wide table\") {\n-    val N = 1 << 20\n-    val df = sparkSession.range(N)\n-    val columns = (0 until 400).map{ i => s\"id as id$i\"}\n-    val benchmark = new Benchmark(\"projection on wide table\", N)\n-    benchmark.addCase(\"wide table\", numIters = 5) { iter =>\n-      df.selectExpr(columns : _*).queryExecution.toRdd.count()\n+  override def runBenchmarkSuite(): Unit = {\n+    runBenchmark(\"projection on wide table\") {\n+      val N = 1 << 20\n+      val df = spark.range(N)\n+      val columns = (0 until 400).map{ i => s\"id as id$i\"}\n+      val benchmark = new Benchmark(\"projection on wide table\", N, output = output)\n+      Seq(\"10\", \"100\", \"1024\", \"8196\", \"65536\").foreach { n =>"
  }],
  "prId": 22823
}, {
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "`BenchmarkWideTable` -> `WideTableBenchmark`?",
    "commit": "610fc315c60b5caec241d7c7774aac1fb683a019",
    "createdAt": "2018-10-25T13:02:35Z",
    "diffHunk": "@@ -21,32 +21,30 @@ import org.apache.spark.benchmark.Benchmark\n \n /**\n  * Benchmark to measure performance for wide table.\n- * To run this:\n- *  build/sbt \"sql/test-only *benchmark.BenchmarkWideTable\"\n- *\n- * Benchmarks in this file are skipped in normal builds.\n+ * {{{\n+ *   To run this benchmark:\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/BenchmarkWideTable-results.txt\".\n+ * }}}\n  */\n-class BenchmarkWideTable extends BenchmarkWithCodegen {\n+object BenchmarkWideTable extends SqlBasedBenchmark {"
  }],
  "prId": 22823
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Hi, @davies and @cloud-fan and @kiszk .\r\n\r\nThis benchmark is added in [Spark 2.1.0](https://github.com/apache/spark/commit/8d35a6f68d6d733212674491cbf31bed73fada0f#diff-71964129f49db97eb030a6d7320af314). This value `1k` is determined by **manually** changing the split threhold.\r\n\r\nThis PR wants to [add a configuration in CodeGenerator.scala](https://github.com/apache/spark/pull/22823/files#diff-8bcc5aea39c73d4bf38aef6f6951d42cR914) for testing-purpose only.\r\n\r\n1. Is the configuration helpful in general purpose?\r\n2. If then, can we make another PR for that first?\r\n3. If not, is it allowed to add this testing parameter?",
    "commit": "610fc315c60b5caec241d7c7774aac1fb683a019",
    "createdAt": "2018-10-26T04:08:55Z",
    "diffHunk": "@@ -1,52 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.spark.sql.execution.benchmark\n-\n-import org.apache.spark.benchmark.Benchmark\n-\n-/**\n- * Benchmark to measure performance for wide table.\n- * To run this:\n- *  build/sbt \"sql/test-only *benchmark.BenchmarkWideTable\"\n- *\n- * Benchmarks in this file are skipped in normal builds.\n- */\n-class BenchmarkWideTable extends BenchmarkWithCodegen {\n-\n-  ignore(\"project on wide table\") {\n-    val N = 1 << 20\n-    val df = sparkSession.range(N)\n-    val columns = (0 until 400).map{ i => s\"id as id$i\"}\n-    val benchmark = new Benchmark(\"projection on wide table\", N)\n-    benchmark.addCase(\"wide table\", numIters = 5) { iter =>\n-      df.selectExpr(columns : _*).queryExecution.toRdd.count()\n-    }\n-    benchmark.run()\n-\n-    /**\n-     * Here are some numbers with different split threshold:\n-     *\n-     *  Split threshold      methods       Rate(M/s)   Per Row(ns)\n-     *  10                   400           0.4         2279\n-     *  100                  200           0.6         1554\n-     *  1k                   37            0.9         1116",
    "line": 47
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "I think we should have a PR to add this config officially. It should be useful for performance tuning.",
    "commit": "610fc315c60b5caec241d7c7774aac1fb683a019",
    "createdAt": "2018-10-26T05:37:01Z",
    "diffHunk": "@@ -1,52 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.spark.sql.execution.benchmark\n-\n-import org.apache.spark.benchmark.Benchmark\n-\n-/**\n- * Benchmark to measure performance for wide table.\n- * To run this:\n- *  build/sbt \"sql/test-only *benchmark.BenchmarkWideTable\"\n- *\n- * Benchmarks in this file are skipped in normal builds.\n- */\n-class BenchmarkWideTable extends BenchmarkWithCodegen {\n-\n-  ignore(\"project on wide table\") {\n-    val N = 1 << 20\n-    val df = sparkSession.range(N)\n-    val columns = (0 until 400).map{ i => s\"id as id$i\"}\n-    val benchmark = new Benchmark(\"projection on wide table\", N)\n-    benchmark.addCase(\"wide table\", numIters = 5) { iter =>\n-      df.selectExpr(columns : _*).queryExecution.toRdd.count()\n-    }\n-    benchmark.run()\n-\n-    /**\n-     * Here are some numbers with different split threshold:\n-     *\n-     *  Split threshold      methods       Rate(M/s)   Per Row(ns)\n-     *  10                   400           0.4         2279\n-     *  100                  200           0.6         1554\n-     *  1k                   37            0.9         1116",
    "line": 47
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thank you for the decision, @cloud-fan !\r\n\r\n@yucai . Please proceed to propose a new PR for only that new configuration (if you didn't start yet).",
    "commit": "610fc315c60b5caec241d7c7774aac1fb683a019",
    "createdAt": "2018-10-26T17:25:29Z",
    "diffHunk": "@@ -1,52 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.spark.sql.execution.benchmark\n-\n-import org.apache.spark.benchmark.Benchmark\n-\n-/**\n- * Benchmark to measure performance for wide table.\n- * To run this:\n- *  build/sbt \"sql/test-only *benchmark.BenchmarkWideTable\"\n- *\n- * Benchmarks in this file are skipped in normal builds.\n- */\n-class BenchmarkWideTable extends BenchmarkWithCodegen {\n-\n-  ignore(\"project on wide table\") {\n-    val N = 1 << 20\n-    val df = sparkSession.range(N)\n-    val columns = (0 until 400).map{ i => s\"id as id$i\"}\n-    val benchmark = new Benchmark(\"projection on wide table\", N)\n-    benchmark.addCase(\"wide table\", numIters = 5) { iter =>\n-      df.selectExpr(columns : _*).queryExecution.toRdd.count()\n-    }\n-    benchmark.run()\n-\n-    /**\n-     * Here are some numbers with different split threshold:\n-     *\n-     *  Split threshold      methods       Rate(M/s)   Per Row(ns)\n-     *  10                   400           0.4         2279\n-     *  100                  200           0.6         1554\n-     *  1k                   37            0.9         1116",
    "line": 47
  }, {
    "author": {
      "login": "yucai"
    },
    "body": "@dongjoon-hyun I am working on #22847.",
    "commit": "610fc315c60b5caec241d7c7774aac1fb683a019",
    "createdAt": "2018-10-27T15:03:59Z",
    "diffHunk": "@@ -1,52 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.spark.sql.execution.benchmark\n-\n-import org.apache.spark.benchmark.Benchmark\n-\n-/**\n- * Benchmark to measure performance for wide table.\n- * To run this:\n- *  build/sbt \"sql/test-only *benchmark.BenchmarkWideTable\"\n- *\n- * Benchmarks in this file are skipped in normal builds.\n- */\n-class BenchmarkWideTable extends BenchmarkWithCodegen {\n-\n-  ignore(\"project on wide table\") {\n-    val N = 1 << 20\n-    val df = sparkSession.range(N)\n-    val columns = (0 until 400).map{ i => s\"id as id$i\"}\n-    val benchmark = new Benchmark(\"projection on wide table\", N)\n-    benchmark.addCase(\"wide table\", numIters = 5) { iter =>\n-      df.selectExpr(columns : _*).queryExecution.toRdd.count()\n-    }\n-    benchmark.run()\n-\n-    /**\n-     * Here are some numbers with different split threshold:\n-     *\n-     *  Split threshold      methods       Rate(M/s)   Per Row(ns)\n-     *  10                   400           0.4         2279\n-     *  100                  200           0.6         1554\n-     *  1k                   37            0.9         1116",
    "line": 47
  }],
  "prId": 22823
}]