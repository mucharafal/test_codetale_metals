[{
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "How about change scala doc to below to fix **fails to generate documentation**?\r\n```scala\r\n * To run this benchmark:\r\n * {{{\r\n *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\r\n *   2. build/sbt \"sql/test:runMain <this class>\"\r\n *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\r\n *      Results will be written to \"benchmarks/FilterPushdownBenchmark-results.txt\".\r\n * }}}\r\n```\r\nfails to generate documentation error message:\r\n```java\r\n/home/jenkins/workspace/SparkPullRequestBuilder@2/target/javaunidoc/org/apache/spark/mllib/linalg/UDTSerializationBenchmark.html...\r\n[error] /home/jenkins/workspace/SparkPullRequestBuilder@2/mllib/target/java/org/apache/spark/mllib/linalg/UDTSerializationBenchmark.java:5: error: unknown tag: this\r\n[error]  * 1. without sbt: bin/spark-submit --class <this class> <spark mllib test jar>\r\n[error]                                             ^\r\n[error] /home/jenkins/workspace/SparkPullRequestBuilder@2/mllib/target/java/org/apache/spark/mllib/linalg/UDTSerializationBenchmark.java:5: error: unknown tag: spark\r\n[error]  * 1. without sbt: bin/spark-submit --class <this class> <spark mllib test jar>\r\n[error]                                                          ^\r\n[error] /home/jenkins/workspace/SparkPullRequestBuilder@2/mllib/target/java/org/apache/spark/mllib/linalg/UDTSerializationBenchmark.java:6: error: unknown tag: this\r\n[error]  * 2. build/sbt \"mllib/test:runMain <this class>\"\r\n[error]                                     ^\r\n[error] /home/jenkins/workspace/SparkPullRequestBuilder@2/mllib/target/java/org/apache/spark/mllib/linalg/UDTSerializationBenchmark.java:7: error: unknown tag: this\r\n[error]  * 3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"mllib/test:runMain <this class>\"\r\n[error] \r\n```",
    "commit": "1a5e1e927072e4438ea1ce7dc579a6d5b0986835",
    "createdAt": "2018-09-21T05:38:26Z",
    "diffHunk": "@@ -27,7 +27,7 @@ import org.apache.spark.sql.functions.monotonically_increasing_id\n import org.apache.spark.sql.internal.SQLConf\n import org.apache.spark.sql.internal.SQLConf.ParquetOutputTimestampType\n import org.apache.spark.sql.types.{ByteType, Decimal, DecimalType, TimestampType}\n-import org.apache.spark.util.{Benchmark, BenchmarkBase => FileBenchmarkBase, Utils}\n+import org.apache.spark.util.Utils\n \n /**\n  * Benchmark to measure read performance with Filter pushdown.",
    "line": 14
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "Thanks, I have updated the doc ðŸ‘ ",
    "commit": "1a5e1e927072e4438ea1ce7dc579a6d5b0986835",
    "createdAt": "2018-09-21T06:46:20Z",
    "diffHunk": "@@ -27,7 +27,7 @@ import org.apache.spark.sql.functions.monotonically_increasing_id\n import org.apache.spark.sql.internal.SQLConf\n import org.apache.spark.sql.internal.SQLConf.ParquetOutputTimestampType\n import org.apache.spark.sql.types.{ByteType, Decimal, DecimalType, TimestampType}\n-import org.apache.spark.util.{Benchmark, BenchmarkBase => FileBenchmarkBase, Utils}\n+import org.apache.spark.util.Utils\n \n /**\n  * Benchmark to measure read performance with Filter pushdown.",
    "line": 14
  }],
  "prId": 22513
}]