[{
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "Nit: It is strange to me to use blocks. I would rather get rid of `tables` and put the `runShowTablesSql` inside `assert`.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-02T18:27:07Z",
    "diffHunk": "@@ -1646,4 +1651,70 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSQLContext with BeforeAn\n       }\n     }\n   }\n+\n+  test(\"ShowTables using v2 catalog\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table_name (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.n1.n2.db.table_name (id bigint, data string) USING foo\")\n+\n+    {"
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "Fixed as suggested.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-04T01:55:41Z",
    "diffHunk": "@@ -1646,4 +1651,70 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSQLContext with BeforeAn\n       }\n     }\n   }\n+\n+  test(\"ShowTables using v2 catalog\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table_name (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.n1.n2.db.table_name (id bigint, data string) USING foo\")\n+\n+    {"
  }],
  "prId": 25247
}, {
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "This isn't quite accurate. If db is not specified, then it should have an analysis exception if there is a default catalog. If there is not a default catalog, it should fall back to v1.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-02T18:28:06Z",
    "diffHunk": "@@ -1646,4 +1651,70 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSQLContext with BeforeAn\n       }\n     }\n   }\n+\n+  test(\"ShowTables using v2 catalog\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table_name (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.n1.n2.db.table_name (id bigint, data string) USING foo\")\n+\n+    {\n+      val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.db\")\n+      assert(tables === Seq(Row(\"db\", \"table_name\", false)))\n+    }\n+    {\n+      val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.n1.n2.db\")\n+      assert(tables === Seq(Row(\"n1.n2.db\", \"table_name\", false)))\n+    }\n+  }\n+\n+  test(\"ShowTables using v2 catalog with a pattern\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_1 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_2 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db2.table_name_2 (id bigint, data string) USING foo\")\n+\n+    {\n+      val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.db\")\n+      assert(tables === Seq(\n+        Row(\"db\", \"table\", false),\n+        Row(\"db\", \"table_name_1\", false),\n+        Row(\"db\", \"table_name_2\", false)))\n+    }\n+    {\n+      val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.db LIKE '*name*'\")\n+      assert(tables === Seq(\n+        Row(\"db\", \"table_name_1\", false),\n+        Row(\"db\", \"table_name_2\", false)))\n+    }\n+    {\n+      val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.db LIKE '*2'\")\n+      assert(tables === Seq(Row(\"db\", \"table_name_2\", false)))\n+    }\n+  }\n+\n+  test(\"ShowTables: using v2 catalog, db doesn't exist\") {\n+    val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.unknown\")\n+    assert(tables.isEmpty)\n+  }\n+\n+  test(\"ShowTables: db is not specified - fallback to v1\") {"
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "Yes, you are right. I was waiting for your OK with the approach I suggested. I will update the tests now. Thanks!",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-03T06:38:44Z",
    "diffHunk": "@@ -1646,4 +1651,70 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSQLContext with BeforeAn\n       }\n     }\n   }\n+\n+  test(\"ShowTables using v2 catalog\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table_name (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.n1.n2.db.table_name (id bigint, data string) USING foo\")\n+\n+    {\n+      val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.db\")\n+      assert(tables === Seq(Row(\"db\", \"table_name\", false)))\n+    }\n+    {\n+      val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.n1.n2.db\")\n+      assert(tables === Seq(Row(\"n1.n2.db\", \"table_name\", false)))\n+    }\n+  }\n+\n+  test(\"ShowTables using v2 catalog with a pattern\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_1 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_2 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db2.table_name_2 (id bigint, data string) USING foo\")\n+\n+    {\n+      val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.db\")\n+      assert(tables === Seq(\n+        Row(\"db\", \"table\", false),\n+        Row(\"db\", \"table_name_1\", false),\n+        Row(\"db\", \"table_name_2\", false)))\n+    }\n+    {\n+      val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.db LIKE '*name*'\")\n+      assert(tables === Seq(\n+        Row(\"db\", \"table_name_1\", false),\n+        Row(\"db\", \"table_name_2\", false)))\n+    }\n+    {\n+      val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.db LIKE '*2'\")\n+      assert(tables === Seq(Row(\"db\", \"table_name_2\", false)))\n+    }\n+  }\n+\n+  test(\"ShowTables: using v2 catalog, db doesn't exist\") {\n+    val tables = runShowTablesSql(\"SHOW TABLES FROM testcat.unknown\")\n+    assert(tables.isEmpty)\n+  }\n+\n+  test(\"ShowTables: db is not specified - fallback to v1\") {"
  }],
  "prId": 25247
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "In current Spark, `SHOW TABLES FROM non-existing-db` would fail, shall we follow it?",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-12T03:31:15Z",
    "diffHunk": "@@ -1700,6 +1704,126 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSQLContext with BeforeAn\n     }\n   }\n \n+  test(\"ShowTables: using v2 catalog\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table_name (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.n1.n2.db.table_name (id bigint, data string) USING foo\")\n+\n+    runShowTablesSql(\"SHOW TABLES FROM testcat.db\", Seq(Row(\"db\", \"table_name\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.n1.n2.db\",\n+      Seq(Row(\"n1.n2.db\", \"table_name\")))\n+  }\n+\n+  test(\"ShowTables: using v2 catalog with a pattern\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_1 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_2 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db2.table_name_2 (id bigint, data string) USING foo\")\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db\",\n+      Seq(\n+        Row(\"db\", \"table\"),\n+        Row(\"db\", \"table_name_1\"),\n+        Row(\"db\", \"table_name_2\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db LIKE '*name*'\",\n+      Seq(Row(\"db\", \"table_name_1\"), Row(\"db\", \"table_name_2\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db LIKE '*2'\",\n+      Seq(Row(\"db\", \"table_name_2\")))\n+  }\n+\n+  test(\"ShowTables: using v2 catalog, namespace doesn't exist\") {\n+    runShowTablesSql(\"SHOW TABLES FROM testcat.unknown\", Seq())",
    "line": 63
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "@cloud-fan as far as I understand, throwing `NoSuchNamespaceException` is optional in v2:\r\n```\r\n  /**\r\n   * List the tables in a namespace from the catalog.\r\n   * <p>\r\n   * If the catalog supports views, this must return identifiers for only tables and not views.\r\n   *\r\n   * @param namespace a multi-part namespace\r\n   * @return an array of Identifiers for tables\r\n   * @throws NoSuchNamespaceException If the namespace does not exist (optional).\r\n   */\r\n  Identifier[] listTables(String[] namespace) throws NoSuchNamespaceException;\r\n```\r\n\r\nI can update `TestInMemoryTableCatalog` to throw NoSuchNamespaceException if there is no namespace existing for the tables created. However, I am not sure if this is the right approach since you could have created namespace without tables - in v1, you could have done `CREATE DATABASE db` without creating tables belonging to `db`, although I don't think this scenario is supported in v2 yet.\r\n\r\nPlease advise how this needs to be handled. Thanks!\r\n\r\n",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-12T04:24:06Z",
    "diffHunk": "@@ -1700,6 +1704,126 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSQLContext with BeforeAn\n     }\n   }\n \n+  test(\"ShowTables: using v2 catalog\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table_name (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.n1.n2.db.table_name (id bigint, data string) USING foo\")\n+\n+    runShowTablesSql(\"SHOW TABLES FROM testcat.db\", Seq(Row(\"db\", \"table_name\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.n1.n2.db\",\n+      Seq(Row(\"n1.n2.db\", \"table_name\")))\n+  }\n+\n+  test(\"ShowTables: using v2 catalog with a pattern\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_1 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_2 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db2.table_name_2 (id bigint, data string) USING foo\")\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db\",\n+      Seq(\n+        Row(\"db\", \"table\"),\n+        Row(\"db\", \"table_name_1\"),\n+        Row(\"db\", \"table_name_2\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db LIKE '*name*'\",\n+      Seq(Row(\"db\", \"table_name_1\"), Row(\"db\", \"table_name_2\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db LIKE '*2'\",\n+      Seq(Row(\"db\", \"table_name_2\")))\n+  }\n+\n+  test(\"ShowTables: using v2 catalog, namespace doesn't exist\") {\n+    runShowTablesSql(\"SHOW TABLES FROM testcat.unknown\", Seq())",
    "line": 63
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "v2 can support `CREATE NAMESPACE`, we have the APIs in `SupportNamespace`.\r\n\r\nI think this is another case we should discuss: how much should Spark restrict the semantic of a SQL command? e.g. `SHOW TABLE catalog.nonExistingNS`, should Spark guarantee that, this command fails if the namespace doesn't exist?\r\n\r\ncc @brkyvz @rdblue ",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-12T11:34:02Z",
    "diffHunk": "@@ -1700,6 +1704,126 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSQLContext with BeforeAn\n     }\n   }\n \n+  test(\"ShowTables: using v2 catalog\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table_name (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.n1.n2.db.table_name (id bigint, data string) USING foo\")\n+\n+    runShowTablesSql(\"SHOW TABLES FROM testcat.db\", Seq(Row(\"db\", \"table_name\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.n1.n2.db\",\n+      Seq(Row(\"n1.n2.db\", \"table_name\")))\n+  }\n+\n+  test(\"ShowTables: using v2 catalog with a pattern\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_1 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_2 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db2.table_name_2 (id bigint, data string) USING foo\")\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db\",\n+      Seq(\n+        Row(\"db\", \"table\"),\n+        Row(\"db\", \"table_name_1\"),\n+        Row(\"db\", \"table_name_2\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db LIKE '*name*'\",\n+      Seq(Row(\"db\", \"table_name_1\"), Row(\"db\", \"table_name_2\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db LIKE '*2'\",\n+      Seq(Row(\"db\", \"table_name_2\")))\n+  }\n+\n+  test(\"ShowTables: using v2 catalog, namespace doesn't exist\") {\n+    runShowTablesSql(\"SHOW TABLES FROM testcat.unknown\", Seq())",
    "line": 63
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "If the catalog throws `NoSuchNamespaceException`, then the query should fail. If not, then this should return whatever the catalog returned. Throwing `NoSuchNamespaceException` is optional, so I think Spark should respect the catalog's choice of whether to throw it or not in this case.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-12T17:35:23Z",
    "diffHunk": "@@ -1700,6 +1704,126 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSQLContext with BeforeAn\n     }\n   }\n \n+  test(\"ShowTables: using v2 catalog\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table_name (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.n1.n2.db.table_name (id bigint, data string) USING foo\")\n+\n+    runShowTablesSql(\"SHOW TABLES FROM testcat.db\", Seq(Row(\"db\", \"table_name\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.n1.n2.db\",\n+      Seq(Row(\"n1.n2.db\", \"table_name\")))\n+  }\n+\n+  test(\"ShowTables: using v2 catalog with a pattern\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_1 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_2 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db2.table_name_2 (id bigint, data string) USING foo\")\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db\",\n+      Seq(\n+        Row(\"db\", \"table\"),\n+        Row(\"db\", \"table_name_1\"),\n+        Row(\"db\", \"table_name_2\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db LIKE '*name*'\",\n+      Seq(Row(\"db\", \"table_name_1\"), Row(\"db\", \"table_name_2\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db LIKE '*2'\",\n+      Seq(Row(\"db\", \"table_name_2\")))\n+  }\n+\n+  test(\"ShowTables: using v2 catalog, namespace doesn't exist\") {\n+    runShowTablesSql(\"SHOW TABLES FROM testcat.unknown\", Seq())",
    "line": 63
  }],
  "prId": 25247
}, {
  "comments": [{
    "author": {
      "login": "imback82"
    },
    "body": "This test is currently failing and will be updated based on the resolution of https://github.com/apache/spark/pull/25368/files#r315980292.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-21T03:16:21Z",
    "diffHunk": "@@ -1703,6 +1707,113 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSparkSession with Before\n     }\n   }\n \n+  test(\"ShowTables: using v2 catalog\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table_name (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.n1.n2.db.table_name (id bigint, data string) USING foo\")\n+\n+    runShowTablesSql(\"SHOW TABLES FROM testcat.db\", Seq(Row(\"db\", \"table_name\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.n1.n2.db\",\n+      Seq(Row(\"n1.n2.db\", \"table_name\")))\n+  }\n+\n+  test(\"ShowTables: using v2 catalog with a pattern\") {\n+    spark.sql(\"CREATE TABLE testcat.db.table (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_1 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db.table_name_2 (id bigint, data string) USING foo\")\n+    spark.sql(\"CREATE TABLE testcat.db2.table_name_2 (id bigint, data string) USING foo\")\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db\",\n+      Seq(\n+        Row(\"db\", \"table\"),\n+        Row(\"db\", \"table_name_1\"),\n+        Row(\"db\", \"table_name_2\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db LIKE '*name*'\",\n+      Seq(Row(\"db\", \"table_name_1\"), Row(\"db\", \"table_name_2\")))\n+\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM testcat.db LIKE '*2'\",\n+      Seq(Row(\"db\", \"table_name_2\")))\n+  }\n+\n+  test(\"ShowTables: using v2 catalog, namespace doesn't exist\") {\n+    runShowTablesSql(\"SHOW TABLES FROM testcat.unknown\", Seq())\n+  }\n+\n+  test(\"ShowTables: using v1 catalog\") {\n+    runShowTablesSql(\n+      \"SHOW TABLES FROM default\",\n+      Seq(Row(\"\", \"source\", true), Row(\"\", \"source2\", true)),\n+      expectV2Catalog = false)\n+  }\n+\n+  test(\"ShowTables: using v1 catalog, db doesn't exist \") {\n+    // 'db' below resolves to a database name for v1 catalog because there is no catalog named\n+    // 'db' and there is no default catalog set.\n+    val exception = intercept[NoSuchDatabaseException] {\n+      runShowTablesSql(\"SHOW TABLES FROM db\", Seq(), expectV2Catalog = false)\n+    }\n+\n+    assert(exception.getMessage.contains(\"Database 'db' not found\"))\n+  }\n+\n+  test(\"ShowTables: using v1 catalog, db name with multipartIdentifier ('a.b') is not allowed.\") {\n+    val exception = intercept[AnalysisException] {\n+      runShowTablesSql(\"SHOW TABLES FROM a.b\", Seq(), expectV2Catalog = false)\n+    }\n+\n+    assert(exception.getMessage.contains(\"The database name is not valid: a.b\"))\n+  }\n+\n+  test(\"ShowTables: using v2 catalog with empty namespace\") {\n+    spark.sql(\"CREATE TABLE testcat.table (id bigint, data string) USING foo\")\n+    runShowTablesSql(\"SHOW TABLES FROM testcat\", Seq(Row(\"\", \"table\")))\n+  }\n+\n+  test(\"ShowTables: namespace is not specified and default v2 catalog is set\") {\n+    spark.conf.set(\"spark.sql.default.catalog\", \"testcat\")",
    "line": 97
  }],
  "prId": 25247
}, {
  "comments": [{
    "author": {
      "login": "rdblue"
    },
    "body": "Nit: please remove this unnecessary change as well",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-21T20:40:29Z",
    "diffHunk": "@@ -1909,7 +2020,6 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSparkSession with Before\n   }\n }\n \n-"
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "Fixed. Thanks.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-21T22:12:01Z",
    "diffHunk": "@@ -1909,7 +2020,6 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSparkSession with Before\n   }\n }\n \n-"
  }],
  "prId": 25247
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "why is this need? This test suite always clear all the tables after each test case.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-22T09:27:04Z",
    "diffHunk": "@@ -482,6 +482,8 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSparkSession with Before\n \n     val rdd = sparkContext.parallelize(table.asInstanceOf[InMemoryTable].rows)\n     checkAnswer(spark.internalCreateDataFrame(rdd, table.schema), spark.table(\"source\"))\n+\n+    spark.sql(\"DROP TABLE table_name\")"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "I agree",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-22T15:45:34Z",
    "diffHunk": "@@ -482,6 +482,8 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSparkSession with Before\n \n     val rdd = sparkContext.parallelize(table.asInstanceOf[InMemoryTable].rows)\n     checkAnswer(spark.internalCreateDataFrame(rdd, table.schema), spark.table(\"source\"))\n+\n+    spark.sql(\"DROP TABLE table_name\")"
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "These tests create a `table_name` table with v1 catalog (db = default, isTemporary = false). Is there a recommended way to clean this up?",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-22T17:06:42Z",
    "diffHunk": "@@ -482,6 +482,8 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSparkSession with Before\n \n     val rdd = sparkContext.parallelize(table.asInstanceOf[InMemoryTable].rows)\n     checkAnswer(spark.internalCreateDataFrame(rdd, table.schema), spark.table(\"source\"))\n+\n+    spark.sql(\"DROP TABLE table_name\")"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "In `after`, the catalog manager is reset:\r\n\r\n```\r\nspark.sessionState.catalogManager.reset()\r\n```\r\n\r\nThat discards all of the in-memory catalogs and the tables in them so test cases won't conflict.",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-22T17:30:46Z",
    "diffHunk": "@@ -482,6 +482,8 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSparkSession with Before\n \n     val rdd = sparkContext.parallelize(table.asInstanceOf[InMemoryTable].rows)\n     checkAnswer(spark.internalCreateDataFrame(rdd, table.schema), spark.table(\"source\"))\n+\n+    spark.sql(\"DROP TABLE table_name\")"
  }, {
    "author": {
      "login": "imback82"
    },
    "body": "Ah, my mistake. This can be removed, but the `DROP TABLE` below is still valid.\r\n\r\nFor the test below, when the table `table_name` is created, V1 catalog (`SessionCatalog`) is used via `sparkSession.sessionState.catalog`. So, it cannot be reset from `spark.sessionState.catalogManager.reset()`.\r\n\r\nI think `spark.sessionState.catalog.reset()` is a better way to do in `after`.\r\n",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-22T23:04:01Z",
    "diffHunk": "@@ -482,6 +482,8 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSparkSession with Before\n \n     val rdd = sparkContext.parallelize(table.asInstanceOf[InMemoryTable].rows)\n     checkAnswer(spark.internalCreateDataFrame(rdd, table.schema), spark.table(\"source\"))\n+\n+    spark.sql(\"DROP TABLE table_name\")"
  }],
  "prId": 25247
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "ditto",
    "commit": "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "createdAt": "2019-08-22T09:27:12Z",
    "diffHunk": "@@ -498,6 +500,8 @@ class DataSourceV2SQLSuite extends QueryTest with SharedSparkSession with Before\n     val t = catalog(\"session\").asTableCatalog\n       .loadTable(Identifier.of(Array.empty, \"table_name\"))\n     assert(t.isInstanceOf[UnresolvedTable], \"V1 table wasn't returned as an unresolved table\")\n+\n+    spark.sql(\"DROP TABLE table_name\")"
  }],
  "prId": 25247
}]