[{
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "@mengxr Here are two examples to define nondeterministic UDFs.\n",
    "commit": "d2ee5eee7c569b551779a2d73a98c84fd335a4ac",
    "createdAt": "2015-11-01T00:04:01Z",
    "diffHunk": "@@ -191,4 +193,86 @@ class UDFSuite extends QueryTest with SharedSQLContext {\n     // pass a decimal to intExpected.\n     assert(sql(\"SELECT intExpected(1.0)\").head().getInt(0) === 1)\n   }\n+\n+  private def checkNumUDFs(df: DataFrame, expectedNumUDFs: Int): Unit = {\n+    val udfs = df.queryExecution.optimizedPlan.collect {\n+      case p: logical.Project => p.projectList.flatMap {\n+        case e => e.collect {\n+          case udf: ScalaUDF => udf\n+        }\n+      }\n+    }.flatMap(functions => functions)\n+    assert(udfs.length === expectedNumUDFs)\n+  }\n+\n+  test(\"nondeterministic udf: using UDFRegistration\") {\n+    import org.apache.spark.sql.functions._\n+\n+    val deterministicUDF = sqlContext.udf.register(\"plusOne1\", (x: Int) => x + 1)\n+    val nondeterministicUDF = deterministicUDF.nonDeterministic\n+    sqlContext.udf.register(\"plusOne2\", nondeterministicUDF)\n+\n+    {\n+      val df = sql(\"SELECT 1 as a\")\n+        .select(col(\"a\"), deterministicUDF(col(\"a\")).as(\"b\"))\n+        .select(col(\"a\"), col(\"b\"), deterministicUDF(col(\"b\")).as(\"c\"))\n+      checkNumUDFs(df, 3)\n+      checkAnswer(df, Row(1, 2, 3))\n+    }\n+\n+    {\n+      val df = sql(\"SELECT 1 as a\")\n+        .select(col(\"a\"), callUDF(\"plusOne1\", col(\"a\")).as(\"b\"))\n+        .select(col(\"a\"), col(\"b\"), callUDF(\"plusOne1\", col(\"b\")).as(\"c\"))\n+      checkNumUDFs(df, 3)\n+      checkAnswer(df, Row(1, 2, 3))\n+    }\n+\n+    {\n+      val df = sql(\"SELECT 1 as a\")\n+        .select(col(\"a\"), nondeterministicUDF(col(\"a\")).as(\"b\"))\n+        .select(col(\"a\"), col(\"b\"), nondeterministicUDF(col(\"b\")).as(\"c\"))\n+      checkNumUDFs(df, 2)\n+      checkAnswer(df, Row(1, 2, 3))\n+    }\n+\n+    {\n+      val df = sql(\"SELECT 1 as a\")\n+        .select(col(\"a\"), callUDF(\"plusOne2\", col(\"a\")).as(\"b\"))\n+        .select(col(\"a\"), col(\"b\"), callUDF(\"plusOne2\", col(\"b\")).as(\"c\"))\n+      checkNumUDFs(df, 2)\n+      checkAnswer(df, Row(1, 2, 3))\n+    }\n+  }\n+\n+  test(\"nondeterministic udf: using udf function\") {\n+    import org.apache.spark.sql.functions._\n+\n+    val deterministicUDF = udf((x: Int) => x + 1)\n+    val nondeterministicUDF = deterministicUDF.nonDeterministic\n+\n+    {\n+      val df = sql(\"SELECT 1 as a\")\n+        .select(col(\"a\"), deterministicUDF(col(\"a\")).as(\"b\"))\n+        .select(col(\"a\"), col(\"b\"), deterministicUDF(col(\"b\")).as(\"c\"))\n+      checkNumUDFs(df, 3)\n+      checkAnswer(df, Row(1, 2, 3))\n+    }\n+\n+    {\n+      val df = sql(\"SELECT 1 as a\")\n+        .select(col(\"a\"), nondeterministicUDF(col(\"a\")).as(\"b\"))\n+        .select(col(\"a\"), col(\"b\"), nondeterministicUDF(col(\"b\")).as(\"c\"))\n+      checkNumUDFs(df, 2)\n+      checkAnswer(df, Row(1, 2, 3))\n+    }\n+  }"
  }],
  "prId": 9393
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "We can just call `flatten`\n",
    "commit": "d2ee5eee7c569b551779a2d73a98c84fd335a4ac",
    "createdAt": "2015-11-02T05:54:58Z",
    "diffHunk": "@@ -191,4 +193,86 @@ class UDFSuite extends QueryTest with SharedSQLContext {\n     // pass a decimal to intExpected.\n     assert(sql(\"SELECT intExpected(1.0)\").head().getInt(0) === 1)\n   }\n+\n+  private def checkNumUDFs(df: DataFrame, expectedNumUDFs: Int): Unit = {\n+    val udfs = df.queryExecution.optimizedPlan.collect {\n+      case p: logical.Project => p.projectList.flatMap {\n+        case e => e.collect {\n+          case udf: ScalaUDF => udf\n+        }\n+      }\n+    }.flatMap(functions => functions)"
  }],
  "prId": 9393
}, {
  "comments": [{
    "author": {
      "login": "chenghao-intel"
    },
    "body": "The optimization rule `ConstantFolding` probably doesn't work as still the UDF number is 3, but should be 0, right?\n",
    "commit": "d2ee5eee7c569b551779a2d73a98c84fd335a4ac",
    "createdAt": "2015-11-02T08:03:14Z",
    "diffHunk": "@@ -191,4 +193,86 @@ class UDFSuite extends QueryTest with SharedSQLContext {\n     // pass a decimal to intExpected.\n     assert(sql(\"SELECT intExpected(1.0)\").head().getInt(0) === 1)\n   }\n+\n+  private def checkNumUDFs(df: DataFrame, expectedNumUDFs: Int): Unit = {\n+    val udfs = df.queryExecution.optimizedPlan.collect {\n+      case p: logical.Project => p.projectList.flatMap {\n+        case e => e.collect {\n+          case udf: ScalaUDF => udf\n+        }\n+      }\n+    }.flatMap(functions => functions)\n+    assert(udfs.length === expectedNumUDFs)\n+  }\n+\n+  test(\"nondeterministic udf: using UDFRegistration\") {\n+    import org.apache.spark.sql.functions._\n+\n+    val deterministicUDF = sqlContext.udf.register(\"plusOne1\", (x: Int) => x + 1)\n+    val nondeterministicUDF = deterministicUDF.nonDeterministic\n+    sqlContext.udf.register(\"plusOne2\", nondeterministicUDF)\n+\n+    {\n+      val df = sql(\"SELECT 1 as a\")\n+        .select(col(\"a\"), deterministicUDF(col(\"a\")).as(\"b\"))\n+        .select(col(\"a\"), col(\"b\"), deterministicUDF(col(\"b\")).as(\"c\"))\n+      checkNumUDFs(df, 3)"
  }, {
    "author": {
      "login": "yhuai"
    },
    "body": "The default value of `foldable` is false, which is why we see three expressions at here.\n",
    "commit": "d2ee5eee7c569b551779a2d73a98c84fd335a4ac",
    "createdAt": "2015-11-02T17:52:22Z",
    "diffHunk": "@@ -191,4 +193,86 @@ class UDFSuite extends QueryTest with SharedSQLContext {\n     // pass a decimal to intExpected.\n     assert(sql(\"SELECT intExpected(1.0)\").head().getInt(0) === 1)\n   }\n+\n+  private def checkNumUDFs(df: DataFrame, expectedNumUDFs: Int): Unit = {\n+    val udfs = df.queryExecution.optimizedPlan.collect {\n+      case p: logical.Project => p.projectList.flatMap {\n+        case e => e.collect {\n+          case udf: ScalaUDF => udf\n+        }\n+      }\n+    }.flatMap(functions => functions)\n+    assert(udfs.length === expectedNumUDFs)\n+  }\n+\n+  test(\"nondeterministic udf: using UDFRegistration\") {\n+    import org.apache.spark.sql.functions._\n+\n+    val deterministicUDF = sqlContext.udf.register(\"plusOne1\", (x: Int) => x + 1)\n+    val nondeterministicUDF = deterministicUDF.nonDeterministic\n+    sqlContext.udf.register(\"plusOne2\", nondeterministicUDF)\n+\n+    {\n+      val df = sql(\"SELECT 1 as a\")\n+        .select(col(\"a\"), deterministicUDF(col(\"a\")).as(\"b\"))\n+        .select(col(\"a\"), col(\"b\"), deterministicUDF(col(\"b\")).as(\"c\"))\n+      checkNumUDFs(df, 3)"
  }],
  "prId": 9393
}]