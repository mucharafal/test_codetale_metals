[{
  "comments": [{
    "author": {
      "login": "steveloughran"
    },
    "body": "It's not needed here, but it is worth knowing that there is a package scoped static method `Filesystem.addFileSystemForTesting` to actually let you add a specific instance to the file system cache. I use sometimes as it lets me register mob file systems for existing schemes (s3, etc).",
    "commit": "dc48da8ca62ae0f84bb3f73aa4476066d3f963db",
    "createdAt": "2019-09-23T13:19:36Z",
    "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path, RawLocalFileSystem}\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+class DataSourceSuite extends SharedSparkSession {\n+  import TestPaths._\n+\n+  test(\"test glob and non glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        path1.toString,\n+        path2.toString,\n+        globPath1.toString,\n+        globPath2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(resultPaths.toSet == allPathsInFs.toSet)\n+  }\n+\n+  test(\"test glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        globPath1.toString,\n+        globPath2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(\n+      resultPaths.toSet == Set(\n+        globPath1Result1,\n+        globPath1Result2,\n+        globPath2Result1,\n+        globPath2Result2\n+      )\n+    )\n+  }\n+\n+  test(\"test non glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        path1.toString,\n+        path2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(\n+      resultPaths.toSet == Set(\n+        path1,\n+        path2\n+      )\n+    )\n+  }\n+\n+  test(\"test non existent paths\") {\n+    assertThrows[AnalysisException](\n+      DataSource.checkAndGlobPathIfNecessary(\n+        Seq(\n+          path1.toString,\n+          path2.toString,\n+          nonExistentPath.toString\n+        ),\n+        hadoopConf,\n+        checkEmptyGlobPath = true,\n+        checkFilesExist = true\n+      )\n+    )\n+  }\n+\n+  test(\"test non existent glob paths\") {\n+    assertThrows[AnalysisException](\n+      DataSource.checkAndGlobPathIfNecessary(\n+        Seq(\n+          globPath1.toString,\n+          globPath2.toString,\n+          nonExistentGlobPath.toString\n+        ),\n+        hadoopConf,\n+        checkEmptyGlobPath = true,\n+        checkFilesExist = true\n+      )\n+    )\n+  }\n+}\n+\n+object TestPaths {\n+  val hadoopConf = new Configuration()\n+  hadoopConf.set(\"fs.mockFs.impl\", classOf[MockFileSystem].getName)",
    "line": 139
  }],
  "prId": 25899
}, {
  "comments": [{
    "author": {
      "login": "steveloughran"
    },
    "body": "I think it is safest to actually have an authority here, e.g mockFs://mock/somepath1\r\n\r\nFileSystem uses the scheme and authority to cache things, and some of the FS operations work on the path part of the URI, ignoring the authority.",
    "commit": "dc48da8ca62ae0f84bb3f73aa4476066d3f963db",
    "createdAt": "2019-09-23T13:22:42Z",
    "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path, RawLocalFileSystem}\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+class DataSourceSuite extends SharedSparkSession {\n+  import TestPaths._\n+\n+  test(\"test glob and non glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        path1.toString,\n+        path2.toString,\n+        globPath1.toString,\n+        globPath2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(resultPaths.toSet == allPathsInFs.toSet)\n+  }\n+\n+  test(\"test glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        globPath1.toString,\n+        globPath2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(\n+      resultPaths.toSet == Set(\n+        globPath1Result1,\n+        globPath1Result2,\n+        globPath2Result1,\n+        globPath2Result2\n+      )\n+    )\n+  }\n+\n+  test(\"test non glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        path1.toString,\n+        path2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(\n+      resultPaths.toSet == Set(\n+        path1,\n+        path2\n+      )\n+    )\n+  }\n+\n+  test(\"test non existent paths\") {\n+    assertThrows[AnalysisException](\n+      DataSource.checkAndGlobPathIfNecessary(\n+        Seq(\n+          path1.toString,\n+          path2.toString,\n+          nonExistentPath.toString\n+        ),\n+        hadoopConf,\n+        checkEmptyGlobPath = true,\n+        checkFilesExist = true\n+      )\n+    )\n+  }\n+\n+  test(\"test non existent glob paths\") {\n+    assertThrows[AnalysisException](\n+      DataSource.checkAndGlobPathIfNecessary(\n+        Seq(\n+          globPath1.toString,\n+          globPath2.toString,\n+          nonExistentGlobPath.toString\n+        ),\n+        hadoopConf,\n+        checkEmptyGlobPath = true,\n+        checkFilesExist = true\n+      )\n+    )\n+  }\n+}\n+\n+object TestPaths {\n+  val hadoopConf = new Configuration()\n+  hadoopConf.set(\"fs.mockFs.impl\", classOf[MockFileSystem].getName)\n+\n+  val path1: Path = new Path(\"mockFs:///somepath1\")"
  }, {
    "author": {
      "login": "cozos"
    },
    "body": "https://github.com/apache/spark/pull/25899/commits/ba36de4280babd2c564fddeba1c166186747eded",
    "commit": "dc48da8ca62ae0f84bb3f73aa4476066d3f963db",
    "createdAt": "2019-09-24T02:21:31Z",
    "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path, RawLocalFileSystem}\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+class DataSourceSuite extends SharedSparkSession {\n+  import TestPaths._\n+\n+  test(\"test glob and non glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        path1.toString,\n+        path2.toString,\n+        globPath1.toString,\n+        globPath2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(resultPaths.toSet == allPathsInFs.toSet)\n+  }\n+\n+  test(\"test glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        globPath1.toString,\n+        globPath2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(\n+      resultPaths.toSet == Set(\n+        globPath1Result1,\n+        globPath1Result2,\n+        globPath2Result1,\n+        globPath2Result2\n+      )\n+    )\n+  }\n+\n+  test(\"test non glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        path1.toString,\n+        path2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(\n+      resultPaths.toSet == Set(\n+        path1,\n+        path2\n+      )\n+    )\n+  }\n+\n+  test(\"test non existent paths\") {\n+    assertThrows[AnalysisException](\n+      DataSource.checkAndGlobPathIfNecessary(\n+        Seq(\n+          path1.toString,\n+          path2.toString,\n+          nonExistentPath.toString\n+        ),\n+        hadoopConf,\n+        checkEmptyGlobPath = true,\n+        checkFilesExist = true\n+      )\n+    )\n+  }\n+\n+  test(\"test non existent glob paths\") {\n+    assertThrows[AnalysisException](\n+      DataSource.checkAndGlobPathIfNecessary(\n+        Seq(\n+          globPath1.toString,\n+          globPath2.toString,\n+          nonExistentGlobPath.toString\n+        ),\n+        hadoopConf,\n+        checkEmptyGlobPath = true,\n+        checkFilesExist = true\n+      )\n+    )\n+  }\n+}\n+\n+object TestPaths {\n+  val hadoopConf = new Configuration()\n+  hadoopConf.set(\"fs.mockFs.impl\", classOf[MockFileSystem].getName)\n+\n+  val path1: Path = new Path(\"mockFs:///somepath1\")"
  }],
  "prId": 25899
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Small nit: use `===` in asserts",
    "commit": "dc48da8ca62ae0f84bb3f73aa4476066d3f963db",
    "createdAt": "2019-09-23T13:34:41Z",
    "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path, RawLocalFileSystem}\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+class DataSourceSuite extends SharedSparkSession {\n+  import TestPaths._\n+\n+  test(\"test glob and non glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        path1.toString,\n+        path2.toString,\n+        globPath1.toString,\n+        globPath2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(resultPaths.toSet == allPathsInFs.toSet)\n+  }\n+\n+  test(\"test glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        globPath1.toString,\n+        globPath2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(\n+      resultPaths.toSet == Set("
  }, {
    "author": {
      "login": "cozos"
    },
    "body": "https://github.com/apache/spark/pull/25899/commits/41f6cfa07381244e0f1c5bacddeab670ea7050b5",
    "commit": "dc48da8ca62ae0f84bb3f73aa4476066d3f963db",
    "createdAt": "2019-09-24T02:21:43Z",
    "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path, RawLocalFileSystem}\n+\n+import org.apache.spark.sql.AnalysisException\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+class DataSourceSuite extends SharedSparkSession {\n+  import TestPaths._\n+\n+  test(\"test glob and non glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        path1.toString,\n+        path2.toString,\n+        globPath1.toString,\n+        globPath2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(resultPaths.toSet == allPathsInFs.toSet)\n+  }\n+\n+  test(\"test glob paths\") {\n+    val resultPaths = DataSource.checkAndGlobPathIfNecessary(\n+      Seq(\n+        globPath1.toString,\n+        globPath2.toString\n+      ),\n+      hadoopConf,\n+      checkEmptyGlobPath = true,\n+      checkFilesExist = true\n+    )\n+\n+    assert(\n+      resultPaths.toSet == Set("
  }],
  "prId": 25899
}]