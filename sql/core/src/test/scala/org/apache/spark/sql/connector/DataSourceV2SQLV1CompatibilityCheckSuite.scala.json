[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "can we put it in `DataSourceV2SQLSuite`? Seems not worthwhile to have a new suite.",
    "commit": "567bb7c78e6fcda3965d0fe9bcf60609cd96a589",
    "createdAt": "2019-11-12T14:37:45Z",
    "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector\n+\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.sql.{AnalysisException, QueryTest}\n+import org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog\n+import org.apache.spark.sql.internal.SQLConf.V2_SESSION_CATALOG_IMPLEMENTATION\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+class DataSourceV2SQLV1CompatibilityCheckSuite extends QueryTest\n+    with SharedSparkSession\n+    with BeforeAndAfter {\n+\n+  before {\n+    spark.conf.set(V2_SESSION_CATALOG_IMPLEMENTATION.key, classOf[V2SessionCatalog].getName)\n+  }\n+\n+  after {\n+    spark.sessionState.catalog.reset()\n+    spark.sessionState.catalogManager.reset()\n+    spark.sessionState.conf.clear()\n+  }\n+\n+  test(\"DeleteFrom: DELETE is only supported with v2 tables\") {"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "I tried that but unfortunately fails. \r\n\r\nBelow is my understandings (pls correct me if i'm wrong):`DataSourceV2SQLSuite` has set `V2_SESSION_CATALOG_IMPLEMENTATION` to `InMemoryTableSessionCatalog`, but here we need `V2SessionCatalog` which returns a `V1Table` when loading table. We cannot set the current catalog to `V2SessionCatalog` because it doesn't has a register name, and we cannot register `V2SessionCatalog` to a new catalog name because it does not have a constructor without any args. We cannot either set `V2_SESSION_CATALOG_IMPLEMENTATION` to `V2SessionCatalog` because there already has an `V2_SESSION_CATALOG_IMPLEMENTATION` registered. ",
    "commit": "567bb7c78e6fcda3965d0fe9bcf60609cd96a589",
    "createdAt": "2019-11-13T02:38:44Z",
    "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector\n+\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.sql.{AnalysisException, QueryTest}\n+import org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog\n+import org.apache.spark.sql.internal.SQLConf.V2_SESSION_CATALOG_IMPLEMENTATION\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+class DataSourceV2SQLV1CompatibilityCheckSuite extends QueryTest\n+    with SharedSparkSession\n+    with BeforeAndAfter {\n+\n+  before {\n+    spark.conf.set(V2_SESSION_CATALOG_IMPLEMENTATION.key, classOf[V2SessionCatalog].getName)\n+  }\n+\n+  after {\n+    spark.sessionState.catalog.reset()\n+    spark.sessionState.catalogManager.reset()\n+    spark.sessionState.conf.clear()\n+  }\n+\n+  test(\"DeleteFrom: DELETE is only supported with v2 tables\") {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "We can follow `DataSourceV2SQLSuite.CreateTableAsSelect: v2 session catalog can load v1 source table`, to unset the v2 session catalog config and use the default impl.",
    "commit": "567bb7c78e6fcda3965d0fe9bcf60609cd96a589",
    "createdAt": "2019-11-13T08:12:59Z",
    "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector\n+\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.sql.{AnalysisException, QueryTest}\n+import org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog\n+import org.apache.spark.sql.internal.SQLConf.V2_SESSION_CATALOG_IMPLEMENTATION\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+class DataSourceV2SQLV1CompatibilityCheckSuite extends QueryTest\n+    with SharedSparkSession\n+    with BeforeAndAfter {\n+\n+  before {\n+    spark.conf.set(V2_SESSION_CATALOG_IMPLEMENTATION.key, classOf[V2SessionCatalog].getName)\n+  }\n+\n+  after {\n+    spark.sessionState.catalog.reset()\n+    spark.sessionState.catalogManager.reset()\n+    spark.sessionState.conf.clear()\n+  }\n+\n+  test(\"DeleteFrom: DELETE is only supported with v2 tables\") {"
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Yea, that's exactly what i want, thanks!",
    "commit": "567bb7c78e6fcda3965d0fe9bcf60609cd96a589",
    "createdAt": "2019-11-13T08:20:07Z",
    "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector\n+\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.sql.{AnalysisException, QueryTest}\n+import org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog\n+import org.apache.spark.sql.internal.SQLConf.V2_SESSION_CATALOG_IMPLEMENTATION\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+class DataSourceV2SQLV1CompatibilityCheckSuite extends QueryTest\n+    with SharedSparkSession\n+    with BeforeAndAfter {\n+\n+  before {\n+    spark.conf.set(V2_SESSION_CATALOG_IMPLEMENTATION.key, classOf[V2SessionCatalog].getName)\n+  }\n+\n+  after {\n+    spark.sessionState.catalog.reset()\n+    spark.sessionState.catalogManager.reset()\n+    spark.sessionState.conf.clear()\n+  }\n+\n+  test(\"DeleteFrom: DELETE is only supported with v2 tables\") {"
  }],
  "prId": 26464
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "we can use `SimpleScanSource`. Parquet may become v2 in the future, when file source v2 is fully completed.",
    "commit": "567bb7c78e6fcda3965d0fe9bcf60609cd96a589",
    "createdAt": "2019-11-12T14:40:00Z",
    "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector\n+\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.sql.{AnalysisException, QueryTest}\n+import org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog\n+import org.apache.spark.sql.internal.SQLConf.V2_SESSION_CATALOG_IMPLEMENTATION\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+class DataSourceV2SQLV1CompatibilityCheckSuite extends QueryTest\n+    with SharedSparkSession\n+    with BeforeAndAfter {\n+\n+  before {\n+    spark.conf.set(V2_SESSION_CATALOG_IMPLEMENTATION.key, classOf[V2SessionCatalog].getName)\n+  }\n+\n+  after {\n+    spark.sessionState.catalog.reset()\n+    spark.sessionState.catalogManager.reset()\n+    spark.sessionState.conf.clear()\n+  }\n+\n+  test(\"DeleteFrom: DELETE is only supported with v2 tables\") {\n+    val v1Table = \"tbl\"\n+    // val format = classOf[V1FallbackTableCatalog].getName\n+    val format = \"parquet\""
  }, {
    "author": {
      "login": "xianyinxin"
    },
    "body": "Done.",
    "commit": "567bb7c78e6fcda3965d0fe9bcf60609cd96a589",
    "createdAt": "2019-11-13T02:38:56Z",
    "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector\n+\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.sql.{AnalysisException, QueryTest}\n+import org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog\n+import org.apache.spark.sql.internal.SQLConf.V2_SESSION_CATALOG_IMPLEMENTATION\n+import org.apache.spark.sql.test.SharedSparkSession\n+\n+class DataSourceV2SQLV1CompatibilityCheckSuite extends QueryTest\n+    with SharedSparkSession\n+    with BeforeAndAfter {\n+\n+  before {\n+    spark.conf.set(V2_SESSION_CATALOG_IMPLEMENTATION.key, classOf[V2SessionCatalog].getName)\n+  }\n+\n+  after {\n+    spark.sessionState.catalog.reset()\n+    spark.sessionState.catalogManager.reset()\n+    spark.sessionState.conf.clear()\n+  }\n+\n+  test(\"DeleteFrom: DELETE is only supported with v2 tables\") {\n+    val v1Table = \"tbl\"\n+    // val format = classOf[V1FallbackTableCatalog].getName\n+    val format = \"parquet\""
  }],
  "prId": 26464
}]