[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "`withTempPath` can be used instead I believe.",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-17T14:27:34Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "+1",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T01:54:11Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>"
  }],
  "prId": 18654
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Can we just do this simpler? for example,\r\n\r\n```\r\n.listFiles().filter { f =>\r\n  f.isFile && !f.getName.startsWith(\".\") && !f.getName.startsWith(\"_\")\r\n}\r\n```",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-17T14:31:09Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Both is ok I think, just copy this from `HadoopFsRelationSuite`.",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T00:06:03Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Yea. If both are okay, let's go for the shorter one.",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T00:39:49Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "+1 for the shorter one",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T01:54:36Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {"
  }],
  "prId": 18654
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Could I ask what this test targets? I think I am lost around here ...",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-17T14:33:13Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {\n+        override def accept(dir: File, name: String): Boolean = {\n+          !name.startsWith(\".\") && !name.startsWith(\"_\")\n+        }\n+      })\n+      assert(allFiles.length == 10)"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Just make sure the source dir have many files, and the output dir only have 2 files.\r\nIf this make people confuse, just leave a notes and delete the assert?",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T00:08:02Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {\n+        override def accept(dir: File, name: String): Boolean = {\n+          !name.startsWith(\".\") && !name.startsWith(\"_\")\n+        }\n+      })\n+      assert(allFiles.length == 10)"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "but I guess this one (the latter) does not test this change? If this test passes regardless of this PR change, I would rather remove this one.",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T00:44:41Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {\n+        override def accept(dir: File, name: String): Boolean = {\n+          !name.startsWith(\".\") && !name.startsWith(\"_\")\n+        }\n+      })\n+      assert(allFiles.length == 10)"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "OK, I'll remove this assert and leave a note.",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T01:29:55Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {\n+        override def accept(dir: File, name: String): Boolean = {\n+          !name.startsWith(\".\") && !name.startsWith(\"_\")\n+        }\n+      })\n+      assert(allFiles.length == 10)"
  }],
  "prId": 18654
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I would explicitly repartition here.",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-17T14:34:11Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {\n+        override def accept(dir: File, name: String): Boolean = {\n+          !name.startsWith(\".\") && !name.startsWith(\"_\")\n+        }\n+      })\n+      assert(allFiles.length == 10)\n+\n+      withTempDir { dst_dir =>\n+        dst_dir.delete()\n+        df.where(\"id = 50\").write.parquet(dst_dir.toString)"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "why we need repartition?",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T01:55:58Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {\n+        override def accept(dir: File, name: String): Boolean = {\n+          !name.startsWith(\".\") && !name.startsWith(\"_\")\n+        }\n+      })\n+      assert(allFiles.length == 10)\n+\n+      withTempDir { dst_dir =>\n+        dst_dir.delete()\n+        df.where(\"id = 50\").write.parquet(dst_dir.toString)"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I was thinking just in order to make sure the (previous) number of files written out.",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T02:05:27Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {\n+        override def accept(dir: File, name: String): Boolean = {\n+          !name.startsWith(\".\") && !name.startsWith(\"_\")\n+        }\n+      })\n+      assert(allFiles.length == 10)\n+\n+      withTempDir { dst_dir =>\n+        dst_dir.delete()\n+        df.where(\"id = 50\").write.parquet(dst_dir.toString)"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I mean..  for example, if we happen to have few partitions in the `df` in any event, I guess this test can become invalid ...",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T02:20:44Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {\n+        override def accept(dir: File, name: String): Boolean = {\n+          !name.startsWith(\".\") && !name.startsWith(\"_\")\n+        }\n+      })\n+      assert(allFiles.length == 10)\n+\n+      withTempDir { dst_dir =>\n+        dst_dir.delete()\n+        df.where(\"id = 50\").write.parquet(dst_dir.toString)"
  }],
  "prId": 18654
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "Ideally we only need the first partition file if all other partitions are empty, but this is hard to do right now.",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T01:56:44Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {\n+        override def accept(dir: File, name: String): Boolean = {\n+          !name.startsWith(\".\") && !name.startsWith(\"_\")\n+        }\n+      })\n+      assert(allFiles.length == 10)\n+\n+      withTempDir { dst_dir =>\n+        dst_dir.delete()\n+        df.where(\"id = 50\").write.parquet(dst_dir.toString)\n+        val allFiles = dst_dir.listFiles(new FilenameFilter {\n+          override def accept(dir: File, name: String): Boolean = {\n+            !name.startsWith(\".\") && !name.startsWith(\"_\")\n+          }\n+        })\n+        // First partition file and the data file"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Can't agree more,  firstly I try to implement like this but the `FileFormatWriter.write` can only see the iterator of each task self.",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T02:55:39Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.{File, FilenameFilter}\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempDir { dir =>\n+      dir.delete()\n+      spark.range(10000).repartition(10).write.parquet(dir.toString)\n+      val df = spark.read.parquet(dir.toString)\n+      val allFiles = dir.listFiles(new FilenameFilter {\n+        override def accept(dir: File, name: String): Boolean = {\n+          !name.startsWith(\".\") && !name.startsWith(\"_\")\n+        }\n+      })\n+      assert(allFiles.length == 10)\n+\n+      withTempDir { dst_dir =>\n+        dst_dir.delete()\n+        df.where(\"id = 50\").write.parquet(dst_dir.toString)\n+        val allFiles = dst_dir.listFiles(new FilenameFilter {\n+          override def accept(dir: File, name: String): Boolean = {\n+            !name.startsWith(\".\") && !name.startsWith(\"_\")\n+          }\n+        })\n+        // First partition file and the data file"
  }],
  "prId": 18654
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Could we maybe just do as below?\r\n\r\n```scala\r\nwithTempPath { path =>\r\n  spark.range(100).repartition(10).where(\"id = 50\").write.parquet(path)\r\n  val partFiles = path.listFiles()\r\n    .filter(f => f.isFile && !f.getName.startsWith(\".\") && !f.getName.startsWith(\"_\"))    \r\n  assert(partFiles.length === 2)\r\n}\r\n```",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T03:44:23Z",
    "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempPath { dir =>"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "More clear :) No need to create source files in real.",
    "commit": "d118d685374242599a12d6536675ba7aeae4bfb7",
    "createdAt": "2017-07-18T06:05:16Z",
    "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import org.apache.spark.sql.QueryTest\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class FileFormatWriterSuite extends QueryTest with SharedSQLContext {\n+\n+  test(\"empty file should be skipped while write to file\") {\n+    withTempPath { dir =>"
  }],
  "prId": 18654
}]