[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "does this really work? Create a spark conf and leave it there?\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-02T05:04:15Z",
    "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  new SparkConf()\n+    .setMaster(\"local[1]\")\n+    .setAppName(\"microbenchmark\")\n+    .set(\"spark.driver.memory\", \"3g\")"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "Removed\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-03T06:55:56Z",
    "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  new SparkConf()\n+    .setMaster(\"local[1]\")\n+    .setAppName(\"microbenchmark\")\n+    .set(\"spark.driver.memory\", \"3g\")"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "removed\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-03T06:57:22Z",
    "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  new SparkConf()\n+    .setMaster(\"local[1]\")\n+    .setAppName(\"microbenchmark\")\n+    .set(\"spark.driver.memory\", \"3g\")"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "I think we need to benchmark 4 cases:\n1. normal write: generate a random int array and use encoder to turn it into array data, e.g.\n\n```\nval array: Array[Int] = ...\nval encoder = ExpressionEncoder[Array[Int]].resolveAndBind()\nencoder.toRow(array) // benchmark it.\n```\n1. from primitive array: benchmark the `UnsafeArrayData.fromPrimitiveArray`\n2. normal read: generate random array, turn it into array data by encoder, then benchmark the element reading, e.g. `getInt`\n3. to primitive array: benchmark the `UnsafeArrayData.toIntArray`, etc.\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-02T05:13:45Z",
    "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  new SparkConf()\n+    .setMaster(\"local[1]\")\n+    .setAppName(\"microbenchmark\")\n+    .set(\"spark.driver.memory\", \"3g\")\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "I will update an allocation method of `UnsafeArrayData` for \"normal read\". For \"normal write\" I think that it is not possible to turn it into `UnsafeArray` for write. This is because `UnsafeArrayData` does not have a setter method like `write(int)` or `putInt()` method. This is why we use `UnsafeArrayWriter`.\n\nWe have already done for \"from primitive array\" and \"to primitive array\".\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-02T18:58:02Z",
    "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  new SparkConf()\n+    .setMaster(\"local[1]\")\n+    .setAppName(\"microbenchmark\")\n+    .set(\"spark.driver.memory\", \"3g\")\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "`encoder.toRow(array)` actually writes the unsafe array. It will generate code to use the array writer and write the data to buffer holder, I think it's good to benchmark it.\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-03T14:48:50Z",
    "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  new SparkConf()\n+    .setMaster(\"local[1]\")\n+    .setAppName(\"microbenchmark\")\n+    .set(\"spark.driver.memory\", \"3g\")\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "only put the current result here, i.e. with this PR. and put the result without this PR in PR comment.\n\nA benchmark is used to show the performance of current code, not the improvement for some patches, or it will be very hard to maintain.(think about if we improve unsafe array again in the future, how should we update this benchmark?)\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-02T05:22:39Z",
    "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  new SparkConf()\n+    .setMaster(\"local[1]\")\n+    .setAppName(\"microbenchmark\")\n+    .set(\"spark.driver.memory\", \"3g\")\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeArray = new UnsafeArrayData\n+    var intResult: Int = 0\n+    val intSize = calculateHeaderPortionInBytes(count) + 4 * count\n+    val intBuffer = new Array[Byte](intSize)\n+    Platform.putInt(intBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    intUnsafeArray.pointTo(intBuffer, Platform.BYTE_ARRAY_OFFSET, intSize)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeArray = new UnsafeArrayData\n+    var doubleResult: Double = 0\n+    val doubleSize = calculateHeaderPortionInBytes(count) + 8 * count\n+    val doubleBuffer = new Array[Byte](doubleSize)\n+    Platform.putInt(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    doubleUnsafeArray.pointTo(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, doubleSize)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Without SPARK-15962\n+    OpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.0.4-301.fc22.x86_64\n+    Intel Xeon E3-12xx v2 (Ivy Bridge)\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            370 /  471        454.0           2.2       1.0X\n+    Double                                         351 /  466        477.5           2.1       1.1X\n+    */\n+    /*\n+    With SPARK-15962"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "Sure, removed the result without this PR\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-03T07:00:59Z",
    "diffHunk": "@@ -0,0 +1,298 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  new SparkConf()\n+    .setMaster(\"local[1]\")\n+    .setAppName(\"microbenchmark\")\n+    .set(\"spark.driver.memory\", \"3g\")\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeArray = new UnsafeArrayData\n+    var intResult: Int = 0\n+    val intSize = calculateHeaderPortionInBytes(count) + 4 * count\n+    val intBuffer = new Array[Byte](intSize)\n+    Platform.putInt(intBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    intUnsafeArray.pointTo(intBuffer, Platform.BYTE_ARRAY_OFFSET, intSize)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeArray = new UnsafeArrayData\n+    var doubleResult: Double = 0\n+    val doubleSize = calculateHeaderPortionInBytes(count) + 8 * count\n+    val doubleBuffer = new Array[Byte](doubleSize)\n+    Platform.putInt(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    doubleUnsafeArray.pointTo(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, doubleSize)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Without SPARK-15962\n+    OpenJDK 64-Bit Server VM 1.8.0_91-b14 on Linux 4.0.4-301.fc22.x86_64\n+    Intel Xeon E3-12xx v2 (Ivy Bridge)\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            370 /  471        454.0           2.2       1.0X\n+    Double                                         351 /  466        477.5           2.1       1.1X\n+    */\n+    /*\n+    With SPARK-15962"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "looks like we can remove this method?\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-03T14:40:57Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {",
    "line": 37
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "I would like to keep this for ease of supporting multiple versions that have different headers. In this approach, we need to change one place.\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-04T08:48:13Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {",
    "line": 37
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "we should assign some random values for this array.\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-03T14:41:59Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    var intResult: Int = 0\n+    val intBuffer = new Array[Int](count)"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "Done\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-04T18:10:41Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    var intResult: Int = 0\n+    val intBuffer = new Array[Int](count)"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "We should generate a random array, then use encoder to convert it to unsafe array, then follows the benmark.\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-03T14:50:32Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    var intResult: Int = 0\n+    val intBuffer = new Array[Int](count)\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = new Array[Double](count)\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            281 /  296        597.5           1.7       1.0X\n+    Double                                         298 /  301        562.3           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeRow = new UnsafeRow(1)\n+    val intUnsafeArrayWriter = new UnsafeArrayWriter\n+    val intBufferHolder = new BufferHolder(intUnsafeRow, 64)\n+    intBufferHolder.reset()\n+    intUnsafeArrayWriter.initialize(intBufferHolder, count, 4)\n+    val intCursor = intBufferHolder.cursor\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intBufferHolder.cursor = intCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          intUnsafeArrayWriter.write(i, 0.toInt)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeRow = new UnsafeRow(1)\n+    val doubleUnsafeArrayWriter = new UnsafeArrayWriter\n+    val doubleBufferHolder = new BufferHolder(doubleUnsafeRow, 64)\n+    doubleBufferHolder.reset()\n+    doubleUnsafeArrayWriter.initialize(doubleBufferHolder, count, 8)\n+    val doubleCursor = doubleBufferHolder.cursor\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleBufferHolder.cursor = doubleCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          doubleUnsafeArrayWriter.write(i, 0.toDouble)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             82 /   85       2056.9           0.5       1.0X\n+    Double                                         139 /  144       1207.1           0.8       0.6X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intUnsafeArray = new UnsafeArrayData\n+    val intSize = calculateHeaderPortionInBytes(count) + 4 * count\n+    val intBuffer = new Array[Byte](intSize)\n+    Platform.putInt(intBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    intUnsafeArray.pointTo(intBuffer, Platform.BYTE_ARRAY_OFFSET, intSize)"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "Updated\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-04T18:10:59Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    var intResult: Int = 0\n+    val intBuffer = new Array[Int](count)\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = new Array[Double](count)\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            281 /  296        597.5           1.7       1.0X\n+    Double                                         298 /  301        562.3           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeRow = new UnsafeRow(1)\n+    val intUnsafeArrayWriter = new UnsafeArrayWriter\n+    val intBufferHolder = new BufferHolder(intUnsafeRow, 64)\n+    intBufferHolder.reset()\n+    intUnsafeArrayWriter.initialize(intBufferHolder, count, 4)\n+    val intCursor = intBufferHolder.cursor\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intBufferHolder.cursor = intCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          intUnsafeArrayWriter.write(i, 0.toInt)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeRow = new UnsafeRow(1)\n+    val doubleUnsafeArrayWriter = new UnsafeArrayWriter\n+    val doubleBufferHolder = new BufferHolder(doubleUnsafeRow, 64)\n+    doubleBufferHolder.reset()\n+    doubleUnsafeArrayWriter.initialize(doubleBufferHolder, count, 8)\n+    val doubleCursor = doubleBufferHolder.cursor\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleBufferHolder.cursor = doubleCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          doubleUnsafeArrayWriter.write(i, 0.toDouble)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             82 /   85       2056.9           0.5       1.0X\n+    Double                                         139 /  144       1207.1           0.8       0.6X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intUnsafeArray = new UnsafeArrayData\n+    val intSize = calculateHeaderPortionInBytes(count) + 4 * count\n+    val intBuffer = new Array[Byte](intSize)\n+    Platform.putInt(intBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    intUnsafeArray.pointTo(intBuffer, Platform.BYTE_ARRAY_OFFSET, intSize)"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "I'm afraid this will be optimized by JIT. How about use a double and `totalLength += intUnsafeArray.toIntArray.length` here?\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-03T14:51:33Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    var intResult: Int = 0\n+    val intBuffer = new Array[Int](count)\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = new Array[Double](count)\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            281 /  296        597.5           1.7       1.0X\n+    Double                                         298 /  301        562.3           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeRow = new UnsafeRow(1)\n+    val intUnsafeArrayWriter = new UnsafeArrayWriter\n+    val intBufferHolder = new BufferHolder(intUnsafeRow, 64)\n+    intBufferHolder.reset()\n+    intUnsafeArrayWriter.initialize(intBufferHolder, count, 4)\n+    val intCursor = intBufferHolder.cursor\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intBufferHolder.cursor = intCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          intUnsafeArrayWriter.write(i, 0.toInt)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeRow = new UnsafeRow(1)\n+    val doubleUnsafeArrayWriter = new UnsafeArrayWriter\n+    val doubleBufferHolder = new BufferHolder(doubleUnsafeRow, 64)\n+    doubleBufferHolder.reset()\n+    doubleUnsafeArrayWriter.initialize(doubleBufferHolder, count, 8)\n+    val doubleCursor = doubleBufferHolder.cursor\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleBufferHolder.cursor = doubleCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          doubleUnsafeArrayWriter.write(i, 0.toDouble)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             82 /   85       2056.9           0.5       1.0X\n+    Double                                         139 /  144       1207.1           0.8       0.6X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intUnsafeArray = new UnsafeArrayData\n+    val intSize = calculateHeaderPortionInBytes(count) + 4 * count\n+    val intBuffer = new Array[Byte](intSize)\n+    Platform.putInt(intBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    intUnsafeArray.pointTo(intBuffer, Platform.BYTE_ARRAY_OFFSET, intSize)\n+    var intPrimitiveArray: Array[Int] = null\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intPrimitiveArray = intUnsafeArray.toIntArray"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "make sense. done\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-04T18:11:14Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    var intResult: Int = 0\n+    val intBuffer = new Array[Int](count)\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = new Array[Double](count)\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            281 /  296        597.5           1.7       1.0X\n+    Double                                         298 /  301        562.3           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeRow = new UnsafeRow(1)\n+    val intUnsafeArrayWriter = new UnsafeArrayWriter\n+    val intBufferHolder = new BufferHolder(intUnsafeRow, 64)\n+    intBufferHolder.reset()\n+    intUnsafeArrayWriter.initialize(intBufferHolder, count, 4)\n+    val intCursor = intBufferHolder.cursor\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intBufferHolder.cursor = intCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          intUnsafeArrayWriter.write(i, 0.toInt)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeRow = new UnsafeRow(1)\n+    val doubleUnsafeArrayWriter = new UnsafeArrayWriter\n+    val doubleBufferHolder = new BufferHolder(doubleUnsafeRow, 64)\n+    doubleBufferHolder.reset()\n+    doubleUnsafeArrayWriter.initialize(doubleBufferHolder, count, 8)\n+    val doubleCursor = doubleBufferHolder.cursor\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleBufferHolder.cursor = doubleCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          doubleUnsafeArrayWriter.write(i, 0.toDouble)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             82 /   85       2056.9           0.5       1.0X\n+    Double                                         139 /  144       1207.1           0.8       0.6X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intUnsafeArray = new UnsafeArrayData\n+    val intSize = calculateHeaderPortionInBytes(count) + 4 * count\n+    val intBuffer = new Array[Byte](intSize)\n+    Platform.putInt(intBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    intUnsafeArray.pointTo(intBuffer, Platform.BYTE_ARRAY_OFFSET, intSize)\n+    var intPrimitiveArray: Array[Int] = null\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intPrimitiveArray = intUnsafeArray.toIntArray"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "again, we should assign random values here, all-zero array may get optimized.\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-03T14:52:41Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    var intResult: Int = 0\n+    val intBuffer = new Array[Int](count)\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = new Array[Double](count)\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            281 /  296        597.5           1.7       1.0X\n+    Double                                         298 /  301        562.3           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeRow = new UnsafeRow(1)\n+    val intUnsafeArrayWriter = new UnsafeArrayWriter\n+    val intBufferHolder = new BufferHolder(intUnsafeRow, 64)\n+    intBufferHolder.reset()\n+    intUnsafeArrayWriter.initialize(intBufferHolder, count, 4)\n+    val intCursor = intBufferHolder.cursor\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intBufferHolder.cursor = intCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          intUnsafeArrayWriter.write(i, 0.toInt)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeRow = new UnsafeRow(1)\n+    val doubleUnsafeArrayWriter = new UnsafeArrayWriter\n+    val doubleBufferHolder = new BufferHolder(doubleUnsafeRow, 64)\n+    doubleBufferHolder.reset()\n+    doubleUnsafeArrayWriter.initialize(doubleBufferHolder, count, 8)\n+    val doubleCursor = doubleBufferHolder.cursor\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleBufferHolder.cursor = doubleCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          doubleUnsafeArrayWriter.write(i, 0.toDouble)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             82 /   85       2056.9           0.5       1.0X\n+    Double                                         139 /  144       1207.1           0.8       0.6X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intUnsafeArray = new UnsafeArrayData\n+    val intSize = calculateHeaderPortionInBytes(count) + 4 * count\n+    val intBuffer = new Array[Byte](intSize)\n+    Platform.putInt(intBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    intUnsafeArray.pointTo(intBuffer, Platform.BYTE_ARRAY_OFFSET, intSize)\n+    var intPrimitiveArray: Array[Int] = null\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intPrimitiveArray = intUnsafeArray.toIntArray\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeArray = new UnsafeArrayData\n+    val doubleSize = calculateHeaderPortionInBytes(count) + 8 * count\n+    val doubleBuffer = new Array[Byte](doubleSize)\n+    Platform.putInt(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    doubleUnsafeArray.pointTo(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, doubleSize)\n+    var doublePrimitiveArray: Array[Double] = null\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doublePrimitiveArray = doubleUnsafeArray.toDoubleArray\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Get primitive array from UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Get primitive array from UnsafeArrayData: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)  Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            100 /  176        632.1           1.6       1.0X\n+    Double                                         267 /  334        236.0           4.2       0.4X\n+    */\n+  }\n+\n+  def putPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intPrimitiveArray: Array[Int] = new Array[Int](count)"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "done\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-04T18:11:29Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    var intResult: Int = 0\n+    val intBuffer = new Array[Int](count)\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = new Array[Double](count)\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            281 /  296        597.5           1.7       1.0X\n+    Double                                         298 /  301        562.3           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeRow = new UnsafeRow(1)\n+    val intUnsafeArrayWriter = new UnsafeArrayWriter\n+    val intBufferHolder = new BufferHolder(intUnsafeRow, 64)\n+    intBufferHolder.reset()\n+    intUnsafeArrayWriter.initialize(intBufferHolder, count, 4)\n+    val intCursor = intBufferHolder.cursor\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intBufferHolder.cursor = intCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          intUnsafeArrayWriter.write(i, 0.toInt)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeRow = new UnsafeRow(1)\n+    val doubleUnsafeArrayWriter = new UnsafeArrayWriter\n+    val doubleBufferHolder = new BufferHolder(doubleUnsafeRow, 64)\n+    doubleBufferHolder.reset()\n+    doubleUnsafeArrayWriter.initialize(doubleBufferHolder, count, 8)\n+    val doubleCursor = doubleBufferHolder.cursor\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleBufferHolder.cursor = doubleCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          doubleUnsafeArrayWriter.write(i, 0.toDouble)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             82 /   85       2056.9           0.5       1.0X\n+    Double                                         139 /  144       1207.1           0.8       0.6X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intUnsafeArray = new UnsafeArrayData\n+    val intSize = calculateHeaderPortionInBytes(count) + 4 * count\n+    val intBuffer = new Array[Byte](intSize)\n+    Platform.putInt(intBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    intUnsafeArray.pointTo(intBuffer, Platform.BYTE_ARRAY_OFFSET, intSize)\n+    var intPrimitiveArray: Array[Int] = null\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intPrimitiveArray = intUnsafeArray.toIntArray\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeArray = new UnsafeArrayData\n+    val doubleSize = calculateHeaderPortionInBytes(count) + 8 * count\n+    val doubleBuffer = new Array[Byte](doubleSize)\n+    Platform.putInt(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    doubleUnsafeArray.pointTo(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, doubleSize)\n+    var doublePrimitiveArray: Array[Double] = null\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doublePrimitiveArray = doubleUnsafeArray.toDoubleArray\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Get primitive array from UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Get primitive array from UnsafeArrayData: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)  Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            100 /  176        632.1           1.6       1.0X\n+    Double                                         267 /  334        236.0           4.2       0.4X\n+    */\n+  }\n+\n+  def putPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intPrimitiveArray: Array[Int] = new Array[Int](count)"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "other subclasses of `BenchmarkBase` don't have `main` method, is it true that we can run it with `build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"`?\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-03T14:54:59Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    var intResult: Int = 0\n+    val intBuffer = new Array[Int](count)\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = new Array[Double](count)\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            281 /  296        597.5           1.7       1.0X\n+    Double                                         298 /  301        562.3           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeRow = new UnsafeRow(1)\n+    val intUnsafeArrayWriter = new UnsafeArrayWriter\n+    val intBufferHolder = new BufferHolder(intUnsafeRow, 64)\n+    intBufferHolder.reset()\n+    intUnsafeArrayWriter.initialize(intBufferHolder, count, 4)\n+    val intCursor = intBufferHolder.cursor\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intBufferHolder.cursor = intCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          intUnsafeArrayWriter.write(i, 0.toInt)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeRow = new UnsafeRow(1)\n+    val doubleUnsafeArrayWriter = new UnsafeArrayWriter\n+    val doubleBufferHolder = new BufferHolder(doubleUnsafeRow, 64)\n+    doubleBufferHolder.reset()\n+    doubleUnsafeArrayWriter.initialize(doubleBufferHolder, count, 8)\n+    val doubleCursor = doubleBufferHolder.cursor\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleBufferHolder.cursor = doubleCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          doubleUnsafeArrayWriter.write(i, 0.toDouble)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             82 /   85       2056.9           0.5       1.0X\n+    Double                                         139 /  144       1207.1           0.8       0.6X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intUnsafeArray = new UnsafeArrayData\n+    val intSize = calculateHeaderPortionInBytes(count) + 4 * count\n+    val intBuffer = new Array[Byte](intSize)\n+    Platform.putInt(intBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    intUnsafeArray.pointTo(intBuffer, Platform.BYTE_ARRAY_OFFSET, intSize)\n+    var intPrimitiveArray: Array[Int] = null\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intPrimitiveArray = intUnsafeArray.toIntArray\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeArray = new UnsafeArrayData\n+    val doubleSize = calculateHeaderPortionInBytes(count) + 8 * count\n+    val doubleBuffer = new Array[Byte](doubleSize)\n+    Platform.putInt(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    doubleUnsafeArray.pointTo(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, doubleSize)\n+    var doublePrimitiveArray: Array[Double] = null\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doublePrimitiveArray = doubleUnsafeArray.toDoubleArray\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Get primitive array from UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Get primitive array from UnsafeArrayData: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)  Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            100 /  176        632.1           1.6       1.0X\n+    Double                                         267 /  334        236.0           4.2       0.4X\n+    */\n+  }\n+\n+  def putPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intPrimitiveArray: Array[Int] = new Array[Int](count)\n+    var intUnsafeArray: UnsafeArrayData = null\n+    val createIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intUnsafeArray = UnsafeArrayData.fromPrimitiveArray(intPrimitiveArray)\n+        n += 1\n+      }\n+    }\n+\n+    val doublePrimitiveArray: Array[Double] = new Array[Double](count)\n+    var doubleUnsafeArray: UnsafeArrayData = null\n+    val createDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleUnsafeArray = UnsafeArrayData.fromPrimitiveArray(doublePrimitiveArray)\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Create UnsafeArrayData from primitive array\", count * iters)\n+    benchmark.addCase(\"Int\")(createIntArray)\n+    benchmark.addCase(\"Double\")(createDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Create UnsafeArrayData from primitive array: Best/Avg Time(ms)  Rate(M/s)  Per Row(ns)  Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             69 /  168        911.5           1.1       1.0X\n+    Double                                         298 /  328        210.8           4.7       0.2X\n+    */\n+  }\n+\n+  ignore(\"Benchmark UnsafeArrayData\") {\n+    readUnsafeArray(10)\n+    writeUnsafeArray(10)\n+    getPrimitiveArray(5)\n+    putPrimitiveArray(5)\n+  }\n+\n+  def main(args: Array[String]): Unit = {"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "`main()` is not used actually. I will remove it. The steps are as follows:\n1. Replace `ignore(` with `test(`\n2. Run this with `build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"`\n\nI added step 1 in the comment\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-03T17:03:09Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.unsafe.Platform\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    var intResult: Int = 0\n+    val intBuffer = new Array[Int](count)\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = new Array[Double](count)\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            281 /  296        597.5           1.7       1.0X\n+    Double                                         298 /  301        562.3           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeRow = new UnsafeRow(1)\n+    val intUnsafeArrayWriter = new UnsafeArrayWriter\n+    val intBufferHolder = new BufferHolder(intUnsafeRow, 64)\n+    intBufferHolder.reset()\n+    intUnsafeArrayWriter.initialize(intBufferHolder, count, 4)\n+    val intCursor = intBufferHolder.cursor\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intBufferHolder.cursor = intCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          intUnsafeArrayWriter.write(i, 0.toInt)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeRow = new UnsafeRow(1)\n+    val doubleUnsafeArrayWriter = new UnsafeArrayWriter\n+    val doubleBufferHolder = new BufferHolder(doubleUnsafeRow, 64)\n+    doubleBufferHolder.reset()\n+    doubleUnsafeArrayWriter.initialize(doubleBufferHolder, count, 8)\n+    val doubleCursor = doubleBufferHolder.cursor\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleBufferHolder.cursor = doubleCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          doubleUnsafeArrayWriter.write(i, 0.toDouble)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             82 /   85       2056.9           0.5       1.0X\n+    Double                                         139 /  144       1207.1           0.8       0.6X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intUnsafeArray = new UnsafeArrayData\n+    val intSize = calculateHeaderPortionInBytes(count) + 4 * count\n+    val intBuffer = new Array[Byte](intSize)\n+    Platform.putInt(intBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    intUnsafeArray.pointTo(intBuffer, Platform.BYTE_ARRAY_OFFSET, intSize)\n+    var intPrimitiveArray: Array[Int] = null\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intPrimitiveArray = intUnsafeArray.toIntArray\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeArray = new UnsafeArrayData\n+    val doubleSize = calculateHeaderPortionInBytes(count) + 8 * count\n+    val doubleBuffer = new Array[Byte](doubleSize)\n+    Platform.putInt(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, count)\n+    doubleUnsafeArray.pointTo(doubleBuffer, Platform.BYTE_ARRAY_OFFSET, doubleSize)\n+    var doublePrimitiveArray: Array[Double] = null\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doublePrimitiveArray = doubleUnsafeArray.toDoubleArray\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Get primitive array from UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Get primitive array from UnsafeArrayData: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)  Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            100 /  176        632.1           1.6       1.0X\n+    Double                                         267 /  334        236.0           4.2       0.4X\n+    */\n+  }\n+\n+  def putPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+\n+    val intPrimitiveArray: Array[Int] = new Array[Int](count)\n+    var intUnsafeArray: UnsafeArrayData = null\n+    val createIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intUnsafeArray = UnsafeArrayData.fromPrimitiveArray(intPrimitiveArray)\n+        n += 1\n+      }\n+    }\n+\n+    val doublePrimitiveArray: Array[Double] = new Array[Double](count)\n+    var doubleUnsafeArray: UnsafeArrayData = null\n+    val createDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleUnsafeArray = UnsafeArrayData.fromPrimitiveArray(doublePrimitiveArray)\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Create UnsafeArrayData from primitive array\", count * iters)\n+    benchmark.addCase(\"Int\")(createIntArray)\n+    benchmark.addCase(\"Double\")(createDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Create UnsafeArrayData from primitive array: Best/Avg Time(ms)  Rate(M/s)  Per Row(ns)  Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             69 /  168        911.5           1.1       1.0X\n+    Double                                         298 /  328        210.8           4.7       0.2X\n+    */\n+  }\n+\n+  ignore(\"Benchmark UnsafeArrayData\") {\n+    readUnsafeArray(10)\n+    writeUnsafeArray(10)\n+    getPrimitiveArray(5)\n+    putPrimitiveArray(5)\n+  }\n+\n+  def main(args: Array[String]): Unit = {"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "remove this comment?\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-07T04:33:18Z",
    "diffHunk": "@@ -0,0 +1,251 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "we can just return `UnsafeArrayData.calculateHeaderPortionInBytes(count)`\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-07T04:33:40Z",
    "diffHunk": "@@ -0,0 +1,251 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "combine these 2 lines\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-07T04:34:44Z",
    "diffHunk": "@@ -0,0 +1,251 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intResult: Int = 0\n+    val intBuffer = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "unnecessary `toInt`\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-07T04:35:15Z",
    "diffHunk": "@@ -0,0 +1,251 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intResult: Int = 0\n+    val intBuffer = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "`var sum = 0L`\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-07T04:35:56Z",
    "diffHunk": "@@ -0,0 +1,251 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intResult: Int = 0\n+    val intBuffer = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "did you see a very different performance result without this assignment?\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-07T04:36:48Z",
    "diffHunk": "@@ -0,0 +1,251 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intResult: Int = 0\n+    val intBuffer = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "have you seen my comment here? https://github.com/apache/spark/pull/13680/files#r69392823\n\ntesting the array writer is so low level and peoples are more interested in writing the whole array. If you take a look at what `encoder.toRow` does, it generates a project to write the given array into an unsafe row. Although it has some overhead for the row stuff, it's still a good example of writing array.\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-07T04:41:48Z",
    "diffHunk": "@@ -0,0 +1,251 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intResult: Int = 0\n+    val intBuffer = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            279 /  294        600.4           1.7       1.0X\n+    Double                                         296 /  303        567.0           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeRow = new UnsafeRow(1)\n+    val intUnsafeArrayWriter = new UnsafeArrayWriter"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "Got it. My interpretation was to use an `UnsafeArray` generated by `encoder.toRow(array)` for benchmark. I will update `writeUnsafeArray` to measure the elapsed time of `encoder.toRow(array)`\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-07T15:24:06Z",
    "diffHunk": "@@ -0,0 +1,251 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intResult: Int = 0\n+    val intBuffer = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            279 /  294        600.4           1.7       1.0X\n+    Double                                         296 /  303        567.0           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeRow = new UnsafeRow(1)\n+    val intUnsafeArrayWriter = new UnsafeArrayWriter"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "calling it buffer is misleading, it's just the input array data right?\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-07T04:42:47Z",
    "diffHunk": "@@ -0,0 +1,251 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    // Use this assignment for SPARK-15962\n+    // val size = 4 + 4 * count\n+    val size = UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+    size\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intResult: Int = 0\n+    val intBuffer = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intInternalRow = intEncoder.toRow(intBuffer)\n+    val intUnsafeArray = intInternalRow.getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0.toInt\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        intResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    var doubleResult: Double = 0\n+    val doubleBuffer = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleInternalRow = doubleEncoder.toRow(doubleBuffer)\n+    val doubleUnsafeArray = doubleInternalRow.getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.toDouble\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        doubleResult = sum\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            279 /  294        600.4           1.7       1.0X\n+    Double                                         296 /  303        567.0           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+\n+    val intUnsafeRow = new UnsafeRow(1)\n+    val intUnsafeArrayWriter = new UnsafeArrayWriter\n+    val intBufferHolder = new BufferHolder(intUnsafeRow, 64)\n+    intBufferHolder.reset()\n+    intUnsafeArrayWriter.initialize(intBufferHolder, count, 4)\n+    val intCursor = intBufferHolder.cursor\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intBufferHolder.cursor = intCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          intUnsafeArrayWriter.write(i, 0.toInt)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doubleUnsafeRow = new UnsafeRow(1)\n+    val doubleUnsafeArrayWriter = new UnsafeArrayWriter\n+    val doubleBufferHolder = new BufferHolder(doubleUnsafeRow, 64)\n+    doubleBufferHolder.reset()\n+    doubleUnsafeArrayWriter.initialize(doubleBufferHolder, count, 8)\n+    val doubleCursor = doubleBufferHolder.cursor\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleBufferHolder.cursor = doubleCursor\n+        val len = count\n+        var i = 0\n+        while (i < len) {\n+          doubleUnsafeArrayWriter.write(i, 0.toDouble)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             79 /   86       2124.2           0.5       1.0X\n+    Double                                         140 /  147       1201.0           0.8       0.6X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intBuffer = Array.fill[Int](count) { rand.nextInt }"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "put the benchmark result here?\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-07-08T00:29:50Z",
    "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    /* 4 + 4 * count // Use this expression for SPARK-15962 */\n+    UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intUnsafeArray = intEncoder.toRow(intPrimitiveArray).getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleUnsafeArray = doubleEncoder.toRow(doublePrimitiveArray).getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.0\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            279 /  294        600.4           1.7       1.0X\n+    Double                                         296 /  303        567.0           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intTotalLength += intEncoder.toRow(intPrimitiveArray).getArray(0).numElements()\n+        n += 1\n+      }\n+    }\n+\n+    var doubleTotalLength: Int = 0\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleTotalLength += doubleEncoder.toRow(doublePrimitiveArray).getArray(0).numElements()\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run",
    "line": 127
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "let's move `intTotalLength` into this closure, or it may hurt performance\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-09-20T09:13:58Z",
    "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    /* 4 + 4 * count // Use this expression for SPARK-15962 */\n+    UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intUnsafeArray = intEncoder.toRow(intPrimitiveArray).getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleUnsafeArray = doubleEncoder.toRow(doublePrimitiveArray).getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.0\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            279 /  294        600.4           1.7       1.0X\n+    Double                                         296 /  303        567.0           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val writeIntArray = { i: Int =>",
    "line": 101
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "same here\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-09-20T09:14:06Z",
    "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    /* 4 + 4 * count // Use this expression for SPARK-15962 */\n+    UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intUnsafeArray = intEncoder.toRow(intPrimitiveArray).getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleUnsafeArray = doubleEncoder.toRow(doublePrimitiveArray).getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.0\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            279 /  294        600.4           1.7       1.0X\n+    Double                                         296 /  303        567.0           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intTotalLength += intEncoder.toRow(intPrimitiveArray).getArray(0).numElements()\n+        n += 1\n+      }\n+    }\n+\n+    var doubleTotalLength: Int = 0\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val writeDoubleArray = { i: Int =>",
    "line": 114
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "same here\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-09-20T09:14:18Z",
    "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    /* 4 + 4 * count // Use this expression for SPARK-15962 */\n+    UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intUnsafeArray = intEncoder.toRow(intPrimitiveArray).getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleUnsafeArray = doubleEncoder.toRow(doublePrimitiveArray).getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.0\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            279 /  294        600.4           1.7       1.0X\n+    Double                                         296 /  303        567.0           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intTotalLength += intEncoder.toRow(intPrimitiveArray).getArray(0).numElements()\n+        n += 1\n+      }\n+    }\n+\n+    var doubleTotalLength: Int = 0\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleTotalLength += doubleEncoder.toRow(doublePrimitiveArray).getArray(0).numElements()\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            135 /  180        154.9           6.5       1.0X\n+    Double                                         195 /  300        107.8           9.3       0.7X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intUnsafeArray = intEncoder.toRow(intPrimitiveArray).getArray(0)\n+    val readIntArray = { i: Int =>",
    "line": 146
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "same here\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-09-20T09:14:26Z",
    "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    /* 4 + 4 * count // Use this expression for SPARK-15962 */\n+    UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intUnsafeArray = intEncoder.toRow(intPrimitiveArray).getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleUnsafeArray = doubleEncoder.toRow(doublePrimitiveArray).getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.0\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            279 /  294        600.4           1.7       1.0X\n+    Double                                         296 /  303        567.0           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intTotalLength += intEncoder.toRow(intPrimitiveArray).getArray(0).numElements()\n+        n += 1\n+      }\n+    }\n+\n+    var doubleTotalLength: Int = 0\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleTotalLength += doubleEncoder.toRow(doublePrimitiveArray).getArray(0).numElements()\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            135 /  180        154.9           6.5       1.0X\n+    Double                                         195 /  300        107.8           9.3       0.7X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intUnsafeArray = intEncoder.toRow(intPrimitiveArray).getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intTotalLength += intUnsafeArray.toIntArray.length\n+        n += 1\n+      }\n+    }\n+\n+    var doubleTotalLength: Int = 0\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleUnsafeArray = doubleEncoder.toRow(doublePrimitiveArray).getArray(0)\n+    val readDoubleArray = { i: Int =>",
    "line": 160
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "this may get optimized , let's do\n`totalLength += UnsafeArrayData.fromPrimitiveArray(intPrimitiveArray).numElements`\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-09-20T09:15:16Z",
    "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    /* 4 + 4 * count // Use this expression for SPARK-15962 */\n+    UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intUnsafeArray = intEncoder.toRow(intPrimitiveArray).getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleUnsafeArray = doubleEncoder.toRow(doublePrimitiveArray).getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.0\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            279 /  294        600.4           1.7       1.0X\n+    Double                                         296 /  303        567.0           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intTotalLength += intEncoder.toRow(intPrimitiveArray).getArray(0).numElements()\n+        n += 1\n+      }\n+    }\n+\n+    var doubleTotalLength: Int = 0\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleTotalLength += doubleEncoder.toRow(doublePrimitiveArray).getArray(0).numElements()\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            135 /  180        154.9           6.5       1.0X\n+    Double                                         195 /  300        107.8           9.3       0.7X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intUnsafeArray = intEncoder.toRow(intPrimitiveArray).getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intTotalLength += intUnsafeArray.toIntArray.length\n+        n += 1\n+      }\n+    }\n+\n+    var doubleTotalLength: Int = 0\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleUnsafeArray = doubleEncoder.toRow(doublePrimitiveArray).getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleTotalLength += doubleUnsafeArray.toDoubleArray.length\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Get primitive array from UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Get primitive array from UnsafeArrayData: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)  Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             80 /  151        783.4           1.3       1.0X\n+    Double                                         208 /  366        302.8           3.3       0.4X\n+    */\n+  }\n+\n+  def putPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+    val rand = new Random(42)\n+\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    var intUnsafeArray: UnsafeArrayData = null\n+    val createIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intUnsafeArray = UnsafeArrayData.fromPrimitiveArray(intPrimitiveArray)"
  }],
  "prId": 13680
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "same here\n",
    "commit": "2ef6e3bdbd16c7f7b9ff006d48382e108ed37eef",
    "createdAt": "2016-09-20T09:15:22Z",
    "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import scala.util.Random\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.sql.catalyst.expressions.{UnsafeArrayData, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.{BufferHolder, UnsafeArrayWriter}\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark [[UnsafeArrayDataBenchmark]] for UnsafeArrayData\n+ * To run this:\n+ *  1. replace ignore(...) with test(...)\n+ *  2. build/sbt \"sql/test-only *benchmark.UnsafeArrayDataBenchmark\"\n+ *\n+ * Benchmarks in this file are skipped in normal builds.\n+ */\n+class UnsafeArrayDataBenchmark extends BenchmarkBase {\n+\n+  def calculateHeaderPortionInBytes(count: Int) : Int = {\n+    /* 4 + 4 * count // Use this expression for SPARK-15962 */\n+    UnsafeArrayData.calculateHeaderPortionInBytes(count)\n+  }\n+\n+  def readUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intUnsafeArray = intEncoder.toRow(intPrimitiveArray).getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = intUnsafeArray.numElements\n+        var sum = 0\n+        var i = 0\n+        while (i < len) {\n+          sum += intUnsafeArray.getInt(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleUnsafeArray = doubleEncoder.toRow(doublePrimitiveArray).getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        val len = doubleUnsafeArray.numElements\n+        var sum = 0.0\n+        var i = 0\n+        while (i < len) {\n+          sum += doubleUnsafeArray.getDouble(i)\n+          i += 1\n+        }\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Read UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Read UnsafeArrayData:                    Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            279 /  294        600.4           1.7       1.0X\n+    Double                                         296 /  303        567.0           1.8       0.9X\n+    */\n+  }\n+\n+  def writeUnsafeArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 16\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val writeIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intTotalLength += intEncoder.toRow(intPrimitiveArray).getArray(0).numElements()\n+        n += 1\n+      }\n+    }\n+\n+    var doubleTotalLength: Int = 0\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val writeDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleTotalLength += doubleEncoder.toRow(doublePrimitiveArray).getArray(0).numElements()\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Write UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(writeIntArray)\n+    benchmark.addCase(\"Double\")(writeDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Write UnsafeArrayData:                   Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                            135 /  180        154.9           6.5       1.0X\n+    Double                                         195 /  300        107.8           9.3       0.7X\n+    */\n+  }\n+\n+  def getPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+    val rand = new Random(42)\n+\n+    var intTotalLength: Int = 0\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    val intEncoder = ExpressionEncoder[Array[Int]].resolveAndBind()\n+    val intUnsafeArray = intEncoder.toRow(intPrimitiveArray).getArray(0)\n+    val readIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intTotalLength += intUnsafeArray.toIntArray.length\n+        n += 1\n+      }\n+    }\n+\n+    var doubleTotalLength: Int = 0\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    val doubleEncoder = ExpressionEncoder[Array[Double]].resolveAndBind()\n+    val doubleUnsafeArray = doubleEncoder.toRow(doublePrimitiveArray).getArray(0)\n+    val readDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleTotalLength += doubleUnsafeArray.toDoubleArray.length\n+        n += 1\n+      }\n+    }\n+\n+    val benchmark = new Benchmark(\"Get primitive array from UnsafeArrayData\", count * iters)\n+    benchmark.addCase(\"Int\")(readIntArray)\n+    benchmark.addCase(\"Double\")(readDoubleArray)\n+    benchmark.run\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14 on Mac OS X 10.10.4\n+    Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+\n+    Get primitive array from UnsafeArrayData: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)  Relative\n+    ------------------------------------------------------------------------------------------------\n+    Int                                             80 /  151        783.4           1.3       1.0X\n+    Double                                         208 /  366        302.8           3.3       0.4X\n+    */\n+  }\n+\n+  def putPrimitiveArray(iters: Int): Unit = {\n+    val count = 1024 * 1024 * 12\n+    val rand = new Random(42)\n+\n+    val intPrimitiveArray = Array.fill[Int](count) { rand.nextInt }\n+    var intUnsafeArray: UnsafeArrayData = null\n+    val createIntArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        intUnsafeArray = UnsafeArrayData.fromPrimitiveArray(intPrimitiveArray)\n+        n += 1\n+      }\n+    }\n+\n+    val doublePrimitiveArray = Array.fill[Double](count) { rand.nextDouble }\n+    var doubleUnsafeArray: UnsafeArrayData = null\n+    val createDoubleArray = { i: Int =>\n+      var n = 0\n+      while (n < iters) {\n+        doubleUnsafeArray = UnsafeArrayData.fromPrimitiveArray(doublePrimitiveArray)"
  }],
  "prId": 13680
}]