[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Hi, All.\r\nIt turns out that this breaks Scala-2.12 build. I made a PR to fix that. https://github.com/apache/spark/pull/22970\r\n",
    "commit": "610fc315c60b5caec241d7c7774aac1fb683a019",
    "createdAt": "2018-11-08T05:41:11Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Benchmark to measure performance for wide table.\n+ * {{{\n+ *   To run this benchmark:\n+ *   1. without sbt: bin/spark-submit --class <this class>\n+ *        --jars <spark core test jar>,<spark catalyst test jar> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/WideTableBenchmark-results.txt\".\n+ * }}}\n+ */\n+object WideTableBenchmark extends SqlBasedBenchmark {\n+\n+  override def runBenchmarkSuite(mainArgs: Array[String]): Unit = {\n+    runBenchmark(\"projection on wide table\") {\n+      val N = 1 << 20\n+      val df = spark.range(N)\n+      val columns = (0 until 400).map{ i => s\"id as id$i\"}\n+      val benchmark = new Benchmark(\"projection on wide table\", N, output = output)\n+      Seq(\"10\", \"100\", \"1024\", \"2048\", \"4096\", \"8192\", \"65536\").foreach { n =>\n+        benchmark.addCase(s\"split threshold $n\", numIters = 5) { iter =>\n+          withSQLConf(SQLConf.CODEGEN_METHOD_SPLIT_THRESHOLD.key -> n) {\n+            df.selectExpr(columns: _*).foreach(identity(_))",
    "line": 45
  }, {
    "author": {
      "login": "yucai"
    },
    "body": "I see, thanks!",
    "commit": "610fc315c60b5caec241d7c7774aac1fb683a019",
    "createdAt": "2018-11-08T05:54:06Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Benchmark to measure performance for wide table.\n+ * {{{\n+ *   To run this benchmark:\n+ *   1. without sbt: bin/spark-submit --class <this class>\n+ *        --jars <spark core test jar>,<spark catalyst test jar> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/WideTableBenchmark-results.txt\".\n+ * }}}\n+ */\n+object WideTableBenchmark extends SqlBasedBenchmark {\n+\n+  override def runBenchmarkSuite(mainArgs: Array[String]): Unit = {\n+    runBenchmark(\"projection on wide table\") {\n+      val N = 1 << 20\n+      val df = spark.range(N)\n+      val columns = (0 until 400).map{ i => s\"id as id$i\"}\n+      val benchmark = new Benchmark(\"projection on wide table\", N, output = output)\n+      Seq(\"10\", \"100\", \"1024\", \"2048\", \"4096\", \"8192\", \"65536\").foreach { n =>\n+        benchmark.addCase(s\"split threshold $n\", numIters = 5) { iter =>\n+          withSQLConf(SQLConf.CODEGEN_METHOD_SPLIT_THRESHOLD.key -> n) {\n+            df.selectExpr(columns: _*).foreach(identity(_))",
    "line": 45
  }],
  "prId": 22823
}]