[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Shall we assert `true`?",
    "commit": "9a2f640f3e695970c0c4ffe93d6fe978c4013ed1",
    "createdAt": "2018-02-02T00:22:53Z",
    "diffHunk": "@@ -655,4 +655,35 @@ class OrcQuerySuite extends OrcQueryTest with SharedSQLContext {\n       }\n     }\n   }\n+\n+  testQuietly(\"Enabling/disabling ignoreMissingFiles\") {\n+    def testIgnoreMissingFiles(): Unit = {\n+      withTempDir { dir =>\n+        val basePath = dir.getCanonicalPath\n+        spark.range(1).toDF(\"a\").write.orc(new Path(basePath, \"first\").toString)\n+        spark.range(1, 2).toDF(\"a\").write.orc(new Path(basePath, \"second\").toString)\n+        val thirdPath = new Path(basePath, \"third\")\n+        spark.range(2, 3).toDF(\"a\").write.orc(thirdPath.toString)\n+        val df = spark.read.orc(\n+          new Path(basePath, \"first\").toString,\n+          new Path(basePath, \"second\").toString,\n+          new Path(basePath, \"third\").toString)\n+\n+        val fs = thirdPath.getFileSystem(spark.sparkContext.hadoopConfiguration)\n+        fs.delete(thirdPath, true)"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Sure.",
    "commit": "9a2f640f3e695970c0c4ffe93d6fe978c4013ed1",
    "createdAt": "2018-02-02T01:24:05Z",
    "diffHunk": "@@ -655,4 +655,35 @@ class OrcQuerySuite extends OrcQueryTest with SharedSQLContext {\n       }\n     }\n   }\n+\n+  testQuietly(\"Enabling/disabling ignoreMissingFiles\") {\n+    def testIgnoreMissingFiles(): Unit = {\n+      withTempDir { dir =>\n+        val basePath = dir.getCanonicalPath\n+        spark.range(1).toDF(\"a\").write.orc(new Path(basePath, \"first\").toString)\n+        spark.range(1, 2).toDF(\"a\").write.orc(new Path(basePath, \"second\").toString)\n+        val thirdPath = new Path(basePath, \"third\")\n+        spark.range(2, 3).toDF(\"a\").write.orc(thirdPath.toString)\n+        val df = spark.read.orc(\n+          new Path(basePath, \"first\").toString,\n+          new Path(basePath, \"second\").toString,\n+          new Path(basePath, \"third\").toString)\n+\n+        val fs = thirdPath.getFileSystem(spark.sparkContext.hadoopConfiguration)\n+        fs.delete(thirdPath, true)"
  }],
  "prId": 20479
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Basically, this is copied from Parquet. To avoid duplicate codes, create a common base test class for parquet and orc? Then, we can deduplicate the codes? ",
    "commit": "9a2f640f3e695970c0c4ffe93d6fe978c4013ed1",
    "createdAt": "2018-02-02T04:43:17Z",
    "diffHunk": "@@ -655,4 +655,35 @@ class OrcQuerySuite extends OrcQueryTest with SharedSQLContext {\n       }\n     }\n   }\n+\n+  testQuietly(\"Enabling/disabling ignoreMissingFiles\") {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "+1. Which suite is proper for that base test class?",
    "commit": "9a2f640f3e695970c0c4ffe93d6fe978c4013ed1",
    "createdAt": "2018-02-02T05:11:03Z",
    "diffHunk": "@@ -655,4 +655,35 @@ class OrcQuerySuite extends OrcQueryTest with SharedSQLContext {\n       }\n     }\n   }\n+\n+  testQuietly(\"Enabling/disabling ignoreMissingFiles\") {"
  }],
  "prId": 20479
}]