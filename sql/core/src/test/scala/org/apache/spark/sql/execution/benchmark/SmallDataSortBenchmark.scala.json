[{
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "Would you please add the performance results without and with this PR to this space like other benchmarks?",
    "commit": "6f52f1fde3d4df9384e1c99d08b930953843bcde",
    "createdAt": "2018-08-06T08:53:14Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.benchmark\n+\n+import java.io.File\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.util.{Benchmark, Utils}\n+\n+/**\n+  * The benchmarks aims to measure performance of\n+  * [SPARK-24900][SQL]speed up sort when the dataset is small\n+  */\n+object SmallDataSortBenchmark {\n+\n+  val conf = new SparkConf()\n+\n+  val spark = SparkSession.builder\n+    .master(\"local[1]\")\n+    .appName(\"speed up sort when the dataset is small\")\n+    .config(conf)\n+    .getOrCreate()\n+\n+  import spark.implicits._\n+\n+  def withTempPath(f: File => Unit): Unit = {\n+    val path = Utils.createTempDir()\n+    path.delete()\n+    try f(path) finally Utils.deleteRecursively(path)\n+  }\n+\n+  def run(rowsNum: Int): Unit = {\n+    val factor = 1000\n+    val key = rowsNum / 2\n+    val benchmark = new Benchmark(\"speed up sort when the dataset is small\", rowsNum * factor)\n+    withTempPath { path =>\n+      // scalastyle:off println\n+      benchmark.out.println(\"Preparing data for benchmarking ...\")\n+      // scalastyle:on println\n+\n+      val list = (0 to factor).toList\n+\n+      spark.sparkContext.range(0, rowsNum, 1)\n+        .flatMap(num => {\n+          list.map(x => (num, x))\n+        })\n+        .toDF(\"key\", \"value\")\n+        .write\n+        .option(\"encoding\", \"UTF-8\")\n+        .json(path.getAbsolutePath)\n+\n+      benchmark.addCase(\"sort\", 10) { _ =>\n+        val dataset = spark.read.json(path.getAbsolutePath)\n+        dataset.createOrReplaceTempView(\"src\")\n+        val result = spark.\n+          sql(s\"select * from src where key = $key order by value\").collectAsList().size()\n+\n+      }\n+\n+      benchmark.run()"
  }, {
    "author": {
      "login": "sddyljsx"
    },
    "body": "the benchmark has been updated, and the result is\r\n  ```\r\nJava HotSpot(TM) 64-Bit Server VM 1.8.0_91-b14 on Mac OS X 10.13.6\r\nIntel(R) Core(TM) i5-5257U CPU @ 2.70GHz\r\n\r\nspeed up sort when the dataset is small: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------\r\nsort with optimization                      56695 / 61700          1.8         566.9       1.0X\r\nsort without optimization                 112698 / 115274          0.9        1127.0       0.5X\r\n\r\n```\r\n  \r\nthe sql speeds ​​up almost by 100% with this optimization.",
    "commit": "6f52f1fde3d4df9384e1c99d08b930953843bcde",
    "createdAt": "2018-08-07T07:33:27Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.benchmark\n+\n+import java.io.File\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.util.{Benchmark, Utils}\n+\n+/**\n+  * The benchmarks aims to measure performance of\n+  * [SPARK-24900][SQL]speed up sort when the dataset is small\n+  */\n+object SmallDataSortBenchmark {\n+\n+  val conf = new SparkConf()\n+\n+  val spark = SparkSession.builder\n+    .master(\"local[1]\")\n+    .appName(\"speed up sort when the dataset is small\")\n+    .config(conf)\n+    .getOrCreate()\n+\n+  import spark.implicits._\n+\n+  def withTempPath(f: File => Unit): Unit = {\n+    val path = Utils.createTempDir()\n+    path.delete()\n+    try f(path) finally Utils.deleteRecursively(path)\n+  }\n+\n+  def run(rowsNum: Int): Unit = {\n+    val factor = 1000\n+    val key = rowsNum / 2\n+    val benchmark = new Benchmark(\"speed up sort when the dataset is small\", rowsNum * factor)\n+    withTempPath { path =>\n+      // scalastyle:off println\n+      benchmark.out.println(\"Preparing data for benchmarking ...\")\n+      // scalastyle:on println\n+\n+      val list = (0 to factor).toList\n+\n+      spark.sparkContext.range(0, rowsNum, 1)\n+        .flatMap(num => {\n+          list.map(x => (num, x))\n+        })\n+        .toDF(\"key\", \"value\")\n+        .write\n+        .option(\"encoding\", \"UTF-8\")\n+        .json(path.getAbsolutePath)\n+\n+      benchmark.addCase(\"sort\", 10) { _ =>\n+        val dataset = spark.read.json(path.getAbsolutePath)\n+        dataset.createOrReplaceTempView(\"src\")\n+        val result = spark.\n+          sql(s\"select * from src where key = $key order by value\").collectAsList().size()\n+\n+      }\n+\n+      benchmark.run()"
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "It would be good to put the result into the source file as a comment. WDYT?",
    "commit": "6f52f1fde3d4df9384e1c99d08b930953843bcde",
    "createdAt": "2018-08-08T02:06:29Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.benchmark\n+\n+import java.io.File\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.util.{Benchmark, Utils}\n+\n+/**\n+  * The benchmarks aims to measure performance of\n+  * [SPARK-24900][SQL]speed up sort when the dataset is small\n+  */\n+object SmallDataSortBenchmark {\n+\n+  val conf = new SparkConf()\n+\n+  val spark = SparkSession.builder\n+    .master(\"local[1]\")\n+    .appName(\"speed up sort when the dataset is small\")\n+    .config(conf)\n+    .getOrCreate()\n+\n+  import spark.implicits._\n+\n+  def withTempPath(f: File => Unit): Unit = {\n+    val path = Utils.createTempDir()\n+    path.delete()\n+    try f(path) finally Utils.deleteRecursively(path)\n+  }\n+\n+  def run(rowsNum: Int): Unit = {\n+    val factor = 1000\n+    val key = rowsNum / 2\n+    val benchmark = new Benchmark(\"speed up sort when the dataset is small\", rowsNum * factor)\n+    withTempPath { path =>\n+      // scalastyle:off println\n+      benchmark.out.println(\"Preparing data for benchmarking ...\")\n+      // scalastyle:on println\n+\n+      val list = (0 to factor).toList\n+\n+      spark.sparkContext.range(0, rowsNum, 1)\n+        .flatMap(num => {\n+          list.map(x => (num, x))\n+        })\n+        .toDF(\"key\", \"value\")\n+        .write\n+        .option(\"encoding\", \"UTF-8\")\n+        .json(path.getAbsolutePath)\n+\n+      benchmark.addCase(\"sort\", 10) { _ =>\n+        val dataset = spark.read.json(path.getAbsolutePath)\n+        dataset.createOrReplaceTempView(\"src\")\n+        val result = spark.\n+          sql(s\"select * from src where key = $key order by value\").collectAsList().size()\n+\n+      }\n+\n+      benchmark.run()"
  }, {
    "author": {
      "login": "sddyljsx"
    },
    "body": "Yes, I forgot it. I have added it.",
    "commit": "6f52f1fde3d4df9384e1c99d08b930953843bcde",
    "createdAt": "2018-08-08T02:40:37Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.benchmark\n+\n+import java.io.File\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.util.{Benchmark, Utils}\n+\n+/**\n+  * The benchmarks aims to measure performance of\n+  * [SPARK-24900][SQL]speed up sort when the dataset is small\n+  */\n+object SmallDataSortBenchmark {\n+\n+  val conf = new SparkConf()\n+\n+  val spark = SparkSession.builder\n+    .master(\"local[1]\")\n+    .appName(\"speed up sort when the dataset is small\")\n+    .config(conf)\n+    .getOrCreate()\n+\n+  import spark.implicits._\n+\n+  def withTempPath(f: File => Unit): Unit = {\n+    val path = Utils.createTempDir()\n+    path.delete()\n+    try f(path) finally Utils.deleteRecursively(path)\n+  }\n+\n+  def run(rowsNum: Int): Unit = {\n+    val factor = 1000\n+    val key = rowsNum / 2\n+    val benchmark = new Benchmark(\"speed up sort when the dataset is small\", rowsNum * factor)\n+    withTempPath { path =>\n+      // scalastyle:off println\n+      benchmark.out.println(\"Preparing data for benchmarking ...\")\n+      // scalastyle:on println\n+\n+      val list = (0 to factor).toList\n+\n+      spark.sparkContext.range(0, rowsNum, 1)\n+        .flatMap(num => {\n+          list.map(x => (num, x))\n+        })\n+        .toDF(\"key\", \"value\")\n+        .write\n+        .option(\"encoding\", \"UTF-8\")\n+        .json(path.getAbsolutePath)\n+\n+      benchmark.addCase(\"sort\", 10) { _ =>\n+        val dataset = spark.read.json(path.getAbsolutePath)\n+        dataset.createOrReplaceTempView(\"src\")\n+        val result = spark.\n+          sql(s\"select * from src where key = $key order by value\").collectAsList().size()\n+\n+      }\n+\n+      benchmark.run()"
  }],
  "prId": 21859
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "nit: remove unnecessary blank lines. Lines 90 and 94, too.",
    "commit": "6f52f1fde3d4df9384e1c99d08b930953843bcde",
    "createdAt": "2018-08-08T02:05:37Z",
    "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.benchmark\n+\n+import java.io.File\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.util.{Benchmark, Utils}\n+\n+/**\n+  * The benchmarks aims to measure performance of\n+  * [SPARK-24900][SQL]speed up sort when the dataset is small\n+  */\n+object SmallDataSortBenchmark {\n+\n+  val conf = new SparkConf()\n+\n+  val spark = SparkSession.builder\n+    .master(\"local[1]\")\n+    .appName(\"speed up sort when the dataset is small\")\n+    .config(conf)\n+    .getOrCreate()\n+\n+  import spark.implicits._\n+\n+  def withTempPath(f: File => Unit): Unit = {\n+    val path = Utils.createTempDir()\n+    path.delete()\n+    try f(path) finally Utils.deleteRecursively(path)\n+  }\n+\n+  def run(rowsNum: Int): Unit = {\n+    val factor = 1000\n+    val key = rowsNum / 2\n+    val benchmark = new Benchmark(\"speed up sort when the dataset is small\", rowsNum * factor)\n+    withTempPath { path =>\n+      // scalastyle:off println\n+      benchmark.out.println(\"Preparing data for benchmarking ...\")\n+      // scalastyle:on println\n+\n+      val list = (0 to factor).toList\n+\n+      spark.sparkContext.range(0, rowsNum, 1)\n+        .flatMap(num => {\n+          list.map(x => (num, x))\n+        })\n+        .toDF(\"key\", \"value\")\n+        .write\n+        .option(\"encoding\", \"UTF-8\")\n+        .json(path.getAbsolutePath)\n+\n+      val dataset = spark.read.json(path.getAbsolutePath)\n+\n+      dataset.createOrReplaceTempView(\"src\")\n+\n+      benchmark.addCase(\"sort with optimization\", 10) { _ =>\n+        spark.conf.set(\"spark.sql.execution.rangeExchange.sampleCache.enabled\", \"true\")\n+        val result = spark.\n+          sql(s\"select * from src where key = $key order by value\").collectAsList().size()\n+\n+      }\n+\n+      benchmark.addCase(\"sort without optimization\", 10) { _ =>\n+        spark.conf.set(\"spark.sql.execution.rangeExchange.sampleCache.enabled\", \"false\")\n+        val result = spark.\n+          sql(s\"select * from src where key = $key order by value\").collectAsList().size()\n+\n+      }\n+\n+      benchmark.run()\n+    }\n+"
  }, {
    "author": {
      "login": "sddyljsx"
    },
    "body": "I have removed them.",
    "commit": "6f52f1fde3d4df9384e1c99d08b930953843bcde",
    "createdAt": "2018-08-08T02:41:13Z",
    "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.benchmark\n+\n+import java.io.File\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.util.{Benchmark, Utils}\n+\n+/**\n+  * The benchmarks aims to measure performance of\n+  * [SPARK-24900][SQL]speed up sort when the dataset is small\n+  */\n+object SmallDataSortBenchmark {\n+\n+  val conf = new SparkConf()\n+\n+  val spark = SparkSession.builder\n+    .master(\"local[1]\")\n+    .appName(\"speed up sort when the dataset is small\")\n+    .config(conf)\n+    .getOrCreate()\n+\n+  import spark.implicits._\n+\n+  def withTempPath(f: File => Unit): Unit = {\n+    val path = Utils.createTempDir()\n+    path.delete()\n+    try f(path) finally Utils.deleteRecursively(path)\n+  }\n+\n+  def run(rowsNum: Int): Unit = {\n+    val factor = 1000\n+    val key = rowsNum / 2\n+    val benchmark = new Benchmark(\"speed up sort when the dataset is small\", rowsNum * factor)\n+    withTempPath { path =>\n+      // scalastyle:off println\n+      benchmark.out.println(\"Preparing data for benchmarking ...\")\n+      // scalastyle:on println\n+\n+      val list = (0 to factor).toList\n+\n+      spark.sparkContext.range(0, rowsNum, 1)\n+        .flatMap(num => {\n+          list.map(x => (num, x))\n+        })\n+        .toDF(\"key\", \"value\")\n+        .write\n+        .option(\"encoding\", \"UTF-8\")\n+        .json(path.getAbsolutePath)\n+\n+      val dataset = spark.read.json(path.getAbsolutePath)\n+\n+      dataset.createOrReplaceTempView(\"src\")\n+\n+      benchmark.addCase(\"sort with optimization\", 10) { _ =>\n+        spark.conf.set(\"spark.sql.execution.rangeExchange.sampleCache.enabled\", \"true\")\n+        val result = spark.\n+          sql(s\"select * from src where key = $key order by value\").collectAsList().size()\n+\n+      }\n+\n+      benchmark.addCase(\"sort without optimization\", 10) { _ =>\n+        spark.conf.set(\"spark.sql.execution.rangeExchange.sampleCache.enabled\", \"false\")\n+        val result = spark.\n+          sql(s\"select * from src where key = $key order by value\").collectAsList().size()\n+\n+      }\n+\n+      benchmark.run()\n+    }\n+"
  }],
  "prId": 21859
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "For the benchmark, we usually put the baseline result at the first line. Could you switch line 71~78 and 80~87?",
    "commit": "6f52f1fde3d4df9384e1c99d08b930953843bcde",
    "createdAt": "2018-10-23T22:53:52Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution.benchmark\n+\n+import java.io.File\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.util.{Benchmark, Utils}\n+\n+/**\n+ * The benchmarks aims to measure performance of\n+ * [SPARK-24900][SQL]speed up sort when the dataset is small\n+ */\n+object SmallDataSortBenchmark {\n+\n+  val conf = new SparkConf()\n+\n+  val spark = SparkSession.builder\n+    .master(\"local[1]\")\n+    .appName(\"speed up sort when the dataset is small\")\n+    .config(conf)\n+    .getOrCreate()\n+\n+  import spark.implicits._\n+\n+  def withTempPath(f: File => Unit): Unit = {\n+    val path = Utils.createTempDir()\n+    path.delete()\n+    try f(path) finally Utils.deleteRecursively(path)\n+  }\n+\n+  def run(rowsNum: Int): Unit = {\n+    val factor = 1000\n+    val key = rowsNum / 2\n+    val benchmark = new Benchmark(\"small data sort\", rowsNum * factor)\n+    withTempPath { path =>\n+      // scalastyle:off println\n+      benchmark.out.println(\"Preparing data for benchmarking ...\")\n+      // scalastyle:on println\n+\n+      val list = (0 to factor).toList\n+\n+      spark.sparkContext.range(0, rowsNum, 1)\n+        .flatMap(num => {\n+          list.map(x => (num, x))\n+        })\n+        .toDF(\"key\", \"value\")\n+        .write\n+        .option(\"encoding\", \"UTF-8\")\n+        .json(path.getAbsolutePath)\n+\n+      val dataset = spark.read.json(path.getAbsolutePath)\n+\n+      dataset.createOrReplaceTempView(\"src\")\n+\n+      benchmark.addCase(\"with optimization\", 10) { _ =>\n+        // 334 * 3 > 1000, the optimization works\n+        spark.conf.set(\"spark.sql.shuffle.partitions\", dataset.rdd.getNumPartitions)\n+        spark.conf.set(\"spark.sql.execution.rangeExchange.sampleSizePerPartition\", \"334\")\n+        val result = spark.\n+          sql(s\"select * from src where key = $key order by value\").collectAsList().size()\n+\n+      }\n+\n+      benchmark.addCase(\"without optimization\", 10) { _ =>\n+        // 333 * 3 < 1000, the optimization doesn't work\n+        spark.conf.set(\"spark.sql.shuffle.partitions\", dataset.rdd.getNumPartitions)\n+        spark.conf.set(\"spark.sql.execution.rangeExchange.sampleSizePerPartition\", \"333\")\n+        val result = spark.\n+          sql(s\"select * from src where key = $key order by value\").collectAsList().size()\n+\n+      }\n+\n+      /*\n+       * Java HotSpot(TM) 64-Bit Server VM 1.8.0_91-b14 on Mac OS X 10.13.6\n+       * Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz\n+       *\n+       * small data sort:           Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+       * ----------------------------------------------------------------------------------\n+       * with optimization             54077 / 57989          1.8         540.8       1.0X\n+       * without optimization        111780 / 115001          0.9        1117.8       0.5X",
    "line": 96
  }],
  "prId": 21859
}]