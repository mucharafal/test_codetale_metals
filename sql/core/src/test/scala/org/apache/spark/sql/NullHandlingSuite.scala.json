[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "My original proposal is to do it in `SQLQueryTestSuite.scala` like the other `.sql` files. Just curious why you want to write it using Dataset APIs?",
    "commit": "92308a4341849258caf549d1bcbeabd9002d3ead",
    "createdAt": "2017-11-03T16:27:32Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+case class T1(a: Int, b: Option[Int], c: Option[Int])\n+\n+/**\n+ * This test suite takes https://sqlite.org/nulls.html as a reference.\n+ */\n+class NullHandlingSuite extends QueryTest with SharedSQLContext {"
  }, {
    "author": {
      "login": "mgaido91"
    },
    "body": "I wasn't aware of your original proposal, sorry.\r\nI simply prefer it because I think it is less error prone.\r\n\r\nI can change it if you want.",
    "commit": "92308a4341849258caf549d1bcbeabd9002d3ead",
    "createdAt": "2017-11-03T16:35:43Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+case class T1(a: Int, b: Option[Int], c: Option[Int])\n+\n+/**\n+ * This test suite takes https://sqlite.org/nulls.html as a reference.\n+ */\n+class NullHandlingSuite extends QueryTest with SharedSQLContext {"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "When you create a .sql file, you just need to run the command:\r\n> SPARK_GENERATE_GOLDEN_FILES=1 build/sbt \"sql/test-only *SQLQueryTestSuite\"\r\n\r\nWhy you think it is error-prone?",
    "commit": "92308a4341849258caf549d1bcbeabd9002d3ead",
    "createdAt": "2017-11-03T16:57:04Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+case class T1(a: Int, b: Option[Int], c: Option[Int])\n+\n+/**\n+ * This test suite takes https://sqlite.org/nulls.html as a reference.\n+ */\n+class NullHandlingSuite extends QueryTest with SharedSQLContext {"
  }, {
    "author": {
      "login": "mgaido91"
    },
    "body": "I think that in general writing SQL code is more error prone than writing Scala code because there are no compile checks and I prefer to write Scala code than SQL for this reason. Moreover, I think it is easier to do some things like running for loops over all the possible 0's implementations. With SQL I should have copied and pasted the same query multiple times to achieve the same. But maybe this is not even necessary, we can just check one.\r\n\r\nAs I said, I wasn't aware that you had a proposal for the location of the checks, thus I just did what I considered the best option. If you want, I can move them to a sql file.",
    "commit": "92308a4341849258caf549d1bcbeabd9002d3ead",
    "createdAt": "2017-11-03T17:16:11Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+case class T1(a: Int, b: Option[Int], c: Option[Int])\n+\n+/**\n+ * This test suite takes https://sqlite.org/nulls.html as a reference.\n+ */\n+class NullHandlingSuite extends QueryTest with SharedSQLContext {"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Maybe using SQL? It will be easier for the others who knew SQL only to understand our NULL handling logics. Thanks again!",
    "commit": "92308a4341849258caf549d1bcbeabd9002d3ead",
    "createdAt": "2017-11-03T18:47:00Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+case class T1(a: Int, b: Option[Int], c: Option[Int])\n+\n+/**\n+ * This test suite takes https://sqlite.org/nulls.html as a reference.\n+ */\n+class NullHandlingSuite extends QueryTest with SharedSQLContext {"
  }],
  "prId": 19653
}]