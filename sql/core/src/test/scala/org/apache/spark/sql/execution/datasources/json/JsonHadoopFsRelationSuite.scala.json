[{
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "Just curious, why this change?",
    "commit": "9c85b18c059e4ab3b4b25a5b2e414b4f0c67072f",
    "createdAt": "2018-01-23T19:39:15Z",
    "diffHunk": "@@ -110,14 +113,16 @@ class JsonHadoopFsRelationSuite extends HadoopFsRelationTest {\n \n   test(\"invalid json with leading nulls - from file (multiLine=true)\") {\n     import testImplicits._\n-    withTempDir { tempDir =>\n-      val path = tempDir.getAbsolutePath\n-      Seq(badJson, \"\"\"{\"a\":1}\"\"\").toDS().write.mode(\"overwrite\").text(path)\n-      val expected = s\"\"\"$badJson\\n{\"a\":1}\\n\"\"\"\n-      val schema = new StructType().add(\"a\", IntegerType).add(\"_corrupt_record\", StringType)\n-      val df =\n-        spark.read.format(dataSourceName).option(\"multiLine\", true).schema(schema).load(path)\n-      checkAnswer(df, Row(null, expected))\n+    withSQLConf(SQLConf.MAX_RECORDS_PER_FILE.key -> \"2\") {",
    "line": 35
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "The test will fail if `SQLConf.MAX_RECORDS_PER_FILE.key` is less than 2",
    "commit": "9c85b18c059e4ab3b4b25a5b2e414b4f0c67072f",
    "createdAt": "2018-01-23T20:36:17Z",
    "diffHunk": "@@ -110,14 +113,16 @@ class JsonHadoopFsRelationSuite extends HadoopFsRelationTest {\n \n   test(\"invalid json with leading nulls - from file (multiLine=true)\") {\n     import testImplicits._\n-    withTempDir { tempDir =>\n-      val path = tempDir.getAbsolutePath\n-      Seq(badJson, \"\"\"{\"a\":1}\"\"\").toDS().write.mode(\"overwrite\").text(path)\n-      val expected = s\"\"\"$badJson\\n{\"a\":1}\\n\"\"\"\n-      val schema = new StructType().add(\"a\", IntegerType).add(\"_corrupt_record\", StringType)\n-      val df =\n-        spark.read.format(dataSourceName).option(\"multiLine\", true).schema(schema).load(path)\n-      checkAnswer(df, Row(null, expected))\n+    withSQLConf(SQLConf.MAX_RECORDS_PER_FILE.key -> \"2\") {",
    "line": 35
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "I think the default value won't be less than 2, we don't need to be so careful...",
    "commit": "9c85b18c059e4ab3b4b25a5b2e414b4f0c67072f",
    "createdAt": "2018-03-08T06:05:43Z",
    "diffHunk": "@@ -110,14 +113,16 @@ class JsonHadoopFsRelationSuite extends HadoopFsRelationTest {\n \n   test(\"invalid json with leading nulls - from file (multiLine=true)\") {\n     import testImplicits._\n-    withTempDir { tempDir =>\n-      val path = tempDir.getAbsolutePath\n-      Seq(badJson, \"\"\"{\"a\":1}\"\"\").toDS().write.mode(\"overwrite\").text(path)\n-      val expected = s\"\"\"$badJson\\n{\"a\":1}\\n\"\"\"\n-      val schema = new StructType().add(\"a\", IntegerType).add(\"_corrupt_record\", StringType)\n-      val df =\n-        spark.read.format(dataSourceName).option(\"multiLine\", true).schema(schema).load(path)\n-      checkAnswer(df, Row(null, expected))\n+    withSQLConf(SQLConf.MAX_RECORDS_PER_FILE.key -> \"2\") {",
    "line": 35
  }],
  "prId": 20331
}]