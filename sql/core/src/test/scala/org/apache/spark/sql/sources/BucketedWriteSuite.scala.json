[{
  "comments": [{
    "author": {
      "login": "tejasapatil"
    },
    "body": "curious : why is `orc` not in this list ?",
    "commit": "3ecf1872550b72d5eb21e607e23fb07f503ba2f2",
    "createdAt": "2017-02-21T19:39:52Z",
    "diffHunk": "@@ -20,19 +20,29 @@ package org.apache.spark.sql.sources\n import java.io.File\n import java.net.URI\n \n-import org.apache.spark.SparkException\n import org.apache.spark.sql.{AnalysisException, QueryTest}\n import org.apache.spark.sql.catalyst.expressions.UnsafeProjection\n import org.apache.spark.sql.catalyst.plans.physical.HashPartitioning\n import org.apache.spark.sql.execution.datasources.BucketingUtils\n import org.apache.spark.sql.functions._\n-import org.apache.spark.sql.hive.test.TestHiveSingleton\n import org.apache.spark.sql.internal.SQLConf\n-import org.apache.spark.sql.test.SQLTestUtils\n+import org.apache.spark.sql.internal.StaticSQLConf.CATALOG_IMPLEMENTATION\n+import org.apache.spark.sql.test.{SharedSQLContext, SQLTestUtils}\n \n-class BucketedWriteSuite extends QueryTest with SQLTestUtils with TestHiveSingleton {\n+class BucketedWriteWithoutHiveSupportSuite extends BucketedWriteSuite with SharedSQLContext {\n+  protected override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    assume(spark.sparkContext.conf.get(CATALOG_IMPLEMENTATION) == \"in-memory\")\n+  }\n+\n+  override protected def fileFormatsToTest: Seq[String] = Seq(\"parquet\", \"json\")",
    "line": 23
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "`orc` is not available in sql/core package. : (",
    "commit": "3ecf1872550b72d5eb21e607e23fb07f503ba2f2",
    "createdAt": "2017-02-21T19:47:54Z",
    "diffHunk": "@@ -20,19 +20,29 @@ package org.apache.spark.sql.sources\n import java.io.File\n import java.net.URI\n \n-import org.apache.spark.SparkException\n import org.apache.spark.sql.{AnalysisException, QueryTest}\n import org.apache.spark.sql.catalyst.expressions.UnsafeProjection\n import org.apache.spark.sql.catalyst.plans.physical.HashPartitioning\n import org.apache.spark.sql.execution.datasources.BucketingUtils\n import org.apache.spark.sql.functions._\n-import org.apache.spark.sql.hive.test.TestHiveSingleton\n import org.apache.spark.sql.internal.SQLConf\n-import org.apache.spark.sql.test.SQLTestUtils\n+import org.apache.spark.sql.internal.StaticSQLConf.CATALOG_IMPLEMENTATION\n+import org.apache.spark.sql.test.{SharedSQLContext, SQLTestUtils}\n \n-class BucketedWriteSuite extends QueryTest with SQLTestUtils with TestHiveSingleton {\n+class BucketedWriteWithoutHiveSupportSuite extends BucketedWriteSuite with SharedSQLContext {\n+  protected override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    assume(spark.sparkContext.conf.get(CATALOG_IMPLEMENTATION) == \"in-memory\")\n+  }\n+\n+  override protected def fileFormatsToTest: Seq[String] = Seq(\"parquet\", \"json\")",
    "line": 23
  }],
  "prId": 17004
}]