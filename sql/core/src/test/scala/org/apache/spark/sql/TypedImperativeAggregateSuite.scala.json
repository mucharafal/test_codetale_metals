[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "why do we need to save it to a member variable? I think the bug can be exposed even if we just return the buffer here.",
    "commit": "28ea0f9e9fefe7a23ab43843286812a68e9fa7b9",
    "createdAt": "2019-03-21T18:40:43Z",
    "diffHunk": "@@ -299,5 +319,86 @@ object TypedImperativeAggregateSuite {\n     }\n   }\n \n+  /**\n+   * Calculate the max value with object aggregation buffer. This stores class MaxValue\n+   * in aggregation buffer.\n+   */\n+  private case class TypedMax2(\n+    child: Expression,\n+    nullable: Boolean = false,\n+    mutableAggBufferOffset: Int = 0,\n+    inputAggBufferOffset: Int = 0)\n+    extends TypedImperativeAggregate[MaxValue] with ImplicitCastInputTypes {\n+\n+\n+    var maxValueBuffer: MaxValue = null\n+    override def createAggregationBuffer(): MaxValue = {\n+      // Returns Int.MinValue if all inputs are null\n+      maxValueBuffer = new MaxValue(Int.MinValue)"
  }, {
    "author": {
      "login": "pgandhi999"
    },
    "body": "@cloud-fan I am still looking more into it, but for some reason, calling merge() without invoking initialize() does not cause any visible exception on normal UDAF functions, but it fails with a Null Pointer Exception when I test it with the test case described in SPARK-24935(PR #24144 ). My guess is that for the above test case, since, two different aggregation buffer instances are created(SketchState and UnionState), the exception shows up. Will investigate more on it and get back to you soon. Thank you.",
    "commit": "28ea0f9e9fefe7a23ab43843286812a68e9fa7b9",
    "createdAt": "2019-03-22T18:22:42Z",
    "diffHunk": "@@ -299,5 +319,86 @@ object TypedImperativeAggregateSuite {\n     }\n   }\n \n+  /**\n+   * Calculate the max value with object aggregation buffer. This stores class MaxValue\n+   * in aggregation buffer.\n+   */\n+  private case class TypedMax2(\n+    child: Expression,\n+    nullable: Boolean = false,\n+    mutableAggBufferOffset: Int = 0,\n+    inputAggBufferOffset: Int = 0)\n+    extends TypedImperativeAggregate[MaxValue] with ImplicitCastInputTypes {\n+\n+\n+    var maxValueBuffer: MaxValue = null\n+    override def createAggregationBuffer(): MaxValue = {\n+      // Returns Int.MinValue if all inputs are null\n+      maxValueBuffer = new MaxValue(Int.MinValue)"
  }],
  "prId": 24149
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "4 space indentation.",
    "commit": "28ea0f9e9fefe7a23ab43843286812a68e9fa7b9",
    "createdAt": "2019-05-07T05:46:34Z",
    "diffHunk": "@@ -299,5 +319,87 @@ object TypedImperativeAggregateSuite {\n     }\n   }\n \n+  /**\n+   * Calculate the max value with object aggregation buffer. This stores class MaxValue\n+   * in aggregation buffer.\n+   */\n+  private case class TypedMax2(\n+    child: Expression,"
  }],
  "prId": 24149
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "can we simplify it? I think we just need to do some initialization work in  `createAggregationBuffer`.\r\n```\r\ncase class MyUDAF ... {\r\n  var initialized = false\r\n  override def createAggregationBuffer(): MyBuffer = {\r\n    initialized = true\r\n    null\r\n  }\r\n\r\n  override def update(buffer: MaxValue, input: InternalRow): MyBuffer = {\r\n    assert(initialized)\r\n    null\r\n  }\r\n\r\n  ...\r\n}\r\n```",
    "commit": "28ea0f9e9fefe7a23ab43843286812a68e9fa7b9",
    "createdAt": "2019-05-07T05:49:46Z",
    "diffHunk": "@@ -299,5 +319,87 @@ object TypedImperativeAggregateSuite {\n     }\n   }\n \n+  /**\n+   * Calculate the max value with object aggregation buffer. This stores class MaxValue\n+   * in aggregation buffer.\n+   */\n+  private case class TypedMax2("
  }],
  "prId": 24149
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit: we should not use `show` in the test. Let's use `checkAnswer`.",
    "commit": "28ea0f9e9fefe7a23ab43843286812a68e9fa7b9",
    "createdAt": "2019-05-07T16:42:51Z",
    "diffHunk": "@@ -210,6 +211,14 @@ class TypedImperativeAggregateSuite extends QueryTest with SharedSQLContext {\n     checkAnswer(query, expected)\n   }\n \n+  test(\"SPARK-27207: Ensure aggregate buffers are initialized again for SortBasedAggregate\") {\n+    withSQLConf(\"spark.sql.objectHashAggregate.sortBased.fallbackThreshold\" -> \"5\") {\n+      val df = data.toDF(\"value\", \"key\").coalesce(2)\n+      val query = df.groupBy($\"key\").agg(typedMax2($\"value\"), count($\"value\"), typedMax2($\"value\"))\n+      query.show(10, false)"
  }],
  "prId": 24149
}]