[{
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Can we also add comment to explain which tests exercise this method?\n",
    "commit": "d1bcb495307b72b831e2b1aff540d6000019b973",
    "createdAt": "2016-11-02T04:04:48Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.sources\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession, SQLContext}\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.execution.datasources.LogicalRelation\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.types.StructType\n+\n+class TestOptionsSource extends RelationProvider with CreatableRelationProvider {\n+\n+  override def createRelation(\n+      sqlContext: SQLContext,\n+      parameters: Map[String, String]): BaseRelation = {\n+    new TestOptionsRelation(parameters)(sqlContext.sparkSession)"
  }],
  "prId": 15024
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "This test case is still calling the `InMemoryCatalog.renameTable`. Thus, we still need a test case to verify the behavior of `HiveExternalCatalog.renameTable`\n",
    "commit": "d1bcb495307b72b831e2b1aff540d6000019b973",
    "createdAt": "2016-11-02T05:25:32Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.sources\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession, SQLContext}\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.execution.datasources.LogicalRelation\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.types.StructType\n+\n+class TestOptionsSource extends RelationProvider with CreatableRelationProvider {\n+\n+  override def createRelation(\n+      sqlContext: SQLContext,\n+      parameters: Map[String, String]): BaseRelation = {\n+    new TestOptionsRelation(parameters)(sqlContext.sparkSession)\n+  }\n+\n+  override def createRelation(\n+      sqlContext: SQLContext,\n+      mode: SaveMode,\n+      parameters: Map[String, String],\n+      data: DataFrame): BaseRelation = {\n+    new TestOptionsRelation(parameters)(sqlContext.sparkSession)\n+  }\n+}\n+\n+class TestOptionsRelation(val options: Map[String, String])(@transient val session: SparkSession)\n+  extends BaseRelation {\n+\n+  override def sqlContext: SQLContext = session.sqlContext\n+\n+  override def schema: StructType = new StructType().add(\"i\", \"int\")\n+}\n+\n+class PathOptionSuite extends DataSourceTest with SharedSQLContext {\n+\n+  test(\"path option always exist\") {\n+    withTable(\"src\") {\n+      sql(\n+        s\"\"\"\n+           |CREATE TABLE src(i int)\n+           |USING ${classOf[TestOptionsSource].getCanonicalName}\n+           |OPTIONS (PATH '/tmp/path')\"\"\".stripMargin)\n+      assert(getPathOption(\"src\") == Some(\"/tmp/path\"))\n+    }\n+\n+    // should exist even path option is not specified when creating table\n+    withTable(\"src\") {\n+      sql(s\"CREATE TABLE src(i int) USING ${classOf[TestOptionsSource].getCanonicalName}\")\n+      assert(getPathOption(\"src\") == Some(defaultTablePath(\"src\")))\n+    }\n+  }\n+\n+  test(\"path option always represent the value of table location\") {\n+    withTable(\"src\") {\n+      sql(\n+        s\"\"\"\n+           |CREATE TABLE src(i int)\n+           |USING ${classOf[TestOptionsSource].getCanonicalName}\n+           |OPTIONS (PATH '/tmp/path')\"\"\".stripMargin)\n+      sql(\"ALTER TABLE src SET LOCATION '/tmp/path2'\")\n+      assert(getPathOption(\"src\") == Some(\"/tmp/path2\"))\n+    }\n+\n+    withTable(\"src\", \"src2\") {\n+      sql(s\"CREATE TABLE src(i int) USING ${classOf[TestOptionsSource].getCanonicalName}\")\n+      sql(\"ALTER TABLE src RENAME TO src2\")",
    "line": 122
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "It's nothing about `ExternalCatalog`, as `ExternalCatalog` doesn't need to know about the path option. We generate the path option outside of `ExternalCatalog`, and we only need `ExternalCatalog` to put table location in the `locationUri` field correctly.\n",
    "commit": "d1bcb495307b72b831e2b1aff540d6000019b973",
    "createdAt": "2016-11-02T07:36:53Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.sources\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession, SQLContext}\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.execution.datasources.LogicalRelation\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.types.StructType\n+\n+class TestOptionsSource extends RelationProvider with CreatableRelationProvider {\n+\n+  override def createRelation(\n+      sqlContext: SQLContext,\n+      parameters: Map[String, String]): BaseRelation = {\n+    new TestOptionsRelation(parameters)(sqlContext.sparkSession)\n+  }\n+\n+  override def createRelation(\n+      sqlContext: SQLContext,\n+      mode: SaveMode,\n+      parameters: Map[String, String],\n+      data: DataFrame): BaseRelation = {\n+    new TestOptionsRelation(parameters)(sqlContext.sparkSession)\n+  }\n+}\n+\n+class TestOptionsRelation(val options: Map[String, String])(@transient val session: SparkSession)\n+  extends BaseRelation {\n+\n+  override def sqlContext: SQLContext = session.sqlContext\n+\n+  override def schema: StructType = new StructType().add(\"i\", \"int\")\n+}\n+\n+class PathOptionSuite extends DataSourceTest with SharedSQLContext {\n+\n+  test(\"path option always exist\") {\n+    withTable(\"src\") {\n+      sql(\n+        s\"\"\"\n+           |CREATE TABLE src(i int)\n+           |USING ${classOf[TestOptionsSource].getCanonicalName}\n+           |OPTIONS (PATH '/tmp/path')\"\"\".stripMargin)\n+      assert(getPathOption(\"src\") == Some(\"/tmp/path\"))\n+    }\n+\n+    // should exist even path option is not specified when creating table\n+    withTable(\"src\") {\n+      sql(s\"CREATE TABLE src(i int) USING ${classOf[TestOptionsSource].getCanonicalName}\")\n+      assert(getPathOption(\"src\") == Some(defaultTablePath(\"src\")))\n+    }\n+  }\n+\n+  test(\"path option always represent the value of table location\") {\n+    withTable(\"src\") {\n+      sql(\n+        s\"\"\"\n+           |CREATE TABLE src(i int)\n+           |USING ${classOf[TestOptionsSource].getCanonicalName}\n+           |OPTIONS (PATH '/tmp/path')\"\"\".stripMargin)\n+      sql(\"ALTER TABLE src SET LOCATION '/tmp/path2'\")\n+      assert(getPathOption(\"src\") == Some(\"/tmp/path2\"))\n+    }\n+\n+    withTable(\"src\", \"src2\") {\n+      sql(s\"CREATE TABLE src(i int) USING ${classOf[TestOptionsSource].getCanonicalName}\")\n+      sql(\"ALTER TABLE src RENAME TO src2\")",
    "line": 122
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Agree. But we still need a test case to verify the code path and the behavior you mentioned above. So far, it sounds like we do not have any end-to-end test case for `RENAME TABLE` using HiveExternalCatalog. I manually verified it and it works.\n",
    "commit": "d1bcb495307b72b831e2b1aff540d6000019b973",
    "createdAt": "2016-11-02T07:45:31Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.sources\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession, SQLContext}\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.execution.datasources.LogicalRelation\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.types.StructType\n+\n+class TestOptionsSource extends RelationProvider with CreatableRelationProvider {\n+\n+  override def createRelation(\n+      sqlContext: SQLContext,\n+      parameters: Map[String, String]): BaseRelation = {\n+    new TestOptionsRelation(parameters)(sqlContext.sparkSession)\n+  }\n+\n+  override def createRelation(\n+      sqlContext: SQLContext,\n+      mode: SaveMode,\n+      parameters: Map[String, String],\n+      data: DataFrame): BaseRelation = {\n+    new TestOptionsRelation(parameters)(sqlContext.sparkSession)\n+  }\n+}\n+\n+class TestOptionsRelation(val options: Map[String, String])(@transient val session: SparkSession)\n+  extends BaseRelation {\n+\n+  override def sqlContext: SQLContext = session.sqlContext\n+\n+  override def schema: StructType = new StructType().add(\"i\", \"int\")\n+}\n+\n+class PathOptionSuite extends DataSourceTest with SharedSQLContext {\n+\n+  test(\"path option always exist\") {\n+    withTable(\"src\") {\n+      sql(\n+        s\"\"\"\n+           |CREATE TABLE src(i int)\n+           |USING ${classOf[TestOptionsSource].getCanonicalName}\n+           |OPTIONS (PATH '/tmp/path')\"\"\".stripMargin)\n+      assert(getPathOption(\"src\") == Some(\"/tmp/path\"))\n+    }\n+\n+    // should exist even path option is not specified when creating table\n+    withTable(\"src\") {\n+      sql(s\"CREATE TABLE src(i int) USING ${classOf[TestOptionsSource].getCanonicalName}\")\n+      assert(getPathOption(\"src\") == Some(defaultTablePath(\"src\")))\n+    }\n+  }\n+\n+  test(\"path option always represent the value of table location\") {\n+    withTable(\"src\") {\n+      sql(\n+        s\"\"\"\n+           |CREATE TABLE src(i int)\n+           |USING ${classOf[TestOptionsSource].getCanonicalName}\n+           |OPTIONS (PATH '/tmp/path')\"\"\".stripMargin)\n+      sql(\"ALTER TABLE src SET LOCATION '/tmp/path2'\")\n+      assert(getPathOption(\"src\") == Some(\"/tmp/path2\"))\n+    }\n+\n+    withTable(\"src\", \"src2\") {\n+      sql(s\"CREATE TABLE src(i int) USING ${classOf[TestOptionsSource].getCanonicalName}\")\n+      sql(\"ALTER TABLE src RENAME TO src2\")",
    "line": 122
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "yea, we should create a JIRA for improving the DDL command test coverage.\n",
    "commit": "d1bcb495307b72b831e2b1aff540d6000019b973",
    "createdAt": "2016-11-02T15:13:47Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql.sources\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession, SQLContext}\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.execution.datasources.LogicalRelation\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.types.StructType\n+\n+class TestOptionsSource extends RelationProvider with CreatableRelationProvider {\n+\n+  override def createRelation(\n+      sqlContext: SQLContext,\n+      parameters: Map[String, String]): BaseRelation = {\n+    new TestOptionsRelation(parameters)(sqlContext.sparkSession)\n+  }\n+\n+  override def createRelation(\n+      sqlContext: SQLContext,\n+      mode: SaveMode,\n+      parameters: Map[String, String],\n+      data: DataFrame): BaseRelation = {\n+    new TestOptionsRelation(parameters)(sqlContext.sparkSession)\n+  }\n+}\n+\n+class TestOptionsRelation(val options: Map[String, String])(@transient val session: SparkSession)\n+  extends BaseRelation {\n+\n+  override def sqlContext: SQLContext = session.sqlContext\n+\n+  override def schema: StructType = new StructType().add(\"i\", \"int\")\n+}\n+\n+class PathOptionSuite extends DataSourceTest with SharedSQLContext {\n+\n+  test(\"path option always exist\") {\n+    withTable(\"src\") {\n+      sql(\n+        s\"\"\"\n+           |CREATE TABLE src(i int)\n+           |USING ${classOf[TestOptionsSource].getCanonicalName}\n+           |OPTIONS (PATH '/tmp/path')\"\"\".stripMargin)\n+      assert(getPathOption(\"src\") == Some(\"/tmp/path\"))\n+    }\n+\n+    // should exist even path option is not specified when creating table\n+    withTable(\"src\") {\n+      sql(s\"CREATE TABLE src(i int) USING ${classOf[TestOptionsSource].getCanonicalName}\")\n+      assert(getPathOption(\"src\") == Some(defaultTablePath(\"src\")))\n+    }\n+  }\n+\n+  test(\"path option always represent the value of table location\") {\n+    withTable(\"src\") {\n+      sql(\n+        s\"\"\"\n+           |CREATE TABLE src(i int)\n+           |USING ${classOf[TestOptionsSource].getCanonicalName}\n+           |OPTIONS (PATH '/tmp/path')\"\"\".stripMargin)\n+      sql(\"ALTER TABLE src SET LOCATION '/tmp/path2'\")\n+      assert(getPathOption(\"src\") == Some(\"/tmp/path2\"))\n+    }\n+\n+    withTable(\"src\", \"src2\") {\n+      sql(s\"CREATE TABLE src(i int) USING ${classOf[TestOptionsSource].getCanonicalName}\")\n+      sql(\"ALTER TABLE src RENAME TO src2\")",
    "line": 122
  }],
  "prId": 15024
}]