[{
  "comments": [{
    "author": {
      "login": "sarutak"
    },
    "body": "Extra new lines.\n",
    "commit": "381d5030e15da798732e1d9b12b0edaa4e62c248",
    "createdAt": "2014-10-27T08:32:04Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to Big Data Genomics (BDG) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The BDG licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{SQLContext, QueryTest}\n+import org.apache.spark.sql.test._\n+import TestSQLContext._\n+\n+case class RecordData1(start1: Long, end1: Long) extends Serializable\n+case class RecordData2(start2: Long, end2: Long) extends Serializable\n+\n+class SQLRangeJoinSuite extends QueryTest {\n+\n+\n+  val sc = TestSQLContext.sparkContext\n+  val sqlContext = new SQLContext(sc)\n+  import sqlContext._\n+\n+  test(\"joining non overlappings results into no entries\"){\n+\n+    val rdd1 = sc.parallelize(Seq((1L,5L), (2L,7L))).map(i => RecordData1(i._1, i._2))\n+    val rdd2 = sc.parallelize(Seq((11L,44L), (23L, 45L))).map(i => RecordData2(i._1, i._2))\n+\n+    rdd1.registerTempTable(\"t1\")\n+    rdd2.registerTempTable(\"t2\")\n+    checkAnswer(\n+      sql(\"select * from t1 RANGEJOIN t2 on OVERLAPS( (start1, end1), (start2, end2))\"),\n+      Nil\n+    )\n+\n+  }\n+\n+  test(\"basic range join\"){\n+    val rdd1 = sc.parallelize(Seq((100L, 199L),\n+      (200L, 299L),\n+      (400L, 600L),\n+      (10000L, 20000L)))\n+      .map(i => RecordData1(i._1, i._2))\n+\n+    val rdd2 = sc.parallelize(Seq((150L, 250L),\n+      (300L, 500L),\n+      (500L, 700L),\n+      (22000L, 22300L)))\n+      .map(i => RecordData2(i._1, i._2))\n+\n+    rdd1.registerTempTable(\"s1\")\n+    rdd2.registerTempTable(\"s2\")\n+\n+\n+    checkAnswer(\n+      sql(\"select start1, end1, start2, end2 from s1 RANGEJOIN s2 on OVERLAPS( (start1, end1), (start2, end2))\"),\n+      (100L, 199L, 150L, 250L) ::\n+        (200L, 299L, 150L, 250L) ::\n+        (400L, 600L, 300L, 500L) ::\n+        (400L, 600L, 500L, 700L) :: Nil\n+    )\n+\n+    checkAnswer(\n+      sql(\"select end1 from s1 RANGEJOIN s2 on OVERLAPS( (start1, end1), (start2, end2))\"),\n+      Seq(199L) :: Seq(299L) :: Seq(600L) :: Seq(600L) :: Nil\n+    )\n+  }\n+\n+"
  }],
  "prId": 2939
}, {
  "comments": [{
    "author": {
      "login": "sarutak"
    },
    "body": "extra new line.\n",
    "commit": "381d5030e15da798732e1d9b12b0edaa4e62c248",
    "createdAt": "2014-10-27T08:32:15Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to Big Data Genomics (BDG) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The BDG licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{SQLContext, QueryTest}\n+import org.apache.spark.sql.test._\n+import TestSQLContext._\n+\n+case class RecordData1(start1: Long, end1: Long) extends Serializable\n+case class RecordData2(start2: Long, end2: Long) extends Serializable\n+\n+class SQLRangeJoinSuite extends QueryTest {\n+\n+\n+  val sc = TestSQLContext.sparkContext\n+  val sqlContext = new SQLContext(sc)\n+  import sqlContext._\n+\n+  test(\"joining non overlappings results into no entries\"){\n+\n+    val rdd1 = sc.parallelize(Seq((1L,5L), (2L,7L))).map(i => RecordData1(i._1, i._2))\n+    val rdd2 = sc.parallelize(Seq((11L,44L), (23L, 45L))).map(i => RecordData2(i._1, i._2))\n+\n+    rdd1.registerTempTable(\"t1\")\n+    rdd2.registerTempTable(\"t2\")\n+    checkAnswer(\n+      sql(\"select * from t1 RANGEJOIN t2 on OVERLAPS( (start1, end1), (start2, end2))\"),\n+      Nil\n+    )\n+"
  }],
  "prId": 2939
}, {
  "comments": [{
    "author": {
      "login": "sarutak"
    },
    "body": " extra new line.\n",
    "commit": "381d5030e15da798732e1d9b12b0edaa4e62c248",
    "createdAt": "2014-10-27T08:32:29Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to Big Data Genomics (BDG) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The BDG licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{SQLContext, QueryTest}\n+import org.apache.spark.sql.test._\n+import TestSQLContext._\n+\n+case class RecordData1(start1: Long, end1: Long) extends Serializable\n+case class RecordData2(start2: Long, end2: Long) extends Serializable\n+\n+class SQLRangeJoinSuite extends QueryTest {\n+\n+"
  }],
  "prId": 2939
}]