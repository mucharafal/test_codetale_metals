[{
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "(we do not need to put the example class inside this object.)\n",
    "commit": "9ae648c485819cba27bde3aad920970ccdc1ab4e",
    "createdAt": "2016-08-21T00:10:04Z",
    "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.AggregateWithObjectAggregateBufferSuite.MaxWithObjectAggregateBuffer\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, Expression, GenericMutableRow, MutableRow, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{ImperativeAggregate, WithObjectAggregateBuffer}\n+import org.apache.spark.sql.execution.aggregate.{SortAggregateExec}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.types.{AbstractDataType, DataType, IntegerType, StructType}\n+\n+class AggregateWithObjectAggregateBufferSuite extends QueryTest with SharedSQLContext {\n+\n+  import testImplicits._\n+\n+  private val data = Seq((1, 0), (3, 1), (2, 0), (6, 3), (3, 1), (4, 1), (5, 0))\n+\n+\n+  test(\"aggregate with object aggregate buffer, should not use HashAggregate\") {\n+    val df = data.toDF(\"a\", \"b\")\n+    val max = new MaxWithObjectAggregateBuffer($\"a\".expr)\n+\n+    // Always use SortAggregateExec instead of HashAggregateExec for planning even if the aggregate\n+    //  buffer attributes are mutable fields (every field can be mutated inline like int, long...)\n+    val allFieldsMutable = max.aggBufferSchema.map(_.dataType).forall(UnsafeRow.isMutable)\n+    val sparkPlan = df.select(Column(max.toAggregateExpression())).queryExecution.sparkPlan\n+    assert(allFieldsMutable == true && sparkPlan.isInstanceOf[SortAggregateExec])\n+  }\n+\n+  test(\"aggregate with object aggregate buffer, no group by\") {\n+    val df = data.toDF(\"a\", \"b\").coalesce(2)\n+    checkAnswer(\n+      df.select(objectAggregateMax($\"a\"), count($\"a\"), objectAggregateMax($\"b\"), count($\"b\")),\n+      Seq(Row(6, 7, 3, 7))\n+    )\n+  }\n+\n+  test(\"aggregate with object aggregate buffer, with group by\") {\n+    val df = data.toDF(\"a\", \"b\").coalesce(2)\n+    checkAnswer(\n+      df.groupBy($\"b\").agg(objectAggregateMax($\"a\"), count($\"a\"), objectAggregateMax($\"a\")),\n+      Seq(\n+        Row(0, 5, 3, 5),\n+        Row(1, 4, 3, 4),\n+        Row(3, 6, 1, 6)\n+      )\n+    )\n+  }\n+\n+  test(\"aggregate with object aggregate buffer, empty inputs, no group by\") {\n+    val empty = Seq.empty[(Int, Int)].toDF(\"a\", \"b\")\n+    checkAnswer(\n+      empty.select(objectAggregateMax($\"a\"), count($\"a\"), objectAggregateMax($\"b\"), count($\"b\")),\n+      Seq(Row(Int.MinValue, 0, Int.MinValue, 0)))\n+  }\n+\n+  test(\"aggregate with object aggregate buffer, empty inputs, with group by\") {\n+    val empty = Seq.empty[(Int, Int)].toDF(\"a\", \"b\")\n+    checkAnswer(\n+      empty.groupBy($\"b\").agg(objectAggregateMax($\"a\"), count($\"a\"), objectAggregateMax($\"a\")),\n+      Seq.empty[Row])\n+  }\n+\n+  private def objectAggregateMax(column: Column): Column = {\n+    val max = MaxWithObjectAggregateBuffer(column.expr)\n+    Column(max.toAggregateExpression())\n+  }\n+}\n+\n+object AggregateWithObjectAggregateBufferSuite {",
    "line": 87
  }, {
    "author": {
      "login": "clockfly"
    },
    "body": "I use the companion object to define a private scope.\n",
    "commit": "9ae648c485819cba27bde3aad920970ccdc1ab4e",
    "createdAt": "2016-08-22T06:04:20Z",
    "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.AggregateWithObjectAggregateBufferSuite.MaxWithObjectAggregateBuffer\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, Expression, GenericMutableRow, MutableRow, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{ImperativeAggregate, WithObjectAggregateBuffer}\n+import org.apache.spark.sql.execution.aggregate.{SortAggregateExec}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.types.{AbstractDataType, DataType, IntegerType, StructType}\n+\n+class AggregateWithObjectAggregateBufferSuite extends QueryTest with SharedSQLContext {\n+\n+  import testImplicits._\n+\n+  private val data = Seq((1, 0), (3, 1), (2, 0), (6, 3), (3, 1), (4, 1), (5, 0))\n+\n+\n+  test(\"aggregate with object aggregate buffer, should not use HashAggregate\") {\n+    val df = data.toDF(\"a\", \"b\")\n+    val max = new MaxWithObjectAggregateBuffer($\"a\".expr)\n+\n+    // Always use SortAggregateExec instead of HashAggregateExec for planning even if the aggregate\n+    //  buffer attributes are mutable fields (every field can be mutated inline like int, long...)\n+    val allFieldsMutable = max.aggBufferSchema.map(_.dataType).forall(UnsafeRow.isMutable)\n+    val sparkPlan = df.select(Column(max.toAggregateExpression())).queryExecution.sparkPlan\n+    assert(allFieldsMutable == true && sparkPlan.isInstanceOf[SortAggregateExec])\n+  }\n+\n+  test(\"aggregate with object aggregate buffer, no group by\") {\n+    val df = data.toDF(\"a\", \"b\").coalesce(2)\n+    checkAnswer(\n+      df.select(objectAggregateMax($\"a\"), count($\"a\"), objectAggregateMax($\"b\"), count($\"b\")),\n+      Seq(Row(6, 7, 3, 7))\n+    )\n+  }\n+\n+  test(\"aggregate with object aggregate buffer, with group by\") {\n+    val df = data.toDF(\"a\", \"b\").coalesce(2)\n+    checkAnswer(\n+      df.groupBy($\"b\").agg(objectAggregateMax($\"a\"), count($\"a\"), objectAggregateMax($\"a\")),\n+      Seq(\n+        Row(0, 5, 3, 5),\n+        Row(1, 4, 3, 4),\n+        Row(3, 6, 1, 6)\n+      )\n+    )\n+  }\n+\n+  test(\"aggregate with object aggregate buffer, empty inputs, no group by\") {\n+    val empty = Seq.empty[(Int, Int)].toDF(\"a\", \"b\")\n+    checkAnswer(\n+      empty.select(objectAggregateMax($\"a\"), count($\"a\"), objectAggregateMax($\"b\"), count($\"b\")),\n+      Seq(Row(Int.MinValue, 0, Int.MinValue, 0)))\n+  }\n+\n+  test(\"aggregate with object aggregate buffer, empty inputs, with group by\") {\n+    val empty = Seq.empty[(Int, Int)].toDF(\"a\", \"b\")\n+    checkAnswer(\n+      empty.groupBy($\"b\").agg(objectAggregateMax($\"a\"), count($\"a\"), objectAggregateMax($\"a\")),\n+      Seq.empty[Row])\n+  }\n+\n+  private def objectAggregateMax(column: Column): Column = {\n+    val max = MaxWithObjectAggregateBuffer(column.expr)\n+    Column(max.toAggregateExpression())\n+  }\n+}\n+\n+object AggregateWithObjectAggregateBufferSuite {",
    "line": 87
  }],
  "prId": 14723
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "We should also put a basic test in `HashAggregationQueryWithControlledFallbackSuite`, to test the fallback.\n",
    "commit": "9ae648c485819cba27bde3aad920970ccdc1ab4e",
    "createdAt": "2016-08-22T03:21:06Z",
    "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.AggregateWithObjectAggregateBufferSuite.MaxWithObjectAggregateBuffer\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, Expression, GenericMutableRow, MutableRow, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{ImperativeAggregate, WithObjectAggregateBuffer}\n+import org.apache.spark.sql.execution.aggregate.{SortAggregateExec}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.types.{AbstractDataType, DataType, IntegerType, StructType}\n+\n+class AggregateWithObjectAggregateBufferSuite extends QueryTest with SharedSQLContext {",
    "line": 29
  }, {
    "author": {
      "login": "clockfly"
    },
    "body": "We will not use HashAggregationExec, so there is no point to fallback from HashAggregationExec?\n",
    "commit": "9ae648c485819cba27bde3aad920970ccdc1ab4e",
    "createdAt": "2016-08-22T14:32:54Z",
    "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.AggregateWithObjectAggregateBufferSuite.MaxWithObjectAggregateBuffer\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, Expression, GenericMutableRow, MutableRow, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{ImperativeAggregate, WithObjectAggregateBuffer}\n+import org.apache.spark.sql.execution.aggregate.{SortAggregateExec}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.types.{AbstractDataType, DataType, IntegerType, StructType}\n+\n+class AggregateWithObjectAggregateBufferSuite extends QueryTest with SharedSQLContext {",
    "line": 29
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "oh right, I misread the code.\n",
    "commit": "9ae648c485819cba27bde3aad920970ccdc1ab4e",
    "createdAt": "2016-08-22T15:34:16Z",
    "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.AggregateWithObjectAggregateBufferSuite.MaxWithObjectAggregateBuffer\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{AttributeReference, Expression, GenericMutableRow, MutableRow, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{ImperativeAggregate, WithObjectAggregateBuffer}\n+import org.apache.spark.sql.execution.aggregate.{SortAggregateExec}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.types.{AbstractDataType, DataType, IntegerType, StructType}\n+\n+class AggregateWithObjectAggregateBufferSuite extends QueryTest with SharedSQLContext {",
    "line": 29
  }],
  "prId": 14723
}]