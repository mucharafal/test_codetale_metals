[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "The session is shared among all test suites, so we should drop the table after all tests here, or we may pollute other test suites.\n",
    "commit": "030776ae49484c4e5db7f775344e5e40dff27e9a",
    "createdAt": "2016-07-03T17:40:08Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.sql._\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class MetadataOnlyOptimizerSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    val data = (1 to 10).map(i => (i, s\"data-$i\", i % 2, if ((i % 2) == 0) \"even\" else \"odd\"))\n+      .toDF(\"id\", \"data\", \"partId\", \"part\")\n+    data.write.partitionBy(\"partId\", \"part\").mode(\"append\").saveAsTable(\"srcpart_15752\")"
  }],
  "prId": 13494
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "the last 2 cases can be added in follow-up PRs :)\n",
    "commit": "030776ae49484c4e5db7f775344e5e40dff27e9a",
    "createdAt": "2016-07-03T17:44:17Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.sql._\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class MetadataOnlyOptimizerSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    val data = (1 to 10).map(i => (i, s\"data-$i\", i % 2, if ((i % 2) == 0) \"even\" else \"odd\"))\n+      .toDF(\"id\", \"data\", \"partId\", \"part\")\n+    data.write.partitionBy(\"partId\", \"part\").mode(\"append\").saveAsTable(\"srcpart_15752\")\n+  }\n+\n+  private def checkWithMetadataOnly(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 1)\n+  }\n+\n+  private def checkWithoutMetadataOnly(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect{\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 0)\n+  }\n+\n+  test(\"spark-15752 metadata only optimizer for partition table\") {\n+    withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"true\") {\n+      checkWithMetadataOnly(sql(\"select part from srcpart_15752 where part = 0 group by part\"))\n+      checkWithMetadataOnly(sql(\"select max(part) from srcpart_15752\"))\n+      checkWithMetadataOnly(sql(\"select max(part) from srcpart_15752 where part = 0\"))\n+      checkWithMetadataOnly(\n+        sql(\"select part, min(partId) from srcpart_15752 where part = 0 group by part\"))\n+      checkWithMetadataOnly(\n+        sql(\"select max(x) from (select part + 1 as x from srcpart_15752 where part = 1) t\"))\n+      checkWithMetadataOnly(sql(\"select distinct part from srcpart_15752\"))\n+      checkWithMetadataOnly(sql(\"select distinct part, partId from srcpart_15752\"))\n+      checkWithMetadataOnly(\n+        sql(\"select distinct x from (select part + 1 as x from srcpart_15752 where part = 0) t\"))\n+\n+      // Now donot support metadata only optimizer\n+      checkWithoutMetadataOnly(sql(\"select part, max(id) from srcpart_15752 group by part\"))\n+      checkWithoutMetadataOnly(sql(\"select distinct part, id from srcpart_15752\"))\n+      checkWithoutMetadataOnly(sql(\"select part, sum(partId) from srcpart_15752 group by part\"))\n+      checkWithoutMetadataOnly(\n+        sql(\"select part from srcpart_15752 where part = 1 group by rollup(part)\"))\n+      checkWithoutMetadataOnly(\n+        sql(\"select part from (select part from srcpart_15752 where part = 0 union all \" +"
  }, {
    "author": {
      "login": "lianhuiwang"
    },
    "body": "Yes, I think it is not difficult.\n",
    "commit": "030776ae49484c4e5db7f775344e5e40dff27e9a",
    "createdAt": "2016-07-04T10:46:34Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.sql._\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class MetadataOnlyOptimizerSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    val data = (1 to 10).map(i => (i, s\"data-$i\", i % 2, if ((i % 2) == 0) \"even\" else \"odd\"))\n+      .toDF(\"id\", \"data\", \"partId\", \"part\")\n+    data.write.partitionBy(\"partId\", \"part\").mode(\"append\").saveAsTable(\"srcpart_15752\")\n+  }\n+\n+  private def checkWithMetadataOnly(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 1)\n+  }\n+\n+  private def checkWithoutMetadataOnly(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect{\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 0)\n+  }\n+\n+  test(\"spark-15752 metadata only optimizer for partition table\") {\n+    withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"true\") {\n+      checkWithMetadataOnly(sql(\"select part from srcpart_15752 where part = 0 group by part\"))\n+      checkWithMetadataOnly(sql(\"select max(part) from srcpart_15752\"))\n+      checkWithMetadataOnly(sql(\"select max(part) from srcpart_15752 where part = 0\"))\n+      checkWithMetadataOnly(\n+        sql(\"select part, min(partId) from srcpart_15752 where part = 0 group by part\"))\n+      checkWithMetadataOnly(\n+        sql(\"select max(x) from (select part + 1 as x from srcpart_15752 where part = 1) t\"))\n+      checkWithMetadataOnly(sql(\"select distinct part from srcpart_15752\"))\n+      checkWithMetadataOnly(sql(\"select distinct part, partId from srcpart_15752\"))\n+      checkWithMetadataOnly(\n+        sql(\"select distinct x from (select part + 1 as x from srcpart_15752 where part = 0) t\"))\n+\n+      // Now donot support metadata only optimizer\n+      checkWithoutMetadataOnly(sql(\"select part, max(id) from srcpart_15752 group by part\"))\n+      checkWithoutMetadataOnly(sql(\"select distinct part, id from srcpart_15752\"))\n+      checkWithoutMetadataOnly(sql(\"select part, sum(partId) from srcpart_15752 group by part\"))\n+      checkWithoutMetadataOnly(\n+        sql(\"select part from srcpart_15752 where part = 1 group by rollup(part)\"))\n+      checkWithoutMetadataOnly(\n+        sql(\"select part from (select part from srcpart_15752 where part = 0 union all \" +"
  }],
  "prId": 13494
}]