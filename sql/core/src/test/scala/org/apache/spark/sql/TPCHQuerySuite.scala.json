[{
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "How about making a base trait to remove duplicate code between this and `TPCDSQuerySuite`?",
    "commit": "2671416688ca6275556602b2f1990cd4361b95e6",
    "createdAt": "2017-12-14T23:39:55Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.scalatest.BeforeAndAfterAll\n+\n+import org.apache.spark.sql.catalyst.expressions.codegen.{CodeFormatter, CodeGenerator}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.catalyst.util.resourceToString\n+import org.apache.spark.sql.execution.{SparkPlan, WholeStageCodegenExec}\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This test suite ensures all the TPC-H queries can be successfully analyzed, optimized\n+ * and compiled without hitting the max iteration threshold.\n+ */\n+class TPCHQuerySuite extends QueryTest with SharedSQLContext with BeforeAndAfterAll {\n+\n+  // When Utils.isTesting is true, the RuleExecutor will issue an exception when hitting\n+  // the max iteration of analyzer/optimizer batches.\n+  assert(Utils.isTesting, \"spark.testing is not set to true\")\n+\n+  /**\n+   * Drop all the tables\n+   */\n+  protected override def afterAll(): Unit = {\n+    try {\n+      // For debugging dump some statistics about how much time was spent in various optimizer rules\n+      logWarning(RuleExecutor.dumpTimeSpent())\n+      spark.sessionState.catalog.reset()\n+    } finally {\n+      super.afterAll()\n+    }\n+  }\n+\n+  override def beforeAll() {\n+    super.beforeAll()\n+    RuleExecutor.resetTime()\n+\n+    sql(\n+      \"\"\"\n+        |CREATE TABLE `orders` (\n+        |`o_orderkey` BIGINT, `o_custkey` BIGINT, `o_orderstatus` STRING,\n+        |`o_totalprice` DECIMAL(10,0), `o_orderdate` DATE, `o_orderpriority` STRING,\n+        |`o_clerk` STRING, `o_shippriority` INT, `o_comment` STRING)\n+        |USING parquet\n+      \"\"\".stripMargin)\n+\n+    sql(\n+      \"\"\"\n+        |CREATE TABLE `nation` (\n+        |`n_nationkey` BIGINT, `n_name` STRING, `n_regionkey` BIGINT, `n_comment` STRING)\n+        |USING parquet\n+      \"\"\".stripMargin)\n+\n+    sql(\n+      \"\"\"\n+        |CREATE TABLE `region` (\n+        |`r_regionkey` BIGINT, `r_name` STRING, `r_comment` STRING)\n+        |USING parquet\n+      \"\"\".stripMargin)\n+\n+    sql(\n+      \"\"\"\n+        |CREATE TABLE `part` (`p_partkey` BIGINT, `p_name` STRING, `p_mfgr` STRING,\n+        |`p_brand` STRING, `p_type` STRING, `p_size` INT, `p_container` STRING,\n+        |`p_retailprice` DECIMAL(10,0), `p_comment` STRING)\n+        |USING parquet\n+      \"\"\".stripMargin)\n+\n+    sql(\n+      \"\"\"\n+        |CREATE TABLE `partsupp` (`ps_partkey` BIGINT, `ps_suppkey` BIGINT,\n+        |`ps_availqty` INT, `ps_supplycost` DECIMAL(10,0), `ps_comment` STRING)\n+        |USING parquet\n+      \"\"\".stripMargin)\n+\n+    sql(\n+      \"\"\"\n+        |CREATE TABLE `customer` (`c_custkey` BIGINT, `c_name` STRING, `c_address` STRING,\n+        |`c_nationkey` STRING, `c_phone` STRING, `c_acctbal` DECIMAL(10,0),\n+        |`c_mktsegment` STRING, `c_comment` STRING)\n+        |USING parquet\n+      \"\"\".stripMargin)\n+\n+    sql(\n+      \"\"\"\n+        |CREATE TABLE `supplier` (`s_suppkey` BIGINT, `s_name` STRING, `s_address` STRING,\n+        |`s_nationkey` BIGINT, `s_phone` STRING, `s_acctbal` DECIMAL(10,0), `s_comment` STRING)\n+        |USING parquet\n+      \"\"\".stripMargin)\n+\n+    sql(\n+      \"\"\"\n+        |CREATE TABLE `lineitem` (`l_orderkey` BIGINT, `l_partkey` BIGINT, `l_suppkey` BIGINT,\n+        |`l_linenumber` INT, `l_quantity` DECIMAL(10,0), `l_extendedprice` DECIMAL(10,0),\n+        |`l_discount` DECIMAL(10,0), `l_tax` DECIMAL(10,0), `l_returnflag` STRING,\n+        |`l_linestatus` STRING, `l_shipdate` DATE, `l_commitdate` DATE, `l_receiptdate` DATE,\n+        |`l_shipinstruct` STRING, `l_shipmode` STRING, `l_comment` STRING)\n+        |USING parquet\n+      \"\"\".stripMargin)\n+  }\n+\n+  val tpchQueries = Seq(\n+    \"q1\", \"q2\", \"q3\", \"q4\", \"q5\", \"q6\", \"q7\", \"q8\", \"q9\", \"q10\", \"q11\",\n+    \"q12\", \"q13\", \"q14\", \"q15\", \"q16\", \"q17\", \"q18\", \"q19\", \"q20\", \"q21\", \"q22\")\n+\n+  private def checkGeneratedCode(plan: SparkPlan): Unit = {"
  }],
  "prId": 19982
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "As same as `TPCDSQuerySuite`, we can use `BenchmarkQueryTest.afterAll`.",
    "commit": "2671416688ca6275556602b2f1990cd4361b95e6",
    "createdAt": "2017-12-15T01:25:48Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.catalyst.util.resourceToString\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This test suite ensures all the TPC-H queries can be successfully analyzed, optimized\n+ * and compiled without hitting the max iteration threshold.\n+ */\n+class TPCHQuerySuite extends BenchmarkQueryTest {\n+\n+  /**\n+   * Drop all the tables\n+   */\n+  protected override def afterAll(): Unit = {"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "yea we don't need to overwrite it here.",
    "commit": "2671416688ca6275556602b2f1990cd4361b95e6",
    "createdAt": "2017-12-15T02:36:26Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.catalyst.util.resourceToString\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This test suite ensures all the TPC-H queries can be successfully analyzed, optimized\n+ * and compiled without hitting the max iteration threshold.\n+ */\n+class TPCHQuerySuite extends BenchmarkQueryTest {\n+\n+  /**\n+   * Drop all the tables\n+   */\n+  protected override def afterAll(): Unit = {"
  }],
  "prId": 19982
}]