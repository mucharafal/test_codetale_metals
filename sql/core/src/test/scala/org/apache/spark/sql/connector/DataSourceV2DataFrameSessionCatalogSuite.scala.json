[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This seems to be last remaining instance.\r\n```scala\r\n-    catalog(\"session\").asInstanceOf[Catalog].clearTables()\r\n+    catalog(SESSION_CATALOG_NAME).asInstanceOf[Catalog].clearTables()\r\n```",
    "commit": "e973e419c1ab04b75a0a5dddbb538c9355a3336c",
    "createdAt": "2019-10-12T23:13:43Z",
    "diffHunk": "@@ -144,13 +144,13 @@ private [connector] trait SessionCatalogTest[T <: Table, Catalog <: TestV2Sessio\n   protected val catalogClassName: String = classOf[InMemoryTableSessionCatalog].getName\n \n   before {\n-    spark.conf.set(V2_SESSION_CATALOG.key, catalogClassName)\n+    spark.conf.set(V2_SESSION_CATALOG_IMPLEMENTATION.key, catalogClassName)\n   }\n \n   override def afterEach(): Unit = {\n     super.afterEach()\n     catalog(\"session\").asInstanceOf[Catalog].clearTables()"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This test suite fails without this.",
    "commit": "e973e419c1ab04b75a0a5dddbb538c9355a3336c",
    "createdAt": "2019-10-12T23:20:37Z",
    "diffHunk": "@@ -144,13 +144,13 @@ private [connector] trait SessionCatalogTest[T <: Table, Catalog <: TestV2Sessio\n   protected val catalogClassName: String = classOf[InMemoryTableSessionCatalog].getName\n \n   before {\n-    spark.conf.set(V2_SESSION_CATALOG.key, catalogClassName)\n+    spark.conf.set(V2_SESSION_CATALOG_IMPLEMENTATION.key, catalogClassName)\n   }\n \n   override def afterEach(): Unit = {\n     super.afterEach()\n     catalog(\"session\").asInstanceOf[Catalog].clearTables()"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "Good catch!",
    "commit": "e973e419c1ab04b75a0a5dddbb538c9355a3336c",
    "createdAt": "2019-10-13T17:56:48Z",
    "diffHunk": "@@ -144,13 +144,13 @@ private [connector] trait SessionCatalogTest[T <: Table, Catalog <: TestV2Sessio\n   protected val catalogClassName: String = classOf[InMemoryTableSessionCatalog].getName\n \n   before {\n-    spark.conf.set(V2_SESSION_CATALOG.key, catalogClassName)\n+    spark.conf.set(V2_SESSION_CATALOG_IMPLEMENTATION.key, catalogClassName)\n   }\n \n   override def afterEach(): Unit = {\n     super.afterEach()\n     catalog(\"session\").asInstanceOf[Catalog].clearTables()"
  }],
  "prId": 26071
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "```scala\r\n+  import org.apache.spark.sql.connector.catalog.CatalogManager.SESSION_CATALOG_NAME\r\n```",
    "commit": "e973e419c1ab04b75a0a5dddbb538c9355a3336c",
    "createdAt": "2019-10-12T23:18:40Z",
    "diffHunk": "@@ -26,7 +26,7 @@ import org.apache.spark.sql.catalyst.TableIdentifier\n import org.apache.spark.sql.catalyst.analysis.{NoSuchTableException, TableAlreadyExistsException}\n import org.apache.spark.sql.connector.catalog._",
    "line": 3
  }],
  "prId": 26071
}]