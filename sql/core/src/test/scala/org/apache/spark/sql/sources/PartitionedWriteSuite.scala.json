[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "`append data to an existing partitioned table without custom partition path`",
    "commit": "c200b986fed37015a30f99ba2f870dda84cc2ef6",
    "createdAt": "2017-01-22T13:35:22Z",
    "diffHunk": "@@ -92,6 +96,47 @@ class PartitionedWriteSuite extends QueryTest with SharedSQLContext {\n     }\n   }\n \n+  test(\"append data an existed partition in a datasource table,\" +"
  }, {
    "author": {
      "login": "windpiger"
    },
    "body": "thanks~",
    "commit": "c200b986fed37015a30f99ba2f870dda84cc2ef6",
    "createdAt": "2017-01-23T07:12:42Z",
    "diffHunk": "@@ -92,6 +96,47 @@ class PartitionedWriteSuite extends QueryTest with SharedSQLContext {\n     }\n   }\n \n+  test(\"append data an existed partition in a datasource table,\" +"
  }],
  "prId": 16642
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "how about we make a custom `FileCommitProtocol` to test this behavior?",
    "commit": "c200b986fed37015a30f99ba2f870dda84cc2ef6",
    "createdAt": "2017-01-22T13:44:48Z",
    "diffHunk": "@@ -92,6 +96,47 @@ class PartitionedWriteSuite extends QueryTest with SharedSQLContext {\n     }\n   }\n \n+  test(\"append data an existed partition in a datasource table,\" +\n+    \"custom location sent to Task should be None \") {\n+    withTable(\"t\") {\n+      Seq((1, 2)).toDF(\"a\", \"b\").write.partitionBy(\"b\").saveAsTable(\"t\")\n+      val writer = Seq((3, 2)).toDF(\"a\", \"b\").write.mode(\"append\").partitionBy(\"b\")\n+\n+      spark.sessionState.executePlan(writer.createTableCommand(TableIdentifier(\"t\")))"
  }, {
    "author": {
      "login": "windpiger"
    },
    "body": "good idea, thanks!",
    "commit": "c200b986fed37015a30f99ba2f870dda84cc2ef6",
    "createdAt": "2017-01-23T07:13:03Z",
    "diffHunk": "@@ -92,6 +96,47 @@ class PartitionedWriteSuite extends QueryTest with SharedSQLContext {\n     }\n   }\n \n+  test(\"append data an existed partition in a datasource table,\" +\n+    \"custom location sent to Task should be None \") {\n+    withTable(\"t\") {\n+      Seq((1, 2)).toDF(\"a\", \"b\").write.partitionBy(\"b\").saveAsTable(\"t\")\n+      val writer = Seq((3, 2)).toDF(\"a\", \"b\").write.mode(\"append\").partitionBy(\"b\")\n+\n+      spark.sessionState.executePlan(writer.createTableCommand(TableIdentifier(\"t\")))"
  }],
  "prId": 16642
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit: SQLConf.FILE_COMMIT_PROTOCOL_CLASS.key -> classOf[OnlyDetectCustomPathFileCommitProtocol].getName",
    "commit": "c200b986fed37015a30f99ba2f870dda84cc2ef6",
    "createdAt": "2017-01-23T07:21:37Z",
    "diffHunk": "@@ -92,6 +111,16 @@ class PartitionedWriteSuite extends QueryTest with SharedSQLContext {\n     }\n   }\n \n+  test(\"append data to an existed partitioned table without custom partition path\") {\n+    withTable(\"t\") {\n+      withSQLConf(\"spark.sql.sources.commitProtocolClass\" ->"
  }],
  "prId": 16642
}]