[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "lower case all\n",
    "commit": "6c8f92e4394022017894425feb36769f3b0bd448",
    "createdAt": "2015-02-12T02:08:31Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql\n+\n+import org.scalatest.BeforeAndAfterAll\n+\n+import org.apache.spark.sql.test.TestSQLContext\n+import org.apache.spark.sql.test.TestSQLContext._\n+import org.apache.spark.sql.types.{BooleanType, StringType, StructField, StructType}\n+\n+class ListTablesSuite extends QueryTest with BeforeAndAfterAll {\n+\n+  import org.apache.spark.sql.test.TestSQLContext.implicits._\n+\n+  val df =\n+    sparkContext.parallelize((1 to 10).map(i => (i,s\"str$i\"))).toDataFrame(\"key\", \"value\")\n+\n+  override def beforeAll(): Unit = {\n+    (1 to 10).foreach(i => df.registerTempTable(s\"table$i\"))\n+  }\n+\n+  override def afterAll(): Unit = {\n+    catalog.unregisterAllTables()\n+  }\n+\n+  test(\"get All Tables\") {"
  }],
  "prId": 4547
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "lower case all\n",
    "commit": "6c8f92e4394022017894425feb36769f3b0bd448",
    "createdAt": "2015-02-12T02:08:36Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+\n+package org.apache.spark.sql\n+\n+import org.scalatest.BeforeAndAfterAll\n+\n+import org.apache.spark.sql.test.TestSQLContext\n+import org.apache.spark.sql.test.TestSQLContext._\n+import org.apache.spark.sql.types.{BooleanType, StringType, StructField, StructType}\n+\n+class ListTablesSuite extends QueryTest with BeforeAndAfterAll {\n+\n+  import org.apache.spark.sql.test.TestSQLContext.implicits._\n+\n+  val df =\n+    sparkContext.parallelize((1 to 10).map(i => (i,s\"str$i\"))).toDataFrame(\"key\", \"value\")\n+\n+  override def beforeAll(): Unit = {\n+    (1 to 10).foreach(i => df.registerTempTable(s\"table$i\"))\n+  }\n+\n+  override def afterAll(): Unit = {\n+    catalog.unregisterAllTables()\n+  }\n+\n+  test(\"get All Tables\") {\n+    checkAnswer(tables(), (1 to 10).map(i => Row(s\"table$i\", true)))\n+  }\n+\n+  test(\"getting All Tables with a database name has not impact on returned table names\") {"
  }],
  "prId": 4547
}]