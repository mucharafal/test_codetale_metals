[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "can we create a test case for each of these checks? We can move the `scalaTestUDF`, `pythonTestUDF` and `base` to the class body.",
    "commit": "24c674408708cfa961055102f5483af0c78e0e43",
    "createdAt": "2019-07-30T12:32:20Z",
    "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.python\n+\n+import org.apache.spark.sql.{IntegratedUDFTestUtils, QueryTest}\n+import org.apache.spark.sql.functions.count\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class PythonUDFSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  test(\"SPARK-28445: PythonUDF in grouping key and aggregate expressions\") {\n+    import IntegratedUDFTestUtils._\n+\n+    val scalaTestUDF = TestScalaUDF(name = \"scalaUDF\")\n+    val pythonTestUDF = TestPythonUDF(name = \"pyUDF\")\n+    assume(shouldTestPythonUDFs)\n+\n+    val base = Seq(\n+      (Some(1), Some(1)), (Some(1), Some(2)), (Some(2), Some(1)),\n+      (Some(2), Some(2)), (Some(3), Some(1)), (Some(3), Some(2)),\n+      (None, Some(1)), (Some(3), None), (None, None)).toDF(\"a\", \"b\")\n+\n+    val df = base.groupBy(scalaTestUDF(base(\"a\") + 1))\n+      .agg(scalaTestUDF(base(\"a\") + 1), scalaTestUDF(count(base(\"b\"))))\n+    val df2 = base.groupBy(pythonTestUDF(base(\"a\") + 1))\n+      .agg(pythonTestUDF(base(\"a\") + 1), pythonTestUDF(count(base(\"b\"))))\n+    checkAnswer(df, df2)"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Ok.",
    "commit": "24c674408708cfa961055102f5483af0c78e0e43",
    "createdAt": "2019-08-02T05:52:53Z",
    "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.python\n+\n+import org.apache.spark.sql.{IntegratedUDFTestUtils, QueryTest}\n+import org.apache.spark.sql.functions.count\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class PythonUDFSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  test(\"SPARK-28445: PythonUDF in grouping key and aggregate expressions\") {\n+    import IntegratedUDFTestUtils._\n+\n+    val scalaTestUDF = TestScalaUDF(name = \"scalaUDF\")\n+    val pythonTestUDF = TestPythonUDF(name = \"pyUDF\")\n+    assume(shouldTestPythonUDFs)\n+\n+    val base = Seq(\n+      (Some(1), Some(1)), (Some(1), Some(2)), (Some(2), Some(1)),\n+      (Some(2), Some(2)), (Some(3), Some(1)), (Some(3), Some(2)),\n+      (None, Some(1)), (Some(3), None), (None, None)).toDF(\"a\", \"b\")\n+\n+    val df = base.groupBy(scalaTestUDF(base(\"a\") + 1))\n+      .agg(scalaTestUDF(base(\"a\") + 1), scalaTestUDF(count(base(\"b\"))))\n+    val df2 = base.groupBy(pythonTestUDF(base(\"a\") + 1))\n+      .agg(pythonTestUDF(base(\"a\") + 1), pythonTestUDF(count(base(\"b\"))))\n+    checkAnswer(df, df2)"
  }],
  "prId": 25215
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "BTW, thanks for changing this into DSL. It was rather a nit that needs some efforts.",
    "commit": "24c674408708cfa961055102f5483af0c78e0e43",
    "createdAt": "2019-08-02T09:29:35Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.python\n+\n+import org.apache.spark.sql.{IntegratedUDFTestUtils, QueryTest}\n+import org.apache.spark.sql.functions.count\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class PythonUDFSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  import IntegratedUDFTestUtils._\n+\n+  val scalaTestUDF = TestScalaUDF(name = \"scalaUDF\")\n+  val pythonTestUDF = TestPythonUDF(name = \"pyUDF\")\n+  assume(shouldTestPythonUDFs)\n+\n+  lazy val base = Seq(\n+    (Some(1), Some(1)), (Some(1), Some(2)), (Some(2), Some(1)),\n+    (Some(2), Some(2)), (Some(3), Some(1)), (Some(3), Some(2)),\n+    (None, Some(1)), (Some(3), None), (None, None)).toDF(\"a\", \"b\")\n+\n+  test(\"SPARK-28445: PythonUDF as grouping key and aggregate expressions\") {\n+    val df1 = base.groupBy(scalaTestUDF(base(\"a\") + 1))",
    "line": 39
  }],
  "prId": 25215
}]