[{
  "comments": [{
    "author": {
      "login": "xuanwang14"
    },
    "body": "This test may be flaky. It depends on the ratio of `n/RANGE_EXCHANGE_SAMPLE_SIZE_PER_PARTITION`. What is the default value of `RANGE_EXCHANGE_SAMPLE_SIZE_PER_PARTITION` ?",
    "commit": "99c5bc6226b395aeee79167180bfd92a349e45d3",
    "createdAt": "2017-09-28T23:51:34Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.commons.math3.stat.inference.ChiSquareTest\n+\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+\n+class ConfigBehaviorSuite extends QueryTest with SharedSQLContext {\n+\n+  import testImplicits._\n+\n+  test(\"SPARK-22160 spark.sql.execution.rangeExchange.sampleSizePerPartition\") {\n+    // In this test, we run a sort and compute the histogram for partition size post shuffle.\n+    // With a high sample count, the partition size should be more evenly distributed, and has a\n+    // low chi-sq test value.\n+\n+    val numPartitions = 4\n+\n+    def computeChiSquareTest(): Double = {\n+      val n = 10000\n+      // Trigger a sort\n+      val data = spark.range(0, n, 1, 1).sort('id)\n+        .selectExpr(\"SPARK_PARTITION_ID() pid\", \"id\").as[(Int, Long)].collect()\n+\n+      // Compute histogram for the number of records per partition post sort\n+      val dist = data.groupBy(_._1).map(_._2.length.toLong).toArray\n+      assert(dist.length == 4)\n+\n+      new ChiSquareTest().chiSquare(\n+        Array.fill(numPartitions) { n.toDouble / numPartitions },\n+        dist)\n+    }\n+\n+    withSQLConf(SQLConf.SHUFFLE_PARTITIONS.key -> numPartitions.toString) {\n+      // The default chi-sq value should be low\n+      assert(computeChiSquareTest() < 100)",
    "line": 56
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "100 - which is pretty high\r\n\r\nthe actual value computed on my laptop is around 10, so 1000 is already three orders of magnitude larger",
    "commit": "99c5bc6226b395aeee79167180bfd92a349e45d3",
    "createdAt": "2017-09-29T00:04:46Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.commons.math3.stat.inference.ChiSquareTest\n+\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+\n+class ConfigBehaviorSuite extends QueryTest with SharedSQLContext {\n+\n+  import testImplicits._\n+\n+  test(\"SPARK-22160 spark.sql.execution.rangeExchange.sampleSizePerPartition\") {\n+    // In this test, we run a sort and compute the histogram for partition size post shuffle.\n+    // With a high sample count, the partition size should be more evenly distributed, and has a\n+    // low chi-sq test value.\n+\n+    val numPartitions = 4\n+\n+    def computeChiSquareTest(): Double = {\n+      val n = 10000\n+      // Trigger a sort\n+      val data = spark.range(0, n, 1, 1).sort('id)\n+        .selectExpr(\"SPARK_PARTITION_ID() pid\", \"id\").as[(Int, Long)].collect()\n+\n+      // Compute histogram for the number of records per partition post sort\n+      val dist = data.groupBy(_._1).map(_._2.length.toLong).toArray\n+      assert(dist.length == 4)\n+\n+      new ChiSquareTest().chiSquare(\n+        Array.fill(numPartitions) { n.toDouble / numPartitions },\n+        dist)\n+    }\n+\n+    withSQLConf(SQLConf.SHUFFLE_PARTITIONS.key -> numPartitions.toString) {\n+      // The default chi-sq value should be low\n+      assert(computeChiSquareTest() < 100)",
    "line": 56
  }],
  "prId": 19387
}, {
  "comments": [{
    "author": {
      "login": "xuanwang14"
    },
    "body": "This test may be flaky as well. ",
    "commit": "99c5bc6226b395aeee79167180bfd92a349e45d3",
    "createdAt": "2017-09-28T23:52:38Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.commons.math3.stat.inference.ChiSquareTest\n+\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+\n+class ConfigBehaviorSuite extends QueryTest with SharedSQLContext {\n+\n+  import testImplicits._\n+\n+  test(\"SPARK-22160 spark.sql.execution.rangeExchange.sampleSizePerPartition\") {\n+    // In this test, we run a sort and compute the histogram for partition size post shuffle.\n+    // With a high sample count, the partition size should be more evenly distributed, and has a\n+    // low chi-sq test value.\n+\n+    val numPartitions = 4\n+\n+    def computeChiSquareTest(): Double = {\n+      val n = 10000\n+      // Trigger a sort\n+      val data = spark.range(0, n, 1, 1).sort('id)\n+        .selectExpr(\"SPARK_PARTITION_ID() pid\", \"id\").as[(Int, Long)].collect()\n+\n+      // Compute histogram for the number of records per partition post sort\n+      val dist = data.groupBy(_._1).map(_._2.length.toLong).toArray\n+      assert(dist.length == 4)\n+\n+      new ChiSquareTest().chiSquare(\n+        Array.fill(numPartitions) { n.toDouble / numPartitions },\n+        dist)\n+    }\n+\n+    withSQLConf(SQLConf.SHUFFLE_PARTITIONS.key -> numPartitions.toString) {\n+      // The default chi-sq value should be low\n+      assert(computeChiSquareTest() < 100)\n+\n+      withSQLConf(SQLConf.RANGE_EXCHANGE_SAMPLE_SIZE_PER_PARTITION.key -> \"1\") {\n+        // If we only sample one point, the range boundaries will be pretty bad and the\n+        // chi-sq value would be very high.\n+        assert(computeChiSquareTest() > 1000)",
    "line": 61
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "the value i got from my laptop was 1800",
    "commit": "99c5bc6226b395aeee79167180bfd92a349e45d3",
    "createdAt": "2017-09-29T00:04:55Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.commons.math3.stat.inference.ChiSquareTest\n+\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+\n+class ConfigBehaviorSuite extends QueryTest with SharedSQLContext {\n+\n+  import testImplicits._\n+\n+  test(\"SPARK-22160 spark.sql.execution.rangeExchange.sampleSizePerPartition\") {\n+    // In this test, we run a sort and compute the histogram for partition size post shuffle.\n+    // With a high sample count, the partition size should be more evenly distributed, and has a\n+    // low chi-sq test value.\n+\n+    val numPartitions = 4\n+\n+    def computeChiSquareTest(): Double = {\n+      val n = 10000\n+      // Trigger a sort\n+      val data = spark.range(0, n, 1, 1).sort('id)\n+        .selectExpr(\"SPARK_PARTITION_ID() pid\", \"id\").as[(Int, Long)].collect()\n+\n+      // Compute histogram for the number of records per partition post sort\n+      val dist = data.groupBy(_._1).map(_._2.length.toLong).toArray\n+      assert(dist.length == 4)\n+\n+      new ChiSquareTest().chiSquare(\n+        Array.fill(numPartitions) { n.toDouble / numPartitions },\n+        dist)\n+    }\n+\n+    withSQLConf(SQLConf.SHUFFLE_PARTITIONS.key -> numPartitions.toString) {\n+      // The default chi-sq value should be low\n+      assert(computeChiSquareTest() < 100)\n+\n+      withSQLConf(SQLConf.RANGE_EXCHANGE_SAMPLE_SIZE_PER_PARTITION.key -> \"1\") {\n+        // If we only sample one point, the range boundaries will be pretty bad and the\n+        // chi-sq value would be very high.\n+        assert(computeChiSquareTest() > 1000)",
    "line": 61
  }],
  "prId": 19387
}]