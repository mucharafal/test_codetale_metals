[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "`Seq(true, false)` seems simpler... but is this just less confusing to split out into two cases?\r\nYou always test without vectorized, and then if `testVectored` is true, test with it enabled. I know you'd repeat the same block twice but it's the same amount of code and easier to reason about I think.\r\n(I know this is how the code was already.)",
    "commit": "7962660cfa8c752349eefa7421678ccc12060864",
    "createdAt": "2019-01-25T15:41:16Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.File\n+\n+import scala.reflect.ClassTag\n+import scala.reflect.runtime.universe.TypeTag\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode}\n+import org.apache.spark.sql.test.SQLTestUtils\n+\n+private[sql] trait FileBasedDataSourceTest extends SQLTestUtils {\n+\n+  protected val dataSourceName: String\n+  protected val vectorizedReaderEnabledKey: String\n+\n+  /**\n+   * Reads data source file from given `path` as `DataFrame` and passes it to given function.\n+   *\n+   * @param path           The path to file\n+   * @param testVectorized Whether to read the file with vectorized reader. If the data source\n+   *                       doesn't support vectorized reader, this is no op.\n+   * @param f              The given function that takes a `DataFrame` as input.\n+   */\n+  protected def readFile(path: String, testVectorized: Boolean = true)\n+      (f: DataFrame => Unit): Unit = {\n+    (true :: false :: Nil).foreach { vectorized =>"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "OK. I split it to two cases now.",
    "commit": "7962660cfa8c752349eefa7421678ccc12060864",
    "createdAt": "2019-01-29T00:40:04Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.File\n+\n+import scala.reflect.ClassTag\n+import scala.reflect.runtime.universe.TypeTag\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode}\n+import org.apache.spark.sql.test.SQLTestUtils\n+\n+private[sql] trait FileBasedDataSourceTest extends SQLTestUtils {\n+\n+  protected val dataSourceName: String\n+  protected val vectorizedReaderEnabledKey: String\n+\n+  /**\n+   * Reads data source file from given `path` as `DataFrame` and passes it to given function.\n+   *\n+   * @param path           The path to file\n+   * @param testVectorized Whether to read the file with vectorized reader. If the data source\n+   *                       doesn't support vectorized reader, this is no op.\n+   * @param f              The given function that takes a `DataFrame` as input.\n+   */\n+  protected def readFile(path: String, testVectorized: Boolean = true)\n+      (f: DataFrame => Unit): Unit = {\n+    (true :: false :: Nil).foreach { vectorized =>"
  }],
  "prId": 23628
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Could you leave comments about what this trait is used for?",
    "commit": "7962660cfa8c752349eefa7421678ccc12060864",
    "createdAt": "2019-01-29T02:21:20Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.File\n+\n+import scala.reflect.ClassTag\n+import scala.reflect.runtime.universe.TypeTag\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode}\n+import org.apache.spark.sql.test.SQLTestUtils\n+",
    "line": 27
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "The comments added. Thanks.",
    "commit": "7962660cfa8c752349eefa7421678ccc12060864",
    "createdAt": "2019-01-29T02:59:41Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.File\n+\n+import scala.reflect.ClassTag\n+import scala.reflect.runtime.universe.TypeTag\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode}\n+import org.apache.spark.sql.test.SQLTestUtils\n+",
    "line": 27
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Thanks alot!",
    "commit": "7962660cfa8c752349eefa7421678ccc12060864",
    "createdAt": "2019-01-29T03:15:51Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.File\n+\n+import scala.reflect.ClassTag\n+import scala.reflect.runtime.universe.TypeTag\n+\n+import org.apache.spark.sql.{DataFrame, SaveMode}\n+import org.apache.spark.sql.test.SQLTestUtils\n+",
    "line": 27
  }],
  "prId": 23628
}]