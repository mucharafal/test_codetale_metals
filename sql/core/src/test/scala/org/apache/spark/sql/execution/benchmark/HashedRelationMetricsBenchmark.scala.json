[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "we should also check in the result",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-11T10:40:27Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".",
    "line": 36
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "I see. I think we should check in the result after the metrics is removed.",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-11T12:00:19Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".",
    "line": 36
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "<del>oh, actually I can do it by removing the metrics myself.</del>",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-11T12:57:45Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".",
    "line": 36
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "the \"revert\" PR need to update the result, if your PR gets merged first.",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-11T13:03:46Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".",
    "line": 36
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "The result was checked in.",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-11T13:06:42Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".",
    "line": 36
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "The \"revert\" PR gets merged. Let me update the benchmark result.",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-11T14:10:22Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".",
    "line": 36
  }],
  "prId": 23284
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "So, is this the real difference from [AggregateBenchmark.LongToUnsafeRowMap](https://github.com/apache/spark/blob/master/sql/core/src/test/scala/org/apache/spark/sql/execution/benchmark/AggregateBenchmark.scala#L468-L502) benchmark case?",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-11T21:45:47Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".\n+ * }}}\n+ */\n+object HashedRelationMetricsBenchmark extends SqlBasedBenchmark {\n+\n+  def benchmarkLongToUnsafeRowMapMetrics(numRows: Int): Unit = {\n+    runBenchmark(\"LongToUnsafeRowMap metrics\") {\n+      val benchmark = new Benchmark(\"LongToUnsafeRowMap metrics\", numRows, output = output)\n+      benchmark.addCase(\"LongToUnsafeRowMap\") { iter =>\n+        val taskMemoryManager = new TaskMemoryManager(\n+          new StaticMemoryManager(\n+            new SparkConf().set(MEMORY_OFFHEAP_ENABLED.key, \"false\"),\n+            Long.MaxValue,\n+            Long.MaxValue,\n+            1),\n+          0)\n+        val unsafeProj = UnsafeProjection.create(Seq(BoundReference(0, LongType, false)))\n+\n+        val keys = Range.Long(0, numRows, 1)\n+        val map = new LongToUnsafeRowMap(taskMemoryManager, 1)\n+        keys.foreach { k =>\n+          map.append(k, unsafeProj(InternalRow(k)))\n+        }\n+        map.optimize()\n+\n+        val threads = (0 to 100).map { _ =>\n+          val thread = new Thread {",
    "line": 62
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "I think multi-thread is the key here.",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-12T02:07:08Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".\n+ * }}}\n+ */\n+object HashedRelationMetricsBenchmark extends SqlBasedBenchmark {\n+\n+  def benchmarkLongToUnsafeRowMapMetrics(numRows: Int): Unit = {\n+    runBenchmark(\"LongToUnsafeRowMap metrics\") {\n+      val benchmark = new Benchmark(\"LongToUnsafeRowMap metrics\", numRows, output = output)\n+      benchmark.addCase(\"LongToUnsafeRowMap\") { iter =>\n+        val taskMemoryManager = new TaskMemoryManager(\n+          new StaticMemoryManager(\n+            new SparkConf().set(MEMORY_OFFHEAP_ENABLED.key, \"false\"),\n+            Long.MaxValue,\n+            Long.MaxValue,\n+            1),\n+          0)\n+        val unsafeProj = UnsafeProjection.create(Seq(BoundReference(0, LongType, false)))\n+\n+        val keys = Range.Long(0, numRows, 1)\n+        val map = new LongToUnsafeRowMap(taskMemoryManager, 1)\n+        keys.foreach { k =>\n+          map.append(k, unsafeProj(InternalRow(k)))\n+        }\n+        map.optimize()\n+\n+        val threads = (0 to 100).map { _ =>\n+          val thread = new Thread {",
    "line": 62
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "yea, here we focus on multi-thread reading the same `LongToUnsafeRowMap `.",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-12T02:27:27Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".\n+ * }}}\n+ */\n+object HashedRelationMetricsBenchmark extends SqlBasedBenchmark {\n+\n+  def benchmarkLongToUnsafeRowMapMetrics(numRows: Int): Unit = {\n+    runBenchmark(\"LongToUnsafeRowMap metrics\") {\n+      val benchmark = new Benchmark(\"LongToUnsafeRowMap metrics\", numRows, output = output)\n+      benchmark.addCase(\"LongToUnsafeRowMap\") { iter =>\n+        val taskMemoryManager = new TaskMemoryManager(\n+          new StaticMemoryManager(\n+            new SparkConf().set(MEMORY_OFFHEAP_ENABLED.key, \"false\"),\n+            Long.MaxValue,\n+            Long.MaxValue,\n+            1),\n+          0)\n+        val unsafeProj = UnsafeProjection.create(Seq(BoundReference(0, LongType, false)))\n+\n+        val keys = Range.Long(0, numRows, 1)\n+        val map = new LongToUnsafeRowMap(taskMemoryManager, 1)\n+        keys.foreach { k =>\n+          map.append(k, unsafeProj(InternalRow(k)))\n+        }\n+        map.optimize()\n+\n+        val threads = (0 to 100).map { _ =>\n+          val thread = new Thread {",
    "line": 62
  }],
  "prId": 23284
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "to match the real case, shall we benchmark `BytesToBytesMap` instead of `LongToUnsafeRowMap`? The real case is, we have one `LongToUnsafeRowMap` for each thread, but they share the same `BytesToBytesMap`",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-12T02:08:21Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".\n+ * }}}\n+ */\n+object HashedRelationMetricsBenchmark extends SqlBasedBenchmark {",
    "line": 39
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "`UnsafeHashedRelation` uses `BytesToBytesMap`. `LongHashedRelation` uses `LongToUnsafeRowMap`. The real case is we have one `LongHashedRelation` for each thread and they share the same `LongToUnsafeRowMap`.",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-12T02:25:47Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".\n+ * }}}\n+ */\n+object HashedRelationMetricsBenchmark extends SqlBasedBenchmark {",
    "line": 39
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "oh yes I got messed up :P",
    "commit": "723b27ce55770f5846d4244377b37f66f2f9ad60",
    "createdAt": "2018-12-12T02:43:51Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.internal.config.MEMORY_OFFHEAP_ENABLED\n+import org.apache.spark.memory.{StaticMemoryManager, TaskMemoryManager}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.{BoundReference, UnsafeProjection}\n+import org.apache.spark.sql.execution.joins.LongToUnsafeRowMap\n+import org.apache.spark.sql.types.LongType\n+\n+/**\n+ * Benchmark to measure metrics performance at HashedRelation.\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/HashedRelationMetricsBenchmark-results.txt\".\n+ * }}}\n+ */\n+object HashedRelationMetricsBenchmark extends SqlBasedBenchmark {",
    "line": 39
  }],
  "prId": 23284
}]