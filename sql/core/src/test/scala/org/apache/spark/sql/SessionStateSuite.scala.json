[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "just realized. I think there should be some tests that verify that the shared state is still shared and not independent. that is changes in the shared state through one session is reflected in other sessions.",
    "commit": "4c23e7a0caaff5aa2df3dbbf5e6a688b3a4d442d",
    "createdAt": "2017-02-25T01:02:12Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+class SessionStateSuite extends SparkFunSuite with BeforeAndAfterEach {\n+\n+  protected var activeSession: SparkSession = _\n+\n+  protected def createSession(): Unit = {\n+    activeSession = SparkSession.builder().master(\"local\").getOrCreate()\n+  }\n+\n+  override def beforeEach(): Unit = {\n+    createSession()\n+  }\n+\n+  override def afterEach(): Unit = {\n+    activeSession.stop()\n+  }\n+"
  }],
  "prId": 16826
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "the setting and clearing of active session should be in a try-finally so that errors in this test (that does not clear the session) does not cascade to future tests.",
    "commit": "4c23e7a0caaff5aa2df3dbbf5e6a688b3a4d442d",
    "createdAt": "2017-02-25T01:22:15Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+class SessionStateSuite extends SparkFunSuite with BeforeAndAfterEach {\n+\n+  protected var activeSession: SparkSession = _\n+\n+  protected def createSession(): Unit = {\n+    activeSession = SparkSession.builder().master(\"local\").getOrCreate()\n+  }\n+\n+  override def beforeEach(): Unit = {\n+    createSession()\n+  }\n+\n+  override def afterEach(): Unit = {\n+    activeSession.stop()\n+  }\n+\n+  test(\"fork new session and inherit RuntimeConfig options\") {\n+    val key = \"spark-config-clone\"\n+    activeSession.conf.set(key, \"active\")\n+\n+    // inheritance\n+    val forkedSession = activeSession.cloneSession()\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.conf ne activeSession.conf)\n+    assert(forkedSession.conf.get(key) == \"active\")\n+\n+    // independence\n+    forkedSession.conf.set(key, \"forked\")\n+    assert(activeSession.conf.get(key) == \"active\")\n+    activeSession.conf.set(key, \"dontcopyme\")\n+    assert(forkedSession.conf.get(key) == \"forked\")\n+  }\n+\n+  test(\"fork new session and inherit function registry and udf\") {\n+    activeSession.udf.register(\"strlenScala\", (_: String).length + (_: Int))\n+    val forkedSession = activeSession.cloneSession()\n+\n+    // inheritance\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.sessionState.functionRegistry ne\n+      activeSession.sessionState.functionRegistry)\n+    assert(forkedSession.sessionState.functionRegistry.lookupFunction(\"strlenScala\").nonEmpty)\n+\n+    // independence\n+    forkedSession.sessionState.functionRegistry.dropFunction(\"strlenScala\")\n+    assert(activeSession.sessionState.functionRegistry.lookupFunction(\"strlenScala\").nonEmpty)\n+    activeSession.udf.register(\"addone\", (_: Int) + 1)\n+    assert(forkedSession.sessionState.functionRegistry.lookupFunction(\"addone\").isEmpty)\n+  }\n+\n+  test(\"fork new session and inherit experimental methods\") {\n+    object DummyRule1 extends Rule[LogicalPlan] {\n+      def apply(p: LogicalPlan): LogicalPlan = p\n+    }\n+    object DummyRule2 extends Rule[LogicalPlan] {\n+      def apply(p: LogicalPlan): LogicalPlan = p\n+    }\n+    val optimizations = List(DummyRule1, DummyRule2)\n+\n+    activeSession.experimental.extraOptimizations = optimizations\n+\n+    val forkedSession = activeSession.cloneSession()\n+\n+    // inheritance\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.experimental ne activeSession.experimental)\n+    assert(forkedSession.experimental.extraOptimizations.toSet ==\n+      activeSession.experimental.extraOptimizations.toSet)\n+\n+    // independence\n+    forkedSession.experimental.extraOptimizations = List(DummyRule2)\n+    assert(activeSession.experimental.extraOptimizations == optimizations)\n+    activeSession.experimental.extraOptimizations = List(DummyRule1)\n+    assert(forkedSession.experimental.extraOptimizations == List(DummyRule2))\n+  }\n+\n+  test(\"fork new sessions and run query on inherited table\") {\n+    def checkTableExists(sparkSession: SparkSession): Unit = {\n+      QueryTest.checkAnswer(sparkSession.sql(\n+        \"\"\"\n+          |SELECT x.str, COUNT(*)\n+          |FROM df x JOIN df y ON x.str = y.str\n+          |GROUP BY x.str\n+        \"\"\".stripMargin),\n+        Row(\"1\", 1) :: Row(\"2\", 1) :: Row(\"3\", 1) :: Nil)\n+    }\n+\n+    SparkSession.setActiveSession(activeSession)"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "well.. why do you need to set this? other tests in this suite does not set it. if there is a reason, its not obvious and should be commented about.",
    "commit": "4c23e7a0caaff5aa2df3dbbf5e6a688b3a4d442d",
    "createdAt": "2017-02-25T01:32:31Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+class SessionStateSuite extends SparkFunSuite with BeforeAndAfterEach {\n+\n+  protected var activeSession: SparkSession = _\n+\n+  protected def createSession(): Unit = {\n+    activeSession = SparkSession.builder().master(\"local\").getOrCreate()\n+  }\n+\n+  override def beforeEach(): Unit = {\n+    createSession()\n+  }\n+\n+  override def afterEach(): Unit = {\n+    activeSession.stop()\n+  }\n+\n+  test(\"fork new session and inherit RuntimeConfig options\") {\n+    val key = \"spark-config-clone\"\n+    activeSession.conf.set(key, \"active\")\n+\n+    // inheritance\n+    val forkedSession = activeSession.cloneSession()\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.conf ne activeSession.conf)\n+    assert(forkedSession.conf.get(key) == \"active\")\n+\n+    // independence\n+    forkedSession.conf.set(key, \"forked\")\n+    assert(activeSession.conf.get(key) == \"active\")\n+    activeSession.conf.set(key, \"dontcopyme\")\n+    assert(forkedSession.conf.get(key) == \"forked\")\n+  }\n+\n+  test(\"fork new session and inherit function registry and udf\") {\n+    activeSession.udf.register(\"strlenScala\", (_: String).length + (_: Int))\n+    val forkedSession = activeSession.cloneSession()\n+\n+    // inheritance\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.sessionState.functionRegistry ne\n+      activeSession.sessionState.functionRegistry)\n+    assert(forkedSession.sessionState.functionRegistry.lookupFunction(\"strlenScala\").nonEmpty)\n+\n+    // independence\n+    forkedSession.sessionState.functionRegistry.dropFunction(\"strlenScala\")\n+    assert(activeSession.sessionState.functionRegistry.lookupFunction(\"strlenScala\").nonEmpty)\n+    activeSession.udf.register(\"addone\", (_: Int) + 1)\n+    assert(forkedSession.sessionState.functionRegistry.lookupFunction(\"addone\").isEmpty)\n+  }\n+\n+  test(\"fork new session and inherit experimental methods\") {\n+    object DummyRule1 extends Rule[LogicalPlan] {\n+      def apply(p: LogicalPlan): LogicalPlan = p\n+    }\n+    object DummyRule2 extends Rule[LogicalPlan] {\n+      def apply(p: LogicalPlan): LogicalPlan = p\n+    }\n+    val optimizations = List(DummyRule1, DummyRule2)\n+\n+    activeSession.experimental.extraOptimizations = optimizations\n+\n+    val forkedSession = activeSession.cloneSession()\n+\n+    // inheritance\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.experimental ne activeSession.experimental)\n+    assert(forkedSession.experimental.extraOptimizations.toSet ==\n+      activeSession.experimental.extraOptimizations.toSet)\n+\n+    // independence\n+    forkedSession.experimental.extraOptimizations = List(DummyRule2)\n+    assert(activeSession.experimental.extraOptimizations == optimizations)\n+    activeSession.experimental.extraOptimizations = List(DummyRule1)\n+    assert(forkedSession.experimental.extraOptimizations == List(DummyRule2))\n+  }\n+\n+  test(\"fork new sessions and run query on inherited table\") {\n+    def checkTableExists(sparkSession: SparkSession): Unit = {\n+      QueryTest.checkAnswer(sparkSession.sql(\n+        \"\"\"\n+          |SELECT x.str, COUNT(*)\n+          |FROM df x JOIN df y ON x.str = y.str\n+          |GROUP BY x.str\n+        \"\"\".stripMargin),\n+        Row(\"1\", 1) :: Row(\"2\", 1) :: Row(\"3\", 1) :: Nil)\n+    }\n+\n+    SparkSession.setActiveSession(activeSession)"
  }, {
    "author": {
      "login": "kunalkhamar"
    },
    "body": "True, its not required to set active session anymore. Removed.",
    "commit": "4c23e7a0caaff5aa2df3dbbf5e6a688b3a4d442d",
    "createdAt": "2017-02-27T23:20:01Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+class SessionStateSuite extends SparkFunSuite with BeforeAndAfterEach {\n+\n+  protected var activeSession: SparkSession = _\n+\n+  protected def createSession(): Unit = {\n+    activeSession = SparkSession.builder().master(\"local\").getOrCreate()\n+  }\n+\n+  override def beforeEach(): Unit = {\n+    createSession()\n+  }\n+\n+  override def afterEach(): Unit = {\n+    activeSession.stop()\n+  }\n+\n+  test(\"fork new session and inherit RuntimeConfig options\") {\n+    val key = \"spark-config-clone\"\n+    activeSession.conf.set(key, \"active\")\n+\n+    // inheritance\n+    val forkedSession = activeSession.cloneSession()\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.conf ne activeSession.conf)\n+    assert(forkedSession.conf.get(key) == \"active\")\n+\n+    // independence\n+    forkedSession.conf.set(key, \"forked\")\n+    assert(activeSession.conf.get(key) == \"active\")\n+    activeSession.conf.set(key, \"dontcopyme\")\n+    assert(forkedSession.conf.get(key) == \"forked\")\n+  }\n+\n+  test(\"fork new session and inherit function registry and udf\") {\n+    activeSession.udf.register(\"strlenScala\", (_: String).length + (_: Int))\n+    val forkedSession = activeSession.cloneSession()\n+\n+    // inheritance\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.sessionState.functionRegistry ne\n+      activeSession.sessionState.functionRegistry)\n+    assert(forkedSession.sessionState.functionRegistry.lookupFunction(\"strlenScala\").nonEmpty)\n+\n+    // independence\n+    forkedSession.sessionState.functionRegistry.dropFunction(\"strlenScala\")\n+    assert(activeSession.sessionState.functionRegistry.lookupFunction(\"strlenScala\").nonEmpty)\n+    activeSession.udf.register(\"addone\", (_: Int) + 1)\n+    assert(forkedSession.sessionState.functionRegistry.lookupFunction(\"addone\").isEmpty)\n+  }\n+\n+  test(\"fork new session and inherit experimental methods\") {\n+    object DummyRule1 extends Rule[LogicalPlan] {\n+      def apply(p: LogicalPlan): LogicalPlan = p\n+    }\n+    object DummyRule2 extends Rule[LogicalPlan] {\n+      def apply(p: LogicalPlan): LogicalPlan = p\n+    }\n+    val optimizations = List(DummyRule1, DummyRule2)\n+\n+    activeSession.experimental.extraOptimizations = optimizations\n+\n+    val forkedSession = activeSession.cloneSession()\n+\n+    // inheritance\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.experimental ne activeSession.experimental)\n+    assert(forkedSession.experimental.extraOptimizations.toSet ==\n+      activeSession.experimental.extraOptimizations.toSet)\n+\n+    // independence\n+    forkedSession.experimental.extraOptimizations = List(DummyRule2)\n+    assert(activeSession.experimental.extraOptimizations == optimizations)\n+    activeSession.experimental.extraOptimizations = List(DummyRule1)\n+    assert(forkedSession.experimental.extraOptimizations == List(DummyRule2))\n+  }\n+\n+  test(\"fork new sessions and run query on inherited table\") {\n+    def checkTableExists(sparkSession: SparkSession): Unit = {\n+      QueryTest.checkAnswer(sparkSession.sql(\n+        \"\"\"\n+          |SELECT x.str, COUNT(*)\n+          |FROM df x JOIN df y ON x.str = y.str\n+          |GROUP BY x.str\n+        \"\"\".stripMargin),\n+        Row(\"1\", 1) :: Row(\"2\", 1) :: Row(\"3\", 1) :: Nil)\n+    }\n+\n+    SparkSession.setActiveSession(activeSession)"
  }],
  "prId": 16826
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: this is creating a SparkContext every time. rather use SharedSparkContext trait, to share that, and create sessions using the same spark context.",
    "commit": "4c23e7a0caaff5aa2df3dbbf5e6a688b3a4d442d",
    "createdAt": "2017-02-25T01:30:59Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+class SessionStateSuite extends SparkFunSuite with BeforeAndAfterEach {\n+\n+  protected var activeSession: SparkSession = _\n+\n+  protected def createSession(): Unit = {"
  }],
  "prId": 16826
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: too many extra lines.",
    "commit": "4c23e7a0caaff5aa2df3dbbf5e6a688b3a4d442d",
    "createdAt": "2017-02-25T01:32:06Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+class SessionStateSuite extends SparkFunSuite with BeforeAndAfterEach {\n+\n+  protected var activeSession: SparkSession = _\n+\n+  protected def createSession(): Unit = {\n+    activeSession = SparkSession.builder().master(\"local\").getOrCreate()\n+  }\n+\n+  override def beforeEach(): Unit = {\n+    createSession()\n+  }\n+\n+  override def afterEach(): Unit = {\n+    activeSession.stop()\n+  }\n+\n+  test(\"fork new session and inherit RuntimeConfig options\") {\n+    val key = \"spark-config-clone\"\n+    activeSession.conf.set(key, \"active\")\n+\n+    // inheritance\n+    val forkedSession = activeSession.cloneSession()\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.conf ne activeSession.conf)\n+    assert(forkedSession.conf.get(key) == \"active\")\n+\n+    // independence\n+    forkedSession.conf.set(key, \"forked\")\n+    assert(activeSession.conf.get(key) == \"active\")\n+    activeSession.conf.set(key, \"dontcopyme\")\n+    assert(forkedSession.conf.get(key) == \"forked\")\n+  }\n+\n+  test(\"fork new session and inherit function registry and udf\") {\n+    activeSession.udf.register(\"strlenScala\", (_: String).length + (_: Int))\n+    val forkedSession = activeSession.cloneSession()\n+\n+    // inheritance\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.sessionState.functionRegistry ne\n+      activeSession.sessionState.functionRegistry)\n+    assert(forkedSession.sessionState.functionRegistry.lookupFunction(\"strlenScala\").nonEmpty)\n+\n+    // independence\n+    forkedSession.sessionState.functionRegistry.dropFunction(\"strlenScala\")\n+    assert(activeSession.sessionState.functionRegistry.lookupFunction(\"strlenScala\").nonEmpty)\n+    activeSession.udf.register(\"addone\", (_: Int) + 1)\n+    assert(forkedSession.sessionState.functionRegistry.lookupFunction(\"addone\").isEmpty)\n+  }\n+\n+  test(\"fork new session and inherit experimental methods\") {\n+    object DummyRule1 extends Rule[LogicalPlan] {\n+      def apply(p: LogicalPlan): LogicalPlan = p\n+    }\n+    object DummyRule2 extends Rule[LogicalPlan] {\n+      def apply(p: LogicalPlan): LogicalPlan = p\n+    }\n+    val optimizations = List(DummyRule1, DummyRule2)\n+\n+    activeSession.experimental.extraOptimizations = optimizations\n+"
  }, {
    "author": {
      "login": "kunalkhamar"
    },
    "body": "removed.",
    "commit": "4c23e7a0caaff5aa2df3dbbf5e6a688b3a4d442d",
    "createdAt": "2017-02-27T20:41:06Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.rules.Rule\n+\n+class SessionStateSuite extends SparkFunSuite with BeforeAndAfterEach {\n+\n+  protected var activeSession: SparkSession = _\n+\n+  protected def createSession(): Unit = {\n+    activeSession = SparkSession.builder().master(\"local\").getOrCreate()\n+  }\n+\n+  override def beforeEach(): Unit = {\n+    createSession()\n+  }\n+\n+  override def afterEach(): Unit = {\n+    activeSession.stop()\n+  }\n+\n+  test(\"fork new session and inherit RuntimeConfig options\") {\n+    val key = \"spark-config-clone\"\n+    activeSession.conf.set(key, \"active\")\n+\n+    // inheritance\n+    val forkedSession = activeSession.cloneSession()\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.conf ne activeSession.conf)\n+    assert(forkedSession.conf.get(key) == \"active\")\n+\n+    // independence\n+    forkedSession.conf.set(key, \"forked\")\n+    assert(activeSession.conf.get(key) == \"active\")\n+    activeSession.conf.set(key, \"dontcopyme\")\n+    assert(forkedSession.conf.get(key) == \"forked\")\n+  }\n+\n+  test(\"fork new session and inherit function registry and udf\") {\n+    activeSession.udf.register(\"strlenScala\", (_: String).length + (_: Int))\n+    val forkedSession = activeSession.cloneSession()\n+\n+    // inheritance\n+    assert(forkedSession ne activeSession)\n+    assert(forkedSession.sessionState.functionRegistry ne\n+      activeSession.sessionState.functionRegistry)\n+    assert(forkedSession.sessionState.functionRegistry.lookupFunction(\"strlenScala\").nonEmpty)\n+\n+    // independence\n+    forkedSession.sessionState.functionRegistry.dropFunction(\"strlenScala\")\n+    assert(activeSession.sessionState.functionRegistry.lookupFunction(\"strlenScala\").nonEmpty)\n+    activeSession.udf.register(\"addone\", (_: Int) + 1)\n+    assert(forkedSession.sessionState.functionRegistry.lookupFunction(\"addone\").isEmpty)\n+  }\n+\n+  test(\"fork new session and inherit experimental methods\") {\n+    object DummyRule1 extends Rule[LogicalPlan] {\n+      def apply(p: LogicalPlan): LogicalPlan = p\n+    }\n+    object DummyRule2 extends Rule[LogicalPlan] {\n+      def apply(p: LogicalPlan): LogicalPlan = p\n+    }\n+    val optimizations = List(DummyRule1, DummyRule2)\n+\n+    activeSession.experimental.extraOptimizations = optimizations\n+"
  }],
  "prId": 16826
}, {
  "comments": [{
    "author": {
      "login": "kunalkhamar"
    },
    "body": "Shoud this be inside try {} ?",
    "commit": "4c23e7a0caaff5aa2df3dbbf5e6a688b3a4d442d",
    "createdAt": "2017-03-07T21:16:27Z",
    "diffHunk": "@@ -20,86 +20,105 @@ package org.apache.spark.sql\n import org.scalatest.BeforeAndAfterAll\n import org.scalatest.BeforeAndAfterEach\n \n-import org.apache.spark.SparkContext\n import org.apache.spark.SparkFunSuite\n import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n import org.apache.spark.sql.catalyst.rules.Rule\n \n class SessionStateSuite extends SparkFunSuite\n     with BeforeAndAfterEach with BeforeAndAfterAll {\n \n+  /**\n+   * A shared SparkSession for all tests in this suite. Make sure you reset any changes to this\n+   * session as this is a singleton HiveSparkSession in HiveSessionStateSuite and it's shared\n+   * with all Hive test suites.\n+   */\n   protected var activeSession: SparkSession = _\n-  protected var sparkContext: SparkContext = null\n \n   override def beforeAll(): Unit = {\n-    sparkContext = SparkSession.builder().master(\"local\").getOrCreate().sparkContext\n+    activeSession = SparkSession.builder().master(\"local\").getOrCreate()\n   }\n \n-  protected def createSession(): Unit = {\n-    activeSession =\n-      SparkSession.builder().master(\"local\").sparkContext(sparkContext).getOrCreate()\n-  }\n-\n-  override def beforeEach(): Unit = {\n-    createSession()\n+  override def afterAll(): Unit = {\n+    if (activeSession != null) {\n+      activeSession.stop()\n+      activeSession = null\n+    }\n+    super.afterAll()\n   }\n \n   test(\"fork new session and inherit RuntimeConfig options\") {\n     val key = \"spark-config-clone\"\n     activeSession.conf.set(key, \"active\")"
  }],
  "prId": 16826
}, {
  "comments": [{
    "author": {
      "login": "kunalkhamar"
    },
    "body": "Should create temp view be inside try block?",
    "commit": "4c23e7a0caaff5aa2df3dbbf5e6a688b3a4d442d",
    "createdAt": "2017-03-07T21:18:32Z",
    "diffHunk": "@@ -113,19 +132,26 @@ class SessionStateSuite extends SparkFunSuite\n         Row(\"1\", 1) :: Row(\"2\", 1) :: Row(\"3\", 1) :: Nil)\n     }\n \n-    implicit val enc = Encoders.tuple(Encoders.scalaInt, Encoders.STRING)\n+    val spark = activeSession\n+    // Cannot use `import activeSession.implicits._` due to the compiler limitation.\n+    import spark.implicits._\n+\n     activeSession"
  }],
  "prId": 16826
}]