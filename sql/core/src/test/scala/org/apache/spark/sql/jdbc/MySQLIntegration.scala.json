[{
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "nit: MySQLIntegrationSuite\n",
    "commit": "fbc471bd8de9d7742b4329f79610ab9dd8fe123c",
    "createdAt": "2015-08-12T17:31:17Z",
    "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.jdbc\n+\n+import java.math.BigDecimal\n+import java.sql.{Date, Timestamp}\n+\n+import org.scalatest.BeforeAndAfterAll\n+\n+import com.spotify.docker.client.DockerClient\n+import com.spotify.docker.client.messages.ContainerConfig\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.test._\n+\n+class MySQLDatabase {\n+  val docker: DockerClient = DockerClientFactory.get()\n+\n+  val containerId = {\n+    docker.pull(\"mysql\")\n+    val config = ContainerConfig.builder().image(\"mysql\")\n+      .env(\"MYSQL_ROOT_PASSWORD=rootpass\")\n+      .build()\n+    val id = docker.createContainer(config).id\n+    docker.startContainer(id)\n+    id\n+  }\n+\n+  val ip = docker.inspectContainer(containerId).networkSettings.ipAddress\n+\n+  def close() {\n+    docker.killContainer(containerId)\n+    docker.removeContainer(containerId)\n+    DockerClientFactory.close(docker)\n+  }\n+}\n+\n+class MySQLIntegration extends SparkFunSuite with BeforeAndAfterAll {"
  }],
  "prId": 8101
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "```\n[warn] /home/jenkins/workspace/SparkPullRequestBuilder@2/sql/core/src/test/scala/org/apache/spark/sql/jdbc/MySQLIntegration.scala:130: method jdbc in class SQLContext is deprecated: use read.jdbc()\n[warn]     val df = TestSQLContext.jdbc(url(ip, \"foo\"), \"tbl\")\n[warn]                             ^\n```\n",
    "commit": "fbc471bd8de9d7742b4329f79610ab9dd8fe123c",
    "createdAt": "2015-08-12T17:34:49Z",
    "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.jdbc\n+\n+import java.math.BigDecimal\n+import java.sql.{Date, Timestamp}\n+\n+import org.scalatest.BeforeAndAfterAll\n+\n+import com.spotify.docker.client.DockerClient\n+import com.spotify.docker.client.messages.ContainerConfig\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.sql.test._\n+\n+class MySQLDatabase {\n+  val docker: DockerClient = DockerClientFactory.get()\n+\n+  val containerId = {\n+    docker.pull(\"mysql\")\n+    val config = ContainerConfig.builder().image(\"mysql\")\n+      .env(\"MYSQL_ROOT_PASSWORD=rootpass\")\n+      .build()\n+    val id = docker.createContainer(config).id\n+    docker.startContainer(id)\n+    id\n+  }\n+\n+  val ip = docker.inspectContainer(containerId).networkSettings.ipAddress\n+\n+  def close() {\n+    docker.killContainer(containerId)\n+    docker.removeContainer(containerId)\n+    DockerClientFactory.close(docker)\n+  }\n+}\n+\n+class MySQLIntegration extends SparkFunSuite with BeforeAndAfterAll {\n+  var ip: String = null\n+\n+  def url(ip: String): String = url(ip, \"mysql\")\n+  def url(ip: String, db: String): String = s\"jdbc:mysql://$ip:3306/$db?user=root&password=rootpass\"\n+\n+  def waitForDatabase(ip: String, maxMillis: Long) {\n+    val before = System.currentTimeMillis()\n+    var lastException: java.sql.SQLException = null\n+    while (true) {\n+      if (System.currentTimeMillis() > before + maxMillis) {\n+        throw new java.sql.SQLException(s\"Database not up after $maxMillis ms.\", lastException)\n+      }\n+      try {\n+        val conn = java.sql.DriverManager.getConnection(url(ip))\n+        conn.close()\n+        return\n+      } catch {\n+        case e: java.sql.SQLException =>\n+          lastException = e\n+          java.lang.Thread.sleep(250)\n+      }\n+    }\n+  }\n+\n+  def setupDatabase(ip: String) {\n+    val conn = java.sql.DriverManager.getConnection(url(ip))\n+    try {\n+      conn.prepareStatement(\"CREATE DATABASE foo\").executeUpdate()\n+      conn.prepareStatement(\"CREATE TABLE foo.tbl (x INTEGER, y TEXT(8))\").executeUpdate()\n+      conn.prepareStatement(\"INSERT INTO foo.tbl VALUES (42,'fred')\").executeUpdate()\n+      conn.prepareStatement(\"INSERT INTO foo.tbl VALUES (17,'dave')\").executeUpdate()\n+\n+      conn.prepareStatement(\"CREATE TABLE foo.numbers (onebit BIT(1), tenbits BIT(10), \"\n+        + \"small SMALLINT, med MEDIUMINT, nor INT, big BIGINT, deci DECIMAL(40,20), flt FLOAT, \"\n+        + \"dbl DOUBLE)\").executeUpdate()\n+      conn.prepareStatement(\"INSERT INTO foo.numbers VALUES (b'0', b'1000100101', \"\n+        + \"17, 77777, 123456789, 123456789012345, 123456789012345.123456789012345, \"\n+        + \"42.75, 1.0000000000000002)\").executeUpdate()\n+\n+      conn.prepareStatement(\"CREATE TABLE foo.dates (d DATE, t TIME, dt DATETIME, ts TIMESTAMP, \"\n+        + \"yr YEAR)\").executeUpdate()\n+      conn.prepareStatement(\"INSERT INTO foo.dates VALUES ('1991-11-09', '13:31:24', \"\n+        + \"'1996-01-01 01:23:45', '2009-02-13 23:31:30', '2001')\").executeUpdate()\n+\n+      // TODO: Test locale conversion for strings.\n+      conn.prepareStatement(\"CREATE TABLE foo.strings (a CHAR(10), b VARCHAR(10), c TINYTEXT, \"\n+        + \"d TEXT, e MEDIUMTEXT, f LONGTEXT, g BINARY(4), h VARBINARY(10), i BLOB)\"\n+      ).executeUpdate()\n+      conn.prepareStatement(\"INSERT INTO foo.strings VALUES ('the', 'quick', 'brown', 'fox', \" +\n+        \"'jumps', 'over', 'the', 'lazy', 'dog')\").executeUpdate()\n+    } finally {\n+      conn.close()\n+    }\n+  }\n+\n+  var db: MySQLDatabase = null\n+\n+  override def beforeAll() {\n+    // If you load the MySQL driver here, DriverManager will deadlock.  The\n+    // MySQL driver gets loaded when its jar gets loaded, unlike the Postgres\n+    // and H2 drivers.\n+    // scalastyle:off classforname\n+    // Class.forName(\"com.mysql.jdbc.Driver\")\n+    // scalastyle:on classforname\n+\n+    db = new MySQLDatabase()\n+    waitForDatabase(db.ip, 60000)\n+    setupDatabase(db.ip)\n+    ip = db.ip\n+  }\n+\n+  override def afterAll() {\n+    db.close()\n+  }\n+\n+  test(\"Basic test\") {\n+    val df = TestSQLContext.jdbc(url(ip, \"foo\"), \"tbl\")\n+    val rows = df.collect()\n+    assert(rows.length == 2)\n+    val types = rows(0).toSeq.map(x => x.getClass.toString)\n+    assert(types.length == 2)\n+    assert(types(0).equals(\"class java.lang.Integer\"))\n+    assert(types(1).equals(\"class java.lang.String\"))\n+  }\n+\n+  test(\"Numeric types\") {\n+    val df = TestSQLContext.jdbc(url(ip, \"foo\"), \"numbers\")"
  }],
  "prId": 8101
}]