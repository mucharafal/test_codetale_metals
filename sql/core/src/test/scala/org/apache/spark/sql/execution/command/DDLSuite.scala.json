[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "To other reviewers: ALTER TABLE SET LOCATION for partition is not allowed for tables defined using the datasource API",
    "commit": "0d947a55a80ecc63eb15092c29b2c44aeeb197e5",
    "createdAt": "2017-02-13T18:26:53Z",
    "diffHunk": "@@ -1816,4 +1816,127 @@ class DDLSuite extends QueryTest with SharedSQLContext with BeforeAndAfterEach {\n       }\n     }\n   }\n+\n+  test(\"insert data to a data source table which has a not existed location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+              |CREATE TABLE t(a string, b int)\n+              |USING parquet\n+              |OPTIONS(path \"file:${dir.getCanonicalPath}\")\n+           \"\"\".stripMargin)\n+        val table = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        val expectedPath = s\"file:${dir.getAbsolutePath.stripSuffix(\"/\")}\"\n+        assert(table.location.stripSuffix(\"/\") == expectedPath)\n+\n+        dir.delete\n+        val tableLocFile = new File(table.location.stripPrefix(\"file:\"))\n+        assert(!tableLocFile.exists)\n+        spark.sql(\"INSERT INTO TABLE t SELECT 'c', 1\")\n+        assert(tableLocFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+\n+        Utils.deleteRecursively(dir)\n+        assert(!tableLocFile.exists)\n+        spark.sql(\"INSERT OVERWRITE TABLE t SELECT 'c', 1\")\n+        assert(tableLocFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+\n+        val newDir = dir.getAbsolutePath.stripSuffix(\"/\") + \"/x\"\n+        val newDirFile = new File(newDir)\n+        spark.sql(s\"ALTER TABLE t SET LOCATION '$newDir'\")\n+        spark.sessionState.catalog.refreshTable(TableIdentifier(\"t\"))\n+\n+        val table1 = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        assert(table1.location == newDir)\n+        assert(!newDirFile.exists)\n+\n+        spark.sql(\"INSERT INTO TABLE t SELECT 'c', 1\")\n+        assert(newDirFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+      }\n+    }\n+  }\n+\n+  test(\"insert into a data source table with no existed partition location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+              |CREATE TABLE t(a int, b int, c int, d int)\n+              |USING parquet\n+              |PARTITIONED BY(a, b)\n+              |LOCATION \"file:${dir.getCanonicalPath}\"\n+           \"\"\".stripMargin)\n+        val table = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        val expectedPath = s\"file:${dir.getAbsolutePath.stripSuffix(\"/\")}\"\n+        assert(table.location.stripSuffix(\"/\") == expectedPath)\n+\n+        spark.sql(\"INSERT INTO TABLE t PARTITION(a=1, b=2) SELECT 3, 4\")\n+        checkAnswer(spark.table(\"t\"), Row(3, 4, 1, 2) :: Nil)\n+\n+        val partLoc = new File(s\"${dir.getAbsolutePath}/a=1\")\n+        Utils.deleteRecursively(partLoc)\n+        assert(!partLoc.exists())\n+        // insert overwrite into a partition which location has been deleted.\n+        spark.sql(\"INSERT OVERWRITE TABLE t PARTITION(a=1, b=2) SELECT 7, 8\")\n+        assert(partLoc.exists())\n+        checkAnswer(spark.table(\"t\"), Row(7, 8, 1, 2) :: Nil)\n+\n+        // TODO:insert into a partition after alter the partition location by alter command"
  }, {
    "author": {
      "login": "windpiger"
    },
    "body": "I found there is a bug in this situation. and I create a jira\r\nhttps://issues.apache.org/jira/browse/SPARK-19577\r\n\r\nshall we just forbid this situation or fix it?",
    "commit": "0d947a55a80ecc63eb15092c29b2c44aeeb197e5",
    "createdAt": "2017-02-14T05:44:59Z",
    "diffHunk": "@@ -1816,4 +1816,127 @@ class DDLSuite extends QueryTest with SharedSQLContext with BeforeAndAfterEach {\n       }\n     }\n   }\n+\n+  test(\"insert data to a data source table which has a not existed location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+              |CREATE TABLE t(a string, b int)\n+              |USING parquet\n+              |OPTIONS(path \"file:${dir.getCanonicalPath}\")\n+           \"\"\".stripMargin)\n+        val table = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        val expectedPath = s\"file:${dir.getAbsolutePath.stripSuffix(\"/\")}\"\n+        assert(table.location.stripSuffix(\"/\") == expectedPath)\n+\n+        dir.delete\n+        val tableLocFile = new File(table.location.stripPrefix(\"file:\"))\n+        assert(!tableLocFile.exists)\n+        spark.sql(\"INSERT INTO TABLE t SELECT 'c', 1\")\n+        assert(tableLocFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+\n+        Utils.deleteRecursively(dir)\n+        assert(!tableLocFile.exists)\n+        spark.sql(\"INSERT OVERWRITE TABLE t SELECT 'c', 1\")\n+        assert(tableLocFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+\n+        val newDir = dir.getAbsolutePath.stripSuffix(\"/\") + \"/x\"\n+        val newDirFile = new File(newDir)\n+        spark.sql(s\"ALTER TABLE t SET LOCATION '$newDir'\")\n+        spark.sessionState.catalog.refreshTable(TableIdentifier(\"t\"))\n+\n+        val table1 = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        assert(table1.location == newDir)\n+        assert(!newDirFile.exists)\n+\n+        spark.sql(\"INSERT INTO TABLE t SELECT 'c', 1\")\n+        assert(newDirFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+      }\n+    }\n+  }\n+\n+  test(\"insert into a data source table with no existed partition location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+              |CREATE TABLE t(a int, b int, c int, d int)\n+              |USING parquet\n+              |PARTITIONED BY(a, b)\n+              |LOCATION \"file:${dir.getCanonicalPath}\"\n+           \"\"\".stripMargin)\n+        val table = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        val expectedPath = s\"file:${dir.getAbsolutePath.stripSuffix(\"/\")}\"\n+        assert(table.location.stripSuffix(\"/\") == expectedPath)\n+\n+        spark.sql(\"INSERT INTO TABLE t PARTITION(a=1, b=2) SELECT 3, 4\")\n+        checkAnswer(spark.table(\"t\"), Row(3, 4, 1, 2) :: Nil)\n+\n+        val partLoc = new File(s\"${dir.getAbsolutePath}/a=1\")\n+        Utils.deleteRecursively(partLoc)\n+        assert(!partLoc.exists())\n+        // insert overwrite into a partition which location has been deleted.\n+        spark.sql(\"INSERT OVERWRITE TABLE t PARTITION(a=1, b=2) SELECT 7, 8\")\n+        assert(partLoc.exists())\n+        checkAnswer(spark.table(\"t\"), Row(7, 8, 1, 2) :: Nil)\n+\n+        // TODO:insert into a partition after alter the partition location by alter command"
  }],
  "prId": 16672
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "- First, you do not need to add the `file:`\r\n- Second, you still need to adjust the indent.\r\n\r\n```Scala\r\n        spark.sql(\r\n          s\"\"\"\r\n            |CREATE TABLE t(a int, b int, c int, d int)\r\n            |USING parquet\r\n            |PARTITIONED BY(a, b)\r\n            |LOCATION '$dir'\r\n           \"\"\".stripMargin)\r\n        val expectedPath = dir.getAbsolutePath.stripSuffix(\"/\")\r\n```",
    "commit": "0d947a55a80ecc63eb15092c29b2c44aeeb197e5",
    "createdAt": "2017-02-13T19:52:52Z",
    "diffHunk": "@@ -1816,4 +1816,127 @@ class DDLSuite extends QueryTest with SharedSQLContext with BeforeAndAfterEach {\n       }\n     }\n   }\n+\n+  test(\"insert data to a data source table which has a not existed location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+              |CREATE TABLE t(a string, b int)\n+              |USING parquet\n+              |OPTIONS(path \"file:${dir.getCanonicalPath}\")"
  }],
  "prId": 16672
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "This is not being used.",
    "commit": "0d947a55a80ecc63eb15092c29b2c44aeeb197e5",
    "createdAt": "2017-02-13T19:55:17Z",
    "diffHunk": "@@ -1816,4 +1816,127 @@ class DDLSuite extends QueryTest with SharedSQLContext with BeforeAndAfterEach {\n       }\n     }\n   }\n+\n+  test(\"insert data to a data source table which has a not existed location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+              |CREATE TABLE t(a string, b int)\n+              |USING parquet\n+              |OPTIONS(path \"file:${dir.getCanonicalPath}\")\n+           \"\"\".stripMargin)\n+        val table = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        val expectedPath = s\"file:${dir.getAbsolutePath.stripSuffix(\"/\")}\"\n+        assert(table.location.stripSuffix(\"/\") == expectedPath)\n+\n+        dir.delete\n+        val tableLocFile = new File(table.location.stripPrefix(\"file:\"))\n+        assert(!tableLocFile.exists)\n+        spark.sql(\"INSERT INTO TABLE t SELECT 'c', 1\")\n+        assert(tableLocFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+\n+        Utils.deleteRecursively(dir)\n+        assert(!tableLocFile.exists)\n+        spark.sql(\"INSERT OVERWRITE TABLE t SELECT 'c', 1\")\n+        assert(tableLocFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+\n+        val newDir = dir.getAbsolutePath.stripSuffix(\"/\") + \"/x\"\n+        val newDirFile = new File(newDir)\n+        spark.sql(s\"ALTER TABLE t SET LOCATION '$newDir'\")\n+        spark.sessionState.catalog.refreshTable(TableIdentifier(\"t\"))\n+\n+        val table1 = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        assert(table1.location == newDir)\n+        assert(!newDirFile.exists)\n+\n+        spark.sql(\"INSERT INTO TABLE t SELECT 'c', 1\")\n+        assert(newDirFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+      }\n+    }\n+  }\n+\n+  test(\"insert into a data source table with no existed partition location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+              |CREATE TABLE t(a int, b int, c int, d int)\n+              |USING parquet\n+              |PARTITIONED BY(a, b)\n+              |LOCATION \"file:${dir.getCanonicalPath}\"\n+           \"\"\".stripMargin)\n+        val table = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        val expectedPath = s\"file:${dir.getAbsolutePath.stripSuffix(\"/\")}\"\n+        assert(table.location.stripSuffix(\"/\") == expectedPath)\n+\n+        spark.sql(\"INSERT INTO TABLE t PARTITION(a=1, b=2) SELECT 3, 4\")\n+        checkAnswer(spark.table(\"t\"), Row(3, 4, 1, 2) :: Nil)\n+\n+        val partLoc = new File(s\"${dir.getAbsolutePath}/a=1\")\n+        Utils.deleteRecursively(partLoc)\n+        assert(!partLoc.exists())\n+        // insert overwrite into a partition which location has been deleted.\n+        spark.sql(\"INSERT OVERWRITE TABLE t PARTITION(a=1, b=2) SELECT 7, 8\")\n+        assert(partLoc.exists())\n+        checkAnswer(spark.table(\"t\"), Row(7, 8, 1, 2) :: Nil)\n+\n+        // TODO:insert into a partition after alter the partition location by alter command\n+      }\n+    }\n+  }\n+\n+  test(\"read data from a data source table which has a not existed location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+              |CREATE TABLE t(a string, b int)\n+              |USING parquet\n+              |OPTIONS(path \"file:${dir.getAbsolutePath}\")\n+           \"\"\".stripMargin)\n+        val table = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        val expectedPath = s\"file:${dir.getAbsolutePath.stripSuffix(\"/\")}\"\n+        assert(table.location.stripSuffix(\"/\") == expectedPath)\n+\n+        dir.delete()\n+        checkAnswer(spark.table(\"t\"), Nil)\n+\n+        val newDir = dir.getAbsolutePath.stripSuffix(\"/\") + \"/x\"\n+        spark.sql(s\"ALTER TABLE t SET LOCATION '$newDir'\")\n+\n+        val table1 = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        assert(table1.location == newDir)\n+        assert(!new File(newDir).exists())\n+        checkAnswer(spark.table(\"t\"), Nil)\n+      }\n+    }\n+  }\n+\n+  test(\"read data from a data source table with no existed partition location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+              |CREATE TABLE t(a int, b int, c int, d int)\n+              |USING parquet\n+              |PARTITIONED BY(a, b)\n+              |LOCATION \"file:${dir.getCanonicalPath}\"\n+           \"\"\".stripMargin)\n+        val table = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))"
  }],
  "prId": 16672
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "what if the path doesn't exist when create? will we succeed or fail?",
    "commit": "0d947a55a80ecc63eb15092c29b2c44aeeb197e5",
    "createdAt": "2017-02-15T21:32:05Z",
    "diffHunk": "@@ -1816,4 +1816,123 @@ class DDLSuite extends QueryTest with SharedSQLContext with BeforeAndAfterEach {\n       }\n     }\n   }\n+\n+  test(\"insert data to a data source table which has a not existed location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+             |CREATE TABLE t(a string, b int)\n+             |USING parquet\n+             |OPTIONS(path \"$dir\")",
    "line": 12
  }, {
    "author": {
      "login": "windpiger"
    },
    "body": "currently, it will throw an exception that the path does not existed. maybe we can check if the path is a dir or not, dir can not exist and file must be exist?",
    "commit": "0d947a55a80ecc63eb15092c29b2c44aeeb197e5",
    "createdAt": "2017-02-16T15:13:50Z",
    "diffHunk": "@@ -1816,4 +1816,123 @@ class DDLSuite extends QueryTest with SharedSQLContext with BeforeAndAfterEach {\n       }\n     }\n   }\n+\n+  test(\"insert data to a data source table which has a not existed location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+             |CREATE TABLE t(a string, b int)\n+             |USING parquet\n+             |OPTIONS(path \"$dir\")",
    "line": 12
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "what's the behavior of hive?",
    "commit": "0d947a55a80ecc63eb15092c29b2c44aeeb197e5",
    "createdAt": "2017-02-16T18:23:35Z",
    "diffHunk": "@@ -1816,4 +1816,123 @@ class DDLSuite extends QueryTest with SharedSQLContext with BeforeAndAfterEach {\n       }\n     }\n   }\n+\n+  test(\"insert data to a data source table which has a not existed location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+             |CREATE TABLE t(a string, b int)\n+             |USING parquet\n+             |OPTIONS(path \"$dir\")",
    "line": 12
  }],
  "prId": 16672
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "nit: `new File(dir, \"x\")`",
    "commit": "0d947a55a80ecc63eb15092c29b2c44aeeb197e5",
    "createdAt": "2017-02-15T21:34:05Z",
    "diffHunk": "@@ -1816,4 +1816,123 @@ class DDLSuite extends QueryTest with SharedSQLContext with BeforeAndAfterEach {\n       }\n     }\n   }\n+\n+  test(\"insert data to a data source table which has a not existed location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+             |CREATE TABLE t(a string, b int)\n+             |USING parquet\n+             |OPTIONS(path \"$dir\")\n+           \"\"\".stripMargin)\n+        val table = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        val expectedPath = dir.getAbsolutePath.stripSuffix(\"/\")\n+        assert(table.location.stripSuffix(\"/\") == expectedPath)\n+\n+        dir.delete\n+        val tableLocFile = new File(table.location.stripPrefix(\"file:\"))\n+        assert(!tableLocFile.exists)\n+        spark.sql(\"INSERT INTO TABLE t SELECT 'c', 1\")\n+        assert(tableLocFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+\n+        Utils.deleteRecursively(dir)\n+        assert(!tableLocFile.exists)\n+        spark.sql(\"INSERT OVERWRITE TABLE t SELECT 'c', 1\")\n+        assert(tableLocFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+\n+        val newDir = dir.getAbsolutePath.stripSuffix(\"/\") + \"/x\"",
    "line": 31
  }, {
    "author": {
      "login": "windpiger"
    },
    "body": "ok, I will fix this when I do another pr, thanks~",
    "commit": "0d947a55a80ecc63eb15092c29b2c44aeeb197e5",
    "createdAt": "2017-02-16T15:14:38Z",
    "diffHunk": "@@ -1816,4 +1816,123 @@ class DDLSuite extends QueryTest with SharedSQLContext with BeforeAndAfterEach {\n       }\n     }\n   }\n+\n+  test(\"insert data to a data source table which has a not existed location should succeed\") {\n+    withTable(\"t\") {\n+      withTempDir { dir =>\n+        spark.sql(\n+          s\"\"\"\n+             |CREATE TABLE t(a string, b int)\n+             |USING parquet\n+             |OPTIONS(path \"$dir\")\n+           \"\"\".stripMargin)\n+        val table = spark.sessionState.catalog.getTableMetadata(TableIdentifier(\"t\"))\n+        val expectedPath = dir.getAbsolutePath.stripSuffix(\"/\")\n+        assert(table.location.stripSuffix(\"/\") == expectedPath)\n+\n+        dir.delete\n+        val tableLocFile = new File(table.location.stripPrefix(\"file:\"))\n+        assert(!tableLocFile.exists)\n+        spark.sql(\"INSERT INTO TABLE t SELECT 'c', 1\")\n+        assert(tableLocFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+\n+        Utils.deleteRecursively(dir)\n+        assert(!tableLocFile.exists)\n+        spark.sql(\"INSERT OVERWRITE TABLE t SELECT 'c', 1\")\n+        assert(tableLocFile.exists)\n+        checkAnswer(spark.table(\"t\"), Row(\"c\", 1) :: Nil)\n+\n+        val newDir = dir.getAbsolutePath.stripSuffix(\"/\") + \"/x\"",
    "line": 31
  }],
  "prId": 16672
}]