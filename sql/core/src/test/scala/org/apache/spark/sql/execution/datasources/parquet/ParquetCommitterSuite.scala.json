[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "maybe `super.afterAll()`?",
    "commit": "f486263605e2635275f1336e1673378b9b849ecb",
    "createdAt": "2017-10-11T01:42:30Z",
    "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet\n+\n+import java.io.FileNotFoundException\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path}\n+import org.apache.hadoop.mapreduce.{JobContext, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n+import org.apache.parquet.hadoop.{ParquetOutputCommitter, ParquetOutputFormat}\n+\n+import org.apache.spark.{LocalSparkContext, SparkFunSuite}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SQLTestUtils\n+\n+/**\n+ * Test logic related to choice of output commtters\n+ */\n+class ParquetCommitterSuite extends SparkFunSuite with SQLTestUtils\n+  with LocalSparkContext {\n+\n+  private val PARQUET_COMMITTER = classOf[ParquetOutputCommitter].getCanonicalName\n+\n+  protected var spark: SparkSession = _\n+\n+  /**\n+   * Create a new [[SparkSession]] running in local-cluster mode with unsafe and codegen enabled.\n+   */\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    spark = SparkSession.builder()\n+      .master(\"local-cluster[2,1,1024]\")\n+      .appName(\"testing\")\n+      .getOrCreate()\n+  }\n+\n+  override def afterAll(): Unit = {\n+    spark.stop()\n+    spark = null"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "done, + will add a check for spark==null so if a failure happens during setup, the exception doesn't get lost in teardown",
    "commit": "f486263605e2635275f1336e1673378b9b849ecb",
    "createdAt": "2017-10-11T16:31:02Z",
    "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet\n+\n+import java.io.FileNotFoundException\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path}\n+import org.apache.hadoop.mapreduce.{JobContext, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n+import org.apache.parquet.hadoop.{ParquetOutputCommitter, ParquetOutputFormat}\n+\n+import org.apache.spark.{LocalSparkContext, SparkFunSuite}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SQLTestUtils\n+\n+/**\n+ * Test logic related to choice of output commtters\n+ */\n+class ParquetCommitterSuite extends SparkFunSuite with SQLTestUtils\n+  with LocalSparkContext {\n+\n+  private val PARQUET_COMMITTER = classOf[ParquetOutputCommitter].getCanonicalName\n+\n+  protected var spark: SparkSession = _\n+\n+  /**\n+   * Create a new [[SparkSession]] running in local-cluster mode with unsafe and codegen enabled.\n+   */\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    spark = SparkSession.builder()\n+      .master(\"local-cluster[2,1,1024]\")\n+      .appName(\"testing\")\n+      .getOrCreate()\n+  }\n+\n+  override def afterAll(): Unit = {\n+    spark.stop()\n+    spark = null"
  }],
  "prId": 19448
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I think It might be a little bit better to use named arguments for readability: `writeDataFrame(MarkingFileOutput.COMMITTER, summary = false, check  = true)`",
    "commit": "f486263605e2635275f1336e1673378b9b849ecb",
    "createdAt": "2017-10-11T01:43:36Z",
    "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet\n+\n+import java.io.FileNotFoundException\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path}\n+import org.apache.hadoop.mapreduce.{JobContext, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n+import org.apache.parquet.hadoop.{ParquetOutputCommitter, ParquetOutputFormat}\n+\n+import org.apache.spark.{LocalSparkContext, SparkFunSuite}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SQLTestUtils\n+\n+/**\n+ * Test logic related to choice of output commtters\n+ */\n+class ParquetCommitterSuite extends SparkFunSuite with SQLTestUtils\n+  with LocalSparkContext {\n+\n+  private val PARQUET_COMMITTER = classOf[ParquetOutputCommitter].getCanonicalName\n+\n+  protected var spark: SparkSession = _\n+\n+  /**\n+   * Create a new [[SparkSession]] running in local-cluster mode with unsafe and codegen enabled.\n+   */\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    spark = SparkSession.builder()\n+      .master(\"local-cluster[2,1,1024]\")\n+      .appName(\"testing\")\n+      .getOrCreate()\n+  }\n+\n+  override def afterAll(): Unit = {\n+    spark.stop()\n+    spark = null\n+  }\n+\n+  test(\"alternative output committer, merge schema\") {\n+    intercept[RuntimeException] {\n+      val stat = writeDataFrame(MarkingFileOutput.COMMITTER, true, true)\n+      logError(s\"Created marker file $stat\")\n+    }\n+  }\n+\n+  test(\"alternative output committer, no merge schema\") {\n+    writeDataFrame(MarkingFileOutput.COMMITTER, false, true)"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "OK",
    "commit": "f486263605e2635275f1336e1673378b9b849ecb",
    "createdAt": "2017-10-11T12:20:33Z",
    "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet\n+\n+import java.io.FileNotFoundException\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path}\n+import org.apache.hadoop.mapreduce.{JobContext, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n+import org.apache.parquet.hadoop.{ParquetOutputCommitter, ParquetOutputFormat}\n+\n+import org.apache.spark.{LocalSparkContext, SparkFunSuite}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SQLTestUtils\n+\n+/**\n+ * Test logic related to choice of output commtters\n+ */\n+class ParquetCommitterSuite extends SparkFunSuite with SQLTestUtils\n+  with LocalSparkContext {\n+\n+  private val PARQUET_COMMITTER = classOf[ParquetOutputCommitter].getCanonicalName\n+\n+  protected var spark: SparkSession = _\n+\n+  /**\n+   * Create a new [[SparkSession]] running in local-cluster mode with unsafe and codegen enabled.\n+   */\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    spark = SparkSession.builder()\n+      .master(\"local-cluster[2,1,1024]\")\n+      .appName(\"testing\")\n+      .getOrCreate()\n+  }\n+\n+  override def afterAll(): Unit = {\n+    spark.stop()\n+    spark = null\n+  }\n+\n+  test(\"alternative output committer, merge schema\") {\n+    intercept[RuntimeException] {\n+      val stat = writeDataFrame(MarkingFileOutput.COMMITTER, true, true)\n+      logError(s\"Created marker file $stat\")\n+    }\n+  }\n+\n+  test(\"alternative output committer, no merge schema\") {\n+    writeDataFrame(MarkingFileOutput.COMMITTER, false, true)"
  }],
  "prId": 19448
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "\r\n\r\n```Scala\r\n    try {\r\n      ...\r\n    } finally {\r\n      super.afterAll()\r\n    }\r\n```",
    "commit": "f486263605e2635275f1336e1673378b9b849ecb",
    "createdAt": "2017-10-11T17:52:36Z",
    "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet\n+\n+import java.io.FileNotFoundException\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path}\n+import org.apache.hadoop.mapreduce.{JobContext, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n+import org.apache.parquet.hadoop.{ParquetOutputCommitter, ParquetOutputFormat}\n+\n+import org.apache.spark.{LocalSparkContext, SparkFunSuite}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SQLTestUtils\n+\n+/**\n+ * Test logic related to choice of output commtters\n+ */\n+class ParquetCommitterSuite extends SparkFunSuite with SQLTestUtils\n+  with LocalSparkContext {\n+\n+  private val PARQUET_COMMITTER = classOf[ParquetOutputCommitter].getCanonicalName\n+\n+  protected var spark: SparkSession = _\n+\n+  /**\n+   * Create a new [[SparkSession]] running in local-cluster mode with unsafe and codegen enabled.\n+   */\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    spark = SparkSession.builder()\n+      .master(\"local-cluster[2,1,1024]\")\n+      .appName(\"testing\")\n+      .getOrCreate()\n+  }\n+\n+  override def afterAll(): Unit = {\n+    if (spark != null) {\n+      spark.stop()\n+      spark = null\n+    }\n+    super.afterAll()"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "good point",
    "commit": "f486263605e2635275f1336e1673378b9b849ecb",
    "createdAt": "2017-10-12T09:35:24Z",
    "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet\n+\n+import java.io.FileNotFoundException\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path}\n+import org.apache.hadoop.mapreduce.{JobContext, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n+import org.apache.parquet.hadoop.{ParquetOutputCommitter, ParquetOutputFormat}\n+\n+import org.apache.spark.{LocalSparkContext, SparkFunSuite}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SQLTestUtils\n+\n+/**\n+ * Test logic related to choice of output commtters\n+ */\n+class ParquetCommitterSuite extends SparkFunSuite with SQLTestUtils\n+  with LocalSparkContext {\n+\n+  private val PARQUET_COMMITTER = classOf[ParquetOutputCommitter].getCanonicalName\n+\n+  protected var spark: SparkSession = _\n+\n+  /**\n+   * Create a new [[SparkSession]] running in local-cluster mode with unsafe and codegen enabled.\n+   */\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    spark = SparkSession.builder()\n+      .master(\"local-cluster[2,1,1024]\")\n+      .appName(\"testing\")\n+      .getOrCreate()\n+  }\n+\n+  override def afterAll(): Unit = {\n+    if (spark != null) {\n+      spark.stop()\n+      spark = null\n+    }\n+    super.afterAll()"
  }],
  "prId": 19448
}, {
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "nit: `commtters` -> `committers`",
    "commit": "f486263605e2635275f1336e1673378b9b849ecb",
    "createdAt": "2017-10-12T13:32:06Z",
    "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet\n+\n+import java.io.FileNotFoundException\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, Path}\n+import org.apache.hadoop.mapreduce.{JobContext, TaskAttemptContext}\n+import org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n+import org.apache.parquet.hadoop.{ParquetOutputCommitter, ParquetOutputFormat}\n+\n+import org.apache.spark.{LocalSparkContext, SparkFunSuite}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SQLTestUtils\n+\n+/**\n+ * Test logic related to choice of output commtters"
  }],
  "prId": 19448
}]