[{
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "Please update `without sbt` usage to:\r\n```\r\nbin/spark-submit --class <this class> --jars <spark core test jar>,<spark catalyst test jar> <spark sql test jar>\r\n```",
    "commit": "490a60c9ae77459b32e5c32a2200372af5168f4b",
    "createdAt": "2018-10-29T08:22:57Z",
    "diffHunk": "@@ -16,30 +16,30 @@\n  */\n package org.apache.spark.sql.execution.datasources.csv\n \n-import org.apache.spark.SparkConf\n import org.apache.spark.benchmark.Benchmark\n-import org.apache.spark.sql.{Column, Row, SparkSession}\n-import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.{Column, Row}\n+import org.apache.spark.sql.execution.benchmark.SqlBasedBenchmark\n import org.apache.spark.sql.functions.lit\n import org.apache.spark.sql.types._\n \n /**\n  * Benchmark to measure CSV read/write performance.\n- * To run this:\n- *  spark-submit --class <this class> --jars <spark sql test jar>\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt:\n+ *      bin/spark-submit --class <this class> --jars <spark core test jar> <spark sql test jar>"
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "Also update the usage in description:\r\n```console\r\nbin/spark-submit --class org.apache.spark.sql.execution.datasources.csv.CSVBenchmarks --jars ./core/target/spark-core_2.11-3.0.0-SNAPSHOT-tests.jar,./sql/catalyst/target/spark-catalyst_2.11-3.0.0-SNAPSHOT-tests.jar ./sql/core/target/spark-sql_2.11-3.0.0-SNAPSHOT-tests.jar\r\n```",
    "commit": "490a60c9ae77459b32e5c32a2200372af5168f4b",
    "createdAt": "2018-10-29T08:25:52Z",
    "diffHunk": "@@ -16,30 +16,30 @@\n  */\n package org.apache.spark.sql.execution.datasources.csv\n \n-import org.apache.spark.SparkConf\n import org.apache.spark.benchmark.Benchmark\n-import org.apache.spark.sql.{Column, Row, SparkSession}\n-import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.{Column, Row}\n+import org.apache.spark.sql.execution.benchmark.SqlBasedBenchmark\n import org.apache.spark.sql.functions.lit\n import org.apache.spark.sql.types._\n \n /**\n  * Benchmark to measure CSV read/write performance.\n- * To run this:\n- *  spark-submit --class <this class> --jars <spark sql test jar>\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt:\n+ *      bin/spark-submit --class <this class> --jars <spark core test jar> <spark sql test jar>"
  }],
  "prId": 22845
}, {
  "comments": [{
    "author": {
      "login": "yucai"
    },
    "body": "#22872 has updated `runBenchmarkSuite`'s signature.\r\n```suggestion\r\n  override def runBenchmarkSuite(mainArgs: Array[String]): Unit = {\r\n```",
    "commit": "490a60c9ae77459b32e5c32a2200372af5168f4b",
    "createdAt": "2018-10-29T16:53:40Z",
    "diffHunk": "@@ -137,22 +124,15 @@ object CSVBenchmarks extends SQLHelper {\n         ds.count()\n       }\n \n-      /*\n-      Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz\n-\n-      Count a dataset with 10 columns:      Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n-      ---------------------------------------------------------------------------------------------\n-      Select 10 columns + count()              12598 / 12740          0.8        1259.8       1.0X\n-      Select 1 column + count()                  7960 / 8175          1.3         796.0       1.6X\n-      count()                                    2332 / 2386          4.3         233.2       5.4X\n-      */\n       benchmark.run()\n     }\n   }\n \n-  def main(args: Array[String]): Unit = {\n-    quotedValuesBenchmark(rowsNum = 50 * 1000, numIters = 3)\n-    multiColumnsBenchmark(rowsNum = 1000 * 1000)\n-    countBenchmark(10 * 1000 * 1000)\n+  override def runBenchmarkSuite(): Unit = {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "+1 for @yucai 's comment.",
    "commit": "490a60c9ae77459b32e5c32a2200372af5168f4b",
    "createdAt": "2018-10-29T17:16:04Z",
    "diffHunk": "@@ -137,22 +124,15 @@ object CSVBenchmarks extends SQLHelper {\n         ds.count()\n       }\n \n-      /*\n-      Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz\n-\n-      Count a dataset with 10 columns:      Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n-      ---------------------------------------------------------------------------------------------\n-      Select 10 columns + count()              12598 / 12740          0.8        1259.8       1.0X\n-      Select 1 column + count()                  7960 / 8175          1.3         796.0       1.6X\n-      count()                                    2332 / 2386          4.3         233.2       5.4X\n-      */\n       benchmark.run()\n     }\n   }\n \n-  def main(args: Array[String]): Unit = {\n-    quotedValuesBenchmark(rowsNum = 50 * 1000, numIters = 3)\n-    multiColumnsBenchmark(rowsNum = 1000 * 1000)\n-    countBenchmark(10 * 1000 * 1000)\n+  override def runBenchmarkSuite(): Unit = {"
  }],
  "prId": 22845
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "@heary-cao . Could you rename the files?\r\n- `CSVBenchmarks.scala` -> `CSVBenchmark.scala`\r\n- `CSVBenchmarks-results.txt` -> `CSVBenchmark-results.txt`\r\n- [Line 35](https://github.com/apache/spark/pull/22845/files#diff-985fa5181f2aec4df39324995590ea83R35) should be changed together from `benchmarks/CSVBenchmarks-results.txt` to `benchmarks/CSVBenchmark-results.txt`.",
    "commit": "490a60c9ae77459b32e5c32a2200372af5168f4b",
    "createdAt": "2018-10-30T08:46:42Z",
    "diffHunk": "@@ -16,30 +16,31 @@\n  */\n package org.apache.spark.sql.execution.datasources.csv\n \n-import org.apache.spark.SparkConf\n import org.apache.spark.benchmark.Benchmark\n-import org.apache.spark.sql.{Column, Row, SparkSession}\n-import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.{Column, Row}\n+import org.apache.spark.sql.execution.benchmark.SqlBasedBenchmark\n import org.apache.spark.sql.functions.lit\n import org.apache.spark.sql.types._\n \n /**\n  * Benchmark to measure CSV read/write performance.\n- * To run this:\n- *  spark-submit --class <this class> --jars <spark sql test jar>\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt:\n+ *      bin/spark-submit --class <this class> --jars <spark core test jar>,\n+ *       <spark catalyst test jar> <spark sql test jar>\n+ *   2. build/sbt \"sql/test:runMain <this class>\"\n+ *   3. generate result:\n+ *      SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/CSVBenchmarks-results.txt\".\n+ * }}}\n  */\n-object CSVBenchmarks extends SQLHelper {\n-  val conf = new SparkConf()\n-\n-  val spark = SparkSession.builder\n-    .master(\"local[1]\")\n-    .appName(\"benchmark-csv-datasource\")\n-    .config(conf)\n-    .getOrCreate()\n+\n+object CSVBenchmarks extends SqlBasedBenchmark {"
  }],
  "prId": 22845
}]