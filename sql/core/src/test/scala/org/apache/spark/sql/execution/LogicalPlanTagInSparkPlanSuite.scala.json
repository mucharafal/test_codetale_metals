[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Add ReusedSubqueryExec?",
    "commit": "b380f1dc39f0e4c7701b1a46603b0b62d1f94f96",
    "createdAt": "2019-05-16T17:47:08Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark.sql.TPCDSQuerySuite\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, Complete, Final}\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical.{Aggregate, Generate, Join, LocalRelation, LogicalPlan, Range, Sample, Union, Window}\n+import org.apache.spark.sql.execution.aggregate.{HashAggregateExec, ObjectHashAggregateExec, SortAggregateExec}\n+import org.apache.spark.sql.execution.columnar.{InMemoryRelation, InMemoryTableScanExec}\n+import org.apache.spark.sql.execution.datasources.LogicalRelation\n+import org.apache.spark.sql.execution.datasources.v2.{BatchScanExec, DataSourceV2Relation}\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, ReusedExchangeExec, ShuffleExchangeExec}\n+import org.apache.spark.sql.execution.joins._\n+import org.apache.spark.sql.execution.window.WindowExec\n+\n+class LogicalPlanTagInSparkPlanSuite extends TPCDSQuerySuite {\n+\n+  override protected def checkGeneratedCode(plan: SparkPlan): Unit = {\n+    super.checkGeneratedCode(plan)\n+    checkLogicalPlanTag(plan)\n+  }\n+\n+  private def isFinalAgg(aggExprs: Seq[AggregateExpression]): Boolean = {\n+    // TODO: aggregate node without aggregate expressions can also be a final aggregate, but\n+    // currently the aggregate node doesn't have a final/partial flag.\n+    aggExprs.nonEmpty && aggExprs.forall(ae => ae.mode == Complete || ae.mode == Final)\n+  }\n+\n+  // A scan plan tree is a plan tree that has a leaf node under zero or more Project/Filter nodes.\n+  private def isScanPlanTree(plan: SparkPlan): Boolean = plan match {\n+    case p: ProjectExec => isScanPlanTree(p.child)\n+    case f: FilterExec => isScanPlanTree(f.child)\n+    case _: LeafExecNode => true\n+    case _ => false\n+  }\n+\n+  private def checkLogicalPlanTag(plan: SparkPlan): Unit = {\n+    plan match {\n+      case _: HashJoin | _: BroadcastNestedLoopJoinExec | _: CartesianProductExec\n+           | _: ShuffledHashJoinExec | _: SortMergeJoinExec =>\n+        assertLogicalPlanType[Join](plan)\n+\n+      // There is no corresponding logical plan for the physical partial aggregate.\n+      case agg: HashAggregateExec if isFinalAgg(agg.aggregateExpressions) =>\n+        assertLogicalPlanType[Aggregate](plan)\n+      case agg: ObjectHashAggregateExec if isFinalAgg(agg.aggregateExpressions) =>\n+        assertLogicalPlanType[Aggregate](plan)\n+      case agg: SortAggregateExec if isFinalAgg(agg.aggregateExpressions) =>\n+        assertLogicalPlanType[Aggregate](plan)\n+\n+      case _: WindowExec =>\n+        assertLogicalPlanType[Window](plan)\n+\n+      case _: UnionExec =>\n+        assertLogicalPlanType[Union](plan)\n+\n+      case _: SampleExec =>\n+        assertLogicalPlanType[Sample](plan)\n+\n+      case _: GenerateExec =>\n+        assertLogicalPlanType[Generate](plan)\n+\n+      // The exchange related nodes are created after the planning, they don't have corresponding\n+      // logical plan.\n+      case _: ShuffleExchangeExec | _: BroadcastExchangeExec | _: ReusedExchangeExec =>",
    "line": 83
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "added below",
    "commit": "b380f1dc39f0e4c7701b1a46603b0b62d1f94f96",
    "createdAt": "2019-05-17T11:46:44Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark.sql.TPCDSQuerySuite\n+import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, Complete, Final}\n+import org.apache.spark.sql.catalyst.plans.QueryPlan\n+import org.apache.spark.sql.catalyst.plans.logical.{Aggregate, Generate, Join, LocalRelation, LogicalPlan, Range, Sample, Union, Window}\n+import org.apache.spark.sql.execution.aggregate.{HashAggregateExec, ObjectHashAggregateExec, SortAggregateExec}\n+import org.apache.spark.sql.execution.columnar.{InMemoryRelation, InMemoryTableScanExec}\n+import org.apache.spark.sql.execution.datasources.LogicalRelation\n+import org.apache.spark.sql.execution.datasources.v2.{BatchScanExec, DataSourceV2Relation}\n+import org.apache.spark.sql.execution.exchange.{BroadcastExchangeExec, ReusedExchangeExec, ShuffleExchangeExec}\n+import org.apache.spark.sql.execution.joins._\n+import org.apache.spark.sql.execution.window.WindowExec\n+\n+class LogicalPlanTagInSparkPlanSuite extends TPCDSQuerySuite {\n+\n+  override protected def checkGeneratedCode(plan: SparkPlan): Unit = {\n+    super.checkGeneratedCode(plan)\n+    checkLogicalPlanTag(plan)\n+  }\n+\n+  private def isFinalAgg(aggExprs: Seq[AggregateExpression]): Boolean = {\n+    // TODO: aggregate node without aggregate expressions can also be a final aggregate, but\n+    // currently the aggregate node doesn't have a final/partial flag.\n+    aggExprs.nonEmpty && aggExprs.forall(ae => ae.mode == Complete || ae.mode == Final)\n+  }\n+\n+  // A scan plan tree is a plan tree that has a leaf node under zero or more Project/Filter nodes.\n+  private def isScanPlanTree(plan: SparkPlan): Boolean = plan match {\n+    case p: ProjectExec => isScanPlanTree(p.child)\n+    case f: FilterExec => isScanPlanTree(f.child)\n+    case _: LeafExecNode => true\n+    case _ => false\n+  }\n+\n+  private def checkLogicalPlanTag(plan: SparkPlan): Unit = {\n+    plan match {\n+      case _: HashJoin | _: BroadcastNestedLoopJoinExec | _: CartesianProductExec\n+           | _: ShuffledHashJoinExec | _: SortMergeJoinExec =>\n+        assertLogicalPlanType[Join](plan)\n+\n+      // There is no corresponding logical plan for the physical partial aggregate.\n+      case agg: HashAggregateExec if isFinalAgg(agg.aggregateExpressions) =>\n+        assertLogicalPlanType[Aggregate](plan)\n+      case agg: ObjectHashAggregateExec if isFinalAgg(agg.aggregateExpressions) =>\n+        assertLogicalPlanType[Aggregate](plan)\n+      case agg: SortAggregateExec if isFinalAgg(agg.aggregateExpressions) =>\n+        assertLogicalPlanType[Aggregate](plan)\n+\n+      case _: WindowExec =>\n+        assertLogicalPlanType[Window](plan)\n+\n+      case _: UnionExec =>\n+        assertLogicalPlanType[Union](plan)\n+\n+      case _: SampleExec =>\n+        assertLogicalPlanType[Sample](plan)\n+\n+      case _: GenerateExec =>\n+        assertLogicalPlanType[Generate](plan)\n+\n+      // The exchange related nodes are created after the planning, they don't have corresponding\n+      // logical plan.\n+      case _: ShuffleExchangeExec | _: BroadcastExchangeExec | _: ReusedExchangeExec =>",
    "line": 83
  }],
  "prId": 24626
}]