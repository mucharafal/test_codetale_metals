[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Typo: indeed\n",
    "commit": "c02fc3f4179df860ebb8c24614247c016c3603e6",
    "createdAt": "2015-08-03T04:23:07Z",
    "diffHunk": "@@ -0,0 +1,236 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.optimizer\n+\n+import org.apache.spark.sql.catalyst.analysis.EliminateSubQueries\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions.{Not, AtLeastNNulls}\n+import org.apache.spark.sql.catalyst.optimizer._\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{Filter, LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.test.TestSQLContext\n+\n+/** This is the test suite for FilterNullsInJoinKey optimization rule. */\n+class FilterNullsInJoinKeySuite extends PlanTest {\n+\n+  // We add predicate pushdown rules at here to make sure we do not\n+  // create redundant Filter operators. Also, because the attribute ordering of\n+  // the Project operator added by ColumnPruning may be not deterministic\n+  // (the ordering may depend on the testing environment),\n+  // we first construct the plan with expected Filter operators and then\n+  // run the optimizer to add the the Project for column pruning.\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Subqueries\", Once,\n+        EliminateSubQueries) ::\n+      Batch(\"Operator Optimizations\", FixedPoint(100),\n+        FilterNullsInJoinKey(TestSQLContext), // This is the rule we test in this suite.\n+        CombineFilters,\n+        PushPredicateThroughProject,\n+        BooleanSimplification,\n+        PushPredicateThroughJoin,\n+        PushPredicateThroughGenerate,\n+        ColumnPruning,\n+        ProjectCollapsing) :: Nil\n+  }\n+\n+  val leftRelation = LocalRelation('a.int, 'b.int, 'c.int, 'd.int)\n+\n+  val rightRelation = LocalRelation('e.int, 'f.int, 'g.int, 'h.int)\n+\n+  test(\"inner join\") {\n+    val joinCondition =\n+      ('a === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)\n+\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, Inner, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+    // For an inner join, FilterNullsInJoinKey add filter to both side.\n+    val correctLeft =\n+      leftRelation\n+        .where(!(AtLeastNNulls(1, 'a.expr :: Nil)))\n+\n+    val correctRight =\n+      rightRelation.where(!(AtLeastNNulls(1, 'e.expr :: 'f.expr :: Nil)))\n+\n+    val correctAnswer =\n+      correctLeft\n+        .join(correctRight, Inner, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    comparePlans(optimized, Optimize.execute(correctAnswer.analyze))\n+  }\n+\n+  test(\"make sure we do not keep adding filters\") {\n+    val thirdRelation = LocalRelation('i.int, 'j.int, 'k.int, 'l.int)\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, Inner, Some('a === 'e))\n+        .join(thirdRelation, Inner, Some('b === 'i && 'a === 'j))\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+    val conditions = optimized.collect {\n+      case Filter(condition @ Not(AtLeastNNulls(1, exprs)), _) => exprs\n+    }\n+\n+    // Make sure that we have three Not(AtLeastNNulls(1, exprs)) for those three tables.\n+    assert(conditions.length === 3)\n+\n+    // Make sure attribtues are indded a, b, e, i, and j."
  }],
  "prId": 7768
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Technically I suppose that we could also add a filter if `b` is null, since `null + 1 == null`, leading to an empty join result for those rows?  We can figure this out for a simple case like this, but I guess the logic is too complicated to apply to arbitrary expressions.\n",
    "commit": "c02fc3f4179df860ebb8c24614247c016c3603e6",
    "createdAt": "2015-08-03T04:28:13Z",
    "diffHunk": "@@ -0,0 +1,236 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.optimizer\n+\n+import org.apache.spark.sql.catalyst.analysis.EliminateSubQueries\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions.{Not, AtLeastNNulls}\n+import org.apache.spark.sql.catalyst.optimizer._\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{Filter, LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.test.TestSQLContext\n+\n+/** This is the test suite for FilterNullsInJoinKey optimization rule. */\n+class FilterNullsInJoinKeySuite extends PlanTest {\n+\n+  // We add predicate pushdown rules at here to make sure we do not\n+  // create redundant Filter operators. Also, because the attribute ordering of\n+  // the Project operator added by ColumnPruning may be not deterministic\n+  // (the ordering may depend on the testing environment),\n+  // we first construct the plan with expected Filter operators and then\n+  // run the optimizer to add the the Project for column pruning.\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Subqueries\", Once,\n+        EliminateSubQueries) ::\n+      Batch(\"Operator Optimizations\", FixedPoint(100),\n+        FilterNullsInJoinKey(TestSQLContext), // This is the rule we test in this suite.\n+        CombineFilters,\n+        PushPredicateThroughProject,\n+        BooleanSimplification,\n+        PushPredicateThroughJoin,\n+        PushPredicateThroughGenerate,\n+        ColumnPruning,\n+        ProjectCollapsing) :: Nil\n+  }\n+\n+  val leftRelation = LocalRelation('a.int, 'b.int, 'c.int, 'd.int)\n+\n+  val rightRelation = LocalRelation('e.int, 'f.int, 'g.int, 'h.int)\n+\n+  test(\"inner join\") {\n+    val joinCondition =\n+      ('a === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)\n+\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, Inner, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+    // For an inner join, FilterNullsInJoinKey add filter to both side.\n+    val correctLeft =\n+      leftRelation\n+        .where(!(AtLeastNNulls(1, 'a.expr :: Nil)))\n+\n+    val correctRight =\n+      rightRelation.where(!(AtLeastNNulls(1, 'e.expr :: 'f.expr :: Nil)))\n+\n+    val correctAnswer =\n+      correctLeft\n+        .join(correctRight, Inner, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    comparePlans(optimized, Optimize.execute(correctAnswer.analyze))\n+  }\n+\n+  test(\"make sure we do not keep adding filters\") {\n+    val thirdRelation = LocalRelation('i.int, 'j.int, 'k.int, 'l.int)\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, Inner, Some('a === 'e))\n+        .join(thirdRelation, Inner, Some('b === 'i && 'a === 'j))\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+    val conditions = optimized.collect {\n+      case Filter(condition @ Not(AtLeastNNulls(1, exprs)), _) => exprs\n+    }\n+\n+    // Make sure that we have three Not(AtLeastNNulls(1, exprs)) for those three tables.\n+    assert(conditions.length === 3)\n+\n+    // Make sure attribtues are indded a, b, e, i, and j.\n+    assert(\n+      conditions.flatMap(exprs => exprs).toSet ===\n+        joinedPlan.select('a, 'b, 'e, 'i, 'j).analyze.output.toSet)\n+  }\n+\n+  test(\"inner join (partially optimized)\") {\n+    val joinCondition =\n+      ('a + 2 === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)\n+\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, Inner, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+    // We cannot extract attribute from the left join key.\n+    val correctRight =\n+      rightRelation.where(!(AtLeastNNulls(1, 'e.expr :: 'f.expr :: Nil)))\n+\n+    val correctAnswer =\n+      leftRelation\n+        .join(correctRight, Inner, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    comparePlans(optimized, Optimize.execute(correctAnswer.analyze))\n+  }\n+\n+  test(\"inner join (not optimized)\") {\n+    val nonOptimizedJoinConditions =\n+      Some('c - 100 + 'd === 'g + 1 - 'h) ::\n+        Some('d > 'h || 'c === 'g) ::\n+        Some('d + 'g + 'c > 'd - 'h) :: Nil\n+\n+    nonOptimizedJoinConditions.foreach { joinCondition =>\n+      val joinedPlan =\n+        leftRelation\n+          .join(rightRelation.select('f, 'g, 'h), Inner, joinCondition)\n+          .select('a, 'c, 'f, 'd, 'h, 'g)\n+\n+      val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+      comparePlans(optimized, Optimize.execute(joinedPlan.analyze))\n+    }\n+  }\n+\n+  test(\"left outer join\") {\n+    val joinCondition =\n+      ('a === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)\n+\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, LeftOuter, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+    // For a left outer join, FilterNullsInJoinKey add filter to the right side.\n+    val correctRight =\n+      rightRelation.where(!(AtLeastNNulls(1, 'e.expr :: 'f.expr :: Nil)))\n+\n+    val correctAnswer =\n+      leftRelation\n+        .join(correctRight, LeftOuter, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    comparePlans(optimized, Optimize.execute(correctAnswer.analyze))\n+  }\n+\n+  test(\"right outer join\") {\n+    val joinCondition =\n+      ('a === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)\n+\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, RightOuter, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+    // For a right outer join, FilterNullsInJoinKey add filter to the left side.\n+    val correctLeft =\n+      leftRelation\n+        .where(!(AtLeastNNulls(1, 'a.expr :: Nil)))\n+\n+    val correctAnswer =\n+      correctLeft\n+        .join(rightRelation, RightOuter, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+\n+    comparePlans(optimized, Optimize.execute(correctAnswer.analyze))\n+  }\n+\n+  test(\"full outer join\") {\n+    val joinCondition =\n+      ('a === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)\n+\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, FullOuter, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    // FilterNullsInJoinKey does not fire for a full outer join.\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+    comparePlans(optimized, Optimize.execute(joinedPlan.analyze))\n+  }\n+\n+  test(\"left semi join\") {\n+    val joinCondition =\n+      ('a === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)",
    "line": 212
  }, {
    "author": {
      "login": "yhuai"
    },
    "body": "Yeah. We need to understand if an expression can generate null if the input is non-nullable.\n",
    "commit": "c02fc3f4179df860ebb8c24614247c016c3603e6",
    "createdAt": "2015-08-03T04:34:57Z",
    "diffHunk": "@@ -0,0 +1,236 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.optimizer\n+\n+import org.apache.spark.sql.catalyst.analysis.EliminateSubQueries\n+import org.apache.spark.sql.catalyst.dsl.plans._\n+import org.apache.spark.sql.catalyst.dsl.expressions._\n+import org.apache.spark.sql.catalyst.expressions.{Not, AtLeastNNulls}\n+import org.apache.spark.sql.catalyst.optimizer._\n+import org.apache.spark.sql.catalyst.plans._\n+import org.apache.spark.sql.catalyst.plans.logical.{Filter, LocalRelation, LogicalPlan}\n+import org.apache.spark.sql.catalyst.rules.RuleExecutor\n+import org.apache.spark.sql.test.TestSQLContext\n+\n+/** This is the test suite for FilterNullsInJoinKey optimization rule. */\n+class FilterNullsInJoinKeySuite extends PlanTest {\n+\n+  // We add predicate pushdown rules at here to make sure we do not\n+  // create redundant Filter operators. Also, because the attribute ordering of\n+  // the Project operator added by ColumnPruning may be not deterministic\n+  // (the ordering may depend on the testing environment),\n+  // we first construct the plan with expected Filter operators and then\n+  // run the optimizer to add the the Project for column pruning.\n+  object Optimize extends RuleExecutor[LogicalPlan] {\n+    val batches =\n+      Batch(\"Subqueries\", Once,\n+        EliminateSubQueries) ::\n+      Batch(\"Operator Optimizations\", FixedPoint(100),\n+        FilterNullsInJoinKey(TestSQLContext), // This is the rule we test in this suite.\n+        CombineFilters,\n+        PushPredicateThroughProject,\n+        BooleanSimplification,\n+        PushPredicateThroughJoin,\n+        PushPredicateThroughGenerate,\n+        ColumnPruning,\n+        ProjectCollapsing) :: Nil\n+  }\n+\n+  val leftRelation = LocalRelation('a.int, 'b.int, 'c.int, 'd.int)\n+\n+  val rightRelation = LocalRelation('e.int, 'f.int, 'g.int, 'h.int)\n+\n+  test(\"inner join\") {\n+    val joinCondition =\n+      ('a === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)\n+\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, Inner, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+    // For an inner join, FilterNullsInJoinKey add filter to both side.\n+    val correctLeft =\n+      leftRelation\n+        .where(!(AtLeastNNulls(1, 'a.expr :: Nil)))\n+\n+    val correctRight =\n+      rightRelation.where(!(AtLeastNNulls(1, 'e.expr :: 'f.expr :: Nil)))\n+\n+    val correctAnswer =\n+      correctLeft\n+        .join(correctRight, Inner, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    comparePlans(optimized, Optimize.execute(correctAnswer.analyze))\n+  }\n+\n+  test(\"make sure we do not keep adding filters\") {\n+    val thirdRelation = LocalRelation('i.int, 'j.int, 'k.int, 'l.int)\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, Inner, Some('a === 'e))\n+        .join(thirdRelation, Inner, Some('b === 'i && 'a === 'j))\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+    val conditions = optimized.collect {\n+      case Filter(condition @ Not(AtLeastNNulls(1, exprs)), _) => exprs\n+    }\n+\n+    // Make sure that we have three Not(AtLeastNNulls(1, exprs)) for those three tables.\n+    assert(conditions.length === 3)\n+\n+    // Make sure attribtues are indded a, b, e, i, and j.\n+    assert(\n+      conditions.flatMap(exprs => exprs).toSet ===\n+        joinedPlan.select('a, 'b, 'e, 'i, 'j).analyze.output.toSet)\n+  }\n+\n+  test(\"inner join (partially optimized)\") {\n+    val joinCondition =\n+      ('a + 2 === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)\n+\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, Inner, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+    // We cannot extract attribute from the left join key.\n+    val correctRight =\n+      rightRelation.where(!(AtLeastNNulls(1, 'e.expr :: 'f.expr :: Nil)))\n+\n+    val correctAnswer =\n+      leftRelation\n+        .join(correctRight, Inner, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    comparePlans(optimized, Optimize.execute(correctAnswer.analyze))\n+  }\n+\n+  test(\"inner join (not optimized)\") {\n+    val nonOptimizedJoinConditions =\n+      Some('c - 100 + 'd === 'g + 1 - 'h) ::\n+        Some('d > 'h || 'c === 'g) ::\n+        Some('d + 'g + 'c > 'd - 'h) :: Nil\n+\n+    nonOptimizedJoinConditions.foreach { joinCondition =>\n+      val joinedPlan =\n+        leftRelation\n+          .join(rightRelation.select('f, 'g, 'h), Inner, joinCondition)\n+          .select('a, 'c, 'f, 'd, 'h, 'g)\n+\n+      val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+      comparePlans(optimized, Optimize.execute(joinedPlan.analyze))\n+    }\n+  }\n+\n+  test(\"left outer join\") {\n+    val joinCondition =\n+      ('a === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)\n+\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, LeftOuter, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+    // For a left outer join, FilterNullsInJoinKey add filter to the right side.\n+    val correctRight =\n+      rightRelation.where(!(AtLeastNNulls(1, 'e.expr :: 'f.expr :: Nil)))\n+\n+    val correctAnswer =\n+      leftRelation\n+        .join(correctRight, LeftOuter, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    comparePlans(optimized, Optimize.execute(correctAnswer.analyze))\n+  }\n+\n+  test(\"right outer join\") {\n+    val joinCondition =\n+      ('a === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)\n+\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, RightOuter, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+    // For a right outer join, FilterNullsInJoinKey add filter to the left side.\n+    val correctLeft =\n+      leftRelation\n+        .where(!(AtLeastNNulls(1, 'a.expr :: Nil)))\n+\n+    val correctAnswer =\n+      correctLeft\n+        .join(rightRelation, RightOuter, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+\n+    comparePlans(optimized, Optimize.execute(correctAnswer.analyze))\n+  }\n+\n+  test(\"full outer join\") {\n+    val joinCondition =\n+      ('a === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)\n+\n+    val joinedPlan =\n+      leftRelation\n+        .join(rightRelation, FullOuter, Some(joinCondition))\n+        .select('a, 'f, 'd, 'h)\n+\n+    // FilterNullsInJoinKey does not fire for a full outer join.\n+    val optimized = Optimize.execute(joinedPlan.analyze)\n+\n+    comparePlans(optimized, Optimize.execute(joinedPlan.analyze))\n+  }\n+\n+  test(\"left semi join\") {\n+    val joinCondition =\n+      ('a === 'e && 'b + 1 === 'f) && ('d > 'h || 'd === 'g)",
    "line": 212
  }],
  "prId": 7768
}]