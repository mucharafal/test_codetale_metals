[{
  "comments": [{
    "author": {
      "login": "rayortigas"
    },
    "body": "Addressing feedback, this test suite is now separate from the other DataFrame test suites.\n",
    "commit": "6d4bec2c25a6675ead005e521b632f1fefd0e239",
    "createdAt": "2015-09-28T02:17:19Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+// For SPARK-7160: toTypedRDD[T].\n+class DataFrameToRDDSuite extends QueryTest with SharedSQLContext {",
    "line": 23
  }],
  "prId": 5713
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "If there are any test cases here that aren't covered by [ExpressionEncoderSuite](https://github.com/apache/spark/blob/master/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/encoders/ExpressionEncoderSuite.scala) it would be awesome to add them.\n",
    "commit": "6d4bec2c25a6675ead005e521b632f1fefd0e239",
    "createdAt": "2015-11-03T10:37:12Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+// For SPARK-7160: toTypedRDD[T].\n+class DataFrameToRDDSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  test(\"toTypedRDD[T] works with simple case class\") {\n+    import org.scalatest.Matchers._\n+    val oldRDD = sqlContext.sparkContext.parallelize(\n+      Seq(A(\"apple\", 1), A(\"banana\", 2), A(\"cherry\", 3)))\n+    val df = oldRDD.toDF()\n+    val newRDD = df.toTypedRDD[A]()\n+    newRDD.collect() should contain theSameElementsAs oldRDD.collect()\n+  }\n+\n+  test(\"toTypedRDD[T] works with case class dependent on another case class\") {\n+    import org.scalatest.Matchers._\n+    val oldRDD = sqlContext.sparkContext.parallelize(\n+      Seq(B(A(\"apple\", 1), 1.0), B(A(\"banana\", 2), 2.0), B(A(\"cherry\", 3), 3.0)))\n+    val df = oldRDD.toDF()\n+    val newRDD = df.toTypedRDD[B]()\n+    newRDD.collect() should contain theSameElementsAs oldRDD.collect()\n+  }\n+\n+  test(\"toTypedRDD[T] works with case class having a Seq\") {\n+    import org.scalatest.Matchers._\n+    val oldRDD = sqlContext.sparkContext.parallelize(\n+      Seq(\n+        C(\"fruits\", Seq(A(\"apple\", 1), A(\"banana\", 2), A(\"cherry\", 3))),\n+        C(\"vegetables\", Seq(A(\"eggplant\", 4), A(\"spinach\", 5), A(\"zucchini\", 6)))))\n+    val df = oldRDD.toDF()\n+    val newRDD = df.toTypedRDD[C]()\n+    newRDD.collect() should contain theSameElementsAs oldRDD.collect()\n+  }\n+\n+  test(\"toTypedRDD[T] works with case class having a Map\") {\n+    import org.scalatest.Matchers._\n+    val oldRDD = sqlContext.sparkContext.parallelize(\n+      Seq(\n+        D(\"fruits\", Map(1 -> A(\"apple\", 1), 2 -> A(\"banana\", 2), 3 -> A(\"cherry\", 3))),\n+        D(\"vegetables\", Map(4 -> A(\"eggplant\", 4), 5 -> A(\"spinach\", 5), 6 -> A(\"zucchini\", 6)))))\n+    val df = oldRDD.toDF()\n+    val newRDD = df.toTypedRDD[D]()\n+    newRDD.collect() should contain theSameElementsAs oldRDD.collect()\n+  }\n+\n+  test(\"toTypedRDD[T] works with case class having an Option\") {\n+    import org.scalatest.Matchers._\n+    val oldRDD = sqlContext.sparkContext.parallelize(\n+      Seq(E(Some(A(\"apple\", 1))), E(Some(A(\"banana\", 2))), E(Some(A(\"cherry\", 3))), E(None)))\n+    val df = oldRDD.toDF()\n+    val newRDD = df.toTypedRDD[E]()\n+    newRDD.collect() should contain theSameElementsAs oldRDD.collect()\n+  }\n+\n+  test(\"toTypedRDD[T] works with case class having a (Scala) BigDecimal\") {\n+    import org.scalatest.Matchers._\n+    val oldRDD = sqlContext.sparkContext.parallelize(\n+      Seq(F(BigDecimal(1.0)), F(BigDecimal(2.0)), F(BigDecimal(3.0))))\n+    val df = oldRDD.toDF()\n+    val newRDD = df.toTypedRDD[F]()\n+    newRDD.collect() should contain theSameElementsAs oldRDD.collect()\n+  }\n+\n+  test(\"toTypedRDD[T] fails with an incompatible case class\") {\n+    intercept[IllegalArgumentException] {\n+      val oldRDD = sqlContext.sparkContext.parallelize(Seq(A(\"apple\", 1)))\n+      val df = oldRDD.toDF()\n+      val newRDD = df.toTypedRDD[B]()\n+      newRDD.collect()\n+    }\n+  }\n+\n+  test(\"toTypedRDD[T] can be used to reload an RDD saved to Parquet\") {\n+    import java.io.File\n+    import org.apache.spark.util.Utils\n+    import org.scalatest.Matchers._\n+\n+    val tempDir = Utils.createTempDir()\n+    val filePath = new File(tempDir, \"testParquet\").getCanonicalPath\n+\n+    val rdd0 =\n+      sqlContext.sparkContext.parallelize(Seq(A(\"apple\", 1), A(\"banana\", 2), A(\"cherry\", 3)))\n+    val df0 = rdd0.toDF()\n+    df0.write.format(\"parquet\").save(filePath)\n+\n+    val df1 = sqlContext.read.format(\"parquet\").load(filePath)\n+    val rdd1 = df1.toTypedRDD[A]()\n+    rdd1.collect() should contain theSameElementsAs rdd0.collect()\n+  }\n+}\n+\n+case class A(x: String, y: Int)\n+case class B(a: A, z: Double)\n+case class C(x: String, a: Seq[A])\n+case class D(x: String, a: Map[Int, A])",
    "line": 115
  }],
  "prId": 5713
}]