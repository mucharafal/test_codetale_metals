[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Hi, @sameeragarwal !\nThis PR looks great. By the way, could you update line 36~44 with new `SparkSession` builder pattern?\n",
    "commit": "18150121df04c8f0fd39c2c2fbfbc7fc39ccbd64",
    "createdAt": "2016-05-19T06:03:23Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet.tpcds\n+\n+import java.io.File\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.SQLContext\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.util._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark to measure TPCDS query performance.\n+ * To run this:\n+ *  spark-submit --class <this class> --jars <spark sql test jar>\n+ */\n+object TPCDSQueryBenchmark {\n+  val conf = new SparkConf()\n+  conf.set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n+  conf.set(\"spark.sql.shuffle.partitions\", \"4\")\n+  conf.set(\"spark.driver.memory\", \"3g\")\n+  conf.set(\"spark.executor.memory\", \"3g\")\n+  conf.set(\"spark.sql.autoBroadcastJoinThreshold\", (20 * 1024 * 1024).toString)\n+\n+  val sc = new SparkContext(\"local[1]\", \"test-sql-context\", conf)\n+  val sqlContext = new SQLContext(sc)"
  }, {
    "author": {
      "login": "sameeragarwal"
    },
    "body": "yes, for sure. Thanks!\n",
    "commit": "18150121df04c8f0fd39c2c2fbfbc7fc39ccbd64",
    "createdAt": "2016-05-19T19:34:45Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet.tpcds\n+\n+import java.io.File\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.SQLContext\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.util._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark to measure TPCDS query performance.\n+ * To run this:\n+ *  spark-submit --class <this class> --jars <spark sql test jar>\n+ */\n+object TPCDSQueryBenchmark {\n+  val conf = new SparkConf()\n+  conf.set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n+  conf.set(\"spark.sql.shuffle.partitions\", \"4\")\n+  conf.set(\"spark.driver.memory\", \"3g\")\n+  conf.set(\"spark.executor.memory\", \"3g\")\n+  conf.set(\"spark.sql.autoBroadcastJoinThreshold\", (20 * 1024 * 1024).toString)\n+\n+  val sc = new SparkContext(\"local[1]\", \"test-sql-context\", conf)\n+  val sqlContext = new SQLContext(sc)"
  }],
  "prId": 13188
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Offtopic: What is wrong with q41?\n",
    "commit": "18150121df04c8f0fd39c2c2fbfbc7fc39ccbd64",
    "createdAt": "2016-05-19T16:59:08Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet.tpcds\n+\n+import java.io.File\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.SQLContext\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.util._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark to measure TPCDS query performance.\n+ * To run this:\n+ *  spark-submit --class <this class> --jars <spark sql test jar>\n+ */\n+object TPCDSQueryBenchmark {\n+  val conf = new SparkConf()\n+  conf.set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n+  conf.set(\"spark.sql.shuffle.partitions\", \"4\")\n+  conf.set(\"spark.driver.memory\", \"3g\")\n+  conf.set(\"spark.executor.memory\", \"3g\")\n+  conf.set(\"spark.sql.autoBroadcastJoinThreshold\", (20 * 1024 * 1024).toString)\n+\n+  val sc = new SparkContext(\"local[1]\", \"test-sql-context\", conf)\n+  val sqlContext = new SQLContext(sc)\n+\n+  // modified q9\n+\n+  val queries = Seq(\n+    \"q1\", \"q2\", \"q3\", \"q4\", \"q5\", \"q6\", \"q7\", \"q8\", \"q9\", \"q10\", \"q11\",\n+    \"q12\", \"q13\", \"q14a\", \"q14b\", \"q15\", \"q16\", \"q17\", \"q18\", \"q19\", \"q20\",\n+    \"q21\", \"q22\", \"q23a\", \"q23b\", \"q24a\", \"q24b\", \"q25\", \"q26\", \"q27\", \"q28\", \"q29\", \"q30\",\n+    \"q31\", \"q32\", \"q33\", \"q34\", \"q35\", \"q36\", \"q37\", \"q38\", \"q39a\", \"q39b\", \"q40\",\n+    \"q41\", \"q42\", \"q43\", \"q44\", \"q45\", \"q46\", \"q47\", \"q48\", \"q49\", \"q50\",\n+    \"q51\", \"q52\", \"q53\", \"q54\", \"q55\", \"q56\", \"q57\", \"q58\", \"q59\", \"q60\",\n+    \"q61\", \"q62\", \"q63\", \"q64\", \"q65\", \"q66\", \"q67\", \"q68\", \"q69\", \"q70\",\n+    \"q71\", \"q72\", \"q73\", \"q74\", \"q75\", \"q76\", \"q77\", \"q78\", \"q79\", \"q80\",\n+    \"q81\", \"q82\", \"q83\", \"q84\", \"q85\", \"q86\", \"q87\", \"q88\", \"q89\", \"q90\",\n+    \"q91\", \"q92\", \"q93\", \"q94\", \"q95\", \"q96\", \"q97\", \"q98\", \"q99\", \"ss_max\")\n+    .filter(_ != \"q41\") // Exclude 41; 72 is long!"
  }, {
    "author": {
      "login": "sameeragarwal"
    },
    "body": "I think it had a correlated subquery that used to not work. It works now thanks to your patch :)\n",
    "commit": "18150121df04c8f0fd39c2c2fbfbc7fc39ccbd64",
    "createdAt": "2016-05-19T19:35:00Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet.tpcds\n+\n+import java.io.File\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.sql.SQLContext\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.util._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark to measure TPCDS query performance.\n+ * To run this:\n+ *  spark-submit --class <this class> --jars <spark sql test jar>\n+ */\n+object TPCDSQueryBenchmark {\n+  val conf = new SparkConf()\n+  conf.set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n+  conf.set(\"spark.sql.shuffle.partitions\", \"4\")\n+  conf.set(\"spark.driver.memory\", \"3g\")\n+  conf.set(\"spark.executor.memory\", \"3g\")\n+  conf.set(\"spark.sql.autoBroadcastJoinThreshold\", (20 * 1024 * 1024).toString)\n+\n+  val sc = new SparkContext(\"local[1]\", \"test-sql-context\", conf)\n+  val sqlContext = new SQLContext(sc)\n+\n+  // modified q9\n+\n+  val queries = Seq(\n+    \"q1\", \"q2\", \"q3\", \"q4\", \"q5\", \"q6\", \"q7\", \"q8\", \"q9\", \"q10\", \"q11\",\n+    \"q12\", \"q13\", \"q14a\", \"q14b\", \"q15\", \"q16\", \"q17\", \"q18\", \"q19\", \"q20\",\n+    \"q21\", \"q22\", \"q23a\", \"q23b\", \"q24a\", \"q24b\", \"q25\", \"q26\", \"q27\", \"q28\", \"q29\", \"q30\",\n+    \"q31\", \"q32\", \"q33\", \"q34\", \"q35\", \"q36\", \"q37\", \"q38\", \"q39a\", \"q39b\", \"q40\",\n+    \"q41\", \"q42\", \"q43\", \"q44\", \"q45\", \"q46\", \"q47\", \"q48\", \"q49\", \"q50\",\n+    \"q51\", \"q52\", \"q53\", \"q54\", \"q55\", \"q56\", \"q57\", \"q58\", \"q59\", \"q60\",\n+    \"q61\", \"q62\", \"q63\", \"q64\", \"q65\", \"q66\", \"q67\", \"q68\", \"q69\", \"q70\",\n+    \"q71\", \"q72\", \"q73\", \"q74\", \"q75\", \"q76\", \"q77\", \"q78\", \"q79\", \"q80\",\n+    \"q81\", \"q82\", \"q83\", \"q84\", \"q85\", \"q86\", \"q87\", \"q88\", \"q89\", \"q90\",\n+    \"q91\", \"q92\", \"q93\", \"q94\", \"q95\", \"q96\", \"q97\", \"q98\", \"q99\", \"ss_max\")\n+    .filter(_ != \"q41\") // Exclude 41; 72 is long!"
  }],
  "prId": 13188
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "Should we move this outside of parquet? \n",
    "commit": "18150121df04c8f0fd39c2c2fbfbc7fc39ccbd64",
    "createdAt": "2016-05-19T23:09:33Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet.tpcds"
  }],
  "prId": 13188
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "The scale may be not 5\n",
    "commit": "18150121df04c8f0fd39c2c2fbfbc7fc39ccbd64",
    "createdAt": "2016-05-19T23:45:16Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources.parquet.tpcds\n+\n+import java.io.File\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.TableIdentifier\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation\n+import org.apache.spark.sql.catalyst.expressions.SubqueryExpression\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.catalyst.util._\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Benchmark to measure TPCDS query performance.\n+ * To run this:\n+ *  spark-submit --class <this class> --jars <spark sql test jar>\n+ */\n+object TPCDSQueryBenchmark {\n+  val conf =\n+    new SparkConf()\n+      .setMaster(\"local[1]\")\n+      .setAppName(\"test-sql-context\")\n+      .set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n+      .set(\"spark.sql.shuffle.partitions\", \"4\")\n+      .set(\"spark.driver.memory\", \"3g\")\n+      .set(\"spark.executor.memory\", \"3g\")\n+      .set(\"spark.sql.autoBroadcastJoinThreshold\", (20 * 1024 * 1024).toString)\n+\n+  val spark = SparkSession.builder.config(conf).getOrCreate()\n+\n+  val tables = Seq(\"catalog_page\", \"catalog_returns\", \"customer\", \"customer_address\",\n+    \"customer_demographics\", \"date_dim\", \"household_demographics\", \"inventory\", \"item\",\n+    \"promotion\", \"store\", \"store_returns\", \"catalog_sales\", \"web_sales\", \"store_sales\",\n+    \"web_returns\", \"web_site\", \"reason\", \"call_center\", \"warehouse\", \"ship_mode\", \"income_band\",\n+    \"time_dim\", \"web_page\")\n+\n+  def setupTables(dataLocation: String): Map[String, Long] = {\n+    tables.map { tableName =>\n+      spark.read.parquet(s\"$dataLocation/$tableName\").createOrReplaceTempView(tableName)\n+      tableName -> spark.table(tableName).count()\n+    }.toMap\n+  }\n+\n+  def tpcdsAll(dataLocation: String, queries: Seq[String]): Unit = {\n+    require(dataLocation.nonEmpty,\n+      \"please modify the value of dataLocation to point to your local TPCDS data\")\n+    val tableSizes = setupTables(dataLocation)\n+    spark.conf.set(SQLConf.PARQUET_VECTORIZED_READER_ENABLED.key, \"true\")\n+    spark.conf.set(SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key, \"true\")\n+    queries.foreach { name =>\n+      val queriesString = fileToString(new File(s\"sql/core/src/test/scala/org/apache/spark/sql/\" +\n+        s\"execution/datasources/parquet/tpcds/queries/$name.sql\"))\n+\n+      // This is an indirect hack to estimate the size of each query's input by traversing the\n+      // logical plan and adding up the sizes of all tables that appear in the plan. Note that this\n+      // currently doesn't take WITH subqueries into account which might lead to fairly inaccurate\n+      // per-row processing time for those cases.\n+      val queryRelations = scala.collection.mutable.HashSet[String]()\n+      spark.sql(queriesString).queryExecution.logical.map {\n+        case ur @ UnresolvedRelation(t: TableIdentifier, _) =>\n+          queryRelations.add(t.table)\n+        case lp: LogicalPlan =>\n+          lp.expressions.foreach { _ foreach {\n+            case subquery: SubqueryExpression =>\n+              subquery.plan.foreach {\n+                case ur @ UnresolvedRelation(t: TableIdentifier, _) =>\n+                  queryRelations.add(t.table)\n+                case _ =>\n+              }\n+            case _ =>\n+          }\n+        }\n+        case _ =>\n+      }\n+      val numRows = queryRelations.map(tableSizes.getOrElse(_, 0L)).sum\n+      val benchmark = new Benchmark(\"TPCDS Snappy (scale = 5)\", numRows, 1)"
  }],
  "prId": 13188
}]