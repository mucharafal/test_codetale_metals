[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "These tests are likely to be flaky because of the timing related issues. Other then making the timings more coarse, i am not sure how else to test awaitTerminations's behavior.\n",
    "commit": "458199b3cb7acd3f57bcc425830ea219f92b91d8",
    "createdAt": "2016-02-02T21:55:16Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming\n+\n+import scala.concurrent.Future\n+import scala.util.Random\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.BeforeAndAfter\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.concurrent.PatienceConfiguration.Timeout\n+import org.scalatest.time.Span\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.sql.execution.streaming.{MemorySink, MemoryStream, StreamExecution}\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.{Dataset, ContinuousQuery, StreamTest}\n+\n+class ContinuousQueryManagerSuite extends StreamTest with SharedSQLContext with BeforeAndAfter {\n+\n+  import AwaitTerminationTester._\n+  import testImplicits._\n+\n+  after {\n+    assert(sqlContext.streams.active.isEmpty)\n+  }\n+\n+  test(\"listing\") {\n+    val (m1, ds1) = makeDataset\n+    val (m2, ds2) = makeDataset\n+    val (m3, ds3) = makeDataset\n+\n+    withQueriesOn(ds1, ds2, ds3) { queries =>\n+      require(queries.size === 3)\n+      assert(sqlContext.streams.active.toSet === queries.toSet)\n+      val (q1, q2, q3) = (queries(0), queries(1), queries(2))\n+\n+      assert(sqlContext.streams.get(q1.name).eq(q1))\n+      assert(sqlContext.streams.get(q2.name).eq(q2))\n+      assert(sqlContext.streams.get(q3.name).eq(q3))\n+\n+      q1.stop()\n+\n+      assert(sqlContext.streams.active.toSet === Set(q2, q3))\n+      val ex1 = withClue(\"no error while getting non-active query\") {\n+        intercept[IllegalArgumentException] {\n+          sqlContext.streams.get(q1.name).eq(q1)\n+        }\n+      }\n+      assert(ex1.getMessage.contains(q1.name), \"error does not contain name of query to be fetched\")\n+      assert(sqlContext.streams.get(q2.name).eq(q2))\n+\n+      m2.addData(0)   // q2 should terminate with error\n+\n+      eventually(Timeout(streamingTimout)) {\n+        require(!q2.isActive)\n+        require(q2.exception.isDefined)\n+      }\n+      val ex2 = withClue(\"no error while getting non-active query\") {\n+        intercept[IllegalArgumentException] {\n+          sqlContext.streams.get(q2.name).eq(q2)\n+        }\n+      }\n+\n+      assert(sqlContext.streams.active.toSet === Set(q3))\n+    }\n+  }\n+\n+  test(\"awaitAnyTermination\") {"
  }],
  "prId": 11030
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "typo\n",
    "commit": "458199b3cb7acd3f57bcc425830ea219f92b91d8",
    "createdAt": "2016-02-03T01:28:33Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming\n+\n+import scala.concurrent.Future\n+import scala.util.Random\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.BeforeAndAfter\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.concurrent.PatienceConfiguration.Timeout\n+import org.scalatest.time.Span\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.sql.execution.streaming.{MemorySink, MemoryStream, StreamExecution}\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.{Dataset, ContinuousQuery, StreamTest}\n+\n+class ContinuousQueryManagerSuite extends StreamTest with SharedSQLContext with BeforeAndAfter {\n+\n+  import AwaitTerminationTester._\n+  import testImplicits._\n+\n+  after {\n+    assert(sqlContext.streams.active.isEmpty)\n+  }\n+\n+  test(\"listing\") {\n+    val (m1, ds1) = makeDataset\n+    val (m2, ds2) = makeDataset\n+    val (m3, ds3) = makeDataset\n+\n+    withQueriesOn(ds1, ds2, ds3) { queries =>\n+      require(queries.size === 3)\n+      assert(sqlContext.streams.active.toSet === queries.toSet)\n+      val (q1, q2, q3) = (queries(0), queries(1), queries(2))\n+\n+      assert(sqlContext.streams.get(q1.name).eq(q1))\n+      assert(sqlContext.streams.get(q2.name).eq(q2))\n+      assert(sqlContext.streams.get(q3.name).eq(q3))\n+\n+      q1.stop()\n+\n+      assert(sqlContext.streams.active.toSet === Set(q2, q3))\n+      val ex1 = withClue(\"no error while getting non-active query\") {\n+        intercept[IllegalArgumentException] {\n+          sqlContext.streams.get(q1.name).eq(q1)\n+        }\n+      }\n+      assert(ex1.getMessage.contains(q1.name), \"error does not contain name of query to be fetched\")\n+      assert(sqlContext.streams.get(q2.name).eq(q2))\n+\n+      m2.addData(0)   // q2 should terminate with error\n+\n+      eventually(Timeout(streamingTimout)) {\n+        require(!q2.isActive)\n+        require(q2.exception.isDefined)\n+      }\n+      val ex2 = withClue(\"no error while getting non-active query\") {\n+        intercept[IllegalArgumentException] {\n+          sqlContext.streams.get(q2.name).eq(q2)\n+        }\n+      }\n+\n+      assert(sqlContext.streams.active.toSet === Set(q3))\n+    }\n+  }\n+\n+  test(\"awaitAnyTermination\") {\n+    val dss = Seq.fill(5)(makeDataset._2)\n+    withQueriesOn(dss:_*) { queries =>\n+      require(queries.size === dss.size)\n+      assert(sqlContext.streams.active.toSet === queries.toSet)\n+\n+      testAwaitAnyTermination(ExpectBlocked)\n+      testAwaitAnyTermination(ExpectBlocked, awaitTimeout = 2 seconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked, awaitTimeout = 100 milliseconds, expectedReturnedValue = None)\n+\n+      val q1 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(ExpectNotBlocked, expectedReturnedValue = q1)\n+      eventually(Timeout(streamingTimout)) { require(!q1.isActive) }\n+\n+\n+      val q2 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked,\n+        awaitTimeout = 2 seconds,\n+        expectedReturnedValue = Some(q2),\n+        testTimeout = 4 seconds)\n+      eventually(Timeout(streamingTimout)) { require(!q2.isActive) }\n+\n+      val q3 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked, awaitTimeout = 100 milliseconds, expectedReturnedValue = None)\n+      eventually(Timeout(streamingTimout)) { require(!q3.isActive) }\n+\n+      assert(sqlContext.streams.active.size === 2)\n+    }\n+  }\n+\n+  private def withQueriesOn(datasets: Dataset[_]*)(body: Seq[ContinuousQuery] => Unit): Unit = {\n+    failAfter(streamingTimout) {\n+      val queries = withClue(\"Error starting queries\") {\n+        datasets.map { ds =>\n+          @volatile var query: StreamExecution = null\n+          try {\n+            val df = ds.toDF\n+            query = sqlContext\n+              .streams\n+              .startQuery(StreamExecution.nextName, df, new MemorySink(df.schema))\n+              .asInstanceOf[StreamExecution]\n+          } catch {\n+            case NonFatal(e) =>\n+              if (query != null) query.stop()\n+              throw e\n+          }\n+          query\n+        }\n+      }\n+      try {\n+        body(queries)\n+      } finally {\n+        queries.foreach(_.stop())\n+      }\n+    }\n+  }\n+\n+  private def makeDataset: (MemoryStream[Int], Dataset[Int]) = {\n+    val inputData = MemoryStream[Int]\n+    val mapped = inputData.toDS.map(6 / _)\n+    (inputData, mapped)\n+  }\n+\n+  private def testAwaitAnyTermination(\n+      expectedBehavior: ExpectedBehavior,\n+      expectedReturnedValue: Any = null,\n+      awaitTimeout: Span = null,\n+      testTimeout: Span = 1000 milliseconds\n+    ): Unit = {\n+    require(expectedBehavior != ExpectNotBlocked || expectedReturnedValue != null,\n+      \"Expected returned value not specified when awaitTermination is expected to be not blocked\")\n+\n+    def awaitTermFunc(): Unit = {\n+      val returnedValue = if (awaitTimeout != null && awaitTimeout.toMillis > 0) {\n+        sqlContext.streams.awaitAnyTermination(awaitTimeout.toMillis)\n+      } else {\n+        sqlContext.streams.awaitAnyTermination()\n+      }\n+      assert(returnedValue === expectedReturnedValue,\n+        \"Returned value does not match expect3ed\")"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Fixed.\n",
    "commit": "458199b3cb7acd3f57bcc425830ea219f92b91d8",
    "createdAt": "2016-02-04T02:59:01Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming\n+\n+import scala.concurrent.Future\n+import scala.util.Random\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.BeforeAndAfter\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.concurrent.PatienceConfiguration.Timeout\n+import org.scalatest.time.Span\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.sql.execution.streaming.{MemorySink, MemoryStream, StreamExecution}\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.{Dataset, ContinuousQuery, StreamTest}\n+\n+class ContinuousQueryManagerSuite extends StreamTest with SharedSQLContext with BeforeAndAfter {\n+\n+  import AwaitTerminationTester._\n+  import testImplicits._\n+\n+  after {\n+    assert(sqlContext.streams.active.isEmpty)\n+  }\n+\n+  test(\"listing\") {\n+    val (m1, ds1) = makeDataset\n+    val (m2, ds2) = makeDataset\n+    val (m3, ds3) = makeDataset\n+\n+    withQueriesOn(ds1, ds2, ds3) { queries =>\n+      require(queries.size === 3)\n+      assert(sqlContext.streams.active.toSet === queries.toSet)\n+      val (q1, q2, q3) = (queries(0), queries(1), queries(2))\n+\n+      assert(sqlContext.streams.get(q1.name).eq(q1))\n+      assert(sqlContext.streams.get(q2.name).eq(q2))\n+      assert(sqlContext.streams.get(q3.name).eq(q3))\n+\n+      q1.stop()\n+\n+      assert(sqlContext.streams.active.toSet === Set(q2, q3))\n+      val ex1 = withClue(\"no error while getting non-active query\") {\n+        intercept[IllegalArgumentException] {\n+          sqlContext.streams.get(q1.name).eq(q1)\n+        }\n+      }\n+      assert(ex1.getMessage.contains(q1.name), \"error does not contain name of query to be fetched\")\n+      assert(sqlContext.streams.get(q2.name).eq(q2))\n+\n+      m2.addData(0)   // q2 should terminate with error\n+\n+      eventually(Timeout(streamingTimout)) {\n+        require(!q2.isActive)\n+        require(q2.exception.isDefined)\n+      }\n+      val ex2 = withClue(\"no error while getting non-active query\") {\n+        intercept[IllegalArgumentException] {\n+          sqlContext.streams.get(q2.name).eq(q2)\n+        }\n+      }\n+\n+      assert(sqlContext.streams.active.toSet === Set(q3))\n+    }\n+  }\n+\n+  test(\"awaitAnyTermination\") {\n+    val dss = Seq.fill(5)(makeDataset._2)\n+    withQueriesOn(dss:_*) { queries =>\n+      require(queries.size === dss.size)\n+      assert(sqlContext.streams.active.toSet === queries.toSet)\n+\n+      testAwaitAnyTermination(ExpectBlocked)\n+      testAwaitAnyTermination(ExpectBlocked, awaitTimeout = 2 seconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked, awaitTimeout = 100 milliseconds, expectedReturnedValue = None)\n+\n+      val q1 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(ExpectNotBlocked, expectedReturnedValue = q1)\n+      eventually(Timeout(streamingTimout)) { require(!q1.isActive) }\n+\n+\n+      val q2 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked,\n+        awaitTimeout = 2 seconds,\n+        expectedReturnedValue = Some(q2),\n+        testTimeout = 4 seconds)\n+      eventually(Timeout(streamingTimout)) { require(!q2.isActive) }\n+\n+      val q3 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked, awaitTimeout = 100 milliseconds, expectedReturnedValue = None)\n+      eventually(Timeout(streamingTimout)) { require(!q3.isActive) }\n+\n+      assert(sqlContext.streams.active.size === 2)\n+    }\n+  }\n+\n+  private def withQueriesOn(datasets: Dataset[_]*)(body: Seq[ContinuousQuery] => Unit): Unit = {\n+    failAfter(streamingTimout) {\n+      val queries = withClue(\"Error starting queries\") {\n+        datasets.map { ds =>\n+          @volatile var query: StreamExecution = null\n+          try {\n+            val df = ds.toDF\n+            query = sqlContext\n+              .streams\n+              .startQuery(StreamExecution.nextName, df, new MemorySink(df.schema))\n+              .asInstanceOf[StreamExecution]\n+          } catch {\n+            case NonFatal(e) =>\n+              if (query != null) query.stop()\n+              throw e\n+          }\n+          query\n+        }\n+      }\n+      try {\n+        body(queries)\n+      } finally {\n+        queries.foreach(_.stop())\n+      }\n+    }\n+  }\n+\n+  private def makeDataset: (MemoryStream[Int], Dataset[Int]) = {\n+    val inputData = MemoryStream[Int]\n+    val mapped = inputData.toDS.map(6 / _)\n+    (inputData, mapped)\n+  }\n+\n+  private def testAwaitAnyTermination(\n+      expectedBehavior: ExpectedBehavior,\n+      expectedReturnedValue: Any = null,\n+      awaitTimeout: Span = null,\n+      testTimeout: Span = 1000 milliseconds\n+    ): Unit = {\n+    require(expectedBehavior != ExpectNotBlocked || expectedReturnedValue != null,\n+      \"Expected returned value not specified when awaitTermination is expected to be not blocked\")\n+\n+    def awaitTermFunc(): Unit = {\n+      val returnedValue = if (awaitTimeout != null && awaitTimeout.toMillis > 0) {\n+        sqlContext.streams.awaitAnyTermination(awaitTimeout.toMillis)\n+      } else {\n+        sqlContext.streams.awaitAnyTermination()\n+      }\n+      assert(returnedValue === expectedReturnedValue,\n+        \"Returned value does not match expect3ed\")"
  }],
  "prId": 11030
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "Add a log about the query to stop? Otherwise, it may be hard to debug if we don't know the value of `Random.nextInt(activeQueries.length)`.\n",
    "commit": "458199b3cb7acd3f57bcc425830ea219f92b91d8",
    "createdAt": "2016-02-03T23:02:09Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming\n+\n+import scala.concurrent.Future\n+import scala.util.Random\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.BeforeAndAfter\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.concurrent.PatienceConfiguration.Timeout\n+import org.scalatest.time.Span\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.sql.execution.streaming.{MemorySink, MemoryStream, StreamExecution}\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.{Dataset, ContinuousQuery, StreamTest}\n+\n+class ContinuousQueryManagerSuite extends StreamTest with SharedSQLContext with BeforeAndAfter {\n+\n+  import AwaitTerminationTester._\n+  import testImplicits._\n+\n+  after {\n+    assert(sqlContext.streams.active.isEmpty)\n+  }\n+\n+  test(\"listing\") {\n+    val (m1, ds1) = makeDataset\n+    val (m2, ds2) = makeDataset\n+    val (m3, ds3) = makeDataset\n+\n+    withQueriesOn(ds1, ds2, ds3) { queries =>\n+      require(queries.size === 3)\n+      assert(sqlContext.streams.active.toSet === queries.toSet)\n+      val (q1, q2, q3) = (queries(0), queries(1), queries(2))\n+\n+      assert(sqlContext.streams.get(q1.name).eq(q1))\n+      assert(sqlContext.streams.get(q2.name).eq(q2))\n+      assert(sqlContext.streams.get(q3.name).eq(q3))\n+\n+      q1.stop()\n+\n+      assert(sqlContext.streams.active.toSet === Set(q2, q3))\n+      val ex1 = withClue(\"no error while getting non-active query\") {\n+        intercept[IllegalArgumentException] {\n+          sqlContext.streams.get(q1.name).eq(q1)\n+        }\n+      }\n+      assert(ex1.getMessage.contains(q1.name), \"error does not contain name of query to be fetched\")\n+      assert(sqlContext.streams.get(q2.name).eq(q2))\n+\n+      m2.addData(0)   // q2 should terminate with error\n+\n+      eventually(Timeout(streamingTimout)) {\n+        require(!q2.isActive)\n+        require(q2.exception.isDefined)\n+      }\n+      val ex2 = withClue(\"no error while getting non-active query\") {\n+        intercept[IllegalArgumentException] {\n+          sqlContext.streams.get(q2.name).eq(q2)\n+        }\n+      }\n+\n+      assert(sqlContext.streams.active.toSet === Set(q3))\n+    }\n+  }\n+\n+  test(\"awaitAnyTermination\") {\n+    val dss = Seq.fill(5)(makeDataset._2)\n+    withQueriesOn(dss:_*) { queries =>\n+      require(queries.size === dss.size)\n+      assert(sqlContext.streams.active.toSet === queries.toSet)\n+\n+      testAwaitAnyTermination(ExpectBlocked)\n+      testAwaitAnyTermination(ExpectBlocked, awaitTimeout = 2 seconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked, awaitTimeout = 100 milliseconds, expectedReturnedValue = None)\n+\n+      val q1 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(ExpectNotBlocked, expectedReturnedValue = q1)\n+      eventually(Timeout(streamingTimout)) { require(!q1.isActive) }\n+\n+\n+      val q2 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked,\n+        awaitTimeout = 2 seconds,\n+        expectedReturnedValue = Some(q2),\n+        testTimeout = 4 seconds)\n+      eventually(Timeout(streamingTimout)) { require(!q2.isActive) }\n+\n+      val q3 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked, awaitTimeout = 100 milliseconds, expectedReturnedValue = None)\n+      eventually(Timeout(streamingTimout)) { require(!q3.isActive) }\n+\n+      assert(sqlContext.streams.active.size === 2)\n+    }\n+  }\n+\n+  private def withQueriesOn(datasets: Dataset[_]*)(body: Seq[ContinuousQuery] => Unit): Unit = {\n+    failAfter(streamingTimout) {\n+      val queries = withClue(\"Error starting queries\") {\n+        datasets.map { ds =>\n+          @volatile var query: StreamExecution = null\n+          try {\n+            val df = ds.toDF\n+            query = sqlContext\n+              .streams\n+              .startQuery(StreamExecution.nextName, df, new MemorySink(df.schema))\n+              .asInstanceOf[StreamExecution]\n+          } catch {\n+            case NonFatal(e) =>\n+              if (query != null) query.stop()\n+              throw e\n+          }\n+          query\n+        }\n+      }\n+      try {\n+        body(queries)\n+      } finally {\n+        queries.foreach(_.stop())\n+      }\n+    }\n+  }\n+\n+  private def makeDataset: (MemoryStream[Int], Dataset[Int]) = {\n+    val inputData = MemoryStream[Int]\n+    val mapped = inputData.toDS.map(6 / _)\n+    (inputData, mapped)\n+  }\n+\n+  private def testAwaitAnyTermination(\n+      expectedBehavior: ExpectedBehavior,\n+      expectedReturnedValue: Any = null,\n+      awaitTimeout: Span = null,\n+      testTimeout: Span = 1000 milliseconds\n+    ): Unit = {\n+    require(expectedBehavior != ExpectNotBlocked || expectedReturnedValue != null,\n+      \"Expected returned value not specified when awaitTermination is expected to be not blocked\")\n+\n+    def awaitTermFunc(): Unit = {\n+      val returnedValue = if (awaitTimeout != null && awaitTimeout.toMillis > 0) {\n+        sqlContext.streams.awaitAnyTermination(awaitTimeout.toMillis)\n+      } else {\n+        sqlContext.streams.awaitAnyTermination()\n+      }\n+      assert(returnedValue === expectedReturnedValue,\n+        \"Returned value does not match expect3ed\")\n+    }\n+\n+    AwaitTerminationTester.test(expectedBehavior, awaitTermFunc, testTimeout)\n+  }\n+\n+  private def stopRandomQueryAsync(delay: Span): ContinuousQuery = {\n+    import scala.concurrent.ExecutionContext.Implicits.global\n+\n+    val activeQueries = sqlContext.streams.active\n+    val queryToStop = activeQueries(Random.nextInt(activeQueries.length))"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Done.\n",
    "commit": "458199b3cb7acd3f57bcc425830ea219f92b91d8",
    "createdAt": "2016-02-04T02:59:59Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.streaming\n+\n+import scala.concurrent.Future\n+import scala.util.Random\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.BeforeAndAfter\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.concurrent.PatienceConfiguration.Timeout\n+import org.scalatest.time.Span\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.sql.execution.streaming.{MemorySink, MemoryStream, StreamExecution}\n+import org.apache.spark.sql.test.SharedSQLContext\n+import org.apache.spark.sql.{Dataset, ContinuousQuery, StreamTest}\n+\n+class ContinuousQueryManagerSuite extends StreamTest with SharedSQLContext with BeforeAndAfter {\n+\n+  import AwaitTerminationTester._\n+  import testImplicits._\n+\n+  after {\n+    assert(sqlContext.streams.active.isEmpty)\n+  }\n+\n+  test(\"listing\") {\n+    val (m1, ds1) = makeDataset\n+    val (m2, ds2) = makeDataset\n+    val (m3, ds3) = makeDataset\n+\n+    withQueriesOn(ds1, ds2, ds3) { queries =>\n+      require(queries.size === 3)\n+      assert(sqlContext.streams.active.toSet === queries.toSet)\n+      val (q1, q2, q3) = (queries(0), queries(1), queries(2))\n+\n+      assert(sqlContext.streams.get(q1.name).eq(q1))\n+      assert(sqlContext.streams.get(q2.name).eq(q2))\n+      assert(sqlContext.streams.get(q3.name).eq(q3))\n+\n+      q1.stop()\n+\n+      assert(sqlContext.streams.active.toSet === Set(q2, q3))\n+      val ex1 = withClue(\"no error while getting non-active query\") {\n+        intercept[IllegalArgumentException] {\n+          sqlContext.streams.get(q1.name).eq(q1)\n+        }\n+      }\n+      assert(ex1.getMessage.contains(q1.name), \"error does not contain name of query to be fetched\")\n+      assert(sqlContext.streams.get(q2.name).eq(q2))\n+\n+      m2.addData(0)   // q2 should terminate with error\n+\n+      eventually(Timeout(streamingTimout)) {\n+        require(!q2.isActive)\n+        require(q2.exception.isDefined)\n+      }\n+      val ex2 = withClue(\"no error while getting non-active query\") {\n+        intercept[IllegalArgumentException] {\n+          sqlContext.streams.get(q2.name).eq(q2)\n+        }\n+      }\n+\n+      assert(sqlContext.streams.active.toSet === Set(q3))\n+    }\n+  }\n+\n+  test(\"awaitAnyTermination\") {\n+    val dss = Seq.fill(5)(makeDataset._2)\n+    withQueriesOn(dss:_*) { queries =>\n+      require(queries.size === dss.size)\n+      assert(sqlContext.streams.active.toSet === queries.toSet)\n+\n+      testAwaitAnyTermination(ExpectBlocked)\n+      testAwaitAnyTermination(ExpectBlocked, awaitTimeout = 2 seconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked, awaitTimeout = 100 milliseconds, expectedReturnedValue = None)\n+\n+      val q1 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(ExpectNotBlocked, expectedReturnedValue = q1)\n+      eventually(Timeout(streamingTimout)) { require(!q1.isActive) }\n+\n+\n+      val q2 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked,\n+        awaitTimeout = 2 seconds,\n+        expectedReturnedValue = Some(q2),\n+        testTimeout = 4 seconds)\n+      eventually(Timeout(streamingTimout)) { require(!q2.isActive) }\n+\n+      val q3 = stopRandomQueryAsync(500 milliseconds)\n+      testAwaitAnyTermination(\n+        ExpectNotBlocked, awaitTimeout = 100 milliseconds, expectedReturnedValue = None)\n+      eventually(Timeout(streamingTimout)) { require(!q3.isActive) }\n+\n+      assert(sqlContext.streams.active.size === 2)\n+    }\n+  }\n+\n+  private def withQueriesOn(datasets: Dataset[_]*)(body: Seq[ContinuousQuery] => Unit): Unit = {\n+    failAfter(streamingTimout) {\n+      val queries = withClue(\"Error starting queries\") {\n+        datasets.map { ds =>\n+          @volatile var query: StreamExecution = null\n+          try {\n+            val df = ds.toDF\n+            query = sqlContext\n+              .streams\n+              .startQuery(StreamExecution.nextName, df, new MemorySink(df.schema))\n+              .asInstanceOf[StreamExecution]\n+          } catch {\n+            case NonFatal(e) =>\n+              if (query != null) query.stop()\n+              throw e\n+          }\n+          query\n+        }\n+      }\n+      try {\n+        body(queries)\n+      } finally {\n+        queries.foreach(_.stop())\n+      }\n+    }\n+  }\n+\n+  private def makeDataset: (MemoryStream[Int], Dataset[Int]) = {\n+    val inputData = MemoryStream[Int]\n+    val mapped = inputData.toDS.map(6 / _)\n+    (inputData, mapped)\n+  }\n+\n+  private def testAwaitAnyTermination(\n+      expectedBehavior: ExpectedBehavior,\n+      expectedReturnedValue: Any = null,\n+      awaitTimeout: Span = null,\n+      testTimeout: Span = 1000 milliseconds\n+    ): Unit = {\n+    require(expectedBehavior != ExpectNotBlocked || expectedReturnedValue != null,\n+      \"Expected returned value not specified when awaitTermination is expected to be not blocked\")\n+\n+    def awaitTermFunc(): Unit = {\n+      val returnedValue = if (awaitTimeout != null && awaitTimeout.toMillis > 0) {\n+        sqlContext.streams.awaitAnyTermination(awaitTimeout.toMillis)\n+      } else {\n+        sqlContext.streams.awaitAnyTermination()\n+      }\n+      assert(returnedValue === expectedReturnedValue,\n+        \"Returned value does not match expect3ed\")\n+    }\n+\n+    AwaitTerminationTester.test(expectedBehavior, awaitTermFunc, testTimeout)\n+  }\n+\n+  private def stopRandomQueryAsync(delay: Span): ContinuousQuery = {\n+    import scala.concurrent.ExecutionContext.Implicits.global\n+\n+    val activeQueries = sqlContext.streams.active\n+    val queryToStop = activeQueries(Random.nextInt(activeQueries.length))"
  }],
  "prId": 11030
}]