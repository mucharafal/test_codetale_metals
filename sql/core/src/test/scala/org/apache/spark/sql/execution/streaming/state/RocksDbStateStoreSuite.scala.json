[{
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Is this done? Looks like it should. Please remove this if you handled this.",
    "commit": "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "createdAt": "2019-07-01T00:13:56Z",
    "diffHunk": "@@ -0,0 +1,615 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import java.io.File\n+import java.util.UUID\n+\n+import org.apache.commons.io.FileUtils\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.Path\n+import org.scalatest.{BeforeAndAfter, PrivateMethodTester}\n+import org.scalatest.concurrent.Eventually.{eventually, timeout}\n+import org.scalatest.time.SpanSugar._\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.util.Random\n+\n+import org.apache.spark.{SparkConf, SparkContext, SparkEnv}\n+import org.apache.spark.LocalSparkContext.withSpark\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.catalyst.util.quietly\n+import org.apache.spark.sql.execution.streaming.MemoryStream\n+import org.apache.spark.sql.functions.count\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n+import org.apache.spark.util.Utils\n+\n+class RocksDbStateStoreSuite\n+    extends StateStoreSuiteBase[RocksDbStateStoreProvider]\n+    with BeforeAndAfter\n+    with PrivateMethodTester {\n+  type MapType = mutable.HashMap[UnsafeRow, UnsafeRow]\n+  type ProviderMapType = java.util.concurrent.ConcurrentHashMap[UnsafeRow, UnsafeRow]\n+\n+  import StateStoreCoordinatorSuite._\n+  import StateStoreTestsHelper._\n+\n+  val keySchema = StructType(Seq(StructField(\"key\", StringType, true)))\n+  val valueSchema = StructType(Seq(StructField(\"value\", IntegerType, true)))\n+\n+  before {\n+    StateStore.stop()\n+    require(!StateStore.isMaintenanceRunning)\n+  }\n+\n+  after {\n+    StateStore.stop()\n+    require(!StateStore.isMaintenanceRunning)\n+  }\n+\n+  def updateVersionTo(\n+      provider: StateStoreProvider,\n+      currentVersion: Int,\n+      targetVersion: Int): Int = {\n+    var newCurrentVersion = currentVersion\n+    for (i <- newCurrentVersion until targetVersion) {\n+      newCurrentVersion = incrementVersion(provider, i)\n+    }\n+    require(newCurrentVersion === targetVersion)\n+    newCurrentVersion\n+  }\n+\n+  def incrementVersion(provider: StateStoreProvider, currentVersion: Int): Int = {\n+    val store = provider.getStore(currentVersion)\n+    put(store, \"a\", currentVersion + 1)\n+    store.commit()\n+    currentVersion + 1\n+  }\n+\n+  def checkLoadedVersions(\n+      rocksDbWriteInstance: RocksDbInstance,\n+      count: Int,\n+      earliestKey: Long,\n+      latestKey: Long): Unit = {\n+    assert(rocksDbWriteInstance.iterator(false).length === count)\n+  }\n+\n+  def checkVersion(\n+      rocksDbWriteInstance: RocksDbInstance,\n+      version: Long,\n+      expectedData: Map[String, Int]): Unit = {\n+\n+    val originValueMap = rocksDbWriteInstance\n+      .iterator(false)\n+      .map { row =>\n+        rowToString(row.key) -> rowToInt(row.value)\n+      }\n+      .toMap[String, Int]\n+\n+    assert(originValueMap === expectedData)\n+  }\n+\n+  test(\"get, put, remove, commit, and all data iterator\") {\n+    val provider = newStoreProvider()\n+\n+    // Verify state before starting a new set of updates\n+    assert(getLatestData(provider).isEmpty)\n+\n+    val store = provider.getStore(0)\n+    assert(!store.hasCommitted)\n+    assert(get(store, \"a\") === None)\n+    assert(store.iterator().isEmpty)\n+\n+    // Verify state after updating\n+    put(store, \"a\", 1)\n+    assert(get(store, \"a\") === Some(1))\n+\n+    assert(store.iterator().nonEmpty)\n+    assert(getLatestData(provider).isEmpty)\n+\n+    // Make updates, commit and then verify state\n+    put(store, \"b\", 2)\n+    put(store, \"aa\", 3)\n+    remove(store, _.startsWith(\"a\"))\n+    assert(store.commit() === 1)\n+\n+    assert(store.hasCommitted)\n+    assert(rowsToSet(store.iterator()) === Set(\"b\" -> 2))\n+    assert(getLatestData(provider) === Set(\"b\" -> 2))\n+\n+    // Trying to get newer versions should fail\n+    intercept[Exception] {\n+      provider.getStore(2)\n+    }\n+    intercept[Exception] {\n+      getData(provider, 2)\n+    }\n+\n+    // New updates to the reloaded store with new version, and does not change old version\n+    val reloadedProvider = newStoreProvider(store.id, provider.getLocalDirectory)\n+    val reloadedStore = reloadedProvider.getStore(1)\n+    put(reloadedStore, \"c\", 4)\n+    assert(reloadedStore.commit() === 2)\n+    assert(rowsToSet(reloadedStore.iterator()) === Set(\"b\" -> 2, \"c\" -> 4))\n+    assert(getLatestData(provider) === Set(\"b\" -> 2, \"c\" -> 4))\n+    assert(getData(provider, version = 1) === Set(\"b\" -> 2))\n+  }\n+\n+  test(\"snapshotting\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+\n+    var currentVersion = 0\n+\n+    currentVersion = updateVersionTo(provider, currentVersion, 2)\n+    require(getData(provider) === Set(\"a\" -> 2))\n+    provider.doMaintenance() // should not generate snapshot files\n+    assert(getData(provider) === Set(\"a\" -> 2))\n+\n+    for (i <- 1 to currentVersion) {\n+      assert(fileExists(provider, i, isSnapshot = false)) // all delta files present\n+      assert(!fileExists(provider, i, isSnapshot = true)) // no snapshot files present\n+    }\n+\n+    // After version 6, snapshotting should generate one snapshot file\n+    currentVersion = updateVersionTo(provider, currentVersion, 6)\n+    require(getData(provider) === Set(\"a\" -> 6), \"store not updated correctly\")\n+    provider.doMaintenance() // should generate snapshot files\n+\n+    val snapshotVersion =\n+      (0 to 6).find(version => fileExists(provider, version, isSnapshot = true))\n+    assert(snapshotVersion.nonEmpty, \"snapshot file not generated\")\n+    deleteFilesEarlierThanVersion(provider, snapshotVersion.get)\n+    assert(\n+      getData(provider, snapshotVersion.get) === Set(\"a\" -> snapshotVersion.get),\n+      \"snapshotting messed up the data of the snapshotted version\")\n+    assert(\n+      getData(provider) === Set(\"a\" -> 6),\n+      \"snapshotting messed up the data of the final version\")\n+\n+    // After version 20, snapshotting should generate newer snapshot files\n+    currentVersion = updateVersionTo(provider, currentVersion, 20)\n+    require(getData(provider) === Set(\"a\" -> 20), \"store not updated correctly\")\n+    provider.doMaintenance() // do snapshot\n+\n+    val latestSnapshotVersion =\n+      (0 to 20).filter(version => fileExists(provider, version, isSnapshot = true)).lastOption\n+    assert(latestSnapshotVersion.nonEmpty, \"no snapshot file found\")\n+    assert(latestSnapshotVersion.get > snapshotVersion.get, \"newer snapshot not generated\")\n+\n+    deleteFilesEarlierThanVersion(provider, latestSnapshotVersion.get)\n+    assert(getData(provider) === Set(\"a\" -> 20), \"snapshotting messed up the data\")\n+  }\n+\n+  test(\"cleaning\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+\n+    for (i <- 1 to 20) {\n+      val store = provider.getStore(i - 1)\n+      put(store, \"a\", i)\n+      store.commit()\n+      provider.doMaintenance() // do cleanup\n+    }\n+    require(\n+      rowsToSet(provider.latestIterator()) === Set(\"a\" -> 20),\n+      \"store not updated correctly\")\n+\n+    assert(!fileExists(provider, version = 1, isSnapshot = false)) // first file should be deleted\n+\n+    // last couple of versions should be retrievable\n+    assert(getData(provider, 20) === Set(\"a\" -> 20))\n+    assert(getData(provider, 19) === Set(\"a\" -> 19))\n+  }\n+\n+  testQuietly(\"SPARK-19677: Committing a delta file atop an existing one should not fail on HDFS\") {\n+    val conf = new Configuration()\n+    conf.set(\"fs.fake.impl\", classOf[RenameLikeHDFSFileSystem].getName)\n+    conf.set(\"fs.defaultFS\", \"fake:///\")\n+\n+    val provider = newStoreProvider(opId = Random.nextInt, partition = 0, hadoopConf = conf)\n+    provider.getStore(0).commit()\n+    provider.getStore(0).commit()\n+\n+    // Verify we don't leak temp files\n+    val tempFiles = FileUtils\n+      .listFiles(new File(provider.stateStoreId.checkpointRootLocation), null, true)\n+      .asScala\n+      .filter(_.getName.startsWith(\"temp-\"))\n+    assert(tempFiles.isEmpty)\n+  }\n+\n+  test(\"corrupted file handling\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+    for (i <- 1 to 6) {\n+      val store = provider.getStore(i - 1)\n+      put(store, \"a\", i)\n+      store.commit()\n+      provider.doMaintenance() // do cleanup\n+    }\n+    val snapshotVersion = (0 to 10)\n+      .find(version => fileExists(provider, version, isSnapshot = true))\n+      .getOrElse(fail(\"snapshot file not found\"))\n+\n+    // Corrupt snapshot file and verify that it throws error\n+    provider.close()\n+    assert(getData(provider, snapshotVersion) === Set(\"a\" -> snapshotVersion))\n+    RocksDbInstance.destroyDB(provider.rocksDbPath)\n+\n+    corruptFile(provider, snapshotVersion, isSnapshot = true)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion)\n+    }\n+\n+    // Corrupt delta file and verify that it throws error\n+    provider.close()\n+    RocksDbInstance.destroyDB(provider.rocksDbPath)\n+    assert(getData(provider, snapshotVersion - 1) === Set(\"a\" -> (snapshotVersion - 1)))\n+\n+    corruptFile(provider, snapshotVersion - 1, isSnapshot = false)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion - 1)\n+    }\n+\n+    // Delete delta file and verify that it throws error\n+    deleteFilesEarlierThanVersion(provider, snapshotVersion)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion - 1)\n+    }\n+  }\n+\n+  test(\"StateStore.get\") {\n+    quietly {\n+      val dir = newDir()\n+      val storeId = StateStoreProviderId(StateStoreId(dir, 0, 0), UUID.randomUUID)\n+      val sqlConf = new SQLConf\n+      sqlConf.setConfString(\n+        \"spark.sql.streaming.stateStore.providerClass\",\n+        \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      val localdir = Utils.createTempDir().getAbsoluteFile.toString\n+      sqlConf.setConfString(\"spark.sql.streaming.stateStore.rocksDb.localDirectory\", localdir)\n+      val storeConf = new StateStoreConf(sqlConf)\n+      assert(\n+        storeConf.providerClass ===\n+          \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      val hadoopConf = new Configuration()\n+\n+      // Verify that trying to get incorrect versions throw errors\n+      intercept[IllegalArgumentException] {\n+        StateStore.get(storeId, keySchema, valueSchema, None, -1, storeConf, hadoopConf)\n+      }\n+      assert(!StateStore.isLoaded(storeId)) // version -1 should not attempt to load the store\n+\n+      intercept[IllegalStateException] {\n+        StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      }\n+\n+      // Increase version of the store and try to get again\n+      val store0 = StateStore.get(storeId, keySchema, valueSchema, None, 0, storeConf, hadoopConf)\n+      assert(store0.version === 0)\n+      put(store0, \"a\", 1)\n+      store0.commit()\n+\n+      val store1 = StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      assert(StateStore.isLoaded(storeId))\n+      assert(store1.version === 1)\n+      assert(rowsToSet(store1.iterator()) === Set(\"a\" -> 1))\n+\n+      // Verify that you can also load older version\n+      val store0reloaded =\n+        StateStore.get(storeId, keySchema, valueSchema, None, 0, storeConf, hadoopConf)\n+      assert(store0reloaded.version === 0)\n+      assert(rowsToSet(store0reloaded.iterator()) === Set.empty)\n+\n+      // Verify that you can remove the store and still reload and use it\n+      StateStore.unload(storeId)\n+      assert(!StateStore.isLoaded(storeId))\n+\n+      val store1reloaded =\n+        StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      assert(StateStore.isLoaded(storeId))\n+      assert(store1reloaded.version === 1)\n+      put(store1reloaded, \"a\", 2)\n+      assert(store1reloaded.commit() === 2)\n+      assert(rowsToSet(store1reloaded.iterator()) === Set(\"a\" -> 2))\n+    }\n+  }\n+\n+  test(\"maintenance\") {\n+    val conf = new SparkConf()\n+      .setMaster(\"local\")\n+      .setAppName(\"test\")\n+      // Make maintenance thread do snapshots and cleanups very fast\n+      .set(StateStore.MAINTENANCE_INTERVAL_CONFIG, \"10ms\")\n+      // Make sure that when SparkContext stops, the StateStore maintenance thread 'quickly'\n+      // fails to talk to the StateStoreCoordinator and unloads all the StateStores\n+      .set(\"spark.rpc.numRetries\", \"1\")\n+    val opId = 0\n+    val dir = newDir()\n+    val storeProviderId = StateStoreProviderId(StateStoreId(dir, opId, 0), UUID.randomUUID)\n+    val sqlConf = new SQLConf()\n+    sqlConf.setConfString(\n+      \"spark.sql.streaming.stateStore.providerClass\",\n+      \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+    sqlConf.setConf(SQLConf.MIN_BATCHES_TO_RETAIN, 2)\n+    sqlConf.setConfString(\n+      \"spark.sql.streaming.stateStore.rocksDb.localDirectory\",\n+      Utils.createTempDir().getAbsoluteFile.toString)\n+    val storeConf = StateStoreConf(sqlConf)\n+    val hadoopConf = new Configuration()\n+    val provider = newStoreProvider(storeProviderId.storeId)\n+\n+    var latestStoreVersion = 0\n+\n+    def generateStoreVersions() {\n+      for (i <- 1 to 20) {\n+        val store = StateStore.get(\n+          storeProviderId,\n+          keySchema,\n+          valueSchema,\n+          None,\n+          latestStoreVersion,\n+          storeConf,\n+          hadoopConf)\n+        put(store, \"a\", i)\n+        store.commit()\n+        latestStoreVersion += 1\n+      }\n+    }\n+\n+    val timeoutDuration = 60 seconds\n+\n+    quietly {\n+      withSpark(new SparkContext(conf)) { sc =>\n+        withCoordinatorRef(sc) { coordinatorRef =>\n+          require(!StateStore.isMaintenanceRunning, \"StateStore is unexpectedly running\")\n+\n+          // Generate sufficient versions of store for snapshots\n+          generateStoreVersions()\n+\n+          eventually(timeout(timeoutDuration)) {\n+            // Store should have been reported to the coordinator\n+            assert(\n+              coordinatorRef.getLocation(storeProviderId).nonEmpty,\n+              \"active instance was not reported\")\n+\n+            // Background maintenance should clean up and generate snapshots\n+            assert(StateStore.isMaintenanceRunning, \"Maintenance task is not running\")\n+\n+            // Some snapshots should have been generated\n+            val snapshotVersions = (1 to latestStoreVersion).filter { version =>\n+              fileExists(provider, version, isSnapshot = true)\n+            }\n+            assert(snapshotVersions.nonEmpty, \"no snapshot file found\")\n+          }\n+\n+          // Generate more versions such that there is another snapshot and\n+          // the earliest delta file will be cleaned up\n+          generateStoreVersions()\n+\n+          // Earliest delta file should get cleaned up\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!fileExists(provider, 1, isSnapshot = false), \"earliest file not deleted\")\n+          }\n+\n+          // If driver decides to deactivate all stores related to a query run,\n+          // then this instance should be unloaded\n+          coordinatorRef.deactivateInstances(storeProviderId.queryRunId)\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!StateStore.isLoaded(storeProviderId))\n+          }\n+\n+          // Reload the store and verify\n+          StateStore.get(\n+            storeProviderId,\n+            keySchema,\n+            valueSchema,\n+            indexOrdinal = None,\n+            latestStoreVersion,\n+            storeConf,\n+            hadoopConf)\n+          assert(StateStore.isLoaded(storeProviderId))\n+\n+          // If some other executor loads the store, then this instance should be unloaded\n+          coordinatorRef.reportActiveInstance(storeProviderId, \"other-host\", \"other-exec\")\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!StateStore.isLoaded(storeProviderId))\n+          }\n+\n+          // Reload the store and verify\n+          StateStore.get(\n+            storeProviderId,\n+            keySchema,\n+            valueSchema,\n+            indexOrdinal = None,\n+            latestStoreVersion,\n+            storeConf,\n+            hadoopConf)\n+          assert(StateStore.isLoaded(storeProviderId))\n+        }\n+      }\n+\n+      // Verify if instance is unloaded if SparkContext is stopped\n+      eventually(timeout(timeoutDuration)) {\n+        require(SparkEnv.get === null)\n+        assert(!StateStore.isLoaded(storeProviderId))\n+        assert(!StateStore.isMaintenanceRunning)\n+      }\n+    }\n+  }\n+\n+  test(\"SPARK-21145: Restarted queries create new provider instances\") {\n+    try {\n+      val checkpointLocation = Utils.createTempDir().getAbsoluteFile\n+      val spark = SparkSession.builder().master(\"local[2]\").getOrCreate()\n+      SparkSession.setActiveSession(spark)\n+      implicit val sqlContext = spark.sqlContext\n+      spark.conf.set(\"spark.sql.shuffle.partitions\", \"1\")\n+      spark.conf.set(\n+        \"spark.sql.streaming.stateStore.providerClass\",\n+        \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      spark.conf.set(\n+        \"spark.sql.streaming.stateStore.rocksDb.localDirectory\",\n+        Utils.createTempDir().getAbsoluteFile.toString)\n+      import spark.implicits._\n+      val inputData = MemoryStream[Int]\n+\n+      def runQueryAndGetLoadedProviders(): Seq[StateStoreProvider] = {\n+        val aggregated = inputData.toDF().groupBy(\"value\").agg(count(\"*\"))\n+        // stateful query\n+        val query = aggregated.writeStream\n+          .format(\"memory\")\n+          .outputMode(\"complete\")\n+          .queryName(\"query\")\n+          .option(\"checkpointLocation\", checkpointLocation.toString)\n+          .start()\n+        inputData.addData(1, 2, 3)\n+        query.processAllAvailable()\n+        require(query.lastProgress != null) // at least one batch processed after start\n+        val loadedProvidersMethod =\n+          PrivateMethod[mutable.HashMap[StateStoreProviderId, StateStoreProvider]](\n+            'loadedProviders)\n+        val loadedProvidersMap = StateStore invokePrivate loadedProvidersMethod()\n+        val loadedProviders = loadedProvidersMap.synchronized { loadedProvidersMap.values.toSeq }\n+        query.stop()\n+        loadedProviders\n+      }\n+\n+      val loadedProvidersAfterRun1 = runQueryAndGetLoadedProviders()\n+      require(loadedProvidersAfterRun1.length === 1)\n+\n+      val loadedProvidersAfterRun2 = runQueryAndGetLoadedProviders()\n+      assert(loadedProvidersAfterRun2.length === 2) // two providers loaded for 2 runs\n+\n+      // Both providers should have the same StateStoreId, but the should be different objects\n+      assert(\n+        loadedProvidersAfterRun2(0).stateStoreId === loadedProvidersAfterRun2(1).stateStoreId)\n+      assert(loadedProvidersAfterRun2(0) ne loadedProvidersAfterRun2(1))\n+\n+    } finally {\n+      SparkSession.getActiveSession.foreach { spark =>\n+        spark.streams.active.foreach(_.stop())\n+        spark.stop()\n+      }\n+    }\n+  }\n+\n+  override def newStoreProvider(): RocksDbStateStoreProvider = {\n+    newStoreProvider(opId = Random.nextInt(), partition = 0)\n+  }\n+\n+  override def newStoreProvider(storeId: StateStoreId): RocksDbStateStoreProvider = {\n+    newStoreProvider(\n+      storeId.operatorId,\n+      storeId.partitionId,\n+      dir = storeId.checkpointRootLocation)\n+  }\n+\n+  def newStoreProvider(storeId: StateStoreId, localDir: String): RocksDbStateStoreProvider = {\n+    newStoreProvider(\n+      storeId.operatorId,\n+      storeId.partitionId,\n+      dir = storeId.checkpointRootLocation,\n+      localDir = localDir)\n+  }\n+\n+  override def getLatestData(storeProvider: RocksDbStateStoreProvider): Set[(String, Int)] = {\n+    getData(storeProvider)\n+  }\n+\n+  override def getData(\n+      provider: RocksDbStateStoreProvider,\n+      version: Int = -1): Set[(String, Int)] = {\n+    val reloadedProvider = newStoreProvider(provider.stateStoreId, provider.getLocalDirectory)\n+    if (version < 0) {\n+      // TODO find out last version from rocksDB"
  }, {
    "author": {
      "login": "itsvikramagr"
    },
    "body": "Fixed.",
    "commit": "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "createdAt": "2019-07-08T10:18:38Z",
    "diffHunk": "@@ -0,0 +1,615 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import java.io.File\n+import java.util.UUID\n+\n+import org.apache.commons.io.FileUtils\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.Path\n+import org.scalatest.{BeforeAndAfter, PrivateMethodTester}\n+import org.scalatest.concurrent.Eventually.{eventually, timeout}\n+import org.scalatest.time.SpanSugar._\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.util.Random\n+\n+import org.apache.spark.{SparkConf, SparkContext, SparkEnv}\n+import org.apache.spark.LocalSparkContext.withSpark\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.catalyst.util.quietly\n+import org.apache.spark.sql.execution.streaming.MemoryStream\n+import org.apache.spark.sql.functions.count\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n+import org.apache.spark.util.Utils\n+\n+class RocksDbStateStoreSuite\n+    extends StateStoreSuiteBase[RocksDbStateStoreProvider]\n+    with BeforeAndAfter\n+    with PrivateMethodTester {\n+  type MapType = mutable.HashMap[UnsafeRow, UnsafeRow]\n+  type ProviderMapType = java.util.concurrent.ConcurrentHashMap[UnsafeRow, UnsafeRow]\n+\n+  import StateStoreCoordinatorSuite._\n+  import StateStoreTestsHelper._\n+\n+  val keySchema = StructType(Seq(StructField(\"key\", StringType, true)))\n+  val valueSchema = StructType(Seq(StructField(\"value\", IntegerType, true)))\n+\n+  before {\n+    StateStore.stop()\n+    require(!StateStore.isMaintenanceRunning)\n+  }\n+\n+  after {\n+    StateStore.stop()\n+    require(!StateStore.isMaintenanceRunning)\n+  }\n+\n+  def updateVersionTo(\n+      provider: StateStoreProvider,\n+      currentVersion: Int,\n+      targetVersion: Int): Int = {\n+    var newCurrentVersion = currentVersion\n+    for (i <- newCurrentVersion until targetVersion) {\n+      newCurrentVersion = incrementVersion(provider, i)\n+    }\n+    require(newCurrentVersion === targetVersion)\n+    newCurrentVersion\n+  }\n+\n+  def incrementVersion(provider: StateStoreProvider, currentVersion: Int): Int = {\n+    val store = provider.getStore(currentVersion)\n+    put(store, \"a\", currentVersion + 1)\n+    store.commit()\n+    currentVersion + 1\n+  }\n+\n+  def checkLoadedVersions(\n+      rocksDbWriteInstance: RocksDbInstance,\n+      count: Int,\n+      earliestKey: Long,\n+      latestKey: Long): Unit = {\n+    assert(rocksDbWriteInstance.iterator(false).length === count)\n+  }\n+\n+  def checkVersion(\n+      rocksDbWriteInstance: RocksDbInstance,\n+      version: Long,\n+      expectedData: Map[String, Int]): Unit = {\n+\n+    val originValueMap = rocksDbWriteInstance\n+      .iterator(false)\n+      .map { row =>\n+        rowToString(row.key) -> rowToInt(row.value)\n+      }\n+      .toMap[String, Int]\n+\n+    assert(originValueMap === expectedData)\n+  }\n+\n+  test(\"get, put, remove, commit, and all data iterator\") {\n+    val provider = newStoreProvider()\n+\n+    // Verify state before starting a new set of updates\n+    assert(getLatestData(provider).isEmpty)\n+\n+    val store = provider.getStore(0)\n+    assert(!store.hasCommitted)\n+    assert(get(store, \"a\") === None)\n+    assert(store.iterator().isEmpty)\n+\n+    // Verify state after updating\n+    put(store, \"a\", 1)\n+    assert(get(store, \"a\") === Some(1))\n+\n+    assert(store.iterator().nonEmpty)\n+    assert(getLatestData(provider).isEmpty)\n+\n+    // Make updates, commit and then verify state\n+    put(store, \"b\", 2)\n+    put(store, \"aa\", 3)\n+    remove(store, _.startsWith(\"a\"))\n+    assert(store.commit() === 1)\n+\n+    assert(store.hasCommitted)\n+    assert(rowsToSet(store.iterator()) === Set(\"b\" -> 2))\n+    assert(getLatestData(provider) === Set(\"b\" -> 2))\n+\n+    // Trying to get newer versions should fail\n+    intercept[Exception] {\n+      provider.getStore(2)\n+    }\n+    intercept[Exception] {\n+      getData(provider, 2)\n+    }\n+\n+    // New updates to the reloaded store with new version, and does not change old version\n+    val reloadedProvider = newStoreProvider(store.id, provider.getLocalDirectory)\n+    val reloadedStore = reloadedProvider.getStore(1)\n+    put(reloadedStore, \"c\", 4)\n+    assert(reloadedStore.commit() === 2)\n+    assert(rowsToSet(reloadedStore.iterator()) === Set(\"b\" -> 2, \"c\" -> 4))\n+    assert(getLatestData(provider) === Set(\"b\" -> 2, \"c\" -> 4))\n+    assert(getData(provider, version = 1) === Set(\"b\" -> 2))\n+  }\n+\n+  test(\"snapshotting\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+\n+    var currentVersion = 0\n+\n+    currentVersion = updateVersionTo(provider, currentVersion, 2)\n+    require(getData(provider) === Set(\"a\" -> 2))\n+    provider.doMaintenance() // should not generate snapshot files\n+    assert(getData(provider) === Set(\"a\" -> 2))\n+\n+    for (i <- 1 to currentVersion) {\n+      assert(fileExists(provider, i, isSnapshot = false)) // all delta files present\n+      assert(!fileExists(provider, i, isSnapshot = true)) // no snapshot files present\n+    }\n+\n+    // After version 6, snapshotting should generate one snapshot file\n+    currentVersion = updateVersionTo(provider, currentVersion, 6)\n+    require(getData(provider) === Set(\"a\" -> 6), \"store not updated correctly\")\n+    provider.doMaintenance() // should generate snapshot files\n+\n+    val snapshotVersion =\n+      (0 to 6).find(version => fileExists(provider, version, isSnapshot = true))\n+    assert(snapshotVersion.nonEmpty, \"snapshot file not generated\")\n+    deleteFilesEarlierThanVersion(provider, snapshotVersion.get)\n+    assert(\n+      getData(provider, snapshotVersion.get) === Set(\"a\" -> snapshotVersion.get),\n+      \"snapshotting messed up the data of the snapshotted version\")\n+    assert(\n+      getData(provider) === Set(\"a\" -> 6),\n+      \"snapshotting messed up the data of the final version\")\n+\n+    // After version 20, snapshotting should generate newer snapshot files\n+    currentVersion = updateVersionTo(provider, currentVersion, 20)\n+    require(getData(provider) === Set(\"a\" -> 20), \"store not updated correctly\")\n+    provider.doMaintenance() // do snapshot\n+\n+    val latestSnapshotVersion =\n+      (0 to 20).filter(version => fileExists(provider, version, isSnapshot = true)).lastOption\n+    assert(latestSnapshotVersion.nonEmpty, \"no snapshot file found\")\n+    assert(latestSnapshotVersion.get > snapshotVersion.get, \"newer snapshot not generated\")\n+\n+    deleteFilesEarlierThanVersion(provider, latestSnapshotVersion.get)\n+    assert(getData(provider) === Set(\"a\" -> 20), \"snapshotting messed up the data\")\n+  }\n+\n+  test(\"cleaning\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+\n+    for (i <- 1 to 20) {\n+      val store = provider.getStore(i - 1)\n+      put(store, \"a\", i)\n+      store.commit()\n+      provider.doMaintenance() // do cleanup\n+    }\n+    require(\n+      rowsToSet(provider.latestIterator()) === Set(\"a\" -> 20),\n+      \"store not updated correctly\")\n+\n+    assert(!fileExists(provider, version = 1, isSnapshot = false)) // first file should be deleted\n+\n+    // last couple of versions should be retrievable\n+    assert(getData(provider, 20) === Set(\"a\" -> 20))\n+    assert(getData(provider, 19) === Set(\"a\" -> 19))\n+  }\n+\n+  testQuietly(\"SPARK-19677: Committing a delta file atop an existing one should not fail on HDFS\") {\n+    val conf = new Configuration()\n+    conf.set(\"fs.fake.impl\", classOf[RenameLikeHDFSFileSystem].getName)\n+    conf.set(\"fs.defaultFS\", \"fake:///\")\n+\n+    val provider = newStoreProvider(opId = Random.nextInt, partition = 0, hadoopConf = conf)\n+    provider.getStore(0).commit()\n+    provider.getStore(0).commit()\n+\n+    // Verify we don't leak temp files\n+    val tempFiles = FileUtils\n+      .listFiles(new File(provider.stateStoreId.checkpointRootLocation), null, true)\n+      .asScala\n+      .filter(_.getName.startsWith(\"temp-\"))\n+    assert(tempFiles.isEmpty)\n+  }\n+\n+  test(\"corrupted file handling\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+    for (i <- 1 to 6) {\n+      val store = provider.getStore(i - 1)\n+      put(store, \"a\", i)\n+      store.commit()\n+      provider.doMaintenance() // do cleanup\n+    }\n+    val snapshotVersion = (0 to 10)\n+      .find(version => fileExists(provider, version, isSnapshot = true))\n+      .getOrElse(fail(\"snapshot file not found\"))\n+\n+    // Corrupt snapshot file and verify that it throws error\n+    provider.close()\n+    assert(getData(provider, snapshotVersion) === Set(\"a\" -> snapshotVersion))\n+    RocksDbInstance.destroyDB(provider.rocksDbPath)\n+\n+    corruptFile(provider, snapshotVersion, isSnapshot = true)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion)\n+    }\n+\n+    // Corrupt delta file and verify that it throws error\n+    provider.close()\n+    RocksDbInstance.destroyDB(provider.rocksDbPath)\n+    assert(getData(provider, snapshotVersion - 1) === Set(\"a\" -> (snapshotVersion - 1)))\n+\n+    corruptFile(provider, snapshotVersion - 1, isSnapshot = false)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion - 1)\n+    }\n+\n+    // Delete delta file and verify that it throws error\n+    deleteFilesEarlierThanVersion(provider, snapshotVersion)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion - 1)\n+    }\n+  }\n+\n+  test(\"StateStore.get\") {\n+    quietly {\n+      val dir = newDir()\n+      val storeId = StateStoreProviderId(StateStoreId(dir, 0, 0), UUID.randomUUID)\n+      val sqlConf = new SQLConf\n+      sqlConf.setConfString(\n+        \"spark.sql.streaming.stateStore.providerClass\",\n+        \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      val localdir = Utils.createTempDir().getAbsoluteFile.toString\n+      sqlConf.setConfString(\"spark.sql.streaming.stateStore.rocksDb.localDirectory\", localdir)\n+      val storeConf = new StateStoreConf(sqlConf)\n+      assert(\n+        storeConf.providerClass ===\n+          \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      val hadoopConf = new Configuration()\n+\n+      // Verify that trying to get incorrect versions throw errors\n+      intercept[IllegalArgumentException] {\n+        StateStore.get(storeId, keySchema, valueSchema, None, -1, storeConf, hadoopConf)\n+      }\n+      assert(!StateStore.isLoaded(storeId)) // version -1 should not attempt to load the store\n+\n+      intercept[IllegalStateException] {\n+        StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      }\n+\n+      // Increase version of the store and try to get again\n+      val store0 = StateStore.get(storeId, keySchema, valueSchema, None, 0, storeConf, hadoopConf)\n+      assert(store0.version === 0)\n+      put(store0, \"a\", 1)\n+      store0.commit()\n+\n+      val store1 = StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      assert(StateStore.isLoaded(storeId))\n+      assert(store1.version === 1)\n+      assert(rowsToSet(store1.iterator()) === Set(\"a\" -> 1))\n+\n+      // Verify that you can also load older version\n+      val store0reloaded =\n+        StateStore.get(storeId, keySchema, valueSchema, None, 0, storeConf, hadoopConf)\n+      assert(store0reloaded.version === 0)\n+      assert(rowsToSet(store0reloaded.iterator()) === Set.empty)\n+\n+      // Verify that you can remove the store and still reload and use it\n+      StateStore.unload(storeId)\n+      assert(!StateStore.isLoaded(storeId))\n+\n+      val store1reloaded =\n+        StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      assert(StateStore.isLoaded(storeId))\n+      assert(store1reloaded.version === 1)\n+      put(store1reloaded, \"a\", 2)\n+      assert(store1reloaded.commit() === 2)\n+      assert(rowsToSet(store1reloaded.iterator()) === Set(\"a\" -> 2))\n+    }\n+  }\n+\n+  test(\"maintenance\") {\n+    val conf = new SparkConf()\n+      .setMaster(\"local\")\n+      .setAppName(\"test\")\n+      // Make maintenance thread do snapshots and cleanups very fast\n+      .set(StateStore.MAINTENANCE_INTERVAL_CONFIG, \"10ms\")\n+      // Make sure that when SparkContext stops, the StateStore maintenance thread 'quickly'\n+      // fails to talk to the StateStoreCoordinator and unloads all the StateStores\n+      .set(\"spark.rpc.numRetries\", \"1\")\n+    val opId = 0\n+    val dir = newDir()\n+    val storeProviderId = StateStoreProviderId(StateStoreId(dir, opId, 0), UUID.randomUUID)\n+    val sqlConf = new SQLConf()\n+    sqlConf.setConfString(\n+      \"spark.sql.streaming.stateStore.providerClass\",\n+      \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+    sqlConf.setConf(SQLConf.MIN_BATCHES_TO_RETAIN, 2)\n+    sqlConf.setConfString(\n+      \"spark.sql.streaming.stateStore.rocksDb.localDirectory\",\n+      Utils.createTempDir().getAbsoluteFile.toString)\n+    val storeConf = StateStoreConf(sqlConf)\n+    val hadoopConf = new Configuration()\n+    val provider = newStoreProvider(storeProviderId.storeId)\n+\n+    var latestStoreVersion = 0\n+\n+    def generateStoreVersions() {\n+      for (i <- 1 to 20) {\n+        val store = StateStore.get(\n+          storeProviderId,\n+          keySchema,\n+          valueSchema,\n+          None,\n+          latestStoreVersion,\n+          storeConf,\n+          hadoopConf)\n+        put(store, \"a\", i)\n+        store.commit()\n+        latestStoreVersion += 1\n+      }\n+    }\n+\n+    val timeoutDuration = 60 seconds\n+\n+    quietly {\n+      withSpark(new SparkContext(conf)) { sc =>\n+        withCoordinatorRef(sc) { coordinatorRef =>\n+          require(!StateStore.isMaintenanceRunning, \"StateStore is unexpectedly running\")\n+\n+          // Generate sufficient versions of store for snapshots\n+          generateStoreVersions()\n+\n+          eventually(timeout(timeoutDuration)) {\n+            // Store should have been reported to the coordinator\n+            assert(\n+              coordinatorRef.getLocation(storeProviderId).nonEmpty,\n+              \"active instance was not reported\")\n+\n+            // Background maintenance should clean up and generate snapshots\n+            assert(StateStore.isMaintenanceRunning, \"Maintenance task is not running\")\n+\n+            // Some snapshots should have been generated\n+            val snapshotVersions = (1 to latestStoreVersion).filter { version =>\n+              fileExists(provider, version, isSnapshot = true)\n+            }\n+            assert(snapshotVersions.nonEmpty, \"no snapshot file found\")\n+          }\n+\n+          // Generate more versions such that there is another snapshot and\n+          // the earliest delta file will be cleaned up\n+          generateStoreVersions()\n+\n+          // Earliest delta file should get cleaned up\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!fileExists(provider, 1, isSnapshot = false), \"earliest file not deleted\")\n+          }\n+\n+          // If driver decides to deactivate all stores related to a query run,\n+          // then this instance should be unloaded\n+          coordinatorRef.deactivateInstances(storeProviderId.queryRunId)\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!StateStore.isLoaded(storeProviderId))\n+          }\n+\n+          // Reload the store and verify\n+          StateStore.get(\n+            storeProviderId,\n+            keySchema,\n+            valueSchema,\n+            indexOrdinal = None,\n+            latestStoreVersion,\n+            storeConf,\n+            hadoopConf)\n+          assert(StateStore.isLoaded(storeProviderId))\n+\n+          // If some other executor loads the store, then this instance should be unloaded\n+          coordinatorRef.reportActiveInstance(storeProviderId, \"other-host\", \"other-exec\")\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!StateStore.isLoaded(storeProviderId))\n+          }\n+\n+          // Reload the store and verify\n+          StateStore.get(\n+            storeProviderId,\n+            keySchema,\n+            valueSchema,\n+            indexOrdinal = None,\n+            latestStoreVersion,\n+            storeConf,\n+            hadoopConf)\n+          assert(StateStore.isLoaded(storeProviderId))\n+        }\n+      }\n+\n+      // Verify if instance is unloaded if SparkContext is stopped\n+      eventually(timeout(timeoutDuration)) {\n+        require(SparkEnv.get === null)\n+        assert(!StateStore.isLoaded(storeProviderId))\n+        assert(!StateStore.isMaintenanceRunning)\n+      }\n+    }\n+  }\n+\n+  test(\"SPARK-21145: Restarted queries create new provider instances\") {\n+    try {\n+      val checkpointLocation = Utils.createTempDir().getAbsoluteFile\n+      val spark = SparkSession.builder().master(\"local[2]\").getOrCreate()\n+      SparkSession.setActiveSession(spark)\n+      implicit val sqlContext = spark.sqlContext\n+      spark.conf.set(\"spark.sql.shuffle.partitions\", \"1\")\n+      spark.conf.set(\n+        \"spark.sql.streaming.stateStore.providerClass\",\n+        \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      spark.conf.set(\n+        \"spark.sql.streaming.stateStore.rocksDb.localDirectory\",\n+        Utils.createTempDir().getAbsoluteFile.toString)\n+      import spark.implicits._\n+      val inputData = MemoryStream[Int]\n+\n+      def runQueryAndGetLoadedProviders(): Seq[StateStoreProvider] = {\n+        val aggregated = inputData.toDF().groupBy(\"value\").agg(count(\"*\"))\n+        // stateful query\n+        val query = aggregated.writeStream\n+          .format(\"memory\")\n+          .outputMode(\"complete\")\n+          .queryName(\"query\")\n+          .option(\"checkpointLocation\", checkpointLocation.toString)\n+          .start()\n+        inputData.addData(1, 2, 3)\n+        query.processAllAvailable()\n+        require(query.lastProgress != null) // at least one batch processed after start\n+        val loadedProvidersMethod =\n+          PrivateMethod[mutable.HashMap[StateStoreProviderId, StateStoreProvider]](\n+            'loadedProviders)\n+        val loadedProvidersMap = StateStore invokePrivate loadedProvidersMethod()\n+        val loadedProviders = loadedProvidersMap.synchronized { loadedProvidersMap.values.toSeq }\n+        query.stop()\n+        loadedProviders\n+      }\n+\n+      val loadedProvidersAfterRun1 = runQueryAndGetLoadedProviders()\n+      require(loadedProvidersAfterRun1.length === 1)\n+\n+      val loadedProvidersAfterRun2 = runQueryAndGetLoadedProviders()\n+      assert(loadedProvidersAfterRun2.length === 2) // two providers loaded for 2 runs\n+\n+      // Both providers should have the same StateStoreId, but the should be different objects\n+      assert(\n+        loadedProvidersAfterRun2(0).stateStoreId === loadedProvidersAfterRun2(1).stateStoreId)\n+      assert(loadedProvidersAfterRun2(0) ne loadedProvidersAfterRun2(1))\n+\n+    } finally {\n+      SparkSession.getActiveSession.foreach { spark =>\n+        spark.streams.active.foreach(_.stop())\n+        spark.stop()\n+      }\n+    }\n+  }\n+\n+  override def newStoreProvider(): RocksDbStateStoreProvider = {\n+    newStoreProvider(opId = Random.nextInt(), partition = 0)\n+  }\n+\n+  override def newStoreProvider(storeId: StateStoreId): RocksDbStateStoreProvider = {\n+    newStoreProvider(\n+      storeId.operatorId,\n+      storeId.partitionId,\n+      dir = storeId.checkpointRootLocation)\n+  }\n+\n+  def newStoreProvider(storeId: StateStoreId, localDir: String): RocksDbStateStoreProvider = {\n+    newStoreProvider(\n+      storeId.operatorId,\n+      storeId.partitionId,\n+      dir = storeId.checkpointRootLocation,\n+      localDir = localDir)\n+  }\n+\n+  override def getLatestData(storeProvider: RocksDbStateStoreProvider): Set[(String, Int)] = {\n+    getData(storeProvider)\n+  }\n+\n+  override def getData(\n+      provider: RocksDbStateStoreProvider,\n+      version: Int = -1): Set[(String, Int)] = {\n+    val reloadedProvider = newStoreProvider(provider.stateStoreId, provider.getLocalDirectory)\n+    if (version < 0) {\n+      // TODO find out last version from rocksDB"
  }],
  "prId": 24922
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "This looks like basically copy and paste of StateStoreSuite with some configuration change to enable RocksDbStateStore. Though there're some tests which only make sense to HDFS state store, we should try to deduplicate these things. One good start point of deduplication is, once state store instance is given, we expect it would work similar regardless of provider.",
    "commit": "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "createdAt": "2019-07-01T00:26:54Z",
    "diffHunk": "@@ -0,0 +1,615 @@\n+/*",
    "line": 1
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "+1 on this, just reached this area and remarked the same things.\r\nI would vote on the same approach, let's assume it works the same way and make exceptions with a reason.\r\nYou can take a look at DSv1 and DSv2 tests, the common behavior is in the base class and the difference is in the specialized class.\r\n",
    "commit": "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "createdAt": "2019-07-05T12:49:22Z",
    "diffHunk": "@@ -0,0 +1,615 @@\n+/*",
    "line": 1
  }, {
    "author": {
      "login": "itsvikramagr"
    },
    "body": "Sure. Make sense. I am planning to fix other fixes (and provide performance numbers) before working on deduplicating the test-suite. Let me know if I should fix this first before working on anything else.",
    "commit": "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "createdAt": "2019-07-08T10:17:52Z",
    "diffHunk": "@@ -0,0 +1,615 @@\n+/*",
    "line": 1
  }],
  "prId": 24922
}, {
  "comments": [{
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "It's more safe to use `STATE_STORE_PROVIDER_CLASS.key`.",
    "commit": "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "createdAt": "2019-07-05T12:20:26Z",
    "diffHunk": "@@ -0,0 +1,615 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import java.io.File\n+import java.util.UUID\n+\n+import org.apache.commons.io.FileUtils\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.Path\n+import org.scalatest.{BeforeAndAfter, PrivateMethodTester}\n+import org.scalatest.concurrent.Eventually.{eventually, timeout}\n+import org.scalatest.time.SpanSugar._\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.util.Random\n+\n+import org.apache.spark.{SparkConf, SparkContext, SparkEnv}\n+import org.apache.spark.LocalSparkContext.withSpark\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.catalyst.util.quietly\n+import org.apache.spark.sql.execution.streaming.MemoryStream\n+import org.apache.spark.sql.functions.count\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n+import org.apache.spark.util.Utils\n+\n+class RocksDbStateStoreSuite\n+    extends StateStoreSuiteBase[RocksDbStateStoreProvider]\n+    with BeforeAndAfter\n+    with PrivateMethodTester {\n+  type MapType = mutable.HashMap[UnsafeRow, UnsafeRow]\n+  type ProviderMapType = java.util.concurrent.ConcurrentHashMap[UnsafeRow, UnsafeRow]\n+\n+  import StateStoreCoordinatorSuite._\n+  import StateStoreTestsHelper._\n+\n+  val keySchema = StructType(Seq(StructField(\"key\", StringType, true)))\n+  val valueSchema = StructType(Seq(StructField(\"value\", IntegerType, true)))\n+\n+  before {\n+    StateStore.stop()\n+    require(!StateStore.isMaintenanceRunning)\n+  }\n+\n+  after {\n+    StateStore.stop()\n+    require(!StateStore.isMaintenanceRunning)\n+  }\n+\n+  def updateVersionTo(\n+      provider: StateStoreProvider,\n+      currentVersion: Int,\n+      targetVersion: Int): Int = {\n+    var newCurrentVersion = currentVersion\n+    for (i <- newCurrentVersion until targetVersion) {\n+      newCurrentVersion = incrementVersion(provider, i)\n+    }\n+    require(newCurrentVersion === targetVersion)\n+    newCurrentVersion\n+  }\n+\n+  def incrementVersion(provider: StateStoreProvider, currentVersion: Int): Int = {\n+    val store = provider.getStore(currentVersion)\n+    put(store, \"a\", currentVersion + 1)\n+    store.commit()\n+    currentVersion + 1\n+  }\n+\n+  def checkLoadedVersions(\n+      rocksDbWriteInstance: RocksDbInstance,\n+      count: Int,\n+      earliestKey: Long,\n+      latestKey: Long): Unit = {\n+    assert(rocksDbWriteInstance.iterator(false).length === count)\n+  }\n+\n+  def checkVersion(\n+      rocksDbWriteInstance: RocksDbInstance,\n+      version: Long,\n+      expectedData: Map[String, Int]): Unit = {\n+\n+    val originValueMap = rocksDbWriteInstance\n+      .iterator(false)\n+      .map { row =>\n+        rowToString(row.key) -> rowToInt(row.value)\n+      }\n+      .toMap[String, Int]\n+\n+    assert(originValueMap === expectedData)\n+  }\n+\n+  test(\"get, put, remove, commit, and all data iterator\") {\n+    val provider = newStoreProvider()\n+\n+    // Verify state before starting a new set of updates\n+    assert(getLatestData(provider).isEmpty)\n+\n+    val store = provider.getStore(0)\n+    assert(!store.hasCommitted)\n+    assert(get(store, \"a\") === None)\n+    assert(store.iterator().isEmpty)\n+\n+    // Verify state after updating\n+    put(store, \"a\", 1)\n+    assert(get(store, \"a\") === Some(1))\n+\n+    assert(store.iterator().nonEmpty)\n+    assert(getLatestData(provider).isEmpty)\n+\n+    // Make updates, commit and then verify state\n+    put(store, \"b\", 2)\n+    put(store, \"aa\", 3)\n+    remove(store, _.startsWith(\"a\"))\n+    assert(store.commit() === 1)\n+\n+    assert(store.hasCommitted)\n+    assert(rowsToSet(store.iterator()) === Set(\"b\" -> 2))\n+    assert(getLatestData(provider) === Set(\"b\" -> 2))\n+\n+    // Trying to get newer versions should fail\n+    intercept[Exception] {\n+      provider.getStore(2)\n+    }\n+    intercept[Exception] {\n+      getData(provider, 2)\n+    }\n+\n+    // New updates to the reloaded store with new version, and does not change old version\n+    val reloadedProvider = newStoreProvider(store.id, provider.getLocalDirectory)\n+    val reloadedStore = reloadedProvider.getStore(1)\n+    put(reloadedStore, \"c\", 4)\n+    assert(reloadedStore.commit() === 2)\n+    assert(rowsToSet(reloadedStore.iterator()) === Set(\"b\" -> 2, \"c\" -> 4))\n+    assert(getLatestData(provider) === Set(\"b\" -> 2, \"c\" -> 4))\n+    assert(getData(provider, version = 1) === Set(\"b\" -> 2))\n+  }\n+\n+  test(\"snapshotting\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+\n+    var currentVersion = 0\n+\n+    currentVersion = updateVersionTo(provider, currentVersion, 2)\n+    require(getData(provider) === Set(\"a\" -> 2))\n+    provider.doMaintenance() // should not generate snapshot files\n+    assert(getData(provider) === Set(\"a\" -> 2))\n+\n+    for (i <- 1 to currentVersion) {\n+      assert(fileExists(provider, i, isSnapshot = false)) // all delta files present\n+      assert(!fileExists(provider, i, isSnapshot = true)) // no snapshot files present\n+    }\n+\n+    // After version 6, snapshotting should generate one snapshot file\n+    currentVersion = updateVersionTo(provider, currentVersion, 6)\n+    require(getData(provider) === Set(\"a\" -> 6), \"store not updated correctly\")\n+    provider.doMaintenance() // should generate snapshot files\n+\n+    val snapshotVersion =\n+      (0 to 6).find(version => fileExists(provider, version, isSnapshot = true))\n+    assert(snapshotVersion.nonEmpty, \"snapshot file not generated\")\n+    deleteFilesEarlierThanVersion(provider, snapshotVersion.get)\n+    assert(\n+      getData(provider, snapshotVersion.get) === Set(\"a\" -> snapshotVersion.get),\n+      \"snapshotting messed up the data of the snapshotted version\")\n+    assert(\n+      getData(provider) === Set(\"a\" -> 6),\n+      \"snapshotting messed up the data of the final version\")\n+\n+    // After version 20, snapshotting should generate newer snapshot files\n+    currentVersion = updateVersionTo(provider, currentVersion, 20)\n+    require(getData(provider) === Set(\"a\" -> 20), \"store not updated correctly\")\n+    provider.doMaintenance() // do snapshot\n+\n+    val latestSnapshotVersion =\n+      (0 to 20).filter(version => fileExists(provider, version, isSnapshot = true)).lastOption\n+    assert(latestSnapshotVersion.nonEmpty, \"no snapshot file found\")\n+    assert(latestSnapshotVersion.get > snapshotVersion.get, \"newer snapshot not generated\")\n+\n+    deleteFilesEarlierThanVersion(provider, latestSnapshotVersion.get)\n+    assert(getData(provider) === Set(\"a\" -> 20), \"snapshotting messed up the data\")\n+  }\n+\n+  test(\"cleaning\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+\n+    for (i <- 1 to 20) {\n+      val store = provider.getStore(i - 1)\n+      put(store, \"a\", i)\n+      store.commit()\n+      provider.doMaintenance() // do cleanup\n+    }\n+    require(\n+      rowsToSet(provider.latestIterator()) === Set(\"a\" -> 20),\n+      \"store not updated correctly\")\n+\n+    assert(!fileExists(provider, version = 1, isSnapshot = false)) // first file should be deleted\n+\n+    // last couple of versions should be retrievable\n+    assert(getData(provider, 20) === Set(\"a\" -> 20))\n+    assert(getData(provider, 19) === Set(\"a\" -> 19))\n+  }\n+\n+  testQuietly(\"SPARK-19677: Committing a delta file atop an existing one should not fail on HDFS\") {\n+    val conf = new Configuration()\n+    conf.set(\"fs.fake.impl\", classOf[RenameLikeHDFSFileSystem].getName)\n+    conf.set(\"fs.defaultFS\", \"fake:///\")\n+\n+    val provider = newStoreProvider(opId = Random.nextInt, partition = 0, hadoopConf = conf)\n+    provider.getStore(0).commit()\n+    provider.getStore(0).commit()\n+\n+    // Verify we don't leak temp files\n+    val tempFiles = FileUtils\n+      .listFiles(new File(provider.stateStoreId.checkpointRootLocation), null, true)\n+      .asScala\n+      .filter(_.getName.startsWith(\"temp-\"))\n+    assert(tempFiles.isEmpty)\n+  }\n+\n+  test(\"corrupted file handling\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+    for (i <- 1 to 6) {\n+      val store = provider.getStore(i - 1)\n+      put(store, \"a\", i)\n+      store.commit()\n+      provider.doMaintenance() // do cleanup\n+    }\n+    val snapshotVersion = (0 to 10)\n+      .find(version => fileExists(provider, version, isSnapshot = true))\n+      .getOrElse(fail(\"snapshot file not found\"))\n+\n+    // Corrupt snapshot file and verify that it throws error\n+    provider.close()\n+    assert(getData(provider, snapshotVersion) === Set(\"a\" -> snapshotVersion))\n+    RocksDbInstance.destroyDB(provider.rocksDbPath)\n+\n+    corruptFile(provider, snapshotVersion, isSnapshot = true)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion)\n+    }\n+\n+    // Corrupt delta file and verify that it throws error\n+    provider.close()\n+    RocksDbInstance.destroyDB(provider.rocksDbPath)\n+    assert(getData(provider, snapshotVersion - 1) === Set(\"a\" -> (snapshotVersion - 1)))\n+\n+    corruptFile(provider, snapshotVersion - 1, isSnapshot = false)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion - 1)\n+    }\n+\n+    // Delete delta file and verify that it throws error\n+    deleteFilesEarlierThanVersion(provider, snapshotVersion)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion - 1)\n+    }\n+  }\n+\n+  test(\"StateStore.get\") {\n+    quietly {\n+      val dir = newDir()\n+      val storeId = StateStoreProviderId(StateStoreId(dir, 0, 0), UUID.randomUUID)\n+      val sqlConf = new SQLConf\n+      sqlConf.setConfString(\n+        \"spark.sql.streaming.stateStore.providerClass\",\n+        \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      val localdir = Utils.createTempDir().getAbsoluteFile.toString\n+      sqlConf.setConfString(\"spark.sql.streaming.stateStore.rocksDb.localDirectory\", localdir)\n+      val storeConf = new StateStoreConf(sqlConf)\n+      assert(\n+        storeConf.providerClass ===\n+          \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      val hadoopConf = new Configuration()\n+\n+      // Verify that trying to get incorrect versions throw errors\n+      intercept[IllegalArgumentException] {\n+        StateStore.get(storeId, keySchema, valueSchema, None, -1, storeConf, hadoopConf)\n+      }\n+      assert(!StateStore.isLoaded(storeId)) // version -1 should not attempt to load the store\n+\n+      intercept[IllegalStateException] {\n+        StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      }\n+\n+      // Increase version of the store and try to get again\n+      val store0 = StateStore.get(storeId, keySchema, valueSchema, None, 0, storeConf, hadoopConf)\n+      assert(store0.version === 0)\n+      put(store0, \"a\", 1)\n+      store0.commit()\n+\n+      val store1 = StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      assert(StateStore.isLoaded(storeId))\n+      assert(store1.version === 1)\n+      assert(rowsToSet(store1.iterator()) === Set(\"a\" -> 1))\n+\n+      // Verify that you can also load older version\n+      val store0reloaded =\n+        StateStore.get(storeId, keySchema, valueSchema, None, 0, storeConf, hadoopConf)\n+      assert(store0reloaded.version === 0)\n+      assert(rowsToSet(store0reloaded.iterator()) === Set.empty)\n+\n+      // Verify that you can remove the store and still reload and use it\n+      StateStore.unload(storeId)\n+      assert(!StateStore.isLoaded(storeId))\n+\n+      val store1reloaded =\n+        StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      assert(StateStore.isLoaded(storeId))\n+      assert(store1reloaded.version === 1)\n+      put(store1reloaded, \"a\", 2)\n+      assert(store1reloaded.commit() === 2)\n+      assert(rowsToSet(store1reloaded.iterator()) === Set(\"a\" -> 2))\n+    }\n+  }\n+\n+  test(\"maintenance\") {\n+    val conf = new SparkConf()\n+      .setMaster(\"local\")\n+      .setAppName(\"test\")\n+      // Make maintenance thread do snapshots and cleanups very fast\n+      .set(StateStore.MAINTENANCE_INTERVAL_CONFIG, \"10ms\")\n+      // Make sure that when SparkContext stops, the StateStore maintenance thread 'quickly'\n+      // fails to talk to the StateStoreCoordinator and unloads all the StateStores\n+      .set(\"spark.rpc.numRetries\", \"1\")\n+    val opId = 0\n+    val dir = newDir()\n+    val storeProviderId = StateStoreProviderId(StateStoreId(dir, opId, 0), UUID.randomUUID)\n+    val sqlConf = new SQLConf()\n+    sqlConf.setConfString(\n+      \"spark.sql.streaming.stateStore.providerClass\",\n+      \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+    sqlConf.setConf(SQLConf.MIN_BATCHES_TO_RETAIN, 2)\n+    sqlConf.setConfString(\n+      \"spark.sql.streaming.stateStore.rocksDb.localDirectory\",\n+      Utils.createTempDir().getAbsoluteFile.toString)\n+    val storeConf = StateStoreConf(sqlConf)\n+    val hadoopConf = new Configuration()\n+    val provider = newStoreProvider(storeProviderId.storeId)\n+\n+    var latestStoreVersion = 0\n+\n+    def generateStoreVersions() {\n+      for (i <- 1 to 20) {\n+        val store = StateStore.get(\n+          storeProviderId,\n+          keySchema,\n+          valueSchema,\n+          None,\n+          latestStoreVersion,\n+          storeConf,\n+          hadoopConf)\n+        put(store, \"a\", i)\n+        store.commit()\n+        latestStoreVersion += 1\n+      }\n+    }\n+\n+    val timeoutDuration = 60 seconds\n+\n+    quietly {\n+      withSpark(new SparkContext(conf)) { sc =>\n+        withCoordinatorRef(sc) { coordinatorRef =>\n+          require(!StateStore.isMaintenanceRunning, \"StateStore is unexpectedly running\")\n+\n+          // Generate sufficient versions of store for snapshots\n+          generateStoreVersions()\n+\n+          eventually(timeout(timeoutDuration)) {\n+            // Store should have been reported to the coordinator\n+            assert(\n+              coordinatorRef.getLocation(storeProviderId).nonEmpty,\n+              \"active instance was not reported\")\n+\n+            // Background maintenance should clean up and generate snapshots\n+            assert(StateStore.isMaintenanceRunning, \"Maintenance task is not running\")\n+\n+            // Some snapshots should have been generated\n+            val snapshotVersions = (1 to latestStoreVersion).filter { version =>\n+              fileExists(provider, version, isSnapshot = true)\n+            }\n+            assert(snapshotVersions.nonEmpty, \"no snapshot file found\")\n+          }\n+\n+          // Generate more versions such that there is another snapshot and\n+          // the earliest delta file will be cleaned up\n+          generateStoreVersions()\n+\n+          // Earliest delta file should get cleaned up\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!fileExists(provider, 1, isSnapshot = false), \"earliest file not deleted\")\n+          }\n+\n+          // If driver decides to deactivate all stores related to a query run,\n+          // then this instance should be unloaded\n+          coordinatorRef.deactivateInstances(storeProviderId.queryRunId)\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!StateStore.isLoaded(storeProviderId))\n+          }\n+\n+          // Reload the store and verify\n+          StateStore.get(\n+            storeProviderId,\n+            keySchema,\n+            valueSchema,\n+            indexOrdinal = None,\n+            latestStoreVersion,\n+            storeConf,\n+            hadoopConf)\n+          assert(StateStore.isLoaded(storeProviderId))\n+\n+          // If some other executor loads the store, then this instance should be unloaded\n+          coordinatorRef.reportActiveInstance(storeProviderId, \"other-host\", \"other-exec\")\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!StateStore.isLoaded(storeProviderId))\n+          }\n+\n+          // Reload the store and verify\n+          StateStore.get(\n+            storeProviderId,\n+            keySchema,\n+            valueSchema,\n+            indexOrdinal = None,\n+            latestStoreVersion,\n+            storeConf,\n+            hadoopConf)\n+          assert(StateStore.isLoaded(storeProviderId))\n+        }\n+      }\n+\n+      // Verify if instance is unloaded if SparkContext is stopped\n+      eventually(timeout(timeoutDuration)) {\n+        require(SparkEnv.get === null)\n+        assert(!StateStore.isLoaded(storeProviderId))\n+        assert(!StateStore.isMaintenanceRunning)\n+      }\n+    }\n+  }\n+\n+  test(\"SPARK-21145: Restarted queries create new provider instances\") {\n+    try {\n+      val checkpointLocation = Utils.createTempDir().getAbsoluteFile\n+      val spark = SparkSession.builder().master(\"local[2]\").getOrCreate()\n+      SparkSession.setActiveSession(spark)\n+      implicit val sqlContext = spark.sqlContext\n+      spark.conf.set(\"spark.sql.shuffle.partitions\", \"1\")\n+      spark.conf.set(\n+        \"spark.sql.streaming.stateStore.providerClass\","
  }, {
    "author": {
      "login": "itsvikramagr"
    },
    "body": "will make the change.",
    "commit": "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "createdAt": "2019-07-08T10:31:59Z",
    "diffHunk": "@@ -0,0 +1,615 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import java.io.File\n+import java.util.UUID\n+\n+import org.apache.commons.io.FileUtils\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.Path\n+import org.scalatest.{BeforeAndAfter, PrivateMethodTester}\n+import org.scalatest.concurrent.Eventually.{eventually, timeout}\n+import org.scalatest.time.SpanSugar._\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.util.Random\n+\n+import org.apache.spark.{SparkConf, SparkContext, SparkEnv}\n+import org.apache.spark.LocalSparkContext.withSpark\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.catalyst.util.quietly\n+import org.apache.spark.sql.execution.streaming.MemoryStream\n+import org.apache.spark.sql.functions.count\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n+import org.apache.spark.util.Utils\n+\n+class RocksDbStateStoreSuite\n+    extends StateStoreSuiteBase[RocksDbStateStoreProvider]\n+    with BeforeAndAfter\n+    with PrivateMethodTester {\n+  type MapType = mutable.HashMap[UnsafeRow, UnsafeRow]\n+  type ProviderMapType = java.util.concurrent.ConcurrentHashMap[UnsafeRow, UnsafeRow]\n+\n+  import StateStoreCoordinatorSuite._\n+  import StateStoreTestsHelper._\n+\n+  val keySchema = StructType(Seq(StructField(\"key\", StringType, true)))\n+  val valueSchema = StructType(Seq(StructField(\"value\", IntegerType, true)))\n+\n+  before {\n+    StateStore.stop()\n+    require(!StateStore.isMaintenanceRunning)\n+  }\n+\n+  after {\n+    StateStore.stop()\n+    require(!StateStore.isMaintenanceRunning)\n+  }\n+\n+  def updateVersionTo(\n+      provider: StateStoreProvider,\n+      currentVersion: Int,\n+      targetVersion: Int): Int = {\n+    var newCurrentVersion = currentVersion\n+    for (i <- newCurrentVersion until targetVersion) {\n+      newCurrentVersion = incrementVersion(provider, i)\n+    }\n+    require(newCurrentVersion === targetVersion)\n+    newCurrentVersion\n+  }\n+\n+  def incrementVersion(provider: StateStoreProvider, currentVersion: Int): Int = {\n+    val store = provider.getStore(currentVersion)\n+    put(store, \"a\", currentVersion + 1)\n+    store.commit()\n+    currentVersion + 1\n+  }\n+\n+  def checkLoadedVersions(\n+      rocksDbWriteInstance: RocksDbInstance,\n+      count: Int,\n+      earliestKey: Long,\n+      latestKey: Long): Unit = {\n+    assert(rocksDbWriteInstance.iterator(false).length === count)\n+  }\n+\n+  def checkVersion(\n+      rocksDbWriteInstance: RocksDbInstance,\n+      version: Long,\n+      expectedData: Map[String, Int]): Unit = {\n+\n+    val originValueMap = rocksDbWriteInstance\n+      .iterator(false)\n+      .map { row =>\n+        rowToString(row.key) -> rowToInt(row.value)\n+      }\n+      .toMap[String, Int]\n+\n+    assert(originValueMap === expectedData)\n+  }\n+\n+  test(\"get, put, remove, commit, and all data iterator\") {\n+    val provider = newStoreProvider()\n+\n+    // Verify state before starting a new set of updates\n+    assert(getLatestData(provider).isEmpty)\n+\n+    val store = provider.getStore(0)\n+    assert(!store.hasCommitted)\n+    assert(get(store, \"a\") === None)\n+    assert(store.iterator().isEmpty)\n+\n+    // Verify state after updating\n+    put(store, \"a\", 1)\n+    assert(get(store, \"a\") === Some(1))\n+\n+    assert(store.iterator().nonEmpty)\n+    assert(getLatestData(provider).isEmpty)\n+\n+    // Make updates, commit and then verify state\n+    put(store, \"b\", 2)\n+    put(store, \"aa\", 3)\n+    remove(store, _.startsWith(\"a\"))\n+    assert(store.commit() === 1)\n+\n+    assert(store.hasCommitted)\n+    assert(rowsToSet(store.iterator()) === Set(\"b\" -> 2))\n+    assert(getLatestData(provider) === Set(\"b\" -> 2))\n+\n+    // Trying to get newer versions should fail\n+    intercept[Exception] {\n+      provider.getStore(2)\n+    }\n+    intercept[Exception] {\n+      getData(provider, 2)\n+    }\n+\n+    // New updates to the reloaded store with new version, and does not change old version\n+    val reloadedProvider = newStoreProvider(store.id, provider.getLocalDirectory)\n+    val reloadedStore = reloadedProvider.getStore(1)\n+    put(reloadedStore, \"c\", 4)\n+    assert(reloadedStore.commit() === 2)\n+    assert(rowsToSet(reloadedStore.iterator()) === Set(\"b\" -> 2, \"c\" -> 4))\n+    assert(getLatestData(provider) === Set(\"b\" -> 2, \"c\" -> 4))\n+    assert(getData(provider, version = 1) === Set(\"b\" -> 2))\n+  }\n+\n+  test(\"snapshotting\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+\n+    var currentVersion = 0\n+\n+    currentVersion = updateVersionTo(provider, currentVersion, 2)\n+    require(getData(provider) === Set(\"a\" -> 2))\n+    provider.doMaintenance() // should not generate snapshot files\n+    assert(getData(provider) === Set(\"a\" -> 2))\n+\n+    for (i <- 1 to currentVersion) {\n+      assert(fileExists(provider, i, isSnapshot = false)) // all delta files present\n+      assert(!fileExists(provider, i, isSnapshot = true)) // no snapshot files present\n+    }\n+\n+    // After version 6, snapshotting should generate one snapshot file\n+    currentVersion = updateVersionTo(provider, currentVersion, 6)\n+    require(getData(provider) === Set(\"a\" -> 6), \"store not updated correctly\")\n+    provider.doMaintenance() // should generate snapshot files\n+\n+    val snapshotVersion =\n+      (0 to 6).find(version => fileExists(provider, version, isSnapshot = true))\n+    assert(snapshotVersion.nonEmpty, \"snapshot file not generated\")\n+    deleteFilesEarlierThanVersion(provider, snapshotVersion.get)\n+    assert(\n+      getData(provider, snapshotVersion.get) === Set(\"a\" -> snapshotVersion.get),\n+      \"snapshotting messed up the data of the snapshotted version\")\n+    assert(\n+      getData(provider) === Set(\"a\" -> 6),\n+      \"snapshotting messed up the data of the final version\")\n+\n+    // After version 20, snapshotting should generate newer snapshot files\n+    currentVersion = updateVersionTo(provider, currentVersion, 20)\n+    require(getData(provider) === Set(\"a\" -> 20), \"store not updated correctly\")\n+    provider.doMaintenance() // do snapshot\n+\n+    val latestSnapshotVersion =\n+      (0 to 20).filter(version => fileExists(provider, version, isSnapshot = true)).lastOption\n+    assert(latestSnapshotVersion.nonEmpty, \"no snapshot file found\")\n+    assert(latestSnapshotVersion.get > snapshotVersion.get, \"newer snapshot not generated\")\n+\n+    deleteFilesEarlierThanVersion(provider, latestSnapshotVersion.get)\n+    assert(getData(provider) === Set(\"a\" -> 20), \"snapshotting messed up the data\")\n+  }\n+\n+  test(\"cleaning\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+\n+    for (i <- 1 to 20) {\n+      val store = provider.getStore(i - 1)\n+      put(store, \"a\", i)\n+      store.commit()\n+      provider.doMaintenance() // do cleanup\n+    }\n+    require(\n+      rowsToSet(provider.latestIterator()) === Set(\"a\" -> 20),\n+      \"store not updated correctly\")\n+\n+    assert(!fileExists(provider, version = 1, isSnapshot = false)) // first file should be deleted\n+\n+    // last couple of versions should be retrievable\n+    assert(getData(provider, 20) === Set(\"a\" -> 20))\n+    assert(getData(provider, 19) === Set(\"a\" -> 19))\n+  }\n+\n+  testQuietly(\"SPARK-19677: Committing a delta file atop an existing one should not fail on HDFS\") {\n+    val conf = new Configuration()\n+    conf.set(\"fs.fake.impl\", classOf[RenameLikeHDFSFileSystem].getName)\n+    conf.set(\"fs.defaultFS\", \"fake:///\")\n+\n+    val provider = newStoreProvider(opId = Random.nextInt, partition = 0, hadoopConf = conf)\n+    provider.getStore(0).commit()\n+    provider.getStore(0).commit()\n+\n+    // Verify we don't leak temp files\n+    val tempFiles = FileUtils\n+      .listFiles(new File(provider.stateStoreId.checkpointRootLocation), null, true)\n+      .asScala\n+      .filter(_.getName.startsWith(\"temp-\"))\n+    assert(tempFiles.isEmpty)\n+  }\n+\n+  test(\"corrupted file handling\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+    for (i <- 1 to 6) {\n+      val store = provider.getStore(i - 1)\n+      put(store, \"a\", i)\n+      store.commit()\n+      provider.doMaintenance() // do cleanup\n+    }\n+    val snapshotVersion = (0 to 10)\n+      .find(version => fileExists(provider, version, isSnapshot = true))\n+      .getOrElse(fail(\"snapshot file not found\"))\n+\n+    // Corrupt snapshot file and verify that it throws error\n+    provider.close()\n+    assert(getData(provider, snapshotVersion) === Set(\"a\" -> snapshotVersion))\n+    RocksDbInstance.destroyDB(provider.rocksDbPath)\n+\n+    corruptFile(provider, snapshotVersion, isSnapshot = true)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion)\n+    }\n+\n+    // Corrupt delta file and verify that it throws error\n+    provider.close()\n+    RocksDbInstance.destroyDB(provider.rocksDbPath)\n+    assert(getData(provider, snapshotVersion - 1) === Set(\"a\" -> (snapshotVersion - 1)))\n+\n+    corruptFile(provider, snapshotVersion - 1, isSnapshot = false)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion - 1)\n+    }\n+\n+    // Delete delta file and verify that it throws error\n+    deleteFilesEarlierThanVersion(provider, snapshotVersion)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion - 1)\n+    }\n+  }\n+\n+  test(\"StateStore.get\") {\n+    quietly {\n+      val dir = newDir()\n+      val storeId = StateStoreProviderId(StateStoreId(dir, 0, 0), UUID.randomUUID)\n+      val sqlConf = new SQLConf\n+      sqlConf.setConfString(\n+        \"spark.sql.streaming.stateStore.providerClass\",\n+        \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      val localdir = Utils.createTempDir().getAbsoluteFile.toString\n+      sqlConf.setConfString(\"spark.sql.streaming.stateStore.rocksDb.localDirectory\", localdir)\n+      val storeConf = new StateStoreConf(sqlConf)\n+      assert(\n+        storeConf.providerClass ===\n+          \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      val hadoopConf = new Configuration()\n+\n+      // Verify that trying to get incorrect versions throw errors\n+      intercept[IllegalArgumentException] {\n+        StateStore.get(storeId, keySchema, valueSchema, None, -1, storeConf, hadoopConf)\n+      }\n+      assert(!StateStore.isLoaded(storeId)) // version -1 should not attempt to load the store\n+\n+      intercept[IllegalStateException] {\n+        StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      }\n+\n+      // Increase version of the store and try to get again\n+      val store0 = StateStore.get(storeId, keySchema, valueSchema, None, 0, storeConf, hadoopConf)\n+      assert(store0.version === 0)\n+      put(store0, \"a\", 1)\n+      store0.commit()\n+\n+      val store1 = StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      assert(StateStore.isLoaded(storeId))\n+      assert(store1.version === 1)\n+      assert(rowsToSet(store1.iterator()) === Set(\"a\" -> 1))\n+\n+      // Verify that you can also load older version\n+      val store0reloaded =\n+        StateStore.get(storeId, keySchema, valueSchema, None, 0, storeConf, hadoopConf)\n+      assert(store0reloaded.version === 0)\n+      assert(rowsToSet(store0reloaded.iterator()) === Set.empty)\n+\n+      // Verify that you can remove the store and still reload and use it\n+      StateStore.unload(storeId)\n+      assert(!StateStore.isLoaded(storeId))\n+\n+      val store1reloaded =\n+        StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      assert(StateStore.isLoaded(storeId))\n+      assert(store1reloaded.version === 1)\n+      put(store1reloaded, \"a\", 2)\n+      assert(store1reloaded.commit() === 2)\n+      assert(rowsToSet(store1reloaded.iterator()) === Set(\"a\" -> 2))\n+    }\n+  }\n+\n+  test(\"maintenance\") {\n+    val conf = new SparkConf()\n+      .setMaster(\"local\")\n+      .setAppName(\"test\")\n+      // Make maintenance thread do snapshots and cleanups very fast\n+      .set(StateStore.MAINTENANCE_INTERVAL_CONFIG, \"10ms\")\n+      // Make sure that when SparkContext stops, the StateStore maintenance thread 'quickly'\n+      // fails to talk to the StateStoreCoordinator and unloads all the StateStores\n+      .set(\"spark.rpc.numRetries\", \"1\")\n+    val opId = 0\n+    val dir = newDir()\n+    val storeProviderId = StateStoreProviderId(StateStoreId(dir, opId, 0), UUID.randomUUID)\n+    val sqlConf = new SQLConf()\n+    sqlConf.setConfString(\n+      \"spark.sql.streaming.stateStore.providerClass\",\n+      \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+    sqlConf.setConf(SQLConf.MIN_BATCHES_TO_RETAIN, 2)\n+    sqlConf.setConfString(\n+      \"spark.sql.streaming.stateStore.rocksDb.localDirectory\",\n+      Utils.createTempDir().getAbsoluteFile.toString)\n+    val storeConf = StateStoreConf(sqlConf)\n+    val hadoopConf = new Configuration()\n+    val provider = newStoreProvider(storeProviderId.storeId)\n+\n+    var latestStoreVersion = 0\n+\n+    def generateStoreVersions() {\n+      for (i <- 1 to 20) {\n+        val store = StateStore.get(\n+          storeProviderId,\n+          keySchema,\n+          valueSchema,\n+          None,\n+          latestStoreVersion,\n+          storeConf,\n+          hadoopConf)\n+        put(store, \"a\", i)\n+        store.commit()\n+        latestStoreVersion += 1\n+      }\n+    }\n+\n+    val timeoutDuration = 60 seconds\n+\n+    quietly {\n+      withSpark(new SparkContext(conf)) { sc =>\n+        withCoordinatorRef(sc) { coordinatorRef =>\n+          require(!StateStore.isMaintenanceRunning, \"StateStore is unexpectedly running\")\n+\n+          // Generate sufficient versions of store for snapshots\n+          generateStoreVersions()\n+\n+          eventually(timeout(timeoutDuration)) {\n+            // Store should have been reported to the coordinator\n+            assert(\n+              coordinatorRef.getLocation(storeProviderId).nonEmpty,\n+              \"active instance was not reported\")\n+\n+            // Background maintenance should clean up and generate snapshots\n+            assert(StateStore.isMaintenanceRunning, \"Maintenance task is not running\")\n+\n+            // Some snapshots should have been generated\n+            val snapshotVersions = (1 to latestStoreVersion).filter { version =>\n+              fileExists(provider, version, isSnapshot = true)\n+            }\n+            assert(snapshotVersions.nonEmpty, \"no snapshot file found\")\n+          }\n+\n+          // Generate more versions such that there is another snapshot and\n+          // the earliest delta file will be cleaned up\n+          generateStoreVersions()\n+\n+          // Earliest delta file should get cleaned up\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!fileExists(provider, 1, isSnapshot = false), \"earliest file not deleted\")\n+          }\n+\n+          // If driver decides to deactivate all stores related to a query run,\n+          // then this instance should be unloaded\n+          coordinatorRef.deactivateInstances(storeProviderId.queryRunId)\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!StateStore.isLoaded(storeProviderId))\n+          }\n+\n+          // Reload the store and verify\n+          StateStore.get(\n+            storeProviderId,\n+            keySchema,\n+            valueSchema,\n+            indexOrdinal = None,\n+            latestStoreVersion,\n+            storeConf,\n+            hadoopConf)\n+          assert(StateStore.isLoaded(storeProviderId))\n+\n+          // If some other executor loads the store, then this instance should be unloaded\n+          coordinatorRef.reportActiveInstance(storeProviderId, \"other-host\", \"other-exec\")\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!StateStore.isLoaded(storeProviderId))\n+          }\n+\n+          // Reload the store and verify\n+          StateStore.get(\n+            storeProviderId,\n+            keySchema,\n+            valueSchema,\n+            indexOrdinal = None,\n+            latestStoreVersion,\n+            storeConf,\n+            hadoopConf)\n+          assert(StateStore.isLoaded(storeProviderId))\n+        }\n+      }\n+\n+      // Verify if instance is unloaded if SparkContext is stopped\n+      eventually(timeout(timeoutDuration)) {\n+        require(SparkEnv.get === null)\n+        assert(!StateStore.isLoaded(storeProviderId))\n+        assert(!StateStore.isMaintenanceRunning)\n+      }\n+    }\n+  }\n+\n+  test(\"SPARK-21145: Restarted queries create new provider instances\") {\n+    try {\n+      val checkpointLocation = Utils.createTempDir().getAbsoluteFile\n+      val spark = SparkSession.builder().master(\"local[2]\").getOrCreate()\n+      SparkSession.setActiveSession(spark)\n+      implicit val sqlContext = spark.sqlContext\n+      spark.conf.set(\"spark.sql.shuffle.partitions\", \"1\")\n+      spark.conf.set(\n+        \"spark.sql.streaming.stateStore.providerClass\","
  }],
  "prId": 24922
}, {
  "comments": [{
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "I think it's important enough to implement it with `ConfigBuilder`.",
    "commit": "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "createdAt": "2019-07-05T12:22:20Z",
    "diffHunk": "@@ -0,0 +1,615 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import java.io.File\n+import java.util.UUID\n+\n+import org.apache.commons.io.FileUtils\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.Path\n+import org.scalatest.{BeforeAndAfter, PrivateMethodTester}\n+import org.scalatest.concurrent.Eventually.{eventually, timeout}\n+import org.scalatest.time.SpanSugar._\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.util.Random\n+\n+import org.apache.spark.{SparkConf, SparkContext, SparkEnv}\n+import org.apache.spark.LocalSparkContext.withSpark\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow\n+import org.apache.spark.sql.catalyst.util.quietly\n+import org.apache.spark.sql.execution.streaming.MemoryStream\n+import org.apache.spark.sql.functions.count\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n+import org.apache.spark.util.Utils\n+\n+class RocksDbStateStoreSuite\n+    extends StateStoreSuiteBase[RocksDbStateStoreProvider]\n+    with BeforeAndAfter\n+    with PrivateMethodTester {\n+  type MapType = mutable.HashMap[UnsafeRow, UnsafeRow]\n+  type ProviderMapType = java.util.concurrent.ConcurrentHashMap[UnsafeRow, UnsafeRow]\n+\n+  import StateStoreCoordinatorSuite._\n+  import StateStoreTestsHelper._\n+\n+  val keySchema = StructType(Seq(StructField(\"key\", StringType, true)))\n+  val valueSchema = StructType(Seq(StructField(\"value\", IntegerType, true)))\n+\n+  before {\n+    StateStore.stop()\n+    require(!StateStore.isMaintenanceRunning)\n+  }\n+\n+  after {\n+    StateStore.stop()\n+    require(!StateStore.isMaintenanceRunning)\n+  }\n+\n+  def updateVersionTo(\n+      provider: StateStoreProvider,\n+      currentVersion: Int,\n+      targetVersion: Int): Int = {\n+    var newCurrentVersion = currentVersion\n+    for (i <- newCurrentVersion until targetVersion) {\n+      newCurrentVersion = incrementVersion(provider, i)\n+    }\n+    require(newCurrentVersion === targetVersion)\n+    newCurrentVersion\n+  }\n+\n+  def incrementVersion(provider: StateStoreProvider, currentVersion: Int): Int = {\n+    val store = provider.getStore(currentVersion)\n+    put(store, \"a\", currentVersion + 1)\n+    store.commit()\n+    currentVersion + 1\n+  }\n+\n+  def checkLoadedVersions(\n+      rocksDbWriteInstance: RocksDbInstance,\n+      count: Int,\n+      earliestKey: Long,\n+      latestKey: Long): Unit = {\n+    assert(rocksDbWriteInstance.iterator(false).length === count)\n+  }\n+\n+  def checkVersion(\n+      rocksDbWriteInstance: RocksDbInstance,\n+      version: Long,\n+      expectedData: Map[String, Int]): Unit = {\n+\n+    val originValueMap = rocksDbWriteInstance\n+      .iterator(false)\n+      .map { row =>\n+        rowToString(row.key) -> rowToInt(row.value)\n+      }\n+      .toMap[String, Int]\n+\n+    assert(originValueMap === expectedData)\n+  }\n+\n+  test(\"get, put, remove, commit, and all data iterator\") {\n+    val provider = newStoreProvider()\n+\n+    // Verify state before starting a new set of updates\n+    assert(getLatestData(provider).isEmpty)\n+\n+    val store = provider.getStore(0)\n+    assert(!store.hasCommitted)\n+    assert(get(store, \"a\") === None)\n+    assert(store.iterator().isEmpty)\n+\n+    // Verify state after updating\n+    put(store, \"a\", 1)\n+    assert(get(store, \"a\") === Some(1))\n+\n+    assert(store.iterator().nonEmpty)\n+    assert(getLatestData(provider).isEmpty)\n+\n+    // Make updates, commit and then verify state\n+    put(store, \"b\", 2)\n+    put(store, \"aa\", 3)\n+    remove(store, _.startsWith(\"a\"))\n+    assert(store.commit() === 1)\n+\n+    assert(store.hasCommitted)\n+    assert(rowsToSet(store.iterator()) === Set(\"b\" -> 2))\n+    assert(getLatestData(provider) === Set(\"b\" -> 2))\n+\n+    // Trying to get newer versions should fail\n+    intercept[Exception] {\n+      provider.getStore(2)\n+    }\n+    intercept[Exception] {\n+      getData(provider, 2)\n+    }\n+\n+    // New updates to the reloaded store with new version, and does not change old version\n+    val reloadedProvider = newStoreProvider(store.id, provider.getLocalDirectory)\n+    val reloadedStore = reloadedProvider.getStore(1)\n+    put(reloadedStore, \"c\", 4)\n+    assert(reloadedStore.commit() === 2)\n+    assert(rowsToSet(reloadedStore.iterator()) === Set(\"b\" -> 2, \"c\" -> 4))\n+    assert(getLatestData(provider) === Set(\"b\" -> 2, \"c\" -> 4))\n+    assert(getData(provider, version = 1) === Set(\"b\" -> 2))\n+  }\n+\n+  test(\"snapshotting\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+\n+    var currentVersion = 0\n+\n+    currentVersion = updateVersionTo(provider, currentVersion, 2)\n+    require(getData(provider) === Set(\"a\" -> 2))\n+    provider.doMaintenance() // should not generate snapshot files\n+    assert(getData(provider) === Set(\"a\" -> 2))\n+\n+    for (i <- 1 to currentVersion) {\n+      assert(fileExists(provider, i, isSnapshot = false)) // all delta files present\n+      assert(!fileExists(provider, i, isSnapshot = true)) // no snapshot files present\n+    }\n+\n+    // After version 6, snapshotting should generate one snapshot file\n+    currentVersion = updateVersionTo(provider, currentVersion, 6)\n+    require(getData(provider) === Set(\"a\" -> 6), \"store not updated correctly\")\n+    provider.doMaintenance() // should generate snapshot files\n+\n+    val snapshotVersion =\n+      (0 to 6).find(version => fileExists(provider, version, isSnapshot = true))\n+    assert(snapshotVersion.nonEmpty, \"snapshot file not generated\")\n+    deleteFilesEarlierThanVersion(provider, snapshotVersion.get)\n+    assert(\n+      getData(provider, snapshotVersion.get) === Set(\"a\" -> snapshotVersion.get),\n+      \"snapshotting messed up the data of the snapshotted version\")\n+    assert(\n+      getData(provider) === Set(\"a\" -> 6),\n+      \"snapshotting messed up the data of the final version\")\n+\n+    // After version 20, snapshotting should generate newer snapshot files\n+    currentVersion = updateVersionTo(provider, currentVersion, 20)\n+    require(getData(provider) === Set(\"a\" -> 20), \"store not updated correctly\")\n+    provider.doMaintenance() // do snapshot\n+\n+    val latestSnapshotVersion =\n+      (0 to 20).filter(version => fileExists(provider, version, isSnapshot = true)).lastOption\n+    assert(latestSnapshotVersion.nonEmpty, \"no snapshot file found\")\n+    assert(latestSnapshotVersion.get > snapshotVersion.get, \"newer snapshot not generated\")\n+\n+    deleteFilesEarlierThanVersion(provider, latestSnapshotVersion.get)\n+    assert(getData(provider) === Set(\"a\" -> 20), \"snapshotting messed up the data\")\n+  }\n+\n+  test(\"cleaning\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+\n+    for (i <- 1 to 20) {\n+      val store = provider.getStore(i - 1)\n+      put(store, \"a\", i)\n+      store.commit()\n+      provider.doMaintenance() // do cleanup\n+    }\n+    require(\n+      rowsToSet(provider.latestIterator()) === Set(\"a\" -> 20),\n+      \"store not updated correctly\")\n+\n+    assert(!fileExists(provider, version = 1, isSnapshot = false)) // first file should be deleted\n+\n+    // last couple of versions should be retrievable\n+    assert(getData(provider, 20) === Set(\"a\" -> 20))\n+    assert(getData(provider, 19) === Set(\"a\" -> 19))\n+  }\n+\n+  testQuietly(\"SPARK-19677: Committing a delta file atop an existing one should not fail on HDFS\") {\n+    val conf = new Configuration()\n+    conf.set(\"fs.fake.impl\", classOf[RenameLikeHDFSFileSystem].getName)\n+    conf.set(\"fs.defaultFS\", \"fake:///\")\n+\n+    val provider = newStoreProvider(opId = Random.nextInt, partition = 0, hadoopConf = conf)\n+    provider.getStore(0).commit()\n+    provider.getStore(0).commit()\n+\n+    // Verify we don't leak temp files\n+    val tempFiles = FileUtils\n+      .listFiles(new File(provider.stateStoreId.checkpointRootLocation), null, true)\n+      .asScala\n+      .filter(_.getName.startsWith(\"temp-\"))\n+    assert(tempFiles.isEmpty)\n+  }\n+\n+  test(\"corrupted file handling\") {\n+    val provider =\n+      newStoreProvider(opId = Random.nextInt, partition = 0, minDeltasForSnapshot = 5)\n+    for (i <- 1 to 6) {\n+      val store = provider.getStore(i - 1)\n+      put(store, \"a\", i)\n+      store.commit()\n+      provider.doMaintenance() // do cleanup\n+    }\n+    val snapshotVersion = (0 to 10)\n+      .find(version => fileExists(provider, version, isSnapshot = true))\n+      .getOrElse(fail(\"snapshot file not found\"))\n+\n+    // Corrupt snapshot file and verify that it throws error\n+    provider.close()\n+    assert(getData(provider, snapshotVersion) === Set(\"a\" -> snapshotVersion))\n+    RocksDbInstance.destroyDB(provider.rocksDbPath)\n+\n+    corruptFile(provider, snapshotVersion, isSnapshot = true)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion)\n+    }\n+\n+    // Corrupt delta file and verify that it throws error\n+    provider.close()\n+    RocksDbInstance.destroyDB(provider.rocksDbPath)\n+    assert(getData(provider, snapshotVersion - 1) === Set(\"a\" -> (snapshotVersion - 1)))\n+\n+    corruptFile(provider, snapshotVersion - 1, isSnapshot = false)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion - 1)\n+    }\n+\n+    // Delete delta file and verify that it throws error\n+    deleteFilesEarlierThanVersion(provider, snapshotVersion)\n+    intercept[Exception] {\n+      provider.close()\n+      RocksDbInstance.destroyDB(provider.rocksDbPath)\n+      getData(provider, snapshotVersion - 1)\n+    }\n+  }\n+\n+  test(\"StateStore.get\") {\n+    quietly {\n+      val dir = newDir()\n+      val storeId = StateStoreProviderId(StateStoreId(dir, 0, 0), UUID.randomUUID)\n+      val sqlConf = new SQLConf\n+      sqlConf.setConfString(\n+        \"spark.sql.streaming.stateStore.providerClass\",\n+        \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      val localdir = Utils.createTempDir().getAbsoluteFile.toString\n+      sqlConf.setConfString(\"spark.sql.streaming.stateStore.rocksDb.localDirectory\", localdir)\n+      val storeConf = new StateStoreConf(sqlConf)\n+      assert(\n+        storeConf.providerClass ===\n+          \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      val hadoopConf = new Configuration()\n+\n+      // Verify that trying to get incorrect versions throw errors\n+      intercept[IllegalArgumentException] {\n+        StateStore.get(storeId, keySchema, valueSchema, None, -1, storeConf, hadoopConf)\n+      }\n+      assert(!StateStore.isLoaded(storeId)) // version -1 should not attempt to load the store\n+\n+      intercept[IllegalStateException] {\n+        StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      }\n+\n+      // Increase version of the store and try to get again\n+      val store0 = StateStore.get(storeId, keySchema, valueSchema, None, 0, storeConf, hadoopConf)\n+      assert(store0.version === 0)\n+      put(store0, \"a\", 1)\n+      store0.commit()\n+\n+      val store1 = StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      assert(StateStore.isLoaded(storeId))\n+      assert(store1.version === 1)\n+      assert(rowsToSet(store1.iterator()) === Set(\"a\" -> 1))\n+\n+      // Verify that you can also load older version\n+      val store0reloaded =\n+        StateStore.get(storeId, keySchema, valueSchema, None, 0, storeConf, hadoopConf)\n+      assert(store0reloaded.version === 0)\n+      assert(rowsToSet(store0reloaded.iterator()) === Set.empty)\n+\n+      // Verify that you can remove the store and still reload and use it\n+      StateStore.unload(storeId)\n+      assert(!StateStore.isLoaded(storeId))\n+\n+      val store1reloaded =\n+        StateStore.get(storeId, keySchema, valueSchema, None, 1, storeConf, hadoopConf)\n+      assert(StateStore.isLoaded(storeId))\n+      assert(store1reloaded.version === 1)\n+      put(store1reloaded, \"a\", 2)\n+      assert(store1reloaded.commit() === 2)\n+      assert(rowsToSet(store1reloaded.iterator()) === Set(\"a\" -> 2))\n+    }\n+  }\n+\n+  test(\"maintenance\") {\n+    val conf = new SparkConf()\n+      .setMaster(\"local\")\n+      .setAppName(\"test\")\n+      // Make maintenance thread do snapshots and cleanups very fast\n+      .set(StateStore.MAINTENANCE_INTERVAL_CONFIG, \"10ms\")\n+      // Make sure that when SparkContext stops, the StateStore maintenance thread 'quickly'\n+      // fails to talk to the StateStoreCoordinator and unloads all the StateStores\n+      .set(\"spark.rpc.numRetries\", \"1\")\n+    val opId = 0\n+    val dir = newDir()\n+    val storeProviderId = StateStoreProviderId(StateStoreId(dir, opId, 0), UUID.randomUUID)\n+    val sqlConf = new SQLConf()\n+    sqlConf.setConfString(\n+      \"spark.sql.streaming.stateStore.providerClass\",\n+      \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+    sqlConf.setConf(SQLConf.MIN_BATCHES_TO_RETAIN, 2)\n+    sqlConf.setConfString(\n+      \"spark.sql.streaming.stateStore.rocksDb.localDirectory\",\n+      Utils.createTempDir().getAbsoluteFile.toString)\n+    val storeConf = StateStoreConf(sqlConf)\n+    val hadoopConf = new Configuration()\n+    val provider = newStoreProvider(storeProviderId.storeId)\n+\n+    var latestStoreVersion = 0\n+\n+    def generateStoreVersions() {\n+      for (i <- 1 to 20) {\n+        val store = StateStore.get(\n+          storeProviderId,\n+          keySchema,\n+          valueSchema,\n+          None,\n+          latestStoreVersion,\n+          storeConf,\n+          hadoopConf)\n+        put(store, \"a\", i)\n+        store.commit()\n+        latestStoreVersion += 1\n+      }\n+    }\n+\n+    val timeoutDuration = 60 seconds\n+\n+    quietly {\n+      withSpark(new SparkContext(conf)) { sc =>\n+        withCoordinatorRef(sc) { coordinatorRef =>\n+          require(!StateStore.isMaintenanceRunning, \"StateStore is unexpectedly running\")\n+\n+          // Generate sufficient versions of store for snapshots\n+          generateStoreVersions()\n+\n+          eventually(timeout(timeoutDuration)) {\n+            // Store should have been reported to the coordinator\n+            assert(\n+              coordinatorRef.getLocation(storeProviderId).nonEmpty,\n+              \"active instance was not reported\")\n+\n+            // Background maintenance should clean up and generate snapshots\n+            assert(StateStore.isMaintenanceRunning, \"Maintenance task is not running\")\n+\n+            // Some snapshots should have been generated\n+            val snapshotVersions = (1 to latestStoreVersion).filter { version =>\n+              fileExists(provider, version, isSnapshot = true)\n+            }\n+            assert(snapshotVersions.nonEmpty, \"no snapshot file found\")\n+          }\n+\n+          // Generate more versions such that there is another snapshot and\n+          // the earliest delta file will be cleaned up\n+          generateStoreVersions()\n+\n+          // Earliest delta file should get cleaned up\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!fileExists(provider, 1, isSnapshot = false), \"earliest file not deleted\")\n+          }\n+\n+          // If driver decides to deactivate all stores related to a query run,\n+          // then this instance should be unloaded\n+          coordinatorRef.deactivateInstances(storeProviderId.queryRunId)\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!StateStore.isLoaded(storeProviderId))\n+          }\n+\n+          // Reload the store and verify\n+          StateStore.get(\n+            storeProviderId,\n+            keySchema,\n+            valueSchema,\n+            indexOrdinal = None,\n+            latestStoreVersion,\n+            storeConf,\n+            hadoopConf)\n+          assert(StateStore.isLoaded(storeProviderId))\n+\n+          // If some other executor loads the store, then this instance should be unloaded\n+          coordinatorRef.reportActiveInstance(storeProviderId, \"other-host\", \"other-exec\")\n+          eventually(timeout(timeoutDuration)) {\n+            assert(!StateStore.isLoaded(storeProviderId))\n+          }\n+\n+          // Reload the store and verify\n+          StateStore.get(\n+            storeProviderId,\n+            keySchema,\n+            valueSchema,\n+            indexOrdinal = None,\n+            latestStoreVersion,\n+            storeConf,\n+            hadoopConf)\n+          assert(StateStore.isLoaded(storeProviderId))\n+        }\n+      }\n+\n+      // Verify if instance is unloaded if SparkContext is stopped\n+      eventually(timeout(timeoutDuration)) {\n+        require(SparkEnv.get === null)\n+        assert(!StateStore.isLoaded(storeProviderId))\n+        assert(!StateStore.isMaintenanceRunning)\n+      }\n+    }\n+  }\n+\n+  test(\"SPARK-21145: Restarted queries create new provider instances\") {\n+    try {\n+      val checkpointLocation = Utils.createTempDir().getAbsoluteFile\n+      val spark = SparkSession.builder().master(\"local[2]\").getOrCreate()\n+      SparkSession.setActiveSession(spark)\n+      implicit val sqlContext = spark.sqlContext\n+      spark.conf.set(\"spark.sql.shuffle.partitions\", \"1\")\n+      spark.conf.set(\n+        \"spark.sql.streaming.stateStore.providerClass\",\n+        \"org.apache.spark.sql.execution.streaming.state.RocksDbStateStoreProvider\")\n+      spark.conf.set(\n+        \"spark.sql.streaming.stateStore.rocksDb.localDirectory\","
  }],
  "prId": 24922
}]