[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Here, I clearly mentioned `read schema` and used `evolved` and `projected` as general verbs.",
    "commit": "a7064ac0bc7b56ffffa3e322f31bda8a45bd9517",
    "createdAt": "2018-07-10T21:23:56Z",
    "diffHunk": "@@ -0,0 +1,493 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.File\n+\n+import org.apache.spark.sql.{QueryTest, Row}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.{SharedSQLContext, SQLTestUtils}\n+\n+/**\n+ * The reader schema is said to be evolved (or projected) when it changed after the data is",
    "line": 27
  }],
  "prId": 20208
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Thanks for helping improve the test coverage! All the included test cases are positive. How about the negative test cases? What kind of errors you hit?",
    "commit": "a7064ac0bc7b56ffffa3e322f31bda8a45bd9517",
    "createdAt": "2018-07-10T21:49:32Z",
    "diffHunk": "@@ -0,0 +1,493 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.File\n+\n+import org.apache.spark.sql.{QueryTest, Row}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.{SharedSQLContext, SQLTestUtils}\n+\n+/**\n+ * The reader schema is said to be evolved (or projected) when it changed after the data is\n+ * written by writers. The followings are supported in file-based data sources.\n+ * Note that partition columns are not maintained in files. Here, `column` means non-partition\n+ * column.\n+ *\n+ *   1. Add a column\n+ *   2. Hide a column\n+ *   3. Change a column position\n+ *   4. Change a column type (Upcast)\n+ *\n+ * Here, we consider safe changes without data loss. For example, data type changes should be\n+ * from small types to larger types like `int`-to-`long`, not vice versa.\n+ *\n+ * So far, file-based data sources have the following coverages.\n+ *\n+ *   | File Format  | Coverage     | Note                                                   |\n+ *   | ------------ | ------------ | ------------------------------------------------------ |\n+ *   | TEXT         | N/A          | Schema consists of a single string column.             |\n+ *   | CSV          | 1, 2, 4      |                                                        |\n+ *   | JSON         | 1, 2, 3, 4   |                                                        |\n+ *   | ORC          | 1, 2, 3, 4   | Native vectorized ORC reader has the widest coverage.  |\n+ *   | PARQUET      | 1, 2, 3      |                                                        |",
    "line": 48
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Yes. Right. Since the main purpose of this PR is preventing regressions, it consists of positive-only. The errors are case-by-case for each data sources.\r\n\r\nFor `BooleanTypeTest` example, Parquet raises higher exceptions due to `ClassCastException` (at the bottom). JSON raises `Results do not match` test case failures without exceptions.\r\n\r\n- Parquet\r\n```\r\norg.apache.spark.sql.execution.QueryExecutionException: Encounter error while reading parquet files. One possible cause: Parquet column cannot be converted in the corresponding files. Details: \r\n...\r\nCaused by: org.apache.parquet.io.ParquetDecodingException: Can not read value at 1 in block 0 in file file:/private/var/folders/dc/1pz9m69x14q_gw8t7m143t1c0000gn/T/spark-4b3d788b-1d7e-4ca2-9c01-88f639daf02f/part-00000-975391e5-1f1d-49f5-8e12-3213281618ed-c000.snappy.parquet\r\n...\r\nCaused by: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.MutableByte cannot be cast to org.apache.spark.sql.catalyst.expressions.MutableBoolean\r\n```",
    "commit": "a7064ac0bc7b56ffffa3e322f31bda8a45bd9517",
    "createdAt": "2018-07-10T22:17:24Z",
    "diffHunk": "@@ -0,0 +1,493 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.datasources\n+\n+import java.io.File\n+\n+import org.apache.spark.sql.{QueryTest, Row}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.test.{SharedSQLContext, SQLTestUtils}\n+\n+/**\n+ * The reader schema is said to be evolved (or projected) when it changed after the data is\n+ * written by writers. The followings are supported in file-based data sources.\n+ * Note that partition columns are not maintained in files. Here, `column` means non-partition\n+ * column.\n+ *\n+ *   1. Add a column\n+ *   2. Hide a column\n+ *   3. Change a column position\n+ *   4. Change a column type (Upcast)\n+ *\n+ * Here, we consider safe changes without data loss. For example, data type changes should be\n+ * from small types to larger types like `int`-to-`long`, not vice versa.\n+ *\n+ * So far, file-based data sources have the following coverages.\n+ *\n+ *   | File Format  | Coverage     | Note                                                   |\n+ *   | ------------ | ------------ | ------------------------------------------------------ |\n+ *   | TEXT         | N/A          | Schema consists of a single string column.             |\n+ *   | CSV          | 1, 2, 4      |                                                        |\n+ *   | JSON         | 1, 2, 3, 4   |                                                        |\n+ *   | ORC          | 1, 2, 3, 4   | Native vectorized ORC reader has the widest coverage.  |\n+ *   | PARQUET      | 1, 2, 3      |                                                        |",
    "line": 48
  }],
  "prId": 20208
}]