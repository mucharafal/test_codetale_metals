[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "MINOR: all these test have the same structure. We could move this into a function...\n",
    "commit": "030776ae49484c4e5db7f775344e5e40dff27e9a",
    "createdAt": "2016-07-11T11:26:11Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.sql._\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class OptimizeMetadataOnlyQuerySuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    val data = (1 to 10).map(i => (i, s\"data-$i\", i % 2, if ((i % 2) == 0) \"even\" else \"odd\"))\n+      .toDF(\"col1\", \"col2\", \"partcol1\", \"partcol2\")\n+    data.write.partitionBy(\"partcol1\", \"partcol2\").mode(\"append\").saveAsTable(\"srcpart\")\n+  }\n+\n+  override protected def afterAll(): Unit = {\n+    try {\n+      sql(\"DROP TABLE IF EXISTS srcpart\")\n+    } finally {\n+      super.afterAll()\n+    }\n+  }\n+\n+  private def assertMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 1)\n+  }\n+\n+  private def assertNotMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 0)\n+  }\n+\n+  test(\"OptimizeMetadataOnlyQuery test: aggregate expression is partition columns\") {"
  }, {
    "author": {
      "login": "lianhuiwang"
    },
    "body": "as @rxin addressed before, Dividing this into multiple functions is to have separate test cases for each of the category that has documented in the OptimizeMetadataOnlyQuery.\n",
    "commit": "030776ae49484c4e5db7f775344e5e40dff27e9a",
    "createdAt": "2016-07-11T12:39:03Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.sql._\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class OptimizeMetadataOnlyQuerySuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    val data = (1 to 10).map(i => (i, s\"data-$i\", i % 2, if ((i % 2) == 0) \"even\" else \"odd\"))\n+      .toDF(\"col1\", \"col2\", \"partcol1\", \"partcol2\")\n+    data.write.partitionBy(\"partcol1\", \"partcol2\").mode(\"append\").saveAsTable(\"srcpart\")\n+  }\n+\n+  override protected def afterAll(): Unit = {\n+    try {\n+      sql(\"DROP TABLE IF EXISTS srcpart\")\n+    } finally {\n+      super.afterAll()\n+    }\n+  }\n+\n+  private def assertMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 1)\n+  }\n+\n+  private def assertNotMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 0)\n+  }\n+\n+  test(\"OptimizeMetadataOnlyQuery test: aggregate expression is partition columns\") {"
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "That is not what I mean. I am all for thorough testing, however the structure is the same everywhere. You could generalize this (and improve readability), e.g.:\n\n``` scala\ndef testMetadataOnly(name: String, sql: String*): Unit = {\n  test(name) {\n    withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"true\") {\n      sqls.foreach(assertMetadataOnlyQuery(sql(_)))\n    }\n    withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"false\") {\n      sqls.foreach(assertNotMetadataOnlyQuery(sql(_)))\n    }\n  }\n}\n\ntestMetadataOnly(\n  \"OptimizeMetadataOnlyQuery test: aggregate expression is partition columns\", \n  \"select partcol1 from srcpart group by partcol1\",\n  \"select partcol2 from srcpart where partcol1 = 0 group by partcol2\")\n```\n",
    "commit": "030776ae49484c4e5db7f775344e5e40dff27e9a",
    "createdAt": "2016-07-11T12:59:53Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.sql._\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class OptimizeMetadataOnlyQuerySuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    val data = (1 to 10).map(i => (i, s\"data-$i\", i % 2, if ((i % 2) == 0) \"even\" else \"odd\"))\n+      .toDF(\"col1\", \"col2\", \"partcol1\", \"partcol2\")\n+    data.write.partitionBy(\"partcol1\", \"partcol2\").mode(\"append\").saveAsTable(\"srcpart\")\n+  }\n+\n+  override protected def afterAll(): Unit = {\n+    try {\n+      sql(\"DROP TABLE IF EXISTS srcpart\")\n+    } finally {\n+      super.afterAll()\n+    }\n+  }\n+\n+  private def assertMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 1)\n+  }\n+\n+  private def assertNotMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 0)\n+  }\n+\n+  test(\"OptimizeMetadataOnlyQuery test: aggregate expression is partition columns\") {"
  }, {
    "author": {
      "login": "lianhuiwang"
    },
    "body": "Get it, thanks. I will update it. Thanks.\n",
    "commit": "030776ae49484c4e5db7f775344e5e40dff27e9a",
    "createdAt": "2016-07-11T14:26:02Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.sql._\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class OptimizeMetadataOnlyQuerySuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    val data = (1 to 10).map(i => (i, s\"data-$i\", i % 2, if ((i % 2) == 0) \"even\" else \"odd\"))\n+      .toDF(\"col1\", \"col2\", \"partcol1\", \"partcol2\")\n+    data.write.partitionBy(\"partcol1\", \"partcol2\").mode(\"append\").saveAsTable(\"srcpart\")\n+  }\n+\n+  override protected def afterAll(): Unit = {\n+    try {\n+      sql(\"DROP TABLE IF EXISTS srcpart\")\n+    } finally {\n+      super.afterAll()\n+    }\n+  }\n+\n+  private def assertMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 1)\n+  }\n+\n+  private def assertNotMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 0)\n+  }\n+\n+  test(\"OptimizeMetadataOnlyQuery test: aggregate expression is partition columns\") {"
  }],
  "prId": 13494
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "When is this one used?\n",
    "commit": "030776ae49484c4e5db7f775344e5e40dff27e9a",
    "createdAt": "2016-07-11T18:59:01Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.sql._\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class OptimizeMetadataOnlyQuerySuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    val data = (1 to 10).map(i => (i, s\"data-$i\", i % 2, if ((i % 2) == 0) \"even\" else \"odd\"))\n+      .toDF(\"col1\", \"col2\", \"partcol1\", \"partcol2\")\n+    data.write.partitionBy(\"partcol1\", \"partcol2\").mode(\"append\").saveAsTable(\"srcpart\")\n+  }\n+\n+  override protected def afterAll(): Unit = {\n+    try {\n+      sql(\"DROP TABLE IF EXISTS srcpart\")\n+    } finally {\n+      super.afterAll()\n+    }\n+  }\n+\n+  private def assertMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 1)\n+  }\n+\n+  private def assertNotMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 0)\n+  }\n+\n+  private def testMetadataOnly(name: String, sqls: String*): Unit = {\n+    test(name) {\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"true\") {\n+        sqls.foreach { case q => assertMetadataOnlyQuery(sql(q)) }\n+      }\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"false\") {\n+        sqls.foreach { case q => assertNotMetadataOnlyQuery(sql(q)) }\n+      }\n+    }\n+  }\n+\n+  private def testNotMetadataOnly(name: String, sqls: String*): Unit = {",
    "line": 68
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "NVM - I am blind\n",
    "commit": "030776ae49484c4e5db7f775344e5e40dff27e9a",
    "createdAt": "2016-07-11T18:59:18Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.sql._\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class OptimizeMetadataOnlyQuerySuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    val data = (1 to 10).map(i => (i, s\"data-$i\", i % 2, if ((i % 2) == 0) \"even\" else \"odd\"))\n+      .toDF(\"col1\", \"col2\", \"partcol1\", \"partcol2\")\n+    data.write.partitionBy(\"partcol1\", \"partcol2\").mode(\"append\").saveAsTable(\"srcpart\")\n+  }\n+\n+  override protected def afterAll(): Unit = {\n+    try {\n+      sql(\"DROP TABLE IF EXISTS srcpart\")\n+    } finally {\n+      super.afterAll()\n+    }\n+  }\n+\n+  private def assertMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 1)\n+  }\n+\n+  private def assertNotMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 0)\n+  }\n+\n+  private def testMetadataOnly(name: String, sqls: String*): Unit = {\n+    test(name) {\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"true\") {\n+        sqls.foreach { case q => assertMetadataOnlyQuery(sql(q)) }\n+      }\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"false\") {\n+        sqls.foreach { case q => assertNotMetadataOnlyQuery(sql(q)) }\n+      }\n+    }\n+  }\n+\n+  private def testNotMetadataOnly(name: String, sqls: String*): Unit = {",
    "line": 68
  }],
  "prId": 13494
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "I think we can remove the prefix: `OptimizeMetadataOnlyQuery test`. The test report will print the name of this test suite for these tests.\n",
    "commit": "030776ae49484c4e5db7f775344e5e40dff27e9a",
    "createdAt": "2016-07-12T05:52:51Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.sql._\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class OptimizeMetadataOnlyQuerySuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    val data = (1 to 10).map(i => (i, s\"data-$i\", i % 2, if ((i % 2) == 0) \"even\" else \"odd\"))\n+      .toDF(\"col1\", \"col2\", \"partcol1\", \"partcol2\")\n+    data.write.partitionBy(\"partcol1\", \"partcol2\").mode(\"append\").saveAsTable(\"srcpart\")\n+  }\n+\n+  override protected def afterAll(): Unit = {\n+    try {\n+      sql(\"DROP TABLE IF EXISTS srcpart\")\n+    } finally {\n+      super.afterAll()\n+    }\n+  }\n+\n+  private def assertMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 1)\n+  }\n+\n+  private def assertNotMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 0)\n+  }\n+\n+  private def testMetadataOnly(name: String, sqls: String*): Unit = {\n+    test(name) {\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"true\") {\n+        sqls.foreach { case q => assertMetadataOnlyQuery(sql(q)) }\n+      }\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"false\") {\n+        sqls.foreach { case q => assertNotMetadataOnlyQuery(sql(q)) }\n+      }\n+    }\n+  }\n+\n+  private def testNotMetadataOnly(name: String, sqls: String*): Unit = {\n+    test(name) {\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"true\") {\n+        sqls.foreach { case q => assertNotMetadataOnlyQuery(sql(q)) }\n+      }\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"false\") {\n+        sqls.foreach { case q => assertNotMetadataOnlyQuery(sql(q)) }\n+      }\n+    }\n+  }\n+\n+  testMetadataOnly(\n+    \"OptimizeMetadataOnlyQuery test: aggregate expression is partition columns\","
  }, {
    "author": {
      "login": "lianhuiwang"
    },
    "body": "Sure. thanks.\n",
    "commit": "030776ae49484c4e5db7f775344e5e40dff27e9a",
    "createdAt": "2016-07-12T09:25:06Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution\n+\n+import org.apache.spark.sql._\n+import org.apache.spark.sql.catalyst.plans.logical.LocalRelation\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class OptimizeMetadataOnlyQuerySuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    val data = (1 to 10).map(i => (i, s\"data-$i\", i % 2, if ((i % 2) == 0) \"even\" else \"odd\"))\n+      .toDF(\"col1\", \"col2\", \"partcol1\", \"partcol2\")\n+    data.write.partitionBy(\"partcol1\", \"partcol2\").mode(\"append\").saveAsTable(\"srcpart\")\n+  }\n+\n+  override protected def afterAll(): Unit = {\n+    try {\n+      sql(\"DROP TABLE IF EXISTS srcpart\")\n+    } finally {\n+      super.afterAll()\n+    }\n+  }\n+\n+  private def assertMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 1)\n+  }\n+\n+  private def assertNotMetadataOnlyQuery(df: DataFrame): Unit = {\n+    val localRelations = df.queryExecution.optimizedPlan.collect {\n+      case l @ LocalRelation(_, _) => l\n+    }\n+    assert(localRelations.size == 0)\n+  }\n+\n+  private def testMetadataOnly(name: String, sqls: String*): Unit = {\n+    test(name) {\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"true\") {\n+        sqls.foreach { case q => assertMetadataOnlyQuery(sql(q)) }\n+      }\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"false\") {\n+        sqls.foreach { case q => assertNotMetadataOnlyQuery(sql(q)) }\n+      }\n+    }\n+  }\n+\n+  private def testNotMetadataOnly(name: String, sqls: String*): Unit = {\n+    test(name) {\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"true\") {\n+        sqls.foreach { case q => assertNotMetadataOnlyQuery(sql(q)) }\n+      }\n+      withSQLConf(SQLConf.OPTIMIZER_METADATA_ONLY.key -> \"false\") {\n+        sqls.foreach { case q => assertNotMetadataOnlyQuery(sql(q)) }\n+      }\n+    }\n+  }\n+\n+  testMetadataOnly(\n+    \"OptimizeMetadataOnlyQuery test: aggregate expression is partition columns\","
  }],
  "prId": 13494
}]