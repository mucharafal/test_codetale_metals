[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Shall we avoid duplicating the existing logic `withSQLConf`? Let me try to fix.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-25T02:30:58Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.{AnalysisException, SparkSession}\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase {\n+\n+  val spark: SparkSession = getSparkSession\n+\n+  /** Subclass can override this function to build their own SparkSession */\n+  def getSparkSession: SparkSession = {\n+    SparkSession.builder()\n+      .master(\"local[1]\")\n+      .appName(this.getClass.getCanonicalName)\n+      .config(SQLConf.SHUFFLE_PARTITIONS.key, 1)\n+      .config(SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key, 1)\n+      .getOrCreate()\n+  }\n+\n+  /**\n+   * Sets all SQL configurations specified in `pairs`, calls `f`, and then restores all SQL\n+   * configurations.\n+   */\n+  protected def withSQLConf(pairs: (String, String)*)(f: => Unit): Unit = {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "@wangyum . Thank you for waiting.\r\nSince SPARK-25534 is merged, could you use `SQLHelper.withSQLConf` instead?",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-26T06:09:25Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.{AnalysisException, SparkSession}\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase {\n+\n+  val spark: SparkSession = getSparkSession\n+\n+  /** Subclass can override this function to build their own SparkSession */\n+  def getSparkSession: SparkSession = {\n+    SparkSession.builder()\n+      .master(\"local[1]\")\n+      .appName(this.getClass.getCanonicalName)\n+      .config(SQLConf.SHUFFLE_PARTITIONS.key, 1)\n+      .config(SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key, 1)\n+      .getOrCreate()\n+  }\n+\n+  /**\n+   * Sets all SQL configurations specified in `pairs`, calls `f`, and then restores all SQL\n+   * configurations.\n+   */\n+  protected def withSQLConf(pairs: (String, String)*)(f: => Unit): Unit = {"
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "Yes, I will do it now.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-26T06:27:00Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.{AnalysisException, SparkSession}\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase {\n+\n+  val spark: SparkSession = getSparkSession\n+\n+  /** Subclass can override this function to build their own SparkSession */\n+  def getSparkSession: SparkSession = {\n+    SparkSession.builder()\n+      .master(\"local[1]\")\n+      .appName(this.getClass.getCanonicalName)\n+      .config(SQLConf.SHUFFLE_PARTITIONS.key, 1)\n+      .config(SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key, 1)\n+      .getOrCreate()\n+  }\n+\n+  /**\n+   * Sets all SQL configurations specified in `pairs`, calls `f`, and then restores all SQL\n+   * configurations.\n+   */\n+  protected def withSQLConf(pairs: (String, String)*)(f: => Unit): Unit = {"
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "@dongjoon-hyun  I finished it.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-27T00:37:00Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.{AnalysisException, SparkSession}\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase {\n+\n+  val spark: SparkSession = getSparkSession\n+\n+  /** Subclass can override this function to build their own SparkSession */\n+  def getSparkSession: SparkSession = {\n+    SparkSession.builder()\n+      .master(\"local[1]\")\n+      .appName(this.getClass.getCanonicalName)\n+      .config(SQLConf.SHUFFLE_PARTITIONS.key, 1)\n+      .config(SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key, 1)\n+      .getOrCreate()\n+  }\n+\n+  /**\n+   * Sets all SQL configurations specified in `pairs`, calls `f`, and then restores all SQL\n+   * configurations.\n+   */\n+  protected def withSQLConf(pairs: (String, String)*)(f: => Unit): Unit = {"
  }],
  "prId": 22484
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "for this particular case, do we really need `withSQLConf`? I think we can do\r\n```\r\nval conf = SQLConf.get\r\nconf.set(WHOLESTAGE_CODEGEN_ENABLED, false)\r\nrun benchmark...\r\nconf.set(WHOLESTAGE_CODEGEN_ENABLED, true)\r\nrun benchmark...\r\nconf.unset(WHOLESTAGE_CODEGEN_ENABLED)\r\n```",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-25T18:08:07Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.{AnalysisException, SparkSession}\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase {\n+\n+  val spark: SparkSession = getSparkSession\n+\n+  /** Subclass can override this function to build their own SparkSession */\n+  def getSparkSession: SparkSession = {\n+    SparkSession.builder()\n+      .master(\"local[1]\")\n+      .appName(this.getClass.getCanonicalName)\n+      .config(SQLConf.SHUFFLE_PARTITIONS.key, 1)\n+      .config(SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key, 1)\n+      .getOrCreate()\n+  }\n+\n+  /**\n+   * Sets all SQL configurations specified in `pairs`, calls `f`, and then restores all SQL\n+   * configurations.\n+   */\n+  protected def withSQLConf(pairs: (String, String)*)(f: => Unit): Unit = {\n+    val conf = SQLConf.get\n+    val (keys, values) = pairs.unzip\n+    val currentValues = keys.map { key =>\n+      if (conf.contains(key)) {\n+        Some(conf.getConfString(key))\n+      } else {\n+        None\n+      }\n+    }\n+    (keys, values).zipped.foreach { (k, v) =>\n+      if (SQLConf.staticConfKeys.contains(k)) {\n+        throw new AnalysisException(s\"Cannot modify the value of a static config: $k\")\n+      }\n+      conf.setConfString(k, v)\n+    }\n+    try f finally {\n+      keys.zip(currentValues).foreach {\n+        case (key, Some(value)) => conf.setConfString(key, value)\n+        case (key, None) => conf.unsetConf(key)\n+      }\n+    }\n+  }\n+\n+  /** Runs function `f` with whole stage codegen on and off. */\n+  def runBenchmarkWithCodegen(name: String, cardinality: Long)(f: => Unit): Unit = {\n+    val benchmark = new Benchmark(name, cardinality, output = output)\n+\n+    benchmark.addCase(s\"$name wholestage off\", numIters = 2) { _ =>\n+      withSQLConf(SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key -> \"false\") {",
    "line": 47
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Right. It's the same. And, the previous issue was we don't call `unset`.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-25T18:26:02Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.{AnalysisException, SparkSession}\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase {\n+\n+  val spark: SparkSession = getSparkSession\n+\n+  /** Subclass can override this function to build their own SparkSession */\n+  def getSparkSession: SparkSession = {\n+    SparkSession.builder()\n+      .master(\"local[1]\")\n+      .appName(this.getClass.getCanonicalName)\n+      .config(SQLConf.SHUFFLE_PARTITIONS.key, 1)\n+      .config(SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key, 1)\n+      .getOrCreate()\n+  }\n+\n+  /**\n+   * Sets all SQL configurations specified in `pairs`, calls `f`, and then restores all SQL\n+   * configurations.\n+   */\n+  protected def withSQLConf(pairs: (String, String)*)(f: => Unit): Unit = {\n+    val conf = SQLConf.get\n+    val (keys, values) = pairs.unzip\n+    val currentValues = keys.map { key =>\n+      if (conf.contains(key)) {\n+        Some(conf.getConfString(key))\n+      } else {\n+        None\n+      }\n+    }\n+    (keys, values).zipped.foreach { (k, v) =>\n+      if (SQLConf.staticConfKeys.contains(k)) {\n+        throw new AnalysisException(s\"Cannot modify the value of a static config: $k\")\n+      }\n+      conf.setConfString(k, v)\n+    }\n+    try f finally {\n+      keys.zip(currentValues).foreach {\n+        case (key, Some(value)) => conf.setConfString(key, value)\n+        case (key, None) => conf.unsetConf(key)\n+      }\n+    }\n+  }\n+\n+  /** Runs function `f` with whole stage codegen on and off. */\n+  def runBenchmarkWithCodegen(name: String, cardinality: Long)(f: => Unit): Unit = {\n+    val benchmark = new Benchmark(name, cardinality, output = output)\n+\n+    benchmark.addCase(s\"$name wholestage off\", numIters = 2) { _ =>\n+      withSQLConf(SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key -> \"false\") {",
    "line": 47
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Is it too much to introduce a trait for `withSQLConf`? I made a PR for that to @wangyum .\r\n- https://github.com/wangyum/spark/pull/11",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-25T18:26:52Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.{AnalysisException, SparkSession}\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase {\n+\n+  val spark: SparkSession = getSparkSession\n+\n+  /** Subclass can override this function to build their own SparkSession */\n+  def getSparkSession: SparkSession = {\n+    SparkSession.builder()\n+      .master(\"local[1]\")\n+      .appName(this.getClass.getCanonicalName)\n+      .config(SQLConf.SHUFFLE_PARTITIONS.key, 1)\n+      .config(SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key, 1)\n+      .getOrCreate()\n+  }\n+\n+  /**\n+   * Sets all SQL configurations specified in `pairs`, calls `f`, and then restores all SQL\n+   * configurations.\n+   */\n+  protected def withSQLConf(pairs: (String, String)*)(f: => Unit): Unit = {\n+    val conf = SQLConf.get\n+    val (keys, values) = pairs.unzip\n+    val currentValues = keys.map { key =>\n+      if (conf.contains(key)) {\n+        Some(conf.getConfString(key))\n+      } else {\n+        None\n+      }\n+    }\n+    (keys, values).zipped.foreach { (k, v) =>\n+      if (SQLConf.staticConfKeys.contains(k)) {\n+        throw new AnalysisException(s\"Cannot modify the value of a static config: $k\")\n+      }\n+      conf.setConfString(k, v)\n+    }\n+    try f finally {\n+      keys.zip(currentValues).foreach {\n+        case (key, Some(value)) => conf.setConfString(key, value)\n+        case (key, None) => conf.unsetConf(key)\n+      }\n+    }\n+  }\n+\n+  /** Runs function `f` with whole stage codegen on and off. */\n+  def runBenchmarkWithCodegen(name: String, cardinality: Long)(f: => Unit): Unit = {\n+    val benchmark = new Benchmark(name, cardinality, output = output)\n+\n+    benchmark.addCase(s\"$name wholestage off\", numIters = 2) { _ =>\n+      withSQLConf(SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key -> \"false\") {",
    "line": 47
  }],
  "prId": 22484
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "@wangyum and @gengliangwang .\r\n\r\nWhat is the future plan for the usage of both `SqlBasedBenchmark` and `BenchmarkWithCodegen`? I'm wondering what is the criteria to choose each trait.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-28T22:33:54Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {",
    "line": 28
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "I think we can remove `BenchmarkWithCodegen` after all refactor finished.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-28T22:45:01Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {",
    "line": 28
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "So, if @gengliangwang agree with that, `SqlBasedBenchmark` is another refactoring (renaming and improvement) like `[SPARK-25499][TEST] Refactor BenchmarkBase and Benchmark`. Could you do that in a separate PR in advance?",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-28T23:13:26Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {",
    "line": 28
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "Actually I don't think the the name `SqlBasedBenchmark` is not appropriate..From the naming we can't tell it is about benchmarking with/without whole codegen. I will try to come up with a better name. Or we can discuss in this thread.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-29T04:29:31Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {",
    "line": 28
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "@dongjoon-hyun in https://github.com/apache/spark/pull/22522 I feel that it would be better to have a example refactoring, thus we can see how the new trait is used. \r\nWe can move back to https://github.com/apache/spark/pull/22522 . I am OK either way.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-29T04:32:32Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {",
    "line": 28
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "How about `CodegenBenchmarkBase` ? This is the best I can think of.. @wangyum @dongjoon-hyun @cloud-fan ",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-29T04:56:32Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {",
    "line": 28
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "Maybe we can add more common functions in the future. e.g. `runBenchmarkWithCodegen`, `runBenchmarkWithParquetPushDown`, `runBenchmarkWithOrcPushDown`...",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-29T05:36:58Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {",
    "line": 28
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "Then each function can be in different trait...I don't think that `runBenchmarkWithCodegen` has much in common with `runBenchmarkWithParquetPushDown`.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-29T05:57:22Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {",
    "line": 28
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thank you, @gengliangwang and @wangyum . Let me think about this again.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-09-29T17:11:26Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {",
    "line": 28
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "For the naming, let's keep the current one for now.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-10-01T06:07:39Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {",
    "line": 28
  }],
  "prId": 22484
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "`val spark` -> `protected val spark`",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-10-01T06:09:00Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {\n+\n+  val spark: SparkSession = getSparkSession"
  }],
  "prId": 22484
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This should be `final def runBenchmarkWithCodegen` instead of `def runBenchmarkWithCodegen`.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-10-01T06:09:55Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {\n+\n+  val spark: SparkSession = getSparkSession\n+\n+  /** Subclass can override this function to build their own SparkSession */\n+  def getSparkSession: SparkSession = {\n+    SparkSession.builder()\n+      .master(\"local[1]\")\n+      .appName(this.getClass.getCanonicalName)\n+      .config(SQLConf.SHUFFLE_PARTITIONS.key, 1)\n+      .config(SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key, 1)\n+      .getOrCreate()\n+  }\n+\n+  /** Runs function `f` with whole stage codegen on and off. */\n+  def runBenchmarkWithCodegen(name: String, cardinality: Long)(f: => Unit): Unit = {"
  }],
  "prId": 22484
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Can we use `codegenBenchmark` instead? `runBenchmarkWithCodegen` looks like an extension of `runBenchmark`. It's more like `bitEncodingBenchmark` or `sortBenchmark`.",
    "commit": "6c46ad59c063fa6283fb23046300404767a82248",
    "createdAt": "2018-10-01T06:26:23Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.benchmark\n+\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.catalyst.plans.SQLHelper\n+import org.apache.spark.sql.internal.SQLConf\n+\n+/**\n+ * Common base trait to run benchmark with the Dataset and DataFrame API.\n+ */\n+trait SqlBasedBenchmark extends BenchmarkBase with SQLHelper {\n+\n+  val spark: SparkSession = getSparkSession\n+\n+  /** Subclass can override this function to build their own SparkSession */\n+  def getSparkSession: SparkSession = {\n+    SparkSession.builder()\n+      .master(\"local[1]\")\n+      .appName(this.getClass.getCanonicalName)\n+      .config(SQLConf.SHUFFLE_PARTITIONS.key, 1)\n+      .config(SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key, 1)\n+      .getOrCreate()\n+  }\n+\n+  /** Runs function `f` with whole stage codegen on and off. */",
    "line": 42
  }],
  "prId": 22484
}]