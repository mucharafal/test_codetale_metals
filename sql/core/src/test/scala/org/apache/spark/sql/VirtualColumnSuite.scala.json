[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "add a descriptive name for the test case in addition to the ticket name\n",
    "commit": "7932bf090671dc99e9f38c0eeb52e73c150303ca",
    "createdAt": "2015-07-17T20:37:36Z",
    "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.TestData._\n+\n+class VirtualColumnSuite extends QueryTest {\n+\n+  private lazy val ctx = org.apache.spark.sql.test.TestSQLContext\n+  import ctx.implicits._\n+\n+  test(\"sql resolve spark__partition__id\") {\n+    val df = ctx.sparkContext.parallelize(1 to 1, 1).map(i => (i, i)).toDF(\"a\", \"b\")\n+    df.registerTempTable(\"test_table\")\n+    checkAnswer(ctx.sql(\"select spark__partition__id from test_table\").toDF(), Row(0))\n+  }\n+\n+  test(\"SPARK-8007\") {"
  }],
  "prId": 7478
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Drop this table at the end of this test.\n",
    "commit": "7932bf090671dc99e9f38c0eeb52e73c150303ca",
    "createdAt": "2015-07-18T04:45:18Z",
    "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.TestData._\n+\n+class VirtualColumnSuite extends QueryTest {\n+\n+  private lazy val ctx = org.apache.spark.sql.test.TestSQLContext\n+  import ctx.implicits._\n+\n+  test(\"SQL resolve spark__partition__id - SPARK-8003\") {\n+    val df = ctx.sparkContext.parallelize(1 to 1, 1).map(i => (i, i)).toDF(\"a\", \"b\")\n+    df.registerTempTable(\"test_table\")"
  }],
  "prId": 7478
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Can you use checkAnswer?\n",
    "commit": "7932bf090671dc99e9f38c0eeb52e73c150303ca",
    "createdAt": "2015-07-18T04:45:30Z",
    "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.TestData._\n+\n+class VirtualColumnSuite extends QueryTest {\n+\n+  private lazy val ctx = org.apache.spark.sql.test.TestSQLContext\n+  import ctx.implicits._\n+\n+  test(\"SQL resolve spark__partition__id - SPARK-8003\") {\n+    val df = ctx.sparkContext.parallelize(1 to 1, 1).map(i => (i, i)).toDF(\"a\", \"b\")\n+    df.registerTempTable(\"test_table\")\n+    checkAnswer(ctx.sql(\"select spark__partition__id from test_table\").toDF(), Row(0))\n+  }\n+\n+  test(\"Group by Spark partition - SPARK-8007\") {\n+    val row = testData2.repartition(1).groupBy(\"spark__partition__id\").count().collect().head\n+    assert(row === Row(0, 6))"
  }],
  "prId": 7478
}]