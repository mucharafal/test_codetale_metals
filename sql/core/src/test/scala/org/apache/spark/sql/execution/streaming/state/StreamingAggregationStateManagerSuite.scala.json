[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This is an absolute shallow method, copying the exact same parameters to another method? Whats the point of it?",
    "commit": "19888abc281d7a0689bf57e4c76bda918ad9306b",
    "createdAt": "2018-08-08T08:04:51Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, SpecificInternalRow, UnsafeProjection, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection\n+import org.apache.spark.sql.streaming.StreamTest\n+import org.apache.spark.sql.types.{IntegerType, StructField, StructType}\n+\n+class StreamingAggregationStateManagerSuite extends StreamTest {\n+  // ============================ fields and method for test data ============================\n+\n+  val testKeys: Seq[String] = Seq(\"key1\", \"key2\")\n+  val testValues: Seq[String] = Seq(\"sum(key1)\", \"sum(key2)\")\n+\n+  val testOutputSchema: StructType = StructType(\n+    testKeys.map(createIntegerField) ++ testValues.map(createIntegerField))\n+\n+  val testOutputAttributes: Seq[Attribute] = testOutputSchema.toAttributes\n+  val testKeyAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testKeys.contains(p.name)\n+  }\n+  val testValuesAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testValues.contains(p.name)\n+  }\n+  val expectedTestValuesSchema: StructType = testValuesAttributes.toStructType\n+\n+  val testRow: UnsafeRow = {\n+    val unsafeRowProjection = UnsafeProjection.create(testOutputSchema)\n+    val row = unsafeRowProjection(new SpecificInternalRow(testOutputSchema))\n+    (testKeys ++ testValues).zipWithIndex.foreach { case (_, index) => row.setInt(index, index) }\n+    row\n+  }\n+\n+  val expectedTestKeyRow: UnsafeRow = {\n+    val keyProjector = GenerateUnsafeProjection.generate(testKeyAttributes, testOutputAttributes)\n+    keyProjector(testRow)\n+  }\n+\n+  val expectedTestValueRowForV2: UnsafeRow = {\n+    val valueProjector = GenerateUnsafeProjection.generate(testValuesAttributes,\n+      testOutputAttributes)\n+    valueProjector(testRow)\n+  }\n+\n+  private def createIntegerField(name: String): StructField = {\n+    StructField(name, IntegerType, nullable = false)\n+  }\n+\n+  // ============================ StateManagerImplV1 ============================\n+\n+  test(\"StateManager v1 - get, put, iter\") {\n+    val stateManager = newStateManager(testKeyAttributes, testOutputAttributes, 1)\n+\n+    // in V1, input row is stored as value\n+    testGetPutIterOnStateManager(stateManager, testOutputSchema, testRow,\n+      expectedTestKeyRow, testRow)\n+  }\n+\n+  // ============================ StateManagerImplV2 ============================\n+  test(\"StateManager v2 - get, put, iter\") {\n+    val stateManager = newStateManager(testKeyAttributes, testOutputAttributes, 2)\n+\n+    // in V2, row for values itself (excluding keys from input row) is stored as value\n+    // so that stored value doesn't have key part, but state manager V2 will provide same output\n+    // as V1 when getting row for key\n+    testGetPutIterOnStateManager(stateManager, expectedTestValuesSchema, testRow,\n+      expectedTestKeyRow, expectedTestValueRowForV2)\n+  }\n+\n+  private def newStateManager(\n+      keysAttributes: Seq[Attribute],\n+      inputRowAttributes: Seq[Attribute],\n+      version: Int): StreamingAggregationStateManager = {\n+    StreamingAggregationStateManager.createStateManager(keysAttributes, inputRowAttributes, version)"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "It reduces the code to make code less broader, so adding 5 more lines  vs removing `StreamingAggregationStateManager` from all calling spots.",
    "commit": "19888abc281d7a0689bf57e4c76bda918ad9306b",
    "createdAt": "2018-08-08T14:17:58Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, SpecificInternalRow, UnsafeProjection, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection\n+import org.apache.spark.sql.streaming.StreamTest\n+import org.apache.spark.sql.types.{IntegerType, StructField, StructType}\n+\n+class StreamingAggregationStateManagerSuite extends StreamTest {\n+  // ============================ fields and method for test data ============================\n+\n+  val testKeys: Seq[String] = Seq(\"key1\", \"key2\")\n+  val testValues: Seq[String] = Seq(\"sum(key1)\", \"sum(key2)\")\n+\n+  val testOutputSchema: StructType = StructType(\n+    testKeys.map(createIntegerField) ++ testValues.map(createIntegerField))\n+\n+  val testOutputAttributes: Seq[Attribute] = testOutputSchema.toAttributes\n+  val testKeyAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testKeys.contains(p.name)\n+  }\n+  val testValuesAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testValues.contains(p.name)\n+  }\n+  val expectedTestValuesSchema: StructType = testValuesAttributes.toStructType\n+\n+  val testRow: UnsafeRow = {\n+    val unsafeRowProjection = UnsafeProjection.create(testOutputSchema)\n+    val row = unsafeRowProjection(new SpecificInternalRow(testOutputSchema))\n+    (testKeys ++ testValues).zipWithIndex.foreach { case (_, index) => row.setInt(index, index) }\n+    row\n+  }\n+\n+  val expectedTestKeyRow: UnsafeRow = {\n+    val keyProjector = GenerateUnsafeProjection.generate(testKeyAttributes, testOutputAttributes)\n+    keyProjector(testRow)\n+  }\n+\n+  val expectedTestValueRowForV2: UnsafeRow = {\n+    val valueProjector = GenerateUnsafeProjection.generate(testValuesAttributes,\n+      testOutputAttributes)\n+    valueProjector(testRow)\n+  }\n+\n+  private def createIntegerField(name: String): StructField = {\n+    StructField(name, IntegerType, nullable = false)\n+  }\n+\n+  // ============================ StateManagerImplV1 ============================\n+\n+  test(\"StateManager v1 - get, put, iter\") {\n+    val stateManager = newStateManager(testKeyAttributes, testOutputAttributes, 1)\n+\n+    // in V1, input row is stored as value\n+    testGetPutIterOnStateManager(stateManager, testOutputSchema, testRow,\n+      expectedTestKeyRow, testRow)\n+  }\n+\n+  // ============================ StateManagerImplV2 ============================\n+  test(\"StateManager v2 - get, put, iter\") {\n+    val stateManager = newStateManager(testKeyAttributes, testOutputAttributes, 2)\n+\n+    // in V2, row for values itself (excluding keys from input row) is stored as value\n+    // so that stored value doesn't have key part, but state manager V2 will provide same output\n+    // as V1 when getting row for key\n+    testGetPutIterOnStateManager(stateManager, expectedTestValuesSchema, testRow,\n+      expectedTestKeyRow, expectedTestValueRowForV2)\n+  }\n+\n+  private def newStateManager(\n+      keysAttributes: Seq[Attribute],\n+      inputRowAttributes: Seq[Attribute],\n+      version: Int): StreamingAggregationStateManager = {\n+    StreamingAggregationStateManager.createStateManager(keysAttributes, inputRowAttributes, version)"
  }],
  "prId": 21733
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: last param `testRow` to `expectedStateValue = testRow` to make it clear what it means, and distinguish it from the previous `testRow` param",
    "commit": "19888abc281d7a0689bf57e4c76bda918ad9306b",
    "createdAt": "2018-08-08T08:06:30Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, SpecificInternalRow, UnsafeProjection, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection\n+import org.apache.spark.sql.streaming.StreamTest\n+import org.apache.spark.sql.types.{IntegerType, StructField, StructType}\n+\n+class StreamingAggregationStateManagerSuite extends StreamTest {\n+  // ============================ fields and method for test data ============================\n+\n+  val testKeys: Seq[String] = Seq(\"key1\", \"key2\")\n+  val testValues: Seq[String] = Seq(\"sum(key1)\", \"sum(key2)\")\n+\n+  val testOutputSchema: StructType = StructType(\n+    testKeys.map(createIntegerField) ++ testValues.map(createIntegerField))\n+\n+  val testOutputAttributes: Seq[Attribute] = testOutputSchema.toAttributes\n+  val testKeyAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testKeys.contains(p.name)\n+  }\n+  val testValuesAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testValues.contains(p.name)\n+  }\n+  val expectedTestValuesSchema: StructType = testValuesAttributes.toStructType\n+\n+  val testRow: UnsafeRow = {\n+    val unsafeRowProjection = UnsafeProjection.create(testOutputSchema)\n+    val row = unsafeRowProjection(new SpecificInternalRow(testOutputSchema))\n+    (testKeys ++ testValues).zipWithIndex.foreach { case (_, index) => row.setInt(index, index) }\n+    row\n+  }\n+\n+  val expectedTestKeyRow: UnsafeRow = {\n+    val keyProjector = GenerateUnsafeProjection.generate(testKeyAttributes, testOutputAttributes)\n+    keyProjector(testRow)\n+  }\n+\n+  val expectedTestValueRowForV2: UnsafeRow = {\n+    val valueProjector = GenerateUnsafeProjection.generate(testValuesAttributes,\n+      testOutputAttributes)\n+    valueProjector(testRow)\n+  }\n+\n+  private def createIntegerField(name: String): StructField = {\n+    StructField(name, IntegerType, nullable = false)\n+  }\n+\n+  // ============================ StateManagerImplV1 ============================\n+\n+  test(\"StateManager v1 - get, put, iter\") {\n+    val stateManager = newStateManager(testKeyAttributes, testOutputAttributes, 1)\n+\n+    // in V1, input row is stored as value\n+    testGetPutIterOnStateManager(stateManager, testOutputSchema, testRow,\n+      expectedTestKeyRow, testRow)"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Sounds great. Will address.",
    "commit": "19888abc281d7a0689bf57e4c76bda918ad9306b",
    "createdAt": "2018-08-08T14:14:24Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, SpecificInternalRow, UnsafeProjection, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection\n+import org.apache.spark.sql.streaming.StreamTest\n+import org.apache.spark.sql.types.{IntegerType, StructField, StructType}\n+\n+class StreamingAggregationStateManagerSuite extends StreamTest {\n+  // ============================ fields and method for test data ============================\n+\n+  val testKeys: Seq[String] = Seq(\"key1\", \"key2\")\n+  val testValues: Seq[String] = Seq(\"sum(key1)\", \"sum(key2)\")\n+\n+  val testOutputSchema: StructType = StructType(\n+    testKeys.map(createIntegerField) ++ testValues.map(createIntegerField))\n+\n+  val testOutputAttributes: Seq[Attribute] = testOutputSchema.toAttributes\n+  val testKeyAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testKeys.contains(p.name)\n+  }\n+  val testValuesAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testValues.contains(p.name)\n+  }\n+  val expectedTestValuesSchema: StructType = testValuesAttributes.toStructType\n+\n+  val testRow: UnsafeRow = {\n+    val unsafeRowProjection = UnsafeProjection.create(testOutputSchema)\n+    val row = unsafeRowProjection(new SpecificInternalRow(testOutputSchema))\n+    (testKeys ++ testValues).zipWithIndex.foreach { case (_, index) => row.setInt(index, index) }\n+    row\n+  }\n+\n+  val expectedTestKeyRow: UnsafeRow = {\n+    val keyProjector = GenerateUnsafeProjection.generate(testKeyAttributes, testOutputAttributes)\n+    keyProjector(testRow)\n+  }\n+\n+  val expectedTestValueRowForV2: UnsafeRow = {\n+    val valueProjector = GenerateUnsafeProjection.generate(testValuesAttributes,\n+      testOutputAttributes)\n+    valueProjector(testRow)\n+  }\n+\n+  private def createIntegerField(name: String): StructField = {\n+    StructField(name, IntegerType, nullable = false)\n+  }\n+\n+  // ============================ StateManagerImplV1 ============================\n+\n+  test(\"StateManager v1 - get, put, iter\") {\n+    val stateManager = newStateManager(testKeyAttributes, testOutputAttributes, 1)\n+\n+    // in V1, input row is stored as value\n+    testGetPutIterOnStateManager(stateManager, testOutputSchema, testRow,\n+      expectedTestKeyRow, testRow)"
  }],
  "prId": 21733
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: extra line.",
    "commit": "19888abc281d7a0689bf57e4c76bda918ad9306b",
    "createdAt": "2018-08-08T08:07:06Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, SpecificInternalRow, UnsafeProjection, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection\n+import org.apache.spark.sql.streaming.StreamTest\n+import org.apache.spark.sql.types.{IntegerType, StructField, StructType}\n+\n+class StreamingAggregationStateManagerSuite extends StreamTest {\n+  // ============================ fields and method for test data ============================\n+\n+  val testKeys: Seq[String] = Seq(\"key1\", \"key2\")\n+  val testValues: Seq[String] = Seq(\"sum(key1)\", \"sum(key2)\")\n+\n+  val testOutputSchema: StructType = StructType(\n+    testKeys.map(createIntegerField) ++ testValues.map(createIntegerField))\n+\n+  val testOutputAttributes: Seq[Attribute] = testOutputSchema.toAttributes\n+  val testKeyAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testKeys.contains(p.name)\n+  }\n+  val testValuesAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testValues.contains(p.name)\n+  }\n+  val expectedTestValuesSchema: StructType = testValuesAttributes.toStructType\n+\n+  val testRow: UnsafeRow = {\n+    val unsafeRowProjection = UnsafeProjection.create(testOutputSchema)\n+    val row = unsafeRowProjection(new SpecificInternalRow(testOutputSchema))\n+    (testKeys ++ testValues).zipWithIndex.foreach { case (_, index) => row.setInt(index, index) }\n+    row\n+  }\n+\n+  val expectedTestKeyRow: UnsafeRow = {\n+    val keyProjector = GenerateUnsafeProjection.generate(testKeyAttributes, testOutputAttributes)\n+    keyProjector(testRow)\n+  }\n+\n+  val expectedTestValueRowForV2: UnsafeRow = {\n+    val valueProjector = GenerateUnsafeProjection.generate(testValuesAttributes,\n+      testOutputAttributes)\n+    valueProjector(testRow)\n+  }\n+\n+  private def createIntegerField(name: String): StructField = {\n+    StructField(name, IntegerType, nullable = false)\n+  }\n+\n+  // ============================ StateManagerImplV1 ============================\n+\n+  test(\"StateManager v1 - get, put, iter\") {\n+    val stateManager = newStateManager(testKeyAttributes, testOutputAttributes, 1)\n+\n+    // in V1, input row is stored as value\n+    testGetPutIterOnStateManager(stateManager, testOutputSchema, testRow,\n+      expectedTestKeyRow, testRow)\n+  }\n+\n+  // ============================ StateManagerImplV2 ============================\n+  test(\"StateManager v2 - get, put, iter\") {\n+    val stateManager = newStateManager(testKeyAttributes, testOutputAttributes, 2)\n+\n+    // in V2, row for values itself (excluding keys from input row) is stored as value\n+    // so that stored value doesn't have key part, but state manager V2 will provide same output\n+    // as V1 when getting row for key\n+    testGetPutIterOnStateManager(stateManager, expectedTestValuesSchema, testRow,\n+      expectedTestKeyRow, expectedTestValueRowForV2)\n+  }\n+\n+  private def newStateManager(\n+      keysAttributes: Seq[Attribute],\n+      inputRowAttributes: Seq[Attribute],\n+      version: Int): StreamingAggregationStateManager = {\n+    StreamingAggregationStateManager.createStateManager(keysAttributes, inputRowAttributes, version)\n+  }\n+\n+  private def testGetPutIterOnStateManager(\n+      stateManager: StreamingAggregationStateManager,\n+      expectedValueSchema: StructType,\n+      inputRow: UnsafeRow,\n+      expectedStateKey: UnsafeRow,\n+      expectedStateValue: UnsafeRow): Unit = {\n+\n+    assert(stateManager.getStateValueSchema === expectedValueSchema)\n+\n+    val memoryStateStore = new MemoryStateStore()\n+    stateManager.put(memoryStateStore, inputRow)\n+\n+    assert(memoryStateStore.iterator().size === 1)\n+    assert(stateManager.iterator(memoryStateStore).size === memoryStateStore.iterator().size)\n+\n+    val keyRow = stateManager.getKey(inputRow)\n+    assert(keyRow === expectedStateKey)\n+\n+    // iterate state store and verify whether expected format of key and value are stored\n+    val pair = memoryStateStore.iterator().next()\n+    assert(pair.key === keyRow)\n+    assert(pair.value === expectedStateValue)\n+\n+    // iterate with state manager and see whether original rows are returned as values\n+    val pairFromStateManager = stateManager.iterator(memoryStateStore).next()\n+    assert(pairFromStateManager.key === keyRow)\n+    assert(pairFromStateManager.value === inputRow)\n+\n+    // following as keys and values\n+    assert(stateManager.keys(memoryStateStore).next() === keyRow)\n+    assert(stateManager.values(memoryStateStore).next() === inputRow)\n+\n+    // verify the stored value once again via get\n+    assert(memoryStateStore.get(keyRow) === expectedStateValue)\n+\n+    // state manager should return row which is same as input row regardless of format version\n+    assert(inputRow === stateManager.get(memoryStateStore, keyRow))\n+  }\n+"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Will remove.",
    "commit": "19888abc281d7a0689bf57e4c76bda918ad9306b",
    "createdAt": "2018-08-08T14:15:06Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.execution.streaming.state\n+\n+import org.apache.spark.sql.catalyst.expressions.{Attribute, SpecificInternalRow, UnsafeProjection, UnsafeRow}\n+import org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection\n+import org.apache.spark.sql.streaming.StreamTest\n+import org.apache.spark.sql.types.{IntegerType, StructField, StructType}\n+\n+class StreamingAggregationStateManagerSuite extends StreamTest {\n+  // ============================ fields and method for test data ============================\n+\n+  val testKeys: Seq[String] = Seq(\"key1\", \"key2\")\n+  val testValues: Seq[String] = Seq(\"sum(key1)\", \"sum(key2)\")\n+\n+  val testOutputSchema: StructType = StructType(\n+    testKeys.map(createIntegerField) ++ testValues.map(createIntegerField))\n+\n+  val testOutputAttributes: Seq[Attribute] = testOutputSchema.toAttributes\n+  val testKeyAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testKeys.contains(p.name)\n+  }\n+  val testValuesAttributes: Seq[Attribute] = testOutputAttributes.filter { p =>\n+    testValues.contains(p.name)\n+  }\n+  val expectedTestValuesSchema: StructType = testValuesAttributes.toStructType\n+\n+  val testRow: UnsafeRow = {\n+    val unsafeRowProjection = UnsafeProjection.create(testOutputSchema)\n+    val row = unsafeRowProjection(new SpecificInternalRow(testOutputSchema))\n+    (testKeys ++ testValues).zipWithIndex.foreach { case (_, index) => row.setInt(index, index) }\n+    row\n+  }\n+\n+  val expectedTestKeyRow: UnsafeRow = {\n+    val keyProjector = GenerateUnsafeProjection.generate(testKeyAttributes, testOutputAttributes)\n+    keyProjector(testRow)\n+  }\n+\n+  val expectedTestValueRowForV2: UnsafeRow = {\n+    val valueProjector = GenerateUnsafeProjection.generate(testValuesAttributes,\n+      testOutputAttributes)\n+    valueProjector(testRow)\n+  }\n+\n+  private def createIntegerField(name: String): StructField = {\n+    StructField(name, IntegerType, nullable = false)\n+  }\n+\n+  // ============================ StateManagerImplV1 ============================\n+\n+  test(\"StateManager v1 - get, put, iter\") {\n+    val stateManager = newStateManager(testKeyAttributes, testOutputAttributes, 1)\n+\n+    // in V1, input row is stored as value\n+    testGetPutIterOnStateManager(stateManager, testOutputSchema, testRow,\n+      expectedTestKeyRow, testRow)\n+  }\n+\n+  // ============================ StateManagerImplV2 ============================\n+  test(\"StateManager v2 - get, put, iter\") {\n+    val stateManager = newStateManager(testKeyAttributes, testOutputAttributes, 2)\n+\n+    // in V2, row for values itself (excluding keys from input row) is stored as value\n+    // so that stored value doesn't have key part, but state manager V2 will provide same output\n+    // as V1 when getting row for key\n+    testGetPutIterOnStateManager(stateManager, expectedTestValuesSchema, testRow,\n+      expectedTestKeyRow, expectedTestValueRowForV2)\n+  }\n+\n+  private def newStateManager(\n+      keysAttributes: Seq[Attribute],\n+      inputRowAttributes: Seq[Attribute],\n+      version: Int): StreamingAggregationStateManager = {\n+    StreamingAggregationStateManager.createStateManager(keysAttributes, inputRowAttributes, version)\n+  }\n+\n+  private def testGetPutIterOnStateManager(\n+      stateManager: StreamingAggregationStateManager,\n+      expectedValueSchema: StructType,\n+      inputRow: UnsafeRow,\n+      expectedStateKey: UnsafeRow,\n+      expectedStateValue: UnsafeRow): Unit = {\n+\n+    assert(stateManager.getStateValueSchema === expectedValueSchema)\n+\n+    val memoryStateStore = new MemoryStateStore()\n+    stateManager.put(memoryStateStore, inputRow)\n+\n+    assert(memoryStateStore.iterator().size === 1)\n+    assert(stateManager.iterator(memoryStateStore).size === memoryStateStore.iterator().size)\n+\n+    val keyRow = stateManager.getKey(inputRow)\n+    assert(keyRow === expectedStateKey)\n+\n+    // iterate state store and verify whether expected format of key and value are stored\n+    val pair = memoryStateStore.iterator().next()\n+    assert(pair.key === keyRow)\n+    assert(pair.value === expectedStateValue)\n+\n+    // iterate with state manager and see whether original rows are returned as values\n+    val pairFromStateManager = stateManager.iterator(memoryStateStore).next()\n+    assert(pairFromStateManager.key === keyRow)\n+    assert(pairFromStateManager.value === inputRow)\n+\n+    // following as keys and values\n+    assert(stateManager.keys(memoryStateStore).next() === keyRow)\n+    assert(stateManager.values(memoryStateStore).next() === inputRow)\n+\n+    // verify the stored value once again via get\n+    assert(memoryStateStore.get(keyRow) === expectedStateValue)\n+\n+    // state manager should return row which is same as input row regardless of format version\n+    assert(inputRow === stateManager.get(memoryStateStore, keyRow))\n+  }\n+"
  }],
  "prId": 21733
}]