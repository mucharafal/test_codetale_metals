[{
  "comments": [{
    "author": {
      "login": "skambha"
    },
    "body": "This udf optimization rule is as part of the operator optimization batch.  One other option we could consider is to move it after the 'Check Cartesian Products' batch. ",
    "commit": "93241b30eeb071d575142b26db36c40cad5b93b6",
    "createdAt": "2019-06-12T22:29:12Z",
    "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql\n+\n+import org.apache.spark.sql.catalyst.expressions.ScalaUDF\n+import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan\n+import org.apache.spark.sql.functions.udf\n+import org.apache.spark.sql.internal.SQLConf\n+import org.apache.spark.sql.test.SharedSQLContext\n+\n+class DeterministicLiteralUDFFoldingSuite extends QueryTest with SharedSQLContext {\n+  import testImplicits._\n+\n+  test(\"Deterministic and literal UDF optimization\") {\n+    def udfNodesCount(plan: LogicalPlan): Int = {\n+      plan.expressions.head.children.collect({\n+        case f: ScalaUDF => f\n+      }).length\n+    }\n+\n+    val foo = udf(() => Math.random()).asNondeterministic()\n+    spark.udf.register(\"random0\", foo)\n+    assert(!foo.deterministic)\n+    val foo2 = udf((x: String, i: Int) => x.length + i)\n+    spark.udf.register(\"mystrlen\", foo2)\n+    assert(foo2.deterministic)\n+\n+    Seq((\"true\", (1, 0, 0, 1)), (\"false\", (1, 1, 1, 1))).foreach { case (flag, expectedCounts) =>\n+      withSQLConf(SQLConf.DETERMINISTIC_LITERAL_UDF_FOLDING_ENABLED.key -> flag) {\n+        // Non deterministic\n+        val plan = sql(\"SELECT random0()\").queryExecution.optimizedPlan\n+        assert(udfNodesCount(plan) == expectedCounts._1)\n+\n+        // udf is deterministic and args are literal\n+        assert(sql(\"SELECT mystrlen('abc', 1)\").head().getInt(0) == 4)\n+        val plan2 = sql(\"SELECT mystrlen('abc', 1)\").queryExecution.optimizedPlan\n+        assert(udfNodesCount(plan2) == expectedCounts._2)\n+        val plan3 = sql(\"SELECT mystrlen('abc', mystrlen('c', 1))\").queryExecution.optimizedPlan\n+        assert(udfNodesCount(plan3) == expectedCounts._3)\n+\n+        // udf is deterministic and args are not literal\n+        withTempView(\"temp1\") {\n+          val df = sparkContext.parallelize(\n+            (1 to 10).map(i => i.toString)).toDF(\"i1\")\n+          df.createOrReplaceTempView(\"temp1\")\n+          val plan = sql(\"SELECT mystrlen(i1, 1) FROM temp1\").queryExecution.optimizedPlan\n+          assert(udfNodesCount(plan) == expectedCounts._4)\n+        }\n+      }\n+    }\n+  }\n+\n+  test(\"udf folding rule in join\") {\n+    withTempView(\"temp1\") {\n+      val df = sparkContext.parallelize((1 to 5).map(i => i.toString)).toDF(\"i1\")\n+      df.createOrReplaceTempView(\"temp1\")\n+      val foo = udf((x: String, i: Int) => x.length + i)\n+      spark.udf.register(\"mystrlen1\", foo)\n+      assert(foo.deterministic)\n+\n+      val query = \"SELECT mystrlen1(i1, 1) FROM temp1, \" +\n+        \"(SELECT mystrlen1('abc', mystrlen1('c', 1)) AS ref) WHERE mystrlen1(i1, ref) > 1\"\n+      assert(sql(query).count() == 5)\n+\n+      withSQLConf(SQLConf.DETERMINISTIC_LITERAL_UDF_FOLDING_ENABLED.key -> \"true\") {\n+        val exception = intercept[AnalysisException] {\n+          sql(query).count()\n+        }\n+        assert(exception.message.startsWith(\"Detected implicit cartesian product\"))\n+\n+        withSQLConf(SQLConf.CROSS_JOINS_ENABLED.key -> \"true\") {",
    "line": 86
  }],
  "prId": 24593
}]