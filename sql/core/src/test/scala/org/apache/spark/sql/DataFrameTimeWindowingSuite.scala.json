[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "The same here.",
    "commit": "09ae105c101a1b31d2a8873976c01590c50411d2",
    "createdAt": "2017-10-01T04:32:09Z",
    "diffHunk": "@@ -95,50 +96,62 @@ class DataFrameTimeWindowingSuite extends QueryTest with SharedSQLContext with B\n   }\n \n   test(\"sliding window grouping\") {\n-    val df = Seq(\n-      (\"2016-03-27 19:39:34\", 1, \"a\"),\n-      (\"2016-03-27 19:39:56\", 2, \"a\"),\n-      (\"2016-03-27 19:39:27\", 4, \"b\")).toDF(\"time\", \"value\", \"id\")\n-\n-    checkAnswer(\n-      df.groupBy(window($\"time\", \"10 seconds\", \"3 seconds\", \"0 second\"))\n-        .agg(count(\"*\").as(\"counts\"))\n-        .orderBy($\"window.start\".asc)\n-        .select($\"window.start\".cast(\"string\"), $\"window.end\".cast(\"string\"), $\"counts\"),\n-      // 2016-03-27 19:39:27 UTC -> 4 bins\n-      // 2016-03-27 19:39:34 UTC -> 3 bins\n-      // 2016-03-27 19:39:56 UTC -> 3 bins\n-      Seq(\n-        Row(\"2016-03-27 19:39:18\", \"2016-03-27 19:39:28\", 1),\n-        Row(\"2016-03-27 19:39:21\", \"2016-03-27 19:39:31\", 1),\n-        Row(\"2016-03-27 19:39:24\", \"2016-03-27 19:39:34\", 1),\n-        Row(\"2016-03-27 19:39:27\", \"2016-03-27 19:39:37\", 2),\n-        Row(\"2016-03-27 19:39:30\", \"2016-03-27 19:39:40\", 1),\n-        Row(\"2016-03-27 19:39:33\", \"2016-03-27 19:39:43\", 1),\n-        Row(\"2016-03-27 19:39:48\", \"2016-03-27 19:39:58\", 1),\n-        Row(\"2016-03-27 19:39:51\", \"2016-03-27 19:40:01\", 1),\n-        Row(\"2016-03-27 19:39:54\", \"2016-03-27 19:40:04\", 1))\n-    )\n-  }\n-\n-  test(\"sliding window projection\") {\n-    val df = Seq(\n+    // In SPARK-21871, we added code to check the actual bytecode size of gen'd methods. If the size\n+    // goes over `hugeMethodLimit`, Spark fails to compile the methods and the execution also fails\n+    // in a test mode. So, we explicitly turn off whole-stage codegen here.\n+    // This guard can be removed if this issue fixed.\n+    withSQLConf(SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key -> \"false\") {"
  }],
  "prId": 19083
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "The same here. ",
    "commit": "09ae105c101a1b31d2a8873976c01590c50411d2",
    "createdAt": "2017-10-01T04:32:24Z",
    "diffHunk": "@@ -95,50 +96,62 @@ class DataFrameTimeWindowingSuite extends QueryTest with SharedSQLContext with B\n   }\n \n   test(\"sliding window grouping\") {\n-    val df = Seq(\n-      (\"2016-03-27 19:39:34\", 1, \"a\"),\n-      (\"2016-03-27 19:39:56\", 2, \"a\"),\n-      (\"2016-03-27 19:39:27\", 4, \"b\")).toDF(\"time\", \"value\", \"id\")\n-\n-    checkAnswer(\n-      df.groupBy(window($\"time\", \"10 seconds\", \"3 seconds\", \"0 second\"))\n-        .agg(count(\"*\").as(\"counts\"))\n-        .orderBy($\"window.start\".asc)\n-        .select($\"window.start\".cast(\"string\"), $\"window.end\".cast(\"string\"), $\"counts\"),\n-      // 2016-03-27 19:39:27 UTC -> 4 bins\n-      // 2016-03-27 19:39:34 UTC -> 3 bins\n-      // 2016-03-27 19:39:56 UTC -> 3 bins\n-      Seq(\n-        Row(\"2016-03-27 19:39:18\", \"2016-03-27 19:39:28\", 1),\n-        Row(\"2016-03-27 19:39:21\", \"2016-03-27 19:39:31\", 1),\n-        Row(\"2016-03-27 19:39:24\", \"2016-03-27 19:39:34\", 1),\n-        Row(\"2016-03-27 19:39:27\", \"2016-03-27 19:39:37\", 2),\n-        Row(\"2016-03-27 19:39:30\", \"2016-03-27 19:39:40\", 1),\n-        Row(\"2016-03-27 19:39:33\", \"2016-03-27 19:39:43\", 1),\n-        Row(\"2016-03-27 19:39:48\", \"2016-03-27 19:39:58\", 1),\n-        Row(\"2016-03-27 19:39:51\", \"2016-03-27 19:40:01\", 1),\n-        Row(\"2016-03-27 19:39:54\", \"2016-03-27 19:40:04\", 1))\n-    )\n-  }\n-\n-  test(\"sliding window projection\") {\n-    val df = Seq(\n+    // In SPARK-21871, we added code to check the actual bytecode size of gen'd methods. If the size\n+    // goes over `hugeMethodLimit`, Spark fails to compile the methods and the execution also fails\n+    // in a test mode. So, we explicitly turn off whole-stage codegen here.\n+    // This guard can be removed if this issue fixed.\n+    withSQLConf(SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key -> \"false\") {\n+      val df = Seq(\n         (\"2016-03-27 19:39:34\", 1, \"a\"),\n         (\"2016-03-27 19:39:56\", 2, \"a\"),\n         (\"2016-03-27 19:39:27\", 4, \"b\")).toDF(\"time\", \"value\", \"id\")\n-      .select(window($\"time\", \"10 seconds\", \"3 seconds\", \"0 second\"), $\"value\")\n-      .orderBy($\"window.start\".asc, $\"value\".desc).select(\"value\")\n \n-    val expands = df.queryExecution.optimizedPlan.find(_.isInstanceOf[Expand])\n-    assert(expands.nonEmpty, \"Sliding windows require expand\")\n+      checkAnswer(\n+        df.groupBy(window($\"time\", \"10 seconds\", \"3 seconds\", \"0 second\"))\n+          .agg(count(\"*\").as(\"counts\"))\n+          .orderBy($\"window.start\".asc)\n+          .select($\"window.start\".cast(\"string\"), $\"window.end\".cast(\"string\"), $\"counts\"),\n+        // 2016-03-27 19:39:27 UTC -> 4 bins\n+        // 2016-03-27 19:39:34 UTC -> 3 bins\n+        // 2016-03-27 19:39:56 UTC -> 3 bins\n+        Seq(\n+          Row(\"2016-03-27 19:39:18\", \"2016-03-27 19:39:28\", 1),\n+          Row(\"2016-03-27 19:39:21\", \"2016-03-27 19:39:31\", 1),\n+          Row(\"2016-03-27 19:39:24\", \"2016-03-27 19:39:34\", 1),\n+          Row(\"2016-03-27 19:39:27\", \"2016-03-27 19:39:37\", 2),\n+          Row(\"2016-03-27 19:39:30\", \"2016-03-27 19:39:40\", 1),\n+          Row(\"2016-03-27 19:39:33\", \"2016-03-27 19:39:43\", 1),\n+          Row(\"2016-03-27 19:39:48\", \"2016-03-27 19:39:58\", 1),\n+          Row(\"2016-03-27 19:39:51\", \"2016-03-27 19:40:01\", 1),\n+          Row(\"2016-03-27 19:39:54\", \"2016-03-27 19:40:04\", 1))\n+      )\n+    }\n+  }\n \n-    checkAnswer(\n-      df,\n-      // 2016-03-27 19:39:27 UTC -> 4 bins\n-      // 2016-03-27 19:39:34 UTC -> 3 bins\n-      // 2016-03-27 19:39:56 UTC -> 3 bins\n-      Seq(Row(4), Row(4), Row(4), Row(4), Row(1), Row(1), Row(1), Row(2), Row(2), Row(2))\n-    )\n+  test(\"sliding window projection\") {\n+    // In SPARK-21871, we added code to check the actual bytecode size of gen'd methods. If the size\n+    // goes over `hugeMethodLimit`, Spark fails to compile the methods and the execution also fails\n+    // in a test mode. So, we explicitly turn off whole-stage codegen here.\n+    // This guard can be removed if this issue fixed.\n+    withSQLConf(SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key -> \"false\") {"
  }],
  "prId": 19083
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "The same here.",
    "commit": "09ae105c101a1b31d2a8873976c01590c50411d2",
    "createdAt": "2017-10-01T04:32:35Z",
    "diffHunk": "@@ -228,29 +241,35 @@ class DataFrameTimeWindowingSuite extends QueryTest with SharedSQLContext with B\n   }\n \n   test(\"millisecond precision sliding windows\") {\n-    val df = Seq(\n-      (\"2016-03-27 09:00:00.41\", 3),\n-      (\"2016-03-27 09:00:00.62\", 6),\n-      (\"2016-03-27 09:00:00.715\", 8)).toDF(\"time\", \"value\")\n-    checkAnswer(\n-      df.groupBy(window($\"time\", \"200 milliseconds\", \"40 milliseconds\", \"0 milliseconds\"))\n-        .agg(count(\"*\").as(\"counts\"))\n-        .orderBy($\"window.start\".asc)\n-        .select($\"window.start\".cast(StringType), $\"window.end\".cast(StringType), $\"counts\"),\n-      Seq(\n-        Row(\"2016-03-27 09:00:00.24\", \"2016-03-27 09:00:00.44\", 1),\n-        Row(\"2016-03-27 09:00:00.28\", \"2016-03-27 09:00:00.48\", 1),\n-        Row(\"2016-03-27 09:00:00.32\", \"2016-03-27 09:00:00.52\", 1),\n-        Row(\"2016-03-27 09:00:00.36\", \"2016-03-27 09:00:00.56\", 1),\n-        Row(\"2016-03-27 09:00:00.4\", \"2016-03-27 09:00:00.6\", 1),\n-        Row(\"2016-03-27 09:00:00.44\", \"2016-03-27 09:00:00.64\", 1),\n-        Row(\"2016-03-27 09:00:00.48\", \"2016-03-27 09:00:00.68\", 1),\n-        Row(\"2016-03-27 09:00:00.52\", \"2016-03-27 09:00:00.72\", 2),\n-        Row(\"2016-03-27 09:00:00.56\", \"2016-03-27 09:00:00.76\", 2),\n-        Row(\"2016-03-27 09:00:00.6\", \"2016-03-27 09:00:00.8\", 2),\n-        Row(\"2016-03-27 09:00:00.64\", \"2016-03-27 09:00:00.84\", 1),\n-        Row(\"2016-03-27 09:00:00.68\", \"2016-03-27 09:00:00.88\", 1))\n-    )\n+    // In SPARK-21871, we added code to check the actual bytecode size of gen'd methods. If the size\n+    // goes over `hugeMethodLimit`, Spark fails to compile the methods and the execution also fails\n+    // in a test mode. So, we explicitly turn off whole-stage codegen here.\n+    // This guard can be removed if this issue fixed.\n+    withSQLConf(SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key -> \"false\") {"
  }],
  "prId": 19083
}]