[{
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "Need to use `FileStreamSourceLog` here to add FileEntry as the latest master uses it to compact File source's logs.\n",
    "commit": "666c2c50114349eeae5bf0d532e03a13de09c434",
    "createdAt": "2016-09-21T20:29:15Z",
    "diffHunk": "@@ -73,4 +83,44 @@ class FileStreamSourceSuite extends SparkFunSuite {\n     assert(map.isNewFile(FileEntry(\"b\", 10)))\n   }\n \n+  testWithUninterruptibleThread(\"do not recheck that files exist during getBatch\") {\n+    withTempDir { temp =>\n+      spark.conf.set(\n+        s\"fs.$scheme.impl\",\n+        classOf[ExistsThrowsExceptionFileSystem].getName)\n+      // add the metadata entries as a pre-req\n+      val dir = new File(temp, \"dir\") // use non-existent directory to test whether log make the dir\n+      val metadataLog = new HDFSMetadataLog[Array[FileEntry]](spark, dir.getAbsolutePath)"
  }],
  "prId": 15122
}]