[{
  "comments": [{
    "author": {
      "login": "gengliangwang"
    },
    "body": "Nit: It would be better if the SQL keywords are all in UPPERCASE.",
    "commit": "2d86681e0ba8bc5ef13f5630fc640d4042ddba7a",
    "createdAt": "2019-10-21T10:05:23Z",
    "diffHunk": "@@ -0,0 +1,285 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/window.sql#L320-562\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+select last(salary) over(order by salary range between 1000 preceding and 1000 following),",
    "line": 97
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "I can make them uppercase, but, are you sure? I think that in PostgreSQL they are not always uppercase, such that the diff will be totally different.",
    "commit": "2d86681e0ba8bc5ef13f5630fc640d4042ddba7a",
    "createdAt": "2019-10-22T00:46:11Z",
    "diffHunk": "@@ -0,0 +1,285 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/window.sql#L320-562\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+select last(salary) over(order by salary range between 1000 preceding and 1000 following),",
    "line": 97
  }],
  "prId": 26121
}]