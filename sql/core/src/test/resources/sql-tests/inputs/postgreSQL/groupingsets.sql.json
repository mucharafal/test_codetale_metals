[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Does `primary key` affect this query? Otherwise, we can remove `SPARK-19842` here.",
    "commit": "d7f6909613631b4ea3dfa62a172a9565a213c4ce",
    "createdAt": "2019-11-05T01:32:37Z",
    "diffHunk": "@@ -0,0 +1,563 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- GROUPING SETS\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/groupingsets.sql\n+\n+-- test data sources\n+\n+create temp view gstest1(a,b,v)\n+  as values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),\n+            (2,3,15),\n+            (3,3,16),(3,4,17),\n+            (4,1,18),(4,1,19);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest2 (a integer, b integer, c integer, d integer,\n+--                            e integer, f integer, g integer, h integer);\n+create table gstest2 (a integer, b integer, c integer, d integer,\n+                      e integer, f integer, g integer, h integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest2 from stdin;\n+-- 1\t1\t1\t1\t1\t1\t1\t1\n+-- 1\t1\t1\t1\t1\t1\t1\t2\n+-- 1\t1\t1\t1\t1\t1\t2\t2\n+-- 1\t1\t1\t1\t1\t2\t2\t2\n+-- 1\t1\t1\t1\t2\t2\t2\t2\n+-- 1\t1\t1\t2\t2\t2\t2\t2\n+-- 1\t1\t2\t2\t2\t2\t2\t2\n+-- 1\t2\t2\t2\t2\t2\t2\t2\n+-- 2\t2\t2\t2\t2\t2\t2\t2\n+-- \\.\n+insert into gstest2 values\n+  (1, 1, 1, 1, 1, 1, 1, 1),\n+  (1, 1, 1, 1, 1, 1, 1, 2),\n+  (1, 1, 1, 1, 1, 1, 2, 2),\n+  (1, 1, 1, 1, 1, 2, 2, 2),\n+  (1, 1, 1, 1, 2, 2, 2, 2),\n+  (1, 1, 1, 2, 2, 2, 2, 2),\n+  (1, 1, 2, 2, 2, 2, 2, 2),\n+  (1, 2, 2, 2, 2, 2, 2, 2),\n+  (2, 2, 2, 2, 2, 2, 2, 2);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest3 (a integer, b integer, c integer, d integer);\n+create table gstest3 (a integer, b integer, c integer, d integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest3 from stdin;\n+-- 1\t1\t1\t1\n+-- 2\t2\t2\t2\n+-- \\.\n+insert into gstest3 values\n+  (1, 1, 1, 1),\n+  (2, 2, 2, 2);\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- alter table gstest3 add primary key (a);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest4(id integer, v integer,\n+--                           unhashable_col bit(4), unsortable_col xid);\n+-- [SPARK-29697] Support bit string types/literals\n+create table gstest4(id integer, v integer,\n+                     unhashable_col /* bit(4) */ byte, unsortable_col /* xid */ integer) using parquet;\n+insert into gstest4\n+-- values (1,1,b'0000','1'), (2,2,b'0001','1'),\n+--        (3,4,b'0010','2'), (4,8,b'0011','2'),\n+--        (5,16,b'0000','2'), (6,32,b'0001','2'),\n+--        (7,64,b'0010','1'), (8,128,b'0011','1');\n+values (1,1,tinyint('0'),1), (2,2,tinyint('1'),1),\n+       (3,4,tinyint('2'),2), (4,8,tinyint('3'),2),\n+       (5,16,tinyint('0'),2), (6,32,tinyint('1'),2),\n+       (7,64,tinyint('2'),1), (8,128,tinyint('3'),1);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest_empty (a integer, b integer, v integer);\n+create table gstest_empty (a integer, b integer, v integer) using parquet;\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- create function gstest_data(v integer, out a integer, out b integer)\n+--   returns setof record\n+--   as $f$\n+--     begin\n+--       return query select v, i from generate_series(1,3) i;\n+--     end;\n+--   $f$ language plpgsql;\n+\n+-- basic functionality\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = false;  -- test hashing explicitly later\n+\n+-- simple rollup with multiple plain aggregates, with and without ordering\n+-- (and with ordering differing from grouping)\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b);\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by a,b;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by b desc, a;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by coalesce(a,0)+coalesce(b,0);\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- various types of ordered aggs\n+-- select a, b, grouping(a,b),\n+--        array_agg(v order by v),\n+--        string_agg(string(v:text, ':' order by v desc),\n+--        percentile_disc(0.5) within group (order by v),\n+--        rank(1,2,12) within group (order by a,b,v)\n+--   from gstest1 group by rollup (a,b) order by a,b;\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- test usage of grouped columns in direct args of aggs\n+-- select grouping(a), a, array_agg(b),\n+--        rank(a) within group (order by b nulls first),\n+--        rank(a) within group (order by b nulls last)\n+--   from (values (1,1),(1,4),(1,5),(3,1),(3,2)) v(a,b)\n+--  group by rollup (a) order by a;\n+\n+-- nesting with window functions\n+-- [SPARK-29699] Different answers in nested aggregates with window functions\n+select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+  from gstest2 group by rollup (a,b) order by rsum, a, b;\n+\n+-- [SPARK-29700] Support nested grouping sets\n+-- nesting with grouping sets\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(())))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(((a, b)))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(rollup(c), grouping sets(cube(c))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(a, grouping sets(a, cube(b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, (b))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a, grouping sets(a), ((a)), a, grouping sets(a), (a)), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((a,(a,b)), grouping sets((a,(a,b)),a))\n+--   order by 1 desc;\n+\n+-- empty input: first is 0 rows, second 1, third 3 etc.\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),a);\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),());\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),(),(),());\n+select sum(v), count(*) from gstest_empty group by grouping sets ((),(),());\n+\n+-- empty input with joins tests some important code paths\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select t1.a, t2.b, sum(t1.v), count(*) from gstest_empty t1, gstest_empty t2\n+ group by grouping sets ((t1.a,t2.b),());\n+\n+-- simple joins, var resolution, GROUPING on join vars\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1, gstest2 t2\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1 join gstest2 t2 on (t1.a=t2.a)\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a, b), sum(t1.v), max(t2.c)\n+select a, b, grouping(a), grouping(b), sum(t1.v), max(t2.c)\n+  from gstest1 t1 join gstest2 t2 using (a,b)\n+ group by grouping sets ((a, b), ());\n+\n+-- check that functionally dependent cols are not nulled\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark",
    "line": 192
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Yea, that seems to be yes (I didn't know this behaviour though..). Plz see:\r\n```\r\npostgres=# \\d gstest3\r\n              Table \"public.gstest3\"\r\n Column |  Type   | Collation | Nullable | Default \r\n--------+---------+-----------+----------+---------\r\n a      | integer |           |          | \r\n b      | integer |           |          | \r\n c      | integer |           |          | \r\n d      | integer |           |          | \r\n\r\npostgres=# select a, d, grouping(a,b,c) from gstest3 group by grouping sets ((a,b), (a,c));\r\nERROR:  column \"gstest3.d\" must appear in the GROUP BY clause or be used in an aggregate function\r\nLINE 1: select a, d, grouping(a,b,c) from gstest3 group by grouping ...\r\n                  ^\r\npostgres=# alter table gstest3 add primary key (a);\r\nALTER TABLE\r\n\r\npostgres=# select a, d, grouping(a,b,c) from gstest3 group by grouping sets ((a,b), (a,c));\r\n a | d | grouping \r\n---+---+----------\r\n 1 | 1 |        1\r\n 2 | 2 |        1\r\n 1 | 1 |        2\r\n 2 | 2 |        2\r\n(4 rows)\r\n```",
    "commit": "d7f6909613631b4ea3dfa62a172a9565a213c4ce",
    "createdAt": "2019-11-05T01:58:25Z",
    "diffHunk": "@@ -0,0 +1,563 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- GROUPING SETS\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/groupingsets.sql\n+\n+-- test data sources\n+\n+create temp view gstest1(a,b,v)\n+  as values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),\n+            (2,3,15),\n+            (3,3,16),(3,4,17),\n+            (4,1,18),(4,1,19);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest2 (a integer, b integer, c integer, d integer,\n+--                            e integer, f integer, g integer, h integer);\n+create table gstest2 (a integer, b integer, c integer, d integer,\n+                      e integer, f integer, g integer, h integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest2 from stdin;\n+-- 1\t1\t1\t1\t1\t1\t1\t1\n+-- 1\t1\t1\t1\t1\t1\t1\t2\n+-- 1\t1\t1\t1\t1\t1\t2\t2\n+-- 1\t1\t1\t1\t1\t2\t2\t2\n+-- 1\t1\t1\t1\t2\t2\t2\t2\n+-- 1\t1\t1\t2\t2\t2\t2\t2\n+-- 1\t1\t2\t2\t2\t2\t2\t2\n+-- 1\t2\t2\t2\t2\t2\t2\t2\n+-- 2\t2\t2\t2\t2\t2\t2\t2\n+-- \\.\n+insert into gstest2 values\n+  (1, 1, 1, 1, 1, 1, 1, 1),\n+  (1, 1, 1, 1, 1, 1, 1, 2),\n+  (1, 1, 1, 1, 1, 1, 2, 2),\n+  (1, 1, 1, 1, 1, 2, 2, 2),\n+  (1, 1, 1, 1, 2, 2, 2, 2),\n+  (1, 1, 1, 2, 2, 2, 2, 2),\n+  (1, 1, 2, 2, 2, 2, 2, 2),\n+  (1, 2, 2, 2, 2, 2, 2, 2),\n+  (2, 2, 2, 2, 2, 2, 2, 2);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest3 (a integer, b integer, c integer, d integer);\n+create table gstest3 (a integer, b integer, c integer, d integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest3 from stdin;\n+-- 1\t1\t1\t1\n+-- 2\t2\t2\t2\n+-- \\.\n+insert into gstest3 values\n+  (1, 1, 1, 1),\n+  (2, 2, 2, 2);\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- alter table gstest3 add primary key (a);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest4(id integer, v integer,\n+--                           unhashable_col bit(4), unsortable_col xid);\n+-- [SPARK-29697] Support bit string types/literals\n+create table gstest4(id integer, v integer,\n+                     unhashable_col /* bit(4) */ byte, unsortable_col /* xid */ integer) using parquet;\n+insert into gstest4\n+-- values (1,1,b'0000','1'), (2,2,b'0001','1'),\n+--        (3,4,b'0010','2'), (4,8,b'0011','2'),\n+--        (5,16,b'0000','2'), (6,32,b'0001','2'),\n+--        (7,64,b'0010','1'), (8,128,b'0011','1');\n+values (1,1,tinyint('0'),1), (2,2,tinyint('1'),1),\n+       (3,4,tinyint('2'),2), (4,8,tinyint('3'),2),\n+       (5,16,tinyint('0'),2), (6,32,tinyint('1'),2),\n+       (7,64,tinyint('2'),1), (8,128,tinyint('3'),1);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest_empty (a integer, b integer, v integer);\n+create table gstest_empty (a integer, b integer, v integer) using parquet;\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- create function gstest_data(v integer, out a integer, out b integer)\n+--   returns setof record\n+--   as $f$\n+--     begin\n+--       return query select v, i from generate_series(1,3) i;\n+--     end;\n+--   $f$ language plpgsql;\n+\n+-- basic functionality\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = false;  -- test hashing explicitly later\n+\n+-- simple rollup with multiple plain aggregates, with and without ordering\n+-- (and with ordering differing from grouping)\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b);\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by a,b;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by b desc, a;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by coalesce(a,0)+coalesce(b,0);\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- various types of ordered aggs\n+-- select a, b, grouping(a,b),\n+--        array_agg(v order by v),\n+--        string_agg(string(v:text, ':' order by v desc),\n+--        percentile_disc(0.5) within group (order by v),\n+--        rank(1,2,12) within group (order by a,b,v)\n+--   from gstest1 group by rollup (a,b) order by a,b;\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- test usage of grouped columns in direct args of aggs\n+-- select grouping(a), a, array_agg(b),\n+--        rank(a) within group (order by b nulls first),\n+--        rank(a) within group (order by b nulls last)\n+--   from (values (1,1),(1,4),(1,5),(3,1),(3,2)) v(a,b)\n+--  group by rollup (a) order by a;\n+\n+-- nesting with window functions\n+-- [SPARK-29699] Different answers in nested aggregates with window functions\n+select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+  from gstest2 group by rollup (a,b) order by rsum, a, b;\n+\n+-- [SPARK-29700] Support nested grouping sets\n+-- nesting with grouping sets\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(())))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(((a, b)))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(rollup(c), grouping sets(cube(c))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(a, grouping sets(a, cube(b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, (b))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a, grouping sets(a), ((a)), a, grouping sets(a), (a)), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((a,(a,b)), grouping sets((a,(a,b)),a))\n+--   order by 1 desc;\n+\n+-- empty input: first is 0 rows, second 1, third 3 etc.\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),a);\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),());\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),(),(),());\n+select sum(v), count(*) from gstest_empty group by grouping sets ((),(),());\n+\n+-- empty input with joins tests some important code paths\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select t1.a, t2.b, sum(t1.v), count(*) from gstest_empty t1, gstest_empty t2\n+ group by grouping sets ((t1.a,t2.b),());\n+\n+-- simple joins, var resolution, GROUPING on join vars\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1, gstest2 t2\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1 join gstest2 t2 on (t1.a=t2.a)\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a, b), sum(t1.v), max(t2.c)\n+select a, b, grouping(a), grouping(b), sum(t1.v), max(t2.c)\n+  from gstest1 t1 join gstest2 t2 using (a,b)\n+ group by grouping sets ((a, b), ());\n+\n+-- check that functionally dependent cols are not nulled\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark",
    "line": 192
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "`[SPARK-29702]` might include the issue in `[SPARK-19842]`, so `removing [SPARK-19842]` is ok to me.",
    "commit": "d7f6909613631b4ea3dfa62a172a9565a213c4ce",
    "createdAt": "2019-11-05T01:59:43Z",
    "diffHunk": "@@ -0,0 +1,563 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- GROUPING SETS\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/groupingsets.sql\n+\n+-- test data sources\n+\n+create temp view gstest1(a,b,v)\n+  as values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),\n+            (2,3,15),\n+            (3,3,16),(3,4,17),\n+            (4,1,18),(4,1,19);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest2 (a integer, b integer, c integer, d integer,\n+--                            e integer, f integer, g integer, h integer);\n+create table gstest2 (a integer, b integer, c integer, d integer,\n+                      e integer, f integer, g integer, h integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest2 from stdin;\n+-- 1\t1\t1\t1\t1\t1\t1\t1\n+-- 1\t1\t1\t1\t1\t1\t1\t2\n+-- 1\t1\t1\t1\t1\t1\t2\t2\n+-- 1\t1\t1\t1\t1\t2\t2\t2\n+-- 1\t1\t1\t1\t2\t2\t2\t2\n+-- 1\t1\t1\t2\t2\t2\t2\t2\n+-- 1\t1\t2\t2\t2\t2\t2\t2\n+-- 1\t2\t2\t2\t2\t2\t2\t2\n+-- 2\t2\t2\t2\t2\t2\t2\t2\n+-- \\.\n+insert into gstest2 values\n+  (1, 1, 1, 1, 1, 1, 1, 1),\n+  (1, 1, 1, 1, 1, 1, 1, 2),\n+  (1, 1, 1, 1, 1, 1, 2, 2),\n+  (1, 1, 1, 1, 1, 2, 2, 2),\n+  (1, 1, 1, 1, 2, 2, 2, 2),\n+  (1, 1, 1, 2, 2, 2, 2, 2),\n+  (1, 1, 2, 2, 2, 2, 2, 2),\n+  (1, 2, 2, 2, 2, 2, 2, 2),\n+  (2, 2, 2, 2, 2, 2, 2, 2);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest3 (a integer, b integer, c integer, d integer);\n+create table gstest3 (a integer, b integer, c integer, d integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest3 from stdin;\n+-- 1\t1\t1\t1\n+-- 2\t2\t2\t2\n+-- \\.\n+insert into gstest3 values\n+  (1, 1, 1, 1),\n+  (2, 2, 2, 2);\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- alter table gstest3 add primary key (a);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest4(id integer, v integer,\n+--                           unhashable_col bit(4), unsortable_col xid);\n+-- [SPARK-29697] Support bit string types/literals\n+create table gstest4(id integer, v integer,\n+                     unhashable_col /* bit(4) */ byte, unsortable_col /* xid */ integer) using parquet;\n+insert into gstest4\n+-- values (1,1,b'0000','1'), (2,2,b'0001','1'),\n+--        (3,4,b'0010','2'), (4,8,b'0011','2'),\n+--        (5,16,b'0000','2'), (6,32,b'0001','2'),\n+--        (7,64,b'0010','1'), (8,128,b'0011','1');\n+values (1,1,tinyint('0'),1), (2,2,tinyint('1'),1),\n+       (3,4,tinyint('2'),2), (4,8,tinyint('3'),2),\n+       (5,16,tinyint('0'),2), (6,32,tinyint('1'),2),\n+       (7,64,tinyint('2'),1), (8,128,tinyint('3'),1);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest_empty (a integer, b integer, v integer);\n+create table gstest_empty (a integer, b integer, v integer) using parquet;\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- create function gstest_data(v integer, out a integer, out b integer)\n+--   returns setof record\n+--   as $f$\n+--     begin\n+--       return query select v, i from generate_series(1,3) i;\n+--     end;\n+--   $f$ language plpgsql;\n+\n+-- basic functionality\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = false;  -- test hashing explicitly later\n+\n+-- simple rollup with multiple plain aggregates, with and without ordering\n+-- (and with ordering differing from grouping)\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b);\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by a,b;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by b desc, a;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by coalesce(a,0)+coalesce(b,0);\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- various types of ordered aggs\n+-- select a, b, grouping(a,b),\n+--        array_agg(v order by v),\n+--        string_agg(string(v:text, ':' order by v desc),\n+--        percentile_disc(0.5) within group (order by v),\n+--        rank(1,2,12) within group (order by a,b,v)\n+--   from gstest1 group by rollup (a,b) order by a,b;\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- test usage of grouped columns in direct args of aggs\n+-- select grouping(a), a, array_agg(b),\n+--        rank(a) within group (order by b nulls first),\n+--        rank(a) within group (order by b nulls last)\n+--   from (values (1,1),(1,4),(1,5),(3,1),(3,2)) v(a,b)\n+--  group by rollup (a) order by a;\n+\n+-- nesting with window functions\n+-- [SPARK-29699] Different answers in nested aggregates with window functions\n+select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+  from gstest2 group by rollup (a,b) order by rsum, a, b;\n+\n+-- [SPARK-29700] Support nested grouping sets\n+-- nesting with grouping sets\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(())))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(((a, b)))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(rollup(c), grouping sets(cube(c))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(a, grouping sets(a, cube(b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, (b))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a, grouping sets(a), ((a)), a, grouping sets(a), (a)), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((a,(a,b)), grouping sets((a,(a,b)),a))\n+--   order by 1 desc;\n+\n+-- empty input: first is 0 rows, second 1, third 3 etc.\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),a);\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),());\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),(),(),());\n+select sum(v), count(*) from gstest_empty group by grouping sets ((),(),());\n+\n+-- empty input with joins tests some important code paths\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select t1.a, t2.b, sum(t1.v), count(*) from gstest_empty t1, gstest_empty t2\n+ group by grouping sets ((t1.a,t2.b),());\n+\n+-- simple joins, var resolution, GROUPING on join vars\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1, gstest2 t2\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1 join gstest2 t2 on (t1.a=t2.a)\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a, b), sum(t1.v), max(t2.c)\n+select a, b, grouping(a), grouping(b), sum(t1.v), max(t2.c)\n+  from gstest1 t1 join gstest2 t2 using (a,b)\n+ group by grouping sets ((a, b), ());\n+\n+-- check that functionally dependent cols are not nulled\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark",
    "line": 192
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Got it. No problem. Let's keep it.",
    "commit": "d7f6909613631b4ea3dfa62a172a9565a213c4ce",
    "createdAt": "2019-11-05T02:06:26Z",
    "diffHunk": "@@ -0,0 +1,563 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- GROUPING SETS\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/groupingsets.sql\n+\n+-- test data sources\n+\n+create temp view gstest1(a,b,v)\n+  as values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),\n+            (2,3,15),\n+            (3,3,16),(3,4,17),\n+            (4,1,18),(4,1,19);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest2 (a integer, b integer, c integer, d integer,\n+--                            e integer, f integer, g integer, h integer);\n+create table gstest2 (a integer, b integer, c integer, d integer,\n+                      e integer, f integer, g integer, h integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest2 from stdin;\n+-- 1\t1\t1\t1\t1\t1\t1\t1\n+-- 1\t1\t1\t1\t1\t1\t1\t2\n+-- 1\t1\t1\t1\t1\t1\t2\t2\n+-- 1\t1\t1\t1\t1\t2\t2\t2\n+-- 1\t1\t1\t1\t2\t2\t2\t2\n+-- 1\t1\t1\t2\t2\t2\t2\t2\n+-- 1\t1\t2\t2\t2\t2\t2\t2\n+-- 1\t2\t2\t2\t2\t2\t2\t2\n+-- 2\t2\t2\t2\t2\t2\t2\t2\n+-- \\.\n+insert into gstest2 values\n+  (1, 1, 1, 1, 1, 1, 1, 1),\n+  (1, 1, 1, 1, 1, 1, 1, 2),\n+  (1, 1, 1, 1, 1, 1, 2, 2),\n+  (1, 1, 1, 1, 1, 2, 2, 2),\n+  (1, 1, 1, 1, 2, 2, 2, 2),\n+  (1, 1, 1, 2, 2, 2, 2, 2),\n+  (1, 1, 2, 2, 2, 2, 2, 2),\n+  (1, 2, 2, 2, 2, 2, 2, 2),\n+  (2, 2, 2, 2, 2, 2, 2, 2);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest3 (a integer, b integer, c integer, d integer);\n+create table gstest3 (a integer, b integer, c integer, d integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest3 from stdin;\n+-- 1\t1\t1\t1\n+-- 2\t2\t2\t2\n+-- \\.\n+insert into gstest3 values\n+  (1, 1, 1, 1),\n+  (2, 2, 2, 2);\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- alter table gstest3 add primary key (a);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest4(id integer, v integer,\n+--                           unhashable_col bit(4), unsortable_col xid);\n+-- [SPARK-29697] Support bit string types/literals\n+create table gstest4(id integer, v integer,\n+                     unhashable_col /* bit(4) */ byte, unsortable_col /* xid */ integer) using parquet;\n+insert into gstest4\n+-- values (1,1,b'0000','1'), (2,2,b'0001','1'),\n+--        (3,4,b'0010','2'), (4,8,b'0011','2'),\n+--        (5,16,b'0000','2'), (6,32,b'0001','2'),\n+--        (7,64,b'0010','1'), (8,128,b'0011','1');\n+values (1,1,tinyint('0'),1), (2,2,tinyint('1'),1),\n+       (3,4,tinyint('2'),2), (4,8,tinyint('3'),2),\n+       (5,16,tinyint('0'),2), (6,32,tinyint('1'),2),\n+       (7,64,tinyint('2'),1), (8,128,tinyint('3'),1);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest_empty (a integer, b integer, v integer);\n+create table gstest_empty (a integer, b integer, v integer) using parquet;\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- create function gstest_data(v integer, out a integer, out b integer)\n+--   returns setof record\n+--   as $f$\n+--     begin\n+--       return query select v, i from generate_series(1,3) i;\n+--     end;\n+--   $f$ language plpgsql;\n+\n+-- basic functionality\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = false;  -- test hashing explicitly later\n+\n+-- simple rollup with multiple plain aggregates, with and without ordering\n+-- (and with ordering differing from grouping)\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b);\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by a,b;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by b desc, a;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by coalesce(a,0)+coalesce(b,0);\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- various types of ordered aggs\n+-- select a, b, grouping(a,b),\n+--        array_agg(v order by v),\n+--        string_agg(string(v:text, ':' order by v desc),\n+--        percentile_disc(0.5) within group (order by v),\n+--        rank(1,2,12) within group (order by a,b,v)\n+--   from gstest1 group by rollup (a,b) order by a,b;\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- test usage of grouped columns in direct args of aggs\n+-- select grouping(a), a, array_agg(b),\n+--        rank(a) within group (order by b nulls first),\n+--        rank(a) within group (order by b nulls last)\n+--   from (values (1,1),(1,4),(1,5),(3,1),(3,2)) v(a,b)\n+--  group by rollup (a) order by a;\n+\n+-- nesting with window functions\n+-- [SPARK-29699] Different answers in nested aggregates with window functions\n+select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+  from gstest2 group by rollup (a,b) order by rsum, a, b;\n+\n+-- [SPARK-29700] Support nested grouping sets\n+-- nesting with grouping sets\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(())))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(((a, b)))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(rollup(c), grouping sets(cube(c))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(a, grouping sets(a, cube(b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, (b))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a, grouping sets(a), ((a)), a, grouping sets(a), (a)), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((a,(a,b)), grouping sets((a,(a,b)),a))\n+--   order by 1 desc;\n+\n+-- empty input: first is 0 rows, second 1, third 3 etc.\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),a);\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),());\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),(),(),());\n+select sum(v), count(*) from gstest_empty group by grouping sets ((),(),());\n+\n+-- empty input with joins tests some important code paths\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select t1.a, t2.b, sum(t1.v), count(*) from gstest_empty t1, gstest_empty t2\n+ group by grouping sets ((t1.a,t2.b),());\n+\n+-- simple joins, var resolution, GROUPING on join vars\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1, gstest2 t2\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1 join gstest2 t2 on (t1.a=t2.a)\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a, b), sum(t1.v), max(t2.c)\n+select a, b, grouping(a), grouping(b), sum(t1.v), max(t2.c)\n+  from gstest1 t1 join gstest2 t2 using (a,b)\n+ group by grouping sets ((a, b), ());\n+\n+-- check that functionally dependent cols are not nulled\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark",
    "line": 192
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "ok, thanks for the quick response!",
    "commit": "d7f6909613631b4ea3dfa62a172a9565a213c4ce",
    "createdAt": "2019-11-05T02:07:42Z",
    "diffHunk": "@@ -0,0 +1,563 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- GROUPING SETS\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/groupingsets.sql\n+\n+-- test data sources\n+\n+create temp view gstest1(a,b,v)\n+  as values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),\n+            (2,3,15),\n+            (3,3,16),(3,4,17),\n+            (4,1,18),(4,1,19);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest2 (a integer, b integer, c integer, d integer,\n+--                            e integer, f integer, g integer, h integer);\n+create table gstest2 (a integer, b integer, c integer, d integer,\n+                      e integer, f integer, g integer, h integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest2 from stdin;\n+-- 1\t1\t1\t1\t1\t1\t1\t1\n+-- 1\t1\t1\t1\t1\t1\t1\t2\n+-- 1\t1\t1\t1\t1\t1\t2\t2\n+-- 1\t1\t1\t1\t1\t2\t2\t2\n+-- 1\t1\t1\t1\t2\t2\t2\t2\n+-- 1\t1\t1\t2\t2\t2\t2\t2\n+-- 1\t1\t2\t2\t2\t2\t2\t2\n+-- 1\t2\t2\t2\t2\t2\t2\t2\n+-- 2\t2\t2\t2\t2\t2\t2\t2\n+-- \\.\n+insert into gstest2 values\n+  (1, 1, 1, 1, 1, 1, 1, 1),\n+  (1, 1, 1, 1, 1, 1, 1, 2),\n+  (1, 1, 1, 1, 1, 1, 2, 2),\n+  (1, 1, 1, 1, 1, 2, 2, 2),\n+  (1, 1, 1, 1, 2, 2, 2, 2),\n+  (1, 1, 1, 2, 2, 2, 2, 2),\n+  (1, 1, 2, 2, 2, 2, 2, 2),\n+  (1, 2, 2, 2, 2, 2, 2, 2),\n+  (2, 2, 2, 2, 2, 2, 2, 2);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest3 (a integer, b integer, c integer, d integer);\n+create table gstest3 (a integer, b integer, c integer, d integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest3 from stdin;\n+-- 1\t1\t1\t1\n+-- 2\t2\t2\t2\n+-- \\.\n+insert into gstest3 values\n+  (1, 1, 1, 1),\n+  (2, 2, 2, 2);\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- alter table gstest3 add primary key (a);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest4(id integer, v integer,\n+--                           unhashable_col bit(4), unsortable_col xid);\n+-- [SPARK-29697] Support bit string types/literals\n+create table gstest4(id integer, v integer,\n+                     unhashable_col /* bit(4) */ byte, unsortable_col /* xid */ integer) using parquet;\n+insert into gstest4\n+-- values (1,1,b'0000','1'), (2,2,b'0001','1'),\n+--        (3,4,b'0010','2'), (4,8,b'0011','2'),\n+--        (5,16,b'0000','2'), (6,32,b'0001','2'),\n+--        (7,64,b'0010','1'), (8,128,b'0011','1');\n+values (1,1,tinyint('0'),1), (2,2,tinyint('1'),1),\n+       (3,4,tinyint('2'),2), (4,8,tinyint('3'),2),\n+       (5,16,tinyint('0'),2), (6,32,tinyint('1'),2),\n+       (7,64,tinyint('2'),1), (8,128,tinyint('3'),1);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest_empty (a integer, b integer, v integer);\n+create table gstest_empty (a integer, b integer, v integer) using parquet;\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- create function gstest_data(v integer, out a integer, out b integer)\n+--   returns setof record\n+--   as $f$\n+--     begin\n+--       return query select v, i from generate_series(1,3) i;\n+--     end;\n+--   $f$ language plpgsql;\n+\n+-- basic functionality\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = false;  -- test hashing explicitly later\n+\n+-- simple rollup with multiple plain aggregates, with and without ordering\n+-- (and with ordering differing from grouping)\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b);\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by a,b;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by b desc, a;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by coalesce(a,0)+coalesce(b,0);\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- various types of ordered aggs\n+-- select a, b, grouping(a,b),\n+--        array_agg(v order by v),\n+--        string_agg(string(v:text, ':' order by v desc),\n+--        percentile_disc(0.5) within group (order by v),\n+--        rank(1,2,12) within group (order by a,b,v)\n+--   from gstest1 group by rollup (a,b) order by a,b;\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- test usage of grouped columns in direct args of aggs\n+-- select grouping(a), a, array_agg(b),\n+--        rank(a) within group (order by b nulls first),\n+--        rank(a) within group (order by b nulls last)\n+--   from (values (1,1),(1,4),(1,5),(3,1),(3,2)) v(a,b)\n+--  group by rollup (a) order by a;\n+\n+-- nesting with window functions\n+-- [SPARK-29699] Different answers in nested aggregates with window functions\n+select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+  from gstest2 group by rollup (a,b) order by rsum, a, b;\n+\n+-- [SPARK-29700] Support nested grouping sets\n+-- nesting with grouping sets\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(())))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(((a, b)))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(rollup(c), grouping sets(cube(c))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(a, grouping sets(a, cube(b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, (b))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a, grouping sets(a), ((a)), a, grouping sets(a), (a)), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((a,(a,b)), grouping sets((a,(a,b)),a))\n+--   order by 1 desc;\n+\n+-- empty input: first is 0 rows, second 1, third 3 etc.\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),a);\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),());\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),(),(),());\n+select sum(v), count(*) from gstest_empty group by grouping sets ((),(),());\n+\n+-- empty input with joins tests some important code paths\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select t1.a, t2.b, sum(t1.v), count(*) from gstest_empty t1, gstest_empty t2\n+ group by grouping sets ((t1.a,t2.b),());\n+\n+-- simple joins, var resolution, GROUPING on join vars\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1, gstest2 t2\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1 join gstest2 t2 on (t1.a=t2.a)\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a, b), sum(t1.v), max(t2.c)\n+select a, b, grouping(a), grouping(b), sum(t1.v), max(t2.c)\n+  from gstest1 t1 join gstest2 t2 using (a,b)\n+ group by grouping sets ((a, b), ());\n+\n+-- check that functionally dependent cols are not nulled\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark",
    "line": 192
  }],
  "prId": 26352
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Shall we move line 395 before line 394 and remove the indentation?",
    "commit": "d7f6909613631b4ea3dfa62a172a9565a213c4ce",
    "createdAt": "2019-11-05T01:46:17Z",
    "diffHunk": "@@ -0,0 +1,563 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- GROUPING SETS\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/groupingsets.sql\n+\n+-- test data sources\n+\n+create temp view gstest1(a,b,v)\n+  as values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),\n+            (2,3,15),\n+            (3,3,16),(3,4,17),\n+            (4,1,18),(4,1,19);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest2 (a integer, b integer, c integer, d integer,\n+--                            e integer, f integer, g integer, h integer);\n+create table gstest2 (a integer, b integer, c integer, d integer,\n+                      e integer, f integer, g integer, h integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest2 from stdin;\n+-- 1\t1\t1\t1\t1\t1\t1\t1\n+-- 1\t1\t1\t1\t1\t1\t1\t2\n+-- 1\t1\t1\t1\t1\t1\t2\t2\n+-- 1\t1\t1\t1\t1\t2\t2\t2\n+-- 1\t1\t1\t1\t2\t2\t2\t2\n+-- 1\t1\t1\t2\t2\t2\t2\t2\n+-- 1\t1\t2\t2\t2\t2\t2\t2\n+-- 1\t2\t2\t2\t2\t2\t2\t2\n+-- 2\t2\t2\t2\t2\t2\t2\t2\n+-- \\.\n+insert into gstest2 values\n+  (1, 1, 1, 1, 1, 1, 1, 1),\n+  (1, 1, 1, 1, 1, 1, 1, 2),\n+  (1, 1, 1, 1, 1, 1, 2, 2),\n+  (1, 1, 1, 1, 1, 2, 2, 2),\n+  (1, 1, 1, 1, 2, 2, 2, 2),\n+  (1, 1, 1, 2, 2, 2, 2, 2),\n+  (1, 1, 2, 2, 2, 2, 2, 2),\n+  (1, 2, 2, 2, 2, 2, 2, 2),\n+  (2, 2, 2, 2, 2, 2, 2, 2);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest3 (a integer, b integer, c integer, d integer);\n+create table gstest3 (a integer, b integer, c integer, d integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest3 from stdin;\n+-- 1\t1\t1\t1\n+-- 2\t2\t2\t2\n+-- \\.\n+insert into gstest3 values\n+  (1, 1, 1, 1),\n+  (2, 2, 2, 2);\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- alter table gstest3 add primary key (a);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest4(id integer, v integer,\n+--                           unhashable_col bit(4), unsortable_col xid);\n+-- [SPARK-29697] Support bit string types/literals\n+create table gstest4(id integer, v integer,\n+                     unhashable_col /* bit(4) */ byte, unsortable_col /* xid */ integer) using parquet;\n+insert into gstest4\n+-- values (1,1,b'0000','1'), (2,2,b'0001','1'),\n+--        (3,4,b'0010','2'), (4,8,b'0011','2'),\n+--        (5,16,b'0000','2'), (6,32,b'0001','2'),\n+--        (7,64,b'0010','1'), (8,128,b'0011','1');\n+values (1,1,tinyint('0'),1), (2,2,tinyint('1'),1),\n+       (3,4,tinyint('2'),2), (4,8,tinyint('3'),2),\n+       (5,16,tinyint('0'),2), (6,32,tinyint('1'),2),\n+       (7,64,tinyint('2'),1), (8,128,tinyint('3'),1);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest_empty (a integer, b integer, v integer);\n+create table gstest_empty (a integer, b integer, v integer) using parquet;\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- create function gstest_data(v integer, out a integer, out b integer)\n+--   returns setof record\n+--   as $f$\n+--     begin\n+--       return query select v, i from generate_series(1,3) i;\n+--     end;\n+--   $f$ language plpgsql;\n+\n+-- basic functionality\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = false;  -- test hashing explicitly later\n+\n+-- simple rollup with multiple plain aggregates, with and without ordering\n+-- (and with ordering differing from grouping)\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b);\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by a,b;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by b desc, a;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by coalesce(a,0)+coalesce(b,0);\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- various types of ordered aggs\n+-- select a, b, grouping(a,b),\n+--        array_agg(v order by v),\n+--        string_agg(string(v:text, ':' order by v desc),\n+--        percentile_disc(0.5) within group (order by v),\n+--        rank(1,2,12) within group (order by a,b,v)\n+--   from gstest1 group by rollup (a,b) order by a,b;\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- test usage of grouped columns in direct args of aggs\n+-- select grouping(a), a, array_agg(b),\n+--        rank(a) within group (order by b nulls first),\n+--        rank(a) within group (order by b nulls last)\n+--   from (values (1,1),(1,4),(1,5),(3,1),(3,2)) v(a,b)\n+--  group by rollup (a) order by a;\n+\n+-- nesting with window functions\n+-- [SPARK-29699] Different answers in nested aggregates with window functions\n+select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+  from gstest2 group by rollup (a,b) order by rsum, a, b;\n+\n+-- [SPARK-29700] Support nested grouping sets\n+-- nesting with grouping sets\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(())))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(((a, b)))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(rollup(c), grouping sets(cube(c))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(a, grouping sets(a, cube(b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, (b))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a, grouping sets(a), ((a)), a, grouping sets(a), (a)), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((a,(a,b)), grouping sets((a,(a,b)),a))\n+--   order by 1 desc;\n+\n+-- empty input: first is 0 rows, second 1, third 3 etc.\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),a);\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),());\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),(),(),());\n+select sum(v), count(*) from gstest_empty group by grouping sets ((),(),());\n+\n+-- empty input with joins tests some important code paths\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select t1.a, t2.b, sum(t1.v), count(*) from gstest_empty t1, gstest_empty t2\n+ group by grouping sets ((t1.a,t2.b),());\n+\n+-- simple joins, var resolution, GROUPING on join vars\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1, gstest2 t2\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1 join gstest2 t2 on (t1.a=t2.a)\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a, b), sum(t1.v), max(t2.c)\n+select a, b, grouping(a), grouping(b), sum(t1.v), max(t2.c)\n+  from gstest1 t1 join gstest2 t2 using (a,b)\n+ group by grouping sets ((a, b), ());\n+\n+-- check that functionally dependent cols are not nulled\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- [SPARK-29702] Resolve group-by columns with functional dependencies\n+-- select a, d, grouping(a,b,c)\n+--   from gstest3\n+--  group by grouping sets ((a,b), (a,c));\n+\n+-- check that distinct grouping columns are kept separate\n+-- even if they are equal()\n+-- explain (costs off)\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- [SPARK-27767] Built-in function: generate_series\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- check that pulled-up subquery outputs still go to null when appropriate\n+select four, x\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  having x = 'foo';\n+\n+select four, x || 'x'\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  order by four;\n+\n+select (x+y)*1, sum(z)\n+ from (select 1 as x, 2 as y, 3 as z) s\n+ group by grouping sets (x+y, x);\n+\n+CREATE TEMP VIEW int8_tbl AS SELECT * FROM VALUES\n+  (123L, 456L),\n+  (123L, 4567890123456789L),\n+  (4567890123456789L, 123L),\n+  (4567890123456789L, 4567890123456789L),\n+  (4567890123456789L, -4567890123456789L) as int8_tbl(q1, q2);\n+\n+select x, not x as not_x, q2 from\n+  (select *, q1 = 1 as x from int8_tbl i1) as t\n+  group by grouping sets(x, q2)\n+  order by x, q2;\n+\n+DROP VIEW int8_tbl;\n+\n+-- simple rescan tests\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by rollup (a,b);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select *\n+--   from (values (1),(2)) v(x),\n+--        lateral (select a, b, sum(v.x) from gstest_data(v.x) group by rollup (a,b)) s;\n+\n+-- min max optimization should still work with GROUP BY ()\n+-- explain (costs off)\n+--   select min(unique1) from tenk1 GROUP BY ();\n+\n+-- Views with GROUPING SET queries\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29705] Support more expressive forms in GroupingSets/Cube/Rollup\n+-- CREATE VIEW gstest_view AS select a, b, grouping(a,b), sum(c), count(*), max(c)\n+--   from gstest2 group by rollup ((a,b,c),(c,d));\n+\n+-- select pg_get_viewdef('gstest_view'::regclass, true);\n+\n+-- Nested queries with 3 or more levels of nesting\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(e,f) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(c) from (values (1)) v2(c) GROUP BY c) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+\n+-- Combinations of operations\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select a, b, c, d from gstest2 group by rollup(a,b),grouping sets(c,d);\n+-- select a, b from (values (1,2),(2,3)) v(a,b) group by a,b, grouping sets(a);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- Tests for chained aggregates\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a,b),(a+1,b+1),(a+2,b+2)) order by 3,6;\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP((e+1),(f+1));\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY CUBE((e+1),(f+1)) ORDER BY (e+1),(f+1);\n+-- select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+--   from gstest2 group by cube (a,b) order by rsum, a, b;\n+-- select a, b, sum(c) from (values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),(2,3,15),(3,3,16),(3,4,17),(4,1,18),(4,1,19)) v(a,b,c) group by rollup (a,b);\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by cube (a,b) order by a,b;\n+\n+-- Test reordering of grouping sets\n+-- explain (costs off)\n+-- select * from gstest1 group by grouping sets((a,b,v),(v)) order by v,b,a;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- Agg level check. This query should error out.\n+-- select (select grouping(a), grouping(b) from gstest2) from gstest2 group by a,b;\n+\n+--Nested queries\n+-- [SPARK-29700] Support nested grouping sets\n+-- select a, b, sum(c), count(*) from gstest2 group by grouping sets (rollup(a,b),a);\n+\n+-- HAVING queries\n+select ten, sum(distinct four) from onek a\n+group by grouping sets((ten,four),(ten))\n+having exists (select 1 from onek b where sum(distinct a.four) = b.four);\n+\n+-- Tests around pushdown of HAVING clauses, partially testing against previous bugs\n+select a,count(*) from gstest2 group by rollup(a) order by a;\n+select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+-- explain (costs off)\n+--   select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+\n+-- [SPARK-29706] Support an empty grouping expression\n+-- select v.c, (select count(*) from gstest2 group by () having v.c)\n+--   from (values (false),(true)) v(c) order by v.c;\n+-- explain (costs off)\n+--   select v.c, (select count(*) from gstest2 group by () having v.c)\n+--     from (values (false),(true)) v(c) order by v.c;\n+\n+-- HAVING with GROUPING queries\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten) having grouping(ten) >= 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten, four) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by rollup(ten) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by cube(ten) having grouping(ten) > 0\n+order by 2,1;\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select ten, grouping(ten) from onek\n+-- group by (ten) having grouping(ten) >= 0\n+-- order by 2,1;\n+\n+-- FILTER queries\n+-- [SPARK-27986] Support Aggregate Expressions with filter\n+-- select ten, sum(distinct four) filter (where string(four) ~ '123') from onek a\n+-- group by rollup(ten);\n+\n+-- More rescan tests\n+-- [SPARK-27877] ANSI SQL: LATERAL derived table(T491)\n+-- select * from (values (1),(2)) v(a) left join lateral (select v.a, four, ten, count(*) from onek group by cube(four,ten)) s on true order by v.a,four,ten;\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array(select row(v.a,s1.*) from (select two,four, count(*) from onek group by cube(two,four) order by two,four) s1) from (values (1),(2)) v(a);\n+\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- Grouping on text columns\n+-- select sum(ten) from onek group by two, rollup(string(four)) order by 1;\n+-- select sum(ten) from onek group by rollup(string(four)), two order by 1;\n+\n+-- hashing support\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = true;\n+\n+-- failure cases\n+\n+-- Since this test is implementation specific for plans, it passes in Spark\n+select count(*) from gstest4 group by rollup(unhashable_col,unsortable_col);\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array_agg(v order by v) from gstest4 group by grouping sets ((id,unsortable_col),(id));\n+\n+-- simple cases\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by grouping sets ((a),(b)) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a),(b)) order by 3,1,2;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by cube(a,b) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by cube(a,b) order by 3,1,2;\n+\n+-- shouldn't try and hash\n+-- explain (costs off)\n+--   select a, b, grouping(a,b), array_agg(v order by v)\n+--     from gstest1 group by cube(a,b);\n+\n+-- unsortable cases\n+-- [SPARK-29708] Different answers in aggregates of multiple grouping sets\n+select unsortable_col, count(*)\n+  from gstest4 group by grouping sets ((unsortable_col),(unsortable_col))\n+  order by string(unsortable_col);\n+\n+-- mixed hashable/sortable cases\n+select unhashable_col, unsortable_col,\n+       -- [SPARK-29698] Support grouping function with multiple arguments"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "ok",
    "commit": "d7f6909613631b4ea3dfa62a172a9565a213c4ce",
    "createdAt": "2019-11-05T02:00:39Z",
    "diffHunk": "@@ -0,0 +1,563 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- GROUPING SETS\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/groupingsets.sql\n+\n+-- test data sources\n+\n+create temp view gstest1(a,b,v)\n+  as values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),\n+            (2,3,15),\n+            (3,3,16),(3,4,17),\n+            (4,1,18),(4,1,19);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest2 (a integer, b integer, c integer, d integer,\n+--                            e integer, f integer, g integer, h integer);\n+create table gstest2 (a integer, b integer, c integer, d integer,\n+                      e integer, f integer, g integer, h integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest2 from stdin;\n+-- 1\t1\t1\t1\t1\t1\t1\t1\n+-- 1\t1\t1\t1\t1\t1\t1\t2\n+-- 1\t1\t1\t1\t1\t1\t2\t2\n+-- 1\t1\t1\t1\t1\t2\t2\t2\n+-- 1\t1\t1\t1\t2\t2\t2\t2\n+-- 1\t1\t1\t2\t2\t2\t2\t2\n+-- 1\t1\t2\t2\t2\t2\t2\t2\n+-- 1\t2\t2\t2\t2\t2\t2\t2\n+-- 2\t2\t2\t2\t2\t2\t2\t2\n+-- \\.\n+insert into gstest2 values\n+  (1, 1, 1, 1, 1, 1, 1, 1),\n+  (1, 1, 1, 1, 1, 1, 1, 2),\n+  (1, 1, 1, 1, 1, 1, 2, 2),\n+  (1, 1, 1, 1, 1, 2, 2, 2),\n+  (1, 1, 1, 1, 2, 2, 2, 2),\n+  (1, 1, 1, 2, 2, 2, 2, 2),\n+  (1, 1, 2, 2, 2, 2, 2, 2),\n+  (1, 2, 2, 2, 2, 2, 2, 2),\n+  (2, 2, 2, 2, 2, 2, 2, 2);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest3 (a integer, b integer, c integer, d integer);\n+create table gstest3 (a integer, b integer, c integer, d integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest3 from stdin;\n+-- 1\t1\t1\t1\n+-- 2\t2\t2\t2\n+-- \\.\n+insert into gstest3 values\n+  (1, 1, 1, 1),\n+  (2, 2, 2, 2);\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- alter table gstest3 add primary key (a);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest4(id integer, v integer,\n+--                           unhashable_col bit(4), unsortable_col xid);\n+-- [SPARK-29697] Support bit string types/literals\n+create table gstest4(id integer, v integer,\n+                     unhashable_col /* bit(4) */ byte, unsortable_col /* xid */ integer) using parquet;\n+insert into gstest4\n+-- values (1,1,b'0000','1'), (2,2,b'0001','1'),\n+--        (3,4,b'0010','2'), (4,8,b'0011','2'),\n+--        (5,16,b'0000','2'), (6,32,b'0001','2'),\n+--        (7,64,b'0010','1'), (8,128,b'0011','1');\n+values (1,1,tinyint('0'),1), (2,2,tinyint('1'),1),\n+       (3,4,tinyint('2'),2), (4,8,tinyint('3'),2),\n+       (5,16,tinyint('0'),2), (6,32,tinyint('1'),2),\n+       (7,64,tinyint('2'),1), (8,128,tinyint('3'),1);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest_empty (a integer, b integer, v integer);\n+create table gstest_empty (a integer, b integer, v integer) using parquet;\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- create function gstest_data(v integer, out a integer, out b integer)\n+--   returns setof record\n+--   as $f$\n+--     begin\n+--       return query select v, i from generate_series(1,3) i;\n+--     end;\n+--   $f$ language plpgsql;\n+\n+-- basic functionality\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = false;  -- test hashing explicitly later\n+\n+-- simple rollup with multiple plain aggregates, with and without ordering\n+-- (and with ordering differing from grouping)\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b);\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by a,b;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by b desc, a;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by coalesce(a,0)+coalesce(b,0);\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- various types of ordered aggs\n+-- select a, b, grouping(a,b),\n+--        array_agg(v order by v),\n+--        string_agg(string(v:text, ':' order by v desc),\n+--        percentile_disc(0.5) within group (order by v),\n+--        rank(1,2,12) within group (order by a,b,v)\n+--   from gstest1 group by rollup (a,b) order by a,b;\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- test usage of grouped columns in direct args of aggs\n+-- select grouping(a), a, array_agg(b),\n+--        rank(a) within group (order by b nulls first),\n+--        rank(a) within group (order by b nulls last)\n+--   from (values (1,1),(1,4),(1,5),(3,1),(3,2)) v(a,b)\n+--  group by rollup (a) order by a;\n+\n+-- nesting with window functions\n+-- [SPARK-29699] Different answers in nested aggregates with window functions\n+select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+  from gstest2 group by rollup (a,b) order by rsum, a, b;\n+\n+-- [SPARK-29700] Support nested grouping sets\n+-- nesting with grouping sets\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(())))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(((a, b)))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(rollup(c), grouping sets(cube(c))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(a, grouping sets(a, cube(b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, (b))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a, grouping sets(a), ((a)), a, grouping sets(a), (a)), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((a,(a,b)), grouping sets((a,(a,b)),a))\n+--   order by 1 desc;\n+\n+-- empty input: first is 0 rows, second 1, third 3 etc.\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),a);\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),());\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),(),(),());\n+select sum(v), count(*) from gstest_empty group by grouping sets ((),(),());\n+\n+-- empty input with joins tests some important code paths\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select t1.a, t2.b, sum(t1.v), count(*) from gstest_empty t1, gstest_empty t2\n+ group by grouping sets ((t1.a,t2.b),());\n+\n+-- simple joins, var resolution, GROUPING on join vars\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1, gstest2 t2\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1 join gstest2 t2 on (t1.a=t2.a)\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a, b), sum(t1.v), max(t2.c)\n+select a, b, grouping(a), grouping(b), sum(t1.v), max(t2.c)\n+  from gstest1 t1 join gstest2 t2 using (a,b)\n+ group by grouping sets ((a, b), ());\n+\n+-- check that functionally dependent cols are not nulled\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- [SPARK-29702] Resolve group-by columns with functional dependencies\n+-- select a, d, grouping(a,b,c)\n+--   from gstest3\n+--  group by grouping sets ((a,b), (a,c));\n+\n+-- check that distinct grouping columns are kept separate\n+-- even if they are equal()\n+-- explain (costs off)\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- [SPARK-27767] Built-in function: generate_series\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- check that pulled-up subquery outputs still go to null when appropriate\n+select four, x\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  having x = 'foo';\n+\n+select four, x || 'x'\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  order by four;\n+\n+select (x+y)*1, sum(z)\n+ from (select 1 as x, 2 as y, 3 as z) s\n+ group by grouping sets (x+y, x);\n+\n+CREATE TEMP VIEW int8_tbl AS SELECT * FROM VALUES\n+  (123L, 456L),\n+  (123L, 4567890123456789L),\n+  (4567890123456789L, 123L),\n+  (4567890123456789L, 4567890123456789L),\n+  (4567890123456789L, -4567890123456789L) as int8_tbl(q1, q2);\n+\n+select x, not x as not_x, q2 from\n+  (select *, q1 = 1 as x from int8_tbl i1) as t\n+  group by grouping sets(x, q2)\n+  order by x, q2;\n+\n+DROP VIEW int8_tbl;\n+\n+-- simple rescan tests\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by rollup (a,b);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select *\n+--   from (values (1),(2)) v(x),\n+--        lateral (select a, b, sum(v.x) from gstest_data(v.x) group by rollup (a,b)) s;\n+\n+-- min max optimization should still work with GROUP BY ()\n+-- explain (costs off)\n+--   select min(unique1) from tenk1 GROUP BY ();\n+\n+-- Views with GROUPING SET queries\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29705] Support more expressive forms in GroupingSets/Cube/Rollup\n+-- CREATE VIEW gstest_view AS select a, b, grouping(a,b), sum(c), count(*), max(c)\n+--   from gstest2 group by rollup ((a,b,c),(c,d));\n+\n+-- select pg_get_viewdef('gstest_view'::regclass, true);\n+\n+-- Nested queries with 3 or more levels of nesting\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(e,f) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(c) from (values (1)) v2(c) GROUP BY c) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+\n+-- Combinations of operations\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select a, b, c, d from gstest2 group by rollup(a,b),grouping sets(c,d);\n+-- select a, b from (values (1,2),(2,3)) v(a,b) group by a,b, grouping sets(a);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- Tests for chained aggregates\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a,b),(a+1,b+1),(a+2,b+2)) order by 3,6;\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP((e+1),(f+1));\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY CUBE((e+1),(f+1)) ORDER BY (e+1),(f+1);\n+-- select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+--   from gstest2 group by cube (a,b) order by rsum, a, b;\n+-- select a, b, sum(c) from (values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),(2,3,15),(3,3,16),(3,4,17),(4,1,18),(4,1,19)) v(a,b,c) group by rollup (a,b);\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by cube (a,b) order by a,b;\n+\n+-- Test reordering of grouping sets\n+-- explain (costs off)\n+-- select * from gstest1 group by grouping sets((a,b,v),(v)) order by v,b,a;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- Agg level check. This query should error out.\n+-- select (select grouping(a), grouping(b) from gstest2) from gstest2 group by a,b;\n+\n+--Nested queries\n+-- [SPARK-29700] Support nested grouping sets\n+-- select a, b, sum(c), count(*) from gstest2 group by grouping sets (rollup(a,b),a);\n+\n+-- HAVING queries\n+select ten, sum(distinct four) from onek a\n+group by grouping sets((ten,four),(ten))\n+having exists (select 1 from onek b where sum(distinct a.four) = b.four);\n+\n+-- Tests around pushdown of HAVING clauses, partially testing against previous bugs\n+select a,count(*) from gstest2 group by rollup(a) order by a;\n+select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+-- explain (costs off)\n+--   select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+\n+-- [SPARK-29706] Support an empty grouping expression\n+-- select v.c, (select count(*) from gstest2 group by () having v.c)\n+--   from (values (false),(true)) v(c) order by v.c;\n+-- explain (costs off)\n+--   select v.c, (select count(*) from gstest2 group by () having v.c)\n+--     from (values (false),(true)) v(c) order by v.c;\n+\n+-- HAVING with GROUPING queries\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten) having grouping(ten) >= 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten, four) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by rollup(ten) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by cube(ten) having grouping(ten) > 0\n+order by 2,1;\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select ten, grouping(ten) from onek\n+-- group by (ten) having grouping(ten) >= 0\n+-- order by 2,1;\n+\n+-- FILTER queries\n+-- [SPARK-27986] Support Aggregate Expressions with filter\n+-- select ten, sum(distinct four) filter (where string(four) ~ '123') from onek a\n+-- group by rollup(ten);\n+\n+-- More rescan tests\n+-- [SPARK-27877] ANSI SQL: LATERAL derived table(T491)\n+-- select * from (values (1),(2)) v(a) left join lateral (select v.a, four, ten, count(*) from onek group by cube(four,ten)) s on true order by v.a,four,ten;\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array(select row(v.a,s1.*) from (select two,four, count(*) from onek group by cube(two,four) order by two,four) s1) from (values (1),(2)) v(a);\n+\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- Grouping on text columns\n+-- select sum(ten) from onek group by two, rollup(string(four)) order by 1;\n+-- select sum(ten) from onek group by rollup(string(four)), two order by 1;\n+\n+-- hashing support\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = true;\n+\n+-- failure cases\n+\n+-- Since this test is implementation specific for plans, it passes in Spark\n+select count(*) from gstest4 group by rollup(unhashable_col,unsortable_col);\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array_agg(v order by v) from gstest4 group by grouping sets ((id,unsortable_col),(id));\n+\n+-- simple cases\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by grouping sets ((a),(b)) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a),(b)) order by 3,1,2;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by cube(a,b) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by cube(a,b) order by 3,1,2;\n+\n+-- shouldn't try and hash\n+-- explain (costs off)\n+--   select a, b, grouping(a,b), array_agg(v order by v)\n+--     from gstest1 group by cube(a,b);\n+\n+-- unsortable cases\n+-- [SPARK-29708] Different answers in aggregates of multiple grouping sets\n+select unsortable_col, count(*)\n+  from gstest4 group by grouping sets ((unsortable_col),(unsortable_col))\n+  order by string(unsortable_col);\n+\n+-- mixed hashable/sortable cases\n+select unhashable_col, unsortable_col,\n+       -- [SPARK-29698] Support grouping function with multiple arguments"
  }],
  "prId": 26352
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "The reason I asked is that `SPARK-29698` affects line 400 here, too. So, the indentation might be misleading.",
    "commit": "d7f6909613631b4ea3dfa62a172a9565a213c4ce",
    "createdAt": "2019-11-05T01:47:02Z",
    "diffHunk": "@@ -0,0 +1,563 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- GROUPING SETS\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/groupingsets.sql\n+\n+-- test data sources\n+\n+create temp view gstest1(a,b,v)\n+  as values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),\n+            (2,3,15),\n+            (3,3,16),(3,4,17),\n+            (4,1,18),(4,1,19);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest2 (a integer, b integer, c integer, d integer,\n+--                            e integer, f integer, g integer, h integer);\n+create table gstest2 (a integer, b integer, c integer, d integer,\n+                      e integer, f integer, g integer, h integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest2 from stdin;\n+-- 1\t1\t1\t1\t1\t1\t1\t1\n+-- 1\t1\t1\t1\t1\t1\t1\t2\n+-- 1\t1\t1\t1\t1\t1\t2\t2\n+-- 1\t1\t1\t1\t1\t2\t2\t2\n+-- 1\t1\t1\t1\t2\t2\t2\t2\n+-- 1\t1\t1\t2\t2\t2\t2\t2\n+-- 1\t1\t2\t2\t2\t2\t2\t2\n+-- 1\t2\t2\t2\t2\t2\t2\t2\n+-- 2\t2\t2\t2\t2\t2\t2\t2\n+-- \\.\n+insert into gstest2 values\n+  (1, 1, 1, 1, 1, 1, 1, 1),\n+  (1, 1, 1, 1, 1, 1, 1, 2),\n+  (1, 1, 1, 1, 1, 1, 2, 2),\n+  (1, 1, 1, 1, 1, 2, 2, 2),\n+  (1, 1, 1, 1, 2, 2, 2, 2),\n+  (1, 1, 1, 2, 2, 2, 2, 2),\n+  (1, 1, 2, 2, 2, 2, 2, 2),\n+  (1, 2, 2, 2, 2, 2, 2, 2),\n+  (2, 2, 2, 2, 2, 2, 2, 2);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest3 (a integer, b integer, c integer, d integer);\n+create table gstest3 (a integer, b integer, c integer, d integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest3 from stdin;\n+-- 1\t1\t1\t1\n+-- 2\t2\t2\t2\n+-- \\.\n+insert into gstest3 values\n+  (1, 1, 1, 1),\n+  (2, 2, 2, 2);\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- alter table gstest3 add primary key (a);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest4(id integer, v integer,\n+--                           unhashable_col bit(4), unsortable_col xid);\n+-- [SPARK-29697] Support bit string types/literals\n+create table gstest4(id integer, v integer,\n+                     unhashable_col /* bit(4) */ byte, unsortable_col /* xid */ integer) using parquet;\n+insert into gstest4\n+-- values (1,1,b'0000','1'), (2,2,b'0001','1'),\n+--        (3,4,b'0010','2'), (4,8,b'0011','2'),\n+--        (5,16,b'0000','2'), (6,32,b'0001','2'),\n+--        (7,64,b'0010','1'), (8,128,b'0011','1');\n+values (1,1,tinyint('0'),1), (2,2,tinyint('1'),1),\n+       (3,4,tinyint('2'),2), (4,8,tinyint('3'),2),\n+       (5,16,tinyint('0'),2), (6,32,tinyint('1'),2),\n+       (7,64,tinyint('2'),1), (8,128,tinyint('3'),1);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest_empty (a integer, b integer, v integer);\n+create table gstest_empty (a integer, b integer, v integer) using parquet;\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- create function gstest_data(v integer, out a integer, out b integer)\n+--   returns setof record\n+--   as $f$\n+--     begin\n+--       return query select v, i from generate_series(1,3) i;\n+--     end;\n+--   $f$ language plpgsql;\n+\n+-- basic functionality\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = false;  -- test hashing explicitly later\n+\n+-- simple rollup with multiple plain aggregates, with and without ordering\n+-- (and with ordering differing from grouping)\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b);\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by a,b;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by b desc, a;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by coalesce(a,0)+coalesce(b,0);\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- various types of ordered aggs\n+-- select a, b, grouping(a,b),\n+--        array_agg(v order by v),\n+--        string_agg(string(v:text, ':' order by v desc),\n+--        percentile_disc(0.5) within group (order by v),\n+--        rank(1,2,12) within group (order by a,b,v)\n+--   from gstest1 group by rollup (a,b) order by a,b;\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- test usage of grouped columns in direct args of aggs\n+-- select grouping(a), a, array_agg(b),\n+--        rank(a) within group (order by b nulls first),\n+--        rank(a) within group (order by b nulls last)\n+--   from (values (1,1),(1,4),(1,5),(3,1),(3,2)) v(a,b)\n+--  group by rollup (a) order by a;\n+\n+-- nesting with window functions\n+-- [SPARK-29699] Different answers in nested aggregates with window functions\n+select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+  from gstest2 group by rollup (a,b) order by rsum, a, b;\n+\n+-- [SPARK-29700] Support nested grouping sets\n+-- nesting with grouping sets\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(())))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(((a, b)))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(rollup(c), grouping sets(cube(c))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(a, grouping sets(a, cube(b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, (b))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a, grouping sets(a), ((a)), a, grouping sets(a), (a)), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((a,(a,b)), grouping sets((a,(a,b)),a))\n+--   order by 1 desc;\n+\n+-- empty input: first is 0 rows, second 1, third 3 etc.\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),a);\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),());\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),(),(),());\n+select sum(v), count(*) from gstest_empty group by grouping sets ((),(),());\n+\n+-- empty input with joins tests some important code paths\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select t1.a, t2.b, sum(t1.v), count(*) from gstest_empty t1, gstest_empty t2\n+ group by grouping sets ((t1.a,t2.b),());\n+\n+-- simple joins, var resolution, GROUPING on join vars\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1, gstest2 t2\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1 join gstest2 t2 on (t1.a=t2.a)\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a, b), sum(t1.v), max(t2.c)\n+select a, b, grouping(a), grouping(b), sum(t1.v), max(t2.c)\n+  from gstest1 t1 join gstest2 t2 using (a,b)\n+ group by grouping sets ((a, b), ());\n+\n+-- check that functionally dependent cols are not nulled\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- [SPARK-29702] Resolve group-by columns with functional dependencies\n+-- select a, d, grouping(a,b,c)\n+--   from gstest3\n+--  group by grouping sets ((a,b), (a,c));\n+\n+-- check that distinct grouping columns are kept separate\n+-- even if they are equal()\n+-- explain (costs off)\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- [SPARK-27767] Built-in function: generate_series\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- check that pulled-up subquery outputs still go to null when appropriate\n+select four, x\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  having x = 'foo';\n+\n+select four, x || 'x'\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  order by four;\n+\n+select (x+y)*1, sum(z)\n+ from (select 1 as x, 2 as y, 3 as z) s\n+ group by grouping sets (x+y, x);\n+\n+CREATE TEMP VIEW int8_tbl AS SELECT * FROM VALUES\n+  (123L, 456L),\n+  (123L, 4567890123456789L),\n+  (4567890123456789L, 123L),\n+  (4567890123456789L, 4567890123456789L),\n+  (4567890123456789L, -4567890123456789L) as int8_tbl(q1, q2);\n+\n+select x, not x as not_x, q2 from\n+  (select *, q1 = 1 as x from int8_tbl i1) as t\n+  group by grouping sets(x, q2)\n+  order by x, q2;\n+\n+DROP VIEW int8_tbl;\n+\n+-- simple rescan tests\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by rollup (a,b);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select *\n+--   from (values (1),(2)) v(x),\n+--        lateral (select a, b, sum(v.x) from gstest_data(v.x) group by rollup (a,b)) s;\n+\n+-- min max optimization should still work with GROUP BY ()\n+-- explain (costs off)\n+--   select min(unique1) from tenk1 GROUP BY ();\n+\n+-- Views with GROUPING SET queries\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29705] Support more expressive forms in GroupingSets/Cube/Rollup\n+-- CREATE VIEW gstest_view AS select a, b, grouping(a,b), sum(c), count(*), max(c)\n+--   from gstest2 group by rollup ((a,b,c),(c,d));\n+\n+-- select pg_get_viewdef('gstest_view'::regclass, true);\n+\n+-- Nested queries with 3 or more levels of nesting\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(e,f) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(c) from (values (1)) v2(c) GROUP BY c) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+\n+-- Combinations of operations\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select a, b, c, d from gstest2 group by rollup(a,b),grouping sets(c,d);\n+-- select a, b from (values (1,2),(2,3)) v(a,b) group by a,b, grouping sets(a);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- Tests for chained aggregates\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a,b),(a+1,b+1),(a+2,b+2)) order by 3,6;\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP((e+1),(f+1));\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY CUBE((e+1),(f+1)) ORDER BY (e+1),(f+1);\n+-- select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+--   from gstest2 group by cube (a,b) order by rsum, a, b;\n+-- select a, b, sum(c) from (values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),(2,3,15),(3,3,16),(3,4,17),(4,1,18),(4,1,19)) v(a,b,c) group by rollup (a,b);\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by cube (a,b) order by a,b;\n+\n+-- Test reordering of grouping sets\n+-- explain (costs off)\n+-- select * from gstest1 group by grouping sets((a,b,v),(v)) order by v,b,a;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- Agg level check. This query should error out.\n+-- select (select grouping(a), grouping(b) from gstest2) from gstest2 group by a,b;\n+\n+--Nested queries\n+-- [SPARK-29700] Support nested grouping sets\n+-- select a, b, sum(c), count(*) from gstest2 group by grouping sets (rollup(a,b),a);\n+\n+-- HAVING queries\n+select ten, sum(distinct four) from onek a\n+group by grouping sets((ten,four),(ten))\n+having exists (select 1 from onek b where sum(distinct a.four) = b.four);\n+\n+-- Tests around pushdown of HAVING clauses, partially testing against previous bugs\n+select a,count(*) from gstest2 group by rollup(a) order by a;\n+select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+-- explain (costs off)\n+--   select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+\n+-- [SPARK-29706] Support an empty grouping expression\n+-- select v.c, (select count(*) from gstest2 group by () having v.c)\n+--   from (values (false),(true)) v(c) order by v.c;\n+-- explain (costs off)\n+--   select v.c, (select count(*) from gstest2 group by () having v.c)\n+--     from (values (false),(true)) v(c) order by v.c;\n+\n+-- HAVING with GROUPING queries\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten) having grouping(ten) >= 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten, four) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by rollup(ten) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by cube(ten) having grouping(ten) > 0\n+order by 2,1;\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select ten, grouping(ten) from onek\n+-- group by (ten) having grouping(ten) >= 0\n+-- order by 2,1;\n+\n+-- FILTER queries\n+-- [SPARK-27986] Support Aggregate Expressions with filter\n+-- select ten, sum(distinct four) filter (where string(four) ~ '123') from onek a\n+-- group by rollup(ten);\n+\n+-- More rescan tests\n+-- [SPARK-27877] ANSI SQL: LATERAL derived table(T491)\n+-- select * from (values (1),(2)) v(a) left join lateral (select v.a, four, ten, count(*) from onek group by cube(four,ten)) s on true order by v.a,four,ten;\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array(select row(v.a,s1.*) from (select two,four, count(*) from onek group by cube(two,four) order by two,four) s1) from (values (1),(2)) v(a);\n+\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- Grouping on text columns\n+-- select sum(ten) from onek group by two, rollup(string(four)) order by 1;\n+-- select sum(ten) from onek group by rollup(string(four)), two order by 1;\n+\n+-- hashing support\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = true;\n+\n+-- failure cases\n+\n+-- Since this test is implementation specific for plans, it passes in Spark\n+select count(*) from gstest4 group by rollup(unhashable_col,unsortable_col);\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array_agg(v order by v) from gstest4 group by grouping sets ((id,unsortable_col),(id));\n+\n+-- simple cases\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by grouping sets ((a),(b)) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a),(b)) order by 3,1,2;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by cube(a,b) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by cube(a,b) order by 3,1,2;\n+\n+-- shouldn't try and hash\n+-- explain (costs off)\n+--   select a, b, grouping(a,b), array_agg(v order by v)\n+--     from gstest1 group by cube(a,b);\n+\n+-- unsortable cases\n+-- [SPARK-29708] Different answers in aggregates of multiple grouping sets\n+select unsortable_col, count(*)\n+  from gstest4 group by grouping sets ((unsortable_col),(unsortable_col))\n+  order by string(unsortable_col);\n+\n+-- mixed hashable/sortable cases\n+select unhashable_col, unsortable_col,\n+       -- [SPARK-29698] Support grouping function with multiple arguments\n+       -- grouping(unhashable_col, unsortable_col),\n+       grouping(unhashable_col), grouping(unsortable_col),\n+       count(*), sum(v)\n+  from gstest4 group by grouping sets ((unhashable_col),(unsortable_col))\n+ order by 3, 4, 6 /* 3, 5 */;",
    "line": 400
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Ur, I see. I think so. Thanks!",
    "commit": "d7f6909613631b4ea3dfa62a172a9565a213c4ce",
    "createdAt": "2019-11-05T02:04:12Z",
    "diffHunk": "@@ -0,0 +1,563 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- GROUPING SETS\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/groupingsets.sql\n+\n+-- test data sources\n+\n+create temp view gstest1(a,b,v)\n+  as values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),\n+            (2,3,15),\n+            (3,3,16),(3,4,17),\n+            (4,1,18),(4,1,19);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest2 (a integer, b integer, c integer, d integer,\n+--                            e integer, f integer, g integer, h integer);\n+create table gstest2 (a integer, b integer, c integer, d integer,\n+                      e integer, f integer, g integer, h integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest2 from stdin;\n+-- 1\t1\t1\t1\t1\t1\t1\t1\n+-- 1\t1\t1\t1\t1\t1\t1\t2\n+-- 1\t1\t1\t1\t1\t1\t2\t2\n+-- 1\t1\t1\t1\t1\t2\t2\t2\n+-- 1\t1\t1\t1\t2\t2\t2\t2\n+-- 1\t1\t1\t2\t2\t2\t2\t2\n+-- 1\t1\t2\t2\t2\t2\t2\t2\n+-- 1\t2\t2\t2\t2\t2\t2\t2\n+-- 2\t2\t2\t2\t2\t2\t2\t2\n+-- \\.\n+insert into gstest2 values\n+  (1, 1, 1, 1, 1, 1, 1, 1),\n+  (1, 1, 1, 1, 1, 1, 1, 2),\n+  (1, 1, 1, 1, 1, 1, 2, 2),\n+  (1, 1, 1, 1, 1, 2, 2, 2),\n+  (1, 1, 1, 1, 2, 2, 2, 2),\n+  (1, 1, 1, 2, 2, 2, 2, 2),\n+  (1, 1, 2, 2, 2, 2, 2, 2),\n+  (1, 2, 2, 2, 2, 2, 2, 2),\n+  (2, 2, 2, 2, 2, 2, 2, 2);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest3 (a integer, b integer, c integer, d integer);\n+create table gstest3 (a integer, b integer, c integer, d integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest3 from stdin;\n+-- 1\t1\t1\t1\n+-- 2\t2\t2\t2\n+-- \\.\n+insert into gstest3 values\n+  (1, 1, 1, 1),\n+  (2, 2, 2, 2);\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- alter table gstest3 add primary key (a);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest4(id integer, v integer,\n+--                           unhashable_col bit(4), unsortable_col xid);\n+-- [SPARK-29697] Support bit string types/literals\n+create table gstest4(id integer, v integer,\n+                     unhashable_col /* bit(4) */ byte, unsortable_col /* xid */ integer) using parquet;\n+insert into gstest4\n+-- values (1,1,b'0000','1'), (2,2,b'0001','1'),\n+--        (3,4,b'0010','2'), (4,8,b'0011','2'),\n+--        (5,16,b'0000','2'), (6,32,b'0001','2'),\n+--        (7,64,b'0010','1'), (8,128,b'0011','1');\n+values (1,1,tinyint('0'),1), (2,2,tinyint('1'),1),\n+       (3,4,tinyint('2'),2), (4,8,tinyint('3'),2),\n+       (5,16,tinyint('0'),2), (6,32,tinyint('1'),2),\n+       (7,64,tinyint('2'),1), (8,128,tinyint('3'),1);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest_empty (a integer, b integer, v integer);\n+create table gstest_empty (a integer, b integer, v integer) using parquet;\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- create function gstest_data(v integer, out a integer, out b integer)\n+--   returns setof record\n+--   as $f$\n+--     begin\n+--       return query select v, i from generate_series(1,3) i;\n+--     end;\n+--   $f$ language plpgsql;\n+\n+-- basic functionality\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = false;  -- test hashing explicitly later\n+\n+-- simple rollup with multiple plain aggregates, with and without ordering\n+-- (and with ordering differing from grouping)\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b);\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by a,b;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by b desc, a;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by coalesce(a,0)+coalesce(b,0);\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- various types of ordered aggs\n+-- select a, b, grouping(a,b),\n+--        array_agg(v order by v),\n+--        string_agg(string(v:text, ':' order by v desc),\n+--        percentile_disc(0.5) within group (order by v),\n+--        rank(1,2,12) within group (order by a,b,v)\n+--   from gstest1 group by rollup (a,b) order by a,b;\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- test usage of grouped columns in direct args of aggs\n+-- select grouping(a), a, array_agg(b),\n+--        rank(a) within group (order by b nulls first),\n+--        rank(a) within group (order by b nulls last)\n+--   from (values (1,1),(1,4),(1,5),(3,1),(3,2)) v(a,b)\n+--  group by rollup (a) order by a;\n+\n+-- nesting with window functions\n+-- [SPARK-29699] Different answers in nested aggregates with window functions\n+select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+  from gstest2 group by rollup (a,b) order by rsum, a, b;\n+\n+-- [SPARK-29700] Support nested grouping sets\n+-- nesting with grouping sets\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(())))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(((a, b)))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(rollup(c), grouping sets(cube(c))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(a, grouping sets(a, cube(b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, (b))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a, grouping sets(a), ((a)), a, grouping sets(a), (a)), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((a,(a,b)), grouping sets((a,(a,b)),a))\n+--   order by 1 desc;\n+\n+-- empty input: first is 0 rows, second 1, third 3 etc.\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),a);\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),());\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),(),(),());\n+select sum(v), count(*) from gstest_empty group by grouping sets ((),(),());\n+\n+-- empty input with joins tests some important code paths\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select t1.a, t2.b, sum(t1.v), count(*) from gstest_empty t1, gstest_empty t2\n+ group by grouping sets ((t1.a,t2.b),());\n+\n+-- simple joins, var resolution, GROUPING on join vars\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1, gstest2 t2\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1 join gstest2 t2 on (t1.a=t2.a)\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a, b), sum(t1.v), max(t2.c)\n+select a, b, grouping(a), grouping(b), sum(t1.v), max(t2.c)\n+  from gstest1 t1 join gstest2 t2 using (a,b)\n+ group by grouping sets ((a, b), ());\n+\n+-- check that functionally dependent cols are not nulled\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- [SPARK-29702] Resolve group-by columns with functional dependencies\n+-- select a, d, grouping(a,b,c)\n+--   from gstest3\n+--  group by grouping sets ((a,b), (a,c));\n+\n+-- check that distinct grouping columns are kept separate\n+-- even if they are equal()\n+-- explain (costs off)\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- [SPARK-27767] Built-in function: generate_series\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- check that pulled-up subquery outputs still go to null when appropriate\n+select four, x\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  having x = 'foo';\n+\n+select four, x || 'x'\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  order by four;\n+\n+select (x+y)*1, sum(z)\n+ from (select 1 as x, 2 as y, 3 as z) s\n+ group by grouping sets (x+y, x);\n+\n+CREATE TEMP VIEW int8_tbl AS SELECT * FROM VALUES\n+  (123L, 456L),\n+  (123L, 4567890123456789L),\n+  (4567890123456789L, 123L),\n+  (4567890123456789L, 4567890123456789L),\n+  (4567890123456789L, -4567890123456789L) as int8_tbl(q1, q2);\n+\n+select x, not x as not_x, q2 from\n+  (select *, q1 = 1 as x from int8_tbl i1) as t\n+  group by grouping sets(x, q2)\n+  order by x, q2;\n+\n+DROP VIEW int8_tbl;\n+\n+-- simple rescan tests\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by rollup (a,b);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select *\n+--   from (values (1),(2)) v(x),\n+--        lateral (select a, b, sum(v.x) from gstest_data(v.x) group by rollup (a,b)) s;\n+\n+-- min max optimization should still work with GROUP BY ()\n+-- explain (costs off)\n+--   select min(unique1) from tenk1 GROUP BY ();\n+\n+-- Views with GROUPING SET queries\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29705] Support more expressive forms in GroupingSets/Cube/Rollup\n+-- CREATE VIEW gstest_view AS select a, b, grouping(a,b), sum(c), count(*), max(c)\n+--   from gstest2 group by rollup ((a,b,c),(c,d));\n+\n+-- select pg_get_viewdef('gstest_view'::regclass, true);\n+\n+-- Nested queries with 3 or more levels of nesting\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(e,f) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(c) from (values (1)) v2(c) GROUP BY c) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+\n+-- Combinations of operations\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select a, b, c, d from gstest2 group by rollup(a,b),grouping sets(c,d);\n+-- select a, b from (values (1,2),(2,3)) v(a,b) group by a,b, grouping sets(a);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- Tests for chained aggregates\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a,b),(a+1,b+1),(a+2,b+2)) order by 3,6;\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP((e+1),(f+1));\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY CUBE((e+1),(f+1)) ORDER BY (e+1),(f+1);\n+-- select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+--   from gstest2 group by cube (a,b) order by rsum, a, b;\n+-- select a, b, sum(c) from (values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),(2,3,15),(3,3,16),(3,4,17),(4,1,18),(4,1,19)) v(a,b,c) group by rollup (a,b);\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by cube (a,b) order by a,b;\n+\n+-- Test reordering of grouping sets\n+-- explain (costs off)\n+-- select * from gstest1 group by grouping sets((a,b,v),(v)) order by v,b,a;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- Agg level check. This query should error out.\n+-- select (select grouping(a), grouping(b) from gstest2) from gstest2 group by a,b;\n+\n+--Nested queries\n+-- [SPARK-29700] Support nested grouping sets\n+-- select a, b, sum(c), count(*) from gstest2 group by grouping sets (rollup(a,b),a);\n+\n+-- HAVING queries\n+select ten, sum(distinct four) from onek a\n+group by grouping sets((ten,four),(ten))\n+having exists (select 1 from onek b where sum(distinct a.four) = b.four);\n+\n+-- Tests around pushdown of HAVING clauses, partially testing against previous bugs\n+select a,count(*) from gstest2 group by rollup(a) order by a;\n+select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+-- explain (costs off)\n+--   select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+\n+-- [SPARK-29706] Support an empty grouping expression\n+-- select v.c, (select count(*) from gstest2 group by () having v.c)\n+--   from (values (false),(true)) v(c) order by v.c;\n+-- explain (costs off)\n+--   select v.c, (select count(*) from gstest2 group by () having v.c)\n+--     from (values (false),(true)) v(c) order by v.c;\n+\n+-- HAVING with GROUPING queries\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten) having grouping(ten) >= 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten, four) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by rollup(ten) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by cube(ten) having grouping(ten) > 0\n+order by 2,1;\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select ten, grouping(ten) from onek\n+-- group by (ten) having grouping(ten) >= 0\n+-- order by 2,1;\n+\n+-- FILTER queries\n+-- [SPARK-27986] Support Aggregate Expressions with filter\n+-- select ten, sum(distinct four) filter (where string(four) ~ '123') from onek a\n+-- group by rollup(ten);\n+\n+-- More rescan tests\n+-- [SPARK-27877] ANSI SQL: LATERAL derived table(T491)\n+-- select * from (values (1),(2)) v(a) left join lateral (select v.a, four, ten, count(*) from onek group by cube(four,ten)) s on true order by v.a,four,ten;\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array(select row(v.a,s1.*) from (select two,four, count(*) from onek group by cube(two,four) order by two,four) s1) from (values (1),(2)) v(a);\n+\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- Grouping on text columns\n+-- select sum(ten) from onek group by two, rollup(string(four)) order by 1;\n+-- select sum(ten) from onek group by rollup(string(four)), two order by 1;\n+\n+-- hashing support\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = true;\n+\n+-- failure cases\n+\n+-- Since this test is implementation specific for plans, it passes in Spark\n+select count(*) from gstest4 group by rollup(unhashable_col,unsortable_col);\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array_agg(v order by v) from gstest4 group by grouping sets ((id,unsortable_col),(id));\n+\n+-- simple cases\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by grouping sets ((a),(b)) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a),(b)) order by 3,1,2;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by cube(a,b) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by cube(a,b) order by 3,1,2;\n+\n+-- shouldn't try and hash\n+-- explain (costs off)\n+--   select a, b, grouping(a,b), array_agg(v order by v)\n+--     from gstest1 group by cube(a,b);\n+\n+-- unsortable cases\n+-- [SPARK-29708] Different answers in aggregates of multiple grouping sets\n+select unsortable_col, count(*)\n+  from gstest4 group by grouping sets ((unsortable_col),(unsortable_col))\n+  order by string(unsortable_col);\n+\n+-- mixed hashable/sortable cases\n+select unhashable_col, unsortable_col,\n+       -- [SPARK-29698] Support grouping function with multiple arguments\n+       -- grouping(unhashable_col, unsortable_col),\n+       grouping(unhashable_col), grouping(unsortable_col),\n+       count(*), sum(v)\n+  from gstest4 group by grouping sets ((unhashable_col),(unsortable_col))\n+ order by 3, 4, 6 /* 3, 5 */;",
    "line": 400
  }],
  "prId": 26352
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "ditto. This affects line 414, too. This comment should be mentioned before line 408.",
    "commit": "d7f6909613631b4ea3dfa62a172a9565a213c4ce",
    "createdAt": "2019-11-05T01:47:16Z",
    "diffHunk": "@@ -0,0 +1,563 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- GROUPING SETS\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/groupingsets.sql\n+\n+-- test data sources\n+\n+create temp view gstest1(a,b,v)\n+  as values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),\n+            (2,3,15),\n+            (3,3,16),(3,4,17),\n+            (4,1,18),(4,1,19);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest2 (a integer, b integer, c integer, d integer,\n+--                            e integer, f integer, g integer, h integer);\n+create table gstest2 (a integer, b integer, c integer, d integer,\n+                      e integer, f integer, g integer, h integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest2 from stdin;\n+-- 1\t1\t1\t1\t1\t1\t1\t1\n+-- 1\t1\t1\t1\t1\t1\t1\t2\n+-- 1\t1\t1\t1\t1\t1\t2\t2\n+-- 1\t1\t1\t1\t1\t2\t2\t2\n+-- 1\t1\t1\t1\t2\t2\t2\t2\n+-- 1\t1\t1\t2\t2\t2\t2\t2\n+-- 1\t1\t2\t2\t2\t2\t2\t2\n+-- 1\t2\t2\t2\t2\t2\t2\t2\n+-- 2\t2\t2\t2\t2\t2\t2\t2\n+-- \\.\n+insert into gstest2 values\n+  (1, 1, 1, 1, 1, 1, 1, 1),\n+  (1, 1, 1, 1, 1, 1, 1, 2),\n+  (1, 1, 1, 1, 1, 1, 2, 2),\n+  (1, 1, 1, 1, 1, 2, 2, 2),\n+  (1, 1, 1, 1, 2, 2, 2, 2),\n+  (1, 1, 1, 2, 2, 2, 2, 2),\n+  (1, 1, 2, 2, 2, 2, 2, 2),\n+  (1, 2, 2, 2, 2, 2, 2, 2),\n+  (2, 2, 2, 2, 2, 2, 2, 2);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest3 (a integer, b integer, c integer, d integer);\n+create table gstest3 (a integer, b integer, c integer, d integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest3 from stdin;\n+-- 1\t1\t1\t1\n+-- 2\t2\t2\t2\n+-- \\.\n+insert into gstest3 values\n+  (1, 1, 1, 1),\n+  (2, 2, 2, 2);\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- alter table gstest3 add primary key (a);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest4(id integer, v integer,\n+--                           unhashable_col bit(4), unsortable_col xid);\n+-- [SPARK-29697] Support bit string types/literals\n+create table gstest4(id integer, v integer,\n+                     unhashable_col /* bit(4) */ byte, unsortable_col /* xid */ integer) using parquet;\n+insert into gstest4\n+-- values (1,1,b'0000','1'), (2,2,b'0001','1'),\n+--        (3,4,b'0010','2'), (4,8,b'0011','2'),\n+--        (5,16,b'0000','2'), (6,32,b'0001','2'),\n+--        (7,64,b'0010','1'), (8,128,b'0011','1');\n+values (1,1,tinyint('0'),1), (2,2,tinyint('1'),1),\n+       (3,4,tinyint('2'),2), (4,8,tinyint('3'),2),\n+       (5,16,tinyint('0'),2), (6,32,tinyint('1'),2),\n+       (7,64,tinyint('2'),1), (8,128,tinyint('3'),1);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest_empty (a integer, b integer, v integer);\n+create table gstest_empty (a integer, b integer, v integer) using parquet;\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- create function gstest_data(v integer, out a integer, out b integer)\n+--   returns setof record\n+--   as $f$\n+--     begin\n+--       return query select v, i from generate_series(1,3) i;\n+--     end;\n+--   $f$ language plpgsql;\n+\n+-- basic functionality\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = false;  -- test hashing explicitly later\n+\n+-- simple rollup with multiple plain aggregates, with and without ordering\n+-- (and with ordering differing from grouping)\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b);\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by a,b;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by b desc, a;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by coalesce(a,0)+coalesce(b,0);\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- various types of ordered aggs\n+-- select a, b, grouping(a,b),\n+--        array_agg(v order by v),\n+--        string_agg(string(v:text, ':' order by v desc),\n+--        percentile_disc(0.5) within group (order by v),\n+--        rank(1,2,12) within group (order by a,b,v)\n+--   from gstest1 group by rollup (a,b) order by a,b;\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- test usage of grouped columns in direct args of aggs\n+-- select grouping(a), a, array_agg(b),\n+--        rank(a) within group (order by b nulls first),\n+--        rank(a) within group (order by b nulls last)\n+--   from (values (1,1),(1,4),(1,5),(3,1),(3,2)) v(a,b)\n+--  group by rollup (a) order by a;\n+\n+-- nesting with window functions\n+-- [SPARK-29699] Different answers in nested aggregates with window functions\n+select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+  from gstest2 group by rollup (a,b) order by rsum, a, b;\n+\n+-- [SPARK-29700] Support nested grouping sets\n+-- nesting with grouping sets\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(())))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(((a, b)))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(rollup(c), grouping sets(cube(c))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(a, grouping sets(a, cube(b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, (b))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a, grouping sets(a), ((a)), a, grouping sets(a), (a)), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((a,(a,b)), grouping sets((a,(a,b)),a))\n+--   order by 1 desc;\n+\n+-- empty input: first is 0 rows, second 1, third 3 etc.\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),a);\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),());\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),(),(),());\n+select sum(v), count(*) from gstest_empty group by grouping sets ((),(),());\n+\n+-- empty input with joins tests some important code paths\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select t1.a, t2.b, sum(t1.v), count(*) from gstest_empty t1, gstest_empty t2\n+ group by grouping sets ((t1.a,t2.b),());\n+\n+-- simple joins, var resolution, GROUPING on join vars\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1, gstest2 t2\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1 join gstest2 t2 on (t1.a=t2.a)\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a, b), sum(t1.v), max(t2.c)\n+select a, b, grouping(a), grouping(b), sum(t1.v), max(t2.c)\n+  from gstest1 t1 join gstest2 t2 using (a,b)\n+ group by grouping sets ((a, b), ());\n+\n+-- check that functionally dependent cols are not nulled\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- [SPARK-29702] Resolve group-by columns with functional dependencies\n+-- select a, d, grouping(a,b,c)\n+--   from gstest3\n+--  group by grouping sets ((a,b), (a,c));\n+\n+-- check that distinct grouping columns are kept separate\n+-- even if they are equal()\n+-- explain (costs off)\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- [SPARK-27767] Built-in function: generate_series\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- check that pulled-up subquery outputs still go to null when appropriate\n+select four, x\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  having x = 'foo';\n+\n+select four, x || 'x'\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  order by four;\n+\n+select (x+y)*1, sum(z)\n+ from (select 1 as x, 2 as y, 3 as z) s\n+ group by grouping sets (x+y, x);\n+\n+CREATE TEMP VIEW int8_tbl AS SELECT * FROM VALUES\n+  (123L, 456L),\n+  (123L, 4567890123456789L),\n+  (4567890123456789L, 123L),\n+  (4567890123456789L, 4567890123456789L),\n+  (4567890123456789L, -4567890123456789L) as int8_tbl(q1, q2);\n+\n+select x, not x as not_x, q2 from\n+  (select *, q1 = 1 as x from int8_tbl i1) as t\n+  group by grouping sets(x, q2)\n+  order by x, q2;\n+\n+DROP VIEW int8_tbl;\n+\n+-- simple rescan tests\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by rollup (a,b);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select *\n+--   from (values (1),(2)) v(x),\n+--        lateral (select a, b, sum(v.x) from gstest_data(v.x) group by rollup (a,b)) s;\n+\n+-- min max optimization should still work with GROUP BY ()\n+-- explain (costs off)\n+--   select min(unique1) from tenk1 GROUP BY ();\n+\n+-- Views with GROUPING SET queries\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29705] Support more expressive forms in GroupingSets/Cube/Rollup\n+-- CREATE VIEW gstest_view AS select a, b, grouping(a,b), sum(c), count(*), max(c)\n+--   from gstest2 group by rollup ((a,b,c),(c,d));\n+\n+-- select pg_get_viewdef('gstest_view'::regclass, true);\n+\n+-- Nested queries with 3 or more levels of nesting\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(e,f) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(c) from (values (1)) v2(c) GROUP BY c) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+\n+-- Combinations of operations\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select a, b, c, d from gstest2 group by rollup(a,b),grouping sets(c,d);\n+-- select a, b from (values (1,2),(2,3)) v(a,b) group by a,b, grouping sets(a);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- Tests for chained aggregates\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a,b),(a+1,b+1),(a+2,b+2)) order by 3,6;\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP((e+1),(f+1));\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY CUBE((e+1),(f+1)) ORDER BY (e+1),(f+1);\n+-- select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+--   from gstest2 group by cube (a,b) order by rsum, a, b;\n+-- select a, b, sum(c) from (values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),(2,3,15),(3,3,16),(3,4,17),(4,1,18),(4,1,19)) v(a,b,c) group by rollup (a,b);\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by cube (a,b) order by a,b;\n+\n+-- Test reordering of grouping sets\n+-- explain (costs off)\n+-- select * from gstest1 group by grouping sets((a,b,v),(v)) order by v,b,a;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- Agg level check. This query should error out.\n+-- select (select grouping(a), grouping(b) from gstest2) from gstest2 group by a,b;\n+\n+--Nested queries\n+-- [SPARK-29700] Support nested grouping sets\n+-- select a, b, sum(c), count(*) from gstest2 group by grouping sets (rollup(a,b),a);\n+\n+-- HAVING queries\n+select ten, sum(distinct four) from onek a\n+group by grouping sets((ten,four),(ten))\n+having exists (select 1 from onek b where sum(distinct a.four) = b.four);\n+\n+-- Tests around pushdown of HAVING clauses, partially testing against previous bugs\n+select a,count(*) from gstest2 group by rollup(a) order by a;\n+select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+-- explain (costs off)\n+--   select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+\n+-- [SPARK-29706] Support an empty grouping expression\n+-- select v.c, (select count(*) from gstest2 group by () having v.c)\n+--   from (values (false),(true)) v(c) order by v.c;\n+-- explain (costs off)\n+--   select v.c, (select count(*) from gstest2 group by () having v.c)\n+--     from (values (false),(true)) v(c) order by v.c;\n+\n+-- HAVING with GROUPING queries\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten) having grouping(ten) >= 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten, four) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by rollup(ten) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by cube(ten) having grouping(ten) > 0\n+order by 2,1;\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select ten, grouping(ten) from onek\n+-- group by (ten) having grouping(ten) >= 0\n+-- order by 2,1;\n+\n+-- FILTER queries\n+-- [SPARK-27986] Support Aggregate Expressions with filter\n+-- select ten, sum(distinct four) filter (where string(four) ~ '123') from onek a\n+-- group by rollup(ten);\n+\n+-- More rescan tests\n+-- [SPARK-27877] ANSI SQL: LATERAL derived table(T491)\n+-- select * from (values (1),(2)) v(a) left join lateral (select v.a, four, ten, count(*) from onek group by cube(four,ten)) s on true order by v.a,four,ten;\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array(select row(v.a,s1.*) from (select two,four, count(*) from onek group by cube(two,four) order by two,four) s1) from (values (1),(2)) v(a);\n+\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- Grouping on text columns\n+-- select sum(ten) from onek group by two, rollup(string(four)) order by 1;\n+-- select sum(ten) from onek group by rollup(string(four)), two order by 1;\n+\n+-- hashing support\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = true;\n+\n+-- failure cases\n+\n+-- Since this test is implementation specific for plans, it passes in Spark\n+select count(*) from gstest4 group by rollup(unhashable_col,unsortable_col);\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array_agg(v order by v) from gstest4 group by grouping sets ((id,unsortable_col),(id));\n+\n+-- simple cases\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by grouping sets ((a),(b)) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a),(b)) order by 3,1,2;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by cube(a,b) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by cube(a,b) order by 3,1,2;\n+\n+-- shouldn't try and hash\n+-- explain (costs off)\n+--   select a, b, grouping(a,b), array_agg(v order by v)\n+--     from gstest1 group by cube(a,b);\n+\n+-- unsortable cases\n+-- [SPARK-29708] Different answers in aggregates of multiple grouping sets\n+select unsortable_col, count(*)\n+  from gstest4 group by grouping sets ((unsortable_col),(unsortable_col))\n+  order by string(unsortable_col);\n+\n+-- mixed hashable/sortable cases\n+select unhashable_col, unsortable_col,\n+       -- [SPARK-29698] Support grouping function with multiple arguments\n+       -- grouping(unhashable_col, unsortable_col),\n+       grouping(unhashable_col), grouping(unsortable_col),\n+       count(*), sum(v)\n+  from gstest4 group by grouping sets ((unhashable_col),(unsortable_col))\n+ order by 3, 4, 6 /* 3, 5 */;\n+-- explain (costs off)\n+--   select unhashable_col, unsortable_col,\n+--          grouping(unhashable_col, unsortable_col),\n+--          count(*), sum(v)\n+--     from gstest4 group by grouping sets ((unhashable_col),(unsortable_col))\n+--    order by 3,5;\n+\n+select unhashable_col, unsortable_col,\n+       -- [SPARK-29698] Support grouping function with multiple arguments"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "ok",
    "commit": "d7f6909613631b4ea3dfa62a172a9565a213c4ce",
    "createdAt": "2019-11-05T02:04:23Z",
    "diffHunk": "@@ -0,0 +1,563 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- GROUPING SETS\n+-- https://github.com/postgres/postgres/blob/REL_12_STABLE/src/test/regress/sql/groupingsets.sql\n+\n+-- test data sources\n+\n+create temp view gstest1(a,b,v)\n+  as values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),\n+            (2,3,15),\n+            (3,3,16),(3,4,17),\n+            (4,1,18),(4,1,19);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest2 (a integer, b integer, c integer, d integer,\n+--                            e integer, f integer, g integer, h integer);\n+create table gstest2 (a integer, b integer, c integer, d integer,\n+                      e integer, f integer, g integer, h integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest2 from stdin;\n+-- 1\t1\t1\t1\t1\t1\t1\t1\n+-- 1\t1\t1\t1\t1\t1\t1\t2\n+-- 1\t1\t1\t1\t1\t1\t2\t2\n+-- 1\t1\t1\t1\t1\t2\t2\t2\n+-- 1\t1\t1\t1\t2\t2\t2\t2\n+-- 1\t1\t1\t2\t2\t2\t2\t2\n+-- 1\t1\t2\t2\t2\t2\t2\t2\n+-- 1\t2\t2\t2\t2\t2\t2\t2\n+-- 2\t2\t2\t2\t2\t2\t2\t2\n+-- \\.\n+insert into gstest2 values\n+  (1, 1, 1, 1, 1, 1, 1, 1),\n+  (1, 1, 1, 1, 1, 1, 1, 2),\n+  (1, 1, 1, 1, 1, 1, 2, 2),\n+  (1, 1, 1, 1, 1, 2, 2, 2),\n+  (1, 1, 1, 1, 2, 2, 2, 2),\n+  (1, 1, 1, 2, 2, 2, 2, 2),\n+  (1, 1, 2, 2, 2, 2, 2, 2),\n+  (1, 2, 2, 2, 2, 2, 2, 2),\n+  (2, 2, 2, 2, 2, 2, 2, 2);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest3 (a integer, b integer, c integer, d integer);\n+create table gstest3 (a integer, b integer, c integer, d integer) using parquet;\n+-- [SPARK-29386] Copy data between a file and a table\n+-- copy gstest3 from stdin;\n+-- 1\t1\t1\t1\n+-- 2\t2\t2\t2\n+-- \\.\n+insert into gstest3 values\n+  (1, 1, 1, 1),\n+  (2, 2, 2, 2);\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- alter table gstest3 add primary key (a);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest4(id integer, v integer,\n+--                           unhashable_col bit(4), unsortable_col xid);\n+-- [SPARK-29697] Support bit string types/literals\n+create table gstest4(id integer, v integer,\n+                     unhashable_col /* bit(4) */ byte, unsortable_col /* xid */ integer) using parquet;\n+insert into gstest4\n+-- values (1,1,b'0000','1'), (2,2,b'0001','1'),\n+--        (3,4,b'0010','2'), (4,8,b'0011','2'),\n+--        (5,16,b'0000','2'), (6,32,b'0001','2'),\n+--        (7,64,b'0010','1'), (8,128,b'0011','1');\n+values (1,1,tinyint('0'),1), (2,2,tinyint('1'),1),\n+       (3,4,tinyint('2'),2), (4,8,tinyint('3'),2),\n+       (5,16,tinyint('0'),2), (6,32,tinyint('1'),2),\n+       (7,64,tinyint('2'),1), (8,128,tinyint('3'),1);\n+\n+-- Since Spark doesn't support CREATE TEMPORARY TABLE, we used CREATE TABLE instead\n+-- create temp table gstest_empty (a integer, b integer, v integer);\n+create table gstest_empty (a integer, b integer, v integer) using parquet;\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- create function gstest_data(v integer, out a integer, out b integer)\n+--   returns setof record\n+--   as $f$\n+--     begin\n+--       return query select v, i from generate_series(1,3) i;\n+--     end;\n+--   $f$ language plpgsql;\n+\n+-- basic functionality\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = false;  -- test hashing explicitly later\n+\n+-- simple rollup with multiple plain aggregates, with and without ordering\n+-- (and with ordering differing from grouping)\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b);\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by a,b;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by b desc, a;\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by rollup (a,b) order by coalesce(a,0)+coalesce(b,0);\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- various types of ordered aggs\n+-- select a, b, grouping(a,b),\n+--        array_agg(v order by v),\n+--        string_agg(string(v:text, ':' order by v desc),\n+--        percentile_disc(0.5) within group (order by v),\n+--        rank(1,2,12) within group (order by a,b,v)\n+--   from gstest1 group by rollup (a,b) order by a,b;\n+\n+-- [SPARK-28664] ORDER BY in aggregate function\n+-- test usage of grouped columns in direct args of aggs\n+-- select grouping(a), a, array_agg(b),\n+--        rank(a) within group (order by b nulls first),\n+--        rank(a) within group (order by b nulls last)\n+--   from (values (1,1),(1,4),(1,5),(3,1),(3,2)) v(a,b)\n+--  group by rollup (a) order by a;\n+\n+-- nesting with window functions\n+-- [SPARK-29699] Different answers in nested aggregates with window functions\n+select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+  from gstest2 group by rollup (a,b) order by rsum, a, b;\n+\n+-- [SPARK-29700] Support nested grouping sets\n+-- nesting with grouping sets\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(())))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((), grouping sets((), grouping sets(((a, b)))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(rollup(c), grouping sets(cube(c))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(a, grouping sets(a, cube(b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, (b))))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets((a, b)))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets(grouping sets(a, grouping sets(a, grouping sets(a), ((a)), a, grouping sets(a), (a)), a))\n+--   order by 1 desc;\n+-- select sum(c) from gstest2\n+--   group by grouping sets((a,(a,b)), grouping sets((a,(a,b)),a))\n+--   order by 1 desc;\n+\n+-- empty input: first is 0 rows, second 1, third 3 etc.\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),a);\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),());\n+select a, b, sum(v), count(*) from gstest_empty group by grouping sets ((a,b),(),(),());\n+select sum(v), count(*) from gstest_empty group by grouping sets ((),(),());\n+\n+-- empty input with joins tests some important code paths\n+-- [SPARK-29701] Different answers when empty input given in GROUPING SETS\n+select t1.a, t2.b, sum(t1.v), count(*) from gstest_empty t1, gstest_empty t2\n+ group by grouping sets ((t1.a,t2.b),());\n+\n+-- simple joins, var resolution, GROUPING on join vars\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1, gstest2 t2\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select t1.a, t2.b, grouping(t1.a, t2.b), sum(t1.v), max(t2.a)\n+select t1.a, t2.b, grouping(t1.a), grouping(t2.b), sum(t1.v), max(t2.a)\n+  from gstest1 t1 join gstest2 t2 on (t1.a=t2.a)\n+ group by grouping sets ((t1.a, t2.b), ());\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a, b), sum(t1.v), max(t2.c)\n+select a, b, grouping(a), grouping(b), sum(t1.v), max(t2.c)\n+  from gstest1 t1 join gstest2 t2 using (a,b)\n+ group by grouping sets ((a, b), ());\n+\n+-- check that functionally dependent cols are not nulled\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-19842] Informational Referential Integrity Constraints Support in Spark\n+-- [SPARK-29702] Resolve group-by columns with functional dependencies\n+-- select a, d, grouping(a,b,c)\n+--   from gstest3\n+--  group by grouping sets ((a,b), (a,c));\n+\n+-- check that distinct grouping columns are kept separate\n+-- even if they are equal()\n+-- explain (costs off)\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- [SPARK-27767] Built-in function: generate_series\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select g as alias1, g as alias2\n+--   from generate_series(1,3) g\n+--  group by alias1, rollup(alias2);\n+\n+-- check that pulled-up subquery outputs still go to null when appropriate\n+select four, x\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  having x = 'foo';\n+\n+select four, x || 'x'\n+  from (select four, ten, 'foo' as x from tenk1) as t\n+  group by grouping sets (four, x)\n+  order by four;\n+\n+select (x+y)*1, sum(z)\n+ from (select 1 as x, 2 as y, 3 as z) s\n+ group by grouping sets (x+y, x);\n+\n+CREATE TEMP VIEW int8_tbl AS SELECT * FROM VALUES\n+  (123L, 456L),\n+  (123L, 4567890123456789L),\n+  (4567890123456789L, 123L),\n+  (4567890123456789L, 4567890123456789L),\n+  (4567890123456789L, -4567890123456789L) as int8_tbl(q1, q2);\n+\n+select x, not x as not_x, q2 from\n+  (select *, q1 = 1 as x from int8_tbl i1) as t\n+  group by grouping sets(x, q2)\n+  order by x, q2;\n+\n+DROP VIEW int8_tbl;\n+\n+-- simple rescan tests\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by rollup (a,b);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- select *\n+--   from (values (1),(2)) v(x),\n+--        lateral (select a, b, sum(v.x) from gstest_data(v.x) group by rollup (a,b)) s;\n+\n+-- min max optimization should still work with GROUP BY ()\n+-- explain (costs off)\n+--   select min(unique1) from tenk1 GROUP BY ();\n+\n+-- Views with GROUPING SET queries\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29705] Support more expressive forms in GroupingSets/Cube/Rollup\n+-- CREATE VIEW gstest_view AS select a, b, grouping(a,b), sum(c), count(*), max(c)\n+--   from gstest2 group by rollup ((a,b,c),(c,d));\n+\n+-- select pg_get_viewdef('gstest_view'::regclass, true);\n+\n+-- Nested queries with 3 or more levels of nesting\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(e,f) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+-- select(select (select grouping(c) from (values (1)) v2(c) GROUP BY c) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP(e,f);\n+\n+-- Combinations of operations\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- select a, b, c, d from gstest2 group by rollup(a,b),grouping sets(c,d);\n+-- select a, b from (values (1,2),(2,3)) v(a,b) group by a,b, grouping sets(a);\n+\n+-- Spark doesn't handle UDFs in SQL\n+-- Tests for chained aggregates\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a,b),(a+1,b+1),(a+2,b+2)) order by 3,6;\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY ROLLUP((e+1),(f+1));\n+-- select(select (select grouping(a,b) from (values (1)) v2(c)) from (values (1,2)) v1(a,b) group by (a,b)) from (values(6,7)) v3(e,f) GROUP BY CUBE((e+1),(f+1)) ORDER BY (e+1),(f+1);\n+-- select a, b, sum(c), sum(sum(c)) over (order by a,b) as rsum\n+--   from gstest2 group by cube (a,b) order by rsum, a, b;\n+-- select a, b, sum(c) from (values (1,1,10),(1,1,11),(1,2,12),(1,2,13),(1,3,14),(2,3,15),(3,3,16),(3,4,17),(4,1,18),(4,1,19)) v(a,b,c) group by rollup (a,b);\n+-- select a, b, sum(v.x)\n+--   from (values (1),(2)) v(x), gstest_data(v.x)\n+--  group by cube (a,b) order by a,b;\n+\n+-- Test reordering of grouping sets\n+-- explain (costs off)\n+-- select * from gstest1 group by grouping sets((a,b,v),(v)) order by v,b,a;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- Agg level check. This query should error out.\n+-- select (select grouping(a), grouping(b) from gstest2) from gstest2 group by a,b;\n+\n+--Nested queries\n+-- [SPARK-29700] Support nested grouping sets\n+-- select a, b, sum(c), count(*) from gstest2 group by grouping sets (rollup(a,b),a);\n+\n+-- HAVING queries\n+select ten, sum(distinct four) from onek a\n+group by grouping sets((ten,four),(ten))\n+having exists (select 1 from onek b where sum(distinct a.four) = b.four);\n+\n+-- Tests around pushdown of HAVING clauses, partially testing against previous bugs\n+select a,count(*) from gstest2 group by rollup(a) order by a;\n+select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+-- explain (costs off)\n+--   select a,count(*) from gstest2 group by rollup(a) having a is distinct from 1 order by a;\n+\n+-- [SPARK-29706] Support an empty grouping expression\n+-- select v.c, (select count(*) from gstest2 group by () having v.c)\n+--   from (values (false),(true)) v(c) order by v.c;\n+-- explain (costs off)\n+--   select v.c, (select count(*) from gstest2 group by () having v.c)\n+--     from (values (false),(true)) v(c) order by v.c;\n+\n+-- HAVING with GROUPING queries\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten) having grouping(ten) >= 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by grouping sets(ten, four) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by rollup(ten) having grouping(ten) > 0\n+order by 2,1;\n+select ten, grouping(ten) from onek\n+group by cube(ten) having grouping(ten) > 0\n+order by 2,1;\n+-- [SPARK-29703] grouping() can only be used with GroupingSets/Cube/Rollup\n+-- select ten, grouping(ten) from onek\n+-- group by (ten) having grouping(ten) >= 0\n+-- order by 2,1;\n+\n+-- FILTER queries\n+-- [SPARK-27986] Support Aggregate Expressions with filter\n+-- select ten, sum(distinct four) filter (where string(four) ~ '123') from onek a\n+-- group by rollup(ten);\n+\n+-- More rescan tests\n+-- [SPARK-27877] ANSI SQL: LATERAL derived table(T491)\n+-- select * from (values (1),(2)) v(a) left join lateral (select v.a, four, ten, count(*) from onek group by cube(four,ten)) s on true order by v.a,four,ten;\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array(select row(v.a,s1.*) from (select two,four, count(*) from onek group by cube(two,four) order by two,four) s1) from (values (1),(2)) v(a);\n+\n+-- [SPARK-29704] Support the combinations of grouping operations\n+-- Grouping on text columns\n+-- select sum(ten) from onek group by two, rollup(string(four)) order by 1;\n+-- select sum(ten) from onek group by rollup(string(four)), two order by 1;\n+\n+-- hashing support\n+\n+-- Ignore a PostgreSQL-specific option\n+-- set enable_hashagg = true;\n+\n+-- failure cases\n+\n+-- Since this test is implementation specific for plans, it passes in Spark\n+select count(*) from gstest4 group by rollup(unhashable_col,unsortable_col);\n+-- [SPARK-27878] Support ARRAY(sub-SELECT) expressions\n+-- select array_agg(v order by v) from gstest4 group by grouping sets ((id,unsortable_col),(id));\n+\n+-- simple cases\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by grouping sets ((a),(b)) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by grouping sets ((a),(b)) order by 3,1,2;\n+\n+-- [SPARK-29698] Support grouping function with multiple arguments\n+-- select a, b, grouping(a,b), sum(v), count(*), max(v)\n+select a, b, grouping(a), grouping(b), sum(v), count(*), max(v)\n+  from gstest1 group by cube(a,b) order by 3,4,1,2 /* 3,1,2 */;\n+-- explain (costs off) select a, b, grouping(a,b), sum(v), count(*), max(v)\n+--   from gstest1 group by cube(a,b) order by 3,1,2;\n+\n+-- shouldn't try and hash\n+-- explain (costs off)\n+--   select a, b, grouping(a,b), array_agg(v order by v)\n+--     from gstest1 group by cube(a,b);\n+\n+-- unsortable cases\n+-- [SPARK-29708] Different answers in aggregates of multiple grouping sets\n+select unsortable_col, count(*)\n+  from gstest4 group by grouping sets ((unsortable_col),(unsortable_col))\n+  order by string(unsortable_col);\n+\n+-- mixed hashable/sortable cases\n+select unhashable_col, unsortable_col,\n+       -- [SPARK-29698] Support grouping function with multiple arguments\n+       -- grouping(unhashable_col, unsortable_col),\n+       grouping(unhashable_col), grouping(unsortable_col),\n+       count(*), sum(v)\n+  from gstest4 group by grouping sets ((unhashable_col),(unsortable_col))\n+ order by 3, 4, 6 /* 3, 5 */;\n+-- explain (costs off)\n+--   select unhashable_col, unsortable_col,\n+--          grouping(unhashable_col, unsortable_col),\n+--          count(*), sum(v)\n+--     from gstest4 group by grouping sets ((unhashable_col),(unsortable_col))\n+--    order by 3,5;\n+\n+select unhashable_col, unsortable_col,\n+       -- [SPARK-29698] Support grouping function with multiple arguments"
  }],
  "prId": 26352
}]