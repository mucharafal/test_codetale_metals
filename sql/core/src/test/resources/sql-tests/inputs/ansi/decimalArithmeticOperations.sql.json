[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "can we add a little more description? when will we throw an exception?",
    "commit": "ab0730be8b017be319c6cbc7828dfdea39625617",
    "createdAt": "2019-11-13T11:26:24Z",
    "diffHunk": "@@ -0,0 +1,2 @@\n+-- throw an exception instead of returning NULL, according to SQL ANSI 2011"
  }],
  "prId": 26497
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This seems to fail still.\r\n```\r\n[info] - ansi/decimalArithmeticOperations.sql *** FAILED *** (2 seconds, 158 milliseconds)\r\n```",
    "commit": "ab0730be8b017be319c6cbc7828dfdea39625617",
    "createdAt": "2019-11-13T17:55:10Z",
    "diffHunk": "@@ -0,0 +1,4 @@\n+-- SPARK-23179: SQL ANSI 2011 states that in case of overflow during arithmetic operations,\n+-- an exception should be thrown instead of returning NULL.\n+-- This is what most of the SQL DBs do (eg. SQLServer, DB2).\n+--import decimalArithmeticOperations.sql"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Yea, thanks for your catch-up! I've fixed now.",
    "commit": "ab0730be8b017be319c6cbc7828dfdea39625617",
    "createdAt": "2019-11-14T01:25:20Z",
    "diffHunk": "@@ -0,0 +1,4 @@\n+-- SPARK-23179: SQL ANSI 2011 states that in case of overflow during arithmetic operations,\n+-- an exception should be thrown instead of returning NULL.\n+-- This is what most of the SQL DBs do (eg. SQLServer, DB2).\n+--import decimalArithmeticOperations.sql"
  }],
  "prId": 26497
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Since `inputs/decimalArithmeticOperations.sql` has some nondeterministic output with ansi=true, I inlined the ANSI-related queries in it.",
    "commit": "ab0730be8b017be319c6cbc7828dfdea39625617",
    "createdAt": "2019-11-14T01:28:03Z",
    "diffHunk": "@@ -0,0 +1,32 @@\n+-- SPARK-23179: SQL ANSI 2011 states that in case of overflow during arithmetic operations,\n+-- an exception should be thrown instead of returning NULL.\n+-- This is what most of the SQL DBs do (eg. SQLServer, DB2).\n+",
    "line": 4
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "this is surprising. what causes the nondeterminice?",
    "commit": "ab0730be8b017be319c6cbc7828dfdea39625617",
    "createdAt": "2019-11-14T03:26:05Z",
    "diffHunk": "@@ -0,0 +1,32 @@\n+-- SPARK-23179: SQL ANSI 2011 states that in case of overflow during arithmetic operations,\n+-- an exception should be thrown instead of returning NULL.\n+-- This is what most of the SQL DBs do (eg. SQLServer, DB2).\n+",
    "line": 4
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "For example, the queries below in `inputs/decimalArithmeticOperations.sql` throws multiple exceptions with a different error message in executors with ansi=true;\r\n```\r\nsql(\"SET spark.sql.decimalOperations.allowPrecisionLoss=false\")\r\nsql(\"SET spark.sql.ansi.enabled=true\")\r\nsql(\"create table decimals_test(id int, a decimal(38,18), b decimal(38,18)) using parquet\")\r\nsql(\"insert into decimals_test values(1, 100.0, 999.0), (2, 12345.123, 12345.123), (3, 0.1234567891011, 1234.1), (4, 123456789123456789.0, 1.123456789123456789)\")\r\nsql(\"select id, a+b, a-b, a*b, a/b from decimals_test order by id\").show()\r\n\r\njava.lang.ArithmeticException: Decimal(expanded,138698367904130467.51562262075019052100,38,20}) cannot be represented as Decimal(38, 36).\r\n\tat org.apache.spark.sql.types.Decimal.toPrecision(Decimal.scala:357)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n...\r\njava.lang.ArithmeticException: Decimal(expanded,99900.000000000000000000000000000000000,38,33}) cannot be represented as Decimal(38, 36).\r\n\tat org.apache.spark.sql.types.Decimal.toPrecision(Decimal.scala:357)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n...\r\njava.lang.ArithmeticException: Decimal(expanded,152.35802342966751000000000000000000000,38,35}) cannot be represented as Decimal(38, 36).\r\n\tat org.apache.spark.sql.types.Decimal.toPrecision(Decimal.scala:357)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n...\r\n<more exceptions below>\r\n```\r\nSo, the output string printed in `decimalArithmeticOperations.sql.out` depends on timing.",
    "commit": "ab0730be8b017be319c6cbc7828dfdea39625617",
    "createdAt": "2019-11-14T05:34:05Z",
    "diffHunk": "@@ -0,0 +1,32 @@\n+-- SPARK-23179: SQL ANSI 2011 states that in case of overflow during arithmetic operations,\n+-- an exception should be thrown instead of returning NULL.\n+-- This is what most of the SQL DBs do (eg. SQLServer, DB2).\n+",
    "line": 4
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "ah this is nasty, but no better ideas.",
    "commit": "ab0730be8b017be319c6cbc7828dfdea39625617",
    "createdAt": "2019-11-14T06:23:33Z",
    "diffHunk": "@@ -0,0 +1,32 @@\n+-- SPARK-23179: SQL ANSI 2011 states that in case of overflow during arithmetic operations,\n+-- an exception should be thrown instead of returning NULL.\n+-- This is what most of the SQL DBs do (eg. SQLServer, DB2).\n+",
    "line": 4
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Yea, I have no idea, too.",
    "commit": "ab0730be8b017be319c6cbc7828dfdea39625617",
    "createdAt": "2019-11-14T07:11:04Z",
    "diffHunk": "@@ -0,0 +1,32 @@\n+-- SPARK-23179: SQL ANSI 2011 states that in case of overflow during arithmetic operations,\n+-- an exception should be thrown instead of returning NULL.\n+-- This is what most of the SQL DBs do (eg. SQLServer, DB2).\n+",
    "line": 4
  }],
  "prId": 26497
}]