[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Please keep the following original query as a **comment**. And file a JIRA.\r\n```\r\nSELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\r\n```",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-06-16T03:46:03Z",
    "diffHunk": "@@ -0,0 +1,918 @@\n+--\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA1/src/test/regress/sql/window.sql\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- I get an error when trying `order by rank() over w`, however it works for `order by r' if column rank is renamed to r"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Done.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-06-16T14:09:25Z",
    "diffHunk": "@@ -0,0 +1,918 @@\n+--\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA1/src/test/regress/sql/window.sql\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- I get an error when trying `order by rank() over w`, however it works for `order by r' if column rank is renamed to r"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Please file an Apache Spark JIRA issue if it doesn't exist.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-06-16T03:46:52Z",
    "diffHunk": "@@ -0,0 +1,918 @@\n+--\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA1/src/test/regress/sql/window.sql\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- I get an error when trying `order by rank() over w`, however it works for `order by r' if column rank is renamed to r\n+SELECT depname, empno, salary, rank() OVER w as r FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY r;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- Spark does not accept null as input for `ntile`"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Done.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-06-16T14:09:20Z",
    "diffHunk": "@@ -0,0 +1,918 @@\n+--\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA1/src/test/regress/sql/window.sql\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- I get an error when trying `order by rank() over w`, however it works for `order by r' if column rank is renamed to r\n+SELECT depname, empno, salary, rank() OVER w as r FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY r;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- Spark does not accept null as input for `ntile`"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "Add `SPARK-27880` here.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-06-16T12:58:19Z",
    "diffHunk": "@@ -0,0 +1,918 @@\n+--\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA1/src/test/regress/sql/window.sql\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- I get an error when trying `order by rank() over w`, however it works for `order by r' if column rank is renamed to r\n+SELECT depname, empno, salary, rank() OVER w as r FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY r;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- Spark does not accept null as input for `ntile`\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+-- Spark fills with NULL instead of white space\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- `lag` second argument must be a literal?\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first_value(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last_value returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last_value(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last_value(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- nth_value does not exist?\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+-- Original PSQL query:\n+-- SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+--   sum(hundred) OVER (PARTITION BY four ORDER BY ten))::varchar AS cntsum\n+--   FROM tenk1 WHERE unique2 < 10;\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan/broken\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+  SELECT *,\n+    CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(YEAR FROM enroll_date) END * 500 AS bonus,\n+    CASE WHEN\n+      AVG(salary) OVER (PARTITION BY depname) < salary\n+      THEN 200 END AS depadj FROM empsalary\n+    )s;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+-- window function over ungrouped agg over empty row set\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- no costs_off?\n+-- explain (costs off)\n+-- select first_value(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last_value(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last_value(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last_value(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last_value(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last_value(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- broken\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+-- SELECT first_value(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- SELECT first_value(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT first_value(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT last_value(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT last_value(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT last_value(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (rows between 1 following and 3 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- -- broken\n+-- -- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- -- unique1, four\n+-- -- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+-- --\n+-- -- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- -- unique1, four\n+-- -- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+--\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+--\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+--\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- broken\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+\n+-- we don't have a generate_series?\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following) as sum_rows\n+-- FROM generate_series(1, 10) i;\n+--\n+-- SELECT * FROM v_window;\n+--\n+-- SELECT pg_get_viewdef('v_window');\n+--\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM generate_series(1, 10) i;\n+--\n+-- SELECT * FROM v_window;\n+--\n+-- SELECT pg_get_viewdef('v_window');\n+--\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM generate_series(1, 10) i;\n+--\n+-- SELECT * FROM v_window;\n+--\n+-- SELECT pg_get_viewdef('v_window');\n+--\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+--\n+-- SELECT * FROM v_window;\n+--\n+-- SELECT pg_get_viewdef('v_window');\n+--\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+--\n+-- SELECT * FROM v_window;\n+--\n+-- SELECT pg_get_viewdef('v_window');\n+--\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i groups between 1 preceding and 1 following) as sum_rows FROM generate_series(1, 10) i;\n+--\n+-- SELECT * FROM v_window;\n+--\n+-- SELECT pg_get_viewdef('v_window');\n+--\n+-- DROP VIEW v_window;\n+--\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM generate_series(now(), now()+'100 days'::interval, '1 hour') i;\n+--\n+-- SELECT pg_get_viewdef('v_window');\n+--\n+-- -- RANGE offset PRECEDING/FOLLOWING tests\n+--\n+-- SELECT sum(unique1) over (order by four range between 2::int8 preceding and 1::int2 preceding),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four desc range between 2::int8 preceding and 1::int2 preceding),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four range between 2::int8 preceding and 1::int2 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four range between 2::int8 preceding and 1::int2 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four range between 2::int8 preceding and 1::int2 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four range between 2::int8 preceding and 1::int2 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four range between 2::int8 preceding and 6::int2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four range between 2::int8 preceding and 6::int2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5::int8 preceding and 6::int2 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5::int8 preceding and 6::int2 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- select sum(salary) over (order by enroll_date range between '1 year'::interval preceding and '1 year'::interval following),\n+-- salary, enroll_date from empsalary;\n+--\n+-- select sum(salary) over (order by enroll_date desc range between '1 year'::interval preceding and '1 year'::interval following),\n+-- salary, enroll_date from empsalary;\n+--\n+-- select sum(salary) over (order by enroll_date desc range between '1 year'::interval following and '1 year'::interval following),\n+-- salary, enroll_date from empsalary;\n+--\n+-- select sum(salary) over (order by enroll_date range between '1 year'::interval preceding and '1 year'::interval following\n+--   exclude current row), salary, enroll_date from empsalary;\n+--\n+-- select sum(salary) over (order by enroll_date range between '1 year'::interval preceding and '1 year'::interval following\n+--   exclude group), salary, enroll_date from empsalary;\n+--\n+-- select sum(salary) over (order by enroll_date range between '1 year'::interval preceding and '1 year'::interval following\n+--   exclude ties), salary, enroll_date from empsalary;\n+--\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+--\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+--\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+--\n+-- select last_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+--\n+-- select first_value(salary) over(order by enroll_date range between unbounded preceding and '1 year'::interval following\n+--   exclude ties),\n+-- last_value(salary) over(order by enroll_date range between unbounded preceding and '1 year'::interval following),\n+-- salary, enroll_date from empsalary;\n+--\n+-- select first_value(salary) over(order by enroll_date range between unbounded preceding and '1 year'::interval following\n+--   exclude ties),\n+-- last_value(salary) over(order by enroll_date range between unbounded preceding and '1 year'::interval following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+--\n+-- select first_value(salary) over(order by enroll_date range between unbounded preceding and '1 year'::interval following\n+--   exclude group),\n+-- last_value(salary) over(order by enroll_date range between unbounded preceding and '1 year'::interval following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+--\n+-- select first_value(salary) over(order by enroll_date range between unbounded preceding and '1 year'::interval following\n+--   exclude current row),\n+-- last_value(salary) over(order by enroll_date range between unbounded preceding and '1 year'::interval following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+--\n+-- -- RANGE offset PRECEDING/FOLLOWING with null values\n+-- select x, y,\n+--        first_value(y) over w,\n+--        last_value(y) over w\n+-- from\n+--   (select x, x as y from generate_series(1,5) as x\n+--    union all select null, 42\n+--    union all select null, 43) ss\n+-- window w as\n+--   (order by x asc nulls first range between 2 preceding and 2 following);\n+--\n+-- select x, y,\n+--        first_value(y) over w,\n+--        last_value(y) over w\n+-- from\n+--   (select x, x as y from generate_series(1,5) as x\n+--    union all select null, 42\n+--    union all select null, 43) ss\n+-- window w as\n+--   (order by x asc nulls last range between 2 preceding and 2 following);\n+--\n+-- select x, y,\n+--        first_value(y) over w,\n+--        last_value(y) over w\n+-- from\n+--   (select x, x as y from generate_series(1,5) as x\n+--    union all select null, 42\n+--    union all select null, 43) ss\n+-- window w as\n+--   (order by x desc nulls first range between 2 preceding and 2 following);\n+--\n+-- select x, y,\n+--        first_value(y) over w,\n+--        last_value(y) over w\n+-- from\n+--   (select x, x as y from generate_series(1,5) as x\n+--    union all select null, 42\n+--    union all select null, 43) ss\n+-- window w as\n+--   (order by x desc nulls last range between 2 preceding and 2 following);\n+--\n+-- -- Check overflow behavior for various integer sizes\n+--\n+-- select x, last_value(x) over (order by x::smallint range between current row and 2147450884 following)\n+-- from generate_series(32764, 32766) x;\n+--\n+-- select x, last_value(x) over (order by x::smallint desc range between current row and 2147450885 following)\n+-- from generate_series(-32766, -32764) x;\n+--\n+-- select x, last_value(x) over (order by x range between current row and 4 following)\n+-- from generate_series(2147483644, 2147483646) x;\n+--\n+-- select x, last_value(x) over (order by x desc range between current row and 5 following)\n+-- from generate_series(-2147483646, -2147483644) x;\n+--\n+-- select x, last_value(x) over (order by x range between current row and 4 following)\n+-- from generate_series(9223372036854775804, 9223372036854775806) x;\n+--\n+-- select x, last_value(x) over (order by x desc range between current row and 5 following)\n+-- from generate_series(-9223372036854775806, -9223372036854775804) x;\n+--\n+\n+-- GROUPS tests\n+-- no `groups`?\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four groups between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four groups between 1 preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four groups between 1 following and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and 2 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 preceding),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four groups between 0 preceding and 0 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following),unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+--\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+--\n+-- select last_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lag(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+--\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+--\n+-- select last_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date groups between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+-- WITH cte (x) AS (\n+--         SELECT * FROM generate_series(1, 35, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+--\n+-- WITH cte (x) AS (\n+--         SELECT * FROM generate_series(1, 35, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- WITH cte (x) AS (\n+--         SELECT * FROM generate_series(1, 35, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+-- WITH cte (x) AS (\n+--         select 1 union all select 1 union all select 1 union all\n+--         SELECT * FROM generate_series(5, 49, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+-- WITH cte (x) AS (\n+--         select 1 union all select 1 union all select 1 union all\n+--         SELECT * FROM generate_series(5, 49, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- WITH cte (x) AS (\n+--         select 1 union all select 1 union all select 1 union all\n+--         SELECT * FROM generate_series(5, 49, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+-- with UNION/we didn't have tenk2 yet\n+-- SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+-- broken - costs and range are not available?\n+-- select f1, sum(f1) over (partition by f1\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;  -- error, must have order by\n+-- explain (costs off)\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+                         -- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1, f1 order by f2\n+--                          range between 2 preceding and 1 preceding)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1, f2 order by f2\n+--                          range between 1 following and 2 following)\n+-- from t1 where f1 = f2;\n+\n+-- select f1, sum(f1) over (partition by f1\n+--                          groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;  -- error, must have order by\n+-- explain (costs off)\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1, f1 order by f2\n+--                          groups between 2 preceding and 1 preceding)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1, f2 order by f2\n+--                          groups between 1 following and 2 following)\n+-- from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- random does not exist\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+-- broken\n+-- SELECT * FROM empsalary WHERE row_number() OVER (ORDER BY salary) < 10;\n+\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- broken\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- broken\n+-- SELECT * FROM rank() OVER (ORDER BY random());\n+\n+SELECT count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1);\n+\n+-- broken\n+-- SELECT rank() OVER (PARTITION BY four, ORDER BY ten) FROM tenk1;\n+\n+SELECT count() OVER () FROM tenk1;\n+\n+-- SELECT generate_series(1, 100) OVER () FROM empsalary;\n+\n+-- the error is weird\n+-- SELECT ntile(0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- SELECT nth_value(four, 0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- filter\n+-- FILTER does not work on spark?\n+-- SELECT sum(salary), row_number() OVER (ORDER BY depname), sum(\n+--     sum(salary) FILTER (WHERE enroll_date > '2007-01-01')\n+-- ) FILTER (WHERE depname <> 'sales') OVER (ORDER BY depname DESC) AS \"filtered_sum\",\n+--     depname\n+-- FROM empsalary GROUP BY depname;\n+\n+-- Test pushdown of quals into a subquery containing window functions\n+\n+-- costs off didn't work?\n+-- pushdown is safe because all PARTITION BY clauses include depname:\n+-- EXPLAIN (COSTS OFF)\n+-- SELECT * FROM\n+--   (SELECT depname,\n+--           sum(salary) OVER (PARTITION BY depname) depsalary,\n+--           min(salary) OVER (PARTITION BY depname || 'A', depname) depminsalary\n+--    FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- pushdown is unsafe because there's a PARTITION BY clause without depname:\n+-- EXPLAIN (COSTS OFF)\n+-- SELECT * FROM\n+--   (SELECT depname,\n+--           sum(salary) OVER (PARTITION BY enroll_date) enroll_salary,\n+--           min(salary) OVER (PARTITION BY depname) depminsalary\n+--    FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node collapsing\n+-- EXPLAIN (COSTS OFF)\n+-- SELECT * FROM\n+--   (SELECT depname,\n+--           sum(salary) OVER (PARTITION BY depname order by empno) depsalary,\n+--           min(salary) OVER (PARTITION BY depname, empno order by enroll_date) depminsalary\n+--    FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+--\n+-- -- Test Sort node reordering\n+-- EXPLAIN (COSTS OFF)\n+-- SELECT\n+--   lead(1) OVER (PARTITION BY depname ORDER BY salary, enroll_date),\n+--   lag(1) OVER (PARTITION BY depname ORDER BY salary,enroll_date,empno)\n+-- FROM empsalary;\n+\n+-- test that returning NULL from the inverse transition functions\n+-- restarts the aggregation from scratch. The second aggregate is supposed\n+-- to test cases where only some aggregates restart, the third one checks\n+-- that one aggregate restarting doesn't cause others to restart.\n+\n+\n+-- WITH\n+-- vs AS (\n+--   SELECT i, (random() * 100)::int4 AS v\n+--   FROM generate_series(1, 100) AS i\n+-- ),\n+-- sum_following AS (\n+--   SELECT i, SUM(v) OVER\n+--   (ORDER BY i DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS s\n+--   FROM vs\n+-- )\n+-- SELECT DISTINCT\n+-- sum_following.s = sum_int_randomrestart(v) OVER fwd AS eq1,\n+-- -sum_following.s = sum_int_randomrestart(-v) OVER fwd AS eq2,\n+-- 100*3+(vs.i-1)*3 = length(logging_agg_nonstrict(''::text) OVER fwd) AS eq3\n+-- FROM vs\n+-- JOIN sum_following ON sum_following.i = vs.i\n+-- WINDOW fwd AS (\n+--   ORDER BY vs.i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n+-- );\n+\n+\n+-- Test various built-in aggregates that have moving-aggregate support\n+\n+-- test inverse transition functions handle NULLs properly\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.5),(2,2.5),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,'1 sec'),(2,'2 sec'),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,'1.10'),(2,'2.20'),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,'1 sec'),(2,'2 sec'),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.1),(2,2.2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT SUM(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.01),(2,2),(3,3)) v(i,n);\n+\n+SELECT i,COUNT(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,COUNT(*) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+-- test that inverse transition functions work with various frame options\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND CURRENT ROW)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND 1 FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,3),(4,4)) t(i,v);\n+\n+-- bool_and?"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "JIRA issue?",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-25T19:39:05Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "JIRA issue?",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-25T19:39:16Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "This one works on my computer under SparkSQL, though. By the way, a JIRA with which title? `year` is clearly supported in SparkSQL",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-25T19:56:19Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Then, please uncomment this.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-25T20:37:38Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Just to be clear: if I open a SparkSQL session and wrote down that query, it works fine. However, if I leave it at the `window.sql` file, it fails. What do you think?",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-29T11:55:29Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Oh. Then, could you try with SparkSQL and do the following before the query?\r\n```\r\nSET spark.sql.parser.ansi.enabled=true\r\n```",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-29T17:54:09Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Nice, I'll try this then.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-29T17:57:23Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This test suite is always tested with that option.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-29T18:01:49Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "@dongjoon-hyun Nice, now with this config it also do not pass in my host spark-sql shell. However,  [have look at this comment](https://github.com/apache/spark/pull/25114#issuecomment-512229758). Looks like the problem is such keywords being reserved. Should I JIRA them?",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-29T18:27:02Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Yea, PostgreSQL has weird behaivours for some reserved keywords, but I think we don't need to follow that behaivours for better parsing error messages. So, can you temporarily trun off the ANSI mode in those quries like this?\r\n```\r\n-- Temporarily turns off the ANSI mode because ...\r\nSET spark.sql.parser.ansi.enabled=false\r\n\r\nsome queries using reserved keywords\r\n\r\nSET spark.sql.parser.ansi.enabled=true\r\n```",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-30T00:06:07Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thank you for your advice, @maropu !",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-30T00:29:08Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "@maropu awesome, it worked great. Thank you!",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-30T12:03:19Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "nice",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-30T12:08:52Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+SELECT sum(salary),\n+row_number() OVER (ORDER BY depname),\n+sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- Correlated scalar subqueries must be aggregated: Filter (outer(unique2#x) = unique2#x)\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- no viable alternative at input 'year'"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Could you keep the original PostgreSQL comment like the following, too?\r\n```\r\n-- with GROUP BY\r\n```\r\n\r\nActually, those comments are markers. There are more missing comments in this file.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-25T19:42:24Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1",
    "line": 32
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Yes, I can add them. But I just checked and looks like the PgSQL file is way different from the time that I started to port it. What should I do? Migrate to the new version of the file or ignore the new additions and follow through the old one?",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-25T20:13:50Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1",
    "line": 32
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "As you wrote in the PR description, we are porting `REL_12_BETA2` tag instead of `branch`. Tag is not changed.\r\n- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-25T20:38:53Z",
    "diffHunk": "@@ -0,0 +1,903 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1",
    "line": 32
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This is resolved in the master. Please remove this comment and enable line 936.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-29T17:51:41Z",
    "diffHunk": "@@ -0,0 +1,1167 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28553] subqueries must be aggregated before hand\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- no viable alternative at input 'year'\n+-- SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+-- SELECT *,\n+--   CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+--   CASE WHEN\n+--     AVG(salary) OVER (PARTITION BY depname) < salary\n+--     THEN 200 END AS depadj FROM empsalary\n+--   )s;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28086] Adds `random()` to Spark"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Great, it works now.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-29T18:27:28Z",
    "diffHunk": "@@ -0,0 +1,1167 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28553] subqueries must be aggregated before hand\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- no viable alternative at input 'year'\n+-- SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+-- SELECT *,\n+--   CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+--   CASE WHEN\n+--     AVG(salary) OVER (PARTITION BY depname) < salary\n+--     THEN 200 END AS depadj FROM empsalary\n+--   )s;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28086] Adds `random()` to Spark"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Ur, please file another JIRA issue since the behavior is different.\r\n```\r\npostgres=# SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\r\nERROR:  window functions are not allowed in window definitions\r\nLINE 1: SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random())...\r\n```\r\n\r\n```\r\nspark-sql> SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\r\n1\r\n```",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-30T15:37:36Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Remove line 950 and uncomment 951 since SPARK-28086 is merged.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-30T15:38:13Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- [SPARK-28086] Adds `random()` to Spark\n+-- SELECT * FROM rank() OVER (ORDER BY random());"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Oh. Please file another JIRA and keep this as the commented status. \r\n```\r\nspark-sql> SELECT * FROM rank() OVER (ORDER BY random());\r\nError in query:\r\nmismatched input 'BY' expecting {')', ',', '-'}(line 1, pos 33)\r\n\r\n== SQL ==\r\nSELECT * FROM rank() OVER (ORDER BY random())\r\n---------------------------------^^^\r\n```",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-30T15:51:20Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- [SPARK-28086] Adds `random()` to Spark\n+-- SELECT * FROM rank() OVER (ORDER BY random());"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Hmm, I just checked out and it also does not work for PgSQL:\r\n```sql\r\nSELECT * FROM rank() OVER (ORDER BY random());\r\nERROR:  syntax error at or near \"ORDER\"\r\nLINE 1: SELECT * FROM rank() OVER (ORDER BY random());\r\n```\r\nAlthough the error message is different, an error being thrown looks like the correct behaviour. What do you think? Should I JIRA about the error message being different or should I JIRA a fix to the error itself? \r\n\r\nEdit: By the way, the error is actually below the tag \"some other errors\", so it was expected in pgSQL I think.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-30T18:03:40Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- [SPARK-28086] Adds `random()` to Spark\n+-- SELECT * FROM rank() OVER (ORDER BY random());"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Oh. I see. Then, there is no need to file a JIRA. Just uncomment this since we need to verify this failure behavior.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-30T20:09:09Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- [SPARK-28086] Adds `random()` to Spark\n+-- SELECT * FROM rank() OVER (ORDER BY random());"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Sure. By the way, the CI will not pass then, I think. There's a way to disable the error checking for this specific query?",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-30T20:27:26Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- [SPARK-28086] Adds `random()` to Spark\n+-- SELECT * FROM rank() OVER (ORDER BY random());"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Ah, got it. It's due to `random()` seed issue. Then, please add a comment for that `random seed` issue.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-30T20:31:12Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- [SPARK-28086] Adds `random()` to Spark\n+-- SELECT * FROM rank() OVER (ORDER BY random());"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Done.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-31T13:31:55Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- [SPARK-28086] Adds `random()` to Spark\n+-- SELECT * FROM rank() OVER (ORDER BY random());"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "I think we can comment out this, too.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-31T00:25:30Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Done! Good catch.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-31T12:22:16Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "ditto",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-31T00:25:36Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "ditto",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-31T00:25:43Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Why did you comment out the three statements below?",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-31T01:28:21Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- SELECT * FROM rank() OVER (ORDER BY random());\n+\n+-- Output not being truncated\n+-- SELECT count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1);"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Because the output was not being truncated. For instance: if the result was 1000 rows, then 1000 rows should show up.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-31T12:12:39Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- SELECT * FROM rank() OVER (ORDER BY random());\n+\n+-- Output not being truncated\n+-- SELECT count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1);"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "How about this?\r\n```\r\n-- The original query outputs too many rows, so just count the output number \r\n-- SELECT count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1);\r\nSELECT COUNT(*) FROM (SELECT count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1));\r\n```",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-08-01T01:49:41Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- SELECT * FROM rank() OVER (ORDER BY random());\n+\n+-- Output not being truncated\n+-- SELECT count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1);"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Nice solution. I'll use it.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-08-01T13:59:53Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- SELECT * FROM rank() OVER (ORDER BY random());\n+\n+-- Output not being truncated\n+-- SELECT count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1);"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "some other errors in this query?\r\nhttps://github.com/apache/spark/pull/24881/files#diff-b0daa9878b95f249e63172b55e77b6d9R1978",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-31T01:34:19Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "I did it all wrongly: I didn't paid attention to the fact that these queries are under the \"some other errors\" comment (i.e: the expected behavior was actually an error being thrown), so instead of placing the original PgSQL query I fixed the original query such that it works now. I reverted it to the original query and now the error is showing up. Thank you!",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-07-31T13:33:42Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;"
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "yea, plz keep the original queries where possible.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-08-01T00:54:24Z",
    "diffHunk": "@@ -0,0 +1,1169 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+select * from\n+(select row_number() over (order by salary) rn from empsalary) ss\n+where rn < 10;"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "FYI: this fix is wip in https://github.com/apache/spark/pull/25331",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-08-07T01:07:59Z",
    "diffHunk": "@@ -0,0 +1,1175 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+SELECT * FROM empsalary WHERE row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- Since random() result may change due to seed issues, the behavior is actually unstable\n+SELECT * FROM rank() OVER (ORDER BY random());\n+\n+SELECT * FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+\n+SELECT * FROM empsalary WHERE rank() OVER (ORDER BY random());\n+\n+-- The original query currently outputs too many rows, so just count the output number\n+SELECT count(*) FROM (select count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1));\n+\n+-- The original query currently outputs too many rows, so just count the output number\n+SELECT count(*) FROM (select rank() OVER (PARTITION BY four ORDER BY ten) FROM tenk1);\n+\n+-- The original query currently outputs too many rows, so just count the output number\n+SELECT count(*) FROM (select count() OVER () FROM tenk1);\n+\n+-- [SPARK-28065] ntile only accepting positive (>0) values\n+SELECT ntile(0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(four, 0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- filter\n+\n+-- [SPARK-28500] Adds support for `filter` clause\n+-- SELECT sum(salary), row_number() OVER (ORDER BY depname), sum(\n+--     sum(salary) FILTER (WHERE enroll_date > '2007-01-01')\n+-- )\n+-- FROM empsalary GROUP BY depname;\n+\n+-- Test pushdown of quals into a subquery containing window functions\n+\n+-- pushdown is safe because all PARTITION BY clauses include depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname) depsalary,\n+-- min(salary) OVER (PARTITION BY depname || 'A', depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- pushdown is unsafe because there's a PARTITION BY clause without depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY enroll_date) enroll_salary,\n+-- min(salary) OVER (PARTITION BY depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node collapsing\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname order by empno) depsalary,\n+-- min(salary) OVER (PARTITION BY depname, empno order by enroll_date) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node reordering\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT\n+-- lead(1) OVER (PARTITION BY depname ORDER BY salary, enroll_date),\n+-- lag(1) OVER (PARTITION BY depname ORDER BY salary,enroll_date,empno)\n+-- FROM empsalary;\n+\n+-- cleanup\n+DROP TABLE empsalary;\n+\n+--\n+-- Test various built-in aggregates that have moving-aggregate support\n+--\n+\n+-- test inverse transition functions handle NULLs properly\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.5),(2,2.5),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- [SPARK-28602] Spark does not recognize 'interval' type as 'numeric'\n+-- SELECT i,AVG(cast(v as interval)) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1 sec'),(2,'2 sec'),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- The cast syntax is present in PgSQL for legacy reasons and Spark will not recognize a money field\n+-- SELECT i,SUM(v::money) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1.10'),(2,'2.20'),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- [SPARK-28602] Spark does not recognize 'interval' type as 'numeric'\n+-- SELECT i,SUM(cast(v as interval)) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1 sec'),(2,'2 sec'),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.1),(2,2.2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT SUM(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.01),(2,2),(3,3)) v(i,n);\n+\n+SELECT i,COUNT(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,COUNT(*) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+-- For the following queries Spark result differs from PgSQL:\n+-- Spark handles division by zero as 'NaN' instead of 'NULL', which is the PgSQL behaviour\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND CURRENT ROW)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND 1 FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,3),(4,4)) t(i,v);\n+\n+-- ensure aggregate over numeric properly recovers from NaN values\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Thanks for this explanation.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-08-07T01:22:02Z",
    "diffHunk": "@@ -0,0 +1,1175 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities\n+\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and current row),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 preceding and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 1 following and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between unbounded preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four range between 0 preceding and 0 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by ten\n+  order by four range between 0 preceding and 0 following),unique1, four, ten\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four range between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- select last(salary) over(order by enroll_date range between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date range between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date range between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date range between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 35, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 49, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1 order by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1,\n+f1 order by f2 range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1 order by f2\n+range between 1 preceding and 1 following)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+ \n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+SELECT * FROM empsalary WHERE row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+-- [SPARK-28506] not handling usage of group function and window function at some conditions\n+-- SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- Since random() result may change due to seed issues, the behavior is actually unstable\n+SELECT * FROM rank() OVER (ORDER BY random());\n+\n+SELECT * FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+\n+SELECT * FROM empsalary WHERE rank() OVER (ORDER BY random());\n+\n+-- The original query currently outputs too many rows, so just count the output number\n+SELECT count(*) FROM (select count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1));\n+\n+-- The original query currently outputs too many rows, so just count the output number\n+SELECT count(*) FROM (select rank() OVER (PARTITION BY four ORDER BY ten) FROM tenk1);\n+\n+-- The original query currently outputs too many rows, so just count the output number\n+SELECT count(*) FROM (select count() OVER () FROM tenk1);\n+\n+-- [SPARK-28065] ntile only accepting positive (>0) values\n+SELECT ntile(0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(four, 0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- filter\n+\n+-- [SPARK-28500] Adds support for `filter` clause\n+-- SELECT sum(salary), row_number() OVER (ORDER BY depname), sum(\n+--     sum(salary) FILTER (WHERE enroll_date > '2007-01-01')\n+-- )\n+-- FROM empsalary GROUP BY depname;\n+\n+-- Test pushdown of quals into a subquery containing window functions\n+\n+-- pushdown is safe because all PARTITION BY clauses include depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname) depsalary,\n+-- min(salary) OVER (PARTITION BY depname || 'A', depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- pushdown is unsafe because there's a PARTITION BY clause without depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY enroll_date) enroll_salary,\n+-- min(salary) OVER (PARTITION BY depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node collapsing\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname order by empno) depsalary,\n+-- min(salary) OVER (PARTITION BY depname, empno order by enroll_date) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node reordering\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT\n+-- lead(1) OVER (PARTITION BY depname ORDER BY salary, enroll_date),\n+-- lag(1) OVER (PARTITION BY depname ORDER BY salary,enroll_date,empno)\n+-- FROM empsalary;\n+\n+-- cleanup\n+DROP TABLE empsalary;\n+\n+--\n+-- Test various built-in aggregates that have moving-aggregate support\n+--\n+\n+-- test inverse transition functions handle NULLs properly\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.5),(2,2.5),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- [SPARK-28602] Spark does not recognize 'interval' type as 'numeric'\n+-- SELECT i,AVG(cast(v as interval)) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1 sec'),(2,'2 sec'),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- The cast syntax is present in PgSQL for legacy reasons and Spark will not recognize a money field\n+-- SELECT i,SUM(v::money) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1.10'),(2,'2.20'),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- [SPARK-28602] Spark does not recognize 'interval' type as 'numeric'\n+-- SELECT i,SUM(cast(v as interval)) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1 sec'),(2,'2 sec'),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.1),(2,2.2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT SUM(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.01),(2,2),(3,3)) v(i,n);\n+\n+SELECT i,COUNT(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,COUNT(*) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+-- For the following queries Spark result differs from PgSQL:\n+-- Spark handles division by zero as 'NaN' instead of 'NULL', which is the PgSQL behaviour",
    "line": 1364
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "I think it would be better to wait until https://github.com/apache/spark/pull/25331 merged. That's because the queries in L556-L604 generate different output from pg ones.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-08-07T02:02:27Z",
    "diffHunk": "@@ -0,0 +1,1175 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Sure - I'll be working on the other things then.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-08-07T20:35:03Z",
    "diffHunk": "@@ -0,0 +1,1175 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+CREATE OR REPLACE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id range between 1 preceding and 1 following) as sum_rows FROM range(1, 10) i;\n+\n+SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select last_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,5) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32766) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32764) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483646) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483644) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775806) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775804) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+-- [SPARK-27768] Infinity, -Infinity, NaN should be recognized in a case insensitive manner\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100);\n+--(8, 'infinity', 'infinity', '1000'),\n+--(9, 'NaN', 'NaN', 'NaN');\n+--(0, '-infinity', '-infinity', '-1000'),  -- numeric type lacks infinities"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Where this test comes from? https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql#L1249",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-08-26T05:41:15Z",
    "diffHunk": "@@ -0,0 +1,1401 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+SELECT sum(unique1) over (w range between current row and unbounded following),\n+\tunique1, four\n+FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 11) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i.id, sum(i.id) over (order by i.id groups between 1 preceding and 1 following) as sum_rows FROM range(1, 11) i;\n+-- SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+select last(salary) over(order by salary range between 1000 preceding and 1000 following),\n+lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32767) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32765) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483647) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483645) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775807) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775805) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100)\n+(8, 'infinity', 'infinity', '1000'),\n+(9, 'NaN', 'NaN', 'NaN');\n+(0, '-infinity', '-infinity', '-1000');  -- numeric type lacks infinities\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 1 preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 1 following and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and 2 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 preceding),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 0 preceding and 0 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following),unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select last(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date groups between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 36, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 36, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- WITH cte (x) AS (\n+--         SELECT * FROM range(1, 36, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 50, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 50, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- WITH cte (x) AS (\n+--         select 1 union all select 1 union all select 1 union all\n+--         SELECT * FROM range(5, 50, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1,\n+-- groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1, f1 order by f2\n+-- groups between 2 preceding and 1 preceding)\n+-- from t1 where f1 = f2;\n+ \n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1, f2 order by f2\n+-- groups between 1 following and 2 following)\n+-- from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+SELECT * FROM empsalary WHERE row_number() OVER (ORDER BY salary) < 10;\n+\n+SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- Since random() result may change due to seed issues, the behavior is actually unstable\n+SELECT * FROM rank() OVER (ORDER BY random());\n+\n+-- Original query: DELETE FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+SELECT * FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+\n+-- Original query: DELETE FROM empsalary RETURNING rank() OVER (ORDER BY random());\n+SELECT * FROM empsalary WHERE rank() OVER (ORDER BY random());\n+\n+-- [SPARK-28645] Throw an error on window redefinition\n+-- select count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1);\n+\n+select rank() OVER (PARTITION BY four, ORDER BY ten) FROM tenk1;\n+\n+-- [SPARK-28646] Allow usage of `count` only for parameterless aggregate function\n+-- select count() OVER () FROM tenk1;\n+\n+-- The output is the expected one: `range` is not a window or aggregate function.\n+SELECT range(1, 100) OVER () FROM empsalary;\n+\n+SELECT ntile(0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(four, 0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- filter\n+\n+-- [SPARK-28500] Adds support for `filter` clause\n+-- SELECT sum(salary), row_number() OVER (ORDER BY depname), sum(\n+--     sum(salary) FILTER (WHERE enroll_date > '2007-01-01')\n+-- )\n+-- FROM empsalary GROUP BY depname;\n+\n+-- Test pushdown of quals into a subquery containing window functions\n+\n+-- pushdown is safe because all PARTITION BY clauses include depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname) depsalary,\n+-- min(salary) OVER (PARTITION BY depname || 'A', depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- pushdown is unsafe because there's a PARTITION BY clause without depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY enroll_date) enroll_salary,\n+-- min(salary) OVER (PARTITION BY depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node collapsing\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname order by empno) depsalary,\n+-- min(salary) OVER (PARTITION BY depname, empno order by enroll_date) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node reordering\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT\n+-- lead(1) OVER (PARTITION BY depname ORDER BY salary, enroll_date),\n+-- lag(1) OVER (PARTITION BY depname ORDER BY salary,enroll_date,empno)\n+-- FROM empsalary;\n+\n+-- cleanup\n+DROP TABLE empsalary;\n+\n+-- test user-defined window function with named args and default args\n+-- CREATE FUNCTION nth_value_def(val anyelement, n integer = 1) RETURNS anyelement\n+--   LANGUAGE internal WINDOW IMMUTABLE STRICT AS 'window_nth_value';\n+\n+-- SELECT nth_value_def(n := 2, val := ten) OVER (PARTITION BY four), ten, four\n+--   FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten) s;\n+\n+-- SELECT nth_value_def(ten) OVER (PARTITION BY four), ten, four\n+--   FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten) s;\n+\n+--\n+-- Test the basic moving-aggregate machinery\n+--\n+\n+-- create aggregates that record the series of transform calls (these are\n+-- intentionally not true inverses)\n+\n+-- CREATE FUNCTION logging_sfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT COALESCE($1, '') || '*' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_msfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT COALESCE($1, '') || '+' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_minvfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '-' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE AGGREGATE logging_agg_nonstrict (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_nonstrict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_nonstrict,\n+-- \tminvfunc = logging_minvfunc_nonstrict\n+-- );\n+\n+-- CREATE AGGREGATE logging_agg_nonstrict_initcond (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_nonstrict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_nonstrict,\n+-- \tminvfunc = logging_minvfunc_nonstrict,\n+-- \tinitcond = 'I',\n+-- \tminitcond = 'MI'\n+-- );\n+\n+-- CREATE FUNCTION logging_sfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '*' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_msfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '+' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_minvfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '-' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE AGGREGATE logging_agg_strict (text)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_strict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_strict,\n+-- \tminvfunc = logging_minvfunc_strict\n+-- );\n+\n+-- CREATE AGGREGATE logging_agg_strict_initcond (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_strict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_strict,\n+-- \tminvfunc = logging_minvfunc_strict,\n+-- \tinitcond = 'I',\n+-- \tminitcond = 'MI'\n+-- );\n+\n+-- test strict and non-strict cases\n+-- SELECT\n+-- \tp::text || ',' || i::text || ':' || COALESCE(v::text, 'NULL') AS row,\n+-- \tlogging_agg_nonstrict(v) over wnd as nstrict,\n+-- \tlogging_agg_nonstrict_initcond(v) over wnd as nstrict_init,\n+-- \tlogging_agg_strict(v::text) over wnd as strict,\n+-- \tlogging_agg_strict_initcond(v) over wnd as strict_init\n+-- FROM (VALUES\n+-- \t(1, 1, NULL),\n+-- \t(1, 2, 'a'),\n+-- \t(1, 3, 'b'),\n+-- \t(1, 4, NULL),\n+-- \t(1, 5, NULL),\n+-- \t(1, 6, 'c'),\n+-- \t(2, 1, NULL),\n+-- \t(2, 2, 'x'),\n+-- \t(3, 1, 'z')\n+-- ) AS t(p, i, v)\n+-- WINDOW wnd AS (PARTITION BY P ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY p, i;\n+\n+-- and again, but with filter\n+-- SELECT\n+-- \tp::text || ',' || i::text || ':' ||\n+-- \t\tCASE WHEN f THEN COALESCE(v::text, 'NULL') ELSE '-' END as row,\n+-- \tlogging_agg_nonstrict(v) filter(where f) over wnd as nstrict_filt,\n+-- \tlogging_agg_nonstrict_initcond(v) filter(where f) over wnd as nstrict_init_filt,\n+-- \tlogging_agg_strict(v::text) filter(where f) over wnd as strict_filt,\n+-- \tlogging_agg_strict_initcond(v) filter(where f) over wnd as strict_init_filt\n+-- FROM (VALUES\n+-- \t(1, 1, true,  NULL),\n+-- \t(1, 2, false, 'a'),\n+-- \t(1, 3, true,  'b'),\n+-- \t(1, 4, false, NULL),\n+-- \t(1, 5, false, NULL),\n+-- \t(1, 6, false, 'c'),\n+-- \t(2, 1, false, NULL),\n+-- \t(2, 2, true,  'x'),\n+-- \t(3, 1, true,  'z')\n+-- ) AS t(p, i, f, v)\n+-- WINDOW wnd AS (PARTITION BY p ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY p, i;\n+\n+-- test that volatile arguments disable moving-aggregate mode\n+-- SELECT\n+-- \ti::text || ':' || COALESCE(v::text, 'NULL') as row,\n+-- \tlogging_agg_strict(v::text)\n+-- \t\tover wnd as inverse,\n+-- \tlogging_agg_strict(v::text || CASE WHEN random() < 0 then '?' ELSE '' END)\n+-- \t\tover wnd as noinverse\n+-- FROM (VALUES\n+-- \t(1, 'a'),\n+-- \t(2, 'b'),\n+-- \t(3, 'c')\n+-- ) AS t(i, v)\n+-- WINDOW wnd AS (ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY i;\n+\n+-- SELECT\n+-- \ti::text || ':' || COALESCE(v::text, 'NULL') as row,\n+-- \tlogging_agg_strict(v::text) filter(where true)\n+-- \t\tover wnd as inverse,\n+-- \tlogging_agg_strict(v::text) filter(where random() >= 0)\n+-- \t\tover wnd as noinverse\n+-- FROM (VALUES\n+-- \t(1, 'a'),\n+-- \t(2, 'b'),\n+-- \t(3, 'c')\n+-- ) AS t(i, v)\n+-- WINDOW wnd AS (ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY i;\n+\n+-- test that non-overlapping windows don't use inverse transitions\n+-- SELECT\n+-- \tlogging_agg_strict(v::text) OVER wnd\n+-- FROM (VALUES\n+-- \t(1, 'a'),\n+-- \t(2, 'b'),\n+-- \t(3, 'c')\n+-- ) AS t(i, v)\n+-- WINDOW wnd AS (ORDER BY i ROWS BETWEEN CURRENT ROW AND CURRENT ROW)\n+-- ORDER BY i;\n+\n+-- test that returning NULL from the inverse transition functions\n+-- restarts the aggregation from scratch. The second aggregate is supposed\n+-- to test cases where only some aggregates restart, the third one checks\n+-- that one aggregate restarting doesn't cause others to restart.\n+\n+-- CREATE FUNCTION sum_int_randrestart_minvfunc(int4, int4) RETURNS int4 AS\n+-- $$ SELECT CASE WHEN random() < 0.2 THEN NULL ELSE $1 - $2 END $$\n+-- LANGUAGE SQL STRICT;\n+\n+-- CREATE AGGREGATE sum_int_randomrestart (int4)\n+-- (\n+-- \tstype = int4,\n+-- \tsfunc = int4pl,\n+-- \tmstype = int4,\n+-- \tmsfunc = int4pl,\n+-- \tminvfunc = sum_int_randrestart_minvfunc\n+-- );\n+\n+-- WITH\n+-- vs AS (\n+-- \tSELECT i, (random() * 100)::int4 AS v\n+-- \tFROM generate_series(1, 100) AS i\n+-- ),\n+-- sum_following AS (\n+-- \tSELECT i, SUM(v) OVER\n+-- \t\t(ORDER BY i DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS s\n+-- \tFROM vs\n+-- )\n+-- SELECT DISTINCT\n+-- \tsum_following.s = sum_int_randomrestart(v) OVER fwd AS eq1,\n+-- \t-sum_following.s = sum_int_randomrestart(-v) OVER fwd AS eq2,\n+-- \t100*3+(vs.i-1)*3 = length(logging_agg_nonstrict(''::text) OVER fwd) AS eq3\n+-- FROM vs\n+-- JOIN sum_following ON sum_following.i = vs.i\n+-- WINDOW fwd AS (\n+-- \tORDER BY vs.i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n+-- );\n+\n+--\n+-- Test various built-in aggregates that have moving-aggregate support\n+--\n+\n+-- test inverse transition functions handle NULLs properly\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.5),(2,2.5),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- [SPARK-28602] Spark does not recognize 'interval' type as 'numeric'\n+-- SELECT i,AVG(cast(v as interval)) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1 sec'),(2,'2 sec'),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- The cast syntax is present in PgSQL for legacy reasons and Spark will not recognize a money field\n+-- SELECT i,SUM(v::money) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1.10'),(2,'2.20'),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- [SPARK-28602] Spark does not recognize 'interval' type as 'numeric'\n+-- SELECT i,SUM(cast(v as interval)) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1 sec'),(2,'2 sec'),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.1),(2,2.2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT SUM(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.01),(2,2),(3,3)) v(i,n);\n+\n+SELECT i,COUNT(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,COUNT(*) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+-- For the following queries Spark result differs from PgSQL:\n+-- Spark handles division by zero as 'NaN' instead of 'NULL', which is the PgSQL behaviour\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+-- test that inverse transition functions work with various frame options\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND CURRENT ROW)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND 1 FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,3),(4,4)) t(i,v);\n+\n+-- ensure aggregate over numeric properly recovers from NaN values\n+SELECT a, b,\n+       SUM(b) OVER(ORDER BY A ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+FROM (VALUES(1,1),(2,2),(3,'NaN'),(4,3),(5,4)) t(a,b);\n+\n+select f_float4, sum(f_float4) over (order by f_float8 rows between 1"
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Lol, I don't know what happened there. Whatever, it is fixed now.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-09-07T14:39:48Z",
    "diffHunk": "@@ -0,0 +1,1401 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+SELECT sum(unique1) over (w range between current row and unbounded following),\n+\tunique1, four\n+FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 11) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i.id, sum(i.id) over (order by i.id groups between 1 preceding and 1 following) as sum_rows FROM range(1, 11) i;\n+-- SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+select last(salary) over(order by salary range between 1000 preceding and 1000 following),\n+lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32767) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32765) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483647) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483645) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775807) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775805) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100)\n+(8, 'infinity', 'infinity', '1000'),\n+(9, 'NaN', 'NaN', 'NaN');\n+(0, '-infinity', '-infinity', '-1000');  -- numeric type lacks infinities\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 1 preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 1 following and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and 2 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 preceding),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 0 preceding and 0 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following),unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select last(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date groups between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 36, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 36, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- WITH cte (x) AS (\n+--         SELECT * FROM range(1, 36, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 50, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 50, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- WITH cte (x) AS (\n+--         select 1 union all select 1 union all select 1 union all\n+--         SELECT * FROM range(5, 50, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1,\n+-- groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1, f1 order by f2\n+-- groups between 2 preceding and 1 preceding)\n+-- from t1 where f1 = f2;\n+ \n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1, f2 order by f2\n+-- groups between 1 following and 2 following)\n+-- from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+SELECT * FROM empsalary WHERE row_number() OVER (ORDER BY salary) < 10;\n+\n+SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- Since random() result may change due to seed issues, the behavior is actually unstable\n+SELECT * FROM rank() OVER (ORDER BY random());\n+\n+-- Original query: DELETE FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+SELECT * FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+\n+-- Original query: DELETE FROM empsalary RETURNING rank() OVER (ORDER BY random());\n+SELECT * FROM empsalary WHERE rank() OVER (ORDER BY random());\n+\n+-- [SPARK-28645] Throw an error on window redefinition\n+-- select count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1);\n+\n+select rank() OVER (PARTITION BY four, ORDER BY ten) FROM tenk1;\n+\n+-- [SPARK-28646] Allow usage of `count` only for parameterless aggregate function\n+-- select count() OVER () FROM tenk1;\n+\n+-- The output is the expected one: `range` is not a window or aggregate function.\n+SELECT range(1, 100) OVER () FROM empsalary;\n+\n+SELECT ntile(0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(four, 0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- filter\n+\n+-- [SPARK-28500] Adds support for `filter` clause\n+-- SELECT sum(salary), row_number() OVER (ORDER BY depname), sum(\n+--     sum(salary) FILTER (WHERE enroll_date > '2007-01-01')\n+-- )\n+-- FROM empsalary GROUP BY depname;\n+\n+-- Test pushdown of quals into a subquery containing window functions\n+\n+-- pushdown is safe because all PARTITION BY clauses include depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname) depsalary,\n+-- min(salary) OVER (PARTITION BY depname || 'A', depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- pushdown is unsafe because there's a PARTITION BY clause without depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY enroll_date) enroll_salary,\n+-- min(salary) OVER (PARTITION BY depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node collapsing\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname order by empno) depsalary,\n+-- min(salary) OVER (PARTITION BY depname, empno order by enroll_date) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node reordering\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT\n+-- lead(1) OVER (PARTITION BY depname ORDER BY salary, enroll_date),\n+-- lag(1) OVER (PARTITION BY depname ORDER BY salary,enroll_date,empno)\n+-- FROM empsalary;\n+\n+-- cleanup\n+DROP TABLE empsalary;\n+\n+-- test user-defined window function with named args and default args\n+-- CREATE FUNCTION nth_value_def(val anyelement, n integer = 1) RETURNS anyelement\n+--   LANGUAGE internal WINDOW IMMUTABLE STRICT AS 'window_nth_value';\n+\n+-- SELECT nth_value_def(n := 2, val := ten) OVER (PARTITION BY four), ten, four\n+--   FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten) s;\n+\n+-- SELECT nth_value_def(ten) OVER (PARTITION BY four), ten, four\n+--   FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten) s;\n+\n+--\n+-- Test the basic moving-aggregate machinery\n+--\n+\n+-- create aggregates that record the series of transform calls (these are\n+-- intentionally not true inverses)\n+\n+-- CREATE FUNCTION logging_sfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT COALESCE($1, '') || '*' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_msfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT COALESCE($1, '') || '+' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_minvfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '-' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE AGGREGATE logging_agg_nonstrict (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_nonstrict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_nonstrict,\n+-- \tminvfunc = logging_minvfunc_nonstrict\n+-- );\n+\n+-- CREATE AGGREGATE logging_agg_nonstrict_initcond (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_nonstrict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_nonstrict,\n+-- \tminvfunc = logging_minvfunc_nonstrict,\n+-- \tinitcond = 'I',\n+-- \tminitcond = 'MI'\n+-- );\n+\n+-- CREATE FUNCTION logging_sfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '*' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_msfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '+' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_minvfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '-' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE AGGREGATE logging_agg_strict (text)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_strict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_strict,\n+-- \tminvfunc = logging_minvfunc_strict\n+-- );\n+\n+-- CREATE AGGREGATE logging_agg_strict_initcond (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_strict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_strict,\n+-- \tminvfunc = logging_minvfunc_strict,\n+-- \tinitcond = 'I',\n+-- \tminitcond = 'MI'\n+-- );\n+\n+-- test strict and non-strict cases\n+-- SELECT\n+-- \tp::text || ',' || i::text || ':' || COALESCE(v::text, 'NULL') AS row,\n+-- \tlogging_agg_nonstrict(v) over wnd as nstrict,\n+-- \tlogging_agg_nonstrict_initcond(v) over wnd as nstrict_init,\n+-- \tlogging_agg_strict(v::text) over wnd as strict,\n+-- \tlogging_agg_strict_initcond(v) over wnd as strict_init\n+-- FROM (VALUES\n+-- \t(1, 1, NULL),\n+-- \t(1, 2, 'a'),\n+-- \t(1, 3, 'b'),\n+-- \t(1, 4, NULL),\n+-- \t(1, 5, NULL),\n+-- \t(1, 6, 'c'),\n+-- \t(2, 1, NULL),\n+-- \t(2, 2, 'x'),\n+-- \t(3, 1, 'z')\n+-- ) AS t(p, i, v)\n+-- WINDOW wnd AS (PARTITION BY P ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY p, i;\n+\n+-- and again, but with filter\n+-- SELECT\n+-- \tp::text || ',' || i::text || ':' ||\n+-- \t\tCASE WHEN f THEN COALESCE(v::text, 'NULL') ELSE '-' END as row,\n+-- \tlogging_agg_nonstrict(v) filter(where f) over wnd as nstrict_filt,\n+-- \tlogging_agg_nonstrict_initcond(v) filter(where f) over wnd as nstrict_init_filt,\n+-- \tlogging_agg_strict(v::text) filter(where f) over wnd as strict_filt,\n+-- \tlogging_agg_strict_initcond(v) filter(where f) over wnd as strict_init_filt\n+-- FROM (VALUES\n+-- \t(1, 1, true,  NULL),\n+-- \t(1, 2, false, 'a'),\n+-- \t(1, 3, true,  'b'),\n+-- \t(1, 4, false, NULL),\n+-- \t(1, 5, false, NULL),\n+-- \t(1, 6, false, 'c'),\n+-- \t(2, 1, false, NULL),\n+-- \t(2, 2, true,  'x'),\n+-- \t(3, 1, true,  'z')\n+-- ) AS t(p, i, f, v)\n+-- WINDOW wnd AS (PARTITION BY p ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY p, i;\n+\n+-- test that volatile arguments disable moving-aggregate mode\n+-- SELECT\n+-- \ti::text || ':' || COALESCE(v::text, 'NULL') as row,\n+-- \tlogging_agg_strict(v::text)\n+-- \t\tover wnd as inverse,\n+-- \tlogging_agg_strict(v::text || CASE WHEN random() < 0 then '?' ELSE '' END)\n+-- \t\tover wnd as noinverse\n+-- FROM (VALUES\n+-- \t(1, 'a'),\n+-- \t(2, 'b'),\n+-- \t(3, 'c')\n+-- ) AS t(i, v)\n+-- WINDOW wnd AS (ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY i;\n+\n+-- SELECT\n+-- \ti::text || ':' || COALESCE(v::text, 'NULL') as row,\n+-- \tlogging_agg_strict(v::text) filter(where true)\n+-- \t\tover wnd as inverse,\n+-- \tlogging_agg_strict(v::text) filter(where random() >= 0)\n+-- \t\tover wnd as noinverse\n+-- FROM (VALUES\n+-- \t(1, 'a'),\n+-- \t(2, 'b'),\n+-- \t(3, 'c')\n+-- ) AS t(i, v)\n+-- WINDOW wnd AS (ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY i;\n+\n+-- test that non-overlapping windows don't use inverse transitions\n+-- SELECT\n+-- \tlogging_agg_strict(v::text) OVER wnd\n+-- FROM (VALUES\n+-- \t(1, 'a'),\n+-- \t(2, 'b'),\n+-- \t(3, 'c')\n+-- ) AS t(i, v)\n+-- WINDOW wnd AS (ORDER BY i ROWS BETWEEN CURRENT ROW AND CURRENT ROW)\n+-- ORDER BY i;\n+\n+-- test that returning NULL from the inverse transition functions\n+-- restarts the aggregation from scratch. The second aggregate is supposed\n+-- to test cases where only some aggregates restart, the third one checks\n+-- that one aggregate restarting doesn't cause others to restart.\n+\n+-- CREATE FUNCTION sum_int_randrestart_minvfunc(int4, int4) RETURNS int4 AS\n+-- $$ SELECT CASE WHEN random() < 0.2 THEN NULL ELSE $1 - $2 END $$\n+-- LANGUAGE SQL STRICT;\n+\n+-- CREATE AGGREGATE sum_int_randomrestart (int4)\n+-- (\n+-- \tstype = int4,\n+-- \tsfunc = int4pl,\n+-- \tmstype = int4,\n+-- \tmsfunc = int4pl,\n+-- \tminvfunc = sum_int_randrestart_minvfunc\n+-- );\n+\n+-- WITH\n+-- vs AS (\n+-- \tSELECT i, (random() * 100)::int4 AS v\n+-- \tFROM generate_series(1, 100) AS i\n+-- ),\n+-- sum_following AS (\n+-- \tSELECT i, SUM(v) OVER\n+-- \t\t(ORDER BY i DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS s\n+-- \tFROM vs\n+-- )\n+-- SELECT DISTINCT\n+-- \tsum_following.s = sum_int_randomrestart(v) OVER fwd AS eq1,\n+-- \t-sum_following.s = sum_int_randomrestart(-v) OVER fwd AS eq2,\n+-- \t100*3+(vs.i-1)*3 = length(logging_agg_nonstrict(''::text) OVER fwd) AS eq3\n+-- FROM vs\n+-- JOIN sum_following ON sum_following.i = vs.i\n+-- WINDOW fwd AS (\n+-- \tORDER BY vs.i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n+-- );\n+\n+--\n+-- Test various built-in aggregates that have moving-aggregate support\n+--\n+\n+-- test inverse transition functions handle NULLs properly\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.5),(2,2.5),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- [SPARK-28602] Spark does not recognize 'interval' type as 'numeric'\n+-- SELECT i,AVG(cast(v as interval)) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1 sec'),(2,'2 sec'),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- The cast syntax is present in PgSQL for legacy reasons and Spark will not recognize a money field\n+-- SELECT i,SUM(v::money) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1.10'),(2,'2.20'),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- [SPARK-28602] Spark does not recognize 'interval' type as 'numeric'\n+-- SELECT i,SUM(cast(v as interval)) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+--   FROM (VALUES(1,'1 sec'),(2,'2 sec'),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.1),(2,2.2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT SUM(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.01),(2,2),(3,3)) v(i,n);\n+\n+SELECT i,COUNT(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,COUNT(*) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VAR_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT VARIANCE(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_POP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+-- For the following queries Spark result differs from PgSQL:\n+-- Spark handles division by zero as 'NaN' instead of 'NULL', which is the PgSQL behaviour\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+SELECT STDDEV(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(0,NULL),(1,600),(2,470),(3,170),(4,430),(5,300)) r(i,n);\n+\n+-- test that inverse transition functions work with various frame options\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND CURRENT ROW)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND 1 FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,SUM(v) OVER (ORDER BY i ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,3),(4,4)) t(i,v);\n+\n+-- ensure aggregate over numeric properly recovers from NaN values\n+SELECT a, b,\n+       SUM(b) OVER(ORDER BY A ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+FROM (VALUES(1,1),(2,2),(3,'NaN'),(4,3),(5,4)) t(a,b);\n+\n+select f_float4, sum(f_float4) over (order by f_float8 rows between 1"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "plz keep the original query: https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql#L1133",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-08-26T05:55:46Z",
    "diffHunk": "@@ -0,0 +1,1401 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+SELECT sum(unique1) over (w range between current row and unbounded following),\n+\tunique1, four\n+FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 11) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i.id, sum(i.id) over (order by i.id groups between 1 preceding and 1 following) as sum_rows FROM range(1, 11) i;\n+-- SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+select last(salary) over(order by salary range between 1000 preceding and 1000 following),\n+lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32767) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32765) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483647) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483645) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775807) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775805) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100)\n+(8, 'infinity', 'infinity', '1000'),\n+(9, 'NaN', 'NaN', 'NaN');\n+(0, '-infinity', '-infinity', '-1000');  -- numeric type lacks infinities\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 1 preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 1 following and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and 2 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 preceding),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 0 preceding and 0 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following),unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select last(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date groups between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 36, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 36, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- WITH cte (x) AS (\n+--         SELECT * FROM range(1, 36, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 50, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 50, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- WITH cte (x) AS (\n+--         select 1 union all select 1 union all select 1 union all\n+--         SELECT * FROM range(5, 50, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1,\n+-- groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1, f1 order by f2\n+-- groups between 2 preceding and 1 preceding)\n+-- from t1 where f1 = f2;\n+ \n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1, f2 order by f2\n+-- groups between 1 following and 2 following)\n+-- from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+SELECT * FROM empsalary WHERE row_number() OVER (ORDER BY salary) < 10;\n+\n+SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- Since random() result may change due to seed issues, the behavior is actually unstable\n+SELECT * FROM rank() OVER (ORDER BY random());\n+\n+-- Original query: DELETE FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+SELECT * FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+\n+-- Original query: DELETE FROM empsalary RETURNING rank() OVER (ORDER BY random());\n+SELECT * FROM empsalary WHERE rank() OVER (ORDER BY random());\n+\n+-- [SPARK-28645] Throw an error on window redefinition\n+-- select count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1);\n+\n+select rank() OVER (PARTITION BY four, ORDER BY ten) FROM tenk1;\n+\n+-- [SPARK-28646] Allow usage of `count` only for parameterless aggregate function\n+-- select count() OVER () FROM tenk1;\n+\n+-- The output is the expected one: `range` is not a window or aggregate function.\n+SELECT range(1, 100) OVER () FROM empsalary;\n+\n+SELECT ntile(0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(four, 0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- filter\n+\n+-- [SPARK-28500] Adds support for `filter` clause\n+-- SELECT sum(salary), row_number() OVER (ORDER BY depname), sum(\n+--     sum(salary) FILTER (WHERE enroll_date > '2007-01-01')\n+-- )\n+-- FROM empsalary GROUP BY depname;\n+\n+-- Test pushdown of quals into a subquery containing window functions\n+\n+-- pushdown is safe because all PARTITION BY clauses include depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname) depsalary,\n+-- min(salary) OVER (PARTITION BY depname || 'A', depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- pushdown is unsafe because there's a PARTITION BY clause without depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY enroll_date) enroll_salary,\n+-- min(salary) OVER (PARTITION BY depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node collapsing\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname order by empno) depsalary,\n+-- min(salary) OVER (PARTITION BY depname, empno order by enroll_date) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node reordering\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT\n+-- lead(1) OVER (PARTITION BY depname ORDER BY salary, enroll_date),\n+-- lag(1) OVER (PARTITION BY depname ORDER BY salary,enroll_date,empno)\n+-- FROM empsalary;\n+\n+-- cleanup\n+DROP TABLE empsalary;\n+\n+-- test user-defined window function with named args and default args\n+-- CREATE FUNCTION nth_value_def(val anyelement, n integer = 1) RETURNS anyelement\n+--   LANGUAGE internal WINDOW IMMUTABLE STRICT AS 'window_nth_value';\n+\n+-- SELECT nth_value_def(n := 2, val := ten) OVER (PARTITION BY four), ten, four\n+--   FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten) s;\n+\n+-- SELECT nth_value_def(ten) OVER (PARTITION BY four), ten, four\n+--   FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten) s;\n+\n+--\n+-- Test the basic moving-aggregate machinery\n+--\n+\n+-- create aggregates that record the series of transform calls (these are\n+-- intentionally not true inverses)\n+\n+-- CREATE FUNCTION logging_sfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT COALESCE($1, '') || '*' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_msfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT COALESCE($1, '') || '+' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_minvfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '-' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE AGGREGATE logging_agg_nonstrict (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_nonstrict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_nonstrict,\n+-- \tminvfunc = logging_minvfunc_nonstrict\n+-- );\n+\n+-- CREATE AGGREGATE logging_agg_nonstrict_initcond (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_nonstrict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_nonstrict,\n+-- \tminvfunc = logging_minvfunc_nonstrict,\n+-- \tinitcond = 'I',\n+-- \tminitcond = 'MI'\n+-- );\n+\n+-- CREATE FUNCTION logging_sfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '*' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_msfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '+' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_minvfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '-' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE AGGREGATE logging_agg_strict (text)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_strict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_strict,\n+-- \tminvfunc = logging_minvfunc_strict\n+-- );\n+\n+-- CREATE AGGREGATE logging_agg_strict_initcond (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_strict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_strict,\n+-- \tminvfunc = logging_minvfunc_strict,\n+-- \tinitcond = 'I',\n+-- \tminitcond = 'MI'\n+-- );\n+\n+-- test strict and non-strict cases\n+-- SELECT\n+-- \tp::text || ',' || i::text || ':' || COALESCE(v::text, 'NULL') AS row,\n+-- \tlogging_agg_nonstrict(v) over wnd as nstrict,\n+-- \tlogging_agg_nonstrict_initcond(v) over wnd as nstrict_init,\n+-- \tlogging_agg_strict(v::text) over wnd as strict,\n+-- \tlogging_agg_strict_initcond(v) over wnd as strict_init\n+-- FROM (VALUES\n+-- \t(1, 1, NULL),\n+-- \t(1, 2, 'a'),\n+-- \t(1, 3, 'b'),\n+-- \t(1, 4, NULL),\n+-- \t(1, 5, NULL),\n+-- \t(1, 6, 'c'),\n+-- \t(2, 1, NULL),\n+-- \t(2, 2, 'x'),\n+-- \t(3, 1, 'z')\n+-- ) AS t(p, i, v)\n+-- WINDOW wnd AS (PARTITION BY P ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY p, i;\n+\n+-- and again, but with filter\n+-- SELECT\n+-- \tp::text || ',' || i::text || ':' ||\n+-- \t\tCASE WHEN f THEN COALESCE(v::text, 'NULL') ELSE '-' END as row,\n+-- \tlogging_agg_nonstrict(v) filter(where f) over wnd as nstrict_filt,\n+-- \tlogging_agg_nonstrict_initcond(v) filter(where f) over wnd as nstrict_init_filt,\n+-- \tlogging_agg_strict(v::text) filter(where f) over wnd as strict_filt,\n+-- \tlogging_agg_strict_initcond(v) filter(where f) over wnd as strict_init_filt\n+-- FROM (VALUES\n+-- \t(1, 1, true,  NULL),\n+-- \t(1, 2, false, 'a'),\n+-- \t(1, 3, true,  'b'),\n+-- \t(1, 4, false, NULL),\n+-- \t(1, 5, false, NULL),\n+-- \t(1, 6, false, 'c'),\n+-- \t(2, 1, false, NULL),\n+-- \t(2, 2, true,  'x'),\n+-- \t(3, 1, true,  'z')\n+-- ) AS t(p, i, f, v)\n+-- WINDOW wnd AS (PARTITION BY p ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY p, i;\n+\n+-- test that volatile arguments disable moving-aggregate mode\n+-- SELECT\n+-- \ti::text || ':' || COALESCE(v::text, 'NULL') as row,\n+-- \tlogging_agg_strict(v::text)\n+-- \t\tover wnd as inverse,\n+-- \tlogging_agg_strict(v::text || CASE WHEN random() < 0 then '?' ELSE '' END)\n+-- \t\tover wnd as noinverse\n+-- FROM (VALUES\n+-- \t(1, 'a'),\n+-- \t(2, 'b'),\n+-- \t(3, 'c')\n+-- ) AS t(i, v)\n+-- WINDOW wnd AS (ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY i;\n+\n+-- SELECT\n+-- \ti::text || ':' || COALESCE(v::text, 'NULL') as row,\n+-- \tlogging_agg_strict(v::text) filter(where true)\n+-- \t\tover wnd as inverse,\n+-- \tlogging_agg_strict(v::text) filter(where random() >= 0)\n+-- \t\tover wnd as noinverse\n+-- FROM (VALUES\n+-- \t(1, 'a'),\n+-- \t(2, 'b'),\n+-- \t(3, 'c')\n+-- ) AS t(i, v)\n+-- WINDOW wnd AS (ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY i;\n+\n+-- test that non-overlapping windows don't use inverse transitions\n+-- SELECT\n+-- \tlogging_agg_strict(v::text) OVER wnd\n+-- FROM (VALUES\n+-- \t(1, 'a'),\n+-- \t(2, 'b'),\n+-- \t(3, 'c')\n+-- ) AS t(i, v)\n+-- WINDOW wnd AS (ORDER BY i ROWS BETWEEN CURRENT ROW AND CURRENT ROW)\n+-- ORDER BY i;\n+\n+-- test that returning NULL from the inverse transition functions\n+-- restarts the aggregation from scratch. The second aggregate is supposed\n+-- to test cases where only some aggregates restart, the third one checks\n+-- that one aggregate restarting doesn't cause others to restart.\n+\n+-- CREATE FUNCTION sum_int_randrestart_minvfunc(int4, int4) RETURNS int4 AS\n+-- $$ SELECT CASE WHEN random() < 0.2 THEN NULL ELSE $1 - $2 END $$\n+-- LANGUAGE SQL STRICT;\n+\n+-- CREATE AGGREGATE sum_int_randomrestart (int4)\n+-- (\n+-- \tstype = int4,\n+-- \tsfunc = int4pl,\n+-- \tmstype = int4,\n+-- \tmsfunc = int4pl,\n+-- \tminvfunc = sum_int_randrestart_minvfunc\n+-- );\n+\n+-- WITH\n+-- vs AS (\n+-- \tSELECT i, (random() * 100)::int4 AS v\n+-- \tFROM generate_series(1, 100) AS i\n+-- ),\n+-- sum_following AS (\n+-- \tSELECT i, SUM(v) OVER\n+-- \t\t(ORDER BY i DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS s\n+-- \tFROM vs\n+-- )\n+-- SELECT DISTINCT\n+-- \tsum_following.s = sum_int_randomrestart(v) OVER fwd AS eq1,\n+-- \t-sum_following.s = sum_int_randomrestart(-v) OVER fwd AS eq2,\n+-- \t100*3+(vs.i-1)*3 = length(logging_agg_nonstrict(''::text) OVER fwd) AS eq3\n+-- FROM vs\n+-- JOIN sum_following ON sum_following.i = vs.i\n+-- WINDOW fwd AS (\n+-- \tORDER BY vs.i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n+-- );\n+\n+--\n+-- Test various built-in aggregates that have moving-aggregate support\n+--\n+\n+-- test inverse transition functions handle NULLs properly\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1),(2,2),(3,NULL),(4,NULL)) t(i,v);\n+\n+SELECT i,AVG(v) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n+  FROM (VALUES(1,1.5),(2,2.5),(3,NULL),(4,NULL)) t(i,v);\n+\n+-- [SPARK-28602] Spark does not recognize 'interval' type as 'numeric'\n+-- SELECT i,AVG(cast(v as interval)) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)"
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "Can you describe a comment-out reason for each query where possible?",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-08-26T06:01:21Z",
    "diffHunk": "@@ -0,0 +1,1401 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+SELECT sum(unique1) over (w range between current row and unbounded following),\n+\tunique1, four\n+FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 11) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i.id, sum(i.id) over (order by i.id groups between 1 preceding and 1 following) as sum_rows FROM range(1, 11) i;\n+-- SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+select last(salary) over(order by salary range between 1000 preceding and 1000 following),\n+lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32767) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32765) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483647) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483645) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775807) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775805) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100)\n+(8, 'infinity', 'infinity', '1000'),\n+(9, 'NaN', 'NaN', 'NaN');\n+(0, '-infinity', '-infinity', '-1000');  -- numeric type lacks infinities\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 1 preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 1 following and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and 2 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 preceding),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 0 preceding and 0 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following),unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select last(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date groups between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 36, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 36, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- WITH cte (x) AS (\n+--         SELECT * FROM range(1, 36, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 50, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 50, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- WITH cte (x) AS (\n+--         select 1 union all select 1 union all select 1 union all\n+--         SELECT * FROM range(5, 50, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1,\n+-- groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1, f1 order by f2\n+-- groups between 2 preceding and 1 preceding)\n+-- from t1 where f1 = f2;\n+ \n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1, f2 order by f2\n+-- groups between 1 following and 2 following)\n+-- from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+SELECT * FROM empsalary WHERE row_number() OVER (ORDER BY salary) < 10;\n+\n+SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- Since random() result may change due to seed issues, the behavior is actually unstable\n+SELECT * FROM rank() OVER (ORDER BY random());\n+\n+-- Original query: DELETE FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+SELECT * FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+\n+-- Original query: DELETE FROM empsalary RETURNING rank() OVER (ORDER BY random());\n+SELECT * FROM empsalary WHERE rank() OVER (ORDER BY random());\n+\n+-- [SPARK-28645] Throw an error on window redefinition\n+-- select count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1);\n+\n+select rank() OVER (PARTITION BY four, ORDER BY ten) FROM tenk1;\n+\n+-- [SPARK-28646] Allow usage of `count` only for parameterless aggregate function\n+-- select count() OVER () FROM tenk1;\n+\n+-- The output is the expected one: `range` is not a window or aggregate function.\n+SELECT range(1, 100) OVER () FROM empsalary;\n+\n+SELECT ntile(0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(four, 0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- filter\n+\n+-- [SPARK-28500] Adds support for `filter` clause\n+-- SELECT sum(salary), row_number() OVER (ORDER BY depname), sum(\n+--     sum(salary) FILTER (WHERE enroll_date > '2007-01-01')\n+-- )\n+-- FROM empsalary GROUP BY depname;\n+\n+-- Test pushdown of quals into a subquery containing window functions\n+\n+-- pushdown is safe because all PARTITION BY clauses include depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname) depsalary,\n+-- min(salary) OVER (PARTITION BY depname || 'A', depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- pushdown is unsafe because there's a PARTITION BY clause without depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY enroll_date) enroll_salary,\n+-- min(salary) OVER (PARTITION BY depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node collapsing\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname order by empno) depsalary,\n+-- min(salary) OVER (PARTITION BY depname, empno order by enroll_date) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node reordering\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT\n+-- lead(1) OVER (PARTITION BY depname ORDER BY salary, enroll_date),\n+-- lag(1) OVER (PARTITION BY depname ORDER BY salary,enroll_date,empno)\n+-- FROM empsalary;\n+\n+-- cleanup\n+DROP TABLE empsalary;\n+\n+-- test user-defined window function with named args and default args\n+-- CREATE FUNCTION nth_value_def(val anyelement, n integer = 1) RETURNS anyelement\n+--   LANGUAGE internal WINDOW IMMUTABLE STRICT AS 'window_nth_value';\n+\n+-- SELECT nth_value_def(n := 2, val := ten) OVER (PARTITION BY four), ten, four\n+--   FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten) s;\n+\n+-- SELECT nth_value_def(ten) OVER (PARTITION BY four), ten, four\n+--   FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten) s;\n+\n+--\n+-- Test the basic moving-aggregate machinery\n+--\n+\n+-- create aggregates that record the series of transform calls (these are\n+-- intentionally not true inverses)\n+\n+-- CREATE FUNCTION logging_sfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT COALESCE($1, '') || '*' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_msfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT COALESCE($1, '') || '+' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_minvfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '-' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE AGGREGATE logging_agg_nonstrict (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_nonstrict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_nonstrict,\n+-- \tminvfunc = logging_minvfunc_nonstrict\n+-- );\n+\n+-- CREATE AGGREGATE logging_agg_nonstrict_initcond (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_nonstrict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_nonstrict,\n+-- \tminvfunc = logging_minvfunc_nonstrict,\n+-- \tinitcond = 'I',\n+-- \tminitcond = 'MI'\n+-- );\n+\n+-- CREATE FUNCTION logging_sfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '*' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_msfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '+' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_minvfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '-' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE AGGREGATE logging_agg_strict (text)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_strict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_strict,\n+-- \tminvfunc = logging_minvfunc_strict\n+-- );\n+\n+-- CREATE AGGREGATE logging_agg_strict_initcond (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_strict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_strict,\n+-- \tminvfunc = logging_minvfunc_strict,\n+-- \tinitcond = 'I',\n+-- \tminitcond = 'MI'\n+-- );\n+\n+-- test strict and non-strict cases\n+-- SELECT\n+-- \tp::text || ',' || i::text || ':' || COALESCE(v::text, 'NULL') AS row,\n+-- \tlogging_agg_nonstrict(v) over wnd as nstrict,\n+-- \tlogging_agg_nonstrict_initcond(v) over wnd as nstrict_init,\n+-- \tlogging_agg_strict(v::text) over wnd as strict,\n+-- \tlogging_agg_strict_initcond(v) over wnd as strict_init\n+-- FROM (VALUES\n+-- \t(1, 1, NULL),\n+-- \t(1, 2, 'a'),\n+-- \t(1, 3, 'b'),\n+-- \t(1, 4, NULL),\n+-- \t(1, 5, NULL),\n+-- \t(1, 6, 'c'),\n+-- \t(2, 1, NULL),\n+-- \t(2, 2, 'x'),\n+-- \t(3, 1, 'z')\n+-- ) AS t(p, i, v)\n+-- WINDOW wnd AS (PARTITION BY P ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY p, i;\n+\n+-- and again, but with filter\n+-- SELECT\n+-- \tp::text || ',' || i::text || ':' ||\n+-- \t\tCASE WHEN f THEN COALESCE(v::text, 'NULL') ELSE '-' END as row,\n+-- \tlogging_agg_nonstrict(v) filter(where f) over wnd as nstrict_filt,\n+-- \tlogging_agg_nonstrict_initcond(v) filter(where f) over wnd as nstrict_init_filt,\n+-- \tlogging_agg_strict(v::text) filter(where f) over wnd as strict_filt,\n+-- \tlogging_agg_strict_initcond(v) filter(where f) over wnd as strict_init_filt\n+-- FROM (VALUES\n+-- \t(1, 1, true,  NULL),\n+-- \t(1, 2, false, 'a'),\n+-- \t(1, 3, true,  'b'),\n+-- \t(1, 4, false, NULL),\n+-- \t(1, 5, false, NULL),\n+-- \t(1, 6, false, 'c'),\n+-- \t(2, 1, false, NULL),\n+-- \t(2, 2, true,  'x'),\n+-- \t(3, 1, true,  'z')\n+-- ) AS t(p, i, f, v)\n+-- WINDOW wnd AS (PARTITION BY p ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY p, i;\n+\n+-- test that volatile arguments disable moving-aggregate mode\n+-- SELECT\n+-- \ti::text || ':' || COALESCE(v::text, 'NULL') as row,\n+-- \tlogging_agg_strict(v::text)\n+-- \t\tover wnd as inverse,\n+-- \tlogging_agg_strict(v::text || CASE WHEN random() < 0 then '?' ELSE '' END)\n+-- \t\tover wnd as noinverse\n+-- FROM (VALUES\n+-- \t(1, 'a'),\n+-- \t(2, 'b'),\n+-- \t(3, 'c')\n+-- ) AS t(i, v)\n+-- WINDOW wnd AS (ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY i;\n+\n+-- SELECT",
    "line": 1197
  }, {
    "author": {
      "login": "DylanGuedes"
    },
    "body": "Done",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-09-07T14:38:15Z",
    "diffHunk": "@@ -0,0 +1,1401 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql\n+\n+CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1;\n+\n+CREATE TABLE empsalary (\n+    depname string,\n+    empno integer,\n+    salary int,\n+    enroll_date date\n+) USING parquet;\n+\n+INSERT INTO empsalary VALUES\n+('develop', 10, 5200, '2007-08-01'),\n+('sales', 1, 5000, '2006-10-01'),\n+('personnel', 5, 3500, '2007-12-10'),\n+('sales', 4, 4800, '2007-08-08'),\n+('personnel', 2, 3900, '2006-12-23'),\n+('develop', 7, 4200, '2008-01-01'),\n+('develop', 9, 4500, '2008-01-01'),\n+('sales', 3, 4800, '2007-08-01'),\n+('develop', 8, 6000, '2006-10-01'),\n+('develop', 11, 5200, '2007-08-15');\n+\n+SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname) FROM empsalary ORDER BY depname, salary;\n+\n+SELECT depname, empno, salary, rank() OVER (PARTITION BY depname ORDER BY salary) FROM empsalary;\n+\n+-- with GROUP BY\n+SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\n+GROUP BY four, ten ORDER BY four, ten;\n+\n+SELECT depname, empno, salary, sum(salary) OVER w FROM empsalary WINDOW w AS (PARTITION BY depname);\n+\n+-- [SPARK-28064] Order by does not accept a call to rank()\n+-- SELECT depname, empno, salary, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary) ORDER BY rank() OVER w;\n+\n+-- empty window specification\n+SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ();\n+\n+-- no window operation\n+SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten);\n+\n+-- cumulative aggregate\n+SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28065] ntile does not accept NULL as input\n+-- SELECT ntile(NULL) OVER (ORDER BY ten, four), ten, four FROM tenk1 LIMIT 2;\n+\n+SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- [SPARK-28068] `lag` second argument must be a literal in Spark\n+-- SELECT lag(ten, four, 0) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+-- last returns the last row of the frame, which is CURRENT ROW in ORDER BY window.\n+SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT last(ten) OVER (PARTITION BY four), ten, four FROM\n+(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s\n+ORDER BY four, ten;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(ten, four + 1) OVER (PARTITION BY four), ten, four\n+-- FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum\n+FROM tenk1 GROUP BY ten, two;\n+\n+SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10;\n+\n+SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +\n+  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum\n+  FROM tenk1 WHERE unique2 < 10;\n+\n+-- opexpr with different windows evaluation.\n+SELECT * FROM(\n+  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,\n+    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,\n+    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum\n+    FROM tenk1\n+)sub WHERE total <> fourcount + twosum;\n+\n+SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10;\n+\n+SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum\n+FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten);\n+\n+-- more than one window with GROUP BY\n+SELECT sum(salary),\n+  row_number() OVER (ORDER BY depname),\n+  sum(sum(salary)) OVER (ORDER BY depname DESC)\n+FROM empsalary GROUP BY depname;\n+\n+-- identical windows with different names\n+SELECT sum(salary) OVER w1, count(*) OVER w2\n+FROM empsalary WINDOW w1 AS (ORDER BY salary), w2 AS (ORDER BY salary);\n+\n+-- subplan\n+-- [SPARK-28379] Correlated scalar subqueries must be aggregated\n+-- SELECT lead(ten, (SELECT two FROM tenk1 WHERE s.unique2 = unique2)) OVER (PARTITION BY four ORDER BY ten)\n+-- FROM tenk1 s WHERE unique2 < 10;\n+\n+-- empty table\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s;\n+\n+-- mixture of agg/wfunc in the same window\n+SELECT sum(salary) OVER w, rank() OVER w FROM empsalary WINDOW w AS (PARTITION BY depname ORDER BY salary DESC);\n+\n+-- strict aggs\n+-- Temporarily turns off the ANSI mode because of compatibility issues between keywords\n+SET spark.sql.parser.ansi.enabled=false;\n+SELECT empno, depname, salary, bonus, depadj, MIN(bonus) OVER (ORDER BY empno), MAX(depadj) OVER () FROM(\n+SELECT *,\n+  CASE WHEN enroll_date < '2008-01-01' THEN 2008 - extract(year FROM enroll_date) END * 500 AS bonus,\n+  CASE WHEN\n+    AVG(salary) OVER (PARTITION BY depname) < salary\n+    THEN 200 END AS depadj FROM empsalary\n+  )s;\n+SET spark.sql.parser.ansi.enabled=true;\n+\n+create temporary view int4_tbl as select * from values\n+  (0),\n+  (123456),\n+  (-123456),\n+  (2147483647),\n+  (-2147483647)\n+  as int4_tbl(f1);\n+\n+-- window function over ungrouped agg over empty row set (bug before 9.1)\n+SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42;\n+\n+-- window function with ORDER BY an expression involving aggregates (9.1 bug)\n+select ten,\n+  sum(unique1) + sum(unique2) as res,\n+  rank() over (order by sum(unique1) + sum(unique2)) as rank\n+from tenk1\n+group by ten order by ten;\n+\n+-- window and aggregate with GROUP BY expression (9.2 bug)\n+-- explain\n+-- select first(max(x)) over (), y\n+--   from (select unique1 as x, ten+four as y from tenk1) ss\n+--   group by y;\n+\n+-- test non-default frame specifications\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten),\n+last(ten) over (partition by four order by ten)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and current row),\n+last(ten) over (partition by four order by ten range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten,\n+sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),\n+last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 range between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT four, ten/4 as two,\n+sum(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row),\n+last(ten/4) over (partition by four order by ten/4 rows between unbounded preceding and current row)\n+FROM (select distinct ten, four from tenk1) ss;\n+\n+SELECT sum(unique1) over (order by four range between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between current row and unbounded following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 2 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (rows between 2 preceding and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT first(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT last(unique1) over (ORDER BY four rows between current row and 2 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between 1 following and 3 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (rows between unbounded preceding and 1 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+SELECT sum(unique1) over (w range between current row and unbounded following),\n+\tunique1, four\n+FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (w range between unbounded preceding and current row exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10 WINDOW w AS (order by four);\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT first_value(unique1) over w,\n+-- nth_value(unique1, 2) over w AS nth_2,\n+-- last_value(unique1) over w, unique1, four\n+-- FROM tenk1 WHERE unique1 < 10\n+-- WINDOW w AS (order by four range between current row and unbounded following);\n+\n+-- [SPARK-28501] Frame bound value must be a literal.\n+-- SELECT sum(unique1) over\n+-- (order by unique1\n+--   rows (SELECT unique1 FROM tenk1 ORDER BY unique1 LIMIT 1) + 1 PRECEDING),\n+-- unique1\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+CREATE TEMP VIEW v_window AS\n+SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows\n+FROM range(1, 11) i;\n+\n+SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude current row) as sum_rows FROM range(1, 10) i;\n+\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude group) as sum_rows FROM range(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude ties) as sum_rows FROM generate_series(1, 10) i;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following\n+--   exclude no others) as sum_rows FROM generate_series(1, 10) i;\n+-- SELECT * FROM v_window;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- CREATE OR REPLACE TEMP VIEW v_window AS\n+-- SELECT i.id, sum(i.id) over (order by i.id groups between 1 preceding and 1 following) as sum_rows FROM range(1, 11) i;\n+-- SELECT * FROM v_window;\n+\n+DROP VIEW v_window;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- CREATE TEMP VIEW v_window AS\n+-- SELECT i, min(i) over (order by i range between '1 day' preceding and '10 days' following) as min_i\n+--   FROM range(now(), now()+'100 days', '1 hour') i;\n+\n+-- RANGE offset PRECEDING/FOLLOWING tests\n+\n+SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (order by four desc range between 2 preceding and 1 preceding),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude no others),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 preceding exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude ties),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 6 following exclude group),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following),\n+unique1, four\n+FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (partition by four order by unique1 range between 5 preceding and 6 following\n+--   exclude current row),unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select sum(salary) over (order by enroll_date desc range between '1 year' following and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude current row), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude group), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date range between '1 year' preceding and '1 year' following\n+--   exclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- lead(salary) over(order by salary range between 1000 preceding and 1000 following),\n+-- nth_value(salary, 1) over(order by salary range between 1000 preceding and 1000 following),\n+-- salary from empsalary;\n+\n+select last(salary) over(order by salary range between 1000 preceding and 1000 following),\n+lag(salary) over(order by salary range between 1000 preceding and 1000 following),\n+salary from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude current row),\n+-- lead(salary) over(order by salary range between 1000 following and 3000 following exclude ties),\n+-- nth_value(salary, 1) over(order by salary range between 1000 following and 3000 following\n+--   exclude ties),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by salary range between 1000 following and 3000 following\n+--   exclude group),\n+-- lag(salary) over(order by salary range between 1000 following and 3000 following exclude group),\n+-- salary from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select first(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- last(salary) over(order by enroll_date range between unbounded preceding and '1 year' following\n+--   exclude current row),\n+-- salary, enroll_date from empsalary;\n+\n+-- RANGE offset PRECEDING/FOLLOWING with null values\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id asc nulls last range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls first range between 2 preceding and 2 following);\n+\n+select ss.id, ss.y,\n+       first(ss.y) over w,\n+       last(ss.y) over w\n+from\n+  (select x.id, x.id as y from range(1,6) as x\n+   union all select null, 42\n+   union all select null, 43) ss\n+window w as\n+  (order by ss.id desc nulls last range between 2 preceding and 2 following);\n+\n+-- Check overflow behavior for various integer sizes\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 2147450884 following)\n+from range(32764, 32767) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 2147450885 following)\n+from range(-32766, -32765) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(2147483644, 2147483647) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-2147483646, -2147483645) x;\n+\n+select x.id, last(x.id) over (order by x.id range between current row and 4 following)\n+from range(9223372036854775804, 9223372036854775807) x;\n+\n+select x.id, last(x.id) over (order by x.id desc range between current row and 5 following)\n+from range(-9223372036854775806, -9223372036854775805) x;\n+\n+-- Test in_range for other numeric datatypes\n+\n+create table numerics (\n+    id int,\n+    f_float4 float,\n+    f_float8 float,\n+    f_numeric int\n+) using parquet;\n+\n+insert into numerics values\n+(1, -3, -3, -3),\n+(2, -1, -1, -1),\n+(3, 0, 0, 0),\n+(4, 1.1, 1.1, 1.1),\n+(5, 1.12, 1.12, 1.12),\n+(6, 2, 2, 2),\n+(7, 100, 100, 100)\n+(8, 'infinity', 'infinity', '1000'),\n+(9, 'NaN', 'NaN', 'NaN');\n+(0, '-infinity', '-infinity', '-1000');  -- numeric type lacks infinities\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float4, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float4 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             'inf' preceding and 'inf' following);\n+\n+select id, f_float8, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_float8 range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1 preceding and 1.1 following);  -- currently unsupported\n+\n+select id, f_numeric, first(id) over w, last(id) over w\n+from numerics\n+window w as (order by f_numeric range between\n+             1.1 preceding and 'NaN' following);  -- error, NaN disallowed\n+\n+-- Test in_range for other datetime datatypes\n+\n+-- Spark only supports timestamp\n+create table datetimes (\n+    id int,\n+    f_time timestamp,\n+    f_timetz timestamp,\n+    f_interval timestamp,\n+    f_timestamptz timestamp,\n+    f_timestamp timestamp\n+) using parquet;\n+\n+insert into datetimes values\n+(1, '11:00', '11:00 BST', '1 year', '2000-10-19 10:23:54+01', '2000-10-19 10:23:54'),\n+(2, '12:00', '12:00 BST', '2 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(3, '13:00', '13:00 BST', '3 years', '2001-10-19 10:23:54+01', '2001-10-19 10:23:54'),\n+(4, '14:00', '14:00 BST', '4 years', '2002-10-19 10:23:54+01', '2002-10-19 10:23:54'),\n+(5, '15:00', '15:00 BST', '5 years', '2003-10-19 10:23:54+01', '2003-10-19 10:23:54'),\n+(6, '15:00', '15:00 BST', '5 years', '2004-10-19 10:23:54+01', '2004-10-19 10:23:54'),\n+(7, '17:00', '17:00 BST', '7 years', '2005-10-19 10:23:54+01', '2005-10-19 10:23:54'),\n+(8, '18:00', '18:00 BST', '8 years', '2006-10-19 10:23:54+01', '2006-10-19 10:23:54'),\n+(9, '19:00', '19:00 BST', '9 years', '2007-10-19 10:23:54+01', '2007-10-19 10:23:54'),\n+(10, '20:00', '20:00 BST', '10 years', '2008-10-19 10:23:54+01', '2008-10-19 10:23:54');\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_time, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_time desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timetz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timetz desc range between\n+--              '70 min' preceding and '2 hours' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_interval, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_interval desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamptz, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamptz desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- [SPARK-28429] SQL Datetime util function being casted to double instead of timestamp\n+-- select id, f_timestamp, first(id) over w, last(id) over w\n+-- from datetimes\n+-- window w as (order by f_timestamp desc range between\n+--              '1 year' preceding and '1 year' following);\n+\n+-- RANGE offset PRECEDING/FOLLOWING error cases\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by enroll_date, salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select sum(salary) over (order by depname range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between 1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between -1 preceding and 2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between 1 preceding and -2 following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by salary range between '1 year' preceding and '2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select max(enroll_date) over (order by enroll_date range between '1 year' preceding and '-2 years' following\n+-- \texclude ties), salary, enroll_date from empsalary;\n+\n+-- GROUPS tests\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and current row),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between current row and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 1 preceding and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 1 following and unbounded following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between unbounded preceding and 2 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 preceding),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (order by four groups between 0 preceding and 0 following),\n+-- unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four groups between 2 preceding and 1 following\n+--   exclude current row), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude group), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- SELECT sum(unique1) over (order by four range between 2 preceding and 1 following\n+--   exclude ties), unique1, four\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following),unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude current row), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude group), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- SELECT sum(unique1) over (partition by ten\n+--   order by four groups between 0 preceding and 0 following exclude ties), unique1, four, ten\n+-- FROM tenk1 WHERE unique1 < 10;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select first_value(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lead(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28508] Support for range frame+row frame in the same query\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select last(salary) over(order by enroll_date groups between 1 preceding and 1 following),\n+-- lag(salary)         over(order by enroll_date groups between 1 preceding and 1 following),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- select first_value(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude current row),\n+-- lead(salary) over(order by enroll_date groups between 1 following and 3 following exclude ties),\n+-- nth_value(salary, 1) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude ties),\n+-- salary, enroll_date from empsalary;\n+\n+-- [SPARK-28428] Spark `exclude` always expecting `()`\n+-- select last(salary) over(order by enroll_date groups between 1 following and 3 following\n+--   exclude group),\n+-- lag(salary) over(order by enroll_date groups between 1 following and 3 following exclude group),\n+-- salary, enroll_date from empsalary;\n+\n+-- Show differences in offset interpretation between ROWS, RANGE, and GROUPS\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 36, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        SELECT * FROM range(1, 36, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- WITH cte (x) AS (\n+--         SELECT * FROM range(1, 36, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 50, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);\n+\n+WITH cte (x) AS (\n+        select 1 union all select 1 union all select 1 union all\n+        SELECT * FROM range(5, 50, 2)\n+)\n+SELECT x, (sum(x) over w)\n+FROM cte\n+WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- WITH cte (x) AS (\n+--         select 1 union all select 1 union all select 1 union all\n+--         SELECT * FROM range(5, 50, 2)\n+-- )\n+-- SELECT x, (sum(x) over w)\n+-- FROM cte\n+-- WINDOW w AS (ORDER BY x groups between 1 preceding and 1 following);\n+\n+-- with UNION\n+\n+SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 UNION ALL SELECT * FROM tenk2)s LIMIT 0;\n+\n+-- check some degenerate cases\n+\n+create table t1 (f1 int, f2 int) using parquet;\n+insert into t1 values (1,1),(1,2),(2,2);\n+\n+select f1, sum(f1) over (partition by f1\n+                         range between 1 preceding and 1 following)\n+from t1 where f1 = f2; -- error, must have order by\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+--                          range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f1 order by f2\n+range between 2 preceding and 1 preceding)\n+from t1 where f1 = f2;\n+\n+select f1, sum(f1) over (partition by f1, f2 order by f2\n+range between 1 following and 2 following)\n+from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1,\n+-- groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- explain\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- range between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1 order by f2\n+-- groups between 1 preceding and 1 following)\n+-- from t1 where f1 = f2;\n+\n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1, f1 order by f2\n+-- groups between 2 preceding and 1 preceding)\n+-- from t1 where f1 = f2;\n+ \n+-- [SPARK-28648] Adds support to `groups` unit type in window clauses\n+-- select f1, sum(f1) over (partition by f1, f2 order by f2\n+-- groups between 1 following and 2 following)\n+-- from t1 where f1 = f2;\n+\n+-- ordering by a non-integer constant is allowed\n+\n+SELECT rank() OVER (ORDER BY length('abc'));\n+\n+-- can't order by another window function\n+-- [SPARK-28566] window functions should not be allowed in window definitions\n+-- SELECT rank() OVER (ORDER BY rank() OVER (ORDER BY random()));\n+\n+-- some other errors\n+SELECT * FROM empsalary WHERE row_number() OVER (ORDER BY salary) < 10;\n+\n+SELECT * FROM empsalary INNER JOIN tenk1 ON row_number() OVER (ORDER BY salary) < 10;\n+\n+SELECT rank() OVER (ORDER BY 1), count(*) FROM empsalary GROUP BY 1;\n+\n+-- Since random() result may change due to seed issues, the behavior is actually unstable\n+SELECT * FROM rank() OVER (ORDER BY random());\n+\n+-- Original query: DELETE FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+SELECT * FROM empsalary WHERE (rank() OVER (ORDER BY random())) > 10;\n+\n+-- Original query: DELETE FROM empsalary RETURNING rank() OVER (ORDER BY random());\n+SELECT * FROM empsalary WHERE rank() OVER (ORDER BY random());\n+\n+-- [SPARK-28645] Throw an error on window redefinition\n+-- select count(*) OVER w FROM tenk1 WINDOW w AS (ORDER BY unique1), w AS (ORDER BY unique1);\n+\n+select rank() OVER (PARTITION BY four, ORDER BY ten) FROM tenk1;\n+\n+-- [SPARK-28646] Allow usage of `count` only for parameterless aggregate function\n+-- select count() OVER () FROM tenk1;\n+\n+-- The output is the expected one: `range` is not a window or aggregate function.\n+SELECT range(1, 100) OVER () FROM empsalary;\n+\n+SELECT ntile(0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- [SPARK-27951] ANSI SQL: NTH_VALUE function\n+-- SELECT nth_value(four, 0) OVER (ORDER BY ten), ten, four FROM tenk1;\n+\n+-- filter\n+\n+-- [SPARK-28500] Adds support for `filter` clause\n+-- SELECT sum(salary), row_number() OVER (ORDER BY depname), sum(\n+--     sum(salary) FILTER (WHERE enroll_date > '2007-01-01')\n+-- )\n+-- FROM empsalary GROUP BY depname;\n+\n+-- Test pushdown of quals into a subquery containing window functions\n+\n+-- pushdown is safe because all PARTITION BY clauses include depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname) depsalary,\n+-- min(salary) OVER (PARTITION BY depname || 'A', depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- pushdown is unsafe because there's a PARTITION BY clause without depname:\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY enroll_date) enroll_salary,\n+-- min(salary) OVER (PARTITION BY depname) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node collapsing\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT * FROM\n+-- (SELECT depname,\n+-- sum(salary) OVER (PARTITION BY depname order by empno) depsalary,\n+-- min(salary) OVER (PARTITION BY depname, empno order by enroll_date) depminsalary\n+-- FROM empsalary) emp\n+-- WHERE depname = 'sales';\n+\n+-- Test Sort node reordering\n+-- Since EXPLAIN clause rely on host physical location, it is commented out\n+-- EXPLAIN\n+-- SELECT\n+-- lead(1) OVER (PARTITION BY depname ORDER BY salary, enroll_date),\n+-- lag(1) OVER (PARTITION BY depname ORDER BY salary,enroll_date,empno)\n+-- FROM empsalary;\n+\n+-- cleanup\n+DROP TABLE empsalary;\n+\n+-- test user-defined window function with named args and default args\n+-- CREATE FUNCTION nth_value_def(val anyelement, n integer = 1) RETURNS anyelement\n+--   LANGUAGE internal WINDOW IMMUTABLE STRICT AS 'window_nth_value';\n+\n+-- SELECT nth_value_def(n := 2, val := ten) OVER (PARTITION BY four), ten, four\n+--   FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten) s;\n+\n+-- SELECT nth_value_def(ten) OVER (PARTITION BY four), ten, four\n+--   FROM (SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten) s;\n+\n+--\n+-- Test the basic moving-aggregate machinery\n+--\n+\n+-- create aggregates that record the series of transform calls (these are\n+-- intentionally not true inverses)\n+\n+-- CREATE FUNCTION logging_sfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT COALESCE($1, '') || '*' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_msfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT COALESCE($1, '') || '+' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_minvfunc_nonstrict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '-' || quote_nullable($2) $$\n+-- LANGUAGE SQL IMMUTABLE;\n+\n+-- CREATE AGGREGATE logging_agg_nonstrict (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_nonstrict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_nonstrict,\n+-- \tminvfunc = logging_minvfunc_nonstrict\n+-- );\n+\n+-- CREATE AGGREGATE logging_agg_nonstrict_initcond (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_nonstrict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_nonstrict,\n+-- \tminvfunc = logging_minvfunc_nonstrict,\n+-- \tinitcond = 'I',\n+-- \tminitcond = 'MI'\n+-- );\n+\n+-- CREATE FUNCTION logging_sfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '*' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_msfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '+' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE FUNCTION logging_minvfunc_strict(text, anyelement) RETURNS text AS\n+-- $$ SELECT $1 || '-' || quote_nullable($2) $$\n+-- LANGUAGE SQL STRICT IMMUTABLE;\n+\n+-- CREATE AGGREGATE logging_agg_strict (text)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_strict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_strict,\n+-- \tminvfunc = logging_minvfunc_strict\n+-- );\n+\n+-- CREATE AGGREGATE logging_agg_strict_initcond (anyelement)\n+-- (\n+-- \tstype = text,\n+-- \tsfunc = logging_sfunc_strict,\n+-- \tmstype = text,\n+-- \tmsfunc = logging_msfunc_strict,\n+-- \tminvfunc = logging_minvfunc_strict,\n+-- \tinitcond = 'I',\n+-- \tminitcond = 'MI'\n+-- );\n+\n+-- test strict and non-strict cases\n+-- SELECT\n+-- \tp::text || ',' || i::text || ':' || COALESCE(v::text, 'NULL') AS row,\n+-- \tlogging_agg_nonstrict(v) over wnd as nstrict,\n+-- \tlogging_agg_nonstrict_initcond(v) over wnd as nstrict_init,\n+-- \tlogging_agg_strict(v::text) over wnd as strict,\n+-- \tlogging_agg_strict_initcond(v) over wnd as strict_init\n+-- FROM (VALUES\n+-- \t(1, 1, NULL),\n+-- \t(1, 2, 'a'),\n+-- \t(1, 3, 'b'),\n+-- \t(1, 4, NULL),\n+-- \t(1, 5, NULL),\n+-- \t(1, 6, 'c'),\n+-- \t(2, 1, NULL),\n+-- \t(2, 2, 'x'),\n+-- \t(3, 1, 'z')\n+-- ) AS t(p, i, v)\n+-- WINDOW wnd AS (PARTITION BY P ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY p, i;\n+\n+-- and again, but with filter\n+-- SELECT\n+-- \tp::text || ',' || i::text || ':' ||\n+-- \t\tCASE WHEN f THEN COALESCE(v::text, 'NULL') ELSE '-' END as row,\n+-- \tlogging_agg_nonstrict(v) filter(where f) over wnd as nstrict_filt,\n+-- \tlogging_agg_nonstrict_initcond(v) filter(where f) over wnd as nstrict_init_filt,\n+-- \tlogging_agg_strict(v::text) filter(where f) over wnd as strict_filt,\n+-- \tlogging_agg_strict_initcond(v) filter(where f) over wnd as strict_init_filt\n+-- FROM (VALUES\n+-- \t(1, 1, true,  NULL),\n+-- \t(1, 2, false, 'a'),\n+-- \t(1, 3, true,  'b'),\n+-- \t(1, 4, false, NULL),\n+-- \t(1, 5, false, NULL),\n+-- \t(1, 6, false, 'c'),\n+-- \t(2, 1, false, NULL),\n+-- \t(2, 2, true,  'x'),\n+-- \t(3, 1, true,  'z')\n+-- ) AS t(p, i, f, v)\n+-- WINDOW wnd AS (PARTITION BY p ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY p, i;\n+\n+-- test that volatile arguments disable moving-aggregate mode\n+-- SELECT\n+-- \ti::text || ':' || COALESCE(v::text, 'NULL') as row,\n+-- \tlogging_agg_strict(v::text)\n+-- \t\tover wnd as inverse,\n+-- \tlogging_agg_strict(v::text || CASE WHEN random() < 0 then '?' ELSE '' END)\n+-- \t\tover wnd as noinverse\n+-- FROM (VALUES\n+-- \t(1, 'a'),\n+-- \t(2, 'b'),\n+-- \t(3, 'c')\n+-- ) AS t(i, v)\n+-- WINDOW wnd AS (ORDER BY i ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)\n+-- ORDER BY i;\n+\n+-- SELECT",
    "line": 1197
  }],
  "prId": 24881
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "`REL_12_BETA2` -> `REL_12_BETA3`. Let's use REL_12_BETA3.",
    "commit": "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "createdAt": "2019-09-04T10:11:37Z",
    "diffHunk": "@@ -0,0 +1,1401 @@\n+-- Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group\n+--\n+-- Window Functions Testing\n+-- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql"
  }],
  "prId": 24881
}]