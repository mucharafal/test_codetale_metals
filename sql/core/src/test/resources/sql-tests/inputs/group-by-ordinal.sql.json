[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Except this line, does this PR fix any other queries? ",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T04:09:21Z",
    "diffHunk": "@@ -52,8 +52,19 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal\n+select 4, b from data group by 1, 2;\n+\n+set spark.sql.groupByOrdinal=true;\n+\n+select 4, b from data group by 1, 2;\n+\n+select 3, 4, sum(b) from data group by 1, 2;"
  }, {
    "author": {
      "login": "10110346"
    },
    "body": "Also, it  fixes this query:`select 3 as c, 4 as d, sum(b) from data group by c, d;`\r\n",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T04:18:05Z",
    "diffHunk": "@@ -52,8 +52,19 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal\n+select 4, b from data group by 1, 2;\n+\n+set spark.sql.groupByOrdinal=true;\n+\n+select 4, b from data group by 1, 2;\n+\n+select 3, 4, sum(b) from data group by 1, 2;"
  }],
  "prId": 18779
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Could you move this line to the line before the line 68",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T04:10:28Z",
    "diffHunk": "@@ -52,8 +52,19 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal"
  }, {
    "author": {
      "login": "10110346"
    },
    "body": "OK,thanks",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T04:19:08Z",
    "diffHunk": "@@ -52,8 +52,19 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal"
  }],
  "prId": 18779
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Can those tests test this bug? No matter I use `transform` or  `resolveOperators`, they generate the same results.",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T04:30:08Z",
    "diffHunk": "@@ -52,8 +52,19 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal\n+select 4, b from data group by 1, 2;\n+\n+set spark.sql.groupByOrdinal=true;\n+\n+select 4, b from data group by 1, 2;\n+\n+select 3, 4, sum(b) from data group by 1, 2;"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Only the methods like `Dataset.show` causes en-entrance of analyzed plans. `collect` won't. I guess the queries here are evaluated with `collect`.\r\n\r\n    scala> sql(\"select 4, b, sum(b) from data group by 1, 2\").show\r\n    org.apache.spark.sql.AnalysisException: GROUP BY position 4 is not in select list (valid range is [1, 3]); line 1 pos 7\r\n\r\n    scala> sql(\"select 4, b, sum(b) from data group by 1, 2\").collect\r\n    res2: Array[org.apache.spark.sql.Row] = Array([4,3,3], [4,4,4], [4,2,2])        \r\n\r\n\r\n",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T04:45:06Z",
    "diffHunk": "@@ -52,8 +52,19 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal\n+select 4, b from data group by 1, 2;\n+\n+set spark.sql.groupByOrdinal=true;\n+\n+select 4, b from data group by 1, 2;\n+\n+select 3, 4, sum(b) from data group by 1, 2;"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "We can move those test queries to other test suites like `DataFrameAggregateSuite`.",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T04:47:31Z",
    "diffHunk": "@@ -52,8 +52,19 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal\n+select 4, b from data group by 1, 2;\n+\n+set spark.sql.groupByOrdinal=true;\n+\n+select 4, b from data group by 1, 2;\n+\n+select 3, 4, sum(b) from data group by 1, 2;"
  }, {
    "author": {
      "login": "10110346"
    },
    "body": "ok, i will do.",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T06:56:46Z",
    "diffHunk": "@@ -52,8 +52,19 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal\n+select 4, b from data group by 1, 2;\n+\n+set spark.sql.groupByOrdinal=true;\n+\n+select 4, b from data group by 1, 2;\n+\n+select 3, 4, sum(b) from data group by 1, 2;"
  }],
  "prId": 18779
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Do we need to add those query tests? They are actually no effect in testing this bug.",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T07:29:32Z",
    "diffHunk": "@@ -52,8 +52,18 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+select 4, b from data group by 1, 2;\n+\n+set spark.sql.groupByOrdinal=true;\n+\n+select 4, b from data group by 1, 2;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal\n+select 3, 4, sum(b) from data group by 1, 2;\n+select 3 as c, 4 as d, sum(b) from data group by c, d;"
  }, {
    "author": {
      "login": "10110346"
    },
    "body": "You mean these test cases are not necessary? I think we need to add",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T07:40:35Z",
    "diffHunk": "@@ -52,8 +52,18 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+select 4, b from data group by 1, 2;\n+\n+set spark.sql.groupByOrdinal=true;\n+\n+select 4, b from data group by 1, 2;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal\n+select 3, 4, sum(b) from data group by 1, 2;\n+select 3 as c, 4 as d, sum(b) from data group by c, d;"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Because I ran them without the change `transform` -> `resolveOperators`, and there is no error. Do you have different result?",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T07:45:23Z",
    "diffHunk": "@@ -52,8 +52,18 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+select 4, b from data group by 1, 2;\n+\n+set spark.sql.groupByOrdinal=true;\n+\n+select 4, b from data group by 1, 2;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal\n+select 3, 4, sum(b) from data group by 1, 2;\n+select 3 as c, 4 as d, sum(b) from data group by c, d;"
  }, {
    "author": {
      "login": "10110346"
    },
    "body": "Oh, I see,thanks. \r\nThey are  not necessary, i will remove  them.\r\nAlso these test cases already exist in the `DataFrameAggregateSuite`.",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T08:06:49Z",
    "diffHunk": "@@ -52,8 +52,18 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+select 4, b from data group by 1, 2;\n+\n+set spark.sql.groupByOrdinal=true;\n+\n+select 4, b from data group by 1, 2;\n+\n+-- SPARK-21580 ints in aggregation expressions are taken as group-by ordinal\n+select 3, 4, sum(b) from data group by 1, 2;\n+select 3 as c, 4 as d, sum(b) from data group by c, d;"
  }],
  "prId": 18779
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Why do we need to have change like this? ",
    "commit": "2bf42b11cec794d19ed8f2fd000a9cd7aeb159bb",
    "createdAt": "2017-08-04T09:30:28Z",
    "diffHunk": "@@ -52,8 +52,14 @@ select count(a), a from (select 1 as a) tmp group by 2 having a > 0;\n -- mixed cases: group-by ordinals and aliases\n select a, a AS k, count(b) from data group by k, 1;\n \n--- turn of group by ordinal\n+-- turn off group by ordinal\n set spark.sql.groupByOrdinal=false;\n \n -- can now group by negative literal\n select sum(b) from data group by -1;\n+\n+select 4, b from data group by 1, 2;\n+\n+set spark.sql.groupByOrdinal=true;\n+\n+select 4, b from data group by 1, 2;"
  }],
  "prId": 18779
}]