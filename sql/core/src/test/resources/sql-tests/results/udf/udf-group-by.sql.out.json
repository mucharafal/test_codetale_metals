[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "There seems a typo here `udf(some(v),`",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-18T10:54:32Z",
    "diffHunk": "@@ -0,0 +1,528 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)\n+-- !query 12 schema\n+struct<>\n+-- !query 12 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 13\n+SELECT SKEWNESS(udf(a)), udf(KURTOSIS(a)), udf(MIN(a)), MAX(udf(a)), udf(AVG(udf(a))), udf(VARIANCE(a)), STDDEV(udf(a)), udf(SUM(a)), udf(COUNT(a))\n+FROM testData\n+-- !query 13 schema\n+struct<skewness(CAST(CAST(udf(cast(a as string)) AS INT) AS DOUBLE)):double,CAST(udf(cast(kurtosis(cast(a as double)) as string)) AS DOUBLE):double,CAST(udf(cast(min(a) as string)) AS INT):int,max(CAST(udf(cast(a as string)) AS INT)):int,CAST(udf(cast(avg(cast(cast(udf(cast(a as string)) as int) as bigint)) as string)) AS DOUBLE):double,CAST(udf(cast(var_samp(cast(a as double)) as string)) AS DOUBLE):double,stddev_samp(CAST(CAST(udf(cast(a as string)) AS INT) AS DOUBLE)):double,CAST(udf(cast(sum(cast(a as bigint)) as string)) AS BIGINT):bigint,CAST(udf(cast(count(a) as string)) AS BIGINT):bigint>\n+-- !query 13 output\n+-0.2723801058145729\t-1.5069204152249134\t1\t3\t2.142857142857143\t0.8095238095238094\t0.8997354108424372\t15\t7\n+\n+\n+-- !query 14\n+SELECT COUNT(DISTINCT udf(b)), udf(COUNT(DISTINCT b, c)) FROM (SELECT 1 AS a, 2 AS b, 3 AS c) GROUP BY a\n+-- !query 14 schema\n+struct<count(DISTINCT CAST(udf(cast(b as string)) AS INT)):bigint,CAST(udf(cast(count(distinct b, c) as string)) AS BIGINT):bigint>\n+-- !query 14 output\n+1\t1\n+\n+\n+-- !query 15\n+SELECT a AS k, COUNT(udf(b)) FROM testData GROUP BY k\n+-- !query 15 schema\n+struct<k:int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 15 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 16\n+SELECT a AS k, udf(COUNT(b)) FROM testData GROUP BY k HAVING k > 1\n+-- !query 16 schema\n+struct<k:int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 16 output\n+2\t2\n+3\t2\n+\n+\n+-- !query 17\n+SELECT udf(COUNT(b)) AS k FROM testData GROUP BY k\n+-- !query 17 schema\n+struct<>\n+-- !query 17 output\n+org.apache.spark.sql.AnalysisException\n+aggregate functions are not allowed in GROUP BY, but found CAST(udf(cast(count(b) as string)) AS BIGINT);\n+\n+\n+-- !query 18\n+CREATE OR REPLACE TEMPORARY VIEW testDataHasSameNameWithAlias AS SELECT * FROM VALUES\n+(1, 1, 3), (1, 2, 1) AS testDataHasSameNameWithAlias(k, a, v)\n+-- !query 18 schema\n+struct<>\n+-- !query 18 output\n+\n+\n+\n+-- !query 19\n+SELECT k AS a, udf(COUNT(udf(v))) FROM testDataHasSameNameWithAlias GROUP BY a\n+-- !query 19 schema\n+struct<>\n+-- !query 19 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdatahassamenamewithalias.`k`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 20\n+set spark.sql.groupByAliases=false\n+-- !query 20 schema\n+struct<key:string,value:string>\n+-- !query 20 output\n+spark.sql.groupByAliases\tfalse\n+\n+\n+-- !query 21\n+SELECT a AS k, udf(COUNT(udf(b))) FROM testData GROUP BY k\n+-- !query 21 schema\n+struct<>\n+-- !query 21 output\n+org.apache.spark.sql.AnalysisException\n+cannot resolve '`k`' given input columns: [testdata.a, testdata.b]; line 1 pos 57\n+\n+\n+-- !query 22\n+SELECT a, COUNT(udf(1)) FROM testData WHERE false GROUP BY a\n+-- !query 22 schema\n+struct<a:int,count(CAST(udf(cast(1 as string)) AS INT)):bigint>\n+-- !query 22 output\n+\n+\n+\n+-- !query 23\n+SELECT udf(COUNT(1)) FROM testData WHERE false\n+-- !query 23 schema\n+struct<CAST(udf(cast(count(1) as string)) AS BIGINT):bigint>\n+-- !query 23 output\n+0\n+\n+\n+-- !query 24\n+SELECT 1 FROM (SELECT udf(COUNT(1)) FROM testData WHERE false) t\n+-- !query 24 schema\n+struct<1:int>\n+-- !query 24 output\n+1\n+\n+\n+-- !query 25\n+SELECT 1 from (\n+  SELECT 1 AS z,\n+  udf(MIN(a.x))\n+  FROM (select 1 as x) a\n+  WHERE false\n+) b\n+where b.z != b.z\n+-- !query 25 schema\n+struct<1:int>\n+-- !query 25 output\n+\n+\n+\n+-- !query 26\n+SELECT corr(DISTINCT x, y), udf(corr(DISTINCT y, x)), count(*)\n+  FROM (VALUES (1, 1), (2, 2), (2, 2)) t(x, y)\n+-- !query 26 schema\n+struct<corr(DISTINCT CAST(x AS DOUBLE), CAST(y AS DOUBLE)):double,CAST(udf(cast(corr(distinct cast(y as double), cast(x as double)) as string)) AS DOUBLE):double,count(1):bigint>\n+-- !query 26 output\n+1.0\t1.0\t3\n+\n+\n+-- !query 27\n+SELECT udf(1) FROM range(10) HAVING true\n+-- !query 27 schema\n+struct<CAST(udf(cast(1 as string)) AS INT):int>\n+-- !query 27 output\n+1\n+\n+\n+-- !query 28\n+SELECT udf(udf(1)) FROM range(10) HAVING MAX(id) > 0\n+-- !query 28 schema\n+struct<CAST(udf(cast(cast(udf(cast(1 as string)) as int) as string)) AS INT):int>\n+-- !query 28 output\n+1\n+\n+\n+-- !query 29\n+SELECT udf(id) FROM range(10) HAVING id > 0\n+-- !query 29 schema\n+struct<>\n+-- !query 29 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and '`id`' is not an aggregate function. Wrap '()' in windowing function(s) or wrap '`id`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 30\n+CREATE OR REPLACE TEMPORARY VIEW test_agg AS SELECT * FROM VALUES\n+  (1, true), (1, false),\n+  (2, true),\n+  (3, false), (3, null),\n+  (4, null), (4, null),\n+  (5, null), (5, true), (5, false) AS test_agg(k, v)\n+-- !query 30 schema\n+struct<>\n+-- !query 30 output\n+\n+\n+\n+-- !query 31\n+SELECT udf(every(v)), udf(some(v)), any(v) FROM test_agg WHERE 1 = 0\n+-- !query 31 schema\n+struct<CAST(udf(cast(every(v) as string)) AS BOOLEAN):boolean,CAST(udf(cast(some(v) as string)) AS BOOLEAN):boolean,any(v):boolean>\n+-- !query 31 output\n+NULL\tNULL\tNULL\n+\n+\n+-- !query 32\n+SELECT udf(every(udf(v))), some(v), any(v) FROM test_agg WHERE k = 4\n+-- !query 32 schema\n+struct<CAST(udf(cast(every(cast(udf(cast(v as string)) as boolean)) as string)) AS BOOLEAN):boolean,some(v):boolean,any(v):boolean>\n+-- !query 32 output\n+NULL\tNULL\tNULL\n+\n+\n+-- !query 33\n+SELECT every(v), udf(some(v), any(v) FROM test_agg WHERE k = 5\n+-- !query 33 schema\n+struct<>\n+-- !query 33 output\n+org.apache.spark.sql.catalyst.parser.ParseException\n+\n+extraneous input 'FROM' expecting {')', ','}(line 1, pos 37)\n+\n+== SQL ==\n+SELECT every(v), udf(some(v), any(v) FROM test_agg WHERE k = 5"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "weird it passed locally. will fix.",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-18T10:55:17Z",
    "diffHunk": "@@ -0,0 +1,528 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)\n+-- !query 12 schema\n+struct<>\n+-- !query 12 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 13\n+SELECT SKEWNESS(udf(a)), udf(KURTOSIS(a)), udf(MIN(a)), MAX(udf(a)), udf(AVG(udf(a))), udf(VARIANCE(a)), STDDEV(udf(a)), udf(SUM(a)), udf(COUNT(a))\n+FROM testData\n+-- !query 13 schema\n+struct<skewness(CAST(CAST(udf(cast(a as string)) AS INT) AS DOUBLE)):double,CAST(udf(cast(kurtosis(cast(a as double)) as string)) AS DOUBLE):double,CAST(udf(cast(min(a) as string)) AS INT):int,max(CAST(udf(cast(a as string)) AS INT)):int,CAST(udf(cast(avg(cast(cast(udf(cast(a as string)) as int) as bigint)) as string)) AS DOUBLE):double,CAST(udf(cast(var_samp(cast(a as double)) as string)) AS DOUBLE):double,stddev_samp(CAST(CAST(udf(cast(a as string)) AS INT) AS DOUBLE)):double,CAST(udf(cast(sum(cast(a as bigint)) as string)) AS BIGINT):bigint,CAST(udf(cast(count(a) as string)) AS BIGINT):bigint>\n+-- !query 13 output\n+-0.2723801058145729\t-1.5069204152249134\t1\t3\t2.142857142857143\t0.8095238095238094\t0.8997354108424372\t15\t7\n+\n+\n+-- !query 14\n+SELECT COUNT(DISTINCT udf(b)), udf(COUNT(DISTINCT b, c)) FROM (SELECT 1 AS a, 2 AS b, 3 AS c) GROUP BY a\n+-- !query 14 schema\n+struct<count(DISTINCT CAST(udf(cast(b as string)) AS INT)):bigint,CAST(udf(cast(count(distinct b, c) as string)) AS BIGINT):bigint>\n+-- !query 14 output\n+1\t1\n+\n+\n+-- !query 15\n+SELECT a AS k, COUNT(udf(b)) FROM testData GROUP BY k\n+-- !query 15 schema\n+struct<k:int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 15 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 16\n+SELECT a AS k, udf(COUNT(b)) FROM testData GROUP BY k HAVING k > 1\n+-- !query 16 schema\n+struct<k:int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 16 output\n+2\t2\n+3\t2\n+\n+\n+-- !query 17\n+SELECT udf(COUNT(b)) AS k FROM testData GROUP BY k\n+-- !query 17 schema\n+struct<>\n+-- !query 17 output\n+org.apache.spark.sql.AnalysisException\n+aggregate functions are not allowed in GROUP BY, but found CAST(udf(cast(count(b) as string)) AS BIGINT);\n+\n+\n+-- !query 18\n+CREATE OR REPLACE TEMPORARY VIEW testDataHasSameNameWithAlias AS SELECT * FROM VALUES\n+(1, 1, 3), (1, 2, 1) AS testDataHasSameNameWithAlias(k, a, v)\n+-- !query 18 schema\n+struct<>\n+-- !query 18 output\n+\n+\n+\n+-- !query 19\n+SELECT k AS a, udf(COUNT(udf(v))) FROM testDataHasSameNameWithAlias GROUP BY a\n+-- !query 19 schema\n+struct<>\n+-- !query 19 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdatahassamenamewithalias.`k`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 20\n+set spark.sql.groupByAliases=false\n+-- !query 20 schema\n+struct<key:string,value:string>\n+-- !query 20 output\n+spark.sql.groupByAliases\tfalse\n+\n+\n+-- !query 21\n+SELECT a AS k, udf(COUNT(udf(b))) FROM testData GROUP BY k\n+-- !query 21 schema\n+struct<>\n+-- !query 21 output\n+org.apache.spark.sql.AnalysisException\n+cannot resolve '`k`' given input columns: [testdata.a, testdata.b]; line 1 pos 57\n+\n+\n+-- !query 22\n+SELECT a, COUNT(udf(1)) FROM testData WHERE false GROUP BY a\n+-- !query 22 schema\n+struct<a:int,count(CAST(udf(cast(1 as string)) AS INT)):bigint>\n+-- !query 22 output\n+\n+\n+\n+-- !query 23\n+SELECT udf(COUNT(1)) FROM testData WHERE false\n+-- !query 23 schema\n+struct<CAST(udf(cast(count(1) as string)) AS BIGINT):bigint>\n+-- !query 23 output\n+0\n+\n+\n+-- !query 24\n+SELECT 1 FROM (SELECT udf(COUNT(1)) FROM testData WHERE false) t\n+-- !query 24 schema\n+struct<1:int>\n+-- !query 24 output\n+1\n+\n+\n+-- !query 25\n+SELECT 1 from (\n+  SELECT 1 AS z,\n+  udf(MIN(a.x))\n+  FROM (select 1 as x) a\n+  WHERE false\n+) b\n+where b.z != b.z\n+-- !query 25 schema\n+struct<1:int>\n+-- !query 25 output\n+\n+\n+\n+-- !query 26\n+SELECT corr(DISTINCT x, y), udf(corr(DISTINCT y, x)), count(*)\n+  FROM (VALUES (1, 1), (2, 2), (2, 2)) t(x, y)\n+-- !query 26 schema\n+struct<corr(DISTINCT CAST(x AS DOUBLE), CAST(y AS DOUBLE)):double,CAST(udf(cast(corr(distinct cast(y as double), cast(x as double)) as string)) AS DOUBLE):double,count(1):bigint>\n+-- !query 26 output\n+1.0\t1.0\t3\n+\n+\n+-- !query 27\n+SELECT udf(1) FROM range(10) HAVING true\n+-- !query 27 schema\n+struct<CAST(udf(cast(1 as string)) AS INT):int>\n+-- !query 27 output\n+1\n+\n+\n+-- !query 28\n+SELECT udf(udf(1)) FROM range(10) HAVING MAX(id) > 0\n+-- !query 28 schema\n+struct<CAST(udf(cast(cast(udf(cast(1 as string)) as int) as string)) AS INT):int>\n+-- !query 28 output\n+1\n+\n+\n+-- !query 29\n+SELECT udf(id) FROM range(10) HAVING id > 0\n+-- !query 29 schema\n+struct<>\n+-- !query 29 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and '`id`' is not an aggregate function. Wrap '()' in windowing function(s) or wrap '`id`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 30\n+CREATE OR REPLACE TEMPORARY VIEW test_agg AS SELECT * FROM VALUES\n+  (1, true), (1, false),\n+  (2, true),\n+  (3, false), (3, null),\n+  (4, null), (4, null),\n+  (5, null), (5, true), (5, false) AS test_agg(k, v)\n+-- !query 30 schema\n+struct<>\n+-- !query 30 output\n+\n+\n+\n+-- !query 31\n+SELECT udf(every(v)), udf(some(v)), any(v) FROM test_agg WHERE 1 = 0\n+-- !query 31 schema\n+struct<CAST(udf(cast(every(v) as string)) AS BOOLEAN):boolean,CAST(udf(cast(some(v) as string)) AS BOOLEAN):boolean,any(v):boolean>\n+-- !query 31 output\n+NULL\tNULL\tNULL\n+\n+\n+-- !query 32\n+SELECT udf(every(udf(v))), some(v), any(v) FROM test_agg WHERE k = 4\n+-- !query 32 schema\n+struct<CAST(udf(cast(every(cast(udf(cast(v as string)) as boolean)) as string)) AS BOOLEAN):boolean,some(v):boolean,any(v):boolean>\n+-- !query 32 output\n+NULL\tNULL\tNULL\n+\n+\n+-- !query 33\n+SELECT every(v), udf(some(v), any(v) FROM test_agg WHERE k = 5\n+-- !query 33 schema\n+struct<>\n+-- !query 33 output\n+org.apache.spark.sql.catalyst.parser.ParseException\n+\n+extraneous input 'FROM' expecting {')', ','}(line 1, pos 37)\n+\n+== SQL ==\n+SELECT every(v), udf(some(v), any(v) FROM test_agg WHERE k = 5"
  }],
  "prId": 25098
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Following original group-by.sql, I think this should be `SELECT udf(a + 1) + 1, udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)`?",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-18T14:21:49Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Yeah it could be, both should work though.",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-18T14:25:03Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Since this query is grouping by `udf(a + 1)`, `udf(a + 1 + 1)` is an expression the analyzer will complain about. (an AnalysisException)",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-18T14:45:11Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "yes you are right.. its based on group value. Will change it.",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-18T15:05:52Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "@viirya @HyukjinKwon  If I do that scala udf will generate:\r\n```\r\n SELECT udf(a + 1) + 1, udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)\r\n -- !query 12 schema\r\n-struct<>\r\n+struct<(CAST(udf(cast((a + 1) as string)) AS INT) + 1):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\r\n -- !query 12 output\r\n-org.apache.spark.sql.AnalysisException\r\n-expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\r\n+3      2\r\n+4      2\r\n+5      2\r\n+NULL   1\r\n```\r\nbut then python and pandas udfs will fail with that exception and will over-write the generated file. So then next time I run without `SPARK_GENERATE_GOLDEN_FILES=1` scala tests will fail. This does not look good from a first glance. I will try test it outside tests in spark shell.",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-18T15:34:13Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "here is the output:\r\n```\r\nUsing Python version 2.7.15+ (default, Nov 27 2018 23:36:35)\r\nSparkSession available as 'spark'.\r\n>>> from pyspark.sql.functions import pandas_udf, PandasUDFType\r\n>>> @pandas_udf(\"string\", PandasUDFType.SCALAR)\r\n... def noop(x):\r\n...     return x.apply(str)\r\n... \r\n\r\n>>> spark.udf.register(\"udf\", noop)\r\n<function noop at 0x7ff7ea465b90>\r\n>>> spark.sql(\"CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES (1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null) AS testData(a, b)\")\r\n\r\nDataFrame[]\r\n>>> \r\n>>> spark.sql(\"SELECT udf(a + 1) + 1, udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)\")\r\n19/07/18 18:41:12 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \".../spark/spark-3.0.0-SNAPSHOT-bin-lightbend/python/pyspark/sql/session.py\", line 806, in sql\r\n    return DataFrame(self._jsparkSession.sql(sqlQuery), self._wrapped)\r\n  File \".../spark/spark-3.0.0-SNAPSHOT-bin-lightbend/python/lib/py4j-0.10.8.1-src.zip/py4j/java_gateway.py\", line 1286, in __call__\r\n  File \"...spark/spark-3.0.0-SNAPSHOT-bin-lightbend/python/pyspark/sql/utils.py\", line 93, in deco\r\n    raise converted\r\npyspark.sql.utils.AnalysisException: u\"expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;;\\nAggregate [udf((a#0 + 1))], [(cast(udf((a#0 + 1)) as double) + cast(1 as double)) AS (CAST(udf((a + 1)) AS DOUBLE) + CAST(1 AS DOUBLE))#6, udf(count(b#1)) AS udf(count(b))#7]\\n+- SubqueryAlias `testdata`\\n   +- Project [a#0, b#1]\\n      +- SubqueryAlias `testData`\\n         +- LocalRelation [a#0, b#1]\\n\"\r\n```",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-18T15:41:31Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Let's comment the test with some comments that explains this.",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-19T01:53:28Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "@HyukjinKwon I added the comment, however is this expected behavior? It looks like a bug/inconsistency between udfs, should we investigate it further?",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-19T10:15:40Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Yes, let's skip, file a JIRA with some reproducers. I also tested by myself. feel free to copy and paste this in the new JIRA:\r\n\r\nPython:\r\n\r\n```python\r\nfrom pyspark.sql.functions import pandas_udf, PandasUDFType\r\n\r\n@pandas_udf(\"int\", PandasUDFType.SCALAR)\r\ndef noop(x):\r\n    return x\r\n\r\nspark.udf.register(\"udf\", noop)\r\n\r\nsql(\"\"\"\r\n  CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\r\n  (1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\r\n  AS testData(a, b)\"\"\")\r\n\r\nsql(\"\"\"SELECT udf(a + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)\"\"\").show()\r\n```\r\n\r\n```\r\n: org.apache.spark.sql.AnalysisException: expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;;\r\nAggregate [udf((a#0 + 1))], [udf((a#0 + 1)) AS udf((a + 1))#10, udf(count(b#1)) AS udf(count(b))#12]\r\n+- SubqueryAlias `testdata`\r\n   +- Project [a#0, b#1]\r\n      +- SubqueryAlias `testData`\r\n         +- LocalRelation [a#0, b#1]\r\n```\r\n\r\nScala:\r\n\r\n```scala\r\nspark.udf.register(\"udf\", (input: Int) => input)\r\n\r\nsql(\"\"\"\r\n  CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\r\n  (1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\r\n  AS testData(a, b)\"\"\")\r\n\r\nsql(\"\"\"SELECT udf(a + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)\"\"\").show()\r\n```\r\n\r\n```\r\n+------------+-------------+\r\n|udf((a + 1))|udf(count(b))|\r\n+------------+-------------+\r\n|        null|            1|\r\n|           3|            2|\r\n|           4|            2|\r\n|           2|            2|\r\n+------------+-------------+\r\n```\r\n\r\nLet's skip the tests here with some comments that links the new JIRA, and merge this one first.",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-19T11:17:30Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Here's one example when I met such case.",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-19T11:20:41Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Cool I will create the jira thanks and will update the comment pointing to the jira.",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-19T11:28:13Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "oops, I mean here is the example: https://github.com/apache/spark/blob/master/sql/core/src/test/resources/sql-tests/inputs/udf/pgSQL/udf-aggregates_part1.sql#L65-L67",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-19T11:34:28Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "@HyukjinKwon [Jira](https://issues.apache.org/jira/browse/SPARK-28445), also added a pointer to it in the comment.",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-19T12:08:23Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Submitted #25215 to fix it.",
    "commit": "9dc5aa12cfd0783fb75876611bad4bb054a6d819",
    "createdAt": "2019-07-22T00:55:00Z",
    "diffHunk": "@@ -0,0 +1,521 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 52\n+\n+\n+-- !query 0\n+CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES\n+(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)\n+AS testData(a, b)\n+-- !query 0 schema\n+struct<>\n+-- !query 0 output\n+\n+\n+\n+-- !query 1\n+SELECT udf(a), udf(COUNT(b)) FROM testData\n+-- !query 1 schema\n+struct<>\n+-- !query 1 output\n+org.apache.spark.sql.AnalysisException\n+grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(CAST(udf(cast(count(b) as string)) AS BIGINT) AS `CAST(udf(cast(count(b) as string)) AS BIGINT)`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 2\n+SELECT COUNT(udf(a)), udf(COUNT(b)) FROM testData\n+-- !query 2 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 2 output\n+7\t7\n+\n+\n+-- !query 3\n+SELECT udf(a), COUNT(udf(b)) FROM testData GROUP BY a\n+-- !query 3 schema\n+struct<CAST(udf(cast(a as string)) AS INT):int,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 3 output\n+1\t2\n+2\t2\n+3\t2\n+NULL\t1\n+\n+\n+-- !query 4\n+SELECT udf(a), udf(COUNT(udf(b))) FROM testData GROUP BY b\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 5\n+SELECT COUNT(udf(a)), COUNT(udf(b)) FROM testData GROUP BY udf(a)\n+-- !query 5 schema\n+struct<count(CAST(udf(cast(a as string)) AS INT)):bigint,count(CAST(udf(cast(b as string)) AS INT)):bigint>\n+-- !query 5 output\n+0\t1\n+2\t2\n+2\t2\n+3\t2\n+\n+\n+-- !query 6\n+SELECT 'foo', COUNT(udf(a)) FROM testData GROUP BY 1\n+-- !query 6 schema\n+struct<foo:string,count(CAST(udf(cast(a as string)) AS INT)):bigint>\n+-- !query 6 output\n+foo\t7\n+\n+\n+-- !query 7\n+SELECT 'foo' FROM testData WHERE a = 0 GROUP BY udf(1)\n+-- !query 7 schema\n+struct<foo:string>\n+-- !query 7 output\n+\n+\n+\n+-- !query 8\n+SELECT 'foo', udf(APPROX_COUNT_DISTINCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 8 schema\n+struct<foo:string,CAST(udf(cast(approx_count_distinct(cast(udf(cast(a as string)) as int), 0.05, 0, 0) as string)) AS BIGINT):bigint>\n+-- !query 8 output\n+\n+\n+\n+-- !query 9\n+SELECT 'foo', MAX(STRUCT(udf(a))) FROM testData WHERE a = 0 GROUP BY 1\n+-- !query 9 schema\n+struct<foo:string,max(named_struct(col1, CAST(udf(cast(a as string)) AS INT))):struct<col1:int>>\n+-- !query 9 output\n+\n+\n+\n+-- !query 10\n+SELECT udf(a + b), udf(COUNT(b)) FROM testData GROUP BY a + b\n+-- !query 10 schema\n+struct<CAST(udf(cast((a + b) as string)) AS INT):int,CAST(udf(cast(count(b) as string)) AS BIGINT):bigint>\n+-- !query 10 output\n+2\t1\n+3\t2\n+4\t2\n+5\t1\n+NULL\t1\n+\n+\n+-- !query 11\n+SELECT udf(a + 2), udf(COUNT(b)) FROM testData GROUP BY a + 1\n+-- !query 11 schema\n+struct<>\n+-- !query 11 output\n+org.apache.spark.sql.AnalysisException\n+expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\n+\n+\n+-- !query 12\n+SELECT udf(a + 1 + 1), udf(COUNT(b)) FROM testData GROUP BY udf(a + 1)"
  }],
  "prId": 25098
}]