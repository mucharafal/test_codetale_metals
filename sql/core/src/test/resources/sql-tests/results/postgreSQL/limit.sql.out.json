[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "The following is the original, @maropu .\r\n```\r\nselect sum(tenthous) as s1, sum(tenthous) + random()*0 as s2\r\n  from tenk1 group by thousand order by thousand limit 3;\r\n  s1   |  s2   \r\n-------+-------\r\n 45000 | 45000\r\n 45010 | 45010\r\n 45020 | 45020\r\n(3 rows)\r\n```",
    "commit": "3abbe57b6d85c6794c0598b3a22324fb0e0a4bec",
    "createdAt": "2019-11-05T05:41:18Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 7\n+\n+\n+-- !query 0\n+SELECT '' AS two, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 50\n+\t\tORDER BY unique1 LIMIT 2\n+-- !query 0 schema\n+struct<two:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 0 output\n+\t51\t76\tZBAAAA\n+\t52\t985\tACAAAA\n+\n+\n+-- !query 1\n+SELECT '' AS five, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 60\n+\t\tORDER BY unique1 LIMIT 5\n+-- !query 1 schema\n+struct<five:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 1 output\n+\t61\t560\tJCAAAA\n+\t62\t633\tKCAAAA\n+\t63\t296\tLCAAAA\n+\t64\t479\tMCAAAA\n+\t65\t64\tNCAAAA\n+\n+\n+-- !query 2\n+SELECT '' AS two, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 60 AND unique1 < 63\n+\t\tORDER BY unique1 LIMIT 5\n+-- !query 2 schema\n+struct<two:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 2 output\n+\t61\t560\tJCAAAA\n+\t62\t633\tKCAAAA\n+\n+\n+-- !query 3\n+CREATE OR REPLACE TEMPORARY VIEW INT8_TBL AS SELECT * FROM\n+  (VALUES\n+    (123, 456),\n+    (123, 4567890123456789),\n+    (4567890123456789, 123),\n+    (4567890123456789, 4567890123456789),\n+    (4567890123456789, -4567890123456789))\n+  AS v(q1, q2)\n+-- !query 3 schema\n+struct<>\n+-- !query 3 output\n+\n+\n+\n+-- !query 4\n+select * from int8_tbl limit (case when random() < 0.5 then bigint(null) end)\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+The limit expression must evaluate to a constant value, but got CASE WHEN (`_nondeterministic` < CAST(0.5BD AS DOUBLE)) THEN CAST(NULL AS BIGINT) END;\n+\n+\n+-- !query 5\n+DROP VIEW INT8_TBL\n+-- !query 5 schema\n+struct<>\n+-- !query 5 output\n+\n+\n+\n+-- !query 6\n+select sum(tenthous) as s1, sum(tenthous) + random()*0 as s2\n+  from tenk1 group by thousand order by thousand limit 3\n+-- !query 6 schema\n+struct<s1:bigint,s2:double>\n+-- !query 6 output\n+45000\t45000.0\n+45010\t45010.0\n+45020\t45020.0",
    "line": 81
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "You meant `45000` is different from `45000.0`, right (I might misunderstand your point though)? In pgSQL, `.0` is trimmed in printing;\r\n```\r\npostgres=# create table t(d float8);\r\nCREATE TABLE\r\npostgres=# insert into t values (3.0);\r\nINSERT 0 1\r\npostgres=# select * from t;\r\n d \r\n---\r\n 3\r\n(1 row)\r\n```",
    "commit": "3abbe57b6d85c6794c0598b3a22324fb0e0a4bec",
    "createdAt": "2019-11-05T05:55:44Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 7\n+\n+\n+-- !query 0\n+SELECT '' AS two, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 50\n+\t\tORDER BY unique1 LIMIT 2\n+-- !query 0 schema\n+struct<two:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 0 output\n+\t51\t76\tZBAAAA\n+\t52\t985\tACAAAA\n+\n+\n+-- !query 1\n+SELECT '' AS five, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 60\n+\t\tORDER BY unique1 LIMIT 5\n+-- !query 1 schema\n+struct<five:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 1 output\n+\t61\t560\tJCAAAA\n+\t62\t633\tKCAAAA\n+\t63\t296\tLCAAAA\n+\t64\t479\tMCAAAA\n+\t65\t64\tNCAAAA\n+\n+\n+-- !query 2\n+SELECT '' AS two, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 60 AND unique1 < 63\n+\t\tORDER BY unique1 LIMIT 5\n+-- !query 2 schema\n+struct<two:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 2 output\n+\t61\t560\tJCAAAA\n+\t62\t633\tKCAAAA\n+\n+\n+-- !query 3\n+CREATE OR REPLACE TEMPORARY VIEW INT8_TBL AS SELECT * FROM\n+  (VALUES\n+    (123, 456),\n+    (123, 4567890123456789),\n+    (4567890123456789, 123),\n+    (4567890123456789, 4567890123456789),\n+    (4567890123456789, -4567890123456789))\n+  AS v(q1, q2)\n+-- !query 3 schema\n+struct<>\n+-- !query 3 output\n+\n+\n+\n+-- !query 4\n+select * from int8_tbl limit (case when random() < 0.5 then bigint(null) end)\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+The limit expression must evaluate to a constant value, but got CASE WHEN (`_nondeterministic` < CAST(0.5BD AS DOUBLE)) THEN CAST(NULL AS BIGINT) END;\n+\n+\n+-- !query 5\n+DROP VIEW INT8_TBL\n+-- !query 5 schema\n+struct<>\n+-- !query 5 output\n+\n+\n+\n+-- !query 6\n+select sum(tenthous) as s1, sum(tenthous) + random()*0 as s2\n+  from tenk1 group by thousand order by thousand limit 3\n+-- !query 6 schema\n+struct<s1:bigint,s2:double>\n+-- !query 6 output\n+45000\t45000.0\n+45010\t45010.0\n+45020\t45020.0",
    "line": 81
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Got it. My bad. Thank you for the explanation. I was confused.",
    "commit": "3abbe57b6d85c6794c0598b3a22324fb0e0a4bec",
    "createdAt": "2019-11-05T06:11:26Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 7\n+\n+\n+-- !query 0\n+SELECT '' AS two, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 50\n+\t\tORDER BY unique1 LIMIT 2\n+-- !query 0 schema\n+struct<two:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 0 output\n+\t51\t76\tZBAAAA\n+\t52\t985\tACAAAA\n+\n+\n+-- !query 1\n+SELECT '' AS five, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 60\n+\t\tORDER BY unique1 LIMIT 5\n+-- !query 1 schema\n+struct<five:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 1 output\n+\t61\t560\tJCAAAA\n+\t62\t633\tKCAAAA\n+\t63\t296\tLCAAAA\n+\t64\t479\tMCAAAA\n+\t65\t64\tNCAAAA\n+\n+\n+-- !query 2\n+SELECT '' AS two, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 60 AND unique1 < 63\n+\t\tORDER BY unique1 LIMIT 5\n+-- !query 2 schema\n+struct<two:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 2 output\n+\t61\t560\tJCAAAA\n+\t62\t633\tKCAAAA\n+\n+\n+-- !query 3\n+CREATE OR REPLACE TEMPORARY VIEW INT8_TBL AS SELECT * FROM\n+  (VALUES\n+    (123, 456),\n+    (123, 4567890123456789),\n+    (4567890123456789, 123),\n+    (4567890123456789, 4567890123456789),\n+    (4567890123456789, -4567890123456789))\n+  AS v(q1, q2)\n+-- !query 3 schema\n+struct<>\n+-- !query 3 output\n+\n+\n+\n+-- !query 4\n+select * from int8_tbl limit (case when random() < 0.5 then bigint(null) end)\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+The limit expression must evaluate to a constant value, but got CASE WHEN (`_nondeterministic` < CAST(0.5BD AS DOUBLE)) THEN CAST(NULL AS BIGINT) END;\n+\n+\n+-- !query 5\n+DROP VIEW INT8_TBL\n+-- !query 5 schema\n+struct<>\n+-- !query 5 output\n+\n+\n+\n+-- !query 6\n+select sum(tenthous) as s1, sum(tenthous) + random()*0 as s2\n+  from tenk1 group by thousand order by thousand limit 3\n+-- !query 6 schema\n+struct<s1:bigint,s2:double>\n+-- !query 6 output\n+45000\t45000.0\n+45010\t45010.0\n+45020\t45020.0",
    "line": 81
  }, {
    "author": {
      "login": "maropu"
    },
    "body": "Yea, thanks for your check~",
    "commit": "3abbe57b6d85c6794c0598b3a22324fb0e0a4bec",
    "createdAt": "2019-11-05T06:12:43Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 7\n+\n+\n+-- !query 0\n+SELECT '' AS two, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 50\n+\t\tORDER BY unique1 LIMIT 2\n+-- !query 0 schema\n+struct<two:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 0 output\n+\t51\t76\tZBAAAA\n+\t52\t985\tACAAAA\n+\n+\n+-- !query 1\n+SELECT '' AS five, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 60\n+\t\tORDER BY unique1 LIMIT 5\n+-- !query 1 schema\n+struct<five:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 1 output\n+\t61\t560\tJCAAAA\n+\t62\t633\tKCAAAA\n+\t63\t296\tLCAAAA\n+\t64\t479\tMCAAAA\n+\t65\t64\tNCAAAA\n+\n+\n+-- !query 2\n+SELECT '' AS two, unique1, unique2, stringu1\n+\t\tFROM onek WHERE unique1 > 60 AND unique1 < 63\n+\t\tORDER BY unique1 LIMIT 5\n+-- !query 2 schema\n+struct<two:string,unique1:int,unique2:int,stringu1:string>\n+-- !query 2 output\n+\t61\t560\tJCAAAA\n+\t62\t633\tKCAAAA\n+\n+\n+-- !query 3\n+CREATE OR REPLACE TEMPORARY VIEW INT8_TBL AS SELECT * FROM\n+  (VALUES\n+    (123, 456),\n+    (123, 4567890123456789),\n+    (4567890123456789, 123),\n+    (4567890123456789, 4567890123456789),\n+    (4567890123456789, -4567890123456789))\n+  AS v(q1, q2)\n+-- !query 3 schema\n+struct<>\n+-- !query 3 output\n+\n+\n+\n+-- !query 4\n+select * from int8_tbl limit (case when random() < 0.5 then bigint(null) end)\n+-- !query 4 schema\n+struct<>\n+-- !query 4 output\n+org.apache.spark.sql.AnalysisException\n+The limit expression must evaluate to a constant value, but got CASE WHEN (`_nondeterministic` < CAST(0.5BD AS DOUBLE)) THEN CAST(NULL AS BIGINT) END;\n+\n+\n+-- !query 5\n+DROP VIEW INT8_TBL\n+-- !query 5 schema\n+struct<>\n+-- !query 5 output\n+\n+\n+\n+-- !query 6\n+select sum(tenthous) as s1, sum(tenthous) + random()*0 as s2\n+  from tenk1 group by thousand order by thousand limit 3\n+-- !query 6 schema\n+struct<s1:bigint,s2:double>\n+-- !query 6 output\n+45000\t45000.0\n+45010\t45010.0\n+45020\t45020.0",
    "line": 81
  }],
  "prId": 26311
}]