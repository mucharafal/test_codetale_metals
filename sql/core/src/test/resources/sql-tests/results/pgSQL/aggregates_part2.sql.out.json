[{
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "It's empty at postgres side, but `NULL` at Spark SQL side:\r\nhttps://github.com/postgres/postgres/blob/REL_12_BETA1/src/test/regress/expected/aggregates.out#L800-L804",
    "commit": "41d4e0a4babb29e89532b411c742e481ad632e61",
    "createdAt": "2019-05-30T14:31:24Z",
    "diffHunk": "@@ -0,0 +1,320 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 28\n+\n+\n+-- !query 0\n+-- boolean and transitions\n+     -- null because strict\n+     -- and actual computations\n+\n+     -- boolean or transitions\n+     -- null because strict\n+     -- actual computations\n+\n+\n+\n+\n+\n+\n+\n+\n+explain\n+  select min(unique1) from tenk1\n+-- !query 0 schema\n+struct<plan:string>\n+-- !query 0 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[min(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_min(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 1\n+select min(unique1) from tenk1\n+-- !query 1 schema\n+struct<min(unique1):int>\n+-- !query 1 output\n+0\n+\n+\n+-- !query 2\n+explain\n+  select max(unique1) from tenk1\n+-- !query 2 schema\n+struct<plan:string>\n+-- !query 2 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 3\n+select max(unique1) from tenk1\n+-- !query 3 schema\n+struct<max(unique1):int>\n+-- !query 3 output\n+9999\n+\n+\n+-- !query 4\n+explain\n+  select max(unique1) from tenk1 where unique1 < 42\n+-- !query 4 schema\n+struct<plan:string>\n+-- !query 4 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *Filter (isnotnull(unique1#x) AND (unique1#x < 42))\n+         +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 5\n+select max(unique1) from tenk1 where unique1 < 42\n+-- !query 5 schema\n+struct<max(unique1):int>\n+-- !query 5 output\n+41\n+\n+\n+-- !query 6\n+explain\n+  select max(unique1) from tenk1 where unique1 > 42\n+-- !query 6 schema\n+struct<plan:string>\n+-- !query 6 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *Filter (isnotnull(unique1#x) AND (unique1#x > 42))\n+         +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 7\n+select max(unique1) from tenk1 where unique1 > 42\n+-- !query 7 schema\n+struct<max(unique1):int>\n+-- !query 7 output\n+9999\n+\n+\n+-- !query 8\n+explain\n+  select max(unique1) from tenk1 where unique1 > 42000\n+-- !query 8 schema\n+struct<plan:string>\n+-- !query 8 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *Filter (isnotnull(unique1#x) AND (unique1#x > 42000))\n+         +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 9\n+select max(unique1) from tenk1 where unique1 > 42000\n+-- !query 9 schema\n+struct<max(unique1):int>\n+-- !query 9 output\n+NULL"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "That is how postgreSQL displays NULL, right?",
    "commit": "41d4e0a4babb29e89532b411c742e481ad632e61",
    "createdAt": "2019-05-31T07:02:44Z",
    "diffHunk": "@@ -0,0 +1,320 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 28\n+\n+\n+-- !query 0\n+-- boolean and transitions\n+     -- null because strict\n+     -- and actual computations\n+\n+     -- boolean or transitions\n+     -- null because strict\n+     -- actual computations\n+\n+\n+\n+\n+\n+\n+\n+\n+explain\n+  select min(unique1) from tenk1\n+-- !query 0 schema\n+struct<plan:string>\n+-- !query 0 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[min(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_min(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 1\n+select min(unique1) from tenk1\n+-- !query 1 schema\n+struct<min(unique1):int>\n+-- !query 1 output\n+0\n+\n+\n+-- !query 2\n+explain\n+  select max(unique1) from tenk1\n+-- !query 2 schema\n+struct<plan:string>\n+-- !query 2 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 3\n+select max(unique1) from tenk1\n+-- !query 3 schema\n+struct<max(unique1):int>\n+-- !query 3 output\n+9999\n+\n+\n+-- !query 4\n+explain\n+  select max(unique1) from tenk1 where unique1 < 42\n+-- !query 4 schema\n+struct<plan:string>\n+-- !query 4 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *Filter (isnotnull(unique1#x) AND (unique1#x < 42))\n+         +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 5\n+select max(unique1) from tenk1 where unique1 < 42\n+-- !query 5 schema\n+struct<max(unique1):int>\n+-- !query 5 output\n+41\n+\n+\n+-- !query 6\n+explain\n+  select max(unique1) from tenk1 where unique1 > 42\n+-- !query 6 schema\n+struct<plan:string>\n+-- !query 6 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *Filter (isnotnull(unique1#x) AND (unique1#x > 42))\n+         +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 7\n+select max(unique1) from tenk1 where unique1 > 42\n+-- !query 7 schema\n+struct<max(unique1):int>\n+-- !query 7 output\n+9999\n+\n+\n+-- !query 8\n+explain\n+  select max(unique1) from tenk1 where unique1 > 42000\n+-- !query 8 schema\n+struct<plan:string>\n+-- !query 8 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *Filter (isnotnull(unique1#x) AND (unique1#x > 42000))\n+         +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 9\n+select max(unique1) from tenk1 where unique1 > 42000\n+-- !query 9 schema\n+struct<max(unique1):int>\n+-- !query 9 output\n+NULL"
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "Yes. it is,",
    "commit": "41d4e0a4babb29e89532b411c742e481ad632e61",
    "createdAt": "2019-06-01T09:51:42Z",
    "diffHunk": "@@ -0,0 +1,320 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 28\n+\n+\n+-- !query 0\n+-- boolean and transitions\n+     -- null because strict\n+     -- and actual computations\n+\n+     -- boolean or transitions\n+     -- null because strict\n+     -- actual computations\n+\n+\n+\n+\n+\n+\n+\n+\n+explain\n+  select min(unique1) from tenk1\n+-- !query 0 schema\n+struct<plan:string>\n+-- !query 0 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[min(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_min(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 1\n+select min(unique1) from tenk1\n+-- !query 1 schema\n+struct<min(unique1):int>\n+-- !query 1 output\n+0\n+\n+\n+-- !query 2\n+explain\n+  select max(unique1) from tenk1\n+-- !query 2 schema\n+struct<plan:string>\n+-- !query 2 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 3\n+select max(unique1) from tenk1\n+-- !query 3 schema\n+struct<max(unique1):int>\n+-- !query 3 output\n+9999\n+\n+\n+-- !query 4\n+explain\n+  select max(unique1) from tenk1 where unique1 < 42\n+-- !query 4 schema\n+struct<plan:string>\n+-- !query 4 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *Filter (isnotnull(unique1#x) AND (unique1#x < 42))\n+         +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 5\n+select max(unique1) from tenk1 where unique1 < 42\n+-- !query 5 schema\n+struct<max(unique1):int>\n+-- !query 5 output\n+41\n+\n+\n+-- !query 6\n+explain\n+  select max(unique1) from tenk1 where unique1 > 42\n+-- !query 6 schema\n+struct<plan:string>\n+-- !query 6 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *Filter (isnotnull(unique1#x) AND (unique1#x > 42))\n+         +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 7\n+select max(unique1) from tenk1 where unique1 > 42\n+-- !query 7 schema\n+struct<max(unique1):int>\n+-- !query 7 output\n+9999\n+\n+\n+-- !query 8\n+explain\n+  select max(unique1) from tenk1 where unique1 > 42000\n+-- !query 8 schema\n+struct<plan:string>\n+-- !query 8 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[max(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_max(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *Filter (isnotnull(unique1#x) AND (unique1#x > 42000))\n+         +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>\n+\n+\n+-- !query 9\n+select max(unique1) from tenk1 where unique1 > 42000\n+-- !query 9 schema\n+struct<max(unique1):int>\n+-- !query 9 output\n+NULL"
  }],
  "prId": 24743
}, {
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "Do we need `explain`? It contains the file path when `explain`.",
    "commit": "41d4e0a4babb29e89532b411c742e481ad632e61",
    "createdAt": "2019-05-30T14:33:05Z",
    "diffHunk": "@@ -0,0 +1,320 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 28\n+\n+\n+-- !query 0\n+-- boolean and transitions\n+     -- null because strict\n+     -- and actual computations\n+\n+     -- boolean or transitions\n+     -- null because strict\n+     -- actual computations\n+\n+\n+\n+\n+\n+\n+\n+\n+explain\n+  select min(unique1) from tenk1\n+-- !query 0 schema\n+struct<plan:string>\n+-- !query 0 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[min(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_min(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "we do not need it. ",
    "commit": "41d4e0a4babb29e89532b411c742e481ad632e61",
    "createdAt": "2019-05-31T07:01:54Z",
    "diffHunk": "@@ -0,0 +1,320 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 28\n+\n+\n+-- !query 0\n+-- boolean and transitions\n+     -- null because strict\n+     -- and actual computations\n+\n+     -- boolean or transitions\n+     -- null because strict\n+     -- actual computations\n+\n+\n+\n+\n+\n+\n+\n+\n+explain\n+  select min(unique1) from tenk1\n+-- !query 0 schema\n+struct<plan:string>\n+-- !query 0 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[min(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_min(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>"
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "Done",
    "commit": "41d4e0a4babb29e89532b411c742e481ad632e61",
    "createdAt": "2019-06-01T09:51:52Z",
    "diffHunk": "@@ -0,0 +1,320 @@\n+-- Automatically generated by SQLQueryTestSuite\n+-- Number of queries: 28\n+\n+\n+-- !query 0\n+-- boolean and transitions\n+     -- null because strict\n+     -- and actual computations\n+\n+     -- boolean or transitions\n+     -- null because strict\n+     -- actual computations\n+\n+\n+\n+\n+\n+\n+\n+\n+explain\n+  select min(unique1) from tenk1\n+-- !query 0 schema\n+struct<plan:string>\n+-- !query 0 output\n+== Physical Plan ==\n+*HashAggregate(keys=[], functions=[min(unique1#x)])\n++- *HashAggregate(keys=[], functions=[partial_min(unique1#x)])\n+   +- *Project [unique1#x]\n+      +- *BatchScan[unique1#x] CSVScan Location: InMemoryFileIndex[file:/Users/yumwang/SPARK-27883/spark/sql/core/target/scala-2.12/test-classes/t..., ReadSchema: struct<unique1:int>"
  }],
  "prId": 24743
}]