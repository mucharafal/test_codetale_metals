[{
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "nit: Is the multiplication factor related to `Long.BYTES`? It is just `8L` as `computeSizeInBytes` uses.",
    "commit": "5be5a7a6cbeccfa20c717a36753d469202ff984a",
    "createdAt": "2018-06-15T05:13:27Z",
    "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark.sql.execution.sort;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.memory.TaskMemoryManager;\n+import org.apache.spark.memory.TestMemoryConsumer;\n+import org.apache.spark.memory.TestMemoryManager;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeArrayData;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.execution.RecordBinaryComparator;\n+import org.apache.spark.unsafe.Platform;\n+import org.apache.spark.unsafe.UnsafeAlignedOffset;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.memory.MemoryBlock;\n+import org.apache.spark.unsafe.types.UTF8String;\n+import org.apache.spark.util.collection.unsafe.sort.*;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * Test the RecordBinaryComparator, which compares two UnsafeRows by their binary form.\n+ */\n+public class RecordBinaryComparatorSuite {\n+\n+  private final TaskMemoryManager memoryManager = new TaskMemoryManager(\n+      new TestMemoryManager(new SparkConf().set(\"spark.memory.offHeap.enabled\", \"false\")), 0);\n+  private final TestMemoryConsumer consumer = new TestMemoryConsumer(memoryManager);\n+\n+  private final int uaoSize = UnsafeAlignedOffset.getUaoSize();\n+\n+  private MemoryBlock dataPage;\n+  private long pageCursor;\n+\n+  private LongArray array;\n+  private int pos;\n+\n+  @Before\n+  public void beforeEach() {\n+    // Only compare between two input rows.\n+    array = consumer.allocateArray(2);\n+    pos = 0;\n+\n+    dataPage = memoryManager.allocatePage(4096, consumer);\n+    pageCursor = dataPage.getBaseOffset();\n+  }\n+\n+  @After\n+  public void afterEach() {\n+    consumer.freePage(dataPage);\n+    dataPage = null;\n+    pageCursor = 0;\n+\n+    consumer.freeArray(array);\n+    array = null;\n+    pos = 0;\n+  }\n+\n+  private void insertRow(UnsafeRow row) {\n+    Object recordBase = row.getBaseObject();\n+    long recordOffset = row.getBaseOffset();\n+    int recordLength = row.getSizeInBytes();\n+\n+    Object baseObject = dataPage.getBaseObject();\n+    assert(pageCursor + recordLength <= dataPage.getBaseOffset() + dataPage.size());\n+    long recordAddress = memoryManager.encodePageNumberAndOffset(dataPage, pageCursor);\n+    UnsafeAlignedOffset.putSize(baseObject, pageCursor, recordLength);\n+    pageCursor += uaoSize;\n+    Platform.copyMemory(recordBase, recordOffset, baseObject, pageCursor, recordLength);\n+    pageCursor += recordLength;\n+\n+    assert(pos < 2);\n+    array.set(pos, recordAddress);\n+    pos++;\n+  }\n+\n+  private int compare(int index1, int index2) {\n+    Object baseObject = dataPage.getBaseObject();\n+\n+    long recordAddress1 = array.get(index1);\n+    long baseOffset1 = memoryManager.getOffsetInPage(recordAddress1) + uaoSize;\n+    int recordLength1 = UnsafeAlignedOffset.getSize(baseObject, baseOffset1 - uaoSize);\n+\n+    long recordAddress2 = array.get(index2);\n+    long baseOffset2 = memoryManager.getOffsetInPage(recordAddress2) + uaoSize;\n+    int recordLength2 = UnsafeAlignedOffset.getSize(baseObject, baseOffset2 - uaoSize);\n+\n+    return binaryComparator.compare(baseObject, baseOffset1, recordLength1, baseObject,\n+        baseOffset2, recordLength2);\n+  }\n+\n+  private final RecordComparator binaryComparator = new RecordBinaryComparator();\n+\n+  // Compute the most compact size for UnsafeRow's backing data.\n+  private int computeSizeInBytes(int originalSize) {\n+    // All the UnsafeRows in this suite contains less than 64 columns, so the bitSetSize shall\n+    // always be 8.\n+    return 8 + (originalSize + 7) / 8 * 8;\n+  }\n+\n+  // Compute the relative offset of variable-length values.\n+  private long relativeOffset(int numFields) {\n+    // All the UnsafeRows in this suite contains less than 64 columns, so the bitSetSize shall\n+    // always be 8.\n+    return 8 + numFields * Long.BYTES;"
  }],
  "prId": 21570
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "nit: ditto. Regardless of data type, width is always 8.",
    "commit": "5be5a7a6cbeccfa20c717a36753d469202ff984a",
    "createdAt": "2018-06-15T05:34:06Z",
    "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark.sql.execution.sort;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.memory.TaskMemoryManager;\n+import org.apache.spark.memory.TestMemoryConsumer;\n+import org.apache.spark.memory.TestMemoryManager;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeArrayData;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.execution.RecordBinaryComparator;\n+import org.apache.spark.unsafe.Platform;\n+import org.apache.spark.unsafe.UnsafeAlignedOffset;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.memory.MemoryBlock;\n+import org.apache.spark.unsafe.types.UTF8String;\n+import org.apache.spark.util.collection.unsafe.sort.*;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * Test the RecordBinaryComparator, which compares two UnsafeRows by their binary form.\n+ */\n+public class RecordBinaryComparatorSuite {\n+\n+  private final TaskMemoryManager memoryManager = new TaskMemoryManager(\n+      new TestMemoryManager(new SparkConf().set(\"spark.memory.offHeap.enabled\", \"false\")), 0);\n+  private final TestMemoryConsumer consumer = new TestMemoryConsumer(memoryManager);\n+\n+  private final int uaoSize = UnsafeAlignedOffset.getUaoSize();\n+\n+  private MemoryBlock dataPage;\n+  private long pageCursor;\n+\n+  private LongArray array;\n+  private int pos;\n+\n+  @Before\n+  public void beforeEach() {\n+    // Only compare between two input rows.\n+    array = consumer.allocateArray(2);\n+    pos = 0;\n+\n+    dataPage = memoryManager.allocatePage(4096, consumer);\n+    pageCursor = dataPage.getBaseOffset();\n+  }\n+\n+  @After\n+  public void afterEach() {\n+    consumer.freePage(dataPage);\n+    dataPage = null;\n+    pageCursor = 0;\n+\n+    consumer.freeArray(array);\n+    array = null;\n+    pos = 0;\n+  }\n+\n+  private void insertRow(UnsafeRow row) {\n+    Object recordBase = row.getBaseObject();\n+    long recordOffset = row.getBaseOffset();\n+    int recordLength = row.getSizeInBytes();\n+\n+    Object baseObject = dataPage.getBaseObject();\n+    assert(pageCursor + recordLength <= dataPage.getBaseOffset() + dataPage.size());\n+    long recordAddress = memoryManager.encodePageNumberAndOffset(dataPage, pageCursor);\n+    UnsafeAlignedOffset.putSize(baseObject, pageCursor, recordLength);\n+    pageCursor += uaoSize;\n+    Platform.copyMemory(recordBase, recordOffset, baseObject, pageCursor, recordLength);\n+    pageCursor += recordLength;\n+\n+    assert(pos < 2);\n+    array.set(pos, recordAddress);\n+    pos++;\n+  }\n+\n+  private int compare(int index1, int index2) {\n+    Object baseObject = dataPage.getBaseObject();\n+\n+    long recordAddress1 = array.get(index1);\n+    long baseOffset1 = memoryManager.getOffsetInPage(recordAddress1) + uaoSize;\n+    int recordLength1 = UnsafeAlignedOffset.getSize(baseObject, baseOffset1 - uaoSize);\n+\n+    long recordAddress2 = array.get(index2);\n+    long baseOffset2 = memoryManager.getOffsetInPage(recordAddress2) + uaoSize;\n+    int recordLength2 = UnsafeAlignedOffset.getSize(baseObject, baseOffset2 - uaoSize);\n+\n+    return binaryComparator.compare(baseObject, baseOffset1, recordLength1, baseObject,\n+        baseOffset2, recordLength2);\n+  }\n+\n+  private final RecordComparator binaryComparator = new RecordBinaryComparator();\n+\n+  // Compute the most compact size for UnsafeRow's backing data.\n+  private int computeSizeInBytes(int originalSize) {\n+    // All the UnsafeRows in this suite contains less than 64 columns, so the bitSetSize shall\n+    // always be 8.\n+    return 8 + (originalSize + 7) / 8 * 8;\n+  }\n+\n+  // Compute the relative offset of variable-length values.\n+  private long relativeOffset(int numFields) {\n+    // All the UnsafeRows in this suite contains less than 64 columns, so the bitSetSize shall\n+    // always be 8.\n+    return 8 + numFields * Long.BYTES;\n+  }\n+\n+  @Test\n+  public void testBinaryComparatorForSingleColumnRow() throws Exception {\n+    int numFields = 1;\n+\n+    UnsafeRow row1 = new UnsafeRow(numFields);\n+    byte[] data1 = new byte[100];\n+    row1.pointTo(data1, computeSizeInBytes(numFields * Long.BYTES));\n+    row1.setInt(0, 11);\n+\n+    UnsafeRow row2 = new UnsafeRow(numFields);\n+    byte[] data2 = new byte[100];\n+    row2.pointTo(data2, computeSizeInBytes(numFields * Long.BYTES));\n+    row2.setInt(0, 42);\n+\n+    insertRow(row1);\n+    insertRow(row2);\n+\n+    assert(compare(0, 0) == 0);\n+    assert(compare(0, 1) < 0);\n+  }\n+\n+  @Test\n+  public void testBinaryComparatorForMultipleColumnRow() throws Exception {\n+    int numFields = 5;\n+\n+    UnsafeRow row1 = new UnsafeRow(numFields);\n+    byte[] data1 = new byte[100];\n+    row1.pointTo(data1, computeSizeInBytes(numFields * Double.BYTES));"
  }],
  "prId": 21570
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "nit: ditto. Regardless of data type, width is always 8.",
    "commit": "5be5a7a6cbeccfa20c717a36753d469202ff984a",
    "createdAt": "2018-06-15T05:35:57Z",
    "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark.sql.execution.sort;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.memory.TaskMemoryManager;\n+import org.apache.spark.memory.TestMemoryConsumer;\n+import org.apache.spark.memory.TestMemoryManager;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeArrayData;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.execution.RecordBinaryComparator;\n+import org.apache.spark.unsafe.Platform;\n+import org.apache.spark.unsafe.UnsafeAlignedOffset;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.memory.MemoryBlock;\n+import org.apache.spark.unsafe.types.UTF8String;\n+import org.apache.spark.util.collection.unsafe.sort.*;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * Test the RecordBinaryComparator, which compares two UnsafeRows by their binary form.\n+ */\n+public class RecordBinaryComparatorSuite {\n+\n+  private final TaskMemoryManager memoryManager = new TaskMemoryManager(\n+      new TestMemoryManager(new SparkConf().set(\"spark.memory.offHeap.enabled\", \"false\")), 0);\n+  private final TestMemoryConsumer consumer = new TestMemoryConsumer(memoryManager);\n+\n+  private final int uaoSize = UnsafeAlignedOffset.getUaoSize();\n+\n+  private MemoryBlock dataPage;\n+  private long pageCursor;\n+\n+  private LongArray array;\n+  private int pos;\n+\n+  @Before\n+  public void beforeEach() {\n+    // Only compare between two input rows.\n+    array = consumer.allocateArray(2);\n+    pos = 0;\n+\n+    dataPage = memoryManager.allocatePage(4096, consumer);\n+    pageCursor = dataPage.getBaseOffset();\n+  }\n+\n+  @After\n+  public void afterEach() {\n+    consumer.freePage(dataPage);\n+    dataPage = null;\n+    pageCursor = 0;\n+\n+    consumer.freeArray(array);\n+    array = null;\n+    pos = 0;\n+  }\n+\n+  private void insertRow(UnsafeRow row) {\n+    Object recordBase = row.getBaseObject();\n+    long recordOffset = row.getBaseOffset();\n+    int recordLength = row.getSizeInBytes();\n+\n+    Object baseObject = dataPage.getBaseObject();\n+    assert(pageCursor + recordLength <= dataPage.getBaseOffset() + dataPage.size());\n+    long recordAddress = memoryManager.encodePageNumberAndOffset(dataPage, pageCursor);\n+    UnsafeAlignedOffset.putSize(baseObject, pageCursor, recordLength);\n+    pageCursor += uaoSize;\n+    Platform.copyMemory(recordBase, recordOffset, baseObject, pageCursor, recordLength);\n+    pageCursor += recordLength;\n+\n+    assert(pos < 2);\n+    array.set(pos, recordAddress);\n+    pos++;\n+  }\n+\n+  private int compare(int index1, int index2) {\n+    Object baseObject = dataPage.getBaseObject();\n+\n+    long recordAddress1 = array.get(index1);\n+    long baseOffset1 = memoryManager.getOffsetInPage(recordAddress1) + uaoSize;\n+    int recordLength1 = UnsafeAlignedOffset.getSize(baseObject, baseOffset1 - uaoSize);\n+\n+    long recordAddress2 = array.get(index2);\n+    long baseOffset2 = memoryManager.getOffsetInPage(recordAddress2) + uaoSize;\n+    int recordLength2 = UnsafeAlignedOffset.getSize(baseObject, baseOffset2 - uaoSize);\n+\n+    return binaryComparator.compare(baseObject, baseOffset1, recordLength1, baseObject,\n+        baseOffset2, recordLength2);\n+  }\n+\n+  private final RecordComparator binaryComparator = new RecordBinaryComparator();\n+\n+  // Compute the most compact size for UnsafeRow's backing data.\n+  private int computeSizeInBytes(int originalSize) {\n+    // All the UnsafeRows in this suite contains less than 64 columns, so the bitSetSize shall\n+    // always be 8.\n+    return 8 + (originalSize + 7) / 8 * 8;\n+  }\n+\n+  // Compute the relative offset of variable-length values.\n+  private long relativeOffset(int numFields) {\n+    // All the UnsafeRows in this suite contains less than 64 columns, so the bitSetSize shall\n+    // always be 8.\n+    return 8 + numFields * Long.BYTES;\n+  }\n+\n+  @Test\n+  public void testBinaryComparatorForSingleColumnRow() throws Exception {\n+    int numFields = 1;\n+\n+    UnsafeRow row1 = new UnsafeRow(numFields);\n+    byte[] data1 = new byte[100];\n+    row1.pointTo(data1, computeSizeInBytes(numFields * Long.BYTES));\n+    row1.setInt(0, 11);\n+\n+    UnsafeRow row2 = new UnsafeRow(numFields);\n+    byte[] data2 = new byte[100];\n+    row2.pointTo(data2, computeSizeInBytes(numFields * Long.BYTES));\n+    row2.setInt(0, 42);\n+\n+    insertRow(row1);\n+    insertRow(row2);\n+\n+    assert(compare(0, 0) == 0);\n+    assert(compare(0, 1) < 0);\n+  }\n+\n+  @Test\n+  public void testBinaryComparatorForMultipleColumnRow() throws Exception {\n+    int numFields = 5;\n+\n+    UnsafeRow row1 = new UnsafeRow(numFields);\n+    byte[] data1 = new byte[100];\n+    row1.pointTo(data1, computeSizeInBytes(numFields * Double.BYTES));\n+    for (int i = 0; i < numFields; i++) {\n+      row1.setDouble(i, i * 3.14);\n+    }\n+\n+    UnsafeRow row2 = new UnsafeRow(numFields);\n+    byte[] data2 = new byte[100];\n+    row2.pointTo(data2, computeSizeInBytes(numFields * Double.BYTES));\n+    for (int i = 0; i < numFields; i++) {\n+      row2.setDouble(i, 198.7 / (i + 1));\n+    }\n+\n+    insertRow(row1);\n+    insertRow(row2);\n+\n+    assert(compare(0, 0) == 0);\n+    assert(compare(0, 1) < 0);\n+  }\n+\n+  @Test\n+  public void testBinaryComparatorForArrayColumn() throws Exception {\n+    int numFields = 1;\n+\n+    UnsafeRow row1 = new UnsafeRow(numFields);\n+    byte[] data1 = new byte[100];\n+    UnsafeArrayData arrayData1 = UnsafeArrayData.fromPrimitiveArray(new int[]{11, 42, -1});\n+    row1.pointTo(data1, computeSizeInBytes(numFields * Long.BYTES + arrayData1.getSizeInBytes()));\n+    row1.setLong(0, (relativeOffset(numFields) << 32) | (long) arrayData1.getSizeInBytes());\n+    Platform.copyMemory(arrayData1.getBaseObject(), arrayData1.getBaseOffset(), data1,\n+        row1.getBaseOffset() + relativeOffset(numFields), arrayData1.getSizeInBytes());\n+\n+    UnsafeRow row2 = new UnsafeRow(numFields);\n+    byte[] data2 = new byte[100];\n+    UnsafeArrayData arrayData2 = UnsafeArrayData.fromPrimitiveArray(new int[]{22});\n+    row2.pointTo(data2, computeSizeInBytes(numFields * Long.BYTES + arrayData2.getSizeInBytes()));\n+    row2.setLong(0, (relativeOffset(numFields) << 32) | (long) arrayData2.getSizeInBytes());\n+    Platform.copyMemory(arrayData2.getBaseObject(), arrayData2.getBaseOffset(), data2,\n+        row2.getBaseOffset() + relativeOffset(numFields), arrayData2.getSizeInBytes());\n+\n+    insertRow(row1);\n+    insertRow(row2);\n+\n+    assert(compare(0, 0) == 0);\n+    assert(compare(0, 1) > 0);\n+  }\n+\n+  @Test\n+  public void testBinaryComparatorForMixedColumns() throws Exception {\n+    int numFields = 4;\n+\n+    UnsafeRow row1 = new UnsafeRow(numFields);\n+    byte[] data1 = new byte[100];\n+    UTF8String str1 = UTF8String.fromString(\"Milk tea\");\n+    row1.pointTo(data1, computeSizeInBytes(numFields * Long.BYTES + str1.numBytes()));"
  }],
  "prId": 21570
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "super nit: My suggestion is to use ` * 8L`. Although we know `numFields` is less than 64, it would be good to use long multiplication to avoid possible integer overflow in general. ",
    "commit": "5be5a7a6cbeccfa20c717a36753d469202ff984a",
    "createdAt": "2018-06-15T06:05:26Z",
    "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark.sql.execution.sort;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.memory.TaskMemoryManager;\n+import org.apache.spark.memory.TestMemoryConsumer;\n+import org.apache.spark.memory.TestMemoryManager;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeArrayData;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.execution.RecordBinaryComparator;\n+import org.apache.spark.unsafe.Platform;\n+import org.apache.spark.unsafe.UnsafeAlignedOffset;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.memory.MemoryBlock;\n+import org.apache.spark.unsafe.types.UTF8String;\n+import org.apache.spark.util.collection.unsafe.sort.*;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * Test the RecordBinaryComparator, which compares two UnsafeRows by their binary form.\n+ */\n+public class RecordBinaryComparatorSuite {\n+\n+  private final TaskMemoryManager memoryManager = new TaskMemoryManager(\n+      new TestMemoryManager(new SparkConf().set(\"spark.memory.offHeap.enabled\", \"false\")), 0);\n+  private final TestMemoryConsumer consumer = new TestMemoryConsumer(memoryManager);\n+\n+  private final int uaoSize = UnsafeAlignedOffset.getUaoSize();\n+\n+  private MemoryBlock dataPage;\n+  private long pageCursor;\n+\n+  private LongArray array;\n+  private int pos;\n+\n+  @Before\n+  public void beforeEach() {\n+    // Only compare between two input rows.\n+    array = consumer.allocateArray(2);\n+    pos = 0;\n+\n+    dataPage = memoryManager.allocatePage(4096, consumer);\n+    pageCursor = dataPage.getBaseOffset();\n+  }\n+\n+  @After\n+  public void afterEach() {\n+    consumer.freePage(dataPage);\n+    dataPage = null;\n+    pageCursor = 0;\n+\n+    consumer.freeArray(array);\n+    array = null;\n+    pos = 0;\n+  }\n+\n+  private void insertRow(UnsafeRow row) {\n+    Object recordBase = row.getBaseObject();\n+    long recordOffset = row.getBaseOffset();\n+    int recordLength = row.getSizeInBytes();\n+\n+    Object baseObject = dataPage.getBaseObject();\n+    assert(pageCursor + recordLength <= dataPage.getBaseOffset() + dataPage.size());\n+    long recordAddress = memoryManager.encodePageNumberAndOffset(dataPage, pageCursor);\n+    UnsafeAlignedOffset.putSize(baseObject, pageCursor, recordLength);\n+    pageCursor += uaoSize;\n+    Platform.copyMemory(recordBase, recordOffset, baseObject, pageCursor, recordLength);\n+    pageCursor += recordLength;\n+\n+    assert(pos < 2);\n+    array.set(pos, recordAddress);\n+    pos++;\n+  }\n+\n+  private int compare(int index1, int index2) {\n+    Object baseObject = dataPage.getBaseObject();\n+\n+    long recordAddress1 = array.get(index1);\n+    long baseOffset1 = memoryManager.getOffsetInPage(recordAddress1) + uaoSize;\n+    int recordLength1 = UnsafeAlignedOffset.getSize(baseObject, baseOffset1 - uaoSize);\n+\n+    long recordAddress2 = array.get(index2);\n+    long baseOffset2 = memoryManager.getOffsetInPage(recordAddress2) + uaoSize;\n+    int recordLength2 = UnsafeAlignedOffset.getSize(baseObject, baseOffset2 - uaoSize);\n+\n+    return binaryComparator.compare(baseObject, baseOffset1, recordLength1, baseObject,\n+        baseOffset2, recordLength2);\n+  }\n+\n+  private final RecordComparator binaryComparator = new RecordBinaryComparator();\n+\n+  // Compute the most compact size for UnsafeRow's backing data.\n+  private int computeSizeInBytes(int originalSize) {\n+    // All the UnsafeRows in this suite contains less than 64 columns, so the bitSetSize shall\n+    // always be 8.\n+    return 8 + (originalSize + 7) / 8 * 8;\n+  }\n+\n+  // Compute the relative offset of variable-length values.\n+  private long relativeOffset(int numFields) {\n+    // All the UnsafeRows in this suite contains less than 64 columns, so the bitSetSize shall\n+    // always be 8.\n+    return 8 + numFields * 8;"
  }],
  "prId": 21570
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "Since this is duplicated, it should be deleted.",
    "commit": "5be5a7a6cbeccfa20c717a36753d469202ff984a",
    "createdAt": "2018-06-15T06:07:53Z",
    "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark.sql.execution.sort;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.memory.TaskMemoryManager;",
    "line": 21
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "cc @jiangxb1987",
    "commit": "5be5a7a6cbeccfa20c717a36753d469202ff984a",
    "createdAt": "2018-06-22T02:49:20Z",
    "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark.sql.execution.sort;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.memory.TaskMemoryManager;",
    "line": 21
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "sorry but which duplicated line do you mention? ",
    "commit": "5be5a7a6cbeccfa20c717a36753d469202ff984a",
    "createdAt": "2018-06-26T14:54:10Z",
    "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark.sql.execution.sort;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.memory.TaskMemoryManager;",
    "line": 21
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "I am sorry. Nvm, I thought lines 21 and 23 are duplicated.",
    "commit": "5be5a7a6cbeccfa20c717a36753d469202ff984a",
    "createdAt": "2018-06-26T17:03:53Z",
    "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark.sql.execution.sort;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.memory.TaskMemoryManager;",
    "line": 21
  }],
  "prId": 21570
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "nit: is it better to insert an empty line between L32 and L33?",
    "commit": "5be5a7a6cbeccfa20c717a36753d469202ff984a",
    "createdAt": "2018-06-15T06:08:34Z",
    "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark.sql.execution.sort;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.memory.TaskMemoryManager;\n+import org.apache.spark.memory.TestMemoryConsumer;\n+import org.apache.spark.memory.TestMemoryManager;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeArrayData;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.execution.RecordBinaryComparator;\n+import org.apache.spark.unsafe.Platform;\n+import org.apache.spark.unsafe.UnsafeAlignedOffset;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.memory.MemoryBlock;\n+import org.apache.spark.unsafe.types.UTF8String;\n+import org.apache.spark.util.collection.unsafe.sort.*;\n+import org.junit.After;"
  }],
  "prId": 21570
}, {
  "comments": [{
    "author": {
      "login": "maropu"
    },
    "body": "We need to use `TaskMemoryManager` for this test? Is not simple tests (e.g., just comparing unsafe rows) enough?",
    "commit": "5be5a7a6cbeccfa20c717a36753d469202ff984a",
    "createdAt": "2018-06-16T02:43:22Z",
    "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark.sql.execution.sort;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.memory.TaskMemoryManager;\n+import org.apache.spark.memory.TestMemoryConsumer;\n+import org.apache.spark.memory.TestMemoryManager;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeArrayData;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.execution.RecordBinaryComparator;\n+import org.apache.spark.unsafe.Platform;\n+import org.apache.spark.unsafe.UnsafeAlignedOffset;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.memory.MemoryBlock;\n+import org.apache.spark.unsafe.types.UTF8String;\n+import org.apache.spark.util.collection.unsafe.sort.*;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * Test the RecordBinaryComparator, which compares two UnsafeRows by their binary form.\n+ */\n+public class RecordBinaryComparatorSuite {\n+\n+  private final TaskMemoryManager memoryManager = new TaskMemoryManager(",
    "line": 43
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "Both way shall work. I choose to implement it in low level so the result won't be affected by the UnsafeProjection code.",
    "commit": "5be5a7a6cbeccfa20c717a36753d469202ff984a",
    "createdAt": "2018-06-19T14:04:40Z",
    "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark.sql.execution.sort;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.memory.TaskMemoryManager;\n+import org.apache.spark.memory.TestMemoryConsumer;\n+import org.apache.spark.memory.TestMemoryManager;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeArrayData;\n+import org.apache.spark.sql.catalyst.expressions.UnsafeRow;\n+import org.apache.spark.sql.execution.RecordBinaryComparator;\n+import org.apache.spark.unsafe.Platform;\n+import org.apache.spark.unsafe.UnsafeAlignedOffset;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.memory.MemoryBlock;\n+import org.apache.spark.unsafe.types.UTF8String;\n+import org.apache.spark.util.collection.unsafe.sort.*;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * Test the RecordBinaryComparator, which compares two UnsafeRows by their binary form.\n+ */\n+public class RecordBinaryComparatorSuite {\n+\n+  private final TaskMemoryManager memoryManager = new TaskMemoryManager(",
    "line": 43
  }],
  "prId": 21570
}]