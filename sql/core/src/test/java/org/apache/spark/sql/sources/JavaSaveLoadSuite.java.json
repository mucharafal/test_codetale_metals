[{
  "comments": [{
    "author": {
      "login": "watermen"
    },
    "body": "Maybe need to use `List<StructField> fields = new ArrayList<StructField>();` instead of `List<StructField> fields = new ArrayList<>();`\n",
    "commit": "f3a96f7497ae613fe4668c3ab739c1f8cb315ec6",
    "createdAt": "2015-02-11T03:14:24Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.sources;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.*;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.sql.test.TestSQLContext$;\n+import org.apache.spark.sql.*;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+import org.apache.spark.util.Utils;\n+\n+public class JavaSaveLoadSuite {\n+\n+  private transient JavaSparkContext sc;\n+  private transient SQLContext sqlContext;\n+\n+  String originalDefaultSource;\n+  File path;\n+  DataFrame df;\n+\n+  private void checkAnswer(DataFrame actual, List<Row> expected) {\n+    String errorMessage = QueryTest$.MODULE$.checkAnswer(actual, expected);\n+    if (errorMessage != null) {\n+      Assert.fail(errorMessage);\n+    }\n+  }\n+\n+  @Before\n+  public void setUp() throws IOException {\n+    sqlContext = TestSQLContext$.MODULE$;\n+    sc = new JavaSparkContext(sqlContext.sparkContext());\n+\n+    originalDefaultSource = sqlContext.conf().defaultDataSourceName();\n+    path =\n+      Utils.createTempDir(System.getProperty(\"java.io.tmpdir\"), \"datasource\").getCanonicalFile();\n+    if (path.exists()) {\n+      path.delete();\n+    }\n+\n+    List<String> jsonObjects = new ArrayList<String>(10);\n+    for (int i = 0; i < 10; i++) {\n+      jsonObjects.add(\"{\\\"a\\\":\" + i + \", \\\"b\\\":\\\"str\" + i + \"\\\"}\");\n+    }\n+    JavaRDD<String> rdd = sc.parallelize(jsonObjects);\n+    df = sqlContext.jsonRDD(rdd);\n+    df.registerTempTable(\"jsonTable\");\n+  }\n+\n+  @Test\n+  public void saveAndLoad() {\n+    Map<String, String> options = new HashMap<String, String>();\n+    options.put(\"path\", path.toString());\n+    df.save(\"org.apache.spark.sql.json\", SaveMode.ErrorIfExists, options);\n+\n+    DataFrame loadedDF = sqlContext.load(\"org.apache.spark.sql.json\", options);\n+\n+    checkAnswer(loadedDF, df.collectAsList());\n+  }\n+\n+  @Test\n+  public void saveAndLoadWithSchema() {\n+    Map<String, String> options = new HashMap<String, String>();\n+    options.put(\"path\", path.toString());\n+    df.save(\"org.apache.spark.sql.json\", SaveMode.ErrorIfExists, options);\n+\n+    List<StructField> fields = new ArrayList<>();",
    "line": 90
  }, {
    "author": {
      "login": "yhuai"
    },
    "body": "We have fixed it. Thank you!\n",
    "commit": "f3a96f7497ae613fe4668c3ab739c1f8cb315ec6",
    "createdAt": "2015-02-11T06:44:34Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.sources;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.*;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.sql.test.TestSQLContext$;\n+import org.apache.spark.sql.*;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+import org.apache.spark.util.Utils;\n+\n+public class JavaSaveLoadSuite {\n+\n+  private transient JavaSparkContext sc;\n+  private transient SQLContext sqlContext;\n+\n+  String originalDefaultSource;\n+  File path;\n+  DataFrame df;\n+\n+  private void checkAnswer(DataFrame actual, List<Row> expected) {\n+    String errorMessage = QueryTest$.MODULE$.checkAnswer(actual, expected);\n+    if (errorMessage != null) {\n+      Assert.fail(errorMessage);\n+    }\n+  }\n+\n+  @Before\n+  public void setUp() throws IOException {\n+    sqlContext = TestSQLContext$.MODULE$;\n+    sc = new JavaSparkContext(sqlContext.sparkContext());\n+\n+    originalDefaultSource = sqlContext.conf().defaultDataSourceName();\n+    path =\n+      Utils.createTempDir(System.getProperty(\"java.io.tmpdir\"), \"datasource\").getCanonicalFile();\n+    if (path.exists()) {\n+      path.delete();\n+    }\n+\n+    List<String> jsonObjects = new ArrayList<String>(10);\n+    for (int i = 0; i < 10; i++) {\n+      jsonObjects.add(\"{\\\"a\\\":\" + i + \", \\\"b\\\":\\\"str\" + i + \"\\\"}\");\n+    }\n+    JavaRDD<String> rdd = sc.parallelize(jsonObjects);\n+    df = sqlContext.jsonRDD(rdd);\n+    df.registerTempTable(\"jsonTable\");\n+  }\n+\n+  @Test\n+  public void saveAndLoad() {\n+    Map<String, String> options = new HashMap<String, String>();\n+    options.put(\"path\", path.toString());\n+    df.save(\"org.apache.spark.sql.json\", SaveMode.ErrorIfExists, options);\n+\n+    DataFrame loadedDF = sqlContext.load(\"org.apache.spark.sql.json\", options);\n+\n+    checkAnswer(loadedDF, df.collectAsList());\n+  }\n+\n+  @Test\n+  public void saveAndLoadWithSchema() {\n+    Map<String, String> options = new HashMap<String, String>();\n+    options.put(\"path\", path.toString());\n+    df.save(\"org.apache.spark.sql.json\", SaveMode.ErrorIfExists, options);\n+\n+    List<StructField> fields = new ArrayList<>();",
    "line": 90
  }],
  "prId": 4446
}]