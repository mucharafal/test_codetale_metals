[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Hi, @gengliangwang . \r\nIs there a reason not to update another `OrcFilters`? We had better be consistent for both in order to support Hadoop 3 in Spark 3.0.0.\r\n- sql/core/v2.3.4/src/main/scala/org/apache/spark/sql/execution/datasources/orc/OrcFilters.scala",
    "commit": "90b0b697246251b1e0b8acfe07f53f1153aefe45",
    "createdAt": "2019-05-15T02:06:47Z",
    "diffHunk": "@@ -176,11 +176,11 @@ private[sql] object OrcFilters extends OrcFiltersBase {\n \n       case Or(left, right) =>\n         for {\n-          _ <- createBuilder(dataTypeMap, left, newBuilder, canPartialPushDownConjuncts = false)\n-          _ <- createBuilder(dataTypeMap, right, newBuilder, canPartialPushDownConjuncts = false)\n+          _ <- createBuilder(dataTypeMap, left, newBuilder, canPartialPushDownConjuncts = true)\n+          _ <- createBuilder(dataTypeMap, right, newBuilder, canPartialPushDownConjuncts = true)"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Also, cc @wangyum since he is actively working on `Hadoop 3.2` support.",
    "commit": "90b0b697246251b1e0b8acfe07f53f1153aefe45",
    "createdAt": "2019-05-15T02:08:09Z",
    "diffHunk": "@@ -176,11 +176,11 @@ private[sql] object OrcFilters extends OrcFiltersBase {\n \n       case Or(left, right) =>\n         for {\n-          _ <- createBuilder(dataTypeMap, left, newBuilder, canPartialPushDownConjuncts = false)\n-          _ <- createBuilder(dataTypeMap, right, newBuilder, canPartialPushDownConjuncts = false)\n+          _ <- createBuilder(dataTypeMap, left, newBuilder, canPartialPushDownConjuncts = true)\n+          _ <- createBuilder(dataTypeMap, right, newBuilder, canPartialPushDownConjuncts = true)"
  }],
  "prId": 24598
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "it's weird to call a method \"helper\", what does it do?",
    "commit": "90b0b697246251b1e0b8acfe07f53f1153aefe45",
    "createdAt": "2019-05-17T03:47:31Z",
    "diffHunk": "@@ -75,10 +75,42 @@ private[sql] object OrcFilters extends OrcFiltersBase {\n       schema: StructType,\n       dataTypeMap: Map[String, DataType],\n       filters: Seq[Filter]): Seq[Filter] = {\n-    for {\n-      filter <- filters\n-      _ <- buildSearchArgument(dataTypeMap, filter, newBuilder())\n-    } yield filter\n+    import org.apache.spark.sql.sources._\n+\n+    def convertibleFiltersHelper(",
    "line": 10
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "This is a helper method for converting Filter to Expression recursively.  It can also be `_convertibleFilters` or `convertibleFilters0`...\r\nHere it is following `createFilterHelper` in `ParquetFilters`.",
    "commit": "90b0b697246251b1e0b8acfe07f53f1153aefe45",
    "createdAt": "2019-05-17T04:09:44Z",
    "diffHunk": "@@ -75,10 +75,42 @@ private[sql] object OrcFilters extends OrcFiltersBase {\n       schema: StructType,\n       dataTypeMap: Map[String, DataType],\n       filters: Seq[Filter]): Seq[Filter] = {\n-    for {\n-      filter <- filters\n-      _ <- buildSearchArgument(dataTypeMap, filter, newBuilder())\n-    } yield filter\n+    import org.apache.spark.sql.sources._\n+\n+    def convertibleFiltersHelper(",
    "line": 10
  }],
  "prId": 24598
}]