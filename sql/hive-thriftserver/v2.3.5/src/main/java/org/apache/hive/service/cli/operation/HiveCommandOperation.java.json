[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I think he meant hadoop 3.2 due to this code path. Actually lately Yuming added a way to use hadoop 3.2 profile in PR builder as of https://github.com/apache/spark/pull/24045\r\nIt doesn't look quite likely hadoop 3.2 build will fail because of this change though.",
    "commit": "94bb1d6b9caadb15b5e50c1710a488ca386597b7",
    "createdAt": "2019-08-03T22:02:24Z",
    "diffHunk": "@@ -69,16 +71,16 @@ private void setupSessionIO(SessionState sessionState) {\n       LOG.info(\"Putting temp output to file \" + sessionState.getTmpOutputFile().toString());\n       sessionState.in = null; // hive server's session input stream is not used\n       // open a per-session file in auto-flush mode for writing temp results\n-      sessionState.out = new PrintStream(new FileOutputStream(sessionState.getTmpOutputFile()), true, \"UTF-8\");\n+      sessionState.out = new PrintStream(new FileOutputStream(sessionState.getTmpOutputFile()), true, UTF_8.name());\n       // TODO: for hadoop jobs, progress is printed out to session.err,\n       // we should find a way to feed back job progress to client\n-      sessionState.err = new PrintStream(System.err, true, \"UTF-8\");\n+      sessionState.err = new PrintStream(System.err, true, UTF_8.name());\n     } catch (IOException e) {\n       LOG.error(\"Error in creating temp output file \", e);\n       try {\n         sessionState.in = null;\n-        sessionState.out = new PrintStream(System.out, true, \"UTF-8\");\n-        sessionState.err = new PrintStream(System.err, true, \"UTF-8\");\n+        sessionState.out = new PrintStream(System.out, true, UTF_8.name());\n+        sessionState.err = new PrintStream(System.err, true, UTF_8.name());",
    "line": 26
  }],
  "prId": 25335
}]