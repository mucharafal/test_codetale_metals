[{
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "Does this work?  Won't this throw a class cast exception for non-string types?\n",
    "commit": "6f71d0ba9b4b01247c6844105e5d99db062a0948",
    "createdAt": "2014-11-11T00:58:56Z",
    "diffHunk": "@@ -123,23 +121,19 @@ private[hive] class SparkExecuteStatementOperation(\n       case FloatType =>\n         to += from.getFloat(ordinal)\n       case DecimalType() =>\n-        to += from.get(ordinal).asInstanceOf[BigDecimal].bigDecimal\n+        to += from.getAs[BigDecimal](ordinal).bigDecimal\n       case LongType =>\n         to += from.getLong(ordinal)\n       case ByteType =>\n         to += from.getByte(ordinal)\n       case ShortType =>\n         to += from.getShort(ordinal)\n+      case DateType =>\n+        to += from.getAs[Date](ordinal)\n       case TimestampType =>\n-        to +=  from.get(ordinal).asInstanceOf[Timestamp]\n-      case BinaryType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: ArrayType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: StructType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: MapType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n+        to +=  from.getAs[Timestamp](ordinal)\n+      case StringType | BinaryType | _: ArrayType | _: StructType | _: MapType =>\n+        to += from.getAs[String](ordinal)"
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "My fault, neither the original nor the modified code work, should notice this before merging #2685. Will provide a fix for this in this PR soon.\n",
    "commit": "6f71d0ba9b4b01247c6844105e5d99db062a0948",
    "createdAt": "2014-11-14T17:26:59Z",
    "diffHunk": "@@ -123,23 +121,19 @@ private[hive] class SparkExecuteStatementOperation(\n       case FloatType =>\n         to += from.getFloat(ordinal)\n       case DecimalType() =>\n-        to += from.get(ordinal).asInstanceOf[BigDecimal].bigDecimal\n+        to += from.getAs[BigDecimal](ordinal).bigDecimal\n       case LongType =>\n         to += from.getLong(ordinal)\n       case ByteType =>\n         to += from.getByte(ordinal)\n       case ShortType =>\n         to += from.getShort(ordinal)\n+      case DateType =>\n+        to += from.getAs[Date](ordinal)\n       case TimestampType =>\n-        to +=  from.get(ordinal).asInstanceOf[Timestamp]\n-      case BinaryType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: ArrayType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: StructType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: MapType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n+        to +=  from.getAs[Timestamp](ordinal)\n+      case StringType | BinaryType | _: ArrayType | _: StructType | _: MapType =>\n+        to += from.getAs[String](ordinal)"
  }],
  "prId": 3178
}, {
  "comments": [{
    "author": {
      "login": "marmbrus"
    },
    "body": "Constructing a query execution for each column/row seems kind of expensive.  Can we instead just pull `toHiveString` out into a static function?\n",
    "commit": "6f71d0ba9b4b01247c6844105e5d99db062a0948",
    "createdAt": "2014-11-14T23:26:14Z",
    "diffHunk": "@@ -123,23 +121,23 @@ private[hive] class SparkExecuteStatementOperation(\n       case FloatType =>\n         to += from.getFloat(ordinal)\n       case DecimalType() =>\n-        to += from.get(ordinal).asInstanceOf[BigDecimal].bigDecimal\n+        to += from.getAs[BigDecimal](ordinal).bigDecimal\n       case LongType =>\n         to += from.getLong(ordinal)\n       case ByteType =>\n         to += from.getByte(ordinal)\n       case ShortType =>\n         to += from.getShort(ordinal)\n+      case DateType =>\n+        to += from.getAs[Date](ordinal)\n       case TimestampType =>\n-        to +=  from.get(ordinal).asInstanceOf[Timestamp]\n-      case BinaryType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: ArrayType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: StructType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: MapType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n+        to +=  from.getAs[Timestamp](ordinal)\n+      case StringType | BinaryType | _: ArrayType | _: StructType | _: MapType =>\n+        val hiveString = result\n+          .queryExecution\n+          .asInstanceOf[HiveContext#QueryExecution]\n+          .toHiveString(from.get(ordinal) -> dataTypes(ordinal))\n+        to += hiveString"
  }, {
    "author": {
      "login": "marmbrus"
    },
    "body": "Also why are we only doing this for Hive 13 and not Hive 12?\n",
    "commit": "6f71d0ba9b4b01247c6844105e5d99db062a0948",
    "createdAt": "2014-11-14T23:26:32Z",
    "diffHunk": "@@ -123,23 +121,23 @@ private[hive] class SparkExecuteStatementOperation(\n       case FloatType =>\n         to += from.getFloat(ordinal)\n       case DecimalType() =>\n-        to += from.get(ordinal).asInstanceOf[BigDecimal].bigDecimal\n+        to += from.getAs[BigDecimal](ordinal).bigDecimal\n       case LongType =>\n         to += from.getLong(ordinal)\n       case ByteType =>\n         to += from.getByte(ordinal)\n       case ShortType =>\n         to += from.getShort(ordinal)\n+      case DateType =>\n+        to += from.getAs[Date](ordinal)\n       case TimestampType =>\n-        to +=  from.get(ordinal).asInstanceOf[Timestamp]\n-      case BinaryType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: ArrayType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: StructType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: MapType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n+        to +=  from.getAs[Timestamp](ordinal)\n+      case StringType | BinaryType | _: ArrayType | _: StructType | _: MapType =>\n+        val hiveString = result\n+          .queryExecution\n+          .asInstanceOf[HiveContext#QueryExecution]\n+          .toHiveString(from.get(ordinal) -> dataTypes(ordinal))\n+        to += hiveString"
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "We've already done this for Hive 12, however `toHiveString` wasn't called back in #2685. Making `toHiveString` static sounds good.\n",
    "commit": "6f71d0ba9b4b01247c6844105e5d99db062a0948",
    "createdAt": "2014-11-14T23:59:00Z",
    "diffHunk": "@@ -123,23 +121,23 @@ private[hive] class SparkExecuteStatementOperation(\n       case FloatType =>\n         to += from.getFloat(ordinal)\n       case DecimalType() =>\n-        to += from.get(ordinal).asInstanceOf[BigDecimal].bigDecimal\n+        to += from.getAs[BigDecimal](ordinal).bigDecimal\n       case LongType =>\n         to += from.getLong(ordinal)\n       case ByteType =>\n         to += from.getByte(ordinal)\n       case ShortType =>\n         to += from.getShort(ordinal)\n+      case DateType =>\n+        to += from.getAs[Date](ordinal)\n       case TimestampType =>\n-        to +=  from.get(ordinal).asInstanceOf[Timestamp]\n-      case BinaryType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: ArrayType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: StructType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n-      case _: MapType =>\n-        to += from.get(ordinal).asInstanceOf[String]\n+        to +=  from.getAs[Timestamp](ordinal)\n+      case StringType | BinaryType | _: ArrayType | _: StructType | _: MapType =>\n+        val hiveString = result\n+          .queryExecution\n+          .asInstanceOf[HiveContext#QueryExecution]\n+          .toHiveString(from.get(ordinal) -> dataTypes(ordinal))\n+        to += hiveString"
  }],
  "prId": 3178
}]