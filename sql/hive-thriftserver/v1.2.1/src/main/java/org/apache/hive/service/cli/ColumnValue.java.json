[{
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "We stored it as `Array[Byte]`:\r\nhttps://github.com/apache/spark/blob/687dd4eb55739f802692b3c5457618fd6558e538/sql/hive-thriftserver/src/main/scala/org/apache/spark/sql/hive/thriftserver/SparkExecuteStatementOperation.scala#L105-L106",
    "commit": "7b506e8cf33ad055adcb4daeda9bd8e18d233fbe",
    "createdAt": "2019-08-08T01:15:22Z",
    "diffHunk": "@@ -195,7 +195,7 @@ public static TColumnValue toTColumnValue(Type type, Object value) {\n     case DECIMAL_TYPE:\n       return stringValue(((HiveDecimal)value));\n     case BINARY_TYPE:\n-      return stringValue((String)value);\n+      return stringValue(new String((byte[])value));"
  }],
  "prId": 25379
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Out of curiosity, why we don't need to fix v2.3.5?",
    "commit": "7b506e8cf33ad055adcb4daeda9bd8e18d233fbe",
    "createdAt": "2019-08-08T02:09:49Z",
    "diffHunk": "@@ -195,7 +195,7 @@ public static TColumnValue toTColumnValue(Type type, Object value) {\n     case DECIMAL_TYPE:\n       return stringValue(((HiveDecimal)value));\n     case BINARY_TYPE:\n-      return stringValue((String)value);\n+      return stringValue(new String((byte[])value));"
  }],
  "prId": 25379
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "String roundtrip with system default encoding (say, UTF-8) could be broken. Can we add a test? If that works, then should be good to go.",
    "commit": "7b506e8cf33ad055adcb4daeda9bd8e18d233fbe",
    "createdAt": "2019-08-08T02:39:30Z",
    "diffHunk": "@@ -195,7 +195,7 @@ public static TColumnValue toTColumnValue(Type type, Object value) {\n     case DECIMAL_TYPE:\n       return stringValue(((HiveDecimal)value));\n     case BINARY_TYPE:\n-      return stringValue((String)value);\n+      return stringValue(new String((byte[])value));"
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "How about: ```stringValue(UTF8String.fromBytes((byte[])value).toString());```?\r\nhttps://github.com/apache/spark/blob/b367b323d2d69c6fcb8d4c83d87813e3924b7dc8/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/Cast.scala#L245",
    "commit": "7b506e8cf33ad055adcb4daeda9bd8e18d233fbe",
    "createdAt": "2019-08-08T05:07:57Z",
    "diffHunk": "@@ -195,7 +195,7 @@ public static TColumnValue toTColumnValue(Type type, Object value) {\n     case DECIMAL_TYPE:\n       return stringValue(((HiveDecimal)value));\n     case BINARY_TYPE:\n-      return stringValue((String)value);\n+      return stringValue(new String((byte[])value));"
  }],
  "prId": 25379
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "@wangyum, https://github.com/apache/spark/pull/25480 this might be the cause. `UTF8String.toString()`.\r\n\r\n```\r\nnew String(getBytes(), StandardCharsets.UTF_8);\r\n```\r\n\r\nIt actually reads bytes with UTF-8. IIRC, Java mangles the data if it's not conformed as specified encoding.\r\nFor some protocols, it might be unable to recognise those mangled strings back to binary. It might be the cause.\r\n\r\nBTW, we should allow arbitrary binary, for instance, for the use case like images.\r\n\r\nIf you are unable to find the root cause, we can partially revert to the failed protocols for now.",
    "commit": "7b506e8cf33ad055adcb4daeda9bd8e18d233fbe",
    "createdAt": "2019-08-17T08:44:25Z",
    "diffHunk": "@@ -195,7 +197,8 @@ public static TColumnValue toTColumnValue(Type type, Object value) {\n     case DECIMAL_TYPE:\n       return stringValue(((HiveDecimal)value));\n     case BINARY_TYPE:\n-      return stringValue((String)value);\n+      String strVal = value == null ? null : UTF8String.fromBytes((byte[])value).toString();\n+      return stringValue(strVal);",
    "line": 15
  }],
  "prId": 25379
}]