[{
  "comments": [{
    "author": {
      "login": "bogdanghit"
    },
    "body": "Can you add some tests for the usage and the function class name? @wangyum ",
    "commit": "c95db44f741b2c524090f7258adcd5414c8fa4af",
    "createdAt": "2019-07-31T09:49:15Z",
    "diffHunk": "@@ -182,4 +182,31 @@ class SparkMetadataOperationSuite extends HiveThriftJdbcTest {\n       checkResult(metaData.getTableTypes, Seq(\"TABLE\", \"VIEW\"))\n     }\n   }\n+",
    "line": 13
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "I have added some tests:\r\n```scala\r\nssert(rs.getString(\"REMARKS\").startsWith(s\"${functionName(i)}(\"))\r\nassert(rs.getString(\"SPECIFIC_NAME\").startsWith(\"org.apache.spark.sql.catalyst\"))\r\n```\r\nDo you think we need to assert more details?\r\n",
    "commit": "c95db44f741b2c524090f7258adcd5414c8fa4af",
    "createdAt": "2019-07-31T10:01:27Z",
    "diffHunk": "@@ -182,4 +182,31 @@ class SparkMetadataOperationSuite extends HiveThriftJdbcTest {\n       checkResult(metaData.getTableTypes, Seq(\"TABLE\", \"VIEW\"))\n     }\n   }\n+",
    "line": 13
  }, {
    "author": {
      "login": "bogdanghit"
    },
    "body": "Would be nice to run a ```DESCRIBE function``` statement and then compare the results.",
    "commit": "c95db44f741b2c524090f7258adcd5414c8fa4af",
    "createdAt": "2019-07-31T12:37:09Z",
    "diffHunk": "@@ -182,4 +182,31 @@ class SparkMetadataOperationSuite extends HiveThriftJdbcTest {\n       checkResult(metaData.getTableTypes, Seq(\"TABLE\", \"VIEW\"))\n     }\n   }\n+",
    "line": 13
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "Done:\r\nhttps://github.com/apache/spark/pull/25252/files#diff-1cde3e024f639585984b678383450789R212-R223",
    "commit": "c95db44f741b2c524090f7258adcd5414c8fa4af",
    "createdAt": "2019-08-01T09:28:05Z",
    "diffHunk": "@@ -182,4 +182,31 @@ class SparkMetadataOperationSuite extends HiveThriftJdbcTest {\n       checkResult(metaData.getTableTypes, Seq(\"TABLE\", \"VIEW\"))\n     }\n   }\n+",
    "line": 13
  }],
  "prId": 25252
}, {
  "comments": [{
    "author": {
      "login": "bogdanghit"
    },
    "body": "Thanks for writing all these tests. Was the capital P here intentional?",
    "commit": "c95db44f741b2c524090f7258adcd5414c8fa4af",
    "createdAt": "2019-08-01T09:32:42Z",
    "diffHunk": "@@ -182,4 +182,45 @@ class SparkMetadataOperationSuite extends HiveThriftJdbcTest {\n       checkResult(metaData.getTableTypes, Seq(\"TABLE\", \"VIEW\"))\n     }\n   }\n+\n+  test(\"Spark's own GetFunctionsOperation(SparkGetFunctionsOperation)\") {\n+    def checkResult(rs: ResultSet, functionName: Seq[String]): Unit = {\n+      for (i <- functionName.indices) {\n+        assert(rs.next())\n+        assert(rs.getString(\"FUNCTION_SCHEM\") === \"default\")\n+        assert(rs.getString(\"FUNCTION_NAME\") === functionName(i))\n+        assert(rs.getString(\"REMARKS\").startsWith(s\"${functionName(i)}(\"))\n+        assert(rs.getInt(\"FUNCTION_TYPE\") === DatabaseMetaData.functionResultUnknown)\n+        assert(rs.getString(\"SPECIFIC_NAME\").startsWith(\"org.apache.spark.sql.catalyst\"))\n+      }\n+      // Make sure there are no more elements\n+      assert(!rs.next())\n+    }\n+\n+    withJdbcStatement() { statement =>\n+      val metaData = statement.getConnection.getMetaData\n+      // Hive does not have an overlay function, we use overlay to test.\n+      checkResult(metaData.getFunctions(null, null, \"overlay\"), Seq(\"overlay\"))\n+      checkResult(metaData.getFunctions(null, null, \"overla*\"), Seq(\"overlay\"))\n+      checkResult(metaData.getFunctions(null, \"\", \"overla*\"), Seq(\"overlay\"))\n+      checkResult(metaData.getFunctions(null, null, \"does-not-exist*\"), Seq.empty)\n+      checkResult(metaData.getFunctions(null, \"default\", \"overlay\"), Seq(\"overlay\"))\n+      checkResult(metaData.getFunctions(null, \"default\", \"shift*\"),\n+        Seq(\"shiftleft\", \"shiftright\", \"shiftrightunsigned\"))\n+    }\n+\n+    withJdbcStatement() { statement =>\n+      val metaData = statement.getConnection.getMetaData\n+      val rs = metaData.getFunctions(null, \"default\", \"upPer\")",
    "line": 42
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "Yes.",
    "commit": "c95db44f741b2c524090f7258adcd5414c8fa4af",
    "createdAt": "2019-08-01T09:43:32Z",
    "diffHunk": "@@ -182,4 +182,45 @@ class SparkMetadataOperationSuite extends HiveThriftJdbcTest {\n       checkResult(metaData.getTableTypes, Seq(\"TABLE\", \"VIEW\"))\n     }\n   }\n+\n+  test(\"Spark's own GetFunctionsOperation(SparkGetFunctionsOperation)\") {\n+    def checkResult(rs: ResultSet, functionName: Seq[String]): Unit = {\n+      for (i <- functionName.indices) {\n+        assert(rs.next())\n+        assert(rs.getString(\"FUNCTION_SCHEM\") === \"default\")\n+        assert(rs.getString(\"FUNCTION_NAME\") === functionName(i))\n+        assert(rs.getString(\"REMARKS\").startsWith(s\"${functionName(i)}(\"))\n+        assert(rs.getInt(\"FUNCTION_TYPE\") === DatabaseMetaData.functionResultUnknown)\n+        assert(rs.getString(\"SPECIFIC_NAME\").startsWith(\"org.apache.spark.sql.catalyst\"))\n+      }\n+      // Make sure there are no more elements\n+      assert(!rs.next())\n+    }\n+\n+    withJdbcStatement() { statement =>\n+      val metaData = statement.getConnection.getMetaData\n+      // Hive does not have an overlay function, we use overlay to test.\n+      checkResult(metaData.getFunctions(null, null, \"overlay\"), Seq(\"overlay\"))\n+      checkResult(metaData.getFunctions(null, null, \"overla*\"), Seq(\"overlay\"))\n+      checkResult(metaData.getFunctions(null, \"\", \"overla*\"), Seq(\"overlay\"))\n+      checkResult(metaData.getFunctions(null, null, \"does-not-exist*\"), Seq.empty)\n+      checkResult(metaData.getFunctions(null, \"default\", \"overlay\"), Seq(\"overlay\"))\n+      checkResult(metaData.getFunctions(null, \"default\", \"shift*\"),\n+        Seq(\"shiftleft\", \"shiftright\", \"shiftrightunsigned\"))\n+    }\n+\n+    withJdbcStatement() { statement =>\n+      val metaData = statement.getConnection.getMetaData\n+      val rs = metaData.getFunctions(null, \"default\", \"upPer\")",
    "line": 42
  }],
  "prId": 25252
}]