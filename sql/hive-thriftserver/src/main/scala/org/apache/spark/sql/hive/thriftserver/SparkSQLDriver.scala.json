[{
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "(Actually I'd like to add the comment to the `catch` clause of this `try` block, but GitHub doesn't allow me to.)\n\nOne annoying issue here is that the exception throw is only recorded to the logger, not reported to the console. Thus, when using `bin/spark-sql`, users can only see the following unintuitive exception:\n\n```\n$ ./bin/spark-sql\nspark-sql> foo;\nNoViableAltException(26@[])\n        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:902)\n        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:190)\n        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:161)\n        ...\n```\n\nUnless they run `bin/spark-sql --hiveconf hive.root.logger=INFO,console` (similar to `shark-withinfo` in Shark):\n\n```\n$ ./bin/spark-sql --hiveconf hive.root.logger=INFO,console\nspark-sql> foo;\n14/08/01 11:17:03 INFO parse.ParseDriver: Parsing command: foo\nNoViableAltException(26@[])\n        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:902)\n        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:190)\n        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:161)\n        ...\n14/08/01 11:17:04 ERROR thriftserver.SparkSQLDriver: Failed in [foo]\norg.apache.spark.sql.hive.HiveQl$ParseException: Failed to parse: foo\n        at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:214)\n        at org.apache.spark.sql.hive.HiveContext.hiveql(HiveContext.scala:76)\n        at org.apache.spark.sql.hive.HiveContext.hql(HiveContext.scala:79)\n        ...\n```\n\nTo fix this, we can print the exception (if any) to console after checking response code of the `CommandProcessorResponse` object in [`SparkSQLCLIDriver`](https://github.com/apache/spark/blob/8f51491ea78d8e88fc664c2eac3b4ac14226d98f/sql/hive-thriftserver/src/main/scala/org/apache/spark/sql/hive/thriftserver/SparkSQLCLIDriver.scala#L291).\n",
    "commit": "eb664ccf86ddc30dd53173b6d743f6ff5578483e",
    "createdAt": "2014-08-01T03:22:15Z",
    "diffHunk": "@@ -53,10 +53,9 @@ private[hive] class SparkSQLDriver(val context: HiveContext = SparkSQLEnv.hiveCo\n   }\n \n   override def run(command: String): CommandProcessorResponse = {\n-    val execution = context.executePlan(context.hql(command).logicalPlan)\n-\n     // TODO unify the error code\n     try {\n+      val execution = context.executePlan(context.hql(command).logicalPlan)",
    "line": 8
  }],
  "prId": 1686
}]