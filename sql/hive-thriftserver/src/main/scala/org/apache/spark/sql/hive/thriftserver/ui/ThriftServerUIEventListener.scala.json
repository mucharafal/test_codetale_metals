[{
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Please limit all classes/traits/objects in this file to `private[sql]`.\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T09:06:43Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {"
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "Also please document all event handler methods, especially at what time each handler is called.\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T09:08:45Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {"
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "Actually limit to `private[thriftserver]`.\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T10:03:03Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Space after `if`.\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T09:07:36Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }\n+  def onParse(id: String, executePlan: String, groupId: String) { }\n+  def onError(id: String, errorMessage: String, errorTrace: String) { }\n+  def onFinish(id: String) { }\n+}\n+\n+class SessionInfo(val session: HiveSession, val startTimestamp: Long) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+class ExecutionInfo(val statement: String, val session: HiveSession, val startTimestamp: Long) {\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var groupId = \"\"\n+  var jobId = \"\"\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+class ThriftServerUIEventListener(val conf: SparkConf)\n+  extends ThriftServerEventListener with SparkListener {\n+\n+  import ThriftServerUIEventListener._\n+\n+  var sessionList = new HashMap[SessionHandle, SessionInfo]\n+  var executeList = new HashMap[String, ExecutionInfo]\n+  val retainedStatements =\n+    conf.getInt(\"spark.thriftserver.ui.retainedStatements\", DEFAULT_RETAINED_STATEMENTS)\n+  val retainedSessions =\n+    conf.getInt(\"spark.thriftserver.ui.retainedSessions\", DEFAULT_RETAINED_SESSIONS)\n+  var totalRunning = 0\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val jobGroup = for (\n+      props <- Option(jobStart.properties);\n+      group <- Option(props.getProperty(SparkContext.SPARK_JOB_GROUP_ID))\n+    ) yield group\n+\n+    executeList.foreach {\n+      case (id: String, info: ExecutionInfo) if info.groupId == jobGroup.get => {\n+        executeList(id).jobId = jobStart.jobId.toString\n+      }\n+    }\n+  }\n+\n+  override def onConnected(session: HiveSession): Unit = {\n+    val info = new SessionInfo(session, System.currentTimeMillis())\n+    sessionList(session.getSessionHandle) = info\n+    trimSessionIfNecessary()\n+  }\n+\n+  override def onDisconnected(session: HiveSession): Unit = {\n+    if(!sessionList.contains(session.getSessionHandle)) {"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Remove this empty line.\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T09:07:49Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }\n+  def onParse(id: String, executePlan: String, groupId: String) { }\n+  def onError(id: String, errorMessage: String, errorTrace: String) { }\n+  def onFinish(id: String) { }\n+}\n+\n+class SessionInfo(val session: HiveSession, val startTimestamp: Long) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+class ExecutionInfo(val statement: String, val session: HiveSession, val startTimestamp: Long) {\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var groupId = \"\"\n+  var jobId = \"\"\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+class ThriftServerUIEventListener(val conf: SparkConf)\n+  extends ThriftServerEventListener with SparkListener {\n+\n+  import ThriftServerUIEventListener._\n+\n+  var sessionList = new HashMap[SessionHandle, SessionInfo]\n+  var executeList = new HashMap[String, ExecutionInfo]\n+  val retainedStatements =\n+    conf.getInt(\"spark.thriftserver.ui.retainedStatements\", DEFAULT_RETAINED_STATEMENTS)\n+  val retainedSessions =\n+    conf.getInt(\"spark.thriftserver.ui.retainedSessions\", DEFAULT_RETAINED_SESSIONS)\n+  var totalRunning = 0\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val jobGroup = for (\n+      props <- Option(jobStart.properties);\n+      group <- Option(props.getProperty(SparkContext.SPARK_JOB_GROUP_ID))\n+    ) yield group\n+\n+    executeList.foreach {\n+      case (id: String, info: ExecutionInfo) if info.groupId == jobGroup.get => {\n+        executeList(id).jobId = jobStart.jobId.toString\n+      }\n+    }\n+  }\n+\n+  override def onConnected(session: HiveSession): Unit = {\n+    val info = new SessionInfo(session, System.currentTimeMillis())\n+    sessionList(session.getSessionHandle) = info\n+    trimSessionIfNecessary()\n+  }\n+\n+  override def onDisconnected(session: HiveSession): Unit = {\n+    if(!sessionList.contains(session.getSessionHandle)) {\n+      onConnected(session)\n+    }\n+    sessionList(session.getSessionHandle).finishTimestamp = System.currentTimeMillis()\n+"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "`onQueryStart`?\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T09:09:02Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "`onQueryFinish`?\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T09:09:10Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }\n+  def onParse(id: String, executePlan: String, groupId: String) { }\n+  def onError(id: String, errorMessage: String, errorTrace: String) { }\n+  def onFinish(id: String) { }"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Space after `:`\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T09:15:01Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }\n+  def onParse(id: String, executePlan: String, groupId: String) { }\n+  def onError(id: String, errorMessage: String, errorTrace: String) { }\n+  def onFinish(id: String) { }\n+}\n+\n+class SessionInfo(val session: HiveSession, val startTimestamp: Long) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+class ExecutionInfo(val statement: String, val session: HiveSession, val startTimestamp: Long) {\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var groupId = \"\"\n+  var jobId = \"\"\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+class ThriftServerUIEventListener(val conf: SparkConf)\n+  extends ThriftServerEventListener with SparkListener {\n+\n+  import ThriftServerUIEventListener._\n+\n+  var sessionList = new HashMap[SessionHandle, SessionInfo]\n+  var executeList = new HashMap[String, ExecutionInfo]\n+  val retainedStatements =\n+    conf.getInt(\"spark.thriftserver.ui.retainedStatements\", DEFAULT_RETAINED_STATEMENTS)\n+  val retainedSessions =\n+    conf.getInt(\"spark.thriftserver.ui.retainedSessions\", DEFAULT_RETAINED_SESSIONS)\n+  var totalRunning = 0\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val jobGroup = for (\n+      props <- Option(jobStart.properties);\n+      group <- Option(props.getProperty(SparkContext.SPARK_JOB_GROUP_ID))\n+    ) yield group\n+\n+    executeList.foreach {\n+      case (id: String, info: ExecutionInfo) if info.groupId == jobGroup.get => {\n+        executeList(id).jobId = jobStart.jobId.toString\n+      }\n+    }\n+  }\n+\n+  override def onConnected(session: HiveSession): Unit = {\n+    val info = new SessionInfo(session, System.currentTimeMillis())\n+    sessionList(session.getSessionHandle) = info\n+    trimSessionIfNecessary()\n+  }\n+\n+  override def onDisconnected(session: HiveSession): Unit = {\n+    if(!sessionList.contains(session.getSessionHandle)) {\n+      onConnected(session)\n+    }\n+    sessionList(session.getSessionHandle).finishTimestamp = System.currentTimeMillis()\n+\n+  }\n+\n+  override def onStart(id: String, session: HiveSession, statement: String): Unit = {\n+    // TODO: Due to the incompatible interface between different hive version,\n+    // we can't get the session start event.\n+    // So we have to update session information from here.\n+    if(!sessionList.contains(session.getSessionHandle)) {\n+      onConnected(session)\n+    }\n+    val info = new ExecutionInfo(statement, session, System.currentTimeMillis())\n+    info.state = ExecutionState.STARTED\n+    executeList(id) = info\n+    trimExecutionIfNecessary()\n+    sessionList(session.getSessionHandle).totalExecute += 1\n+    totalRunning += 1\n+  }\n+\n+  override def onParse(id: String, executePlan: String, groupId: String): Unit = {\n+    executeList(id).executePlan = executePlan\n+    executeList(id).groupId = groupId\n+    executeList(id).state = ExecutionState.COMPILED\n+  }\n+\n+  override def onError(id: String, errorMessage: String, errorTrace: String): Unit = {\n+    executeList(id).finishTimestamp = System.currentTimeMillis()\n+    executeList(id).detail = errorMessage\n+    //+ \"<br></br>\" + errorTrace\n+    executeList(id).state = ExecutionState.FAILED\n+    totalRunning -= 1\n+  }\n+\n+  override def onFinish(id: String): Unit = {\n+    executeList(id).finishTimestamp = System.currentTimeMillis()\n+    executeList(id).state = ExecutionState.FINISHED\n+    totalRunning -= 1\n+  }\n+\n+  private def trimExecutionIfNecessary() = synchronized {\n+    if (executeList.size > retainedStatements) {\n+      val toRemove = math.max(retainedStatements / 10, 1)\n+      executeList.toList.sortWith(compareExecutionDesc).take(toRemove).foreach { s =>\n+        executeList.remove(s._1)\n+      }\n+    }\n+  }\n+\n+  private def compareExecutionDesc(\n+      l:(String, ExecutionInfo),\n+      r:(String, ExecutionInfo)): Boolean = {"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Space after `:`\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T09:15:32Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }\n+  def onParse(id: String, executePlan: String, groupId: String) { }\n+  def onError(id: String, errorMessage: String, errorTrace: String) { }\n+  def onFinish(id: String) { }\n+}\n+\n+class SessionInfo(val session: HiveSession, val startTimestamp: Long) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+class ExecutionInfo(val statement: String, val session: HiveSession, val startTimestamp: Long) {\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var groupId = \"\"\n+  var jobId = \"\"\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+class ThriftServerUIEventListener(val conf: SparkConf)\n+  extends ThriftServerEventListener with SparkListener {\n+\n+  import ThriftServerUIEventListener._\n+\n+  var sessionList = new HashMap[SessionHandle, SessionInfo]\n+  var executeList = new HashMap[String, ExecutionInfo]\n+  val retainedStatements =\n+    conf.getInt(\"spark.thriftserver.ui.retainedStatements\", DEFAULT_RETAINED_STATEMENTS)\n+  val retainedSessions =\n+    conf.getInt(\"spark.thriftserver.ui.retainedSessions\", DEFAULT_RETAINED_SESSIONS)\n+  var totalRunning = 0\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val jobGroup = for (\n+      props <- Option(jobStart.properties);\n+      group <- Option(props.getProperty(SparkContext.SPARK_JOB_GROUP_ID))\n+    ) yield group\n+\n+    executeList.foreach {\n+      case (id: String, info: ExecutionInfo) if info.groupId == jobGroup.get => {\n+        executeList(id).jobId = jobStart.jobId.toString\n+      }\n+    }\n+  }\n+\n+  override def onConnected(session: HiveSession): Unit = {\n+    val info = new SessionInfo(session, System.currentTimeMillis())\n+    sessionList(session.getSessionHandle) = info\n+    trimSessionIfNecessary()\n+  }\n+\n+  override def onDisconnected(session: HiveSession): Unit = {\n+    if(!sessionList.contains(session.getSessionHandle)) {\n+      onConnected(session)\n+    }\n+    sessionList(session.getSessionHandle).finishTimestamp = System.currentTimeMillis()\n+\n+  }\n+\n+  override def onStart(id: String, session: HiveSession, statement: String): Unit = {\n+    // TODO: Due to the incompatible interface between different hive version,\n+    // we can't get the session start event.\n+    // So we have to update session information from here.\n+    if(!sessionList.contains(session.getSessionHandle)) {\n+      onConnected(session)\n+    }\n+    val info = new ExecutionInfo(statement, session, System.currentTimeMillis())\n+    info.state = ExecutionState.STARTED\n+    executeList(id) = info\n+    trimExecutionIfNecessary()\n+    sessionList(session.getSessionHandle).totalExecute += 1\n+    totalRunning += 1\n+  }\n+\n+  override def onParse(id: String, executePlan: String, groupId: String): Unit = {\n+    executeList(id).executePlan = executePlan\n+    executeList(id).groupId = groupId\n+    executeList(id).state = ExecutionState.COMPILED\n+  }\n+\n+  override def onError(id: String, errorMessage: String, errorTrace: String): Unit = {\n+    executeList(id).finishTimestamp = System.currentTimeMillis()\n+    executeList(id).detail = errorMessage\n+    //+ \"<br></br>\" + errorTrace\n+    executeList(id).state = ExecutionState.FAILED\n+    totalRunning -= 1\n+  }\n+\n+  override def onFinish(id: String): Unit = {\n+    executeList(id).finishTimestamp = System.currentTimeMillis()\n+    executeList(id).state = ExecutionState.FINISHED\n+    totalRunning -= 1\n+  }\n+\n+  private def trimExecutionIfNecessary() = synchronized {\n+    if (executeList.size > retainedStatements) {\n+      val toRemove = math.max(retainedStatements / 10, 1)\n+      executeList.toList.sortWith(compareExecutionDesc).take(toRemove).foreach { s =>\n+        executeList.remove(s._1)\n+      }\n+    }\n+  }\n+\n+  private def compareExecutionDesc(\n+      l:(String, ExecutionInfo),\n+      r:(String, ExecutionInfo)): Boolean = {\n+    l._2.startTimestamp < r._2.startTimestamp\n+  }\n+\n+  private def compareSessionDesc(\n+      l:(SessionHandle, SessionInfo),\n+      r:(SessionHandle, SessionInfo)): Boolean = {"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Actually we've already got a listener in `object HiveThriftServer2`, is it possible to merge them?\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T09:38:22Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }\n+  def onParse(id: String, executePlan: String, groupId: String) { }\n+  def onError(id: String, errorMessage: String, errorTrace: String) { }\n+  def onFinish(id: String) { }\n+}\n+\n+class SessionInfo(val session: HiveSession, val startTimestamp: Long) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+class ExecutionInfo(val statement: String, val session: HiveSession, val startTimestamp: Long) {\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var groupId = \"\"\n+  var jobId = \"\"\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+class ThriftServerUIEventListener(val conf: SparkConf)"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Remove this line\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T09:42:04Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }\n+  def onParse(id: String, executePlan: String, groupId: String) { }\n+  def onError(id: String, errorMessage: String, errorTrace: String) { }\n+  def onFinish(id: String) { }\n+}\n+\n+class SessionInfo(val session: HiveSession, val startTimestamp: Long) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+class ExecutionInfo(val statement: String, val session: HiveSession, val startTimestamp: Long) {\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var groupId = \"\"\n+  var jobId = \"\"\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+class ThriftServerUIEventListener(val conf: SparkConf)\n+  extends ThriftServerEventListener with SparkListener {\n+\n+  import ThriftServerUIEventListener._\n+\n+  var sessionList = new HashMap[SessionHandle, SessionInfo]\n+  var executeList = new HashMap[String, ExecutionInfo]\n+  val retainedStatements =\n+    conf.getInt(\"spark.thriftserver.ui.retainedStatements\", DEFAULT_RETAINED_STATEMENTS)\n+  val retainedSessions =\n+    conf.getInt(\"spark.thriftserver.ui.retainedSessions\", DEFAULT_RETAINED_SESSIONS)\n+  var totalRunning = 0\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val jobGroup = for (\n+      props <- Option(jobStart.properties);\n+      group <- Option(props.getProperty(SparkContext.SPARK_JOB_GROUP_ID))\n+    ) yield group\n+\n+    executeList.foreach {\n+      case (id: String, info: ExecutionInfo) if info.groupId == jobGroup.get => {\n+        executeList(id).jobId = jobStart.jobId.toString\n+      }\n+    }\n+  }\n+\n+  override def onConnected(session: HiveSession): Unit = {\n+    val info = new SessionInfo(session, System.currentTimeMillis())\n+    sessionList(session.getSessionHandle) = info\n+    trimSessionIfNecessary()\n+  }\n+\n+  override def onDisconnected(session: HiveSession): Unit = {\n+    if(!sessionList.contains(session.getSessionHandle)) {\n+      onConnected(session)\n+    }\n+    sessionList(session.getSessionHandle).finishTimestamp = System.currentTimeMillis()\n+\n+  }\n+\n+  override def onStart(id: String, session: HiveSession, statement: String): Unit = {\n+    // TODO: Due to the incompatible interface between different hive version,\n+    // we can't get the session start event.\n+    // So we have to update session information from here.\n+    if(!sessionList.contains(session.getSessionHandle)) {\n+      onConnected(session)\n+    }\n+    val info = new ExecutionInfo(statement, session, System.currentTimeMillis())\n+    info.state = ExecutionState.STARTED\n+    executeList(id) = info\n+    trimExecutionIfNecessary()\n+    sessionList(session.getSessionHandle).totalExecute += 1\n+    totalRunning += 1\n+  }\n+\n+  override def onParse(id: String, executePlan: String, groupId: String): Unit = {\n+    executeList(id).executePlan = executePlan\n+    executeList(id).groupId = groupId\n+    executeList(id).state = ExecutionState.COMPILED\n+  }\n+\n+  override def onError(id: String, errorMessage: String, errorTrace: String): Unit = {\n+    executeList(id).finishTimestamp = System.currentTimeMillis()\n+    executeList(id).detail = errorMessage\n+    //+ \"<br></br>\" + errorTrace"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "scwf"
    },
    "body": "how/can user set `groupId` ?\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T11:21:02Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }\n+  def onParse(id: String, executePlan: String, groupId: String) { }\n+  def onError(id: String, errorMessage: String, errorTrace: String) { }\n+  def onFinish(id: String) { }\n+}\n+\n+class SessionInfo(val session: HiveSession, val startTimestamp: Long) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+class ExecutionInfo(val statement: String, val session: HiveSession, val startTimestamp: Long) {\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var groupId = \"\""
  }, {
    "author": {
      "login": "scwf"
    },
    "body": "@liancheng, In future ctrl + c can cancel jobs of this group, so if users do not set groupid(use the default value, a empty string), will ctrl +c cancel jobs of all sessions?\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T11:31:28Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }\n+  def onParse(id: String, executePlan: String, groupId: String) { }\n+  def onError(id: String, errorMessage: String, errorTrace: String) { }\n+  def onFinish(id: String) { }\n+}\n+\n+class SessionInfo(val session: HiveSession, val startTimestamp: Long) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+class ExecutionInfo(val statement: String, val session: HiveSession, val startTimestamp: Long) {\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var groupId = \"\""
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "All sessions? Do you mean all executing statements within the current session?\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-08T12:27:14Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }\n+  def onParse(id: String, executePlan: String, groupId: String) { }\n+  def onError(id: String, errorMessage: String, errorTrace: String) { }\n+  def onFinish(id: String) { }\n+}\n+\n+class SessionInfo(val session: HiveSession, val startTimestamp: Long) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+class ExecutionInfo(val statement: String, val session: HiveSession, val startTimestamp: Long) {\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var groupId = \"\""
  }, {
    "author": {
      "login": "tianyi"
    },
    "body": " @scwf @liancheng , I noticed that the `groupId` in `SparkExecuteStatementOperation` had been removed in  #3718. What's this `groupId` used for? \n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-14T07:18:25Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+trait ThriftServerEventListener {\n+\n+  def onConnected(session: HiveSession) { }\n+  def onDisconnected(session: HiveSession) { }\n+\n+  def onStart(id: String, session: HiveSession, statement: String) { }\n+  def onParse(id: String, executePlan: String, groupId: String) { }\n+  def onError(id: String, errorMessage: String, errorTrace: String) { }\n+  def onFinish(id: String) { }\n+}\n+\n+class SessionInfo(val session: HiveSession, val startTimestamp: Long) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+class ExecutionInfo(val statement: String, val session: HiveSession, val startTimestamp: Long) {\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var groupId = \"\""
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "There should be a blank line after this line (same for the other methods).\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-15T20:19:51Z",
    "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+private[thriftserver] trait ThriftServerEventListener {\n+  /**\n+   * Called when a session created.\n+   */\n+  def onSessionCreated(ip: String, session: HiveSession) { }\n+\n+  /**\n+   * Called when a session closed.\n+   */\n+  def onSessionClosed(session: HiveSession) { }\n+\n+  /**\n+   * Called when a statement started to run.\n+   */\n+  def onStatementStart(id: String, session: HiveSession, statement: String) { }"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Space after `if`.\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-15T20:20:04Z",
    "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+private[thriftserver] trait ThriftServerEventListener {\n+  /**\n+   * Called when a session created.\n+   */\n+  def onSessionCreated(ip: String, session: HiveSession) { }\n+\n+  /**\n+   * Called when a session closed.\n+   */\n+  def onSessionClosed(session: HiveSession) { }\n+\n+  /**\n+   * Called when a statement started to run.\n+   */\n+  def onStatementStart(id: String, session: HiveSession, statement: String) { }\n+  /**\n+   * Called when a statement completed compilation.\n+   */\n+  def onStatementParse(id: String, executePlan: String) { }\n+  /**\n+   * Called when a statement got a error during running.\n+   */\n+  def onStatementError(id: String, errorMessage: String, errorTrace: String) { }\n+  /**\n+   * Called when a statement ran success.\n+   */\n+  def onStatementFinish(id: String) { }\n+}\n+\n+private[thriftserver] class SessionInfo(\n+    val session: HiveSession,\n+    val startTimestamp: Long,\n+    val ip: String) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  val userName = if(session.getUserName == null) \"UNKNOWN\" else session.getUserName"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "If you're going to use this strategy to limit memory usage, check out the memory leak prevention tests that I wrote for JobProgressListener: https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/ui/jobs/JobProgressListener.scala#L85.  The main idea was to partition the state according to how it grows / shrinks, then write some general assertions.  This may be overkill for what you're doing here, but I just thought that I should mention that approach since it's a nice testing strategy.\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-15T20:22:38Z",
    "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+private[thriftserver] trait ThriftServerEventListener {\n+  /**\n+   * Called when a session created.\n+   */\n+  def onSessionCreated(ip: String, session: HiveSession) { }\n+\n+  /**\n+   * Called when a session closed.\n+   */\n+  def onSessionClosed(session: HiveSession) { }\n+\n+  /**\n+   * Called when a statement started to run.\n+   */\n+  def onStatementStart(id: String, session: HiveSession, statement: String) { }\n+  /**\n+   * Called when a statement completed compilation.\n+   */\n+  def onStatementParse(id: String, executePlan: String) { }\n+  /**\n+   * Called when a statement got a error during running.\n+   */\n+  def onStatementError(id: String, errorMessage: String, errorTrace: String) { }\n+  /**\n+   * Called when a statement ran success.\n+   */\n+  def onStatementFinish(id: String) { }\n+}\n+\n+private[thriftserver] class SessionInfo(\n+    val session: HiveSession,\n+    val startTimestamp: Long,\n+    val ip: String) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  val userName = if(session.getUserName == null) \"UNKNOWN\" else session.getUserName\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+private[thriftserver] object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+private[thriftserver] class ExecutionInfo(\n+    val statement: String,\n+    val session: HiveSession,\n+    val startTimestamp: Long) {\n+  val userName = if(session.getUserName == null) \"UNKNOWN\" else session.getUserName\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var jobId = \"\"\n+  var groupId = \"\"\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+private[sql] class ThriftServerUIEventListener(val conf: SparkConf)\n+  extends ThriftServerEventListener with SparkListener {\n+\n+  import ThriftServerUIEventListener._\n+\n+  var sessionList = new HashMap[SessionHandle, SessionInfo]\n+  var executeList = new HashMap[String, ExecutionInfo]\n+  val retainedStatements =\n+    conf.getInt(\"spark.thriftserver.ui.retainedStatements\", DEFAULT_RETAINED_STATEMENTS)"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Actually, here's a better reference: #3372\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-15T20:23:04Z",
    "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+private[thriftserver] trait ThriftServerEventListener {\n+  /**\n+   * Called when a session created.\n+   */\n+  def onSessionCreated(ip: String, session: HiveSession) { }\n+\n+  /**\n+   * Called when a session closed.\n+   */\n+  def onSessionClosed(session: HiveSession) { }\n+\n+  /**\n+   * Called when a statement started to run.\n+   */\n+  def onStatementStart(id: String, session: HiveSession, statement: String) { }\n+  /**\n+   * Called when a statement completed compilation.\n+   */\n+  def onStatementParse(id: String, executePlan: String) { }\n+  /**\n+   * Called when a statement got a error during running.\n+   */\n+  def onStatementError(id: String, errorMessage: String, errorTrace: String) { }\n+  /**\n+   * Called when a statement ran success.\n+   */\n+  def onStatementFinish(id: String) { }\n+}\n+\n+private[thriftserver] class SessionInfo(\n+    val session: HiveSession,\n+    val startTimestamp: Long,\n+    val ip: String) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  val userName = if(session.getUserName == null) \"UNKNOWN\" else session.getUserName\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+private[thriftserver] object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+private[thriftserver] class ExecutionInfo(\n+    val statement: String,\n+    val session: HiveSession,\n+    val startTimestamp: Long) {\n+  val userName = if(session.getUserName == null) \"UNKNOWN\" else session.getUserName\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var jobId = \"\"\n+  var groupId = \"\"\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+private[sql] class ThriftServerUIEventListener(val conf: SparkConf)\n+  extends ThriftServerEventListener with SparkListener {\n+\n+  import ThriftServerUIEventListener._\n+\n+  var sessionList = new HashMap[SessionHandle, SessionInfo]\n+  var executeList = new HashMap[String, ExecutionInfo]\n+  val retainedStatements =\n+    conf.getInt(\"spark.thriftserver.ui.retainedStatements\", DEFAULT_RETAINED_STATEMENTS)"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "I think you can use `sortBy(_._2.startTimestamp)` instead of having to define a custom comparison function.\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-15T20:25:01Z",
    "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+private[thriftserver] trait ThriftServerEventListener {\n+  /**\n+   * Called when a session created.\n+   */\n+  def onSessionCreated(ip: String, session: HiveSession) { }\n+\n+  /**\n+   * Called when a session closed.\n+   */\n+  def onSessionClosed(session: HiveSession) { }\n+\n+  /**\n+   * Called when a statement started to run.\n+   */\n+  def onStatementStart(id: String, session: HiveSession, statement: String) { }\n+  /**\n+   * Called when a statement completed compilation.\n+   */\n+  def onStatementParse(id: String, executePlan: String) { }\n+  /**\n+   * Called when a statement got a error during running.\n+   */\n+  def onStatementError(id: String, errorMessage: String, errorTrace: String) { }\n+  /**\n+   * Called when a statement ran success.\n+   */\n+  def onStatementFinish(id: String) { }\n+}\n+\n+private[thriftserver] class SessionInfo(\n+    val session: HiveSession,\n+    val startTimestamp: Long,\n+    val ip: String) {\n+  val sessionID = session.getSessionHandle.getSessionId.toString\n+  val userName = if(session.getUserName == null) \"UNKNOWN\" else session.getUserName\n+  var finishTimestamp = 0L\n+  var totalExecute = 0\n+\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+private[thriftserver] object ExecutionState extends Enumeration {\n+  val STARTED, COMPILED, FAILED, FINISHED = Value\n+  type ExecutionState = Value\n+}\n+\n+private[thriftserver] class ExecutionInfo(\n+    val statement: String,\n+    val session: HiveSession,\n+    val startTimestamp: Long) {\n+  val userName = if(session.getUserName == null) \"UNKNOWN\" else session.getUserName\n+  var finishTimestamp = 0L\n+  var executePlan = \"\"\n+  var detail = \"\"\n+  var state: ExecutionState.Value = ExecutionState.STARTED\n+  var jobId = \"\"\n+  var groupId = \"\"\n+  def totalTime = {\n+    if (finishTimestamp == 0L) {\n+      System.currentTimeMillis() - startTimestamp\n+    } else {\n+      finishTimestamp - startTimestamp\n+    }\n+  }\n+}\n+\n+private[sql] class ThriftServerUIEventListener(val conf: SparkConf)\n+  extends ThriftServerEventListener with SparkListener {\n+\n+  import ThriftServerUIEventListener._\n+\n+  var sessionList = new HashMap[SessionHandle, SessionInfo]\n+  var executeList = new HashMap[String, ExecutionInfo]\n+  val retainedStatements =\n+    conf.getInt(\"spark.thriftserver.ui.retainedStatements\", DEFAULT_RETAINED_STATEMENTS)\n+  val retainedSessions =\n+    conf.getInt(\"spark.thriftserver.ui.retainedSessions\", DEFAULT_RETAINED_SESSIONS)\n+  var totalRunning = 0\n+\n+  override def onJobStart(jobStart: SparkListenerJobStart): Unit = {\n+    val jobGroup = for (\n+      props <- Option(jobStart.properties);\n+      statement <- Option(props.getProperty(SparkContext.SPARK_JOB_DESCRIPTION))\n+    ) yield statement\n+\n+    jobGroup match {\n+      case Some(statement: String) => {\n+        val ret = executeList.find( _ match {\n+          case (id: String, info: ExecutionInfo) => {\n+            info.statement == statement\n+          }\n+        })\n+        if(ret.isDefined) {\n+          ret.get._2.jobId = jobStart.jobId.toString\n+          ret.get._2.groupId = jobStart.properties.getProperty(SparkContext.SPARK_JOB_GROUP_ID,\"\")\n+        }\n+      }\n+    }\n+  }\n+\n+  override def onSessionCreated(ip: String, session: HiveSession): Unit = {\n+    val info = new SessionInfo(session, System.currentTimeMillis(), ip)\n+    sessionList(session.getSessionHandle) = info\n+    trimSessionIfNecessary()\n+  }\n+\n+  override def onSessionClosed(session: HiveSession): Unit = {\n+    sessionList(session.getSessionHandle).finishTimestamp = System.currentTimeMillis()\n+  }\n+\n+  override def onStatementStart(id: String, session: HiveSession, statement: String): Unit = {\n+    val info = new ExecutionInfo(statement, session, System.currentTimeMillis())\n+    info.state = ExecutionState.STARTED\n+    executeList(id) = info\n+    trimExecutionIfNecessary()\n+    sessionList(session.getSessionHandle).totalExecute += 1\n+    totalRunning += 1\n+  }\n+\n+  override def onStatementParse(id: String, executePlan: String): Unit = {\n+    executeList(id).executePlan = executePlan\n+    executeList(id).state = ExecutionState.COMPILED\n+  }\n+\n+  override def onStatementError(id: String, errorMessage: String, errorTrace: String): Unit = {\n+    executeList(id).finishTimestamp = System.currentTimeMillis()\n+    executeList(id).detail = errorMessage\n+    executeList(id).state = ExecutionState.FAILED\n+    totalRunning -= 1\n+  }\n+\n+  override def onStatementFinish(id: String): Unit = {\n+    executeList(id).finishTimestamp = System.currentTimeMillis()\n+    executeList(id).state = ExecutionState.FINISHED\n+    totalRunning -= 1\n+  }\n+\n+  private def trimExecutionIfNecessary() = synchronized {\n+    if (executeList.size > retainedStatements) {\n+      val toRemove = math.max(retainedStatements / 10, 1)\n+      executeList.toList.sortWith(compareExecutionDesc).take(toRemove).foreach { s =>"
  }],
  "prId": 3946
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Nit: `{ }` => `: Unit = {}`\n",
    "commit": "fd352621c215cf39efb6a3d289d8659366b02c53",
    "createdAt": "2015-01-19T09:29:55Z",
    "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver.ui\n+\n+import org.apache.hive.service.cli.SessionHandle\n+import org.apache.hive.service.cli.session.HiveSession\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.scheduler.{SparkListenerJobStart, SparkListener}\n+\n+import scala.collection.mutable.HashMap\n+\n+private[thriftserver] trait ThriftServerEventListener {\n+  /**\n+   * Called when a session created.\n+   */\n+  def onSessionCreated(ip: String, session: HiveSession) { }"
  }],
  "prId": 3946
}]