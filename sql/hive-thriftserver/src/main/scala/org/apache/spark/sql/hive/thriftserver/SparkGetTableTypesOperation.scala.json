[{
  "comments": [{
    "author": {
      "login": "juliuszsompolski"
    },
    "body": "add onStatementClosed once https://github.com/apache/spark/pull/25062 is merged.",
    "commit": "a008c81eddff1bd252326f2acbb6b77605529556",
    "createdAt": "2019-07-08T10:00:48Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.hive.ql.security.authorization.plugin.HiveOperationType\n+import org.apache.hive.service.cli._\n+import org.apache.hive.service.cli.operation.GetTableTypesOperation\n+import org.apache.hive.service.cli.session.HiveSession\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SQLContext\n+import org.apache.spark.sql.catalyst.catalog.CatalogTableType\n+import org.apache.spark.sql.catalyst.catalog.CatalogTableType._\n+import org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.listener\n+import org.apache.spark.util.{Utils => SparkUtils}\n+\n+/**\n+ * Spark's own GetTableTypesOperation\n+ *\n+ * @param sqlContext SQLContext to use\n+ * @param parentSession a HiveSession from SessionManager\n+ */\n+private[hive] class SparkGetTableTypesOperation(\n+    sqlContext: SQLContext,\n+    parentSession: HiveSession)\n+  extends GetTableTypesOperation(parentSession) with Logging {\n+\n+  override def runInternal(): Unit = {\n+    val statementId = UUID.randomUUID().toString\n+    val logMsg = s\"Listing table types\"\n+    logInfo(s\"$logMsg with $statementId\")\n+    setState(OperationState.RUNNING)\n+    // Always use the latest class loader provided by executionHive's state.\n+    val executionHiveClassLoader = sqlContext.sharedState.jarClassLoader\n+    Thread.currentThread().setContextClassLoader(executionHiveClassLoader)\n+\n+    if (isAuthV2Enabled) {\n+      authorizeMetaGets(HiveOperationType.GET_TABLETYPES, null)\n+    }\n+\n+    listener.onStatementStart(\n+      statementId,\n+      parentSession.getSessionHandle.getSessionId.toString,\n+      logMsg,\n+      statementId,\n+      parentSession.getUsername)\n+\n+    try {\n+      CatalogTableType.tableTypes.foreach { tableType =>\n+        if (tableType == EXTERNAL || tableType == EXTERNAL) {\n+          rowSet.addRow(Array[AnyRef](\"TABLE\"))\n+        } else if (tableType == VIEW) {\n+          rowSet.addRow(Array[AnyRef](tableType.name))\n+        } else {\n+          logError(s\"Unknown table type: ${tableType.name}\")\n+        }\n+      }\n+      setState(OperationState.FINISHED)\n+    } catch {\n+      case e: HiveSQLException =>\n+        setState(OperationState.ERROR)\n+        listener.onStatementError(statementId, e.getMessage, SparkUtils.exceptionString(e))\n+        throw e\n+    }\n+    listener.onStatementFinish(statementId)"
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "Sure",
    "commit": "a008c81eddff1bd252326f2acbb6b77605529556",
    "createdAt": "2019-07-08T13:23:00Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.hive.ql.security.authorization.plugin.HiveOperationType\n+import org.apache.hive.service.cli._\n+import org.apache.hive.service.cli.operation.GetTableTypesOperation\n+import org.apache.hive.service.cli.session.HiveSession\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SQLContext\n+import org.apache.spark.sql.catalyst.catalog.CatalogTableType\n+import org.apache.spark.sql.catalyst.catalog.CatalogTableType._\n+import org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.listener\n+import org.apache.spark.util.{Utils => SparkUtils}\n+\n+/**\n+ * Spark's own GetTableTypesOperation\n+ *\n+ * @param sqlContext SQLContext to use\n+ * @param parentSession a HiveSession from SessionManager\n+ */\n+private[hive] class SparkGetTableTypesOperation(\n+    sqlContext: SQLContext,\n+    parentSession: HiveSession)\n+  extends GetTableTypesOperation(parentSession) with Logging {\n+\n+  override def runInternal(): Unit = {\n+    val statementId = UUID.randomUUID().toString\n+    val logMsg = s\"Listing table types\"\n+    logInfo(s\"$logMsg with $statementId\")\n+    setState(OperationState.RUNNING)\n+    // Always use the latest class loader provided by executionHive's state.\n+    val executionHiveClassLoader = sqlContext.sharedState.jarClassLoader\n+    Thread.currentThread().setContextClassLoader(executionHiveClassLoader)\n+\n+    if (isAuthV2Enabled) {\n+      authorizeMetaGets(HiveOperationType.GET_TABLETYPES, null)\n+    }\n+\n+    listener.onStatementStart(\n+      statementId,\n+      parentSession.getSessionHandle.getSessionId.toString,\n+      logMsg,\n+      statementId,\n+      parentSession.getUsername)\n+\n+    try {\n+      CatalogTableType.tableTypes.foreach { tableType =>\n+        if (tableType == EXTERNAL || tableType == EXTERNAL) {\n+          rowSet.addRow(Array[AnyRef](\"TABLE\"))\n+        } else if (tableType == VIEW) {\n+          rowSet.addRow(Array[AnyRef](tableType.name))\n+        } else {\n+          logError(s\"Unknown table type: ${tableType.name}\")\n+        }\n+      }\n+      setState(OperationState.FINISHED)\n+    } catch {\n+      case e: HiveSQLException =>\n+        setState(OperationState.ERROR)\n+        listener.onStatementError(statementId, e.getMessage, SparkUtils.exceptionString(e))\n+        throw e\n+    }\n+    listener.onStatementFinish(statementId)"
  }],
  "prId": 25073
}, {
  "comments": [{
    "author": {
      "login": "juliuszsompolski"
    },
    "body": "I think you meant (tableType == EXTERNAL || tableType == MANAGED), but then you want to add \"TABLE\" to the results only once.\r\nI think you want\r\n`tableTypes.foreach { tableType => tableTypeString(tableType) }.toSet.foreach { type => rowset.addRow(Array[AnyRef](type) }`\r\n\r\ntableTypeString can be shared with SparkGetTablesOperation.\r\nTo share some such functions between the operatoins, how about a mixin utils trait\r\n```\r\ntrait SparkOperationUtils { this: Operation =>\r\n  def tableTypeString(tableType: CatalogTableType) = ...\r\n}\r\n```\r\ne.g. at the bottom of `SparkSQLOperationManager.scala`?",
    "commit": "a008c81eddff1bd252326f2acbb6b77605529556",
    "createdAt": "2019-07-08T10:09:13Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.hive.ql.security.authorization.plugin.HiveOperationType\n+import org.apache.hive.service.cli._\n+import org.apache.hive.service.cli.operation.GetTableTypesOperation\n+import org.apache.hive.service.cli.session.HiveSession\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SQLContext\n+import org.apache.spark.sql.catalyst.catalog.CatalogTableType\n+import org.apache.spark.sql.catalyst.catalog.CatalogTableType._\n+import org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.listener\n+import org.apache.spark.util.{Utils => SparkUtils}\n+\n+/**\n+ * Spark's own GetTableTypesOperation\n+ *\n+ * @param sqlContext SQLContext to use\n+ * @param parentSession a HiveSession from SessionManager\n+ */\n+private[hive] class SparkGetTableTypesOperation(\n+    sqlContext: SQLContext,\n+    parentSession: HiveSession)\n+  extends GetTableTypesOperation(parentSession) with Logging {\n+\n+  override def runInternal(): Unit = {\n+    val statementId = UUID.randomUUID().toString\n+    val logMsg = s\"Listing table types\"\n+    logInfo(s\"$logMsg with $statementId\")\n+    setState(OperationState.RUNNING)\n+    // Always use the latest class loader provided by executionHive's state.\n+    val executionHiveClassLoader = sqlContext.sharedState.jarClassLoader\n+    Thread.currentThread().setContextClassLoader(executionHiveClassLoader)\n+\n+    if (isAuthV2Enabled) {\n+      authorizeMetaGets(HiveOperationType.GET_TABLETYPES, null)\n+    }\n+\n+    listener.onStatementStart(\n+      statementId,\n+      parentSession.getSessionHandle.getSessionId.toString,\n+      logMsg,\n+      statementId,\n+      parentSession.getUsername)\n+\n+    try {\n+      CatalogTableType.tableTypes.foreach { tableType =>\n+        if (tableType == EXTERNAL || tableType == EXTERNAL) {\n+          rowSet.addRow(Array[AnyRef](\"TABLE\"))"
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "+1",
    "commit": "a008c81eddff1bd252326f2acbb6b77605529556",
    "createdAt": "2019-07-08T10:14:18Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.hive.ql.security.authorization.plugin.HiveOperationType\n+import org.apache.hive.service.cli._\n+import org.apache.hive.service.cli.operation.GetTableTypesOperation\n+import org.apache.hive.service.cli.session.HiveSession\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SQLContext\n+import org.apache.spark.sql.catalyst.catalog.CatalogTableType\n+import org.apache.spark.sql.catalyst.catalog.CatalogTableType._\n+import org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.listener\n+import org.apache.spark.util.{Utils => SparkUtils}\n+\n+/**\n+ * Spark's own GetTableTypesOperation\n+ *\n+ * @param sqlContext SQLContext to use\n+ * @param parentSession a HiveSession from SessionManager\n+ */\n+private[hive] class SparkGetTableTypesOperation(\n+    sqlContext: SQLContext,\n+    parentSession: HiveSession)\n+  extends GetTableTypesOperation(parentSession) with Logging {\n+\n+  override def runInternal(): Unit = {\n+    val statementId = UUID.randomUUID().toString\n+    val logMsg = s\"Listing table types\"\n+    logInfo(s\"$logMsg with $statementId\")\n+    setState(OperationState.RUNNING)\n+    // Always use the latest class loader provided by executionHive's state.\n+    val executionHiveClassLoader = sqlContext.sharedState.jarClassLoader\n+    Thread.currentThread().setContextClassLoader(executionHiveClassLoader)\n+\n+    if (isAuthV2Enabled) {\n+      authorizeMetaGets(HiveOperationType.GET_TABLETYPES, null)\n+    }\n+\n+    listener.onStatementStart(\n+      statementId,\n+      parentSession.getSessionHandle.getSessionId.toString,\n+      logMsg,\n+      statementId,\n+      parentSession.getUsername)\n+\n+    try {\n+      CatalogTableType.tableTypes.foreach { tableType =>\n+        if (tableType == EXTERNAL || tableType == EXTERNAL) {\n+          rowSet.addRow(Array[AnyRef](\"TABLE\"))"
  }],
  "prId": 25073
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "nit .. `s`.",
    "commit": "a008c81eddff1bd252326f2acbb6b77605529556",
    "createdAt": "2019-07-09T03:22:56Z",
    "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.hive.ql.security.authorization.plugin.HiveOperationType\n+import org.apache.hive.service.cli._\n+import org.apache.hive.service.cli.operation.GetTableTypesOperation\n+import org.apache.hive.service.cli.session.HiveSession\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SQLContext\n+import org.apache.spark.sql.catalyst.catalog.CatalogTableType\n+import org.apache.spark.util.{Utils => SparkUtils}\n+\n+/**\n+ * Spark's own GetTableTypesOperation\n+ *\n+ * @param sqlContext SQLContext to use\n+ * @param parentSession a HiveSession from SessionManager\n+ */\n+private[hive] class SparkGetTableTypesOperation(\n+    sqlContext: SQLContext,\n+    parentSession: HiveSession)\n+  extends GetTableTypesOperation(parentSession) with SparkMetadataOperationUtils with Logging {\n+\n+  override def runInternal(): Unit = {\n+    val statementId = UUID.randomUUID().toString\n+    val logMsg = s\"Listing table types\""
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "OK. Thank you.",
    "commit": "a008c81eddff1bd252326f2acbb6b77605529556",
    "createdAt": "2019-07-09T03:25:36Z",
    "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.hive.thriftserver\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.hive.ql.security.authorization.plugin.HiveOperationType\n+import org.apache.hive.service.cli._\n+import org.apache.hive.service.cli.operation.GetTableTypesOperation\n+import org.apache.hive.service.cli.session.HiveSession\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.SQLContext\n+import org.apache.spark.sql.catalyst.catalog.CatalogTableType\n+import org.apache.spark.util.{Utils => SparkUtils}\n+\n+/**\n+ * Spark's own GetTableTypesOperation\n+ *\n+ * @param sqlContext SQLContext to use\n+ * @param parentSession a HiveSession from SessionManager\n+ */\n+private[hive] class SparkGetTableTypesOperation(\n+    sqlContext: SQLContext,\n+    parentSession: HiveSession)\n+  extends GetTableTypesOperation(parentSession) with SparkMetadataOperationUtils with Logging {\n+\n+  override def runInternal(): Unit = {\n+    val statementId = UUID.randomUUID().toString\n+    val logMsg = s\"Listing table types\""
  }],
  "prId": 25073
}]