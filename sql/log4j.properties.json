[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Pardon, is a log4j.properties really needed here? what reads it?",
    "commit": "c711ff5363a0608c11b97c915bfc8b8cdbf2ba95",
    "createdAt": "2017-07-25T08:42:32Z",
    "diffHunk": "@@ -0,0 +1,24 @@\n+#"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "This is used - https://github.com/apache/spark/pull/18702/files#diff-a4b1e8e0e72fd59bd246285a34b21a45R49\r\n\r\nI hesitated to add this one but just added to make the infos quiet when a spark session is initialised.\r\n\r\nThere is a similar one in R - https://github.com/apache/spark/blob/master/R/run-tests.sh#L26 and https://github.com/apache/spark/blob/master/R/log4j.properties but this case logs are quite small though.\r\n\r\n```bash\r\n$ sh create-docs.sh\r\n```\r\n\r\n**Before**\r\n\r\n```\r\nGenerating markdown files for SQL documentation.\r\nGenerating HTML files for SQL documentation.\r\nINFO    -  Cleaning site directory\r\nINFO    -  Building documentation to directory: /.../spark/sql/site\r\n```\r\n\r\n**After**\r\n\r\n```\r\nGenerating markdown files for SQL documentation.\r\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\r\n17/07/25 18:02:57 INFO SparkContext: Running Spark version 2.3.0-SNAPSHOT\r\n17/07/25 18:02:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n17/07/25 18:02:57 INFO SparkContext: Submitted application: GenSQLDocs\r\n17/07/25 18:02:57 INFO SecurityManager: Changing view acls to: hyukjinkwon\r\n17/07/25 18:02:57 INFO SecurityManager: Changing modify acls to: hyukjinkwon\r\n17/07/25 18:02:57 INFO SecurityManager: Changing view acls groups to:\r\n17/07/25 18:02:57 INFO SecurityManager: Changing modify acls groups to:\r\n17/07/25 18:02:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hyukjinkwon); groups with view permissions: Set(); users  with modify permissions: Set(hyukjinkwon); groups with modify permissions: Set()\r\n17/07/25 18:02:58 INFO Utils: Successfully started service 'sparkDriver' on port 62695.\r\n17/07/25 18:02:58 INFO SparkEnv: Registering MapOutputTracker\r\n17/07/25 18:02:58 INFO SparkEnv: Registering BlockManagerMaster\r\n17/07/25 18:02:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\r\n17/07/25 18:02:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\r\n17/07/25 18:02:58 INFO DiskBlockManager: Created local directory at /private/var/folders/9j/gf_c342d7d150mwrxvkqnc180000gn/T/blockmgr-13909519-0864-4aa3-82fb-eba4b9d1e527\r\n17/07/25 18:02:58 INFO MemoryStore: MemoryStore started with capacity 366.3 MB\r\n17/07/25 18:02:58 INFO SparkEnv: Registering OutputCommitCoordinator\r\n17/07/25 18:02:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.\r\n17/07/25 18:02:58 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.146:4040\r\n17/07/25 18:02:58 INFO SparkContext: Added file file:/.../spark/sql/gen-sql-markdown.py at file:/.../spark/sql/gen-sql-markdown.py with timestamp 1500973378636\r\n17/07/25 18:02:58 INFO Utils: Copying /.../spark/sql/gen-sql-markdown.py to /private/var/folders/9j/gf_c342d7d150mwrxvkqnc180000gn/T/spark-0eb99795-6a5e-4101-8ed2-c55b3ba80173/userFiles-64210993-0ed8-4c05-85bd-83d13ae22831/gen-sql-markdown.py\r\n17/07/25 18:02:58 INFO Executor: Starting executor ID driver on host localhost\r\n17/07/25 18:02:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62696.\r\n17/07/25 18:02:58 INFO NettyBlockTransferService: Server created on 192.168.0.146:62696\r\n17/07/25 18:02:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\r\n17/07/25 18:02:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.146, 62696, None)\r\n17/07/25 18:02:58 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.146:62696 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.146, 62696, None)\r\n17/07/25 18:02:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.146, 62696, None)\r\n17/07/25 18:02:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.146, 62696, None)\r\n17/07/25 18:02:59 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('/.../spark/sql/_spark-warehouse').\r\n17/07/25 18:02:59 INFO SharedState: Warehouse path is '/.../spark/sql/_spark-warehouse'.\r\n17/07/25 18:02:59 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint\r\n17/07/25 18:02:59 INFO SparkUI: Stopped Spark web UI at http://192.168.0.146:4040\r\n17/07/25 18:02:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\r\n17/07/25 18:02:59 INFO MemoryStore: MemoryStore cleared\r\n17/07/25 18:02:59 INFO BlockManager: BlockManager stopped\r\n17/07/25 18:02:59 INFO BlockManagerMaster: BlockManagerMaster stopped\r\n17/07/25 18:02:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\r\n17/07/25 18:02:59 INFO SparkContext: Successfully stopped SparkContext\r\n17/07/25 18:02:59 INFO ShutdownHookManager: Shutdown hook called\r\n17/07/25 18:02:59 INFO ShutdownHookManager: Deleting directory /private/var/folders/9j/gf_c342d7d150mwrxvkqnc180000gn/T/spark-0eb99795-6a5e-4101-8ed2-c55b3ba80173\r\n17/07/25 18:02:59 INFO ShutdownHookManager: Deleting directory /private/var/folders/9j/gf_c342d7d150mwrxvkqnc180000gn/T/spark-0eb99795-6a5e-4101-8ed2-c55b3ba80173/pyspark-4cdacd99-6ab2-4a1e-9b76-c4d6d457477e\r\nGenerating HTML files for SQL documentation.\r\nINFO    -  Cleaning site directory\r\nINFO    -  Building documentation to directory: /.../spark/sql/site\r\n```\r\n\r\nWould you prefer to get rid of this?",
    "commit": "c711ff5363a0608c11b97c915bfc8b8cdbf2ba95",
    "createdAt": "2017-07-25T09:06:01Z",
    "diffHunk": "@@ -0,0 +1,24 @@\n+#"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Oh, actually, I think I can get rid of this. Let me try.",
    "commit": "c711ff5363a0608c11b97c915bfc8b8cdbf2ba95",
    "createdAt": "2017-07-25T09:10:39Z",
    "diffHunk": "@@ -0,0 +1,24 @@\n+#"
  }],
  "prId": 18702
}]