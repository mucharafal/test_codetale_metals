[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "This is > 100 chars. Do we have the same limitation in java?\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-30T23:49:11Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {\n+  private final Logger logger = LoggerFactory.getLogger(StandaloneShuffleBlockManager.class);\n+\n+  // Map from \"appId-execId\" to the executor's configuration.\n+  private final ConcurrentHashMap<String, ExecutorShuffleConfig> executors =\n+    new ConcurrentHashMap<String, ExecutorShuffleConfig>();\n+\n+  // Returns an id suitable for a single executor within a single application.\n+  private String getAppExecId(String appId, String execId) {\n+    return appId + \"-\" + execId;\n+  }\n+\n+  /** Registers a new Executor with all the configuration we need to find its shuffle files. */\n+  public void registerExecutor(\n+      String appId,\n+      String execId,\n+      ExecutorShuffleConfig executorConfig) {\n+    String fullId = getAppExecId(appId, execId);\n+    executors.put(fullId, executorConfig);\n+  }\n+\n+  /**\n+   * Obtains a FileSegmentManagedBuffer from a shuffle block id. We expect the blockId has the\n+   * format \"shuffle_ShuffleId_MapId_ReduceId\", and additionally make assumptions about how the\n+   * hash and sort based shuffles store their data.\n+   */\n+  public ManagedBuffer getBlockData(String appId, String execId, String blockId) {\n+    String[] blockIdParts = blockId.split(\"_\");\n+    if (blockIdParts.length < 4) {\n+      throw new IllegalArgumentException(\"Unexpected block id format: \" + blockId);\n+    } else if (!blockIdParts[0].equals(\"shuffle\")) {\n+      throw new IllegalArgumentException(\"Expected shuffle block id, got: \" + blockId);\n+    }\n+    int shuffleId = Integer.parseInt(blockIdParts[1]);\n+    int mapId = Integer.parseInt(blockIdParts[2]);\n+    int reduceId = Integer.parseInt(blockIdParts[3]);\n+\n+    ExecutorShuffleConfig executor = executors.get(getAppExecId(appId, execId));\n+    if (executor == null) {\n+      throw new RuntimeException(\n+        String.format(\"Executor is not registered (appId=%s, execId=%s)\", appId, execId));\n+    }\n+\n+    if (\"org.apache.spark.shuffle.hash.HashShuffleManager\".equals(executor.shuffleManager)) {\n+      return getHashBasedShuffleBlockData(executor, blockId);\n+    } else if (\"org.apache.spark.shuffle.sort.SortShuffleManager\".equals(executor.shuffleManager)) {\n+      return getSortBasedShuffleBlockData(executor, shuffleId, mapId, reduceId);\n+    } else {\n+      throw new UnsupportedOperationException(\n+        \"Unsupported shuffle manager: \" + executor.shuffleManager);\n+    }\n+  }\n+\n+  /**\n+   * Hash-based shuffle data is simply stored as one file per block.\n+   * This logic is from FileShuffleBlockManager.\n+   */\n+  // TODO: Support consolidated hash shuffle files\n+  private ManagedBuffer getHashBasedShuffleBlockData(ExecutorShuffleConfig executor, String blockId) {"
  }, {
    "author": {
      "login": "aarondav"
    },
    "body": "Yes, I will fix this.\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-31T01:47:42Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {\n+  private final Logger logger = LoggerFactory.getLogger(StandaloneShuffleBlockManager.class);\n+\n+  // Map from \"appId-execId\" to the executor's configuration.\n+  private final ConcurrentHashMap<String, ExecutorShuffleConfig> executors =\n+    new ConcurrentHashMap<String, ExecutorShuffleConfig>();\n+\n+  // Returns an id suitable for a single executor within a single application.\n+  private String getAppExecId(String appId, String execId) {\n+    return appId + \"-\" + execId;\n+  }\n+\n+  /** Registers a new Executor with all the configuration we need to find its shuffle files. */\n+  public void registerExecutor(\n+      String appId,\n+      String execId,\n+      ExecutorShuffleConfig executorConfig) {\n+    String fullId = getAppExecId(appId, execId);\n+    executors.put(fullId, executorConfig);\n+  }\n+\n+  /**\n+   * Obtains a FileSegmentManagedBuffer from a shuffle block id. We expect the blockId has the\n+   * format \"shuffle_ShuffleId_MapId_ReduceId\", and additionally make assumptions about how the\n+   * hash and sort based shuffles store their data.\n+   */\n+  public ManagedBuffer getBlockData(String appId, String execId, String blockId) {\n+    String[] blockIdParts = blockId.split(\"_\");\n+    if (blockIdParts.length < 4) {\n+      throw new IllegalArgumentException(\"Unexpected block id format: \" + blockId);\n+    } else if (!blockIdParts[0].equals(\"shuffle\")) {\n+      throw new IllegalArgumentException(\"Expected shuffle block id, got: \" + blockId);\n+    }\n+    int shuffleId = Integer.parseInt(blockIdParts[1]);\n+    int mapId = Integer.parseInt(blockIdParts[2]);\n+    int reduceId = Integer.parseInt(blockIdParts[3]);\n+\n+    ExecutorShuffleConfig executor = executors.get(getAppExecId(appId, execId));\n+    if (executor == null) {\n+      throw new RuntimeException(\n+        String.format(\"Executor is not registered (appId=%s, execId=%s)\", appId, execId));\n+    }\n+\n+    if (\"org.apache.spark.shuffle.hash.HashShuffleManager\".equals(executor.shuffleManager)) {\n+      return getHashBasedShuffleBlockData(executor, blockId);\n+    } else if (\"org.apache.spark.shuffle.sort.SortShuffleManager\".equals(executor.shuffleManager)) {\n+      return getSortBasedShuffleBlockData(executor, shuffleId, mapId, reduceId);\n+    } else {\n+      throw new UnsupportedOperationException(\n+        \"Unsupported shuffle manager: \" + executor.shuffleManager);\n+    }\n+  }\n+\n+  /**\n+   * Hash-based shuffle data is simply stored as one file per block.\n+   * This logic is from FileShuffleBlockManager.\n+   */\n+  // TODO: Support consolidated hash shuffle files\n+  private ManagedBuffer getHashBasedShuffleBlockData(ExecutorShuffleConfig executor, String blockId) {"
  }],
  "prId": 3001
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "What will happen if the user uses this with consolidated hash shuffle file? Will it fail through some obscure stream exception? Maybe we should throw an early exception if they try to do that.\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-30T23:50:28Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {\n+  private final Logger logger = LoggerFactory.getLogger(StandaloneShuffleBlockManager.class);\n+\n+  // Map from \"appId-execId\" to the executor's configuration.\n+  private final ConcurrentHashMap<String, ExecutorShuffleConfig> executors =\n+    new ConcurrentHashMap<String, ExecutorShuffleConfig>();\n+\n+  // Returns an id suitable for a single executor within a single application.\n+  private String getAppExecId(String appId, String execId) {\n+    return appId + \"-\" + execId;\n+  }\n+\n+  /** Registers a new Executor with all the configuration we need to find its shuffle files. */\n+  public void registerExecutor(\n+      String appId,\n+      String execId,\n+      ExecutorShuffleConfig executorConfig) {\n+    String fullId = getAppExecId(appId, execId);\n+    executors.put(fullId, executorConfig);\n+  }\n+\n+  /**\n+   * Obtains a FileSegmentManagedBuffer from a shuffle block id. We expect the blockId has the\n+   * format \"shuffle_ShuffleId_MapId_ReduceId\", and additionally make assumptions about how the\n+   * hash and sort based shuffles store their data.\n+   */\n+  public ManagedBuffer getBlockData(String appId, String execId, String blockId) {\n+    String[] blockIdParts = blockId.split(\"_\");\n+    if (blockIdParts.length < 4) {\n+      throw new IllegalArgumentException(\"Unexpected block id format: \" + blockId);\n+    } else if (!blockIdParts[0].equals(\"shuffle\")) {\n+      throw new IllegalArgumentException(\"Expected shuffle block id, got: \" + blockId);\n+    }\n+    int shuffleId = Integer.parseInt(blockIdParts[1]);\n+    int mapId = Integer.parseInt(blockIdParts[2]);\n+    int reduceId = Integer.parseInt(blockIdParts[3]);\n+\n+    ExecutorShuffleConfig executor = executors.get(getAppExecId(appId, execId));\n+    if (executor == null) {\n+      throw new RuntimeException(\n+        String.format(\"Executor is not registered (appId=%s, execId=%s)\", appId, execId));\n+    }\n+\n+    if (\"org.apache.spark.shuffle.hash.HashShuffleManager\".equals(executor.shuffleManager)) {\n+      return getHashBasedShuffleBlockData(executor, blockId);\n+    } else if (\"org.apache.spark.shuffle.sort.SortShuffleManager\".equals(executor.shuffleManager)) {\n+      return getSortBasedShuffleBlockData(executor, shuffleId, mapId, reduceId);\n+    } else {\n+      throw new UnsupportedOperationException(\n+        \"Unsupported shuffle manager: \" + executor.shuffleManager);\n+    }\n+  }\n+\n+  /**\n+   * Hash-based shuffle data is simply stored as one file per block.\n+   * This logic is from FileShuffleBlockManager.\n+   */\n+  // TODO: Support consolidated hash shuffle files"
  }, {
    "author": {
      "login": "aarondav"
    },
    "body": "The exception wouldn't be great, it would say it couldn't find the shuffle block. I will add a check in BlockManager that disallows the co-occurrence of externalShuffleService and consolidateFiles (and not Sort-based shuffle).\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-31T01:48:57Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {\n+  private final Logger logger = LoggerFactory.getLogger(StandaloneShuffleBlockManager.class);\n+\n+  // Map from \"appId-execId\" to the executor's configuration.\n+  private final ConcurrentHashMap<String, ExecutorShuffleConfig> executors =\n+    new ConcurrentHashMap<String, ExecutorShuffleConfig>();\n+\n+  // Returns an id suitable for a single executor within a single application.\n+  private String getAppExecId(String appId, String execId) {\n+    return appId + \"-\" + execId;\n+  }\n+\n+  /** Registers a new Executor with all the configuration we need to find its shuffle files. */\n+  public void registerExecutor(\n+      String appId,\n+      String execId,\n+      ExecutorShuffleConfig executorConfig) {\n+    String fullId = getAppExecId(appId, execId);\n+    executors.put(fullId, executorConfig);\n+  }\n+\n+  /**\n+   * Obtains a FileSegmentManagedBuffer from a shuffle block id. We expect the blockId has the\n+   * format \"shuffle_ShuffleId_MapId_ReduceId\", and additionally make assumptions about how the\n+   * hash and sort based shuffles store their data.\n+   */\n+  public ManagedBuffer getBlockData(String appId, String execId, String blockId) {\n+    String[] blockIdParts = blockId.split(\"_\");\n+    if (blockIdParts.length < 4) {\n+      throw new IllegalArgumentException(\"Unexpected block id format: \" + blockId);\n+    } else if (!blockIdParts[0].equals(\"shuffle\")) {\n+      throw new IllegalArgumentException(\"Expected shuffle block id, got: \" + blockId);\n+    }\n+    int shuffleId = Integer.parseInt(blockIdParts[1]);\n+    int mapId = Integer.parseInt(blockIdParts[2]);\n+    int reduceId = Integer.parseInt(blockIdParts[3]);\n+\n+    ExecutorShuffleConfig executor = executors.get(getAppExecId(appId, execId));\n+    if (executor == null) {\n+      throw new RuntimeException(\n+        String.format(\"Executor is not registered (appId=%s, execId=%s)\", appId, execId));\n+    }\n+\n+    if (\"org.apache.spark.shuffle.hash.HashShuffleManager\".equals(executor.shuffleManager)) {\n+      return getHashBasedShuffleBlockData(executor, blockId);\n+    } else if (\"org.apache.spark.shuffle.sort.SortShuffleManager\".equals(executor.shuffleManager)) {\n+      return getSortBasedShuffleBlockData(executor, shuffleId, mapId, reduceId);\n+    } else {\n+      throw new UnsupportedOperationException(\n+        \"Unsupported shuffle manager: \" + executor.shuffleManager);\n+    }\n+  }\n+\n+  /**\n+   * Hash-based shuffle data is simply stored as one file per block.\n+   * This logic is from FileShuffleBlockManager.\n+   */\n+  // TODO: Support consolidated hash shuffle files"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "Yeah that's what I mean, do it on the executor side\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-31T02:00:51Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {\n+  private final Logger logger = LoggerFactory.getLogger(StandaloneShuffleBlockManager.class);\n+\n+  // Map from \"appId-execId\" to the executor's configuration.\n+  private final ConcurrentHashMap<String, ExecutorShuffleConfig> executors =\n+    new ConcurrentHashMap<String, ExecutorShuffleConfig>();\n+\n+  // Returns an id suitable for a single executor within a single application.\n+  private String getAppExecId(String appId, String execId) {\n+    return appId + \"-\" + execId;\n+  }\n+\n+  /** Registers a new Executor with all the configuration we need to find its shuffle files. */\n+  public void registerExecutor(\n+      String appId,\n+      String execId,\n+      ExecutorShuffleConfig executorConfig) {\n+    String fullId = getAppExecId(appId, execId);\n+    executors.put(fullId, executorConfig);\n+  }\n+\n+  /**\n+   * Obtains a FileSegmentManagedBuffer from a shuffle block id. We expect the blockId has the\n+   * format \"shuffle_ShuffleId_MapId_ReduceId\", and additionally make assumptions about how the\n+   * hash and sort based shuffles store their data.\n+   */\n+  public ManagedBuffer getBlockData(String appId, String execId, String blockId) {\n+    String[] blockIdParts = blockId.split(\"_\");\n+    if (blockIdParts.length < 4) {\n+      throw new IllegalArgumentException(\"Unexpected block id format: \" + blockId);\n+    } else if (!blockIdParts[0].equals(\"shuffle\")) {\n+      throw new IllegalArgumentException(\"Expected shuffle block id, got: \" + blockId);\n+    }\n+    int shuffleId = Integer.parseInt(blockIdParts[1]);\n+    int mapId = Integer.parseInt(blockIdParts[2]);\n+    int reduceId = Integer.parseInt(blockIdParts[3]);\n+\n+    ExecutorShuffleConfig executor = executors.get(getAppExecId(appId, execId));\n+    if (executor == null) {\n+      throw new RuntimeException(\n+        String.format(\"Executor is not registered (appId=%s, execId=%s)\", appId, execId));\n+    }\n+\n+    if (\"org.apache.spark.shuffle.hash.HashShuffleManager\".equals(executor.shuffleManager)) {\n+      return getHashBasedShuffleBlockData(executor, blockId);\n+    } else if (\"org.apache.spark.shuffle.sort.SortShuffleManager\".equals(executor.shuffleManager)) {\n+      return getSortBasedShuffleBlockData(executor, shuffleId, mapId, reduceId);\n+    } else {\n+      throw new UnsupportedOperationException(\n+        \"Unsupported shuffle manager: \" + executor.shuffleManager);\n+    }\n+  }\n+\n+  /**\n+   * Hash-based shuffle data is simply stored as one file per block.\n+   * This logic is from FileShuffleBlockManager.\n+   */\n+  // TODO: Support consolidated hash shuffle files"
  }],
  "prId": 3001
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "We should add a note here that this format is sync'ed with `ShuffleBlockId`\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-30T23:52:43Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {\n+  private final Logger logger = LoggerFactory.getLogger(StandaloneShuffleBlockManager.class);\n+\n+  // Map from \"appId-execId\" to the executor's configuration.\n+  private final ConcurrentHashMap<String, ExecutorShuffleConfig> executors =\n+    new ConcurrentHashMap<String, ExecutorShuffleConfig>();\n+\n+  // Returns an id suitable for a single executor within a single application.\n+  private String getAppExecId(String appId, String execId) {\n+    return appId + \"-\" + execId;\n+  }\n+\n+  /** Registers a new Executor with all the configuration we need to find its shuffle files. */\n+  public void registerExecutor(\n+      String appId,\n+      String execId,\n+      ExecutorShuffleConfig executorConfig) {\n+    String fullId = getAppExecId(appId, execId);\n+    executors.put(fullId, executorConfig);\n+  }\n+\n+  /**\n+   * Obtains a FileSegmentManagedBuffer from a shuffle block id. We expect the blockId has the\n+   * format \"shuffle_ShuffleId_MapId_ReduceId\", and additionally make assumptions about how the"
  }],
  "prId": 3001
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "same here, link this to `ShuffleDataBlockId`\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-30T23:53:21Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {\n+  private final Logger logger = LoggerFactory.getLogger(StandaloneShuffleBlockManager.class);\n+\n+  // Map from \"appId-execId\" to the executor's configuration.\n+  private final ConcurrentHashMap<String, ExecutorShuffleConfig> executors =\n+    new ConcurrentHashMap<String, ExecutorShuffleConfig>();\n+\n+  // Returns an id suitable for a single executor within a single application.\n+  private String getAppExecId(String appId, String execId) {\n+    return appId + \"-\" + execId;\n+  }\n+\n+  /** Registers a new Executor with all the configuration we need to find its shuffle files. */\n+  public void registerExecutor(\n+      String appId,\n+      String execId,\n+      ExecutorShuffleConfig executorConfig) {\n+    String fullId = getAppExecId(appId, execId);\n+    executors.put(fullId, executorConfig);\n+  }\n+\n+  /**\n+   * Obtains a FileSegmentManagedBuffer from a shuffle block id. We expect the blockId has the\n+   * format \"shuffle_ShuffleId_MapId_ReduceId\", and additionally make assumptions about how the\n+   * hash and sort based shuffles store their data.\n+   */\n+  public ManagedBuffer getBlockData(String appId, String execId, String blockId) {\n+    String[] blockIdParts = blockId.split(\"_\");\n+    if (blockIdParts.length < 4) {\n+      throw new IllegalArgumentException(\"Unexpected block id format: \" + blockId);\n+    } else if (!blockIdParts[0].equals(\"shuffle\")) {\n+      throw new IllegalArgumentException(\"Expected shuffle block id, got: \" + blockId);\n+    }\n+    int shuffleId = Integer.parseInt(blockIdParts[1]);\n+    int mapId = Integer.parseInt(blockIdParts[2]);\n+    int reduceId = Integer.parseInt(blockIdParts[3]);\n+\n+    ExecutorShuffleConfig executor = executors.get(getAppExecId(appId, execId));\n+    if (executor == null) {\n+      throw new RuntimeException(\n+        String.format(\"Executor is not registered (appId=%s, execId=%s)\", appId, execId));\n+    }\n+\n+    if (\"org.apache.spark.shuffle.hash.HashShuffleManager\".equals(executor.shuffleManager)) {\n+      return getHashBasedShuffleBlockData(executor, blockId);\n+    } else if (\"org.apache.spark.shuffle.sort.SortShuffleManager\".equals(executor.shuffleManager)) {\n+      return getSortBasedShuffleBlockData(executor, shuffleId, mapId, reduceId);\n+    } else {\n+      throw new UnsupportedOperationException(\n+        \"Unsupported shuffle manager: \" + executor.shuffleManager);\n+    }\n+  }\n+\n+  /**\n+   * Hash-based shuffle data is simply stored as one file per block.\n+   * This logic is from FileShuffleBlockManager.\n+   */\n+  // TODO: Support consolidated hash shuffle files\n+  private ManagedBuffer getHashBasedShuffleBlockData(ExecutorShuffleConfig executor, String blockId) {\n+    File shuffleFile = getFile(executor.localDirs, executor.subDirsPerLocalDir, blockId);\n+    return new FileSegmentManagedBuffer(shuffleFile, 0, shuffleFile.length());\n+  }\n+\n+  /**\n+   * Sort-based shuffle data uses an index called \"shuffle_ShuffleId_MapId_0.index\" into a data file\n+   * called \"shuffle_ShuffleId_MapId_0.data\". This logic is from IndexShuffleBlockManager."
  }],
  "prId": 3001
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "High-level question: what's specific about this class that makes it `Standalone`? The only difference in Yarn is that we make the `localDirs` a special path that includes the application IDs, but I think we could reuse a lot of this code there, especially the ones that decode shuffle files in either manager.\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-31T01:52:09Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {"
  }, {
    "author": {
      "login": "aarondav"
    },
    "body": "Ah -- this is not \"standalone\" as in the deploy mode, but \"standalone\" as in \"not inside an executor\". So it works for both!\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-31T01:58:20Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "(Actually we might be able to just use this class altogether in Yarn, but I still need to verify this)\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-31T01:59:38Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "Oh cool. I think we should call it something else because a lot of people automatically associate \"standalone\" with the cluster manager. There was a PR a while back that rewords this in the docs to replace \"standalone\" with something like \"self-contained\" or \"isolated\"\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-31T02:06:31Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {"
  }, {
    "author": {
      "login": "aarondav"
    },
    "body": "This is a good point, but I'm not very creative with names. I can't think of a better one for this situation. If you have one, I'll switch.\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-31T23:37:29Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "Ok, me neither. I'll let you know if I come up with anything.\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-11-01T00:43:54Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {"
  }],
  "prId": 3001
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "we should log something here\n",
    "commit": "4d1f8c174f362028a6a439a567bc2241f82a61c6",
    "createdAt": "2014-10-31T05:37:31Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.shuffle;\n+\n+import java.io.DataInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.buffer.FileSegmentManagedBuffer;\n+import org.apache.spark.network.buffer.ManagedBuffer;\n+import org.apache.spark.network.util.JavaUtils;\n+\n+/**\n+ * Manages converting shuffle BlockIds into physical segments of local files. Each Executor must\n+ * register its own configuration about where it stores its files (local dirs) and how (shuffle\n+ * manager). The logic for retrieval of individual files is replicated from Spark's\n+ * FileShuffleBlockManager and IndexShuffleBlockManager.\n+ *\n+ * Executors with shuffle file consolidation are not currently supported, as the index is stored in\n+ * the Executor's memory, unlike the IndexShuffleBlockManager.\n+ */\n+public class StandaloneShuffleBlockManager {\n+  private final Logger logger = LoggerFactory.getLogger(StandaloneShuffleBlockManager.class);\n+\n+  // Map from \"appId-execId\" to the executor's configuration.\n+  private final ConcurrentHashMap<String, ExecutorShuffleConfig> executors =\n+    new ConcurrentHashMap<String, ExecutorShuffleConfig>();\n+\n+  // Returns an id suitable for a single executor within a single application.\n+  private String getAppExecId(String appId, String execId) {\n+    return appId + \"-\" + execId;\n+  }\n+\n+  /** Registers a new Executor with all the configuration we need to find its shuffle files. */\n+  public void registerExecutor(\n+      String appId,\n+      String execId,\n+      ExecutorShuffleConfig executorConfig) {\n+    String fullId = getAppExecId(appId, execId);\n+    executors.put(fullId, executorConfig);"
  }],
  "prId": 3001
}]