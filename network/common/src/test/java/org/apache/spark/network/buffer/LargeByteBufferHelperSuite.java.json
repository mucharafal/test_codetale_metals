[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: after `java.*`\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T20:18:07Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import org.junit.Test;"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Similar comments to previous test regarding large temp file and this value.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T20:19:01Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import org.junit.Test;\n+\n+import java.io.*;\n+import java.nio.channels.FileChannel;\n+\n+import static org.junit.Assert.*;\n+\n+public class LargeByteBufferHelperSuite {\n+\n+  @Test\n+  public void testMapFile() throws IOException {\n+    File testFile = File.createTempFile(\"large-byte-buffer-test\", \".bin\");\n+    testFile.deleteOnExit();\n+    OutputStream out = new FileOutputStream(testFile);\n+    byte[] buffer = new byte[1 << 16];\n+    long len = 3L << 30;\n+    assertTrue(len > Integer.MAX_VALUE);  // its 1.5x Integer.MAX_VALUE, just a sanity check"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Ouch, a test that writes a 2GB file... can we use an approach similar to the memory-based one?\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T17:04:37Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.*;\n+import java.nio.channels.FileChannel;\n+\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class LargeByteBufferHelperSuite {\n+\n+  @Test\n+  public void testMapFile() throws IOException {\n+    File testFile = File.createTempFile(\"large-byte-buffer-test\", \".bin\");\n+    try {\n+      testFile.deleteOnExit();\n+      OutputStream out = new FileOutputStream(testFile);\n+      byte[] buffer = new byte[1 << 16];\n+      long len = ((long)buffer.length) + Integer.MAX_VALUE + 1;"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "I can certainly add some test that is like the memory-based one which will be smaller.  But I put this in specifically because I want **at least one test** that stresses behavior over 2GB.  I figure the best way to do with large files that get memory mapped.\n\nI don't love this either, but don't you think we should have at least some test with over 2GB, since that's the whole point of the patch?  Any other ideas of how we can do it?\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T20:10:50Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.*;\n+import java.nio.channels.FileChannel;\n+\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class LargeByteBufferHelperSuite {\n+\n+  @Test\n+  public void testMapFile() throws IOException {\n+    File testFile = File.createTempFile(\"large-byte-buffer-test\", \".bin\");\n+    try {\n+      testFile.deleteOnExit();\n+      OutputStream out = new FileOutputStream(testFile);\n+      byte[] buffer = new byte[1 << 16];\n+      long len = ((long)buffer.length) + Integer.MAX_VALUE + 1;"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "While it's always nice to have more tests, this is what I worry about:\n\n```\n$ time dd if=/dev/zero of=/tmp/2gb bs=1024 count=$((2*1024*1024))\n2097152+0 records in\n2097152+0 records out\n2147483648 bytes (2.1 GB) copied, 9.05902 s, 237 MB/s\n\nreal    0m9.061s\nuser    0m1.337s\nsys     0m4.270s\n```\n\nThat's with a fast local SSD. Most of the underlying logic here is the same as the memory-based test, isn't it? Feels like the only extra things being tested are:\n- The ability of the jdk to mmap a region of a file larger than 2gb\n- The ability of your code to wrap a large file into multiple byte buffers\n\nThe only test I see as really interesting is the second. Using a file > 2g would only really help test the first.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T20:18:02Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.*;\n+import java.nio.channels.FileChannel;\n+\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class LargeByteBufferHelperSuite {\n+\n+  @Test\n+  public void testMapFile() throws IOException {\n+    File testFile = File.createTempFile(\"large-byte-buffer-test\", \".bin\");\n+    try {\n+      testFile.deleteOnExit();\n+      OutputStream out = new FileOutputStream(testFile);\n+      byte[] buffer = new byte[1 << 16];\n+      long len = ((long)buffer.length) + Integer.MAX_VALUE + 1;"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "See my top-level comment below RE: idea of using data generators + checksums to avoid materialization of entire input in order to do comparisons.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T20:27:27Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.*;\n+import java.nio.channels.FileChannel;\n+\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class LargeByteBufferHelperSuite {\n+\n+  @Test\n+  public void testMapFile() throws IOException {\n+    File testFile = File.createTempFile(\"large-byte-buffer-test\", \".bin\");\n+    try {\n+      testFile.deleteOnExit();\n+      OutputStream out = new FileOutputStream(testFile);\n+      byte[] buffer = new byte[1 << 16];\n+      long len = ((long)buffer.length) + Integer.MAX_VALUE + 1;"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "actually, the jvm **cannot** mmap a region of a file larger than 2GB, precisely because `channel.map` returns a `ByteBuffer` -- so the code actually has to [break it into a chunks](https://github.com/squito/spark/blob/112c49e7074dc3a53f7425f6b93fbff7608f6a23/network/common/src/main/java/org/apache/spark/network/buffer/LargeByteBufferHelper.java#L80).  (maybe that is what you meant, just wanted to clarify.)\n\nThough honestly, that isn't even the main thing I wanted to test. really I just wanted to test the dumb basic stuff, eg. `position` isn't accidentally treated as an int somewhere so it overflows.  I know I'm really prone to messing up dumb stuff like that if I don't test it (and even if it is correct now, to prevent future regressions).\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T20:56:42Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.*;\n+import java.nio.channels.FileChannel;\n+\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class LargeByteBufferHelperSuite {\n+\n+  @Test\n+  public void testMapFile() throws IOException {\n+    File testFile = File.createTempFile(\"large-byte-buffer-test\", \".bin\");\n+    try {\n+      testFile.deleteOnExit();\n+      OutputStream out = new FileOutputStream(testFile);\n+      byte[] buffer = new byte[1 << 16];\n+      long len = ((long)buffer.length) + Integer.MAX_VALUE + 1;"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I think we're saying the same thing, it just depends on where you add the missing punctuation marks. :-)\n\ni.e. you can mmap a region smaller than 2gb from a file that is larger than 2gb.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T20:59:52Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.*;\n+import java.nio.channels.FileChannel;\n+\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class LargeByteBufferHelperSuite {\n+\n+  @Test\n+  public void testMapFile() throws IOException {\n+    File testFile = File.createTempFile(\"large-byte-buffer-test\", \".bin\");\n+    try {\n+      testFile.deleteOnExit();\n+      OutputStream out = new FileOutputStream(testFile);\n+      byte[] buffer = new byte[1 << 16];\n+      long len = ((long)buffer.length) + Integer.MAX_VALUE + 1;"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I'm a little concerned that writing the same data over and over might mask some nasty issues like the one I think I found earlier. Perhaps this should be writing random data instead? (That would probably be prohibitively slow with such a large test file, though.)\n\nYou could have two `java.util.Random` instances with the same seed to be able to recreate the input data while checking.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T17:07:34Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.*;\n+import java.nio.channels.FileChannel;\n+\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class LargeByteBufferHelperSuite {\n+\n+  @Test\n+  public void testMapFile() throws IOException {\n+    File testFile = File.createTempFile(\"large-byte-buffer-test\", \".bin\");\n+    try {\n+      testFile.deleteOnExit();\n+      OutputStream out = new FileOutputStream(testFile);\n+      byte[] buffer = new byte[1 << 16];\n+      long len = ((long)buffer.length) + Integer.MAX_VALUE + 1;\n+      for (int i = 0; i < buffer.length; i++) {\n+        buffer[i] = (byte) i;\n+      }\n+      for (int i = 0; i < len / buffer.length; i++) {\n+        out.write(buffer);"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "If the only way to get appropriate coverage is with a slow test, then we can isolate that test into a `*SlowTests` suite (or use whatever JUnit's equivalent of ScalaTest's `@Slow` test tags is) and only run it under special circumstances (e.g. pre-release checks or a build that ones once per day).  Before we resort to this, though, let's just see how long it takes with randomized data; no need to over-engineer things if the test turns out to be fast enough as-is.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T17:10:11Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.*;\n+import java.nio.channels.FileChannel;\n+\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class LargeByteBufferHelperSuite {\n+\n+  @Test\n+  public void testMapFile() throws IOException {\n+    File testFile = File.createTempFile(\"large-byte-buffer-test\", \".bin\");\n+    try {\n+      testFile.deleteOnExit();\n+      OutputStream out = new FileOutputStream(testFile);\n+      byte[] buffer = new byte[1 << 16];\n+      long len = ((long)buffer.length) + Integer.MAX_VALUE + 1;\n+      for (int i = 0; i < buffer.length; i++) {\n+        buffer[i] = (byte) i;\n+      }\n+      for (int i = 0; i < len / buffer.length; i++) {\n+        out.write(buffer);"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "on my laptop, the test went from 6 seconds to 28 seconds when I used a random number generator ... I'll mess with it a bit to see if there is some easy way to speed it up\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T20:21:43Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.*;\n+import java.nio.channels.FileChannel;\n+\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class LargeByteBufferHelperSuite {\n+\n+  @Test\n+  public void testMapFile() throws IOException {\n+    File testFile = File.createTempFile(\"large-byte-buffer-test\", \".bin\");\n+    try {\n+      testFile.deleteOnExit();\n+      OutputStream out = new FileOutputStream(testFile);\n+      byte[] buffer = new byte[1 << 16];\n+      long len = ((long)buffer.length) + Integer.MAX_VALUE + 1;\n+      for (int i = 0; i < buffer.length; i++) {\n+        buffer[i] = (byte) i;\n+      }\n+      for (int i = 0; i < len / buffer.length; i++) {\n+        out.write(buffer);"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: `95, 10`\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-11-02T20:06:45Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.*;\n+import java.nio.channels.FileChannel;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class LargeByteBufferHelperSuite {\n+\n+  @Test\n+  public void testMapFile() throws IOException {\n+    File testFile = File.createTempFile(\"large-byte-buffer-test\", \".bin\");\n+    try {\n+      testFile.deleteOnExit();\n+      OutputStream out = new FileOutputStream(testFile);\n+      byte[] buffer = new byte[1 << 16];\n+      Random rng = new XORShiftRandom(0L);\n+      long len = ((long)buffer.length) + Integer.MAX_VALUE + 1;\n+      for (int i = 0; i < len / buffer.length; i++) {\n+        rng.nextBytes(buffer);\n+        out.write(buffer);\n+      }\n+      out.close();\n+\n+      FileChannel in = new FileInputStream(testFile).getChannel();\n+\n+      //fail quickly on bad bounds\n+      try {\n+        LargeByteBufferHelper.mapFile(in, FileChannel.MapMode.READ_ONLY, 0, len + 1);\n+        fail(\"expected exception\");\n+      } catch (IOException ioe) {\n+      }\n+      try {\n+        LargeByteBufferHelper.mapFile(in, FileChannel.MapMode.READ_ONLY, -1, 10);\n+        fail(\"expected exception\");\n+      } catch (IllegalArgumentException iae) {\n+      }\n+\n+      //now try to read from the buffer\n+      LargeByteBuffer buf = LargeByteBufferHelper.mapFile(in, FileChannel.MapMode.READ_ONLY, 0, len);\n+      assertEquals(len, buf.size());\n+      byte[] read = new byte[buffer.length];\n+      byte[] expected = new byte[buffer.length];\n+      Random rngExpected = new XORShiftRandom(0L);\n+      for (int i = 0; i < len / buffer.length; i++) {\n+        buf.get(read, 0, buffer.length);\n+        // assertArrayEquals() is really slow\n+        rngExpected.nextBytes(expected);\n+        for (int j = 0; j < buffer.length; j++) {\n+          if (read[j] !=  expected[j])\n+            fail(\"bad byte at (i,j) = (\" + i + \",\" + j + \")\");\n+        }\n+      }\n+    } finally {\n+      testFile.delete();\n+    }\n+  }\n+\n+  @Test\n+  public void testAllocate() {\n+    WrappedLargeByteBuffer buf = (WrappedLargeByteBuffer) LargeByteBufferHelper.allocate(95,10);"
  }],
  "prId": 5400
}]