[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: use 2-space indentation all over this file.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-07T21:50:37Z",
    "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+\n+public class LargeByteBufferHelper {\n+\n+    public static final int MAX_CHUNK = Integer.MAX_VALUE - 1000000;\n+\n+    public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+        return new WrappedLargeByteBuffer(new ByteBuffer[]{buffer});"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "another nit: `new ByteBuffer[] { buffer }`, also elsewhere\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-07T21:51:05Z",
    "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+\n+public class LargeByteBufferHelper {\n+\n+    public static final int MAX_CHUNK = Integer.MAX_VALUE - 1000000;\n+\n+    public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+        return new WrappedLargeByteBuffer(new ByteBuffer[]{buffer});"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You could either pre-allocate a `ByteBuffer[]` here, or use `com.google.common.collect.Lists.newArrayListWithExpectedSize`, for efficiency.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-07T21:53:01Z",
    "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+\n+public class LargeByteBufferHelper {\n+\n+    public static final int MAX_CHUNK = Integer.MAX_VALUE - 1000000;\n+\n+    public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+        return new WrappedLargeByteBuffer(new ByteBuffer[]{buffer});\n+    }\n+\n+    public static LargeByteBuffer asLargeByteBuffer(byte[] bytes) {\n+        return new WrappedLargeByteBuffer(new ByteBuffer[]{ByteBuffer.wrap(bytes)});\n+    }\n+\n+    public static LargeByteBuffer allocate(long size) {\n+        ArrayList<ByteBuffer> chunks = new ArrayList<ByteBuffer>();"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: after `java.*`\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T19:49:46Z",
    "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`asLargeByteBuffer(ByteBuffer.wrap(bytes))`\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T19:50:42Z",
    "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+\n+public class LargeByteBufferHelper {\n+\n+  public static final int MAX_CHUNK = Integer.MAX_VALUE - 1000000;\n+\n+  public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { buffer } );\n+  }\n+\n+  public static LargeByteBuffer asLargeByteBuffer(byte[] bytes) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { ByteBuffer.wrap(bytes) } );"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Is there a reason for `1000000`? Comment?\n\nAlso, should this be `MAX_CHUNK_SIZE`?\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T19:51:39Z",
    "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+\n+public class LargeByteBufferHelper {\n+\n+  public static final int MAX_CHUNK = Integer.MAX_VALUE - 1000000;"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit:\n\n```\nif {\n   ...\n}\n```\n\n(You could also use `Preconditions.checkState()`.)\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T19:54:56Z",
    "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+\n+public class LargeByteBufferHelper {\n+\n+  public static final int MAX_CHUNK = Integer.MAX_VALUE - 1000000;\n+\n+  public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { buffer } );\n+  }\n+\n+  public static LargeByteBuffer asLargeByteBuffer(byte[] bytes) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { ByteBuffer.wrap(bytes) } );\n+  }\n+\n+  public static LargeByteBuffer allocate(long size) {\n+    return allocate(size, MAX_CHUNK);\n+  }\n+\n+  @VisibleForTesting\n+  static LargeByteBuffer allocate(long size, int maxChunk) {\n+    int chunksNeeded = (int) ((size + maxChunk - 1) / maxChunk);\n+    ByteBuffer[] chunks = new ByteBuffer[chunksNeeded];\n+    long remaining = size;\n+    for (int i = 0; i < chunksNeeded; i++) {\n+      int nextSize = (int) Math.min(remaining, maxChunk);\n+      ByteBuffer next = ByteBuffer.allocate(nextSize);\n+      remaining -= nextSize;\n+      chunks[i] = next;\n+    }\n+    if (remaining != 0) throw new IllegalStateException(\"remaining = \" + remaining);"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: style is to double-indent these\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T19:55:38Z",
    "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+\n+public class LargeByteBufferHelper {\n+\n+  public static final int MAX_CHUNK = Integer.MAX_VALUE - 1000000;\n+\n+  public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { buffer } );\n+  }\n+\n+  public static LargeByteBuffer asLargeByteBuffer(byte[] bytes) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { ByteBuffer.wrap(bytes) } );\n+  }\n+\n+  public static LargeByteBuffer allocate(long size) {\n+    return allocate(size, MAX_CHUNK);\n+  }\n+\n+  @VisibleForTesting\n+  static LargeByteBuffer allocate(long size, int maxChunk) {\n+    int chunksNeeded = (int) ((size + maxChunk - 1) / maxChunk);\n+    ByteBuffer[] chunks = new ByteBuffer[chunksNeeded];\n+    long remaining = size;\n+    for (int i = 0; i < chunksNeeded; i++) {\n+      int nextSize = (int) Math.min(remaining, maxChunk);\n+      ByteBuffer next = ByteBuffer.allocate(nextSize);\n+      remaining -= nextSize;\n+      chunks[i] = next;\n+    }\n+    if (remaining != 0) throw new IllegalStateException(\"remaining = \" + remaining);\n+    return new WrappedLargeByteBuffer(chunks, maxChunk);\n+  }\n+\n+\n+  public static LargeByteBuffer mapFile(\n+    FileChannel channel,"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "not needed\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T19:57:11Z",
    "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+\n+public class LargeByteBufferHelper {\n+\n+  public static final int MAX_CHUNK = Integer.MAX_VALUE - 1000000;\n+\n+  public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { buffer } );\n+  }\n+\n+  public static LargeByteBuffer asLargeByteBuffer(byte[] bytes) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { ByteBuffer.wrap(bytes) } );\n+  }\n+\n+  public static LargeByteBuffer allocate(long size) {\n+    return allocate(size, MAX_CHUNK);\n+  }\n+\n+  @VisibleForTesting\n+  static LargeByteBuffer allocate(long size, int maxChunk) {\n+    int chunksNeeded = (int) ((size + maxChunk - 1) / maxChunk);\n+    ByteBuffer[] chunks = new ByteBuffer[chunksNeeded];\n+    long remaining = size;\n+    for (int i = 0; i < chunksNeeded; i++) {\n+      int nextSize = (int) Math.min(remaining, maxChunk);\n+      ByteBuffer next = ByteBuffer.allocate(nextSize);\n+      remaining -= nextSize;\n+      chunks[i] = next;\n+    }\n+    if (remaining != 0) throw new IllegalStateException(\"remaining = \" + remaining);\n+    return new WrappedLargeByteBuffer(chunks, maxChunk);\n+  }\n+\n+\n+  public static LargeByteBuffer mapFile(\n+    FileChannel channel,\n+    FileChannel.MapMode mode,\n+    long offset,\n+    long length\n+  ) throws IOException {\n+    int maxChunk = MAX_CHUNK;"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`List<Long> offsets = Lists.newArrayList()`\n\nMinor, but it seems like you could use `Lists.newArrayListWithExpectedSize()` which is a little more efficient.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T19:57:55Z",
    "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+\n+public class LargeByteBufferHelper {\n+\n+  public static final int MAX_CHUNK = Integer.MAX_VALUE - 1000000;\n+\n+  public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { buffer } );\n+  }\n+\n+  public static LargeByteBuffer asLargeByteBuffer(byte[] bytes) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { ByteBuffer.wrap(bytes) } );\n+  }\n+\n+  public static LargeByteBuffer allocate(long size) {\n+    return allocate(size, MAX_CHUNK);\n+  }\n+\n+  @VisibleForTesting\n+  static LargeByteBuffer allocate(long size, int maxChunk) {\n+    int chunksNeeded = (int) ((size + maxChunk - 1) / maxChunk);\n+    ByteBuffer[] chunks = new ByteBuffer[chunksNeeded];\n+    long remaining = size;\n+    for (int i = 0; i < chunksNeeded; i++) {\n+      int nextSize = (int) Math.min(remaining, maxChunk);\n+      ByteBuffer next = ByteBuffer.allocate(nextSize);\n+      remaining -= nextSize;\n+      chunks[i] = next;\n+    }\n+    if (remaining != 0) throw new IllegalStateException(\"remaining = \" + remaining);\n+    return new WrappedLargeByteBuffer(chunks, maxChunk);\n+  }\n+\n+\n+  public static LargeByteBuffer mapFile(\n+    FileChannel channel,\n+    FileChannel.MapMode mode,\n+    long offset,\n+    long length\n+  ) throws IOException {\n+    int maxChunk = MAX_CHUNK;\n+    ArrayList<Long> offsets = new ArrayList<Long>();"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "In fact, it seems like it would be possible to do all this in a single loop and avoid the `offsets` list altogether?\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T19:59:07Z",
    "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+\n+public class LargeByteBufferHelper {\n+\n+  public static final int MAX_CHUNK = Integer.MAX_VALUE - 1000000;\n+\n+  public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { buffer } );\n+  }\n+\n+  public static LargeByteBuffer asLargeByteBuffer(byte[] bytes) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { ByteBuffer.wrap(bytes) } );\n+  }\n+\n+  public static LargeByteBuffer allocate(long size) {\n+    return allocate(size, MAX_CHUNK);\n+  }\n+\n+  @VisibleForTesting\n+  static LargeByteBuffer allocate(long size, int maxChunk) {\n+    int chunksNeeded = (int) ((size + maxChunk - 1) / maxChunk);\n+    ByteBuffer[] chunks = new ByteBuffer[chunksNeeded];\n+    long remaining = size;\n+    for (int i = 0; i < chunksNeeded; i++) {\n+      int nextSize = (int) Math.min(remaining, maxChunk);\n+      ByteBuffer next = ByteBuffer.allocate(nextSize);\n+      remaining -= nextSize;\n+      chunks[i] = next;\n+    }\n+    if (remaining != 0) throw new IllegalStateException(\"remaining = \" + remaining);\n+    return new WrappedLargeByteBuffer(chunks, maxChunk);\n+  }\n+\n+\n+  public static LargeByteBuffer mapFile(\n+    FileChannel channel,\n+    FileChannel.MapMode mode,\n+    long offset,\n+    long length\n+  ) throws IOException {\n+    int maxChunk = MAX_CHUNK;\n+    ArrayList<Long> offsets = new ArrayList<Long>();\n+    long curOffset = offset;\n+    long end = offset + length;\n+    while (curOffset < end) {\n+      offsets.add(curOffset);\n+      int chunkLength = (int) Math.min((end - curOffset), maxChunk);\n+      curOffset += chunkLength;\n+    }\n+    offsets.add(end);\n+    ByteBuffer[] chunks = new ByteBuffer[offsets.size() - 1];\n+    for (int i = 0; i < offsets.size() - 1; i++) {"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "super nit: too many empty lines (also in other places).\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T16:48:20Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Utils for creating {@link org.apache.spark.network.buffer.LargeByteBuffer}s, either from\n+ * pre-allocated byte arrays, ByteBuffers, or by memory mapping a file.\n+ */\n+public class LargeByteBufferHelper {\n+\n+  // netty can't quite send msgs that are a full 2GB -- they need to be slightly smaller\n+  // not sure what the exact limit is, but 200 seems OK.\n+  /**\n+   * The maximum size of any ByteBuffer.\n+   * {@link org.apache.spark.network.buffer.LargeByteBuffer#asByteBuffer} will never return a\n+   * ByteBuffer larger than this.  This is close to the max ByteBuffer size (2GB), minus a small\n+   * amount for message overhead.\n+   */\n+  public static final int MAX_CHUNK_SIZE = Integer.MAX_VALUE - 200;\n+\n+  public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { buffer } );\n+  }\n+\n+  public static LargeByteBuffer asLargeByteBuffer(byte[] bytes) {\n+    return asLargeByteBuffer(ByteBuffer.wrap(bytes));\n+  }\n+\n+  public static LargeByteBuffer allocate(long size) {\n+    return allocate(size, MAX_CHUNK_SIZE);\n+  }\n+\n+  @VisibleForTesting\n+  static LargeByteBuffer allocate(long size, int maxChunk) {\n+    int chunksNeeded = (int) ((size + maxChunk - 1) / maxChunk);\n+    ByteBuffer[] chunks = new ByteBuffer[chunksNeeded];\n+    long remaining = size;\n+    for (int i = 0; i < chunksNeeded; i++) {\n+      int nextSize = (int) Math.min(remaining, maxChunk);\n+      ByteBuffer next = ByteBuffer.allocate(nextSize);\n+      remaining -= nextSize;\n+      chunks[i] = next;\n+    }\n+    if (remaining != 0) {\n+      throw new IllegalStateException(\"remaining = \" + remaining);\n+    }\n+    return new WrappedLargeByteBuffer(chunks, maxChunk);\n+  }\n+\n+\n+  public static LargeByteBuffer mapFile(\n+      FileChannel channel,\n+      FileChannel.MapMode mode,\n+      long offset,\n+      long length\n+  ) throws IOException {\n+    int chunksNeeded = (int) ((length  - 1) / MAX_CHUNK_SIZE) + 1;\n+    ByteBuffer[] chunks = new ByteBuffer[chunksNeeded];\n+    long curPos = offset;\n+    long end = offset + length;\n+    for (int i = 0; i < chunksNeeded; i++) {\n+      long nextPos = Math.min(curPos + MAX_CHUNK_SIZE, end);\n+      chunks[i] = channel.map(mode, curPos, nextPos - curPos);\n+      curPos = nextPos;\n+    }\n+    return new WrappedLargeByteBuffer(chunks);\n+  }\n+",
    "line": 87
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "chenghao-intel"
    },
    "body": "I am not sure if worth to think about to do the lazy mapping / loading, which probably can reduce the entire system memory utilization.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-04T00:58:47Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Utils for creating {@link org.apache.spark.network.buffer.LargeByteBuffer}s, either from\n+ * pre-allocated byte arrays, ByteBuffers, or by memory mapping a file.\n+ */\n+public class LargeByteBufferHelper {\n+\n+  // netty can't quite send msgs that are a full 2GB -- they need to be slightly smaller\n+  // not sure what the exact limit is, but 200 seems OK.\n+  /**\n+   * The maximum size of any ByteBuffer.\n+   * {@link org.apache.spark.network.buffer.LargeByteBuffer#asByteBuffer} will never return a\n+   * ByteBuffer larger than this.  This is close to the max ByteBuffer size (2GB), minus a small\n+   * amount for message overhead.\n+   */\n+  public static final int MAX_CHUNK_SIZE = Integer.MAX_VALUE - 200;\n+\n+  public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { buffer } );\n+  }\n+\n+  public static LargeByteBuffer asLargeByteBuffer(byte[] bytes) {\n+    return asLargeByteBuffer(ByteBuffer.wrap(bytes));\n+  }\n+\n+  public static LargeByteBuffer allocate(long size) {\n+    return allocate(size, MAX_CHUNK_SIZE);\n+  }\n+\n+  @VisibleForTesting\n+  static LargeByteBuffer allocate(long size, int maxChunk) {\n+    int chunksNeeded = (int) ((size + maxChunk - 1) / maxChunk);\n+    ByteBuffer[] chunks = new ByteBuffer[chunksNeeded];\n+    long remaining = size;\n+    for (int i = 0; i < chunksNeeded; i++) {\n+      int nextSize = (int) Math.min(remaining, maxChunk);\n+      ByteBuffer next = ByteBuffer.allocate(nextSize);\n+      remaining -= nextSize;\n+      chunks[i] = next;\n+    }\n+    if (remaining != 0) {\n+      throw new IllegalStateException(\"remaining = \" + remaining);\n+    }\n+    return new WrappedLargeByteBuffer(chunks, maxChunk);\n+  }\n+\n+  public static LargeByteBuffer mapFile(\n+      FileChannel channel,\n+      FileChannel.MapMode mode,\n+      long offset,\n+      long length\n+  ) throws IOException {\n+    int chunksNeeded = (int) ((length  - 1) / MAX_CHUNK_SIZE) + 1;\n+    ByteBuffer[] chunks = new ByteBuffer[chunksNeeded];\n+    long curPos = offset;\n+    long end = offset + length;\n+    for (int i = 0; i < chunksNeeded; i++) {\n+      long nextPos = Math.min(curPos + MAX_CHUNK_SIZE, end);\n+      chunks[i] = channel.map(mode, curPos, nextPos - curPos);",
    "line": 82
  }, {
    "author": {
      "login": "squito"
    },
    "body": "I think its definitely worth thinking about, but as a future optimization.  IMO the first goal is just eliminate the hard cliff at 2GB, so that 1.9GB and 2.1 GB behave simliarly.  Hopefully getting these interfaces in place leave us room to keep making improvements.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-04T01:57:41Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Utils for creating {@link org.apache.spark.network.buffer.LargeByteBuffer}s, either from\n+ * pre-allocated byte arrays, ByteBuffers, or by memory mapping a file.\n+ */\n+public class LargeByteBufferHelper {\n+\n+  // netty can't quite send msgs that are a full 2GB -- they need to be slightly smaller\n+  // not sure what the exact limit is, but 200 seems OK.\n+  /**\n+   * The maximum size of any ByteBuffer.\n+   * {@link org.apache.spark.network.buffer.LargeByteBuffer#asByteBuffer} will never return a\n+   * ByteBuffer larger than this.  This is close to the max ByteBuffer size (2GB), minus a small\n+   * amount for message overhead.\n+   */\n+  public static final int MAX_CHUNK_SIZE = Integer.MAX_VALUE - 200;\n+\n+  public static LargeByteBuffer asLargeByteBuffer(ByteBuffer buffer) {\n+    return new WrappedLargeByteBuffer(new ByteBuffer[] { buffer } );\n+  }\n+\n+  public static LargeByteBuffer asLargeByteBuffer(byte[] bytes) {\n+    return asLargeByteBuffer(ByteBuffer.wrap(bytes));\n+  }\n+\n+  public static LargeByteBuffer allocate(long size) {\n+    return allocate(size, MAX_CHUNK_SIZE);\n+  }\n+\n+  @VisibleForTesting\n+  static LargeByteBuffer allocate(long size, int maxChunk) {\n+    int chunksNeeded = (int) ((size + maxChunk - 1) / maxChunk);\n+    ByteBuffer[] chunks = new ByteBuffer[chunksNeeded];\n+    long remaining = size;\n+    for (int i = 0; i < chunksNeeded; i++) {\n+      int nextSize = (int) Math.min(remaining, maxChunk);\n+      ByteBuffer next = ByteBuffer.allocate(nextSize);\n+      remaining -= nextSize;\n+      chunks[i] = next;\n+    }\n+    if (remaining != 0) {\n+      throw new IllegalStateException(\"remaining = \" + remaining);\n+    }\n+    return new WrappedLargeByteBuffer(chunks, maxChunk);\n+  }\n+\n+  public static LargeByteBuffer mapFile(\n+      FileChannel channel,\n+      FileChannel.MapMode mode,\n+      long offset,\n+      long length\n+  ) throws IOException {\n+    int chunksNeeded = (int) ((length  - 1) / MAX_CHUNK_SIZE) + 1;\n+    ByteBuffer[] chunks = new ByteBuffer[chunksNeeded];\n+    long curPos = offset;\n+    long end = offset + length;\n+    for (int i = 0; i < chunksNeeded; i++) {\n+      long nextPos = Math.min(curPos + MAX_CHUNK_SIZE, end);\n+      chunks[i] = channel.map(mode, curPos, nextPos - curPos);",
    "line": 82
  }],
  "prId": 5400
}]