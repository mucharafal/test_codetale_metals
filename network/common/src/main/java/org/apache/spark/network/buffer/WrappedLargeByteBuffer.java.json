[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You don't need to chain the constructor calls like this; you could just call `findExpectedInitialPosition` from the other constructor, or even inline the code.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-07T21:55:22Z",
    "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  //only public for tests\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  private long _pos;\n+  private int currentBufferIdx;\n+  private ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, findExpectedInitialPosition(underlying));"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I'm a little confused about what this is supposed to be and what the checks are meant to check... could you write a comment explaining all that?\n\nI have a feeling that this might be over-complicating something that is supposed to be simple.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-07T21:58:10Z",
    "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  //only public for tests\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  private long _pos;\n+  private int currentBufferIdx;\n+  private ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, findExpectedInitialPosition(underlying));\n+  }\n+\n+  private static long findExpectedInitialPosition(ByteBuffer[] bufs) {"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: add braces\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-07T22:03:26Z",
    "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  //only public for tests\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  private long _pos;\n+  private int currentBufferIdx;\n+  private ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, findExpectedInitialPosition(underlying));\n+  }\n+\n+  private static long findExpectedInitialPosition(ByteBuffer[] bufs) {\n+    long sum = 0L;\n+    for (ByteBuffer b: bufs) {\n+      if (b.position() > 0) {\n+        // this could still lead to a mix of positions half-way through buffers that\n+        // would be inconsistent -- but we'll discover that in the constructor checks\n+        sum += b.position();\n+      } else {\n+        break;\n+      }\n+    }\n+    return sum;\n+  }\n+\n+  private WrappedLargeByteBuffer(ByteBuffer[] underlying, long initialPosition) {\n+    this.underlying = underlying;\n+    long sum = 0L;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      long nextSum = sum + b.capacity();\n+      int expectedPosition;\n+      if (nextSum < initialPosition) {\n+        expectedPosition = b.capacity();\n+      } else if (sum > initialPosition) {\n+        expectedPosition = 0;\n+      } else {\n+        expectedPosition = (int) (initialPosition - sum);\n+      }\n+      if (b.position() != expectedPosition) {\n+        throw new IllegalArgumentException(\"ByteBuffer[\" + i + \"]:\" + b + \" was expected to have\" +\n+          \" position = \" + expectedPosition + \" to be consistent with the overall \" +\n+          \"initialPosition = \" + initialPosition);\n+      }\n+      sum = nextSum;\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining())"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "If you use a `do...while` the loop will take care of this.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-07T22:05:42Z",
    "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  //only public for tests\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  private long _pos;\n+  private int currentBufferIdx;\n+  private ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, findExpectedInitialPosition(underlying));\n+  }\n+\n+  private static long findExpectedInitialPosition(ByteBuffer[] bufs) {\n+    long sum = 0L;\n+    for (ByteBuffer b: bufs) {\n+      if (b.position() > 0) {\n+        // this could still lead to a mix of positions half-way through buffers that\n+        // would be inconsistent -- but we'll discover that in the constructor checks\n+        sum += b.position();\n+      } else {\n+        break;\n+      }\n+    }\n+    return sum;\n+  }\n+\n+  private WrappedLargeByteBuffer(ByteBuffer[] underlying, long initialPosition) {\n+    this.underlying = underlying;\n+    long sum = 0L;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      long nextSum = sum + b.capacity();\n+      int expectedPosition;\n+      if (nextSum < initialPosition) {\n+        expectedPosition = b.capacity();\n+      } else if (sum > initialPosition) {\n+        expectedPosition = 0;\n+      } else {\n+        expectedPosition = (int) (initialPosition - sum);\n+      }\n+      if (b.position() != expectedPosition) {\n+        throw new IllegalArgumentException(\"ByteBuffer[\" + i + \"]:\" + b + \" was expected to have\" +\n+          \" position = \" + expectedPosition + \" to be consistent with the overall \" +\n+          \"initialPosition = \" + initialPosition);\n+      }\n+      sum = nextSum;\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining())\n+      throw new BufferUnderflowException();\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    while (currentBufferIdx > 0) {\n+      if (currentBuffer != null) {\n+        currentBuffer.rewind();\n+      }\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+    }\n+    currentBuffer.rewind();"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "According to the `ByteBuffer` javadoc, this will only work if the current buffer is in its original state (or after a `rewind`). The interface documentation seems to imply that restriction does not exist.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-07T22:09:19Z",
    "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  //only public for tests\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  private long _pos;\n+  private int currentBufferIdx;\n+  private ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, findExpectedInitialPosition(underlying));\n+  }\n+\n+  private static long findExpectedInitialPosition(ByteBuffer[] bufs) {\n+    long sum = 0L;\n+    for (ByteBuffer b: bufs) {\n+      if (b.position() > 0) {\n+        // this could still lead to a mix of positions half-way through buffers that\n+        // would be inconsistent -- but we'll discover that in the constructor checks\n+        sum += b.position();\n+      } else {\n+        break;\n+      }\n+    }\n+    return sum;\n+  }\n+\n+  private WrappedLargeByteBuffer(ByteBuffer[] underlying, long initialPosition) {\n+    this.underlying = underlying;\n+    long sum = 0L;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      long nextSum = sum + b.capacity();\n+      int expectedPosition;\n+      if (nextSum < initialPosition) {\n+        expectedPosition = b.capacity();\n+      } else if (sum > initialPosition) {\n+        expectedPosition = 0;\n+      } else {\n+        expectedPosition = (int) (initialPosition - sum);\n+      }\n+      if (b.position() != expectedPosition) {\n+        throw new IllegalArgumentException(\"ByteBuffer[\" + i + \"]:\" + b + \" was expected to have\" +\n+          \" position = \" + expectedPosition + \" to be consistent with the overall \" +\n+          \"initialPosition = \" + initialPosition);\n+      }\n+      sum = nextSum;\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining())\n+      throw new BufferUnderflowException();\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    while (currentBufferIdx > 0) {\n+      if (currentBuffer != null) {\n+        currentBuffer.rewind();\n+      }\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+    }\n+    currentBuffer.rewind();\n+    _pos = 0;\n+    return this;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer deepCopy() {\n+    ByteBuffer[] dataCopy = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      dataCopy[i] = ByteBuffer.allocate(b.capacity());\n+      int originalPosition = b.position();\n+      b.position(0);\n+      dataCopy[i].put(b);"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "I set the position of the buffer to 0 just above this: `b.position(0)` -- that's just a rewind without clearing the `mark`, but I can change to `b.rewind()`\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-08T20:54:44Z",
    "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  //only public for tests\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  private long _pos;\n+  private int currentBufferIdx;\n+  private ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, findExpectedInitialPosition(underlying));\n+  }\n+\n+  private static long findExpectedInitialPosition(ByteBuffer[] bufs) {\n+    long sum = 0L;\n+    for (ByteBuffer b: bufs) {\n+      if (b.position() > 0) {\n+        // this could still lead to a mix of positions half-way through buffers that\n+        // would be inconsistent -- but we'll discover that in the constructor checks\n+        sum += b.position();\n+      } else {\n+        break;\n+      }\n+    }\n+    return sum;\n+  }\n+\n+  private WrappedLargeByteBuffer(ByteBuffer[] underlying, long initialPosition) {\n+    this.underlying = underlying;\n+    long sum = 0L;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      long nextSum = sum + b.capacity();\n+      int expectedPosition;\n+      if (nextSum < initialPosition) {\n+        expectedPosition = b.capacity();\n+      } else if (sum > initialPosition) {\n+        expectedPosition = 0;\n+      } else {\n+        expectedPosition = (int) (initialPosition - sum);\n+      }\n+      if (b.position() != expectedPosition) {\n+        throw new IllegalArgumentException(\"ByteBuffer[\" + i + \"]:\" + b + \" was expected to have\" +\n+          \" position = \" + expectedPosition + \" to be consistent with the overall \" +\n+          \"initialPosition = \" + initialPosition);\n+      }\n+      sum = nextSum;\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining())\n+      throw new BufferUnderflowException();\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    while (currentBufferIdx > 0) {\n+      if (currentBuffer != null) {\n+        currentBuffer.rewind();\n+      }\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+    }\n+    currentBuffer.rewind();\n+    _pos = 0;\n+    return this;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer deepCopy() {\n+    ByteBuffer[] dataCopy = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      dataCopy[i] = ByteBuffer.allocate(b.capacity());\n+      int originalPosition = b.position();\n+      b.position(0);\n+      dataCopy[i].put(b);"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`com.google.common.annotations.VisibleForTesting`\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-07T22:10:45Z",
    "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  //only public for tests\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  private long _pos;\n+  private int currentBufferIdx;\n+  private ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, findExpectedInitialPosition(underlying));\n+  }\n+\n+  private static long findExpectedInitialPosition(ByteBuffer[] bufs) {\n+    long sum = 0L;\n+    for (ByteBuffer b: bufs) {\n+      if (b.position() > 0) {\n+        // this could still lead to a mix of positions half-way through buffers that\n+        // would be inconsistent -- but we'll discover that in the constructor checks\n+        sum += b.position();\n+      } else {\n+        break;\n+      }\n+    }\n+    return sum;\n+  }\n+\n+  private WrappedLargeByteBuffer(ByteBuffer[] underlying, long initialPosition) {\n+    this.underlying = underlying;\n+    long sum = 0L;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      long nextSum = sum + b.capacity();\n+      int expectedPosition;\n+      if (nextSum < initialPosition) {\n+        expectedPosition = b.capacity();\n+      } else if (sum > initialPosition) {\n+        expectedPosition = 0;\n+      } else {\n+        expectedPosition = (int) (initialPosition - sum);\n+      }\n+      if (b.position() != expectedPosition) {\n+        throw new IllegalArgumentException(\"ByteBuffer[\" + i + \"]:\" + b + \" was expected to have\" +\n+          \" position = \" + expectedPosition + \" to be consistent with the overall \" +\n+          \"initialPosition = \" + initialPosition);\n+      }\n+      sum = nextSum;\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining())\n+      throw new BufferUnderflowException();\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    while (currentBufferIdx > 0) {\n+      if (currentBuffer != null) {\n+        currentBuffer.rewind();\n+      }\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+    }\n+    currentBuffer.rewind();\n+    _pos = 0;\n+    return this;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer deepCopy() {\n+    ByteBuffer[] dataCopy = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      dataCopy[i] = ByteBuffer.allocate(b.capacity());\n+      int originalPosition = b.position();\n+      b.position(0);\n+      dataCopy[i].put(b);\n+      dataCopy[i].position(0);\n+      b.position(originalPosition);\n+    }\n+    return new WrappedLargeByteBuffer(dataCopy);\n+  }\n+\n+  @Override\n+  public byte get() {\n+    byte r = currentBuffer.get();\n+    _pos += 1;\n+    updateCurrentBuffer();\n+    return r;\n+  }\n+\n+  private void updateCurrentBuffer() {\n+    while (currentBuffer != null && !currentBuffer.hasRemaining()) {\n+      currentBufferIdx += 1;\n+      currentBuffer = currentBufferIdx < underlying.length ? underlying[currentBufferIdx] : null;\n+    }\n+  }\n+\n+  @Override\n+  public long position() {\n+    return _pos;\n+  }\n+\n+  @Override\n+  public long skip(long n) {\n+    if (n < 0) {\n+      final long moveTotal = Math.min(-n, _pos);\n+      long toMove = moveTotal;\n+      // move backwards -- set the position to 0 of every buffer's we go back\n+      if (currentBuffer != null) {\n+        currentBufferIdx += 1;\n+      }\n+      while (toMove > 0) {\n+        currentBufferIdx -= 1;\n+        currentBuffer = underlying[currentBufferIdx];\n+        int thisMove = (int) Math.min(toMove, currentBuffer.position());\n+        currentBuffer.position(currentBuffer.position() - thisMove);\n+        toMove -= thisMove;\n+      }\n+      _pos -= moveTotal;\n+      return -moveTotal;\n+    } else if (n > 0) {\n+      final long moveTotal = Math.min(n, remaining());\n+      long toMove = moveTotal;\n+      // move forwards-- set the position to the end of every buffer as we go forwards\n+      currentBufferIdx -= 1;\n+      while (toMove > 0) {\n+        currentBufferIdx += 1;\n+        currentBuffer = underlying[currentBufferIdx];\n+        int thisMove = (int) Math.min(toMove, currentBuffer.remaining());\n+        currentBuffer.position(currentBuffer.position() + thisMove);\n+        toMove -= thisMove;\n+      }\n+      _pos += moveTotal;\n+      return moveTotal;\n+    } else {\n+      return 0;\n+    }\n+  }\n+\n+  @Override\n+  public long remaining() {\n+    return size - _pos;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer duplicate() {\n+    ByteBuffer[] duplicates = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      duplicates[i] = underlying[i].duplicate();\n+    }\n+    return new WrappedLargeByteBuffer(duplicates, _pos);\n+  }\n+\n+  @Override\n+  public long size() {\n+    return size;\n+  }\n+\n+  @Override\n+  public long writeTo(WritableByteChannel channel) throws IOException {\n+    long written = 0l;\n+    for (; currentBufferIdx < underlying.length; currentBufferIdx++) {\n+      currentBuffer = underlying[currentBufferIdx];\n+      written += currentBuffer.remaining();\n+      while (currentBuffer.hasRemaining())\n+        channel.write(currentBuffer);\n+    }\n+    _pos = size();\n+    return written;\n+  }\n+\n+  @Override\n+  public ByteBuffer asByteBuffer() throws BufferTooLargeException {\n+    if (underlying.length > 1) {\n+      throw new BufferTooLargeException(size());\n+    }\n+    return underlying[0];\n+  }\n+\n+  // only needed for tests"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Isn't it safer to check for `DirectBuffer` here?\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-07T22:12:11Z",
    "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  //only public for tests\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  private long _pos;\n+  private int currentBufferIdx;\n+  private ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, findExpectedInitialPosition(underlying));\n+  }\n+\n+  private static long findExpectedInitialPosition(ByteBuffer[] bufs) {\n+    long sum = 0L;\n+    for (ByteBuffer b: bufs) {\n+      if (b.position() > 0) {\n+        // this could still lead to a mix of positions half-way through buffers that\n+        // would be inconsistent -- but we'll discover that in the constructor checks\n+        sum += b.position();\n+      } else {\n+        break;\n+      }\n+    }\n+    return sum;\n+  }\n+\n+  private WrappedLargeByteBuffer(ByteBuffer[] underlying, long initialPosition) {\n+    this.underlying = underlying;\n+    long sum = 0L;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      long nextSum = sum + b.capacity();\n+      int expectedPosition;\n+      if (nextSum < initialPosition) {\n+        expectedPosition = b.capacity();\n+      } else if (sum > initialPosition) {\n+        expectedPosition = 0;\n+      } else {\n+        expectedPosition = (int) (initialPosition - sum);\n+      }\n+      if (b.position() != expectedPosition) {\n+        throw new IllegalArgumentException(\"ByteBuffer[\" + i + \"]:\" + b + \" was expected to have\" +\n+          \" position = \" + expectedPosition + \" to be consistent with the overall \" +\n+          \"initialPosition = \" + initialPosition);\n+      }\n+      sum = nextSum;\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining())\n+      throw new BufferUnderflowException();\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    while (currentBufferIdx > 0) {\n+      if (currentBuffer != null) {\n+        currentBuffer.rewind();\n+      }\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+    }\n+    currentBuffer.rewind();\n+    _pos = 0;\n+    return this;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer deepCopy() {\n+    ByteBuffer[] dataCopy = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      dataCopy[i] = ByteBuffer.allocate(b.capacity());\n+      int originalPosition = b.position();\n+      b.position(0);\n+      dataCopy[i].put(b);\n+      dataCopy[i].position(0);\n+      b.position(originalPosition);\n+    }\n+    return new WrappedLargeByteBuffer(dataCopy);\n+  }\n+\n+  @Override\n+  public byte get() {\n+    byte r = currentBuffer.get();\n+    _pos += 1;\n+    updateCurrentBuffer();\n+    return r;\n+  }\n+\n+  private void updateCurrentBuffer() {\n+    while (currentBuffer != null && !currentBuffer.hasRemaining()) {\n+      currentBufferIdx += 1;\n+      currentBuffer = currentBufferIdx < underlying.length ? underlying[currentBufferIdx] : null;\n+    }\n+  }\n+\n+  @Override\n+  public long position() {\n+    return _pos;\n+  }\n+\n+  @Override\n+  public long skip(long n) {\n+    if (n < 0) {\n+      final long moveTotal = Math.min(-n, _pos);\n+      long toMove = moveTotal;\n+      // move backwards -- set the position to 0 of every buffer's we go back\n+      if (currentBuffer != null) {\n+        currentBufferIdx += 1;\n+      }\n+      while (toMove > 0) {\n+        currentBufferIdx -= 1;\n+        currentBuffer = underlying[currentBufferIdx];\n+        int thisMove = (int) Math.min(toMove, currentBuffer.position());\n+        currentBuffer.position(currentBuffer.position() - thisMove);\n+        toMove -= thisMove;\n+      }\n+      _pos -= moveTotal;\n+      return -moveTotal;\n+    } else if (n > 0) {\n+      final long moveTotal = Math.min(n, remaining());\n+      long toMove = moveTotal;\n+      // move forwards-- set the position to the end of every buffer as we go forwards\n+      currentBufferIdx -= 1;\n+      while (toMove > 0) {\n+        currentBufferIdx += 1;\n+        currentBuffer = underlying[currentBufferIdx];\n+        int thisMove = (int) Math.min(toMove, currentBuffer.remaining());\n+        currentBuffer.position(currentBuffer.position() + thisMove);\n+        toMove -= thisMove;\n+      }\n+      _pos += moveTotal;\n+      return moveTotal;\n+    } else {\n+      return 0;\n+    }\n+  }\n+\n+  @Override\n+  public long remaining() {\n+    return size - _pos;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer duplicate() {\n+    ByteBuffer[] duplicates = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      duplicates[i] = underlying[i].duplicate();\n+    }\n+    return new WrappedLargeByteBuffer(duplicates, _pos);\n+  }\n+\n+  @Override\n+  public long size() {\n+    return size;\n+  }\n+\n+  @Override\n+  public long writeTo(WritableByteChannel channel) throws IOException {\n+    long written = 0l;\n+    for (; currentBufferIdx < underlying.length; currentBufferIdx++) {\n+      currentBuffer = underlying[currentBufferIdx];\n+      written += currentBuffer.remaining();\n+      while (currentBuffer.hasRemaining())\n+        channel.write(currentBuffer);\n+    }\n+    _pos = size();\n+    return written;\n+  }\n+\n+  @Override\n+  public ByteBuffer asByteBuffer() throws BufferTooLargeException {\n+    if (underlying.length > 1) {\n+      throw new BufferTooLargeException(size());\n+    }\n+    return underlying[0];\n+  }\n+\n+  // only needed for tests\n+  public List<ByteBuffer> nioBuffers() {\n+    return Arrays.asList(underlying);\n+  }\n+\n+  /**\n+   * Attempt to clean up a ByteBuffer if it is memory-mapped. This uses an *unsafe* Sun API that\n+   * might cause errors if one attempts to read from the unmapped buffer, but it's better than\n+   * waiting for the GC to find it because that could lead to huge numbers of open files. There's\n+   * unfortunately no standard API to do this.\n+   */\n+  private static void dispose(ByteBuffer buffer) {\n+    if (buffer != null && buffer instanceof MappedByteBuffer) {"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This doesn't really follow the interface's contract.  E.g., it doesn't guarantee the buffer will have position 0; nor does it return as much data as possible (e.g. if the first buffer is less than the maximum size, you could include data from the second buffer, and so on).\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-07T22:13:38Z",
    "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  //only public for tests\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  private long _pos;\n+  private int currentBufferIdx;\n+  private ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, findExpectedInitialPosition(underlying));\n+  }\n+\n+  private static long findExpectedInitialPosition(ByteBuffer[] bufs) {\n+    long sum = 0L;\n+    for (ByteBuffer b: bufs) {\n+      if (b.position() > 0) {\n+        // this could still lead to a mix of positions half-way through buffers that\n+        // would be inconsistent -- but we'll discover that in the constructor checks\n+        sum += b.position();\n+      } else {\n+        break;\n+      }\n+    }\n+    return sum;\n+  }\n+\n+  private WrappedLargeByteBuffer(ByteBuffer[] underlying, long initialPosition) {\n+    this.underlying = underlying;\n+    long sum = 0L;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      long nextSum = sum + b.capacity();\n+      int expectedPosition;\n+      if (nextSum < initialPosition) {\n+        expectedPosition = b.capacity();\n+      } else if (sum > initialPosition) {\n+        expectedPosition = 0;\n+      } else {\n+        expectedPosition = (int) (initialPosition - sum);\n+      }\n+      if (b.position() != expectedPosition) {\n+        throw new IllegalArgumentException(\"ByteBuffer[\" + i + \"]:\" + b + \" was expected to have\" +\n+          \" position = \" + expectedPosition + \" to be consistent with the overall \" +\n+          \"initialPosition = \" + initialPosition);\n+      }\n+      sum = nextSum;\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining())\n+      throw new BufferUnderflowException();\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    while (currentBufferIdx > 0) {\n+      if (currentBuffer != null) {\n+        currentBuffer.rewind();\n+      }\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+    }\n+    currentBuffer.rewind();\n+    _pos = 0;\n+    return this;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer deepCopy() {\n+    ByteBuffer[] dataCopy = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      dataCopy[i] = ByteBuffer.allocate(b.capacity());\n+      int originalPosition = b.position();\n+      b.position(0);\n+      dataCopy[i].put(b);\n+      dataCopy[i].position(0);\n+      b.position(originalPosition);\n+    }\n+    return new WrappedLargeByteBuffer(dataCopy);\n+  }\n+\n+  @Override\n+  public byte get() {\n+    byte r = currentBuffer.get();\n+    _pos += 1;\n+    updateCurrentBuffer();\n+    return r;\n+  }\n+\n+  private void updateCurrentBuffer() {\n+    while (currentBuffer != null && !currentBuffer.hasRemaining()) {\n+      currentBufferIdx += 1;\n+      currentBuffer = currentBufferIdx < underlying.length ? underlying[currentBufferIdx] : null;\n+    }\n+  }\n+\n+  @Override\n+  public long position() {\n+    return _pos;\n+  }\n+\n+  @Override\n+  public long skip(long n) {\n+    if (n < 0) {\n+      final long moveTotal = Math.min(-n, _pos);\n+      long toMove = moveTotal;\n+      // move backwards -- set the position to 0 of every buffer's we go back\n+      if (currentBuffer != null) {\n+        currentBufferIdx += 1;\n+      }\n+      while (toMove > 0) {\n+        currentBufferIdx -= 1;\n+        currentBuffer = underlying[currentBufferIdx];\n+        int thisMove = (int) Math.min(toMove, currentBuffer.position());\n+        currentBuffer.position(currentBuffer.position() - thisMove);\n+        toMove -= thisMove;\n+      }\n+      _pos -= moveTotal;\n+      return -moveTotal;\n+    } else if (n > 0) {\n+      final long moveTotal = Math.min(n, remaining());\n+      long toMove = moveTotal;\n+      // move forwards-- set the position to the end of every buffer as we go forwards\n+      currentBufferIdx -= 1;\n+      while (toMove > 0) {\n+        currentBufferIdx += 1;\n+        currentBuffer = underlying[currentBufferIdx];\n+        int thisMove = (int) Math.min(toMove, currentBuffer.remaining());\n+        currentBuffer.position(currentBuffer.position() + thisMove);\n+        toMove -= thisMove;\n+      }\n+      _pos += moveTotal;\n+      return moveTotal;\n+    } else {\n+      return 0;\n+    }\n+  }\n+\n+  @Override\n+  public long remaining() {\n+    return size - _pos;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer duplicate() {\n+    ByteBuffer[] duplicates = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      duplicates[i] = underlying[i].duplicate();\n+    }\n+    return new WrappedLargeByteBuffer(duplicates, _pos);\n+  }\n+\n+  @Override\n+  public long size() {\n+    return size;\n+  }\n+\n+  @Override\n+  public long writeTo(WritableByteChannel channel) throws IOException {\n+    long written = 0l;\n+    for (; currentBufferIdx < underlying.length; currentBufferIdx++) {\n+      currentBuffer = underlying[currentBufferIdx];\n+      written += currentBuffer.remaining();\n+      while (currentBuffer.hasRemaining())\n+        channel.write(currentBuffer);\n+    }\n+    _pos = size();\n+    return written;\n+  }\n+\n+  @Override\n+  public ByteBuffer asByteBuffer() throws BufferTooLargeException {\n+    if (underlying.length > 1) {\n+      throw new BufferTooLargeException(size());\n+    }\n+    return underlying[0];"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: after `java.*`\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T20:00:46Z",
    "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Tests are in the same package, so this could be package-private instead.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T20:01:52Z",
    "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  public final ByteBuffer[] underlying;"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: delete\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T20:02:50Z",
    "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+",
    "line": 54
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Can you add a comment explaining what all this code is doing?\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T20:05:55Z",
    "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {\n+    if (underlying.length == 0) {\n+      throw new IllegalArgumentException(\"must wrap at least one ByteBuffer\");\n+    }\n+    this.underlying = underlying;\n+    this.subBufferSize = subBufferSize;\n+    long sum = 0L;\n+    boolean startFound = false;\n+    long initialPosition = -1;"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This will throw an NPE if it is called after you go past the last buffer. Docs say it should throw `BufferUnderflowException` instead.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T20:08:20Z",
    "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {\n+    if (underlying.length == 0) {\n+      throw new IllegalArgumentException(\"must wrap at least one ByteBuffer\");\n+    }\n+    this.underlying = underlying;\n+    this.subBufferSize = subBufferSize;\n+    long sum = 0L;\n+    boolean startFound = false;\n+    long initialPosition = -1;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      if (i != underlying.length -1 && b.capacity() != subBufferSize) {\n+        throw new IllegalArgumentException(\"All buffers, except for the final one, must have \" +\n+          \"size = \" + subBufferSize);\n+      }\n+      if (startFound) {\n+        if (b.position() != 0) {\n+          throw new IllegalArgumentException(\"ByteBuffers have inconsistent positions\");\n+        }\n+      } else if (b.position() != b.capacity()) {\n+        startFound = true;\n+        initialPosition = sum + b.position();\n+      }\n+      sum += b.capacity();\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining()) {\n+      throw new BufferUnderflowException();\n+    }\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    if (currentBuffer != null) {\n+      currentBuffer.rewind();\n+    }\n+    while (currentBufferIdx > 0) {\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+      currentBuffer.rewind();\n+    }\n+    _pos = 0;\n+    return this;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer deepCopy() {\n+    ByteBuffer[] dataCopy = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      dataCopy[i] = ByteBuffer.allocate(b.capacity());\n+      int originalPosition = b.position();\n+      b.rewind();\n+      dataCopy[i].put(b);\n+      dataCopy[i].position(0);\n+      b.position(originalPosition);\n+    }\n+    return new WrappedLargeByteBuffer(dataCopy, subBufferSize);\n+  }\n+\n+  @Override\n+  public byte get() {\n+    byte r = currentBuffer.get();"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Comment is inaccurate.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T20:10:03Z",
    "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {\n+    if (underlying.length == 0) {\n+      throw new IllegalArgumentException(\"must wrap at least one ByteBuffer\");\n+    }\n+    this.underlying = underlying;\n+    this.subBufferSize = subBufferSize;\n+    long sum = 0L;\n+    boolean startFound = false;\n+    long initialPosition = -1;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      if (i != underlying.length -1 && b.capacity() != subBufferSize) {\n+        throw new IllegalArgumentException(\"All buffers, except for the final one, must have \" +\n+          \"size = \" + subBufferSize);\n+      }\n+      if (startFound) {\n+        if (b.position() != 0) {\n+          throw new IllegalArgumentException(\"ByteBuffers have inconsistent positions\");\n+        }\n+      } else if (b.position() != b.capacity()) {\n+        startFound = true;\n+        initialPosition = sum + b.position();\n+      }\n+      sum += b.capacity();\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining()) {\n+      throw new BufferUnderflowException();\n+    }\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    if (currentBuffer != null) {\n+      currentBuffer.rewind();\n+    }\n+    while (currentBufferIdx > 0) {\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+      currentBuffer.rewind();\n+    }\n+    _pos = 0;\n+    return this;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer deepCopy() {\n+    ByteBuffer[] dataCopy = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      dataCopy[i] = ByteBuffer.allocate(b.capacity());\n+      int originalPosition = b.position();\n+      b.rewind();\n+      dataCopy[i].put(b);\n+      dataCopy[i].position(0);\n+      b.position(originalPosition);\n+    }\n+    return new WrappedLargeByteBuffer(dataCopy, subBufferSize);\n+  }\n+\n+  @Override\n+  public byte get() {\n+    byte r = currentBuffer.get();\n+    _pos += 1;\n+    updateCurrentBuffer();\n+    return r;\n+  }\n+\n+  private void updateCurrentBuffer() {\n+    while (currentBuffer != null && !currentBuffer.hasRemaining()) {\n+      currentBufferIdx += 1;\n+      currentBuffer = currentBufferIdx < underlying.length ? underlying[currentBufferIdx] : null;\n+    }\n+  }\n+\n+  @Override\n+  public long position() {\n+    return _pos;\n+  }\n+\n+  @Override\n+  public long skip(long n) {\n+    if (n < 0) {\n+      final long moveTotal = Math.min(-n, _pos);\n+      long toMove = moveTotal;\n+      // move backwards -- set the position to 0 of every buffer's we go back"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Similarly inaccurate (not _every_ buffer).\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T20:11:04Z",
    "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {\n+    if (underlying.length == 0) {\n+      throw new IllegalArgumentException(\"must wrap at least one ByteBuffer\");\n+    }\n+    this.underlying = underlying;\n+    this.subBufferSize = subBufferSize;\n+    long sum = 0L;\n+    boolean startFound = false;\n+    long initialPosition = -1;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      if (i != underlying.length -1 && b.capacity() != subBufferSize) {\n+        throw new IllegalArgumentException(\"All buffers, except for the final one, must have \" +\n+          \"size = \" + subBufferSize);\n+      }\n+      if (startFound) {\n+        if (b.position() != 0) {\n+          throw new IllegalArgumentException(\"ByteBuffers have inconsistent positions\");\n+        }\n+      } else if (b.position() != b.capacity()) {\n+        startFound = true;\n+        initialPosition = sum + b.position();\n+      }\n+      sum += b.capacity();\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining()) {\n+      throw new BufferUnderflowException();\n+    }\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    if (currentBuffer != null) {\n+      currentBuffer.rewind();\n+    }\n+    while (currentBufferIdx > 0) {\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+      currentBuffer.rewind();\n+    }\n+    _pos = 0;\n+    return this;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer deepCopy() {\n+    ByteBuffer[] dataCopy = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      dataCopy[i] = ByteBuffer.allocate(b.capacity());\n+      int originalPosition = b.position();\n+      b.rewind();\n+      dataCopy[i].put(b);\n+      dataCopy[i].position(0);\n+      b.position(originalPosition);\n+    }\n+    return new WrappedLargeByteBuffer(dataCopy, subBufferSize);\n+  }\n+\n+  @Override\n+  public byte get() {\n+    byte r = currentBuffer.get();\n+    _pos += 1;\n+    updateCurrentBuffer();\n+    return r;\n+  }\n+\n+  private void updateCurrentBuffer() {\n+    while (currentBuffer != null && !currentBuffer.hasRemaining()) {\n+      currentBufferIdx += 1;\n+      currentBuffer = currentBufferIdx < underlying.length ? underlying[currentBufferIdx] : null;\n+    }\n+  }\n+\n+  @Override\n+  public long position() {\n+    return _pos;\n+  }\n+\n+  @Override\n+  public long skip(long n) {\n+    if (n < 0) {\n+      final long moveTotal = Math.min(-n, _pos);\n+      long toMove = moveTotal;\n+      // move backwards -- set the position to 0 of every buffer's we go back\n+      if (currentBuffer != null) {\n+        currentBufferIdx += 1;\n+      }\n+      while (toMove > 0) {\n+        currentBufferIdx -= 1;\n+        currentBuffer = underlying[currentBufferIdx];\n+        int thisMove = (int) Math.min(toMove, currentBuffer.position());\n+        currentBuffer.position(currentBuffer.position() - thisMove);\n+        toMove -= thisMove;\n+      }\n+      _pos -= moveTotal;\n+      return -moveTotal;\n+    } else if (n > 0) {\n+      final long moveTotal = Math.min(n, remaining());\n+      long toMove = moveTotal;\n+      // move forwards -- set the position to the end of every buffer as we go forwards"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "package-private?\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-04-20T20:12:16Z",
    "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {\n+    if (underlying.length == 0) {\n+      throw new IllegalArgumentException(\"must wrap at least one ByteBuffer\");\n+    }\n+    this.underlying = underlying;\n+    this.subBufferSize = subBufferSize;\n+    long sum = 0L;\n+    boolean startFound = false;\n+    long initialPosition = -1;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      if (i != underlying.length -1 && b.capacity() != subBufferSize) {\n+        throw new IllegalArgumentException(\"All buffers, except for the final one, must have \" +\n+          \"size = \" + subBufferSize);\n+      }\n+      if (startFound) {\n+        if (b.position() != 0) {\n+          throw new IllegalArgumentException(\"ByteBuffers have inconsistent positions\");\n+        }\n+      } else if (b.position() != b.capacity()) {\n+        startFound = true;\n+        initialPosition = sum + b.position();\n+      }\n+      sum += b.capacity();\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining()) {\n+      throw new BufferUnderflowException();\n+    }\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    if (currentBuffer != null) {\n+      currentBuffer.rewind();\n+    }\n+    while (currentBufferIdx > 0) {\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+      currentBuffer.rewind();\n+    }\n+    _pos = 0;\n+    return this;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer deepCopy() {\n+    ByteBuffer[] dataCopy = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      dataCopy[i] = ByteBuffer.allocate(b.capacity());\n+      int originalPosition = b.position();\n+      b.rewind();\n+      dataCopy[i].put(b);\n+      dataCopy[i].position(0);\n+      b.position(originalPosition);\n+    }\n+    return new WrappedLargeByteBuffer(dataCopy, subBufferSize);\n+  }\n+\n+  @Override\n+  public byte get() {\n+    byte r = currentBuffer.get();\n+    _pos += 1;\n+    updateCurrentBuffer();\n+    return r;\n+  }\n+\n+  private void updateCurrentBuffer() {\n+    while (currentBuffer != null && !currentBuffer.hasRemaining()) {\n+      currentBufferIdx += 1;\n+      currentBuffer = currentBufferIdx < underlying.length ? underlying[currentBufferIdx] : null;\n+    }\n+  }\n+\n+  @Override\n+  public long position() {\n+    return _pos;\n+  }\n+\n+  @Override\n+  public long skip(long n) {\n+    if (n < 0) {\n+      final long moveTotal = Math.min(-n, _pos);\n+      long toMove = moveTotal;\n+      // move backwards -- set the position to 0 of every buffer's we go back\n+      if (currentBuffer != null) {\n+        currentBufferIdx += 1;\n+      }\n+      while (toMove > 0) {\n+        currentBufferIdx -= 1;\n+        currentBuffer = underlying[currentBufferIdx];\n+        int thisMove = (int) Math.min(toMove, currentBuffer.position());\n+        currentBuffer.position(currentBuffer.position() - thisMove);\n+        toMove -= thisMove;\n+      }\n+      _pos -= moveTotal;\n+      return -moveTotal;\n+    } else if (n > 0) {\n+      final long moveTotal = Math.min(n, remaining());\n+      long toMove = moveTotal;\n+      // move forwards -- set the position to the end of every buffer as we go forwards\n+      currentBufferIdx -= 1;\n+      while (toMove > 0) {\n+        currentBufferIdx += 1;\n+        currentBuffer = underlying[currentBufferIdx];\n+        int thisMove = (int) Math.min(toMove, currentBuffer.remaining());\n+        currentBuffer.position(currentBuffer.position() + thisMove);\n+        toMove -= thisMove;\n+      }\n+      _pos += moveTotal;\n+      return moveTotal;\n+    } else {\n+      return 0;\n+    }\n+  }\n+\n+  @Override\n+  public long remaining() {\n+    return size - _pos;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer duplicate() {\n+    ByteBuffer[] duplicates = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      duplicates[i] = underlying[i].duplicate();\n+    }\n+    return new WrappedLargeByteBuffer(duplicates, subBufferSize);\n+  }\n+\n+  @Override\n+  public long size() {\n+    return size;\n+  }\n+\n+  @Override\n+  public long writeTo(WritableByteChannel channel) throws IOException {\n+    long written = 0l;\n+    for (; currentBufferIdx < underlying.length; currentBufferIdx++) {\n+      currentBuffer = underlying[currentBufferIdx];\n+      written += currentBuffer.remaining();\n+      while (currentBuffer.hasRemaining())\n+        channel.write(currentBuffer);\n+    }\n+    _pos = size();\n+    return written;\n+  }\n+\n+  @Override\n+  public ByteBuffer asByteBuffer() throws BufferTooLargeException {\n+    if (underlying.length == 1) {\n+      ByteBuffer b = underlying[0].duplicate();\n+      b.rewind();\n+      return b;\n+    } else {\n+      // NOTE: if subBufferSize != LargeByteBufferHelper.MAX_CAPACITY, in theory\n+      // we could copy the data into a new buffer.  But we don't want to do any copying.\n+      // The only reason we allow smaller subBufferSize is so that we can have tests which\n+      // don't require 2GB of memory\n+      throw new BufferTooLargeException(size(), underlying[0].capacity());\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public List<ByteBuffer> nioBuffers() {"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Similarly, this also needs a Javadoc comment to explain how it works at a high level.  I'd discuss how this wraps over multiple underlying ByteBuffers to present a single buffer-like interface that allows for the buffer size to be > 2GB.  In other words, I'd recap some of the motivation for this class here.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-05-29T19:22:44Z",
    "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Add a comment here.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-05-29T19:23:37Z",
    "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {\n+    if (underlying.length == 0) {\n+      throw new IllegalArgumentException(\"must wrap at least one ByteBuffer\");\n+    }\n+    this.underlying = underlying;\n+    this.subBufferSize = subBufferSize;\n+    long sum = 0L;\n+    boolean startFound = false;\n+    long initialPosition = -1;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      if (i != underlying.length -1 && b.capacity() != subBufferSize) {\n+        throw new IllegalArgumentException(\"All buffers, except for the final one, must have \" +\n+          \"size = \" + subBufferSize);\n+      }\n+      if (startFound) {\n+        if (b.position() != 0) {\n+          throw new IllegalArgumentException(\"ByteBuffers have inconsistent positions\");\n+        }\n+      } else if (b.position() != b.capacity()) {\n+        startFound = true;\n+        initialPosition = sum + b.position();\n+      }\n+      sum += b.capacity();\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining()) {\n+      throw new BufferUnderflowException();\n+    }\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    if (currentBuffer != null) {\n+      currentBuffer.rewind();\n+    }\n+    while (currentBufferIdx > 0) {\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+      currentBuffer.rewind();\n+    }\n+    _pos = 0;\n+    return this;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer deepCopy() {\n+    ByteBuffer[] dataCopy = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      dataCopy[i] = ByteBuffer.allocate(b.capacity());\n+      int originalPosition = b.position();\n+      b.rewind();\n+      dataCopy[i].put(b);\n+      dataCopy[i].position(0);\n+      b.position(originalPosition);\n+    }\n+    return new WrappedLargeByteBuffer(dataCopy, subBufferSize);\n+  }\n+\n+  @Override\n+  public byte get() {\n+    byte r = currentBuffer.get();\n+    _pos += 1;\n+    updateCurrentBuffer();\n+    return r;\n+  }\n+\n+  private void updateCurrentBuffer() {"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Prefer capital `L` in general, since it looks less like a 1.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-05-29T19:24:02Z",
    "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  public final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {\n+    if (underlying.length == 0) {\n+      throw new IllegalArgumentException(\"must wrap at least one ByteBuffer\");\n+    }\n+    this.underlying = underlying;\n+    this.subBufferSize = subBufferSize;\n+    long sum = 0L;\n+    boolean startFound = false;\n+    long initialPosition = -1;\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      if (i != underlying.length -1 && b.capacity() != subBufferSize) {\n+        throw new IllegalArgumentException(\"All buffers, except for the final one, must have \" +\n+          \"size = \" + subBufferSize);\n+      }\n+      if (startFound) {\n+        if (b.position() != 0) {\n+          throw new IllegalArgumentException(\"ByteBuffers have inconsistent positions\");\n+        }\n+      } else if (b.position() != b.capacity()) {\n+        startFound = true;\n+        initialPosition = sum + b.position();\n+      }\n+      sum += b.capacity();\n+    }\n+    _pos = initialPosition;\n+    currentBufferIdx = 0;\n+    currentBuffer = underlying[0];\n+    size = sum;\n+  }\n+\n+  @Override\n+  public void get(byte[] dest, int offset, int length) {\n+    if (length > remaining()) {\n+      throw new BufferUnderflowException();\n+    }\n+    int moved = 0;\n+    while (moved < length) {\n+      int toRead = Math.min(length - moved, currentBuffer.remaining());\n+      currentBuffer.get(dest, offset + moved, toRead);\n+      moved += toRead;\n+      updateCurrentBuffer();\n+    }\n+    _pos += moved;\n+  }\n+\n+  @Override\n+  public LargeByteBuffer rewind() {\n+    if (currentBuffer != null) {\n+      currentBuffer.rewind();\n+    }\n+    while (currentBufferIdx > 0) {\n+      currentBufferIdx -= 1;\n+      currentBuffer = underlying[currentBufferIdx];\n+      currentBuffer.rewind();\n+    }\n+    _pos = 0;\n+    return this;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer deepCopy() {\n+    ByteBuffer[] dataCopy = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i];\n+      dataCopy[i] = ByteBuffer.allocate(b.capacity());\n+      int originalPosition = b.position();\n+      b.rewind();\n+      dataCopy[i].put(b);\n+      dataCopy[i].position(0);\n+      b.position(originalPosition);\n+    }\n+    return new WrappedLargeByteBuffer(dataCopy, subBufferSize);\n+  }\n+\n+  @Override\n+  public byte get() {\n+    byte r = currentBuffer.get();\n+    _pos += 1;\n+    updateCurrentBuffer();\n+    return r;\n+  }\n+\n+  private void updateCurrentBuffer() {\n+    while (currentBuffer != null && !currentBuffer.hasRemaining()) {\n+      currentBufferIdx += 1;\n+      currentBuffer = currentBufferIdx < underlying.length ? underlying[currentBufferIdx] : null;\n+    }\n+  }\n+\n+  @Override\n+  public long position() {\n+    return _pos;\n+  }\n+\n+  @Override\n+  public long skip(long n) {\n+    if (n < 0) {\n+      final long moveTotal = Math.min(-n, _pos);\n+      long toMove = moveTotal;\n+      // move backwards -- set the position to 0 of every buffer's we go back\n+      if (currentBuffer != null) {\n+        currentBufferIdx += 1;\n+      }\n+      while (toMove > 0) {\n+        currentBufferIdx -= 1;\n+        currentBuffer = underlying[currentBufferIdx];\n+        int thisMove = (int) Math.min(toMove, currentBuffer.position());\n+        currentBuffer.position(currentBuffer.position() - thisMove);\n+        toMove -= thisMove;\n+      }\n+      _pos -= moveTotal;\n+      return -moveTotal;\n+    } else if (n > 0) {\n+      final long moveTotal = Math.min(n, remaining());\n+      long toMove = moveTotal;\n+      // move forwards -- set the position to the end of every buffer as we go forwards\n+      currentBufferIdx -= 1;\n+      while (toMove > 0) {\n+        currentBufferIdx += 1;\n+        currentBuffer = underlying[currentBufferIdx];\n+        int thisMove = (int) Math.min(toMove, currentBuffer.remaining());\n+        currentBuffer.position(currentBuffer.position() + thisMove);\n+        toMove -= thisMove;\n+      }\n+      _pos += moveTotal;\n+      return moveTotal;\n+    } else {\n+      return 0;\n+    }\n+  }\n+\n+  @Override\n+  public long remaining() {\n+    return size - _pos;\n+  }\n+\n+  @Override\n+  public WrappedLargeByteBuffer duplicate() {\n+    ByteBuffer[] duplicates = new ByteBuffer[underlying.length];\n+    for (int i = 0; i < underlying.length; i++) {\n+      duplicates[i] = underlying[i].duplicate();\n+    }\n+    return new WrappedLargeByteBuffer(duplicates, subBufferSize);\n+  }\n+\n+  @Override\n+  public long size() {\n+    return size;\n+  }\n+\n+  @Override\n+  public long writeTo(WritableByteChannel channel) throws IOException {\n+    long written = 0l;"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: `- 1`\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T16:49:14Z",
    "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+/**\n+ * A {@link org.apache.spark.network.buffer.LargeByteBuffer} which may contain multiple\n+ * {@link java.nio.ByteBuffer}s.  In order to support <code>asByteBuffer</code>, all\n+ * of the underlying ByteBuffers must have size equal to\n+ * {@link org.apache.spark.network.buffer.LargeByteBufferHelper#MAX_CHUNK_SIZE} (except that last\n+ * one).  The underlying ByteBuffers may be on-heap, direct, or memory-mapped.\n+ */\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK_SIZE.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK_SIZE\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+  /**\n+   * Construct a WrappedLargeByteBuffer from the given ByteBuffers.  Each of the ByteBuffers must\n+   * have size equal to {@link org.apache.spark.network.buffer.LargeByteBufferHelper#MAX_CHUNK_SIZE}\n+   * except for the final one.  The buffers are <code>duplicate</code>d, so the position of the\n+   * given buffers and the returned buffer will be independent, though the underlying data will be\n+   * shared.  The constructed buffer will always have position == 0.\n+   */\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK_SIZE);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {\n+    if (underlying.length == 0) {\n+      throw new IllegalArgumentException(\"must wrap at least one ByteBuffer\");\n+    }\n+    this.underlying = new ByteBuffer[underlying.length];\n+    this.subBufferSize = subBufferSize;\n+    long sum = 0L;\n+\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i].duplicate();\n+      b.position(0);\n+      this.underlying[i] = b;\n+      if (i != underlying.length -1 && b.capacity() != subBufferSize) {"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "It seems like the only use of `subBufferSize` is to throw an exception in this constructor; it doesn't change any logic in the code. In light of that, is it necessary?\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T16:51:43Z",
    "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+/**\n+ * A {@link org.apache.spark.network.buffer.LargeByteBuffer} which may contain multiple\n+ * {@link java.nio.ByteBuffer}s.  In order to support <code>asByteBuffer</code>, all\n+ * of the underlying ByteBuffers must have size equal to\n+ * {@link org.apache.spark.network.buffer.LargeByteBufferHelper#MAX_CHUNK_SIZE} (except that last\n+ * one).  The underlying ByteBuffers may be on-heap, direct, or memory-mapped.\n+ */\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK_SIZE.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK_SIZE\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+  /**\n+   * Construct a WrappedLargeByteBuffer from the given ByteBuffers.  Each of the ByteBuffers must\n+   * have size equal to {@link org.apache.spark.network.buffer.LargeByteBufferHelper#MAX_CHUNK_SIZE}\n+   * except for the final one.  The buffers are <code>duplicate</code>d, so the position of the\n+   * given buffers and the returned buffer will be independent, though the underlying data will be\n+   * shared.  The constructed buffer will always have position == 0.\n+   */\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK_SIZE);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {",
    "line": 75
  }, {
    "author": {
      "login": "squito"
    },
    "body": "The issue is that `asByteBuffer` will not be implemented correctly if the first sub buffer is smaller than `LargeByteBufferHelper.MAX_CHUNK_SIZE`.  It would actually be fine if the rest of the sub buffers had other sizes, but that struck me as just making it more confusing without any real benefits (after you force the first sub buffer to be 2GB, I dont' see much gain in letting other buffers be smaller).\n\nThis is part of what I was getting at with an earlier comment, about how `asByteBuffer` really makes things a little ugly.  Say replication doesn't support blocks that are over 2GB, so it needs to use `asByteBuffer`.  If you let the sub buffers be smaller, than say you try to replicate a block that is 1GB -- that replication should be allowed, so you'll need to a do full copy of all the data to get it into one `ByteBuffer`.\n\nOTOH, this forces `LargeByteBufferOutputStream.largeBuffer` to do a full copy -- but at least that is no worse than what we are doing already to get a `ByteBuffer` from a `ByteArrayOutputStream`.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T20:05:36Z",
    "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+/**\n+ * A {@link org.apache.spark.network.buffer.LargeByteBuffer} which may contain multiple\n+ * {@link java.nio.ByteBuffer}s.  In order to support <code>asByteBuffer</code>, all\n+ * of the underlying ByteBuffers must have size equal to\n+ * {@link org.apache.spark.network.buffer.LargeByteBufferHelper#MAX_CHUNK_SIZE} (except that last\n+ * one).  The underlying ByteBuffers may be on-heap, direct, or memory-mapped.\n+ */\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK_SIZE.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK_SIZE\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+  /**\n+   * Construct a WrappedLargeByteBuffer from the given ByteBuffers.  Each of the ByteBuffers must\n+   * have size equal to {@link org.apache.spark.network.buffer.LargeByteBufferHelper#MAX_CHUNK_SIZE}\n+   * except for the final one.  The buffers are <code>duplicate</code>d, so the position of the\n+   * given buffers and the returned buffer will be independent, though the underlying data will be\n+   * shared.  The constructed buffer will always have position == 0.\n+   */\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK_SIZE);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {",
    "line": 75
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I think I understand. But a better comment explaining why the check exists would help a lot.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-02T20:25:39Z",
    "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+/**\n+ * A {@link org.apache.spark.network.buffer.LargeByteBuffer} which may contain multiple\n+ * {@link java.nio.ByteBuffer}s.  In order to support <code>asByteBuffer</code>, all\n+ * of the underlying ByteBuffers must have size equal to\n+ * {@link org.apache.spark.network.buffer.LargeByteBufferHelper#MAX_CHUNK_SIZE} (except that last\n+ * one).  The underlying ByteBuffers may be on-heap, direct, or memory-mapped.\n+ */\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK_SIZE.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK_SIZE\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+  /**\n+   * Construct a WrappedLargeByteBuffer from the given ByteBuffers.  Each of the ByteBuffers must\n+   * have size equal to {@link org.apache.spark.network.buffer.LargeByteBufferHelper#MAX_CHUNK_SIZE}\n+   * except for the final one.  The buffers are <code>duplicate</code>d, so the position of the\n+   * given buffers and the returned buffer will be independent, though the underlying data will be\n+   * shared.  The constructed buffer will always have position == 0.\n+   */\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK_SIZE);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {",
    "line": 75
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: too many empty lines\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-11-02T20:05:12Z",
    "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one or more\n+* contributor license agreements.  See the NOTICE file distributed with\n+* this work for additional information regarding copyright ownership.\n+* The ASF licenses this file to You under the Apache License, Version 2.0\n+* (the \"License\"); you may not use this file except in compliance with\n+* the License.  You may obtain a copy of the License at\n+*\n+*    http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.spark.network.buffer;\n+\n+import java.io.IOException;\n+import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import sun.nio.ch.DirectBuffer;\n+\n+/**\n+ * A {@link org.apache.spark.network.buffer.LargeByteBuffer} which may contain multiple\n+ * {@link java.nio.ByteBuffer}s.  In order to support <code>asByteBuffer</code>, all\n+ * of the underlying ByteBuffers must have size equal to\n+ * {@link org.apache.spark.network.buffer.LargeByteBufferHelper#MAX_CHUNK_SIZE} (except that last\n+ * one).  The underlying ByteBuffers may be on-heap, direct, or memory-mapped.\n+ */\n+public class WrappedLargeByteBuffer implements LargeByteBuffer {\n+\n+  @VisibleForTesting\n+  final ByteBuffer[] underlying;\n+\n+  private final long size;\n+  /**\n+   * each sub-ByteBuffer (except for the last one) must be exactly this size.  Note that this\n+   * class *really* expects this to be LargeByteBufferHelper.MAX_CHUNK_SIZE.  The only reason it isn't\n+   * is so that we can do tests without creating ginormous buffers.  Public methods force it to\n+   * be LargeByteBufferHelper.MAX_CHUNK_SIZE\n+   */\n+  private final int subBufferSize;\n+  private long _pos;\n+  @VisibleForTesting\n+  int currentBufferIdx;\n+  @VisibleForTesting\n+  ByteBuffer currentBuffer;\n+\n+  /**\n+   * Construct a WrappedLargeByteBuffer from the given ByteBuffers.  Each of the ByteBuffers must\n+   * have size equal to {@link org.apache.spark.network.buffer.LargeByteBufferHelper#MAX_CHUNK_SIZE}\n+   * except for the final one.  The buffers are <code>duplicate</code>d, so the position of the\n+   * given buffers and the returned buffer will be independent, though the underlying data will be\n+   * shared.  The constructed buffer will always have position == 0.\n+   */\n+  public WrappedLargeByteBuffer(ByteBuffer[] underlying) {\n+    this(underlying, LargeByteBufferHelper.MAX_CHUNK_SIZE);\n+  }\n+\n+  /**\n+   * you do **not** want to call this version.  It leads to a buffer which doesn't properly\n+   * support {@link #asByteBuffer}.  The only reason it exists is to we can have tests which\n+   * don't require 2GB of memory\n+   *\n+   * @param underlying\n+   * @param subBufferSize\n+   */\n+  @VisibleForTesting\n+  WrappedLargeByteBuffer(ByteBuffer[] underlying, int subBufferSize) {\n+    if (underlying.length == 0) {\n+      throw new IllegalArgumentException(\"must wrap at least one ByteBuffer\");\n+    }\n+    this.underlying = new ByteBuffer[underlying.length];\n+    this.subBufferSize = subBufferSize;\n+    long sum = 0L;\n+\n+    for (int i = 0; i < underlying.length; i++) {\n+      ByteBuffer b = underlying[i].duplicate();\n+      b.position(0);\n+      this.underlying[i] = b;\n+      if (i != underlying.length - 1 && b.capacity() != subBufferSize) {\n+        // this is to make sure that asByteBuffer() is implemented correctly.  We need the first\n+        // subBuffer to be LargeByteBufferHelper.MAX_CHUNK_SIZE.  We don't *have* to check all the\n+        // subBuffers, but I figure its makes it more consistent this way.  (Also, this check\n+        // really only serves a purpose when using the public constructor -- subBufferSize is a\n+        // a parameter just to allow small tests.)\n+        throw new IllegalArgumentException(\"All buffers, except for the final one, must have \" +\n+          \"size = \" + subBufferSize);\n+      }\n+      sum += b.capacity();\n+    }\n+    _pos = 0;\n+    currentBufferIdx = 0;\n+    currentBuffer = this.underlying[0];\n+    size = sum;\n+  }\n+",
    "line": 103
  }],
  "prId": 5400
}]