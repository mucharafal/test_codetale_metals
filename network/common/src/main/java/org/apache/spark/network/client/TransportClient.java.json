[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "trace?\n",
    "commit": "cadfd28f116f0dbca11e580a23caf82060bcf922",
    "createdAt": "2014-10-27T21:33:15Z",
    "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.client;\n+\n+import java.io.Closeable;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.channel.Channel;\n+import io.netty.channel.ChannelFuture;\n+import io.netty.channel.ChannelFutureListener;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.protocol.StreamChunkId;\n+import org.apache.spark.network.protocol.request.ChunkFetchRequest;\n+import org.apache.spark.network.protocol.request.RpcRequest;\n+import org.apache.spark.network.util.NettyUtils;\n+\n+/**\n+ * Client for fetching consecutive chunks of a pre-negotiated stream. This API is intended to allow\n+ * efficient transfer of a large amount of data, broken up into chunks with size ranging from\n+ * hundreds of KB to a few MB.\n+ *\n+ * Note that while this client deals with the fetching of chunks from a stream (i.e., data plane),\n+ * the actual setup of the streams is done outside the scope of the transport layer. The convenience\n+ * method \"sendRPC\" is provided to enable control plane communication between the client and server\n+ * to perform this setup.\n+ *\n+ * For example, a typical workflow might be:\n+ * client.sendRPC(new OpenFile(\"/foo\")) --> returns StreamId = 100\n+ * client.fetchChunk(streamId = 100, chunkIndex = 0, callback)\n+ * client.fetchChunk(streamId = 100, chunkIndex = 1, callback)\n+ * ...\n+ * client.sendRPC(new CloseStream(100))\n+ *\n+ * Construct an instance of TransportClient using {@link TransportClientFactory}. A single\n+ * TransportClient may be used for multiple streams, but any given stream must be restricted to a\n+ * single client, in order to avoid out-of-order responses.\n+ *\n+ * NB: This class is used to make requests to the server, while {@link TransportResponseHandler} is\n+ * responsible for handling responses from the server.\n+ *\n+ * Concurrency: thread safe and can be called from multiple threads.\n+ */\n+public class TransportClient implements Closeable {\n+  private final Logger logger = LoggerFactory.getLogger(TransportClient.class);\n+\n+  private final Channel channel;\n+  private final TransportResponseHandler handler;\n+\n+  public TransportClient(Channel channel, TransportResponseHandler handler) {\n+    this.channel = Preconditions.checkNotNull(channel);\n+    this.handler = Preconditions.checkNotNull(handler);\n+  }\n+\n+  public boolean isActive() {\n+    return channel.isOpen() || channel.isActive();\n+  }\n+\n+  /**\n+   * Requests a single chunk from the remote side, from the pre-negotiated streamId.\n+   *\n+   * Chunk indices go from 0 onwards. It is valid to request the same chunk multiple times, though\n+   * some streams may not support this.\n+   *\n+   * Multiple fetchChunk requests may be outstanding simultaneously, and the chunks are guaranteed\n+   * to be returned in the same order that they were requested, assuming only a single\n+   * TransportClient is used to fetch the chunks.\n+   *\n+   * @param streamId Identifier that refers to a stream in the remote StreamManager. This should\n+   *                 be agreed upon by client and server beforehand.\n+   * @param chunkIndex 0-based index of the chunk to fetch\n+   * @param callback Callback invoked upon successful receipt of chunk, or upon any failure.\n+   */\n+  public void fetchChunk(\n+      long streamId,\n+      final int chunkIndex,\n+      final ChunkReceivedCallback callback) {\n+    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n+\n+    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n+    handler.addFetchRequest(streamChunkId, callback);\n+\n+    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n+      new ChannelFutureListener() {\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          if (future.isSuccess()) {\n+            long timeTaken = System.currentTimeMillis() - startTime;\n+            logger.debug(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,"
  }],
  "prId": 2753
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "trace?\n",
    "commit": "cadfd28f116f0dbca11e580a23caf82060bcf922",
    "createdAt": "2014-10-27T21:34:04Z",
    "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.client;\n+\n+import java.io.Closeable;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.channel.Channel;\n+import io.netty.channel.ChannelFuture;\n+import io.netty.channel.ChannelFutureListener;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.protocol.StreamChunkId;\n+import org.apache.spark.network.protocol.request.ChunkFetchRequest;\n+import org.apache.spark.network.protocol.request.RpcRequest;\n+import org.apache.spark.network.util.NettyUtils;\n+\n+/**\n+ * Client for fetching consecutive chunks of a pre-negotiated stream. This API is intended to allow\n+ * efficient transfer of a large amount of data, broken up into chunks with size ranging from\n+ * hundreds of KB to a few MB.\n+ *\n+ * Note that while this client deals with the fetching of chunks from a stream (i.e., data plane),\n+ * the actual setup of the streams is done outside the scope of the transport layer. The convenience\n+ * method \"sendRPC\" is provided to enable control plane communication between the client and server\n+ * to perform this setup.\n+ *\n+ * For example, a typical workflow might be:\n+ * client.sendRPC(new OpenFile(\"/foo\")) --> returns StreamId = 100\n+ * client.fetchChunk(streamId = 100, chunkIndex = 0, callback)\n+ * client.fetchChunk(streamId = 100, chunkIndex = 1, callback)\n+ * ...\n+ * client.sendRPC(new CloseStream(100))\n+ *\n+ * Construct an instance of TransportClient using {@link TransportClientFactory}. A single\n+ * TransportClient may be used for multiple streams, but any given stream must be restricted to a\n+ * single client, in order to avoid out-of-order responses.\n+ *\n+ * NB: This class is used to make requests to the server, while {@link TransportResponseHandler} is\n+ * responsible for handling responses from the server.\n+ *\n+ * Concurrency: thread safe and can be called from multiple threads.\n+ */\n+public class TransportClient implements Closeable {\n+  private final Logger logger = LoggerFactory.getLogger(TransportClient.class);\n+\n+  private final Channel channel;\n+  private final TransportResponseHandler handler;\n+\n+  public TransportClient(Channel channel, TransportResponseHandler handler) {\n+    this.channel = Preconditions.checkNotNull(channel);\n+    this.handler = Preconditions.checkNotNull(handler);\n+  }\n+\n+  public boolean isActive() {\n+    return channel.isOpen() || channel.isActive();\n+  }\n+\n+  /**\n+   * Requests a single chunk from the remote side, from the pre-negotiated streamId.\n+   *\n+   * Chunk indices go from 0 onwards. It is valid to request the same chunk multiple times, though\n+   * some streams may not support this.\n+   *\n+   * Multiple fetchChunk requests may be outstanding simultaneously, and the chunks are guaranteed\n+   * to be returned in the same order that they were requested, assuming only a single\n+   * TransportClient is used to fetch the chunks.\n+   *\n+   * @param streamId Identifier that refers to a stream in the remote StreamManager. This should\n+   *                 be agreed upon by client and server beforehand.\n+   * @param chunkIndex 0-based index of the chunk to fetch\n+   * @param callback Callback invoked upon successful receipt of chunk, or upon any failure.\n+   */\n+  public void fetchChunk(\n+      long streamId,\n+      final int chunkIndex,\n+      final ChunkReceivedCallback callback) {\n+    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n+\n+    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n+    handler.addFetchRequest(streamChunkId, callback);\n+\n+    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n+      new ChannelFutureListener() {\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          if (future.isSuccess()) {\n+            long timeTaken = System.currentTimeMillis() - startTime;\n+            logger.debug(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,\n+              timeTaken);\n+          } else {\n+            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n+              serverAddr, future.cause());\n+            logger.error(errorMsg, future.cause());\n+            handler.removeFetchRequest(streamChunkId);\n+            callback.onFailure(chunkIndex, new RuntimeException(errorMsg, future.cause()));\n+          }\n+        }\n+      });\n+  }\n+\n+  /**\n+   * Sends an opaque message to the RpcHandler on the server-side. The callback will be invoked\n+   * with the server's response or upon any failure.\n+   */\n+  public void sendRpc(byte[] message, final RpcResponseCallback callback) {\n+    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending RPC to {}\", serverAddr);"
  }],
  "prId": 2753
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "i think we should close the connection here if we fail to flush\n",
    "commit": "cadfd28f116f0dbca11e580a23caf82060bcf922",
    "createdAt": "2014-10-27T21:46:03Z",
    "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.client;\n+\n+import java.io.Closeable;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.channel.Channel;\n+import io.netty.channel.ChannelFuture;\n+import io.netty.channel.ChannelFutureListener;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.protocol.StreamChunkId;\n+import org.apache.spark.network.protocol.request.ChunkFetchRequest;\n+import org.apache.spark.network.protocol.request.RpcRequest;\n+import org.apache.spark.network.util.NettyUtils;\n+\n+/**\n+ * Client for fetching consecutive chunks of a pre-negotiated stream. This API is intended to allow\n+ * efficient transfer of a large amount of data, broken up into chunks with size ranging from\n+ * hundreds of KB to a few MB.\n+ *\n+ * Note that while this client deals with the fetching of chunks from a stream (i.e., data plane),\n+ * the actual setup of the streams is done outside the scope of the transport layer. The convenience\n+ * method \"sendRPC\" is provided to enable control plane communication between the client and server\n+ * to perform this setup.\n+ *\n+ * For example, a typical workflow might be:\n+ * client.sendRPC(new OpenFile(\"/foo\")) --> returns StreamId = 100\n+ * client.fetchChunk(streamId = 100, chunkIndex = 0, callback)\n+ * client.fetchChunk(streamId = 100, chunkIndex = 1, callback)\n+ * ...\n+ * client.sendRPC(new CloseStream(100))\n+ *\n+ * Construct an instance of TransportClient using {@link TransportClientFactory}. A single\n+ * TransportClient may be used for multiple streams, but any given stream must be restricted to a\n+ * single client, in order to avoid out-of-order responses.\n+ *\n+ * NB: This class is used to make requests to the server, while {@link TransportResponseHandler} is\n+ * responsible for handling responses from the server.\n+ *\n+ * Concurrency: thread safe and can be called from multiple threads.\n+ */\n+public class TransportClient implements Closeable {\n+  private final Logger logger = LoggerFactory.getLogger(TransportClient.class);\n+\n+  private final Channel channel;\n+  private final TransportResponseHandler handler;\n+\n+  public TransportClient(Channel channel, TransportResponseHandler handler) {\n+    this.channel = Preconditions.checkNotNull(channel);\n+    this.handler = Preconditions.checkNotNull(handler);\n+  }\n+\n+  public boolean isActive() {\n+    return channel.isOpen() || channel.isActive();\n+  }\n+\n+  /**\n+   * Requests a single chunk from the remote side, from the pre-negotiated streamId.\n+   *\n+   * Chunk indices go from 0 onwards. It is valid to request the same chunk multiple times, though\n+   * some streams may not support this.\n+   *\n+   * Multiple fetchChunk requests may be outstanding simultaneously, and the chunks are guaranteed\n+   * to be returned in the same order that they were requested, assuming only a single\n+   * TransportClient is used to fetch the chunks.\n+   *\n+   * @param streamId Identifier that refers to a stream in the remote StreamManager. This should\n+   *                 be agreed upon by client and server beforehand.\n+   * @param chunkIndex 0-based index of the chunk to fetch\n+   * @param callback Callback invoked upon successful receipt of chunk, or upon any failure.\n+   */\n+  public void fetchChunk(\n+      long streamId,\n+      final int chunkIndex,\n+      final ChunkReceivedCallback callback) {\n+    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n+\n+    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n+    handler.addFetchRequest(streamChunkId, callback);\n+\n+    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n+      new ChannelFutureListener() {\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          if (future.isSuccess()) {\n+            long timeTaken = System.currentTimeMillis() - startTime;\n+            logger.debug(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,\n+              timeTaken);\n+          } else {\n+            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,"
  }],
  "prId": 2753
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "i think we should close the connection here if we fail to flush\n",
    "commit": "cadfd28f116f0dbca11e580a23caf82060bcf922",
    "createdAt": "2014-10-27T21:46:07Z",
    "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.client;\n+\n+import java.io.Closeable;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.channel.Channel;\n+import io.netty.channel.ChannelFuture;\n+import io.netty.channel.ChannelFutureListener;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.protocol.StreamChunkId;\n+import org.apache.spark.network.protocol.request.ChunkFetchRequest;\n+import org.apache.spark.network.protocol.request.RpcRequest;\n+import org.apache.spark.network.util.NettyUtils;\n+\n+/**\n+ * Client for fetching consecutive chunks of a pre-negotiated stream. This API is intended to allow\n+ * efficient transfer of a large amount of data, broken up into chunks with size ranging from\n+ * hundreds of KB to a few MB.\n+ *\n+ * Note that while this client deals with the fetching of chunks from a stream (i.e., data plane),\n+ * the actual setup of the streams is done outside the scope of the transport layer. The convenience\n+ * method \"sendRPC\" is provided to enable control plane communication between the client and server\n+ * to perform this setup.\n+ *\n+ * For example, a typical workflow might be:\n+ * client.sendRPC(new OpenFile(\"/foo\")) --> returns StreamId = 100\n+ * client.fetchChunk(streamId = 100, chunkIndex = 0, callback)\n+ * client.fetchChunk(streamId = 100, chunkIndex = 1, callback)\n+ * ...\n+ * client.sendRPC(new CloseStream(100))\n+ *\n+ * Construct an instance of TransportClient using {@link TransportClientFactory}. A single\n+ * TransportClient may be used for multiple streams, but any given stream must be restricted to a\n+ * single client, in order to avoid out-of-order responses.\n+ *\n+ * NB: This class is used to make requests to the server, while {@link TransportResponseHandler} is\n+ * responsible for handling responses from the server.\n+ *\n+ * Concurrency: thread safe and can be called from multiple threads.\n+ */\n+public class TransportClient implements Closeable {\n+  private final Logger logger = LoggerFactory.getLogger(TransportClient.class);\n+\n+  private final Channel channel;\n+  private final TransportResponseHandler handler;\n+\n+  public TransportClient(Channel channel, TransportResponseHandler handler) {\n+    this.channel = Preconditions.checkNotNull(channel);\n+    this.handler = Preconditions.checkNotNull(handler);\n+  }\n+\n+  public boolean isActive() {\n+    return channel.isOpen() || channel.isActive();\n+  }\n+\n+  /**\n+   * Requests a single chunk from the remote side, from the pre-negotiated streamId.\n+   *\n+   * Chunk indices go from 0 onwards. It is valid to request the same chunk multiple times, though\n+   * some streams may not support this.\n+   *\n+   * Multiple fetchChunk requests may be outstanding simultaneously, and the chunks are guaranteed\n+   * to be returned in the same order that they were requested, assuming only a single\n+   * TransportClient is used to fetch the chunks.\n+   *\n+   * @param streamId Identifier that refers to a stream in the remote StreamManager. This should\n+   *                 be agreed upon by client and server beforehand.\n+   * @param chunkIndex 0-based index of the chunk to fetch\n+   * @param callback Callback invoked upon successful receipt of chunk, or upon any failure.\n+   */\n+  public void fetchChunk(\n+      long streamId,\n+      final int chunkIndex,\n+      final ChunkReceivedCallback callback) {\n+    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n+\n+    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n+    handler.addFetchRequest(streamChunkId, callback);\n+\n+    channel.writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n+      new ChannelFutureListener() {\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          if (future.isSuccess()) {\n+            long timeTaken = System.currentTimeMillis() - startTime;\n+            logger.debug(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,\n+              timeTaken);\n+          } else {\n+            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n+              serverAddr, future.cause());\n+            logger.error(errorMsg, future.cause());\n+            handler.removeFetchRequest(streamChunkId);\n+            callback.onFailure(chunkIndex, new RuntimeException(errorMsg, future.cause()));\n+          }\n+        }\n+      });\n+  }\n+\n+  /**\n+   * Sends an opaque message to the RpcHandler on the server-side. The callback will be invoked\n+   * with the server's response or upon any failure.\n+   */\n+  public void sendRpc(byte[] message, final RpcResponseCallback callback) {\n+    final String serverAddr = NettyUtils.getRemoteAddress(channel);\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending RPC to {}\", serverAddr);\n+\n+    final long tag = UUID.randomUUID().getLeastSignificantBits();\n+    handler.addRpcRequest(tag, callback);\n+\n+    channel.writeAndFlush(new RpcRequest(tag, message)).addListener(\n+      new ChannelFutureListener() {\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          if (future.isSuccess()) {\n+            long timeTaken = System.currentTimeMillis() - startTime;\n+            logger.debug(\"Sending request {} to {} took {} ms\", tag, serverAddr, timeTaken);\n+          } else {\n+            String errorMsg = String.format(\"Failed to send RPC %s to %s: %s\", tag,"
  }],
  "prId": 2753
}]