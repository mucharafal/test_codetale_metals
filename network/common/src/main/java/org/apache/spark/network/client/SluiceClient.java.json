[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "log instead of print?\n",
    "commit": "cadfd28f116f0dbca11e580a23caf82060bcf922",
    "createdAt": "2014-10-14T05:58:13Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.client;\n+\n+import java.io.Closeable;\n+import java.util.UUID;\n+\n+import io.netty.channel.ChannelFuture;\n+import io.netty.channel.ChannelFutureListener;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.protocol.StreamChunkId;\n+import org.apache.spark.network.protocol.request.ChunkFetchRequest;\n+import org.apache.spark.network.protocol.request.RpcRequest;\n+\n+/**\n+ * Client for fetching consecutive chunks of a pre-negotiated stream. This API is intended to allow\n+ * efficient transfer of a large amount of data, broken up into chunks with size ranging from\n+ * hundreds of KB to a few MB.\n+ *\n+ * Note that while this client deals with the fetching of chunks from a stream (i.e., data plane),\n+ * the actual setup of the streams is done outside the scope of Sluice. The convenience method\n+ * \"sendRPC\" is provided to enable control plane communication between the client and server to\n+ * perform this setup.\n+ *\n+ * For example, a typical workflow might be:\n+ * client.sendRPC(new OpenFile(\"/foo\")) --> returns StreamId = 100\n+ * client.fetchChunk(streamId = 100, chunkIndex = 0, callback)\n+ * client.fetchChunk(streamId = 100, chunkIndex = 1, callback)\n+ * ...\n+ * client.sendRPC(new CloseStream(100))\n+ *\n+ * Construct an instance of SluiceClient using {@link SluiceClientFactory}. A single SluiceClient\n+ * may be used for multiple streams, but any given stream must be restricted to a single client,\n+ * in order to avoid out-of-order responses.\n+ *\n+ * NB: This class is used to make requests to the server, while {@link SluiceClientHandler} is\n+ * responsible for handling responses from the server.\n+ *\n+ * Concurrency: thread safe and can be called from multiple threads.\n+ */\n+public class SluiceClient implements Closeable {\n+  private final Logger logger = LoggerFactory.getLogger(SluiceClient.class);\n+\n+  private final ChannelFuture cf;\n+  private final SluiceClientHandler handler;\n+\n+  private final String serverAddr;\n+\n+  SluiceClient(ChannelFuture cf, SluiceClientHandler handler) {\n+    this.cf = cf;\n+    this.handler = handler;\n+\n+    if (cf != null && cf.channel() != null && cf.channel().remoteAddress() != null) {\n+      serverAddr = cf.channel().remoteAddress().toString();\n+    } else {\n+      serverAddr = \"<unknown address>\";\n+    }\n+  }\n+\n+  public boolean isActive() {\n+    return cf.channel().isActive();\n+  }\n+\n+  /**\n+   * Requests a single chunk from the remote side, from the pre-negotiated streamId.\n+   *\n+   * Chunk indices go from 0 onwards. It is valid to request the same chunk multiple times, though\n+   * some streams may not support this.\n+   *\n+   * Multiple fetchChunk requests may be outstanding simultaneously, and the chunks are guaranteed\n+   * to be returned in the same order that they were requested, assuming only a single SluiceClient\n+   * is used to fetch the chunks.\n+   *\n+   * @param streamId Identifier that refers to a stream in the remote StreamManager. This should\n+   *                 be agreed upon by client and server beforehand.\n+   * @param chunkIndex 0-based index of the chunk to fetch\n+   * @param callback Callback invoked upon successful receipt of chunk, or upon any failure.\n+   */\n+  public void fetchChunk(\n+      long streamId,\n+      final int chunkIndex,\n+      final ChunkReceivedCallback callback) {\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n+\n+    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n+    handler.addFetchRequest(streamChunkId, callback);\n+\n+    cf.channel().writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n+      new ChannelFutureListener() {\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          if (future.isSuccess()) {\n+            long timeTaken = System.currentTimeMillis() - startTime;\n+            logger.debug(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,\n+                timeTaken);\n+          } else {\n+            // Fail all blocks.\n+            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n+              serverAddr, future.cause().getMessage());\n+            logger.error(errorMsg, future.cause());\n+            future.cause().printStackTrace();"
  }, {
    "author": {
      "login": "aarondav"
    },
    "body": "whoops!\n",
    "commit": "cadfd28f116f0dbca11e580a23caf82060bcf922",
    "createdAt": "2014-10-17T02:35:49Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.client;\n+\n+import java.io.Closeable;\n+import java.util.UUID;\n+\n+import io.netty.channel.ChannelFuture;\n+import io.netty.channel.ChannelFutureListener;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.protocol.StreamChunkId;\n+import org.apache.spark.network.protocol.request.ChunkFetchRequest;\n+import org.apache.spark.network.protocol.request.RpcRequest;\n+\n+/**\n+ * Client for fetching consecutive chunks of a pre-negotiated stream. This API is intended to allow\n+ * efficient transfer of a large amount of data, broken up into chunks with size ranging from\n+ * hundreds of KB to a few MB.\n+ *\n+ * Note that while this client deals with the fetching of chunks from a stream (i.e., data plane),\n+ * the actual setup of the streams is done outside the scope of Sluice. The convenience method\n+ * \"sendRPC\" is provided to enable control plane communication between the client and server to\n+ * perform this setup.\n+ *\n+ * For example, a typical workflow might be:\n+ * client.sendRPC(new OpenFile(\"/foo\")) --> returns StreamId = 100\n+ * client.fetchChunk(streamId = 100, chunkIndex = 0, callback)\n+ * client.fetchChunk(streamId = 100, chunkIndex = 1, callback)\n+ * ...\n+ * client.sendRPC(new CloseStream(100))\n+ *\n+ * Construct an instance of SluiceClient using {@link SluiceClientFactory}. A single SluiceClient\n+ * may be used for multiple streams, but any given stream must be restricted to a single client,\n+ * in order to avoid out-of-order responses.\n+ *\n+ * NB: This class is used to make requests to the server, while {@link SluiceClientHandler} is\n+ * responsible for handling responses from the server.\n+ *\n+ * Concurrency: thread safe and can be called from multiple threads.\n+ */\n+public class SluiceClient implements Closeable {\n+  private final Logger logger = LoggerFactory.getLogger(SluiceClient.class);\n+\n+  private final ChannelFuture cf;\n+  private final SluiceClientHandler handler;\n+\n+  private final String serverAddr;\n+\n+  SluiceClient(ChannelFuture cf, SluiceClientHandler handler) {\n+    this.cf = cf;\n+    this.handler = handler;\n+\n+    if (cf != null && cf.channel() != null && cf.channel().remoteAddress() != null) {\n+      serverAddr = cf.channel().remoteAddress().toString();\n+    } else {\n+      serverAddr = \"<unknown address>\";\n+    }\n+  }\n+\n+  public boolean isActive() {\n+    return cf.channel().isActive();\n+  }\n+\n+  /**\n+   * Requests a single chunk from the remote side, from the pre-negotiated streamId.\n+   *\n+   * Chunk indices go from 0 onwards. It is valid to request the same chunk multiple times, though\n+   * some streams may not support this.\n+   *\n+   * Multiple fetchChunk requests may be outstanding simultaneously, and the chunks are guaranteed\n+   * to be returned in the same order that they were requested, assuming only a single SluiceClient\n+   * is used to fetch the chunks.\n+   *\n+   * @param streamId Identifier that refers to a stream in the remote StreamManager. This should\n+   *                 be agreed upon by client and server beforehand.\n+   * @param chunkIndex 0-based index of the chunk to fetch\n+   * @param callback Callback invoked upon successful receipt of chunk, or upon any failure.\n+   */\n+  public void fetchChunk(\n+      long streamId,\n+      final int chunkIndex,\n+      final ChunkReceivedCallback callback) {\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n+\n+    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n+    handler.addFetchRequest(streamChunkId, callback);\n+\n+    cf.channel().writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n+      new ChannelFutureListener() {\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          if (future.isSuccess()) {\n+            long timeTaken = System.currentTimeMillis() - startTime;\n+            logger.debug(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,\n+                timeTaken);\n+          } else {\n+            // Fail all blocks.\n+            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n+              serverAddr, future.cause().getMessage());\n+            logger.error(errorMsg, future.cause());\n+            future.cause().printStackTrace();"
  }],
  "prId": 2753
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "rather than byte[], how about just an Object, and the server/client takes a configurable serializer that does the serialization?\n",
    "commit": "cadfd28f116f0dbca11e580a23caf82060bcf922",
    "createdAt": "2014-10-14T06:00:14Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.client;\n+\n+import java.io.Closeable;\n+import java.util.UUID;\n+\n+import io.netty.channel.ChannelFuture;\n+import io.netty.channel.ChannelFutureListener;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.protocol.StreamChunkId;\n+import org.apache.spark.network.protocol.request.ChunkFetchRequest;\n+import org.apache.spark.network.protocol.request.RpcRequest;\n+\n+/**\n+ * Client for fetching consecutive chunks of a pre-negotiated stream. This API is intended to allow\n+ * efficient transfer of a large amount of data, broken up into chunks with size ranging from\n+ * hundreds of KB to a few MB.\n+ *\n+ * Note that while this client deals with the fetching of chunks from a stream (i.e., data plane),\n+ * the actual setup of the streams is done outside the scope of Sluice. The convenience method\n+ * \"sendRPC\" is provided to enable control plane communication between the client and server to\n+ * perform this setup.\n+ *\n+ * For example, a typical workflow might be:\n+ * client.sendRPC(new OpenFile(\"/foo\")) --> returns StreamId = 100\n+ * client.fetchChunk(streamId = 100, chunkIndex = 0, callback)\n+ * client.fetchChunk(streamId = 100, chunkIndex = 1, callback)\n+ * ...\n+ * client.sendRPC(new CloseStream(100))\n+ *\n+ * Construct an instance of SluiceClient using {@link SluiceClientFactory}. A single SluiceClient\n+ * may be used for multiple streams, but any given stream must be restricted to a single client,\n+ * in order to avoid out-of-order responses.\n+ *\n+ * NB: This class is used to make requests to the server, while {@link SluiceClientHandler} is\n+ * responsible for handling responses from the server.\n+ *\n+ * Concurrency: thread safe and can be called from multiple threads.\n+ */\n+public class SluiceClient implements Closeable {\n+  private final Logger logger = LoggerFactory.getLogger(SluiceClient.class);\n+\n+  private final ChannelFuture cf;\n+  private final SluiceClientHandler handler;\n+\n+  private final String serverAddr;\n+\n+  SluiceClient(ChannelFuture cf, SluiceClientHandler handler) {\n+    this.cf = cf;\n+    this.handler = handler;\n+\n+    if (cf != null && cf.channel() != null && cf.channel().remoteAddress() != null) {\n+      serverAddr = cf.channel().remoteAddress().toString();\n+    } else {\n+      serverAddr = \"<unknown address>\";\n+    }\n+  }\n+\n+  public boolean isActive() {\n+    return cf.channel().isActive();\n+  }\n+\n+  /**\n+   * Requests a single chunk from the remote side, from the pre-negotiated streamId.\n+   *\n+   * Chunk indices go from 0 onwards. It is valid to request the same chunk multiple times, though\n+   * some streams may not support this.\n+   *\n+   * Multiple fetchChunk requests may be outstanding simultaneously, and the chunks are guaranteed\n+   * to be returned in the same order that they were requested, assuming only a single SluiceClient\n+   * is used to fetch the chunks.\n+   *\n+   * @param streamId Identifier that refers to a stream in the remote StreamManager. This should\n+   *                 be agreed upon by client and server beforehand.\n+   * @param chunkIndex 0-based index of the chunk to fetch\n+   * @param callback Callback invoked upon successful receipt of chunk, or upon any failure.\n+   */\n+  public void fetchChunk(\n+      long streamId,\n+      final int chunkIndex,\n+      final ChunkReceivedCallback callback) {\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n+\n+    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n+    handler.addFetchRequest(streamChunkId, callback);\n+\n+    cf.channel().writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n+      new ChannelFutureListener() {\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          if (future.isSuccess()) {\n+            long timeTaken = System.currentTimeMillis() - startTime;\n+            logger.debug(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,\n+                timeTaken);\n+          } else {\n+            // Fail all blocks.\n+            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n+              serverAddr, future.cause().getMessage());\n+            logger.error(errorMsg, future.cause());\n+            future.cause().printStackTrace();\n+            handler.removeFetchRequest(streamChunkId);\n+            callback.onFailure(chunkIndex, new RuntimeException(errorMsg));\n+          }\n+        }\n+      });\n+  }\n+\n+  /**\n+   * Sends an opaque message to the RpcHandler on the server-side. The callback will be invoked\n+   * with the server's response or upon any failure.\n+   */\n+  public void sendRpc(byte[] message, final RpcResponseCallback callback) {"
  }, {
    "author": {
      "login": "aarondav"
    },
    "body": "Issue here is that we'd have to move Serializer into the network layer. I think the bag-o'-bytes model works fine for a networking layer.\n",
    "commit": "cadfd28f116f0dbca11e580a23caf82060bcf922",
    "createdAt": "2014-10-17T02:38:31Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.client;\n+\n+import java.io.Closeable;\n+import java.util.UUID;\n+\n+import io.netty.channel.ChannelFuture;\n+import io.netty.channel.ChannelFutureListener;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.protocol.StreamChunkId;\n+import org.apache.spark.network.protocol.request.ChunkFetchRequest;\n+import org.apache.spark.network.protocol.request.RpcRequest;\n+\n+/**\n+ * Client for fetching consecutive chunks of a pre-negotiated stream. This API is intended to allow\n+ * efficient transfer of a large amount of data, broken up into chunks with size ranging from\n+ * hundreds of KB to a few MB.\n+ *\n+ * Note that while this client deals with the fetching of chunks from a stream (i.e., data plane),\n+ * the actual setup of the streams is done outside the scope of Sluice. The convenience method\n+ * \"sendRPC\" is provided to enable control plane communication between the client and server to\n+ * perform this setup.\n+ *\n+ * For example, a typical workflow might be:\n+ * client.sendRPC(new OpenFile(\"/foo\")) --> returns StreamId = 100\n+ * client.fetchChunk(streamId = 100, chunkIndex = 0, callback)\n+ * client.fetchChunk(streamId = 100, chunkIndex = 1, callback)\n+ * ...\n+ * client.sendRPC(new CloseStream(100))\n+ *\n+ * Construct an instance of SluiceClient using {@link SluiceClientFactory}. A single SluiceClient\n+ * may be used for multiple streams, but any given stream must be restricted to a single client,\n+ * in order to avoid out-of-order responses.\n+ *\n+ * NB: This class is used to make requests to the server, while {@link SluiceClientHandler} is\n+ * responsible for handling responses from the server.\n+ *\n+ * Concurrency: thread safe and can be called from multiple threads.\n+ */\n+public class SluiceClient implements Closeable {\n+  private final Logger logger = LoggerFactory.getLogger(SluiceClient.class);\n+\n+  private final ChannelFuture cf;\n+  private final SluiceClientHandler handler;\n+\n+  private final String serverAddr;\n+\n+  SluiceClient(ChannelFuture cf, SluiceClientHandler handler) {\n+    this.cf = cf;\n+    this.handler = handler;\n+\n+    if (cf != null && cf.channel() != null && cf.channel().remoteAddress() != null) {\n+      serverAddr = cf.channel().remoteAddress().toString();\n+    } else {\n+      serverAddr = \"<unknown address>\";\n+    }\n+  }\n+\n+  public boolean isActive() {\n+    return cf.channel().isActive();\n+  }\n+\n+  /**\n+   * Requests a single chunk from the remote side, from the pre-negotiated streamId.\n+   *\n+   * Chunk indices go from 0 onwards. It is valid to request the same chunk multiple times, though\n+   * some streams may not support this.\n+   *\n+   * Multiple fetchChunk requests may be outstanding simultaneously, and the chunks are guaranteed\n+   * to be returned in the same order that they were requested, assuming only a single SluiceClient\n+   * is used to fetch the chunks.\n+   *\n+   * @param streamId Identifier that refers to a stream in the remote StreamManager. This should\n+   *                 be agreed upon by client and server beforehand.\n+   * @param chunkIndex 0-based index of the chunk to fetch\n+   * @param callback Callback invoked upon successful receipt of chunk, or upon any failure.\n+   */\n+  public void fetchChunk(\n+      long streamId,\n+      final int chunkIndex,\n+      final ChunkReceivedCallback callback) {\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n+\n+    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n+    handler.addFetchRequest(streamChunkId, callback);\n+\n+    cf.channel().writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n+      new ChannelFutureListener() {\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          if (future.isSuccess()) {\n+            long timeTaken = System.currentTimeMillis() - startTime;\n+            logger.debug(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,\n+                timeTaken);\n+          } else {\n+            // Fail all blocks.\n+            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n+              serverAddr, future.cause().getMessage());\n+            logger.error(errorMsg, future.cause());\n+            future.cause().printStackTrace();\n+            handler.removeFetchRequest(streamChunkId);\n+            callback.onFailure(chunkIndex, new RuntimeException(errorMsg));\n+          }\n+        }\n+      });\n+  }\n+\n+  /**\n+   * Sends an opaque message to the RpcHandler on the server-side. The callback will be invoked\n+   * with the server's response or upon any failure.\n+   */\n+  public void sendRpc(byte[] message, final RpcResponseCallback callback) {"
  }],
  "prId": 2753
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "pass cause also into the RuntimeException?\n",
    "commit": "cadfd28f116f0dbca11e580a23caf82060bcf922",
    "createdAt": "2014-10-14T06:01:07Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.client;\n+\n+import java.io.Closeable;\n+import java.util.UUID;\n+\n+import io.netty.channel.ChannelFuture;\n+import io.netty.channel.ChannelFutureListener;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.spark.network.protocol.StreamChunkId;\n+import org.apache.spark.network.protocol.request.ChunkFetchRequest;\n+import org.apache.spark.network.protocol.request.RpcRequest;\n+\n+/**\n+ * Client for fetching consecutive chunks of a pre-negotiated stream. This API is intended to allow\n+ * efficient transfer of a large amount of data, broken up into chunks with size ranging from\n+ * hundreds of KB to a few MB.\n+ *\n+ * Note that while this client deals with the fetching of chunks from a stream (i.e., data plane),\n+ * the actual setup of the streams is done outside the scope of Sluice. The convenience method\n+ * \"sendRPC\" is provided to enable control plane communication between the client and server to\n+ * perform this setup.\n+ *\n+ * For example, a typical workflow might be:\n+ * client.sendRPC(new OpenFile(\"/foo\")) --> returns StreamId = 100\n+ * client.fetchChunk(streamId = 100, chunkIndex = 0, callback)\n+ * client.fetchChunk(streamId = 100, chunkIndex = 1, callback)\n+ * ...\n+ * client.sendRPC(new CloseStream(100))\n+ *\n+ * Construct an instance of SluiceClient using {@link SluiceClientFactory}. A single SluiceClient\n+ * may be used for multiple streams, but any given stream must be restricted to a single client,\n+ * in order to avoid out-of-order responses.\n+ *\n+ * NB: This class is used to make requests to the server, while {@link SluiceClientHandler} is\n+ * responsible for handling responses from the server.\n+ *\n+ * Concurrency: thread safe and can be called from multiple threads.\n+ */\n+public class SluiceClient implements Closeable {\n+  private final Logger logger = LoggerFactory.getLogger(SluiceClient.class);\n+\n+  private final ChannelFuture cf;\n+  private final SluiceClientHandler handler;\n+\n+  private final String serverAddr;\n+\n+  SluiceClient(ChannelFuture cf, SluiceClientHandler handler) {\n+    this.cf = cf;\n+    this.handler = handler;\n+\n+    if (cf != null && cf.channel() != null && cf.channel().remoteAddress() != null) {\n+      serverAddr = cf.channel().remoteAddress().toString();\n+    } else {\n+      serverAddr = \"<unknown address>\";\n+    }\n+  }\n+\n+  public boolean isActive() {\n+    return cf.channel().isActive();\n+  }\n+\n+  /**\n+   * Requests a single chunk from the remote side, from the pre-negotiated streamId.\n+   *\n+   * Chunk indices go from 0 onwards. It is valid to request the same chunk multiple times, though\n+   * some streams may not support this.\n+   *\n+   * Multiple fetchChunk requests may be outstanding simultaneously, and the chunks are guaranteed\n+   * to be returned in the same order that they were requested, assuming only a single SluiceClient\n+   * is used to fetch the chunks.\n+   *\n+   * @param streamId Identifier that refers to a stream in the remote StreamManager. This should\n+   *                 be agreed upon by client and server beforehand.\n+   * @param chunkIndex 0-based index of the chunk to fetch\n+   * @param callback Callback invoked upon successful receipt of chunk, or upon any failure.\n+   */\n+  public void fetchChunk(\n+      long streamId,\n+      final int chunkIndex,\n+      final ChunkReceivedCallback callback) {\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending fetch chunk request {} to {}\", chunkIndex, serverAddr);\n+\n+    final StreamChunkId streamChunkId = new StreamChunkId(streamId, chunkIndex);\n+    handler.addFetchRequest(streamChunkId, callback);\n+\n+    cf.channel().writeAndFlush(new ChunkFetchRequest(streamChunkId)).addListener(\n+      new ChannelFutureListener() {\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          if (future.isSuccess()) {\n+            long timeTaken = System.currentTimeMillis() - startTime;\n+            logger.debug(\"Sending request {} to {} took {} ms\", streamChunkId, serverAddr,\n+                timeTaken);\n+          } else {\n+            // Fail all blocks.\n+            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", streamChunkId,\n+              serverAddr, future.cause().getMessage());\n+            logger.error(errorMsg, future.cause());\n+            future.cause().printStackTrace();\n+            handler.removeFetchRequest(streamChunkId);\n+            callback.onFailure(chunkIndex, new RuntimeException(errorMsg));\n+          }\n+        }\n+      });\n+  }\n+\n+  /**\n+   * Sends an opaque message to the RpcHandler on the server-side. The callback will be invoked\n+   * with the server's response or upon any failure.\n+   */\n+  public void sendRpc(byte[] message, final RpcResponseCallback callback) {\n+    final long startTime = System.currentTimeMillis();\n+    logger.debug(\"Sending RPC to {}\", serverAddr);\n+\n+    final long tag = UUID.randomUUID().getLeastSignificantBits();\n+    handler.addRpcRequest(tag, callback);\n+\n+    cf.channel().writeAndFlush(new RpcRequest(tag, message)).addListener(\n+      new ChannelFutureListener() {\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          if (future.isSuccess()) {\n+            long timeTaken = System.currentTimeMillis() - startTime;\n+            logger.debug(\"Sending request {} to {} took {} ms\", tag, serverAddr, timeTaken);\n+          } else {\n+            // Fail all blocks.\n+            String errorMsg = String.format(\"Failed to send request %s to %s: %s\", tag,\n+                serverAddr, future.cause().getMessage());\n+            logger.error(errorMsg, future.cause());\n+            handler.removeRpcRequest(tag);\n+            callback.onFailure(new RuntimeException(errorMsg));"
  }],
  "prId": 2753
}]