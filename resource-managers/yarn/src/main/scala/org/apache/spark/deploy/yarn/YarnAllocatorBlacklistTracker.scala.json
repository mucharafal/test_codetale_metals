[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "nit: double-indent the continued continuation of the `if` condition.  (we dont' do this everywhere but we should, I find it helps)",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-13T21:35:23Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_ALLOCATION_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_ALLOCATION_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_SIZE_LIMIT = sparkConf.get(YARN_BLACKLIST_SIZE_LIMIT)\n+\n+  private val BLACKLIST_SIZE_DEFAULT_WEIGHT = sparkConf.get(YARN_BLACKLIST_SIZE_DEFAULT_WEIGHT)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklistedNodesWithExpiry = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / BLACKLIST_SIZE_DEFAULT_WEIGHT).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  /**\n+   * Use a different clock. This is mainly used for testing.\n+   */\n+  def setClock(newClock: Clock): Unit = {\n+    clock = newClock\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklistedNodesWithExpiry.contains(hostname) &&\n+          !allocationBlacklistedNodesWithExpiry.contains(hostname)) {\n+          failureWithinTimeIntervalTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureWithinTimeIntervalTracker.registerSumExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (IS_YARN_ALLOCATION_BLACKLIST_ENABLED) {\n+      val failuresOnHost = failureWithinTimeIntervalTracker.getNumExecutorFailuresOnHost(hostname)\n+      if (failuresOnHost > BLACKLIST_MAX_FAILED_EXEC_PER_NODE) {\n+        logInfo(\"blacklisting host as YARN allocation failed: %s\".format(hostname))\n+        allocationBlacklistedNodesWithExpiry.put(\n+          hostname,\n+          clock.getTimeMillis() + BLACKLIST_TIMEOUT_MILLIS)\n+        refreshBlacklistedNodes()\n+      }\n+    }\n+  }\n+\n+  def setSchedulerBlacklistedNodes(schedulerBlacklistedNodesWithExpiry: Map[String, Long]): Unit = {\n+    this.schedulerBlacklistedNodesWithExpiry = schedulerBlacklistedNodesWithExpiry\n+    refreshBlacklistedNodes()\n+  }\n+\n+  private def refreshBlacklistedNodes(): Unit = {\n+    removeExpiredYarnBlacklistedNodes()\n+    val limit =\n+      BLACKLIST_SIZE_LIMIT.getOrElse((numClusterNodes * BLACKLIST_SIZE_DEFAULT_WEIGHT).toInt)\n+    val nodesToBlacklist =\n+      if (schedulerBlacklistedNodesWithExpiry.size +\n+        allocationBlacklistedNodesWithExpiry.size > limit) {"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "henryr"
    },
    "body": "consider just:\r\n\r\n    if (!IS_YARN_ALLOCATION_BLACKLIST_ENABLED) return;\r\n\r\nto save a level of indentation below.",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-16T22:44:55Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_ALLOCATION_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_ALLOCATION_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_SIZE_LIMIT = sparkConf.get(YARN_BLACKLIST_SIZE_LIMIT)\n+\n+  private val BLACKLIST_SIZE_DEFAULT_WEIGHT = sparkConf.get(YARN_BLACKLIST_SIZE_DEFAULT_WEIGHT)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklistedNodesWithExpiry = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / BLACKLIST_SIZE_DEFAULT_WEIGHT).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  /**\n+   * Use a different clock. This is mainly used for testing.\n+   */\n+  def setClock(newClock: Clock): Unit = {\n+    clock = newClock\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklistedNodesWithExpiry.contains(hostname) &&\n+          !allocationBlacklistedNodesWithExpiry.contains(hostname)) {\n+          failureWithinTimeIntervalTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureWithinTimeIntervalTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (IS_YARN_ALLOCATION_BLACKLIST_ENABLED) {"
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "As I know using return in Scala is mostly discouraged. Anyway here we have only two levels of indentations so I would keep these if conditions as it is. ",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-18T12:17:36Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_ALLOCATION_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_ALLOCATION_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_SIZE_LIMIT = sparkConf.get(YARN_BLACKLIST_SIZE_LIMIT)\n+\n+  private val BLACKLIST_SIZE_DEFAULT_WEIGHT = sparkConf.get(YARN_BLACKLIST_SIZE_DEFAULT_WEIGHT)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklistedNodesWithExpiry = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / BLACKLIST_SIZE_DEFAULT_WEIGHT).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  /**\n+   * Use a different clock. This is mainly used for testing.\n+   */\n+  def setClock(newClock: Clock): Unit = {\n+    clock = newClock\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklistedNodesWithExpiry.contains(hostname) &&\n+          !allocationBlacklistedNodesWithExpiry.contains(hostname)) {\n+          failureWithinTimeIntervalTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureWithinTimeIntervalTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (IS_YARN_ALLOCATION_BLACKLIST_ENABLED) {"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "henryr"
    },
    "body": "log msg could include the number of failures",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-16T22:45:23Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_ALLOCATION_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_ALLOCATION_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_SIZE_LIMIT = sparkConf.get(YARN_BLACKLIST_SIZE_LIMIT)\n+\n+  private val BLACKLIST_SIZE_DEFAULT_WEIGHT = sparkConf.get(YARN_BLACKLIST_SIZE_DEFAULT_WEIGHT)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklistedNodesWithExpiry = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / BLACKLIST_SIZE_DEFAULT_WEIGHT).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  /**\n+   * Use a different clock. This is mainly used for testing.\n+   */\n+  def setClock(newClock: Clock): Unit = {\n+    clock = newClock\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklistedNodesWithExpiry.contains(hostname) &&\n+          !allocationBlacklistedNodesWithExpiry.contains(hostname)) {\n+          failureWithinTimeIntervalTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureWithinTimeIntervalTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (IS_YARN_ALLOCATION_BLACKLIST_ENABLED) {\n+      val failuresOnHost = failureWithinTimeIntervalTracker.getNumExecutorFailuresOnHost(hostname)\n+      if (failuresOnHost > BLACKLIST_MAX_FAILED_EXEC_PER_NODE) {\n+        logInfo(\"blacklisting host as YARN allocation failed: %s\".format(hostname))"
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "thanks, I will add it",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-18T12:20:51Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_ALLOCATION_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_ALLOCATION_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_SIZE_LIMIT = sparkConf.get(YARN_BLACKLIST_SIZE_LIMIT)\n+\n+  private val BLACKLIST_SIZE_DEFAULT_WEIGHT = sparkConf.get(YARN_BLACKLIST_SIZE_DEFAULT_WEIGHT)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklistedNodesWithExpiry = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / BLACKLIST_SIZE_DEFAULT_WEIGHT).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  /**\n+   * Use a different clock. This is mainly used for testing.\n+   */\n+  def setClock(newClock: Clock): Unit = {\n+    clock = newClock\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklistedNodesWithExpiry.contains(hostname) &&\n+          !allocationBlacklistedNodesWithExpiry.contains(hostname)) {\n+          failureWithinTimeIntervalTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureWithinTimeIntervalTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (IS_YARN_ALLOCATION_BLACKLIST_ENABLED) {\n+      val failuresOnHost = failureWithinTimeIntervalTracker.getNumExecutorFailuresOnHost(hostname)\n+      if (failuresOnHost > BLACKLIST_MAX_FAILED_EXEC_PER_NODE) {\n+        logInfo(\"blacklisting host as YARN allocation failed: %s\".format(hostname))"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "henryr"
    },
    "body": "Do you need to keep a separate data structure for the scheduler and allocator blacklisted nodes? Instead, could you add the scheduler ones into a shared map when `setSchedulerBlacklistedNodes` is called?",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-16T22:51:55Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_ALLOCATION_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_ALLOCATION_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_SIZE_LIMIT = sparkConf.get(YARN_BLACKLIST_SIZE_LIMIT)\n+\n+  private val BLACKLIST_SIZE_DEFAULT_WEIGHT = sparkConf.get(YARN_BLACKLIST_SIZE_DEFAULT_WEIGHT)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklistedNodesWithExpiry = Map.empty[String, Long]"
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "We have to store them separately as we there is these two sources of backlisted nodes and they are updated separately via the two setters where not the diffs but the complete state of the backlisted sets are coming (another reason is only allocator backlisted nodes expiry handled by YarnAllocatorBlacklistTracker). ",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-18T12:29:25Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_ALLOCATION_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_ALLOCATION_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_SIZE_LIMIT = sparkConf.get(YARN_BLACKLIST_SIZE_LIMIT)\n+\n+  private val BLACKLIST_SIZE_DEFAULT_WEIGHT = sparkConf.get(YARN_BLACKLIST_SIZE_DEFAULT_WEIGHT)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklistedNodesWithExpiry = Map.empty[String, Long]"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "The \"all caps\" names are normally used for constants attached to objects... these are more like final fields and using the usual camel case names is preferred. That's also easier to read.",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-25T21:53:37Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS ="
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`launchBlacklistEnabled`.",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-25T21:54:13Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED ="
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`maxFailuresPerHost`?",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-25T21:54:36Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Not sure how to read this one... needs a shorter / simpler name.",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-25T21:55:01Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_MAX_NODE_BLACKLIST_RATIO ="
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Make this a constructor argument. Or get it from the failure tracker since I assume they need to be the same.",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-25T21:55:24Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_MAX_NODE_BLACKLIST_RATIO =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private var clock: Clock = new SystemClock"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You definitely need shorter names for variables... long names just blend together after some time.\r\n\r\ne.g. `allocatorBlacklist`, `schedulerBlacklist` are much easier to read and give you the same semantic information as this long name.",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-25T21:57:51Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_MAX_NODE_BLACKLIST_RATIO =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: more indent",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-25T21:58:21Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_MAX_NODE_BLACKLIST_RATIO =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklistedNodesWithExpiry = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / BLACKLIST_MAX_NODE_BLACKLIST_RATIO).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  /**\n+   * Use a different clock. This is mainly used for testing.\n+   */\n+  def setClock(newClock: Clock): Unit = {\n+    clock = newClock\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklistedNodesWithExpiry.contains(hostname) &&\n+          !allocationBlacklistedNodesWithExpiry.contains(hostname)) {"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This could potentially generate pretty long log messages in bad clusters... perhaps just log the count?",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-25T22:02:29Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_MAX_NODE_BLACKLIST_RATIO =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklistedNodesWithExpiry = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / BLACKLIST_MAX_NODE_BLACKLIST_RATIO).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  /**\n+   * Use a different clock. This is mainly used for testing.\n+   */\n+  def setClock(newClock: Clock): Unit = {\n+    clock = newClock\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklistedNodesWithExpiry.contains(hostname) &&\n+          !allocationBlacklistedNodesWithExpiry.contains(hostname)) {\n+          failureWithinTimeIntervalTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureWithinTimeIntervalTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED) {\n+      val failuresOnHost = failureWithinTimeIntervalTracker.getNumExecutorFailuresOnHost(hostname)\n+      if (failuresOnHost > BLACKLIST_MAX_FAILED_EXEC_PER_NODE) {\n+        logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")\n+        allocationBlacklistedNodesWithExpiry.put(\n+          hostname,\n+          clock.getTimeMillis() + BLACKLIST_TIMEOUT_MILLIS)\n+        refreshBlacklistedNodes()\n+      }\n+    }\n+  }\n+\n+  def setSchedulerBlacklistedNodes(schedulerBlacklistedNodesWithExpiry: Map[String, Long]): Unit = {\n+    this.schedulerBlacklistedNodesWithExpiry = schedulerBlacklistedNodesWithExpiry\n+    refreshBlacklistedNodes()\n+  }\n+\n+  private def refreshBlacklistedNodes(): Unit = {\n+    removeExpiredYarnBlacklistedNodes()\n+    val limit = (numClusterNodes * BLACKLIST_MAX_NODE_BLACKLIST_RATIO).toInt\n+    val nodesToBlacklist =\n+      if (schedulerBlacklistedNodesWithExpiry.size +\n+          allocationBlacklistedNodesWithExpiry.size > limit) {\n+        mostRelevantSubsetOfBlacklistedNodes(limit)\n+      } else {\n+        schedulerBlacklistedNodesWithExpiry.keySet ++ allocationBlacklistedNodesWithExpiry.keySet\n+      }\n+\n+    synchronizeBlacklistedNodeWithYarn(nodesToBlacklist)\n+  }\n+\n+  private def mostRelevantSubsetOfBlacklistedNodes(limit: Int) = {\n+    val relevant =\n+      (schedulerBlacklistedNodesWithExpiry ++ allocationBlacklistedNodesWithExpiry).toSeq\n+      .sortBy(_._2)(Ordering[Long].reverse)\n+      .take(limit)\n+      .map(_._1)\n+      .toSet\n+    logInfo(s\"blacklist size limit ($limit) is reached, the most relevant subset is: $relevant\")"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`additions`, `removals` are just as good names for these variables.",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-25T22:03:24Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_MAX_NODE_BLACKLIST_RATIO =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklistedNodesWithExpiry = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / BLACKLIST_MAX_NODE_BLACKLIST_RATIO).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  /**\n+   * Use a different clock. This is mainly used for testing.\n+   */\n+  def setClock(newClock: Clock): Unit = {\n+    clock = newClock\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklistedNodesWithExpiry.contains(hostname) &&\n+          !allocationBlacklistedNodesWithExpiry.contains(hostname)) {\n+          failureWithinTimeIntervalTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureWithinTimeIntervalTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED) {\n+      val failuresOnHost = failureWithinTimeIntervalTracker.getNumExecutorFailuresOnHost(hostname)\n+      if (failuresOnHost > BLACKLIST_MAX_FAILED_EXEC_PER_NODE) {\n+        logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")\n+        allocationBlacklistedNodesWithExpiry.put(\n+          hostname,\n+          clock.getTimeMillis() + BLACKLIST_TIMEOUT_MILLIS)\n+        refreshBlacklistedNodes()\n+      }\n+    }\n+  }\n+\n+  def setSchedulerBlacklistedNodes(schedulerBlacklistedNodesWithExpiry: Map[String, Long]): Unit = {\n+    this.schedulerBlacklistedNodesWithExpiry = schedulerBlacklistedNodesWithExpiry\n+    refreshBlacklistedNodes()\n+  }\n+\n+  private def refreshBlacklistedNodes(): Unit = {\n+    removeExpiredYarnBlacklistedNodes()\n+    val limit = (numClusterNodes * BLACKLIST_MAX_NODE_BLACKLIST_RATIO).toInt\n+    val nodesToBlacklist =\n+      if (schedulerBlacklistedNodesWithExpiry.size +\n+          allocationBlacklistedNodesWithExpiry.size > limit) {\n+        mostRelevantSubsetOfBlacklistedNodes(limit)\n+      } else {\n+        schedulerBlacklistedNodesWithExpiry.keySet ++ allocationBlacklistedNodesWithExpiry.keySet\n+      }\n+\n+    synchronizeBlacklistedNodeWithYarn(nodesToBlacklist)\n+  }\n+\n+  private def mostRelevantSubsetOfBlacklistedNodes(limit: Int) = {\n+    val relevant =\n+      (schedulerBlacklistedNodesWithExpiry ++ allocationBlacklistedNodesWithExpiry).toSeq\n+      .sortBy(_._2)(Ordering[Long].reverse)\n+      .take(limit)\n+      .map(_._1)\n+      .toSet\n+    logInfo(s\"blacklist size limit ($limit) is reached, the most relevant subset is: $relevant\")\n+    relevant\n+  }\n+\n+  private def synchronizeBlacklistedNodeWithYarn(nodesToBlacklist: Set[String]): Unit = {\n+    // Update blacklist information to YARN ResourceManager for this application,\n+    // in order to avoid allocating new Containers on the problematic nodes.\n+    val blacklistAdditions = (nodesToBlacklist -- currentBlacklistedYarnNodes).toList.sorted"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Doesn't this work?\r\n\r\n```\r\nallocationBlacklistedNodesWithExpiry.retain { case (_, expiry) =>\r\n  ...\r\n}\r\n```\r\n",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-25T22:04:15Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureWithinTimeIntervalTracker: FailureWithinTimeIntervalTracker)\n+  extends Logging {\n+\n+  private val DEFAULT_TIMEOUT = \"1h\"\n+\n+  private val BLACKLIST_TIMEOUT_MILLIS =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(DEFAULT_TIMEOUT))\n+\n+  private val IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val BLACKLIST_MAX_FAILED_EXEC_PER_NODE = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val BLACKLIST_MAX_NODE_BLACKLIST_RATIO =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private var clock: Clock = new SystemClock\n+\n+  private val allocationBlacklistedNodesWithExpiry = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklistedNodesWithExpiry = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / BLACKLIST_MAX_NODE_BLACKLIST_RATIO).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  /**\n+   * Use a different clock. This is mainly used for testing.\n+   */\n+  def setClock(newClock: Clock): Unit = {\n+    clock = newClock\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklistedNodesWithExpiry.contains(hostname) &&\n+          !allocationBlacklistedNodesWithExpiry.contains(hostname)) {\n+          failureWithinTimeIntervalTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureWithinTimeIntervalTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (IS_YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED) {\n+      val failuresOnHost = failureWithinTimeIntervalTracker.getNumExecutorFailuresOnHost(hostname)\n+      if (failuresOnHost > BLACKLIST_MAX_FAILED_EXEC_PER_NODE) {\n+        logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")\n+        allocationBlacklistedNodesWithExpiry.put(\n+          hostname,\n+          clock.getTimeMillis() + BLACKLIST_TIMEOUT_MILLIS)\n+        refreshBlacklistedNodes()\n+      }\n+    }\n+  }\n+\n+  def setSchedulerBlacklistedNodes(schedulerBlacklistedNodesWithExpiry: Map[String, Long]): Unit = {\n+    this.schedulerBlacklistedNodesWithExpiry = schedulerBlacklistedNodesWithExpiry\n+    refreshBlacklistedNodes()\n+  }\n+\n+  private def refreshBlacklistedNodes(): Unit = {\n+    removeExpiredYarnBlacklistedNodes()\n+    val limit = (numClusterNodes * BLACKLIST_MAX_NODE_BLACKLIST_RATIO).toInt\n+    val nodesToBlacklist =\n+      if (schedulerBlacklistedNodesWithExpiry.size +\n+          allocationBlacklistedNodesWithExpiry.size > limit) {\n+        mostRelevantSubsetOfBlacklistedNodes(limit)\n+      } else {\n+        schedulerBlacklistedNodesWithExpiry.keySet ++ allocationBlacklistedNodesWithExpiry.keySet\n+      }\n+\n+    synchronizeBlacklistedNodeWithYarn(nodesToBlacklist)\n+  }\n+\n+  private def mostRelevantSubsetOfBlacklistedNodes(limit: Int) = {\n+    val relevant =\n+      (schedulerBlacklistedNodesWithExpiry ++ allocationBlacklistedNodesWithExpiry).toSeq\n+      .sortBy(_._2)(Ordering[Long].reverse)\n+      .take(limit)\n+      .map(_._1)\n+      .toSet\n+    logInfo(s\"blacklist size limit ($limit) is reached, the most relevant subset is: $relevant\")\n+    relevant\n+  }\n+\n+  private def synchronizeBlacklistedNodeWithYarn(nodesToBlacklist: Set[String]): Unit = {\n+    // Update blacklist information to YARN ResourceManager for this application,\n+    // in order to avoid allocating new Containers on the problematic nodes.\n+    val blacklistAdditions = (nodesToBlacklist -- currentBlacklistedYarnNodes).toList.sorted\n+    val blacklistRemovals = (currentBlacklistedYarnNodes -- nodesToBlacklist).toList.sorted\n+    if (blacklistAdditions.nonEmpty) {\n+      logInfo(s\"adding nodes to YARN application master's blacklist: $blacklistAdditions\")\n+    }\n+    if (blacklistRemovals.nonEmpty) {\n+      logInfo(s\"removing nodes from YARN application master's blacklist: $blacklistRemovals\")\n+    }\n+    amClient.updateBlacklist(blacklistAdditions.asJava, blacklistRemovals.asJava)\n+    currentBlacklistedYarnNodes = nodesToBlacklist\n+  }\n+\n+  private def removeExpiredYarnBlacklistedNodes() = {\n+    val now = clock.getTimeMillis()\n+    allocationBlacklistedNodesWithExpiry.retain {"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: remove line",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-30T21:05:55Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing these node list to YARN.\n+ *"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "s/these/the",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-30T21:06:12Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing these node list to YARN."
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: move this to previous line",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-30T21:07:12Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing these node list to YARN.\n+ *\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(defaultTimeout))\n+\n+  private val launchBlacklistEnabled =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val blacklistMaxNodeRatio =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / blacklistMaxNodeRatio).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (launchBlacklistEnabled) {\n+      val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+      if (failuresOnHost > maxFailuresPerHost) {\n+        logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")\n+        allocatorBlacklist.put(\n+          hostname,\n+          failureTracker.clock.getTimeMillis() + blacklistTimeoutMillis)\n+        refreshBlacklistedNodes()\n+      }\n+    }\n+  }\n+\n+  def setSchedulerBlacklistedNodes(schedulerBlacklistedNodesWithExpiry: Map[String, Long]): Unit = {\n+    this.schedulerBlacklist = schedulerBlacklistedNodesWithExpiry\n+    refreshBlacklistedNodes()\n+  }\n+\n+  private def refreshBlacklistedNodes(): Unit = {\n+    removeExpiredYarnBlacklistedNodes()\n+    val limit = (numClusterNodes * blacklistMaxNodeRatio).toInt\n+    val nodesToBlacklist =\n+      if (schedulerBlacklist.size +\n+          allocatorBlacklist.size > limit) {\n+        mostRelevantSubsetOfBlacklistedNodes(limit)\n+      } else {\n+        schedulerBlacklist.keySet ++ allocatorBlacklist.keySet\n+      }\n+\n+    synchronizeBlacklistedNodeWithYarn(nodesToBlacklist)\n+  }\n+\n+  private def mostRelevantSubsetOfBlacklistedNodes(limit: Int) = {\n+    val allBlacklist = schedulerBlacklist ++ allocatorBlacklist\n+    val relevant =\n+      allBlacklist.toSeq"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`: Unit =`",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-30T21:08:21Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing these node list to YARN.\n+ *\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(defaultTimeout))\n+\n+  private val launchBlacklistEnabled =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val blacklistMaxNodeRatio =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / blacklistMaxNodeRatio).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (launchBlacklistEnabled) {\n+      val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+      if (failuresOnHost > maxFailuresPerHost) {\n+        logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")\n+        allocatorBlacklist.put(\n+          hostname,\n+          failureTracker.clock.getTimeMillis() + blacklistTimeoutMillis)\n+        refreshBlacklistedNodes()\n+      }\n+    }\n+  }\n+\n+  def setSchedulerBlacklistedNodes(schedulerBlacklistedNodesWithExpiry: Map[String, Long]): Unit = {\n+    this.schedulerBlacklist = schedulerBlacklistedNodesWithExpiry\n+    refreshBlacklistedNodes()\n+  }\n+\n+  private def refreshBlacklistedNodes(): Unit = {\n+    removeExpiredYarnBlacklistedNodes()\n+    val limit = (numClusterNodes * blacklistMaxNodeRatio).toInt\n+    val nodesToBlacklist =\n+      if (schedulerBlacklist.size +\n+          allocatorBlacklist.size > limit) {\n+        mostRelevantSubsetOfBlacklistedNodes(limit)\n+      } else {\n+        schedulerBlacklist.keySet ++ allocatorBlacklist.keySet\n+      }\n+\n+    synchronizeBlacklistedNodeWithYarn(nodesToBlacklist)\n+  }\n+\n+  private def mostRelevantSubsetOfBlacklistedNodes(limit: Int) = {\n+    val allBlacklist = schedulerBlacklist ++ allocatorBlacklist\n+    val relevant =\n+      allBlacklist.toSeq\n+      .sortBy(_._2)(Ordering[Long].reverse)\n+      .take(limit)\n+      .map(_._1)\n+      .toSet\n+    logInfo(s\"blacklist size limit ($limit) is reached, total count: ${allBlacklist.size}\")\n+    relevant\n+  }\n+\n+  private def synchronizeBlacklistedNodeWithYarn(nodesToBlacklist: Set[String]): Unit = {\n+    // Update blacklist information to YARN ResourceManager for this application,\n+    // in order to avoid allocating new Containers on the problematic nodes.\n+    val additions = (nodesToBlacklist -- currentBlacklistedYarnNodes).toList.sorted\n+    val removals = (currentBlacklistedYarnNodes -- nodesToBlacklist).toList.sorted\n+    if (additions.nonEmpty) {\n+      logInfo(s\"adding nodes to YARN application master's blacklist: $additions\")\n+    }\n+    if (removals.nonEmpty) {\n+      logInfo(s\"removing nodes from YARN application master's blacklist: $removals\")\n+    }\n+    amClient.updateBlacklist(additions.asJava, removals.asJava)\n+    currentBlacklistedYarnNodes = nodesToBlacklist\n+  }\n+\n+  private def removeExpiredYarnBlacklistedNodes() = {"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "block fits in one line",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-30T21:09:02Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing these node list to YARN.\n+ *\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(defaultTimeout))\n+\n+  private val launchBlacklistEnabled =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val blacklistMaxNodeRatio =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / blacklistMaxNodeRatio).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (launchBlacklistEnabled) {\n+      val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+      if (failuresOnHost > maxFailuresPerHost) {\n+        logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")\n+        allocatorBlacklist.put(\n+          hostname,\n+          failureTracker.clock.getTimeMillis() + blacklistTimeoutMillis)\n+        refreshBlacklistedNodes()\n+      }\n+    }\n+  }\n+\n+  def setSchedulerBlacklistedNodes(schedulerBlacklistedNodesWithExpiry: Map[String, Long]): Unit = {\n+    this.schedulerBlacklist = schedulerBlacklistedNodesWithExpiry\n+    refreshBlacklistedNodes()\n+  }\n+\n+  private def refreshBlacklistedNodes(): Unit = {\n+    removeExpiredYarnBlacklistedNodes()\n+    val limit = (numClusterNodes * blacklistMaxNodeRatio).toInt\n+    val nodesToBlacklist =\n+      if (schedulerBlacklist.size +\n+          allocatorBlacklist.size > limit) {\n+        mostRelevantSubsetOfBlacklistedNodes(limit)\n+      } else {\n+        schedulerBlacklist.keySet ++ allocatorBlacklist.keySet\n+      }\n+\n+    synchronizeBlacklistedNodeWithYarn(nodesToBlacklist)\n+  }\n+\n+  private def mostRelevantSubsetOfBlacklistedNodes(limit: Int) = {\n+    val allBlacklist = schedulerBlacklist ++ allocatorBlacklist\n+    val relevant =\n+      allBlacklist.toSeq\n+      .sortBy(_._2)(Ordering[Long].reverse)\n+      .take(limit)\n+      .map(_._1)\n+      .toSet\n+    logInfo(s\"blacklist size limit ($limit) is reached, total count: ${allBlacklist.size}\")\n+    relevant\n+  }\n+\n+  private def synchronizeBlacklistedNodeWithYarn(nodesToBlacklist: Set[String]): Unit = {\n+    // Update blacklist information to YARN ResourceManager for this application,\n+    // in order to avoid allocating new Containers on the problematic nodes.\n+    val additions = (nodesToBlacklist -- currentBlacklistedYarnNodes).toList.sorted\n+    val removals = (currentBlacklistedYarnNodes -- nodesToBlacklist).toList.sorted\n+    if (additions.nonEmpty) {\n+      logInfo(s\"adding nodes to YARN application master's blacklist: $additions\")\n+    }\n+    if (removals.nonEmpty) {\n+      logInfo(s\"removing nodes from YARN application master's blacklist: $removals\")\n+    }\n+    amClient.updateBlacklist(additions.asJava, removals.asJava)\n+    currentBlacklistedYarnNodes = nodesToBlacklist\n+  }\n+\n+  private def removeExpiredYarnBlacklistedNodes() = {\n+    val now = failureTracker.clock.getTimeMillis()\n+    allocatorBlacklist.retain {"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "From the code and comment, it's a bit unclear what happens when blacklisting is disabled. Will you miss the failure and potentially keep the app running when in fact it should be killed?\r\n\r\nShould the matches be instead:\r\n\r\n```\r\ncase Some(hostname) if launchBlacklistEnabled =>\r\ncase _ =>\r\n```\r\n",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-30T21:12:41Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing these node list to YARN.\n+ *\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(defaultTimeout))\n+\n+  private val launchBlacklistEnabled =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val blacklistMaxNodeRatio =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / blacklistMaxNodeRatio).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)",
    "line": 80
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "Good catch, thanks. \r\n",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-05-02T09:32:39Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing these node list to YARN.\n+ *\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(defaultTimeout))\n+\n+  private val launchBlacklistEnabled =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val blacklistMaxNodeRatio =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / blacklistMaxNodeRatio).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)",
    "line": 80
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Are the two blacklists guaranteed to not contain duplicates?\r\n\r\n`handleResourceAllocationFailure` seems to avoid that, but it seems it's possible to update the scheduler blacklist with a new one that contains hosts already on the allocator list?",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-04-30T21:17:53Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing these node list to YARN.\n+ *\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(defaultTimeout))\n+\n+  private val launchBlacklistEnabled =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val blacklistMaxNodeRatio =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / blacklistMaxNodeRatio).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (launchBlacklistEnabled) {\n+      val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+      if (failuresOnHost > maxFailuresPerHost) {\n+        logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")\n+        allocatorBlacklist.put(\n+          hostname,\n+          failureTracker.clock.getTimeMillis() + blacklistTimeoutMillis)\n+        refreshBlacklistedNodes()\n+      }\n+    }\n+  }\n+\n+  def setSchedulerBlacklistedNodes(schedulerBlacklistedNodesWithExpiry: Map[String, Long]): Unit = {\n+    this.schedulerBlacklist = schedulerBlacklistedNodesWithExpiry\n+    refreshBlacklistedNodes()\n+  }\n+\n+  private def refreshBlacklistedNodes(): Unit = {\n+    removeExpiredYarnBlacklistedNodes()\n+    val limit = (numClusterNodes * blacklistMaxNodeRatio).toInt\n+    val nodesToBlacklist =\n+      if (schedulerBlacklist.size +"
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "It can be so to be in the safe side I extract `schedulerBlacklist.keySet ++ allocatorBlacklist.keySet` into a val and use the size of this merged set. ",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-05-02T09:37:39Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing these node list to YARN.\n+ *\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(defaultTimeout))\n+\n+  private val launchBlacklistEnabled =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val blacklistMaxNodeRatio =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / blacklistMaxNodeRatio).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case None =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    if (launchBlacklistEnabled) {\n+      val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+      if (failuresOnHost > maxFailuresPerHost) {\n+        logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")\n+        allocatorBlacklist.put(\n+          hostname,\n+          failureTracker.clock.getTimeMillis() + blacklistTimeoutMillis)\n+        refreshBlacklistedNodes()\n+      }\n+    }\n+  }\n+\n+  def setSchedulerBlacklistedNodes(schedulerBlacklistedNodesWithExpiry: Map[String, Long]): Unit = {\n+    this.schedulerBlacklist = schedulerBlacklistedNodesWithExpiry\n+    refreshBlacklistedNodes()\n+  }\n+\n+  private def refreshBlacklistedNodes(): Unit = {\n+    removeExpiredYarnBlacklistedNodes()\n+    val limit = (numClusterNodes * blacklistMaxNodeRatio).toInt\n+    val nodesToBlacklist =\n+      if (schedulerBlacklist.size +"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "grammar super nits:\r\n\r\n        // failures on an already blacklisted nodes are not even tracked.\r\n        // otherwise, such failures could shutdown the application\r\n        // as resource requests are asynchronous\r\n        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\r\n ",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-05-02T15:12:47Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(defaultTimeout))\n+\n+  private val launchBlacklistEnabled =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val blacklistMaxNodeRatio =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / blacklistMaxNodeRatio).toInt\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) if launchBlacklistEnabled =>\n+        // failures on a already blacklisted nodes are not even tracked\n+        // otherwise such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "You're really just initializing to `Int.MaxValue`, since blacklistMaxNodeRatio < 1.",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-05-02T15:43:03Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(defaultTimeout))\n+\n+  private val launchBlacklistEnabled =\n+    sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED).getOrElse(false)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val blacklistMaxNodeRatio =\n+    sparkConf.get(YARN_BLACKLIST_MAX_NODE_BLACKLIST_RATIO)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Map.empty[String, Long]\n+\n+  private var numClusterNodes = (Int.MaxValue / blacklistMaxNodeRatio).toInt"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "this class should have a comment explaining the two sources of blacklisting & why allocation blacklisting is handled here, not the driver.",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-05-02T15:44:16Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.",
    "line": 35
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "`BlacklistTracker.getBlacklistTimeout(conf)`",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-14T15:28:55Z",
    "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ *\n+ * Blacklisted nodes are coming from two different sources:\n+ *\n+ * <ul>\n+ *   <li> from the scheduler as task level blacklisted nodes\n+ *   <li> from this class (tracked here) as YARN resource allocation problems\n+ * </ul>\n+ *\n+ * The reason to realize this logic here (and not in the driver) is to avoid possible delays\n+ * between synchronizing the blacklisted nodes with YARN and resource allocations.\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis ="
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "Ok then I relax a bit on the visibility of BlacklistTracker by changing it from private[scheduler] to private[spark].",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-14T15:51:28Z",
    "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ *\n+ * Blacklisted nodes are coming from two different sources:\n+ *\n+ * <ul>\n+ *   <li> from the scheduler as task level blacklisted nodes\n+ *   <li> from this class (tracked here) as YARN resource allocation problems\n+ * </ul>\n+ *\n+ * The reason to realize this logic here (and not in the driver) is to avoid possible delays\n+ * between synchronizing the blacklisted nodes with YARN and resource allocations.\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis ="
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "double indent the condition",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-14T15:32:17Z",
    "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ *\n+ * Blacklisted nodes are coming from two different sources:\n+ *\n+ * <ul>\n+ *   <li> from the scheduler as task level blacklisted nodes\n+ *   <li> from this class (tracked here) as YARN resource allocation problems\n+ * </ul>\n+ *\n+ * The reason to realize this logic here (and not in the driver) is to avoid possible delays\n+ * between synchronizing the blacklisted nodes with YARN and resource allocations.\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val defaultTimeout = \"1h\"\n+\n+  private val blacklistTimeoutMillis =\n+    sparkConf.get(BLACKLIST_TIMEOUT_CONF).getOrElse(Utils.timeStringAsMs(defaultTimeout))\n+\n+  private val launchBlacklistEnabled = sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Set.empty[String]\n+\n+  private var numClusterNodes = Int.MaxValue\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) if launchBlacklistEnabled =>\n+        // failures on an already blacklisted nodes are not even tracked.\n+        // otherwise, such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case _ =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+    if (failuresOnHost > maxFailuresPerHost) {\n+      logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")\n+      allocatorBlacklist.put(\n+        hostname,\n+        failureTracker.clock.getTimeMillis() + blacklistTimeoutMillis)\n+      refreshBlacklistedNodes()\n+    }\n+  }\n+\n+  def setSchedulerBlacklistedNodes(schedulerBlacklistedNodesWithExpiry: Set[String]): Unit = {\n+    this.schedulerBlacklist = schedulerBlacklistedNodesWithExpiry\n+    refreshBlacklistedNodes()\n+  }\n+\n+  def isAllNodeBlacklisted: Boolean = currentBlacklistedYarnNodes.size >= numClusterNodes\n+\n+  private def refreshBlacklistedNodes(): Unit = {\n+    removeExpiredYarnBlacklistedNodes()\n+    val allBlacklistedNodes = schedulerBlacklist ++ allocatorBlacklist.keySet\n+    synchronizeBlacklistedNodeWithYarn(allBlacklistedNodes)\n+  }\n+\n+  private def synchronizeBlacklistedNodeWithYarn(nodesToBlacklist: Set[String]): Unit = {\n+    // Update blacklist information to YARN ResourceManager for this application,\n+    // in order to avoid allocating new Containers on the problematic nodes.\n+    val additions = (nodesToBlacklist -- currentBlacklistedYarnNodes).toList.sorted\n+    val removals = (currentBlacklistedYarnNodes -- nodesToBlacklist).toList.sorted\n+    if (additions.nonEmpty) {\n+      logInfo(s\"adding nodes to YARN application master's blacklist: $additions\")\n+    }\n+    if (removals.nonEmpty) {\n+      logInfo(s\"removing nodes from YARN application master's blacklist: $removals\")\n+    }\n+    amClient.updateBlacklist(additions.asJava, removals.asJava)\n+    currentBlacklistedYarnNodes = nodesToBlacklist\n+  }\n+\n+  private def removeExpiredYarnBlacklistedNodes(): Unit = {\n+    val now = failureTracker.clock.getTimeMillis()\n+    allocatorBlacklist.retain { (_, expiryTime) => expiryTime > now }\n+  }\n+}\n+\n+/**\n+ * FailureTracker is responsible for tracking executor failures both for each host separately\n+ * and for all hosts altogether.\n+ */\n+private[spark] class FailureTracker(\n+    sparkConf: SparkConf,\n+    val clock: Clock = new SystemClock) extends Logging {\n+\n+  private val executorFailuresValidityInterval =\n+    sparkConf.get(config.EXECUTOR_ATTEMPT_FAILURE_VALIDITY_INTERVAL_MS).getOrElse(-1L)\n+\n+  // Queue to store the timestamp of failed executors for each host\n+  private val failedExecutorsTimeStampsPerHost = mutable.Map[String, mutable.Queue[Long]]()\n+\n+  private val failedExecutorsTimeStamps = new mutable.Queue[Long]()\n+\n+  private def updateAndCountFailures(failedExecutorsWithTimeStamps: mutable.Queue[Long]): Int = {\n+    val endTime = clock.getTimeMillis()\n+    while (executorFailuresValidityInterval > 0 &&\n+      failedExecutorsWithTimeStamps.nonEmpty &&\n+      failedExecutorsWithTimeStamps.head < endTime - executorFailuresValidityInterval) {"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "but only single indent the body of the `while`",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-14T20:49:34Z",
    "diffHunk": "@@ -151,9 +149,9 @@ private[spark] class FailureTracker(\n   private def updateAndCountFailures(failedExecutorsWithTimeStamps: mutable.Queue[Long]): Int = {\n     val endTime = clock.getTimeMillis()\n     while (executorFailuresValidityInterval > 0 &&\n-      failedExecutorsWithTimeStamps.nonEmpty &&\n-      failedExecutorsWithTimeStamps.head < endTime - executorFailuresValidityInterval) {\n-      failedExecutorsWithTimeStamps.dequeue()\n+        failedExecutorsWithTimeStamps.nonEmpty &&\n+        failedExecutorsWithTimeStamps.head < endTime - executorFailuresValidityInterval) {\n+        failedExecutorsWithTimeStamps.dequeue()"
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "This source never touches the scheduler's blacklist right?",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-15T14:05:09Z",
    "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.scheduler.BlacklistTracker\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ *\n+ * Blacklisted nodes are coming from two different sources:\n+ *\n+ * <ul>\n+ *   <li> from the scheduler as task level blacklisted nodes\n+ *   <li> from this class (tracked here) as YARN resource allocation problems",
    "line": 41
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "Right. Just the other way around: the scheduler's blacklisted hosts will be sent here for forwarding them to YARN. This way at the resource allocation they will be taken into account.  ",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-15T14:19:07Z",
    "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.scheduler.BlacklistTracker\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ *\n+ * Blacklisted nodes are coming from two different sources:\n+ *\n+ * <ul>\n+ *   <li> from the scheduler as task level blacklisted nodes\n+ *   <li> from this class (tracked here) as YARN resource allocation problems",
    "line": 41
  }],
  "prId": 21068
}, {
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "maybe logWarn?",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-16T07:15:51Z",
    "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.scheduler.BlacklistTracker\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ *\n+ * Blacklisted nodes are coming from two different sources:\n+ *\n+ * <ul>\n+ *   <li> from the scheduler as task level blacklisted nodes\n+ *   <li> from this class (tracked here) as YARN resource allocation problems\n+ * </ul>\n+ *\n+ * The reason to realize this logic here (and not in the driver) is to avoid possible delays\n+ * between synchronizing the blacklisted nodes with YARN and resource allocations.\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val blacklistTimeoutMillis = BlacklistTracker.getBlacklistTimeout(sparkConf)\n+\n+  private val launchBlacklistEnabled = sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Set.empty[String]\n+\n+  private var numClusterNodes = Int.MaxValue\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) if launchBlacklistEnabled =>\n+        // failures on an already blacklisted nodes are not even tracked.\n+        // otherwise, such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case _ =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+    if (failuresOnHost > maxFailuresPerHost) {\n+      logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")",
    "line": 91
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "would be great if there is a metric on failuresOnHost count...",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-16T07:17:30Z",
    "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.scheduler.BlacklistTracker\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ *\n+ * Blacklisted nodes are coming from two different sources:\n+ *\n+ * <ul>\n+ *   <li> from the scheduler as task level blacklisted nodes\n+ *   <li> from this class (tracked here) as YARN resource allocation problems\n+ * </ul>\n+ *\n+ * The reason to realize this logic here (and not in the driver) is to avoid possible delays\n+ * between synchronizing the blacklisted nodes with YARN and resource allocations.\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val blacklistTimeoutMillis = BlacklistTracker.getBlacklistTimeout(sparkConf)\n+\n+  private val launchBlacklistEnabled = sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Set.empty[String]\n+\n+  private var numClusterNodes = Int.MaxValue\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) if launchBlacklistEnabled =>\n+        // failures on an already blacklisted nodes are not even tracked.\n+        // otherwise, such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case _ =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+    if (failuresOnHost > maxFailuresPerHost) {\n+      logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")",
    "line": 91
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "Thanks, I am happy you consider this change useful.\r\n\r\nRegarding logInfo I have chosen that to be consistent with the logging of the existing BlacklistTracker where blacklisting itself is taken as a part of the normal behaviour and logInfo is used. But if you have a strong feeling about logWarn I can do the change. \r\n\r\nFor the metrics I've done some quick search in the yarn module and it seems to me currently no metrics are coming from there so the change probably is not just a few lines. What about me creating a new jira task for it? Is that fine for you?  ",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-17T09:07:55Z",
    "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.scheduler.BlacklistTracker\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ *\n+ * Blacklisted nodes are coming from two different sources:\n+ *\n+ * <ul>\n+ *   <li> from the scheduler as task level blacklisted nodes\n+ *   <li> from this class (tracked here) as YARN resource allocation problems\n+ * </ul>\n+ *\n+ * The reason to realize this logic here (and not in the driver) is to avoid possible delays\n+ * between synchronizing the blacklisted nodes with YARN and resource allocations.\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val blacklistTimeoutMillis = BlacklistTracker.getBlacklistTimeout(sparkConf)\n+\n+  private val launchBlacklistEnabled = sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Set.empty[String]\n+\n+  private var numClusterNodes = Int.MaxValue\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) if launchBlacklistEnabled =>\n+        // failures on an already blacklisted nodes are not even tracked.\n+        // otherwise, such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case _ =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+    if (failuresOnHost > maxFailuresPerHost) {\n+      logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")",
    "line": 91
  }, {
    "author": {
      "login": "squito"
    },
    "body": "yes, exposing metrics is not a bad idea, but I'd like to leave it out of this change",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-18T18:52:51Z",
    "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.scheduler.BlacklistTracker\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ *\n+ * Blacklisted nodes are coming from two different sources:\n+ *\n+ * <ul>\n+ *   <li> from the scheduler as task level blacklisted nodes\n+ *   <li> from this class (tracked here) as YARN resource allocation problems\n+ * </ul>\n+ *\n+ * The reason to realize this logic here (and not in the driver) is to avoid possible delays\n+ * between synchronizing the blacklisted nodes with YARN and resource allocations.\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val blacklistTimeoutMillis = BlacklistTracker.getBlacklistTimeout(sparkConf)\n+\n+  private val launchBlacklistEnabled = sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Set.empty[String]\n+\n+  private var numClusterNodes = Int.MaxValue\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) if launchBlacklistEnabled =>\n+        // failures on an already blacklisted nodes are not even tracked.\n+        // otherwise, such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case _ =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+    if (failuresOnHost > maxFailuresPerHost) {\n+      logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")",
    "line": 91
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "@felixcheung I have started to gain some experience about metrics (as I worked on [SPARK-24594](https://issues.apache.org/jira/browse/SPARK-24594)) and it seems to me the structure of the metrics (the metric names) should be known and registered before starting the metric systems. So I can add a new metric for ALL the failures, but not for each hosts separately, like with console sink:\r\n```\r\n-- Gauges ----------------------------------------------------------------------\r\nyarn_cluster.executorFailures.ALL\r\n             value = 3\r\n```\r\nAggregated values would be also possible. Any idea what would be the most valuable for Spark users besides this restriction? \r\n\r\n",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-22T13:24:48Z",
    "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.scheduler.BlacklistTracker\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ *\n+ * Blacklisted nodes are coming from two different sources:\n+ *\n+ * <ul>\n+ *   <li> from the scheduler as task level blacklisted nodes\n+ *   <li> from this class (tracked here) as YARN resource allocation problems\n+ * </ul>\n+ *\n+ * The reason to realize this logic here (and not in the driver) is to avoid possible delays\n+ * between synchronizing the blacklisted nodes with YARN and resource allocations.\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val blacklistTimeoutMillis = BlacklistTracker.getBlacklistTimeout(sparkConf)\n+\n+  private val launchBlacklistEnabled = sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Set.empty[String]\n+\n+  private var numClusterNodes = Int.MaxValue\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) if launchBlacklistEnabled =>\n+        // failures on an already blacklisted nodes are not even tracked.\n+        // otherwise, such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case _ =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+    if (failuresOnHost > maxFailuresPerHost) {\n+      logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")",
    "line": 91
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "I was thinking a bit more about this problem and I have an idea:  creating metrics for the number of hosts with a predetermined number of executor failures. Like yarn_cluster.numHostWithExecutorFailures.x where x is [1 , ... max (10, spark.blacklist.application.maxFailedExecutorsPerNode if backlisting enable, spark.yarn.max.executor.failures if set)]. What is your opinion? \r\n",
    "commit": "f71c7c547f173c902eec101d510c87d50c7abb86",
    "createdAt": "2018-06-22T13:43:36Z",
    "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.hadoop.yarn.client.api.AMRMClient\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.yarn.config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.scheduler.BlacklistTracker\n+import org.apache.spark.util.{Clock, SystemClock, Utils}\n+\n+/**\n+ * YarnAllocatorBlacklistTracker is responsible for tracking the blacklisted nodes\n+ * and synchronizing the node list to YARN.\n+ *\n+ * Blacklisted nodes are coming from two different sources:\n+ *\n+ * <ul>\n+ *   <li> from the scheduler as task level blacklisted nodes\n+ *   <li> from this class (tracked here) as YARN resource allocation problems\n+ * </ul>\n+ *\n+ * The reason to realize this logic here (and not in the driver) is to avoid possible delays\n+ * between synchronizing the blacklisted nodes with YARN and resource allocations.\n+ */\n+private[spark] class YarnAllocatorBlacklistTracker(\n+    sparkConf: SparkConf,\n+    amClient: AMRMClient[ContainerRequest],\n+    failureTracker: FailureTracker)\n+  extends Logging {\n+\n+  private val blacklistTimeoutMillis = BlacklistTracker.getBlacklistTimeout(sparkConf)\n+\n+  private val launchBlacklistEnabled = sparkConf.get(YARN_EXECUTOR_LAUNCH_BLACKLIST_ENABLED)\n+\n+  private val maxFailuresPerHost = sparkConf.get(MAX_FAILED_EXEC_PER_NODE)\n+\n+  private val allocatorBlacklist = new HashMap[String, Long]()\n+\n+  private var currentBlacklistedYarnNodes = Set.empty[String]\n+\n+  private var schedulerBlacklist = Set.empty[String]\n+\n+  private var numClusterNodes = Int.MaxValue\n+\n+  def setNumClusterNodes(numClusterNodes: Int): Unit = {\n+    this.numClusterNodes = numClusterNodes\n+  }\n+\n+  def handleResourceAllocationFailure(hostOpt: Option[String]): Unit = {\n+    hostOpt match {\n+      case Some(hostname) if launchBlacklistEnabled =>\n+        // failures on an already blacklisted nodes are not even tracked.\n+        // otherwise, such failures could shutdown the application\n+        // as resource requests are asynchronous\n+        // and a late failure response could exceed MAX_EXECUTOR_FAILURES\n+        if (!schedulerBlacklist.contains(hostname) &&\n+            !allocatorBlacklist.contains(hostname)) {\n+          failureTracker.registerFailureOnHost(hostname)\n+          updateAllocationBlacklistedNodes(hostname)\n+        }\n+      case _ =>\n+        failureTracker.registerExecutorFailure()\n+    }\n+  }\n+\n+  private def updateAllocationBlacklistedNodes(hostname: String): Unit = {\n+    val failuresOnHost = failureTracker.numFailuresOnHost(hostname)\n+    if (failuresOnHost > maxFailuresPerHost) {\n+      logInfo(s\"blacklisting $hostname as YARN allocation failed $failuresOnHost times\")",
    "line": 91
  }],
  "prId": 21068
}]