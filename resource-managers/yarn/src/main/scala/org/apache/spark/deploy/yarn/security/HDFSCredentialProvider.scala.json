[{
  "comments": [{
    "author": {
      "login": "mridulm"
    },
    "body": "Is this gauranteed to have only a single value (if present) ? If not, it could be changing the cardinality of what is returned compared to before.",
    "commit": "17d86725fe1d70df12e02ef40d70a378108d4164",
    "createdAt": "2016-12-13T17:24:02Z",
    "diffHunk": "@@ -72,21 +72,22 @@ private[security] class HDFSCredentialProvider extends ServiceCredentialProvider\n     // We cannot use the tokens generated with renewer yarn. Trying to renew\n     // those will fail with an access control issue. So create new tokens with the logged in\n     // user as renewer.\n-    sparkConf.get(PRINCIPAL).map { renewer =>\n+    sparkConf.get(PRINCIPAL).flatMap { renewer =>\n       val creds = new Credentials()\n       nnsToAccess(hadoopConf, sparkConf).foreach { dst =>\n         val dstFs = dst.getFileSystem(hadoopConf)\n         dstFs.addDelegationTokens(renewer, creds)\n       }\n-      val t = creds.getAllTokens.asScala\n-        .filter(_.getKind == DelegationTokenIdentifier.HDFS_DELEGATION_KIND)\n-        .head\n-      val newExpiration = t.renew(hadoopConf)\n-      val identifier = new DelegationTokenIdentifier()\n-      identifier.readFields(new DataInputStream(new ByteArrayInputStream(t.getIdentifier)))\n-      val interval = newExpiration - identifier.getIssueDate\n-      logInfo(s\"Renewal Interval is $interval\")\n-      interval\n+      val hdfsToken = creds.getAllTokens.asScala\n+        .find(_.getKind == DelegationTokenIdentifier.HDFS_DELEGATION_KIND)\n+      hdfsToken.map { t =>",
    "line": 22
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Does `find` return 1 thing? yes it returns the first match if any as an `Option`.",
    "commit": "17d86725fe1d70df12e02ef40d70a378108d4164",
    "createdAt": "2016-12-13T18:11:05Z",
    "diffHunk": "@@ -72,21 +72,22 @@ private[security] class HDFSCredentialProvider extends ServiceCredentialProvider\n     // We cannot use the tokens generated with renewer yarn. Trying to renew\n     // those will fail with an access control issue. So create new tokens with the logged in\n     // user as renewer.\n-    sparkConf.get(PRINCIPAL).map { renewer =>\n+    sparkConf.get(PRINCIPAL).flatMap { renewer =>\n       val creds = new Credentials()\n       nnsToAccess(hadoopConf, sparkConf).foreach { dst =>\n         val dstFs = dst.getFileSystem(hadoopConf)\n         dstFs.addDelegationTokens(renewer, creds)\n       }\n-      val t = creds.getAllTokens.asScala\n-        .filter(_.getKind == DelegationTokenIdentifier.HDFS_DELEGATION_KIND)\n-        .head\n-      val newExpiration = t.renew(hadoopConf)\n-      val identifier = new DelegationTokenIdentifier()\n-      identifier.readFields(new DataInputStream(new ByteArrayInputStream(t.getIdentifier)))\n-      val interval = newExpiration - identifier.getIssueDate\n-      logInfo(s\"Renewal Interval is $interval\")\n-      interval\n+      val hdfsToken = creds.getAllTokens.asScala\n+        .find(_.getKind == DelegationTokenIdentifier.HDFS_DELEGATION_KIND)\n+      hdfsToken.map { t =>",
    "line": 22
  }, {
    "author": {
      "login": "mridulm"
    },
    "body": "My bad. s/find/filter/g in my head.\r\n\r\nLGTM !",
    "commit": "17d86725fe1d70df12e02ef40d70a378108d4164",
    "createdAt": "2016-12-13T18:20:27Z",
    "diffHunk": "@@ -72,21 +72,22 @@ private[security] class HDFSCredentialProvider extends ServiceCredentialProvider\n     // We cannot use the tokens generated with renewer yarn. Trying to renew\n     // those will fail with an access control issue. So create new tokens with the logged in\n     // user as renewer.\n-    sparkConf.get(PRINCIPAL).map { renewer =>\n+    sparkConf.get(PRINCIPAL).flatMap { renewer =>\n       val creds = new Credentials()\n       nnsToAccess(hadoopConf, sparkConf).foreach { dst =>\n         val dstFs = dst.getFileSystem(hadoopConf)\n         dstFs.addDelegationTokens(renewer, creds)\n       }\n-      val t = creds.getAllTokens.asScala\n-        .filter(_.getKind == DelegationTokenIdentifier.HDFS_DELEGATION_KIND)\n-        .head\n-      val newExpiration = t.renew(hadoopConf)\n-      val identifier = new DelegationTokenIdentifier()\n-      identifier.readFields(new DataInputStream(new ByteArrayInputStream(t.getIdentifier)))\n-      val interval = newExpiration - identifier.getIssueDate\n-      logInfo(s\"Renewal Interval is $interval\")\n-      interval\n+      val hdfsToken = creds.getAllTokens.asScala\n+        .find(_.getKind == DelegationTokenIdentifier.HDFS_DELEGATION_KIND)\n+      hdfsToken.map { t =>",
    "line": 22
  }],
  "prId": 16265
}]