[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You don't need this class.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-03-19T20:21:35Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Indeed, removed this class.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-13T17:47:53Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This doesn't match our coding style; the right style is described in the contributing doc I linked to before. When in doubt, look at existing code.\r\n\r\nPretty much all of your method declarations use the wrong style.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-03-19T20:22:58Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-13T17:48:08Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Why do this at all? These configs didn't exist before, I don't see the point of doing this translation if nobody is expected to use this name.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-03-19T20:24:09Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "It’s a YARN specific thing, if I was provide “memory” as resourceName, a ResourceNotFoundException would have been thrown from YARN.\r\nSee: https://github.com/apache/hadoop/blob/532bbf4602e418276961cfc4f6b5e3f70e9cedc0/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/ResourceInformation.java#L42\r\nSee here how MEMORY_URI is compared with the passed in resource name: https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/Resource.java#L318",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-13T17:48:22Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "That's not what I mean.\r\n\r\nWhat I mean is 2 things:\r\n\r\n- why would we translate \"memory\" to \"memory-mb\" if there are 0 existing users of this feature, since it does not exist? If this were allowed, users should use the right name from the get go.\r\n\r\n- we shouldn't be allowing people to set memory and cpu cores using these options, as I've commented before, because Spark already has different options for those and uses those settings in a lot of different places.\r\n",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:43:28Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "This was fixed before.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-10-05T21:08:18Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Not really a helpful debug log.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-03-19T20:24:41Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Modified it to be more helpful, so the whole resource map is logged.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-13T17:48:33Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "style is `.foreach { rt =>`. As usual, follow what existing code does. This shows up in a bunch of other places.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-03-19T20:25:24Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Fixed, however I only found 2 occurences of this kind of style issue.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-13T17:48:44Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "```\r\nUtils.classForName(\r\n   \"...\")\r\n```",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-03-19T20:26:36Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      // These yarn client methods were added in Hadoop 3, so we still need to use reflection to\n+      // avoid compile error when building against Hadoop 2.x\n+      try {\n+        val resInfoClass = Utils."
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-13T17:48:55Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      // These yarn client methods were added in Hadoop 3, so we still need to use reflection to\n+      // avoid compile error when building against Hadoop 2.x\n+      try {\n+        val resInfoClass = Utils."
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`: AnyRef` is unnecessary.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-03-19T20:26:59Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      // These yarn client methods were added in Hadoop 3, so we still need to use reflection to\n+      // avoid compile error when building against Hadoop 2.x\n+      try {\n+        val resInfoClass = Utils.\n+          classForName(\"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation: AnyRef ="
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-13T17:49:07Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      // These yarn client methods were added in Hadoop 3, so we still need to use reflection to\n+      // avoid compile error when building against Hadoop 2.x\n+      try {\n+        val resInfoClass = Utils.\n+          classForName(\"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation: AnyRef ="
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "What if cause is null?",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-03-19T20:27:26Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      // These yarn client methods were added in Hadoop 3, so we still need to use reflection to\n+      // avoid compile error when building against Hadoop 2.x\n+      try {\n+        val resInfoClass = Utils.\n+          classForName(\"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation: AnyRef =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-13T17:49:16Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      // These yarn client methods were added in Hadoop 3, so we still need to use reflection to\n+      // avoid compile error when building against Hadoop 2.x\n+      try {\n+        val resInfoClass = Utils.\n+          classForName(\"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation: AnyRef =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Make this a constant so it doesn't have to be compiled on every call?",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-03-19T20:28:39Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      // These yarn client methods were added in Hadoop 3, so we still need to use reflection to\n+      // avoid compile error when building against Hadoop 2.x\n+      try {\n+        val resInfoClass = Utils.\n+          classForName(\"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation: AnyRef =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    })\n+    resource\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    val pattern = \"([0-9]+)([A-Za-z]*)\".r"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Good idea, extracted to constant.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-13T17:49:28Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      // These yarn client methods were added in Hadoop 3, so we still need to use reflection to\n+      // avoid compile error when building against Hadoop 2.x\n+      try {\n+        val resInfoClass = Utils.\n+          classForName(\"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation: AnyRef =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    })\n+    resource\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    val pattern = \"([0-9]+)([A-Za-z]*)\".r"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`unit.nonEmpty`",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-03-19T20:33:48Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      // These yarn client methods were added in Hadoop 3, so we still need to use reflection to\n+      // avoid compile error when building against Hadoop 2.x\n+      try {\n+        val resInfoClass = Utils.\n+          classForName(\"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation: AnyRef =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    })\n+    resource\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    val pattern = \"([0-9]+)([A-Za-z]*)\".r\n+    try {\n+      val pattern(amount, unit) = s\n+      (amount.toLong, unit)\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $pattern, unmatched value: $s\")\n+    }\n+  }\n+\n+  private def createResourceInformation(resourceName: String,\n+                                        amount: Long,\n+                                        unit: String,\n+                                        resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.length > 0) {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-13T17:49:53Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+private[yarn] class ResourceTypeHelper {\n+}\n+\n+object ResourceTypeHelper extends Logging {\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(resourceTypesParam: Map[String, String],\n+                                       resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Size of custom resource types: ${resourceTypes.size}\")\n+    resourceTypes.foreach(rt => {\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      // These yarn client methods were added in Hadoop 3, so we still need to use reflection to\n+      // avoid compile error when building against Hadoop 2.x\n+      try {\n+        val resInfoClass = Utils.\n+          classForName(\"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation: AnyRef =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    })\n+    resource\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    val pattern = \"([0-9]+)([A-Za-z]*)\".r\n+    try {\n+      val pattern(amount, unit) = s\n+      (amount.toLong, unit)\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $pattern, unmatched value: $s\")\n+    }\n+  }\n+\n+  private def createResourceInformation(resourceName: String,\n+                                        amount: Long,\n+                                        unit: String,\n+                                        resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.length > 0) {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Mark all these new types as `private` since they're not meant to be used outside this package.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:37:43Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:14:27Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: YARN",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:37:55Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:14:35Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You can use `require(resource != null, msg)` for this.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:38:59Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Thanks for recognizing this, fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:14:51Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`case (name, rawAmount) =>`",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:40:42Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:14:59Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`private`, at least. But there's a single caller, why not just inline it?",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:50:57Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "For the translation: \r\nI see, then the memory to memory-mb translation does not make sense, I get this now. \r\nRemoved the translation. \r\nFor getAmountAndUnit: I inlined the method",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:16:16Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`private`, also see above.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:52:13Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "inlined method",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:16:27Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Missing return type.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:53:00Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "How I would specify return type here? As I cannot refer to the ResourceInformation class directly since by default Spark is compiled against Hadoop2.x and not Hadoop 3.\r\nIn Hadoop2.x we don't have that class in the YARN API jars.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:17:55Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Use `Any` or something along those lines.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-23T23:41:07Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-07-19T16:32:15Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You should explicitly use `java.util.Long` in these calls. Just import it with an alias.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:53:52Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], classOf[Long])"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Good point. FYI, only JLong.TYPE worked as there's a difference calling getMethod with primitive long and Long object. For the latter, it produced NoSuchMethodException at runtime.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:18:50Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], classOf[Long])"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`amount: JLong`",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:54:10Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], classOf[Long])\n+        resInfoNewInstanceMethod.invoke(null, resourceName, unit, amount.asInstanceOf[AnyRef])"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:21:06Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], classOf[Long])\n+        resInfoNewInstanceMethod.invoke(null, resourceName, unit, amount.asInstanceOf[AnyRef])"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:25:39Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], classOf[Long])\n+        resInfoNewInstanceMethod.invoke(null, resourceName, unit, amount.asInstanceOf[AnyRef])"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Remove. This will be noisy for the majority of people, who don't have (and are not even using) this feature.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:56:09Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], classOf[Long])\n+        resInfoNewInstanceMethod.invoke(null, resourceName, unit, amount.asInstanceOf[AnyRef])\n+      } else {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[Long])\n+        resInfoNewInstanceMethod.invoke(null, resourceName, amount.asInstanceOf[AnyRef])\n+      }\n+    resourceInformation\n+  }\n+\n+  /**\n+   * Checks whether Hadoop 2.x or 3 is used as a dependency.\n+   * In case of Hadoop 3 and later,\n+   * the ResourceInformation class should be available on the classpath.\n+   */\n+  def isYarnResourceTypesAvailable(): Boolean = {\n+    try {\n+      Utils.classForName(\"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+      true\n+    } catch {\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)"
  }, {
    "author": {
      "login": "galv"
    },
    "body": "I agree about removing. You already log warnings whenever this is false anyway, so you would print the same warning twice. (But you should double-check these warnings won't be logged when someone is not using Yarn3.0's resouce types feature.)",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-20T03:08:17Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], classOf[Long])\n+        resInfoNewInstanceMethod.invoke(null, resourceName, unit, amount.asInstanceOf[AnyRef])\n+      } else {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[Long])\n+        resInfoNewInstanceMethod.invoke(null, resourceName, amount.asInstanceOf[AnyRef])\n+      }\n+    resourceInformation\n+  }\n+\n+  /**\n+   * Checks whether Hadoop 2.x or 3 is used as a dependency.\n+   * In case of Hadoop 3 and later,\n+   * the ResourceInformation class should be available on the classpath.\n+   */\n+  def isYarnResourceTypesAvailable(): Boolean = {\n+    try {\n+      Utils.classForName(\"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+      true\n+    } catch {\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Removed all warning logs with this message.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:21:34Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {\n+    unit match {\n+      case \"m\" => \"M\"\n+      case \"g\" => \"G\"\n+      case \"t\" => \"T\"\n+      case \"p\" => \"P\"\n+      case _ => unit\n+    }\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], classOf[Long])\n+        resInfoNewInstanceMethod.invoke(null, resourceName, unit, amount.asInstanceOf[AnyRef])\n+      } else {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[Long])\n+        resInfoNewInstanceMethod.invoke(null, resourceName, amount.asInstanceOf[AnyRef])\n+      }\n+    resourceInformation\n+  }\n+\n+  /**\n+   * Checks whether Hadoop 2.x or 3 is used as a dependency.\n+   * In case of Hadoop 3 and later,\n+   * the ResourceInformation class should be available on the classpath.\n+   */\n+  def isYarnResourceTypesAvailable(): Boolean = {\n+    try {\n+      Utils.classForName(\"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+      true\n+    } catch {\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Can you post here an example of the output here?\r\n\r\nI don't see a separator, so this might look weird.\r\n\r\nAlso, use: `i: JInteger`",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:58:07Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed with JInteger.\r\nPlease check my answer for the related comment from @galv whether I need this method or not.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:23:06Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Use `java.util.Integer`.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-18T23:58:45Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Good point. FYI, only JInteger.TYPE worked as there's a difference calling getMethod with primitive int and Integer object. For the latter, it produced NoSuchMethodException at runtime.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:24:16Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "galv"
    },
    "body": "I actually don't think this is a good idea. When you look at YARN's documentation for resource types, you see that they explicitly specify \"m\" and \"p\" as corresponding to milli and pico, not mega and peta. See [here](https://hadoop.apache.org/docs/r3.0.0/hadoop-yarn/hadoop-yarn-site/ResourceModel.html). You can seethe units defined in code [here](https://github.com/apache/hadoop/blob/532bbf4602e418276961cfc4f6b5e3f70e9cedc0/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/util/UnitsConversionUtil.java#L51).\r\n\r\nNow, I cannot think of a single situation where someone would want to request a pico quantity of a resource, but if some user does need this feature at some point, this code will silently request the wrong quantity by changing the unit to peta. Which is bad, because fixing it in a backwards-compatible fashion would be challenging.\r\n\r\nI realize that you may have done this because it is valid to request 8 megabytes in spark via \"8m\". Two options come to mind: Apply this function only for memory, OR disallow requesting memory and vcores via resource types. It looks like vanzin already suggests disallowing seting vcores and memory this way, so that's probably the right thing to do, since you have less code (you can drop this function).",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-20T02:45:07Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "According to the Resource Model documentation page of YARN, for every new custom resource type, the specified units in the table are available.\r\nI see your concern, but I don't know how to resolve this situation as Spark uses m and M for Mega unit. How would I differentiate this from micro? \r\nSuppose someone defines a new resource type (countable) that could have units of mega and giga, and someone requests 2g of that resource.\r\nIf the unit is used as is, YARN cannot understand it as g is not a valid unit. ",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:30:14Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {"
  }, {
    "author": {
      "login": "galv"
    },
    "body": "Well, I suppose the only real problem here is \"m\" and \"M\", since \"g\" and \"G\" can both unambiguously mean giga.\r\n\r\nTo be honest, as far as I know, spark uses \"m\" only for its memory parameters. YARN requires that resource types have their unit specified in advance (in resource-types.xml, I think), so it will throw an exception if someone specifies \"m\" but the resource accepts \"M\".\r\n\r\nI still recommend removing this function because it can silently cause wrong behavior, and fixing it later would be hard because we would have to break backwards compatibility (all jobs that used \"m\" when they really should have used \"M\" will have to be migrated).",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T15:35:25Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Yes, with g/G there is no issue. \r\nI see Spark uses 'm' only for memory nowadays.\r\nWhen you define a custom resource type with YARN, you can indeed specify its unit in resource-types.xml, meaning this would be the default unit.\r\nSo back to your example, if a resource has M as defined default unit with YARN's config, it does also mean that YARN would accept 'm' as a unit and it will convert the amount of 'm' to 'M' (millis to mega).\r\nMore precisely, default units are for cases when you request a resource but don't specify the units, e.g. request 5 and YARN will understand it as request 5M.\r\nSo in this sense, requesting any amount of 'm' of a custom resource is not an exceptional case in my opinion.\r\nOn the other hand I understand your concern and I see that this conversion is hacky and not clean nor future proof.\r\nI can come up with the following: \r\n- 'g' (giga) will auto-convert to 'G'\r\n- 'm' / 'M' (millis / mega) will not be auto-converted as it ambiguous (milli vs mega), in this case Spark documentation should be clear that if 'm' is specified then millis will be requested, if 'M' is specified then mega will be requested from YARN.\r\n- 'p' / 'P' (pico / peta): same as millis/mega\r\n\r\nWhat do you think? Do you have any other idea?",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T19:27:48Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {"
  }, {
    "author": {
      "login": "galv"
    },
    "body": "> So back to your example, if a resource has M as defined default unit with YARN's config, it does also mean that YARN would accept 'm' as a unit and it will convert the amount of 'm' to 'M' (millis to mega).\r\n\r\nYARN does this? I might have missed something.\r\n\r\nI like your proposal. Since you now disallow requesting memory via this interface (great idea in my opinion), we don't have to worry about the weird case where someone requests 500 megabytes of memory with \"500m\". To be honest, I would not autoconvert 'g' to 'G', but I do not feel strongly about it.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-23T01:54:24Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\",\n+          classOf[Int])\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[AnyRef]).toString()\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+      case NonFatal(e) =>\n+        logWarning(resourceTypesNotAvailableErrorMessage, e)\n+\n+    }\n+    res\n+  }\n+\n+  def getAmountAndUnit(s: String): (Long, String) = {\n+    try {\n+      val AMOUNT_AND_UNIT_REGEX(amount, unit) = s\n+      (amount.toLong, convertToYarnResourceFormat(unit))\n+    } catch {\n+      case _: MatchError => throw new IllegalArgumentException(\n+        s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, unmatched value: $s\")\n+    }\n+  }\n+\n+  def convertToYarnResourceFormat(unit: String): String = {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "galv"
    },
    "body": "This is a constant, so why not change it to `RESOURCE_TYPES_NOT_AVAILABLE_ERROR_MESSAGE`?",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-20T03:34:10Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage ="
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "I removed all the warning logs and the constant as well as it became unused.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:27:25Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage ="
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "galv"
    },
    "body": "I'm concerned that this code assumes memory and vcores are always the first two resource types. Can we really assume this?\r\n\r\nSecondly, I am concerned that you are using an interface marked with @InterfaceStability.Unstable. See [here](https://github.com/apache/hadoop/blob/06cceba1cb07340c412c4467439c16ea6812e685/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/Resource.java#L283). Given that [toString](https://github.com/apache/hadoop/blob/532bbf4602e418276961cfc4f6b5e3f70e9cedc0/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/ResourceInformation.java#L264) does not display much you don't already know from your job submission or from resouce-types.xml, I would say consider removing this.\r\n\r\nMaybe a spark dev would have a stronger opinion on whether this is important.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-20T05:13:57Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "I can agree with that, using an unstable interface could cause problems in the future.\r\nFor better traceability and informing users, I kept this method for now.\r\nMaybe @vanzin could please suggest which is the better way (keep or not to keep)? ",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-22T12:31:29Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {"
  }, {
    "author": {
      "login": "galv"
    },
    "body": "Would be great to get @vanzin's opinion on this before merging. Thank you!",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-23T02:10:50Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Can you just print the `amResources` map from the user instead of having this hacky code? I'm not sure the YARN view of this is that interesting for Spark users, who are more interested in what they requested when debugging.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-23T23:40:22Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Sorry but I don't get what is 'amResources' in this context or what exactly you had in mind for this.\r\nI modified the code to append the toString() representation of the Resource field, so that I could completely remove the ResourceTypesHelper.getCustomResourcesAsStrings method which makes that class more simple.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-07-19T16:33:17Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the yarn API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val resourceTypesNotAvailableErrorMessage =\n+    \"Ignoring updating resource with resource types because \" +\n+    \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypesParam: Map[String, String],\n+      resource: Resource): Resource = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return resource\n+    }\n+\n+    val resourceTypes = resourceTypesParam.map { case (k, v) => (\n+      if (k.equals(\"memory\")) {\n+        logWarning(\"Trying to use 'memory' as a custom resource, converted it to 'memory-mb'\")\n+        \"memory-mb\"\n+      } else k, v)\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { rt =>\n+      val resourceName: String = rt._1\n+      val (amount, unit) = getAmountAndUnit(rt._2)\n+      logDebug(s\"Registering resource with name: $resourceName, amount: $amount, unit: $unit\")\n+\n+      try {\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(resourceName, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, resourceName, resourceInformation)\n+      } catch {\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+        case NonFatal(e) =>\n+          logWarning(resourceTypesNotAvailableErrorMessage, e)\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      logWarning(resourceTypesNotAvailableErrorMessage)\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "galv"
    },
    "body": "Don't forget to update this when you are ready.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-23T02:00:33Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return resource\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val (amount, unit) = (amountPart.toLong, unitPart match {\n+          case \"m\" => \"M\""
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Removed the 'm' to 'M' conversion case, I hope you meant this.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-07-19T16:33:41Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return resource\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val (amount, unit) = (amountPart.toLong, unitPart match {\n+          case \"m\" => \"M\""
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Separate lines for each variable would make this look better.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-23T23:34:19Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return resource\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val (amount, unit) = (amountPart.toLong, unitPart match {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-07-19T16:36:04Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return resource\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val (amount, unit) = (amountPart.toLong, unitPart match {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Move these outside the loop.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-23T23:35:26Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return resource\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val (amount, unit) = (amountPart.toLong, unitPart match {\n+          case \"m\" => \"M\"\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        })\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod ="
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-07-19T16:35:59Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return resource\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val (amount, unit) = (amountPart.toLong, unitPart match {\n+          case \"m\" => \"M\"\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        })\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod ="
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Better and shorter message:\r\n\r\n`s\"Resource request for '$name' ('$rawAmount') does not match pattern $AMOUNT_AND_UNIT_REGEX.\"`",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-23T23:36:33Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return resource\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val (amount, unit) = (amountPart.toLong, unitPart match {\n+          case \"m\" => \"M\"\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        })\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(name, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, name, resourceInformation)\n+      } catch {\n+        case _: MatchError => throw new IllegalArgumentException(\n+          s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, \" +"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Fixed accordingly",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-07-19T16:36:23Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return resource\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val (amount, unit) = (amountPart.toLong, unitPart match {\n+          case \"m\" => \"M\"\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        })\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(name, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, name, resourceInformation)\n+      } catch {\n+        case _: MatchError => throw new IllegalArgumentException(\n+          s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, \" +"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "The line breaks in your comments are weird in many places. You're mixing really short with longer lines which makes the comments look weird.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-05-23T23:42:14Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return resource\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val (amount, unit) = (amountPart.toLong, unitPart match {\n+          case \"m\" => \"M\"\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        })\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(name, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, name, resourceInformation)\n+      } catch {\n+        case _: MatchError => throw new IllegalArgumentException(\n+          s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, \" +\n+              s\"unmatched value: $rawAmount\")\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\", JInteger.TYPE)\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[JInteger]).toString()\n+        res ++= \", \"\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+    }\n+    res\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], JLong.TYPE)\n+        resInfoNewInstanceMethod.invoke(null, resourceName, unit, amount.asInstanceOf[JLong])\n+      } else {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], JLong.TYPE)\n+        resInfoNewInstanceMethod.invoke(null, resourceName, amount.asInstanceOf[JLong])\n+      }\n+    resourceInformation\n+  }\n+\n+  /**\n+   * Checks whether Hadoop 2.x or 3 is used as a dependency.\n+   * In case of Hadoop 3 and later,\n+   * the ResourceInformation class should be available on the classpath."
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Could you please point to an example of an acceptable multiline commenting style with line breaks? \r\nPlease check how I modified the comment.\r\nThanks ",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-07-19T16:37:17Z",
    "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return resource\n+    }\n+\n+    logDebug(s\"Custom resource types: $resourceTypes\")\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val (amount, unit) = (amountPart.toLong, unitPart match {\n+          case \"m\" => \"M\"\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        })\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+\n+        val resInfoClass = Utils.classForName(\n+          \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+        val setResourceInformationMethod =\n+          resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+            resInfoClass)\n+\n+        val resourceInformation =\n+          createResourceInformation(name, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, name, resourceInformation)\n+      } catch {\n+        case _: MatchError => throw new IllegalArgumentException(\n+          s\"Value of resource type should match pattern $AMOUNT_AND_UNIT_REGEX, \" +\n+              s\"unmatched value: $rawAmount\")\n+        case e: InvocationTargetException =>\n+          if (e.getCause != null) {\n+            throw e.getCause\n+          } else {\n+            throw e\n+          }\n+      }\n+    }\n+    resource\n+  }\n+\n+  def getCustomResourcesAsStrings(resource: Resource): String = {\n+    if (resource == null) {\n+      throw new IllegalArgumentException(\"Resource parameter should not be null!\")\n+    }\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      return \"\"\n+    }\n+\n+    var res: String = \"\"\n+    try {\n+      val resUtilsClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.util.resource.ResourceUtils\")\n+      val getNumberOfResourceTypesMethod = resUtilsClass.getMethod(\"getNumberOfKnownResourceTypes\")\n+      val numberOfResourceTypes: Int = getNumberOfResourceTypesMethod.invoke(null).asInstanceOf[Int]\n+      val resourceClass = Utils.classForName(\n+        \"org.apache.hadoop.yarn.api.records.Resource\")\n+\n+      // skip memory and vcores (index 0 and 1)\n+      for (i <- 2 until numberOfResourceTypes) {\n+        val getResourceInfoMethod = resourceClass.getMethod(\"getResourceInformation\", JInteger.TYPE)\n+        res ++= getResourceInfoMethod.invoke(resource, i.asInstanceOf[JInteger]).toString()\n+        res ++= \", \"\n+      }\n+    } catch {\n+      case e: InvocationTargetException =>\n+        if (e.getCause != null) {\n+          throw e.getCause\n+        } else {\n+          throw e\n+        }\n+    }\n+    res\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]) = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], JLong.TYPE)\n+        resInfoNewInstanceMethod.invoke(null, resourceName, unit, amount.asInstanceOf[JLong])\n+      } else {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], JLong.TYPE)\n+        resInfoNewInstanceMethod.invoke(null, resourceName, amount.asInstanceOf[JLong])\n+      }\n+    resourceInformation\n+  }\n+\n+  /**\n+   * Checks whether Hadoop 2.x or 3 is used as a dependency.\n+   * In case of Hadoop 3 and later,\n+   * the ResourceInformation class should be available on the classpath."
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "do you mean to return whether or `resourceTypes` is empty, but only log the warning if its empty?\r\n\r\nI suspect that is the cause of the test failures",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-07-20T21:16:37Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val RESOURCE_TYPES_NOT_AVAILABLE_ERROR_MESSAGE =\n+    \"Ignoring updating resource with resource types because \" +\n+        \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable() && resourceTypes.nonEmpty) {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "You are right, this condition was wrong so I added an inner-if to check whether the resourceTypes map is not empty.\r\nThe purpose of this check is: Return resource immediately if YARN resource types is not available (Hadoop version is less than 3) and log the warning if YARN resource types is not available and custom resource types are requested.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-07-21T06:10:20Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val RESOURCE_TYPES_NOT_AVAILABLE_ERROR_MESSAGE =\n+    \"Ignoring updating resource with resource types because \" +\n+        \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable() && resourceTypes.nonEmpty) {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I don't think it's worth factoring out one occurrence of one message?",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-07-31T18:52:52Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val RESOURCE_TYPES_NOT_AVAILABLE_ERROR_MESSAGE ="
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Fair enough, inlined the string.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-09-17T13:53:27Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val RESOURCE_TYPES_NOT_AVAILABLE_ERROR_MESSAGE ="
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I suggest: `case e: InvocationTargetException if e.getCause != null =>` and then you don't need the `throw e` case.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-07-31T18:53:51Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val RESOURCE_TYPES_NOT_AVAILABLE_ERROR_MESSAGE =\n+    \"Ignoring updating resource with resource types because \" +\n+        \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    logDebug(s\"Custom resource types requested: $resourceTypes\")\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      if (resourceTypes.nonEmpty) {\n+        logWarning(RESOURCE_TYPES_NOT_AVAILABLE_ERROR_MESSAGE)\n+      }\n+      return resource\n+    }\n+\n+    val resInfoClass = Utils.classForName(\n+      \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+    val setResourceInformationMethod =\n+      resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+        resInfoClass)\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val amount = amountPart.toLong\n+        val unit = unitPart match {\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        }\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+        val resourceInformation =\n+          createResourceInformation(name, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, name,\n+          resourceInformation.asInstanceOf[AnyRef])\n+      } catch {\n+        case _: MatchError => throw new IllegalArgumentException(\n+          s\"Resource request for '$name' ('$rawAmount') \" +\n+              s\"does not match pattern $AMOUNT_AND_UNIT_REGEX.\")\n+        case e: InvocationTargetException =>"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Good point, fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-09-17T13:55:45Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+  private val RESOURCE_TYPES_NOT_AVAILABLE_ERROR_MESSAGE =\n+    \"Ignoring updating resource with resource types because \" +\n+        \"the version of YARN does not support it!\"\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    logDebug(s\"Custom resource types requested: $resourceTypes\")\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      if (resourceTypes.nonEmpty) {\n+        logWarning(RESOURCE_TYPES_NOT_AVAILABLE_ERROR_MESSAGE)\n+      }\n+      return resource\n+    }\n+\n+    val resInfoClass = Utils.classForName(\n+      \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+    val setResourceInformationMethod =\n+      resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+        resInfoClass)\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val amount = amountPart.toLong\n+        val unit = unitPart match {\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        }\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+        val resourceInformation =\n+          createResourceInformation(name, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, name,\n+          resourceInformation.asInstanceOf[AnyRef])\n+      } catch {\n+        case _: MatchError => throw new IllegalArgumentException(\n+          s\"Resource request for '$name' ('$rawAmount') \" +\n+              s\"does not match pattern $AMOUNT_AND_UNIT_REGEX.\")\n+        case e: InvocationTargetException =>"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "No need for `ResourceTypeHelper.`",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-09-24T23:33:26Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    logDebug(s\"Custom resource types requested: $resourceTypes\")\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "The purpose of this class is to hide the implentation details of the resource type related functionality.\r\nFor example, setResourceInfoFromResourceTypes is called from many places, so with the current implementation, code is not duplicated among classes.\r\nWhat would be your suggestion instead of this class?",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-10-02T02:08:39Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    logDebug(s\"Custom resource types requested: $resourceTypes\")\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I just said you don't need `ResourceTypeHelper.` since the method you're calling is already in this class.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-10-02T02:20:52Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    logDebug(s\"Custom resource types requested: $resourceTypes\")\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Oh I see, that makes sense :)",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-10-02T03:41:10Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    logDebug(s\"Custom resource types requested: $resourceTypes\")\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Move code to next line here since it needs multiple lines anyway.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-09-24T23:37:11Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    logDebug(s\"Custom resource types requested: $resourceTypes\")\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      if (resourceTypes.nonEmpty) {\n+        logWarning(\"Ignoring updating resource with resource types because \" +\n+            \"the version of YARN does not support it!\")\n+      }\n+      return resource\n+    }\n+\n+    val resInfoClass = Utils.classForName(\n+      \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+    val setResourceInformationMethod =\n+      resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+        resInfoClass)\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val amount = amountPart.toLong\n+        val unit = unitPart match {\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        }\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+        val resourceInformation =\n+          createResourceInformation(name, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, name,\n+          resourceInformation.asInstanceOf[AnyRef])\n+      } catch {\n+        case _: MatchError => throw new IllegalArgumentException("
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Fixed.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-10-02T02:22:30Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    logDebug(s\"Custom resource types requested: $resourceTypes\")\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      if (resourceTypes.nonEmpty) {\n+        logWarning(\"Ignoring updating resource with resource types because \" +\n+            \"the version of YARN does not support it!\")\n+      }\n+      return resource\n+    }\n+\n+    val resInfoClass = Utils.classForName(\n+      \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+    val setResourceInformationMethod =\n+      resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+        resInfoClass)\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val amount = amountPart.toLong\n+        val unit = unitPart match {\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        }\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+        val resourceInformation =\n+          createResourceInformation(name, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, name,\n+          resourceInformation.asInstanceOf[AnyRef])\n+      } catch {\n+        case _: MatchError => throw new IllegalArgumentException("
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You're actually not using the return value in the call site, so probably should be `Unit`.\r\n\r\n(You are using the return value in `YarnAllocator` but you don't need to, since it's just the same as the parameter.)",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-09-24T23:37:59Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Very good point, thanks! Fixed this.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-10-02T02:26:54Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`resourceRequests` is a more accurate name.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-09-24T23:38:29Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "I agree, fixed.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-10-02T02:29:16Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`setResourceRequests` is a more accurate name.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-09-24T23:38:39Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes("
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-10-02T02:29:48Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes("
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`ResourceRequestHelper` is a more accurate name.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-09-24T23:39:04Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "I agree, fixed",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-10-02T02:30:24Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {"
  }],
  "prId": 20761
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This can be `Try(Utils.classForName(...)).isSuccess`.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-09-24T23:42:27Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    logDebug(s\"Custom resource types requested: $resourceTypes\")\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      if (resourceTypes.nonEmpty) {\n+        logWarning(\"Ignoring updating resource with resource types because \" +\n+            \"the version of YARN does not support it!\")\n+      }\n+      return resource\n+    }\n+\n+    val resInfoClass = Utils.classForName(\n+      \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+    val setResourceInformationMethod =\n+      resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+        resInfoClass)\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val amount = amountPart.toLong\n+        val unit = unitPart match {\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        }\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+        val resourceInformation =\n+          createResourceInformation(name, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, name,\n+          resourceInformation.asInstanceOf[AnyRef])\n+      } catch {\n+        case _: MatchError => throw new IllegalArgumentException(\n+          s\"Resource request for '$name' ('$rawAmount') \" +\n+              s\"does not match pattern $AMOUNT_AND_UNIT_REGEX.\")\n+        case e: InvocationTargetException if e.getCause != null => throw e.getCause\n+      }\n+    }\n+    resource\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]): Any = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], JLong.TYPE)\n+        resInfoNewInstanceMethod.invoke(null, resourceName, unit, amount.asInstanceOf[JLong])\n+      } else {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], JLong.TYPE)\n+        resInfoNewInstanceMethod.invoke(null, resourceName, amount.asInstanceOf[JLong])\n+      }\n+    resourceInformation\n+  }\n+\n+  /**\n+   * Checks whether Hadoop 2.x or 3 is used as a dependency.\n+   * In case of Hadoop 3 and later, the ResourceInformation class\n+   * should be available on the classpath.\n+   */\n+  def isYarnResourceTypesAvailable(): Boolean = {\n+    try {"
  }, {
    "author": {
      "login": "szilard-nemeth"
    },
    "body": "Thanks, didn't know this syntax. Fixed.",
    "commit": "dc2e382ff1e468f7e54e14a12fdfcf983b70ea0f",
    "createdAt": "2018-10-02T02:38:16Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import java.lang.{Integer => JInteger, Long => JLong}\n+import java.lang.reflect.InvocationTargetException\n+\n+import scala.collection.mutable\n+import scala.util.control.NonFatal\n+\n+import org.apache.hadoop.yarn.api.records.Resource\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * This helper class uses some of Hadoop 3 methods from the YARN API,\n+ * so we need to use reflection to avoid compile error when building against Hadoop 2.x\n+ */\n+private object ResourceTypeHelper extends Logging {\n+  private val AMOUNT_AND_UNIT_REGEX = \"([0-9]+)([A-Za-z]*)\".r\n+\n+  def setResourceInfoFromResourceTypes(\n+      resourceTypes: Map[String, String],\n+      resource: Resource): Resource = {\n+    require(resource != null, \"Resource parameter should not be null!\")\n+\n+    logDebug(s\"Custom resource types requested: $resourceTypes\")\n+    if (!ResourceTypeHelper.isYarnResourceTypesAvailable()) {\n+      if (resourceTypes.nonEmpty) {\n+        logWarning(\"Ignoring updating resource with resource types because \" +\n+            \"the version of YARN does not support it!\")\n+      }\n+      return resource\n+    }\n+\n+    val resInfoClass = Utils.classForName(\n+      \"org.apache.hadoop.yarn.api.records.ResourceInformation\")\n+    val setResourceInformationMethod =\n+      resource.getClass.getMethod(\"setResourceInformation\", classOf[String],\n+        resInfoClass)\n+    resourceTypes.foreach { case (name, rawAmount) =>\n+      try {\n+        val AMOUNT_AND_UNIT_REGEX(amountPart, unitPart) = rawAmount\n+        val amount = amountPart.toLong\n+        val unit = unitPart match {\n+          case \"g\" => \"G\"\n+          case \"t\" => \"T\"\n+          case \"p\" => \"P\"\n+          case _ => unitPart\n+        }\n+        logDebug(s\"Registering resource with name: $name, amount: $amount, unit: $unit\")\n+        val resourceInformation =\n+          createResourceInformation(name, amount, unit, resInfoClass)\n+        setResourceInformationMethod.invoke(resource, name,\n+          resourceInformation.asInstanceOf[AnyRef])\n+      } catch {\n+        case _: MatchError => throw new IllegalArgumentException(\n+          s\"Resource request for '$name' ('$rawAmount') \" +\n+              s\"does not match pattern $AMOUNT_AND_UNIT_REGEX.\")\n+        case e: InvocationTargetException if e.getCause != null => throw e.getCause\n+      }\n+    }\n+    resource\n+  }\n+\n+  private def createResourceInformation(\n+      resourceName: String,\n+      amount: Long,\n+      unit: String,\n+      resInfoClass: Class[_]): Any = {\n+    val resourceInformation =\n+      if (unit.nonEmpty) {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], classOf[String], JLong.TYPE)\n+        resInfoNewInstanceMethod.invoke(null, resourceName, unit, amount.asInstanceOf[JLong])\n+      } else {\n+        val resInfoNewInstanceMethod = resInfoClass.getMethod(\"newInstance\",\n+          classOf[String], JLong.TYPE)\n+        resInfoNewInstanceMethod.invoke(null, resourceName, amount.asInstanceOf[JLong])\n+      }\n+    resourceInformation\n+  }\n+\n+  /**\n+   * Checks whether Hadoop 2.x or 3 is used as a dependency.\n+   * In case of Hadoop 3 and later, the ResourceInformation class\n+   * should be available on the classpath.\n+   */\n+  def isYarnResourceTypesAvailable(): Boolean = {\n+    try {"
  }],
  "prId": 20761
}]