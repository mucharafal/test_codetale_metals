[{
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "I'm not sure we also want to refactor this, as we might need to have redundant code again when one of case needs to have additional arguments. But I can also refactor if we think we can do it later when really needed.",
    "commit": "7992091c9a45ae3f234fd85e13e0deb1a5f4282f",
    "createdAt": "2019-01-30T23:37:36Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.executor\n+\n+import java.net.URL\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkEnv}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.worker.WorkerWatcher\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.RpcEnv\n+import org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages.{RetrieveSparkAppConfig, SparkAppConfig}\n+import org.apache.spark.util.{Utils, YarnContainerInfoHelper}\n+\n+private[spark] class YarnCoarseGrainedExecutorBackend(\n+    rpcEnv: RpcEnv,\n+    driverUrl: String,\n+    executorId: String,\n+    hostname: String,\n+    cores: Int,\n+    userClassPath: Seq[URL],\n+    env: SparkEnv)\n+  extends CoarseGrainedExecutorBackend(\n+    rpcEnv,\n+    driverUrl,\n+    executorId,\n+    hostname,\n+    cores,\n+    userClassPath,\n+    env) with Logging {\n+\n+  private lazy val hadoopConfiguration = SparkHadoopUtil.get.newConfiguration(env.conf)\n+\n+  override def extractLogUrls: Map[String, String] = {\n+    YarnContainerInfoHelper.getLogUrls(hadoopConfiguration, container = None)\n+      .getOrElse(Map())\n+  }\n+\n+  override def extractAttributes: Map[String, String] = {\n+    YarnContainerInfoHelper.getAttributes(hadoopConfiguration, container = None)\n+      .getOrElse(Map())\n+  }\n+}\n+\n+private[spark] object YarnCoarseGrainedExecutorBackend extends Logging {\n+\n+  def main(args: Array[String]) {\n+    var driverUrl: String = null"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "This is the same as the core argument parser and should remain the same.\r\n\r\nIf and when a new argument needs to be added just for the YARN side, then you can think about refactoring this.",
    "commit": "7992091c9a45ae3f234fd85e13e0deb1a5f4282f",
    "createdAt": "2019-02-13T18:33:47Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.executor\n+\n+import java.net.URL\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkEnv}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.worker.WorkerWatcher\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.RpcEnv\n+import org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages.{RetrieveSparkAppConfig, SparkAppConfig}\n+import org.apache.spark.util.{Utils, YarnContainerInfoHelper}\n+\n+private[spark] class YarnCoarseGrainedExecutorBackend(\n+    rpcEnv: RpcEnv,\n+    driverUrl: String,\n+    executorId: String,\n+    hostname: String,\n+    cores: Int,\n+    userClassPath: Seq[URL],\n+    env: SparkEnv)\n+  extends CoarseGrainedExecutorBackend(\n+    rpcEnv,\n+    driverUrl,\n+    executorId,\n+    hostname,\n+    cores,\n+    userClassPath,\n+    env) with Logging {\n+\n+  private lazy val hadoopConfiguration = SparkHadoopUtil.get.newConfiguration(env.conf)\n+\n+  override def extractLogUrls: Map[String, String] = {\n+    YarnContainerInfoHelper.getLogUrls(hadoopConfiguration, container = None)\n+      .getOrElse(Map())\n+  }\n+\n+  override def extractAttributes: Map[String, String] = {\n+    YarnContainerInfoHelper.getAttributes(hadoopConfiguration, container = None)\n+      .getOrElse(Map())\n+  }\n+}\n+\n+private[spark] object YarnCoarseGrainedExecutorBackend extends Logging {\n+\n+  def main(args: Array[String]) {\n+    var driverUrl: String = null"
  }],
  "prId": 23706
}, {
  "comments": [{
    "author": {
      "login": "pgandhi999"
    },
    "body": "Can we have some comments here as to what does this class do?",
    "commit": "7992091c9a45ae3f234fd85e13e0deb1a5f4282f",
    "createdAt": "2019-02-01T15:34:11Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.executor\n+\n+import java.net.URL\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkEnv}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.worker.WorkerWatcher\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.RpcEnv\n+import org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages.{RetrieveSparkAppConfig, SparkAppConfig}\n+import org.apache.spark.util.{Utils, YarnContainerInfoHelper}\n+\n+private[spark] class YarnCoarseGrainedExecutorBackend(",
    "line": 33
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Sorry missed this. Just addressed.",
    "commit": "7992091c9a45ae3f234fd85e13e0deb1a5f4282f",
    "createdAt": "2019-02-12T23:55:41Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.executor\n+\n+import java.net.URL\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkEnv}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.worker.WorkerWatcher\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.RpcEnv\n+import org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages.{RetrieveSparkAppConfig, SparkAppConfig}\n+import org.apache.spark.util.{Utils, YarnContainerInfoHelper}\n+\n+private[spark] class YarnCoarseGrainedExecutorBackend(",
    "line": 33
  }],
  "prId": 23706
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Line too long, just use a wildcard.",
    "commit": "7992091c9a45ae3f234fd85e13e0deb1a5f4282f",
    "createdAt": "2019-02-13T18:30:48Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.executor\n+\n+import java.net.URL\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkEnv}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.worker.WorkerWatcher\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.RpcEnv\n+import org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages.{RetrieveSparkAppConfig, SparkAppConfig}"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Looks like there're unused imports including this line. Will sort them out.",
    "commit": "7992091c9a45ae3f234fd85e13e0deb1a5f4282f",
    "createdAt": "2019-02-13T23:01:49Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.executor\n+\n+import java.net.URL\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkEnv}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.worker.WorkerWatcher\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.RpcEnv\n+import org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages.{RetrieveSparkAppConfig, SparkAppConfig}"
  }],
  "prId": 23706
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: indent args and extends one more level.",
    "commit": "7992091c9a45ae3f234fd85e13e0deb1a5f4282f",
    "createdAt": "2019-02-13T18:31:51Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.executor\n+\n+import java.net.URL\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkEnv}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.worker.WorkerWatcher\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.RpcEnv\n+import org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages.{RetrieveSparkAppConfig, SparkAppConfig}\n+import org.apache.spark.util.{Utils, YarnContainerInfoHelper}\n+\n+/**\n+ * Custom implementation of CoarseGrainedExecutorBackend for YARN resource manager.\n+ * This class extracts executor log URLs and executor attributes from system environment which\n+ * properties are available for container being set via YARN.\n+ */\n+private[spark] class YarnCoarseGrainedExecutorBackend(\n+    rpcEnv: RpcEnv,",
    "line": 34
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "I'm sorry I'm not sure I understand correctly. All args are 4 spaces and `extends` line is 2 spaces which doesn't seem to violate the style. Could you please guide your suggestion via actual code change?",
    "commit": "7992091c9a45ae3f234fd85e13e0deb1a5f4282f",
    "createdAt": "2019-02-13T23:04:51Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.executor\n+\n+import java.net.URL\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkEnv}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.worker.WorkerWatcher\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.RpcEnv\n+import org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages.{RetrieveSparkAppConfig, SparkAppConfig}\n+import org.apache.spark.util.{Utils, YarnContainerInfoHelper}\n+\n+/**\n+ * Custom implementation of CoarseGrainedExecutorBackend for YARN resource manager.\n+ * This class extracts executor log URLs and executor attributes from system environment which\n+ * properties are available for container being set via YARN.\n+ */\n+private[spark] class YarnCoarseGrainedExecutorBackend(\n+    rpcEnv: RpcEnv,",
    "line": 34
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Hmm, I swear I saw 2 spaces here when I looked at this code before. Ignore me.",
    "commit": "7992091c9a45ae3f234fd85e13e0deb1a5f4282f",
    "createdAt": "2019-02-13T23:42:38Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.executor\n+\n+import java.net.URL\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkEnv}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.worker.WorkerWatcher\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.RpcEnv\n+import org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages.{RetrieveSparkAppConfig, SparkAppConfig}\n+import org.apache.spark.util.{Utils, YarnContainerInfoHelper}\n+\n+/**\n+ * Custom implementation of CoarseGrainedExecutorBackend for YARN resource manager.\n+ * This class extracts executor log URLs and executor attributes from system environment which\n+ * properties are available for container being set via YARN.\n+ */\n+private[spark] class YarnCoarseGrainedExecutorBackend(\n+    rpcEnv: RpcEnv,",
    "line": 34
  }],
  "prId": 23706
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`: Unit =`",
    "commit": "7992091c9a45ae3f234fd85e13e0deb1a5f4282f",
    "createdAt": "2019-02-13T18:32:43Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.executor\n+\n+import java.net.URL\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkEnv}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.worker.WorkerWatcher\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.RpcEnv\n+import org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages.{RetrieveSparkAppConfig, SparkAppConfig}\n+import org.apache.spark.util.{Utils, YarnContainerInfoHelper}\n+\n+/**\n+ * Custom implementation of CoarseGrainedExecutorBackend for YARN resource manager.\n+ * This class extracts executor log URLs and executor attributes from system environment which\n+ * properties are available for container being set via YARN.\n+ */\n+private[spark] class YarnCoarseGrainedExecutorBackend(\n+    rpcEnv: RpcEnv,\n+    driverUrl: String,\n+    executorId: String,\n+    hostname: String,\n+    cores: Int,\n+    userClassPath: Seq[URL],\n+    env: SparkEnv)\n+  extends CoarseGrainedExecutorBackend(\n+    rpcEnv,\n+    driverUrl,\n+    executorId,\n+    hostname,\n+    cores,\n+    userClassPath,\n+    env) with Logging {\n+\n+  private lazy val hadoopConfiguration = SparkHadoopUtil.get.newConfiguration(env.conf)\n+\n+  override def extractLogUrls: Map[String, String] = {\n+    YarnContainerInfoHelper.getLogUrls(hadoopConfiguration, container = None)\n+      .getOrElse(Map())\n+  }\n+\n+  override def extractAttributes: Map[String, String] = {\n+    YarnContainerInfoHelper.getAttributes(hadoopConfiguration, container = None)\n+      .getOrElse(Map())\n+  }\n+}\n+\n+private[spark] object YarnCoarseGrainedExecutorBackend extends Logging {\n+\n+  def main(args: Array[String]) {"
  }],
  "prId": 23706
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Here I'm using `CoarseGrainedExecutorBackend.Arguments` instead of `Arguments` for clarity. Please let me know once we would want to use `Arguments` directly.",
    "commit": "7992091c9a45ae3f234fd85e13e0deb1a5f4282f",
    "createdAt": "2019-02-14T21:40:55Z",
    "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.executor\n+\n+import java.net.URL\n+\n+import org.apache.spark.SparkEnv\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.rpc.RpcEnv\n+import org.apache.spark.util.YarnContainerInfoHelper\n+\n+/**\n+ * Custom implementation of CoarseGrainedExecutorBackend for YARN resource manager.\n+ * This class extracts executor log URLs and executor attributes from system environment which\n+ * properties are available for container being set via YARN.\n+ */\n+private[spark] class YarnCoarseGrainedExecutorBackend(\n+    rpcEnv: RpcEnv,\n+    driverUrl: String,\n+    executorId: String,\n+    hostname: String,\n+    cores: Int,\n+    userClassPath: Seq[URL],\n+    env: SparkEnv)\n+  extends CoarseGrainedExecutorBackend(\n+    rpcEnv,\n+    driverUrl,\n+    executorId,\n+    hostname,\n+    cores,\n+    userClassPath,\n+    env) with Logging {\n+\n+  private lazy val hadoopConfiguration = SparkHadoopUtil.get.newConfiguration(env.conf)\n+\n+  override def extractLogUrls: Map[String, String] = {\n+    YarnContainerInfoHelper.getLogUrls(hadoopConfiguration, container = None)\n+      .getOrElse(Map())\n+  }\n+\n+  override def extractAttributes: Map[String, String] = {\n+    YarnContainerInfoHelper.getAttributes(hadoopConfiguration, container = None)\n+      .getOrElse(Map())\n+  }\n+}\n+\n+private[spark] object YarnCoarseGrainedExecutorBackend extends Logging {\n+\n+  def main(args: Array[String]): Unit = {\n+    val createFn: (RpcEnv, CoarseGrainedExecutorBackend.Arguments, SparkEnv) =>",
    "line": 66
  }],
  "prId": 23706
}]