[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This worried me a little bit. Because I'm pretty sure `ServiceLoader` will look at *both* files (this one and the one in core), and when running in YARN you'll end up with way too many providers.\r\n\r\nSo you should verify that behavior, and the best way to do it is to write a unit test.",
    "commit": "e32afeeac95883138751c060a3ebfaf309e3d22f",
    "createdAt": "2017-04-19T19:55:56Z",
    "diffHunk": "@@ -0,0 +1,3 @@\n+org.apache.spark.deploy.yarn.security.YARNHadoopFSCredentialProvider",
    "line": 1
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "Ah, yes.  This is a problem.  I'll write the unit test, and move the core META-INF to Mesos.  I was hoping for a general set of registered providers, but I guess each scheduler will need to register their own.",
    "commit": "e32afeeac95883138751c060a3ebfaf309e3d22f",
    "createdAt": "2017-04-20T22:00:02Z",
    "diffHunk": "@@ -0,0 +1,3 @@\n+org.apache.spark.deploy.yarn.security.YARNHadoopFSCredentialProvider",
    "line": 1
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> move the core META-INF to Mesos\r\n\r\nThat's not enough. Because in a real app (not unit tests), the mesos and yarn jars will both still exist, so both files will still be loaded.",
    "commit": "e32afeeac95883138751c060a3ebfaf309e3d22f",
    "createdAt": "2017-04-20T22:11:54Z",
    "diffHunk": "@@ -0,0 +1,3 @@\n+org.apache.spark.deploy.yarn.security.YARNHadoopFSCredentialProvider",
    "line": 1
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "Oh yea, I guess the standard Spark distributions are compiled with both profiles.  I created a separate `YARNHadoopFSCredentialProvider` to handle YARN's specific functionality (renewer, extra filesystems, etc.), but I guess I could do that through parameterization rather than a separate class, since it seems we can't have a YARN specific class through service loading.  How does that sound?",
    "commit": "e32afeeac95883138751c060a3ebfaf309e3d22f",
    "createdAt": "2017-04-20T22:26:00Z",
    "diffHunk": "@@ -0,0 +1,3 @@\n+org.apache.spark.deploy.yarn.security.YARNHadoopFSCredentialProvider",
    "line": 1
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> but I guess I could do that through parameterization\r\n\r\nThat would probably be better. You can see if using SparkHadoopUtil / YarnSparkHadoopUtil to handle the differences can help too.",
    "commit": "e32afeeac95883138751c060a3ebfaf309e3d22f",
    "createdAt": "2017-04-20T22:30:36Z",
    "diffHunk": "@@ -0,0 +1,3 @@\n+org.apache.spark.deploy.yarn.security.YARNHadoopFSCredentialProvider",
    "line": 1
  }],
  "prId": 17665
}]