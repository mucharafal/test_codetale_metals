[{
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "not used that I see, remove",
    "commit": "68c8925df66a2ada06cbbe7d7b008a376b233b36",
    "createdAt": "2017-01-23T14:33:01Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.mutable.{HashMap, HashSet, Set}\n+\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic\n+import org.apache.hadoop.net.DNSToSwitchMapping\n+import org.apache.hadoop.yarn.api.records._\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest"
  }],
  "prId": 16667
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "any particular reason for the 16 here?  I assume its just random selected that shows the issue but perhaps add in a comment.",
    "commit": "68c8925df66a2ada06cbbe7d7b008a376b233b36",
    "createdAt": "2017-01-23T14:41:08Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.mutable.{HashMap, HashSet, Set}\n+\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic\n+import org.apache.hadoop.net.DNSToSwitchMapping\n+import org.apache.hadoop.yarn.api.records._\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+import org.mockito.Mockito._\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+\n+class LocalityPlacementStrategySuite extends SparkFunSuite {\n+\n+  test(\"handle large number of containers and tasks (SPARK-18750)\") {\n+    // Run the test in a thread with a small stack size, since the original issue\n+    // surfaced as a StackOverflowError.\n+    var error: Throwable = null\n+\n+    val runnable = new Runnable() {\n+      override def run(): Unit = try {\n+        runTest()\n+      } catch {\n+        case e: Throwable => error = e\n+      }\n+    }\n+\n+    val thread = new Thread(new ThreadGroup(\"test\"), runnable, \"test-thread\", 32 * 1024)\n+    thread.start()\n+    thread.join()\n+\n+    assert(error === null)\n+  }\n+\n+  private def runTest(): Unit = {\n+    val yarnConf = new YarnConfiguration()\n+    yarnConf.setClass(\n+      CommonConfigurationKeysPublic.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY,\n+      classOf[MockResolver], classOf[DNSToSwitchMapping])\n+\n+    val resource = Resource.newInstance(8 * 1024, 4)\n+    val strategy = new LocalityPreferredContainerPlacementStrategy(new SparkConf(),\n+      yarnConf, resource)\n+\n+    val totalTasks = 32 * 1024\n+    val totalContainers = totalTasks / 16",
    "line": 68
  }],
  "prId": 16667
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "similar wouldn't hurt to have small description here for someone looking at it later",
    "commit": "68c8925df66a2ada06cbbe7d7b008a376b233b36",
    "createdAt": "2017-01-23T15:07:45Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import scala.collection.mutable.{HashMap, HashSet, Set}\n+\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic\n+import org.apache.hadoop.net.DNSToSwitchMapping\n+import org.apache.hadoop.yarn.api.records._\n+import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+import org.mockito.Mockito._\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+\n+class LocalityPlacementStrategySuite extends SparkFunSuite {\n+\n+  test(\"handle large number of containers and tasks (SPARK-18750)\") {\n+    // Run the test in a thread with a small stack size, since the original issue\n+    // surfaced as a StackOverflowError.\n+    var error: Throwable = null\n+\n+    val runnable = new Runnable() {\n+      override def run(): Unit = try {\n+        runTest()\n+      } catch {\n+        case e: Throwable => error = e\n+      }\n+    }\n+\n+    val thread = new Thread(new ThreadGroup(\"test\"), runnable, \"test-thread\", 32 * 1024)\n+    thread.start()\n+    thread.join()\n+\n+    assert(error === null)\n+  }\n+\n+  private def runTest(): Unit = {\n+    val yarnConf = new YarnConfiguration()\n+    yarnConf.setClass(\n+      CommonConfigurationKeysPublic.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY,\n+      classOf[MockResolver], classOf[DNSToSwitchMapping])\n+\n+    val resource = Resource.newInstance(8 * 1024, 4)\n+    val strategy = new LocalityPreferredContainerPlacementStrategy(new SparkConf(),\n+      yarnConf, resource)\n+\n+    val totalTasks = 32 * 1024\n+    val totalContainers = totalTasks / 16\n+    val totalHosts = totalContainers / 16\n+\n+    val mockId = mock(classOf[ContainerId])\n+    val hosts = (1 to totalHosts).map { i => (s\"host_$i\", totalTasks % i) }.toMap\n+    val containers = (1 to totalContainers).map { i => mockId }\n+    val count = containers.size / hosts.size / 2\n+\n+    val hostToContainerMap = new HashMap[String, Set[ContainerId]]()\n+    hosts.keys.take(hosts.size / 2).zipWithIndex.foreach { case (host, i) =>",
    "line": 77
  }],
  "prId": 16667
}]