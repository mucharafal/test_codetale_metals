[{
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "Add this class. otherwise:\r\n```\r\n[info] YarnClusterSuite:\r\n[info] org.apache.spark.deploy.yarn.YarnClusterSuite *** ABORTED *** (33 milliseconds)\r\n[info]   java.lang.NoClassDefFoundError: org/apache/hadoop/net/ServerSocketUtil\r\n[info]   at org.apache.hadoop.yarn.server.MiniYARNCluster.serviceInit(MiniYARNCluster.java:260)\r\n```\r\nI try to do it by maven, but failed. It seems that [`sbt-pom-reader` does not support `test-jar`](https://github.com/sbt/sbt-pom-reader/pull/#14) very well.:\r\n\r\n```xml\r\n    <dependency>\r\n      <groupId>org.apache.hadoop</groupId>\r\n      <artifactId>hadoop-common</artifactId>\r\n      <version>${hadoop.version}</version>\r\n      <type>test-jar</type>\r\n      <scope>test</scope>\r\n      <exclusions>\r\n        <exclusion>\r\n          <groupId>*</groupId>\r\n          <artifactId>*</artifactId>\r\n        </exclusion>\r\n      </exclusions>\r\n    </dependency>\r\n```",
    "commit": "49f0d8a49c1c75775d22e7c4117e854a9facbfa6",
    "createdAt": "2019-03-16T07:41:14Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*",
    "line": 1
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "We do have other test-jar imports; some use `type` and some `classifier`. Have you tried the latter? e.g. we have\r\n\r\n```\r\n    <dependency>\r\n      <groupId>org.apache.hadoop</groupId>\r\n      <artifactId>hadoop-yarn-server-tests</artifactId>\r\n      <classifier>tests</classifier>\r\n      <scope>test</scope>\r\n    </dependency>\r\n```",
    "commit": "49f0d8a49c1c75775d22e7c4117e854a9facbfa6",
    "createdAt": "2019-03-19T00:16:15Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*",
    "line": 1
  }, {
    "author": {
      "login": "wangyum"
    },
    "body": "Yes, I tried it, this can be successful on hadoop-3.2, but throws a compilation exception on hadoop-2.7(It seems exclude `hadoop-common`).\r\n```java\r\n[error] /Users/yumwang/SPARK-20845/spark/resource-managers/yarn/src/test/scala/org/apache/spark/deploy/yarn/ApplicationMasterSuite.scala:34: Class org.apache.hadoop.conf.Configuration not found - continuing with a stub.\r\n[error]     val yarnConf = new YarnConfiguration()\r\n[error] \r\n```",
    "commit": "49f0d8a49c1c75775d22e7c4117e854a9facbfa6",
    "createdAt": "2019-03-27T15:05:27Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*",
    "line": 1
  }],
  "prId": 24115
}]