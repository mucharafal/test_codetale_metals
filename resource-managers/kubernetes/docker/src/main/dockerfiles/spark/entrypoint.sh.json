[{
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "I think this is fine and what we want to do. But at some point we're going to want to make the API between spark submit and launched containers stable.\r\n\r\nUsing this as an example, if a user upgraded their spark-submit version to 3.0 but didn't upgrade the version of Spark in their docker image, the docker container's command will attempt to look up these old environment variables that are no longer being set by spark submit.\r\n\r\nWe should be thinking about making this contract stable from 3.0 onwards. For this coming release I think this is fine.",
    "commit": "0d755d6549c46332ee7fa54c335d5c6c19727671",
    "createdAt": "2018-11-02T18:59:30Z",
    "diffHunk": "@@ -96,22 +96,6 @@ case \"$SPARK_K8S_CMD\" in\n       \"$@\"\n     )\n     ;;\n-  driver-py)",
    "line": 4
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> if a user upgraded their spark-submit version to 3.0 but didn't upgrade the version of Spark in their docker image\r\n\r\nI don't think Spark really supports that in any case. It is expected that you're using the same version of Spark in the spark-submit side and on the other side, regardless of the cluster manager. e.g., imagine client mode in the scenario you're talking about.\r\n\r\nBut definitely, the contract here needs to be well defined (I've asked for this a long time ago and that's one of the reasons why k8s is still experimental).",
    "commit": "0d755d6549c46332ee7fa54c335d5c6c19727671",
    "createdAt": "2018-11-02T19:58:39Z",
    "diffHunk": "@@ -96,22 +96,6 @@ case \"$SPARK_K8S_CMD\" in\n       \"$@\"\n     )\n     ;;\n-  driver-py)",
    "line": 4
  }],
  "prId": 22897
}]