[{
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "bee -> been?",
    "commit": "635326a88a19e21f7644dbc8a149aa2dd1cb917c",
    "createdAt": "2019-07-30T05:45:12Z",
    "diffHunk": "@@ -134,14 +129,37 @@ private[spark] class KubernetesClusterSchedulerBackend(\n     super.getExecutorIds()\n   }\n \n-  override def doKillExecutors(executorIds: Seq[String]): Future[Boolean] = Future[Boolean] {\n-    kubernetesClient\n-      .pods()\n-      .withLabel(SPARK_APP_ID_LABEL, applicationId())\n-      .withLabel(SPARK_ROLE_LABEL, SPARK_POD_EXECUTOR_ROLE)\n-      .withLabelIn(SPARK_EXECUTOR_ID_LABEL, executorIds: _*)\n-      .delete()\n-    // Don't do anything else - let event handling from the Kubernetes API do the Spark changes\n+  override def doKillExecutors(executorIds: Seq[String]): Future[Boolean] = {\n+    executorIds.foreach { id =>\n+      removeExecutor(id, ExecutorKilled)\n+    }\n+\n+    // Give some time for the executors to shut themselves down, then forcefully kill any\n+    // remaining ones. This intentionally ignores the configuration about whether pods\n+    // should be deleted; only executors that shut down gracefully (and are then collected\n+    // by the ExecutorPodsLifecycleManager) will respect that configuration.\n+    val killTask = new Runnable() {\n+      override def run(): Unit = Utils.tryLogNonFatalError {\n+        val running = kubernetesClient\n+          .pods()\n+          .withField(\"status.phase\", \"Running\")\n+          .withLabel(SPARK_APP_ID_LABEL, applicationId())\n+          .withLabel(SPARK_ROLE_LABEL, SPARK_POD_EXECUTOR_ROLE)\n+          .withLabelIn(SPARK_EXECUTOR_ID_LABEL, executorIds: _*)\n+\n+        if (!running.list().getItems().isEmpty()) {\n+          logInfo(s\"Forcefully deleting ${running.list().getItems().size()} pods \" +\n+            s\"(out of ${executorIds.size}) that are still running after graceful shutdown period.\")\n+          running.delete()\n+        }\n+      }\n+    }\n+    executorService.schedule(killTask, conf.get(KUBERNETES_DYN_ALLOC_KILL_GRACE_PERIOD),\n+      TimeUnit.MILLISECONDS)\n+\n+    // Return an immediate success, since we can't confirm or deny that executors have bee"
  }],
  "prId": 25236
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "this seems bad.  If we get the response wrong, then the ExecutorAllocationManager will mistakenly update its internal state to think the executors have been removed, when they haven't been:\r\n\r\nhttps://github.com/apache/spark/blob/b29829e2abdebdf6fa9dd0a4a4cf4c9d676ee82d/core/src/main/scala/org/apache/spark/ExecutorAllocationManager.scala#L448-L455\r\n\r\nwhich means we're expecting that call to kubernetes to delete the pods to be foolproof.\r\n\r\nWhy is it so bad to wait here?  Is it because we are holding locks when making this call in CoarseGrainedSchedulerBackend?  could that be avoided?",
    "commit": "635326a88a19e21f7644dbc8a149aa2dd1cb917c",
    "createdAt": "2019-08-01T15:01:36Z",
    "diffHunk": "@@ -134,14 +129,37 @@ private[spark] class KubernetesClusterSchedulerBackend(\n     super.getExecutorIds()\n   }\n \n-  override def doKillExecutors(executorIds: Seq[String]): Future[Boolean] = Future[Boolean] {\n-    kubernetesClient\n-      .pods()\n-      .withLabel(SPARK_APP_ID_LABEL, applicationId())\n-      .withLabel(SPARK_ROLE_LABEL, SPARK_POD_EXECUTOR_ROLE)\n-      .withLabelIn(SPARK_EXECUTOR_ID_LABEL, executorIds: _*)\n-      .delete()\n-    // Don't do anything else - let event handling from the Kubernetes API do the Spark changes\n+  override def doKillExecutors(executorIds: Seq[String]): Future[Boolean] = {\n+    executorIds.foreach { id =>\n+      removeExecutor(id, ExecutorKilled)\n+    }\n+\n+    // Give some time for the executors to shut themselves down, then forcefully kill any\n+    // remaining ones. This intentionally ignores the configuration about whether pods\n+    // should be deleted; only executors that shut down gracefully (and are then collected\n+    // by the ExecutorPodsLifecycleManager) will respect that configuration.\n+    val killTask = new Runnable() {\n+      override def run(): Unit = Utils.tryLogNonFatalError {\n+        val running = kubernetesClient\n+          .pods()\n+          .withField(\"status.phase\", \"Running\")\n+          .withLabel(SPARK_APP_ID_LABEL, applicationId())\n+          .withLabel(SPARK_ROLE_LABEL, SPARK_POD_EXECUTOR_ROLE)\n+          .withLabelIn(SPARK_EXECUTOR_ID_LABEL, executorIds: _*)\n+\n+        if (!running.list().getItems().isEmpty()) {\n+          logInfo(s\"Forcefully deleting ${running.list().getItems().size()} pods \" +\n+            s\"(out of ${executorIds.size}) that are still running after graceful shutdown period.\")\n+          running.delete()\n+        }\n+      }\n+    }\n+    executorService.schedule(killTask, conf.get(KUBERNETES_DYN_ALLOC_KILL_GRACE_PERIOD),\n+      TimeUnit.MILLISECONDS)\n+\n+    // Return an immediate success, since we can't confirm or deny that executors have been\n+    // actually shut down without waiting too long and blocking the allocation thread.\n+    Future.successful(true)",
    "line": 140
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I added a longer comment explaining this.\r\n\r\nThe gist is:\r\n- it's bad to wait because it blocks the EAM thread (in this case for a really long time)\r\n- it's ok to return \"true\" because these executors will all die eventually, whether because of the shutdown message or because of the explicit kill.\r\n\r\nThe return value, to the best of my understanding, is not meant to say \"yes all executors have been killed\", but rather \"an attempt has been made to remove all of these executors, and they'll die eventually\".\r\n\r\n(Otherwise there would be no need for the EAM to track which executors are pending removal, since it would know immediately from this return value.)",
    "commit": "635326a88a19e21f7644dbc8a149aa2dd1cb917c",
    "createdAt": "2019-08-05T18:23:28Z",
    "diffHunk": "@@ -134,14 +129,37 @@ private[spark] class KubernetesClusterSchedulerBackend(\n     super.getExecutorIds()\n   }\n \n-  override def doKillExecutors(executorIds: Seq[String]): Future[Boolean] = Future[Boolean] {\n-    kubernetesClient\n-      .pods()\n-      .withLabel(SPARK_APP_ID_LABEL, applicationId())\n-      .withLabel(SPARK_ROLE_LABEL, SPARK_POD_EXECUTOR_ROLE)\n-      .withLabelIn(SPARK_EXECUTOR_ID_LABEL, executorIds: _*)\n-      .delete()\n-    // Don't do anything else - let event handling from the Kubernetes API do the Spark changes\n+  override def doKillExecutors(executorIds: Seq[String]): Future[Boolean] = {\n+    executorIds.foreach { id =>\n+      removeExecutor(id, ExecutorKilled)\n+    }\n+\n+    // Give some time for the executors to shut themselves down, then forcefully kill any\n+    // remaining ones. This intentionally ignores the configuration about whether pods\n+    // should be deleted; only executors that shut down gracefully (and are then collected\n+    // by the ExecutorPodsLifecycleManager) will respect that configuration.\n+    val killTask = new Runnable() {\n+      override def run(): Unit = Utils.tryLogNonFatalError {\n+        val running = kubernetesClient\n+          .pods()\n+          .withField(\"status.phase\", \"Running\")\n+          .withLabel(SPARK_APP_ID_LABEL, applicationId())\n+          .withLabel(SPARK_ROLE_LABEL, SPARK_POD_EXECUTOR_ROLE)\n+          .withLabelIn(SPARK_EXECUTOR_ID_LABEL, executorIds: _*)\n+\n+        if (!running.list().getItems().isEmpty()) {\n+          logInfo(s\"Forcefully deleting ${running.list().getItems().size()} pods \" +\n+            s\"(out of ${executorIds.size}) that are still running after graceful shutdown period.\")\n+          running.delete()\n+        }\n+      }\n+    }\n+    executorService.schedule(killTask, conf.get(KUBERNETES_DYN_ALLOC_KILL_GRACE_PERIOD),\n+      TimeUnit.MILLISECONDS)\n+\n+    // Return an immediate success, since we can't confirm or deny that executors have been\n+    // actually shut down without waiting too long and blocking the allocation thread.\n+    Future.successful(true)",
    "line": 140
  }, {
    "author": {
      "login": "squito"
    },
    "body": "ok, thanks, I buy that explanation",
    "commit": "635326a88a19e21f7644dbc8a149aa2dd1cb917c",
    "createdAt": "2019-08-06T18:42:43Z",
    "diffHunk": "@@ -134,14 +129,37 @@ private[spark] class KubernetesClusterSchedulerBackend(\n     super.getExecutorIds()\n   }\n \n-  override def doKillExecutors(executorIds: Seq[String]): Future[Boolean] = Future[Boolean] {\n-    kubernetesClient\n-      .pods()\n-      .withLabel(SPARK_APP_ID_LABEL, applicationId())\n-      .withLabel(SPARK_ROLE_LABEL, SPARK_POD_EXECUTOR_ROLE)\n-      .withLabelIn(SPARK_EXECUTOR_ID_LABEL, executorIds: _*)\n-      .delete()\n-    // Don't do anything else - let event handling from the Kubernetes API do the Spark changes\n+  override def doKillExecutors(executorIds: Seq[String]): Future[Boolean] = {\n+    executorIds.foreach { id =>\n+      removeExecutor(id, ExecutorKilled)\n+    }\n+\n+    // Give some time for the executors to shut themselves down, then forcefully kill any\n+    // remaining ones. This intentionally ignores the configuration about whether pods\n+    // should be deleted; only executors that shut down gracefully (and are then collected\n+    // by the ExecutorPodsLifecycleManager) will respect that configuration.\n+    val killTask = new Runnable() {\n+      override def run(): Unit = Utils.tryLogNonFatalError {\n+        val running = kubernetesClient\n+          .pods()\n+          .withField(\"status.phase\", \"Running\")\n+          .withLabel(SPARK_APP_ID_LABEL, applicationId())\n+          .withLabel(SPARK_ROLE_LABEL, SPARK_POD_EXECUTOR_ROLE)\n+          .withLabelIn(SPARK_EXECUTOR_ID_LABEL, executorIds: _*)\n+\n+        if (!running.list().getItems().isEmpty()) {\n+          logInfo(s\"Forcefully deleting ${running.list().getItems().size()} pods \" +\n+            s\"(out of ${executorIds.size}) that are still running after graceful shutdown period.\")\n+          running.delete()\n+        }\n+      }\n+    }\n+    executorService.schedule(killTask, conf.get(KUBERNETES_DYN_ALLOC_KILL_GRACE_PERIOD),\n+      TimeUnit.MILLISECONDS)\n+\n+    // Return an immediate success, since we can't confirm or deny that executors have been\n+    // actually shut down without waiting too long and blocking the allocation thread.\n+    Future.successful(true)",
    "line": 140
  }],
  "prId": 25236
}]