[{
  "comments": [{
    "author": {
      "login": "tnachen"
    },
    "body": "Why do we need a separate conf prefix as well?",
    "commit": "ab992ca6f0374e057d865bafb11de7f3ccae2e10",
    "createdAt": "2018-07-04T06:34:50Z",
    "diffHunk": "@@ -18,43 +18,68 @@ package org.apache.spark.scheduler.cluster.k8s\n \n import java.io.File\n \n-import io.fabric8.kubernetes.client.Config\n+import io.fabric8.kubernetes.client.{Config, KubernetesClient}\n \n-import org.apache.spark.{SparkContext, SparkException}\n+import org.apache.spark.{SparkContext, SparkConf}\n import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n import org.apache.spark.deploy.k8s.Config._\n import org.apache.spark.deploy.k8s.Constants._\n import org.apache.spark.internal.Logging\n import org.apache.spark.scheduler.{ExternalClusterManager, SchedulerBackend, TaskScheduler, TaskSchedulerImpl}\n import org.apache.spark.util.ThreadUtils\n \n-private[spark] class KubernetesClusterManager extends ExternalClusterManager with Logging {\n+trait ManagerSpecificHandlers {\n+   def createKubernetesClient(sparkConf: SparkConf): KubernetesClient\n+ }\n \n-  override def canCreate(masterURL: String): Boolean = masterURL.startsWith(\"k8s\")\n+private[spark] class KubernetesClusterManager extends ExternalClusterManager\n+  with ManagerSpecificHandlers with Logging {\n \n-  override def createTaskScheduler(sc: SparkContext, masterURL: String): TaskScheduler = {\n-    if (masterURL.startsWith(\"k8s\") &&\n-      sc.deployMode == \"client\" &&\n-      !sc.conf.get(KUBERNETES_DRIVER_SUBMIT_CHECK).getOrElse(false)) {\n-      throw new SparkException(\"Client mode is currently not supported for Kubernetes.\")\n+ class InClusterHandlers extends ManagerSpecificHandlers {\n+   override def createKubernetesClient(sparkConf: SparkConf): KubernetesClient =\n+       SparkKubernetesClientFactory.createKubernetesClient(\n+           KUBERNETES_MASTER_INTERNAL_URL,\n+           Some(sparkConf.get(KUBERNETES_NAMESPACE)),\n+           APISERVER_AUTH_DRIVER_MOUNTED_CONF_PREFIX,"
  }, {
    "author": {
      "login": "echarles"
    },
    "body": "just took what was existing. will double check to ensure latest merge does not diverge.",
    "commit": "ab992ca6f0374e057d865bafb11de7f3ccae2e10",
    "createdAt": "2018-07-10T04:40:43Z",
    "diffHunk": "@@ -18,43 +18,68 @@ package org.apache.spark.scheduler.cluster.k8s\n \n import java.io.File\n \n-import io.fabric8.kubernetes.client.Config\n+import io.fabric8.kubernetes.client.{Config, KubernetesClient}\n \n-import org.apache.spark.{SparkContext, SparkException}\n+import org.apache.spark.{SparkContext, SparkConf}\n import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n import org.apache.spark.deploy.k8s.Config._\n import org.apache.spark.deploy.k8s.Constants._\n import org.apache.spark.internal.Logging\n import org.apache.spark.scheduler.{ExternalClusterManager, SchedulerBackend, TaskScheduler, TaskSchedulerImpl}\n import org.apache.spark.util.ThreadUtils\n \n-private[spark] class KubernetesClusterManager extends ExternalClusterManager with Logging {\n+trait ManagerSpecificHandlers {\n+   def createKubernetesClient(sparkConf: SparkConf): KubernetesClient\n+ }\n \n-  override def canCreate(masterURL: String): Boolean = masterURL.startsWith(\"k8s\")\n+private[spark] class KubernetesClusterManager extends ExternalClusterManager\n+  with ManagerSpecificHandlers with Logging {\n \n-  override def createTaskScheduler(sc: SparkContext, masterURL: String): TaskScheduler = {\n-    if (masterURL.startsWith(\"k8s\") &&\n-      sc.deployMode == \"client\" &&\n-      !sc.conf.get(KUBERNETES_DRIVER_SUBMIT_CHECK).getOrElse(false)) {\n-      throw new SparkException(\"Client mode is currently not supported for Kubernetes.\")\n+ class InClusterHandlers extends ManagerSpecificHandlers {\n+   override def createKubernetesClient(sparkConf: SparkConf): KubernetesClient =\n+       SparkKubernetesClientFactory.createKubernetesClient(\n+           KUBERNETES_MASTER_INTERNAL_URL,\n+           Some(sparkConf.get(KUBERNETES_NAMESPACE)),\n+           APISERVER_AUTH_DRIVER_MOUNTED_CONF_PREFIX,"
  }],
  "prId": 20451
}, {
  "comments": [{
    "author": {
      "login": "liyinan926"
    },
    "body": "The name of this prefix `spark.kubernetes.authenticate.driver.mounted` sounds weird in this case given that the client is running outside the cluster. BTW: can we alternatively use the config at `$HOME//.kube/config` to build a kubernetes client instead? I think this is a common approach for building clients outside a cluster.",
    "commit": "ab992ca6f0374e057d865bafb11de7f3ccae2e10",
    "createdAt": "2018-07-10T22:12:28Z",
    "diffHunk": "@@ -20,41 +20,65 @@ import java.io.File\n import java.util.concurrent.TimeUnit\n \n import com.google.common.cache.CacheBuilder\n-import io.fabric8.kubernetes.client.Config\n-\n-import org.apache.spark.{SparkContext, SparkException}\n-import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import io.fabric8.kubernetes.client.{Config, KubernetesClient}\n+import org.apache.spark.{SparkConf, SparkContext, SparkException}\n+import org.apache.spark.deploy.k8s.SparkKubernetesClientFactory\n import org.apache.spark.deploy.k8s.Config._\n import org.apache.spark.deploy.k8s.Constants._\n import org.apache.spark.internal.Logging\n import org.apache.spark.scheduler.{ExternalClusterManager, SchedulerBackend, TaskScheduler, TaskSchedulerImpl}\n import org.apache.spark.util.{SystemClock, ThreadUtils}\n \n-private[spark] class KubernetesClusterManager extends ExternalClusterManager with Logging {\n+trait ManagerSpecificHandlers {\n+  def createKubernetesClient(sparkConf: SparkConf): KubernetesClient\n+}\n \n-  override def canCreate(masterURL: String): Boolean = masterURL.startsWith(\"k8s\")\n+private[spark] class KubernetesClusterManager extends ExternalClusterManager\n+  with ManagerSpecificHandlers with Logging {\n \n-  override def createTaskScheduler(sc: SparkContext, masterURL: String): TaskScheduler = {\n-    if (masterURL.startsWith(\"k8s\") &&\n-      sc.deployMode == \"client\" &&\n-      !sc.conf.get(KUBERNETES_DRIVER_SUBMIT_CHECK).getOrElse(false)) {\n-      throw new SparkException(\"Client mode is currently not supported for Kubernetes.\")\n+  class InClusterHandlers extends ManagerSpecificHandlers {\n+    override def createKubernetesClient(sparkConf: SparkConf): KubernetesClient =\n+      SparkKubernetesClientFactory.createKubernetesClient(\n+        KUBERNETES_MASTER_INTERNAL_URL,\n+        Some(sparkConf.get(KUBERNETES_NAMESPACE)),\n+        KUBERNETES_AUTH_DRIVER_MOUNTED_CONF_PREFIX,\n+        sparkConf,\n+        Some(new File(Config.KUBERNETES_SERVICE_ACCOUNT_TOKEN_PATH)),\n+        Some(new File(Config.KUBERNETES_SERVICE_ACCOUNT_CA_CRT_PATH)))\n+  }\n+\n+  class OutClusterHandlers extends ManagerSpecificHandlers {\n+    override def createKubernetesClient(sparkConf: SparkConf): KubernetesClient =\n+      SparkKubernetesClientFactory.createKubernetesClient(\n+        sparkConf.get(\"spark.master\").replace(\"k8s://\", \"\"),\n+        Some(sparkConf.get(KUBERNETES_NAMESPACE)),\n+        KUBERNETES_AUTH_DRIVER_MOUNTED_CONF_PREFIX,",
    "line": 47
  }, {
    "author": {
      "login": "echarles"
    },
    "body": "the call to `createKubernetesClient` is not used in two different ways: \r\n\r\n+ `KUBERNETES_AUTH_DRIVER_MOUNTED_CONF_PREFIX` is used in `KubernetesClusterManager`\r\n+ `KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX` is used in `KubernetesClientApplication`\r\n\r\nI would favor the second and remove the first.\r\n\r\nFor the config place, I remember that the fabric8 k8s client does also some inspection to see if it is in or out cluster, and loads the config form the default place (depending the case), with possiblity to specify other places for the cert, token... (this is what we give as property to the end-user).",
    "commit": "ab992ca6f0374e057d865bafb11de7f3ccae2e10",
    "createdAt": "2018-07-11T17:42:47Z",
    "diffHunk": "@@ -20,41 +20,65 @@ import java.io.File\n import java.util.concurrent.TimeUnit\n \n import com.google.common.cache.CacheBuilder\n-import io.fabric8.kubernetes.client.Config\n-\n-import org.apache.spark.{SparkContext, SparkException}\n-import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import io.fabric8.kubernetes.client.{Config, KubernetesClient}\n+import org.apache.spark.{SparkConf, SparkContext, SparkException}\n+import org.apache.spark.deploy.k8s.SparkKubernetesClientFactory\n import org.apache.spark.deploy.k8s.Config._\n import org.apache.spark.deploy.k8s.Constants._\n import org.apache.spark.internal.Logging\n import org.apache.spark.scheduler.{ExternalClusterManager, SchedulerBackend, TaskScheduler, TaskSchedulerImpl}\n import org.apache.spark.util.{SystemClock, ThreadUtils}\n \n-private[spark] class KubernetesClusterManager extends ExternalClusterManager with Logging {\n+trait ManagerSpecificHandlers {\n+  def createKubernetesClient(sparkConf: SparkConf): KubernetesClient\n+}\n \n-  override def canCreate(masterURL: String): Boolean = masterURL.startsWith(\"k8s\")\n+private[spark] class KubernetesClusterManager extends ExternalClusterManager\n+  with ManagerSpecificHandlers with Logging {\n \n-  override def createTaskScheduler(sc: SparkContext, masterURL: String): TaskScheduler = {\n-    if (masterURL.startsWith(\"k8s\") &&\n-      sc.deployMode == \"client\" &&\n-      !sc.conf.get(KUBERNETES_DRIVER_SUBMIT_CHECK).getOrElse(false)) {\n-      throw new SparkException(\"Client mode is currently not supported for Kubernetes.\")\n+  class InClusterHandlers extends ManagerSpecificHandlers {\n+    override def createKubernetesClient(sparkConf: SparkConf): KubernetesClient =\n+      SparkKubernetesClientFactory.createKubernetesClient(\n+        KUBERNETES_MASTER_INTERNAL_URL,\n+        Some(sparkConf.get(KUBERNETES_NAMESPACE)),\n+        KUBERNETES_AUTH_DRIVER_MOUNTED_CONF_PREFIX,\n+        sparkConf,\n+        Some(new File(Config.KUBERNETES_SERVICE_ACCOUNT_TOKEN_PATH)),\n+        Some(new File(Config.KUBERNETES_SERVICE_ACCOUNT_CA_CRT_PATH)))\n+  }\n+\n+  class OutClusterHandlers extends ManagerSpecificHandlers {\n+    override def createKubernetesClient(sparkConf: SparkConf): KubernetesClient =\n+      SparkKubernetesClientFactory.createKubernetesClient(\n+        sparkConf.get(\"spark.master\").replace(\"k8s://\", \"\"),\n+        Some(sparkConf.get(KUBERNETES_NAMESPACE)),\n+        KUBERNETES_AUTH_DRIVER_MOUNTED_CONF_PREFIX,",
    "line": 47
  }],
  "prId": 20451
}]