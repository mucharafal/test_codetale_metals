[{
  "comments": [{
    "author": {
      "login": "liyinan926"
    },
    "body": "The Scaladoc should not mention hostPath as this function is not hostPath exclusively.",
    "commit": "f482dfc370bace0c5315a2514604be2965bcbbaf",
    "createdAt": "2018-05-03T23:09:31Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.mutable.HashMap\n+\n+import io.fabric8.kubernetes.api.model._\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+\n+private[spark] object KubernetesVolumeUtils {\n+\n+  /**\n+   * Given hostPath volume specs, add volume to pod and volume mount to container.\n+   *\n+   * @param pod original specification of the pod\n+   * @param container original specification of the container\n+   * @param sparkConf Spark configuration\n+   * @param prefix the prefix for volume configuration\n+   * @return a tuple of (pod with the volume(s) added, container with mount(s) added)\n+   */\n+  def addVolumes(",
    "line": 37
  }],
  "prId": 21095
}, {
  "comments": [{
    "author": {
      "login": "liyinan926"
    },
    "body": "The `case` line should be merged into the previous line according to the Spark code convention, e.g., `volumes.foreach { case (name, spec) =>`. ",
    "commit": "f482dfc370bace0c5315a2514604be2965bcbbaf",
    "createdAt": "2018-05-03T23:13:08Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.mutable.HashMap\n+\n+import io.fabric8.kubernetes.api.model._\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+\n+private[spark] object KubernetesVolumeUtils {\n+\n+  /**\n+   * Given hostPath volume specs, add volume to pod and volume mount to container.\n+   *\n+   * @param pod original specification of the pod\n+   * @param container original specification of the container\n+   * @param sparkConf Spark configuration\n+   * @param prefix the prefix for volume configuration\n+   * @return a tuple of (pod with the volume(s) added, container with mount(s) added)\n+   */\n+  def addVolumes(\n+      pod: Pod,\n+      container: Container,\n+      sparkConf: SparkConf,\n+      prefix : String): (Pod, Container) = {\n+    val hostPathVolumeSpecs = parseHostPathVolumesWithPrefix(sparkConf, prefix)\n+    addHostPathVolumes(pod, container, hostPathVolumeSpecs)\n+  }\n+\n+  /**\n+   * Extract Spark volume configuration properties with a given name prefix.\n+   *\n+   * @param sparkConf Spark configuration\n+   * @param prefix the given property name prefix\n+   * @param volumeTypeKey the given property name prefix\n+   * @return a Map storing with volume name as key and spec as value\n+   */\n+  def parseVolumesWithPrefix(\n+      sparkConf: SparkConf,\n+      prefix: String,\n+      volumeTypeKey: String): Map[String, KubernetesVolumeSpec] = {\n+    val volumes = HashMap[String, KubernetesVolumeSpec]()\n+    val properties = sparkConf.getAllWithPrefix(s\"$prefix$volumeTypeKey.\").toList\n+    // Extract volume names\n+    properties.foreach {\n+      k =>\n+        val keys = k._1.split(\"\\\\.\")\n+        if (keys.nonEmpty && !volumes.contains(keys(0))) {\n+          volumes.update(keys(0), KubernetesVolumeSpec.emptySpec())\n+        }\n+    }\n+    // Populate spec\n+    volumes.foreach {\n+      case (name, spec) =>",
    "line": 70
  }],
  "prId": 21095
}, {
  "comments": [{
    "author": {
      "login": "liyinan926"
    },
    "body": "Ditto.",
    "commit": "f482dfc370bace0c5315a2514604be2965bcbbaf",
    "createdAt": "2018-05-03T23:13:16Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.mutable.HashMap\n+\n+import io.fabric8.kubernetes.api.model._\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+\n+private[spark] object KubernetesVolumeUtils {\n+\n+  /**\n+   * Given hostPath volume specs, add volume to pod and volume mount to container.\n+   *\n+   * @param pod original specification of the pod\n+   * @param container original specification of the container\n+   * @param sparkConf Spark configuration\n+   * @param prefix the prefix for volume configuration\n+   * @return a tuple of (pod with the volume(s) added, container with mount(s) added)\n+   */\n+  def addVolumes(\n+      pod: Pod,\n+      container: Container,\n+      sparkConf: SparkConf,\n+      prefix : String): (Pod, Container) = {\n+    val hostPathVolumeSpecs = parseHostPathVolumesWithPrefix(sparkConf, prefix)\n+    addHostPathVolumes(pod, container, hostPathVolumeSpecs)\n+  }\n+\n+  /**\n+   * Extract Spark volume configuration properties with a given name prefix.\n+   *\n+   * @param sparkConf Spark configuration\n+   * @param prefix the given property name prefix\n+   * @param volumeTypeKey the given property name prefix\n+   * @return a Map storing with volume name as key and spec as value\n+   */\n+  def parseVolumesWithPrefix(\n+      sparkConf: SparkConf,\n+      prefix: String,\n+      volumeTypeKey: String): Map[String, KubernetesVolumeSpec] = {\n+    val volumes = HashMap[String, KubernetesVolumeSpec]()\n+    val properties = sparkConf.getAllWithPrefix(s\"$prefix$volumeTypeKey.\").toList\n+    // Extract volume names\n+    properties.foreach {\n+      k =>\n+        val keys = k._1.split(\"\\\\.\")\n+        if (keys.nonEmpty && !volumes.contains(keys(0))) {\n+          volumes.update(keys(0), KubernetesVolumeSpec.emptySpec())\n+        }\n+    }\n+    // Populate spec\n+    volumes.foreach {\n+      case (name, spec) =>\n+        properties.foreach {\n+          k =>",
    "line": 72
  }],
  "prId": 21095
}, {
  "comments": [{
    "author": {
      "login": "liyinan926"
    },
    "body": "Ditto.",
    "commit": "f482dfc370bace0c5315a2514604be2965bcbbaf",
    "createdAt": "2018-05-03T23:14:01Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.mutable.HashMap\n+\n+import io.fabric8.kubernetes.api.model._\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+\n+private[spark] object KubernetesVolumeUtils {\n+\n+  /**\n+   * Given hostPath volume specs, add volume to pod and volume mount to container.\n+   *\n+   * @param pod original specification of the pod\n+   * @param container original specification of the container\n+   * @param sparkConf Spark configuration\n+   * @param prefix the prefix for volume configuration\n+   * @return a tuple of (pod with the volume(s) added, container with mount(s) added)\n+   */\n+  def addVolumes(\n+      pod: Pod,\n+      container: Container,\n+      sparkConf: SparkConf,\n+      prefix : String): (Pod, Container) = {\n+    val hostPathVolumeSpecs = parseHostPathVolumesWithPrefix(sparkConf, prefix)\n+    addHostPathVolumes(pod, container, hostPathVolumeSpecs)\n+  }\n+\n+  /**\n+   * Extract Spark volume configuration properties with a given name prefix.\n+   *\n+   * @param sparkConf Spark configuration\n+   * @param prefix the given property name prefix\n+   * @param volumeTypeKey the given property name prefix\n+   * @return a Map storing with volume name as key and spec as value\n+   */\n+  def parseVolumesWithPrefix(\n+      sparkConf: SparkConf,\n+      prefix: String,\n+      volumeTypeKey: String): Map[String, KubernetesVolumeSpec] = {\n+    val volumes = HashMap[String, KubernetesVolumeSpec]()\n+    val properties = sparkConf.getAllWithPrefix(s\"$prefix$volumeTypeKey.\").toList\n+    // Extract volume names\n+    properties.foreach {\n+      k =>\n+        val keys = k._1.split(\"\\\\.\")\n+        if (keys.nonEmpty && !volumes.contains(keys(0))) {\n+          volumes.update(keys(0), KubernetesVolumeSpec.emptySpec())\n+        }\n+    }\n+    // Populate spec\n+    volumes.foreach {\n+      case (name, spec) =>\n+        properties.foreach {\n+          k =>\n+            k._1.split(\"\\\\.\") match {\n+              case Array(`name`, KUBERNETES_VOLUMES_MOUNT_KEY, KUBERNETES_VOLUMES_PATH_KEY) =>\n+                spec.mountPath = Some(k._2)\n+              case Array(`name`, KUBERNETES_VOLUMES_MOUNT_KEY, KUBERNETES_VOLUMES_READONLY_KEY) =>\n+                spec.mountReadOnly = Some(k._2.toBoolean)\n+              case Array(`name`, KUBERNETES_VOLUMES_OPTIONS_KEY, option) =>\n+                spec.optionsSpec.update(option, k._2)\n+              case _ =>\n+                None\n+            }\n+        }\n+    }\n+    volumes.toMap\n+  }\n+\n+  /**\n+   * Extract Spark hostPath volume configuration properties with a given name prefix and\n+   * return the result as a Map.\n+   *\n+   * @param sparkConf Spark configuration\n+   * @param prefix the given property name prefix\n+   * @return a Map storing with volume name as key and spec as value\n+   */\n+  def parseHostPathVolumesWithPrefix(\n+      sparkConf: SparkConf,\n+      prefix: String): Map[String, KubernetesVolumeSpec] = {\n+    parseVolumesWithPrefix(sparkConf, prefix, KUBERNETES_VOLUMES_HOSTPATH_KEY)\n+  }\n+\n+  /**\n+   * Given hostPath volume specs, add volume to pod and volume mount to container.\n+   *\n+   * @param pod original specification of the pod\n+   * @param container original specification of the container\n+   * @param volumes list of named volume specs\n+   * @return a tuple of (pod with the volume(s) added, container with mount(s) added)\n+   */\n+  def addHostPathVolumes(\n+      pod: Pod,\n+      container: Container,\n+      volumes: Map[String, KubernetesVolumeSpec]): (Pod, Container) = {\n+    val podBuilder = new PodBuilder(pod).editOrNewSpec()\n+    val containerBuilder = new ContainerBuilder(container)\n+    volumes foreach {\n+      case (name, spec) =>",
    "line": 117
  }],
  "prId": 21095
}, {
  "comments": [{
    "author": {
      "login": "liyinan926"
    },
    "body": "Looks like this `if` block can be combined with the previous `if` block, e.g., `if (spec.mountPath.isDefined && spec.optionsSpec.contains(KUBERNETES_VOLUMES_PATH_KEY)) {...}`.",
    "commit": "f482dfc370bace0c5315a2514604be2965bcbbaf",
    "createdAt": "2018-05-03T23:16:36Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.mutable.HashMap\n+\n+import io.fabric8.kubernetes.api.model._\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+\n+private[spark] object KubernetesVolumeUtils {\n+\n+  /**\n+   * Given hostPath volume specs, add volume to pod and volume mount to container.\n+   *\n+   * @param pod original specification of the pod\n+   * @param container original specification of the container\n+   * @param sparkConf Spark configuration\n+   * @param prefix the prefix for volume configuration\n+   * @return a tuple of (pod with the volume(s) added, container with mount(s) added)\n+   */\n+  def addVolumes(\n+      pod: Pod,\n+      container: Container,\n+      sparkConf: SparkConf,\n+      prefix : String): (Pod, Container) = {\n+    val hostPathVolumeSpecs = parseHostPathVolumesWithPrefix(sparkConf, prefix)\n+    addHostPathVolumes(pod, container, hostPathVolumeSpecs)\n+  }\n+\n+  /**\n+   * Extract Spark volume configuration properties with a given name prefix.\n+   *\n+   * @param sparkConf Spark configuration\n+   * @param prefix the given property name prefix\n+   * @param volumeTypeKey the given property name prefix\n+   * @return a Map storing with volume name as key and spec as value\n+   */\n+  def parseVolumesWithPrefix(\n+      sparkConf: SparkConf,\n+      prefix: String,\n+      volumeTypeKey: String): Map[String, KubernetesVolumeSpec] = {\n+    val volumes = HashMap[String, KubernetesVolumeSpec]()\n+    val properties = sparkConf.getAllWithPrefix(s\"$prefix$volumeTypeKey.\").toList\n+    // Extract volume names\n+    properties.foreach {\n+      k =>\n+        val keys = k._1.split(\"\\\\.\")\n+        if (keys.nonEmpty && !volumes.contains(keys(0))) {\n+          volumes.update(keys(0), KubernetesVolumeSpec.emptySpec())\n+        }\n+    }\n+    // Populate spec\n+    volumes.foreach {\n+      case (name, spec) =>\n+        properties.foreach {\n+          k =>\n+            k._1.split(\"\\\\.\") match {\n+              case Array(`name`, KUBERNETES_VOLUMES_MOUNT_KEY, KUBERNETES_VOLUMES_PATH_KEY) =>\n+                spec.mountPath = Some(k._2)\n+              case Array(`name`, KUBERNETES_VOLUMES_MOUNT_KEY, KUBERNETES_VOLUMES_READONLY_KEY) =>\n+                spec.mountReadOnly = Some(k._2.toBoolean)\n+              case Array(`name`, KUBERNETES_VOLUMES_OPTIONS_KEY, option) =>\n+                spec.optionsSpec.update(option, k._2)\n+              case _ =>\n+                None\n+            }\n+        }\n+    }\n+    volumes.toMap\n+  }\n+\n+  /**\n+   * Extract Spark hostPath volume configuration properties with a given name prefix and\n+   * return the result as a Map.\n+   *\n+   * @param sparkConf Spark configuration\n+   * @param prefix the given property name prefix\n+   * @return a Map storing with volume name as key and spec as value\n+   */\n+  def parseHostPathVolumesWithPrefix(\n+      sparkConf: SparkConf,\n+      prefix: String): Map[String, KubernetesVolumeSpec] = {\n+    parseVolumesWithPrefix(sparkConf, prefix, KUBERNETES_VOLUMES_HOSTPATH_KEY)\n+  }\n+\n+  /**\n+   * Given hostPath volume specs, add volume to pod and volume mount to container.\n+   *\n+   * @param pod original specification of the pod\n+   * @param container original specification of the container\n+   * @param volumes list of named volume specs\n+   * @return a tuple of (pod with the volume(s) added, container with mount(s) added)\n+   */\n+  def addHostPathVolumes(\n+      pod: Pod,\n+      container: Container,\n+      volumes: Map[String, KubernetesVolumeSpec]): (Pod, Container) = {\n+    val podBuilder = new PodBuilder(pod).editOrNewSpec()\n+    val containerBuilder = new ContainerBuilder(container)\n+    volumes foreach {\n+      case (name, spec) =>\n+        var hostPath: Option[String] = None\n+        if (spec.optionsSpec.contains(KUBERNETES_VOLUMES_PATH_KEY)) {\n+          hostPath = Some(spec.optionsSpec(KUBERNETES_VOLUMES_PATH_KEY))\n+        }\n+        if (hostPath.isDefined && spec.mountPath.isDefined) {",
    "line": 122
  }],
  "prId": 21095
}, {
  "comments": [{
    "author": {
      "login": "liyinan926"
    },
    "body": "`s/volumeBuilder/mountBuilder`.",
    "commit": "f482dfc370bace0c5315a2514604be2965bcbbaf",
    "createdAt": "2018-05-03T23:19:00Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.mutable.HashMap\n+\n+import io.fabric8.kubernetes.api.model._\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+\n+private[spark] object KubernetesVolumeUtils {\n+\n+  /**\n+   * Given hostPath volume specs, add volume to pod and volume mount to container.\n+   *\n+   * @param pod original specification of the pod\n+   * @param container original specification of the container\n+   * @param sparkConf Spark configuration\n+   * @param prefix the prefix for volume configuration\n+   * @return a tuple of (pod with the volume(s) added, container with mount(s) added)\n+   */\n+  def addVolumes(\n+      pod: Pod,\n+      container: Container,\n+      sparkConf: SparkConf,\n+      prefix : String): (Pod, Container) = {\n+    val hostPathVolumeSpecs = parseHostPathVolumesWithPrefix(sparkConf, prefix)\n+    addHostPathVolumes(pod, container, hostPathVolumeSpecs)\n+  }\n+\n+  /**\n+   * Extract Spark volume configuration properties with a given name prefix.\n+   *\n+   * @param sparkConf Spark configuration\n+   * @param prefix the given property name prefix\n+   * @param volumeTypeKey the given property name prefix\n+   * @return a Map storing with volume name as key and spec as value\n+   */\n+  def parseVolumesWithPrefix(\n+      sparkConf: SparkConf,\n+      prefix: String,\n+      volumeTypeKey: String): Map[String, KubernetesVolumeSpec] = {\n+    val volumes = HashMap[String, KubernetesVolumeSpec]()\n+    val properties = sparkConf.getAllWithPrefix(s\"$prefix$volumeTypeKey.\").toList\n+    // Extract volume names\n+    properties.foreach {\n+      k =>\n+        val keys = k._1.split(\"\\\\.\")\n+        if (keys.nonEmpty && !volumes.contains(keys(0))) {\n+          volumes.update(keys(0), KubernetesVolumeSpec.emptySpec())\n+        }\n+    }\n+    // Populate spec\n+    volumes.foreach {\n+      case (name, spec) =>\n+        properties.foreach {\n+          k =>\n+            k._1.split(\"\\\\.\") match {\n+              case Array(`name`, KUBERNETES_VOLUMES_MOUNT_KEY, KUBERNETES_VOLUMES_PATH_KEY) =>\n+                spec.mountPath = Some(k._2)\n+              case Array(`name`, KUBERNETES_VOLUMES_MOUNT_KEY, KUBERNETES_VOLUMES_READONLY_KEY) =>\n+                spec.mountReadOnly = Some(k._2.toBoolean)\n+              case Array(`name`, KUBERNETES_VOLUMES_OPTIONS_KEY, option) =>\n+                spec.optionsSpec.update(option, k._2)\n+              case _ =>\n+                None\n+            }\n+        }\n+    }\n+    volumes.toMap\n+  }\n+\n+  /**\n+   * Extract Spark hostPath volume configuration properties with a given name prefix and\n+   * return the result as a Map.\n+   *\n+   * @param sparkConf Spark configuration\n+   * @param prefix the given property name prefix\n+   * @return a Map storing with volume name as key and spec as value\n+   */\n+  def parseHostPathVolumesWithPrefix(\n+      sparkConf: SparkConf,\n+      prefix: String): Map[String, KubernetesVolumeSpec] = {\n+    parseVolumesWithPrefix(sparkConf, prefix, KUBERNETES_VOLUMES_HOSTPATH_KEY)\n+  }\n+\n+  /**\n+   * Given hostPath volume specs, add volume to pod and volume mount to container.\n+   *\n+   * @param pod original specification of the pod\n+   * @param container original specification of the container\n+   * @param volumes list of named volume specs\n+   * @return a tuple of (pod with the volume(s) added, container with mount(s) added)\n+   */\n+  def addHostPathVolumes(\n+      pod: Pod,\n+      container: Container,\n+      volumes: Map[String, KubernetesVolumeSpec]): (Pod, Container) = {\n+    val podBuilder = new PodBuilder(pod).editOrNewSpec()\n+    val containerBuilder = new ContainerBuilder(container)\n+    volumes foreach {\n+      case (name, spec) =>\n+        var hostPath: Option[String] = None\n+        if (spec.optionsSpec.contains(KUBERNETES_VOLUMES_PATH_KEY)) {\n+          hostPath = Some(spec.optionsSpec(KUBERNETES_VOLUMES_PATH_KEY))\n+        }\n+        if (hostPath.isDefined && spec.mountPath.isDefined) {\n+          podBuilder.addToVolumes(new VolumeBuilder()\n+            .withHostPath(new HostPathVolumeSource(hostPath.get))\n+            .withName(name)\n+            .build())\n+          val volumeBuilder = new VolumeMountBuilder()",
    "line": 127
  }],
  "prId": 21095
}, {
  "comments": [{
    "author": {
      "login": "liyinan926"
    },
    "body": "Looks like you don't really need this function as it's just a wrapper of `parseVolumesWithPrefix `. ",
    "commit": "f482dfc370bace0c5315a2514604be2965bcbbaf",
    "createdAt": "2018-05-04T02:20:14Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.mutable.HashMap\n+\n+import io.fabric8.kubernetes.api.model._\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+\n+private[spark] object KubernetesVolumeUtils {\n+\n+  /**\n+   * Given hostPath volume specs, add volume to pod and volume mount to container.\n+   *\n+   * @param pod original specification of the pod\n+   * @param container original specification of the container\n+   * @param sparkConf Spark configuration\n+   * @param prefix the prefix for volume configuration\n+   * @return a tuple of (pod with the volume(s) added, container with mount(s) added)\n+   */\n+  def addVolumes(\n+      pod: Pod,\n+      container: Container,\n+      sparkConf: SparkConf,\n+      prefix : String): (Pod, Container) = {\n+    val hostPathVolumeSpecs = parseHostPathVolumesWithPrefix(sparkConf, prefix)\n+    addHostPathVolumes(pod, container, hostPathVolumeSpecs)\n+  }\n+\n+  /**\n+   * Extract Spark volume configuration properties with a given name prefix.\n+   *\n+   * @param sparkConf Spark configuration\n+   * @param prefix the given property name prefix\n+   * @param volumeTypeKey the given property name prefix\n+   * @return a Map storing with volume name as key and spec as value\n+   */\n+  def parseVolumesWithPrefix(\n+      sparkConf: SparkConf,\n+      prefix: String,\n+      volumeTypeKey: String): Map[String, KubernetesVolumeSpec] = {\n+    val volumes = HashMap[String, KubernetesVolumeSpec]()\n+    val properties = sparkConf.getAllWithPrefix(s\"$prefix$volumeTypeKey.\").toList\n+    // Extract volume names\n+    properties.foreach {\n+      k =>\n+        val keys = k._1.split(\"\\\\.\")\n+        if (keys.nonEmpty && !volumes.contains(keys(0))) {\n+          volumes.update(keys(0), KubernetesVolumeSpec.emptySpec())\n+        }\n+    }\n+    // Populate spec\n+    volumes.foreach {\n+      case (name, spec) =>\n+        properties.foreach {\n+          k =>\n+            k._1.split(\"\\\\.\") match {\n+              case Array(`name`, KUBERNETES_VOLUMES_MOUNT_KEY, KUBERNETES_VOLUMES_PATH_KEY) =>\n+                spec.mountPath = Some(k._2)\n+              case Array(`name`, KUBERNETES_VOLUMES_MOUNT_KEY, KUBERNETES_VOLUMES_READONLY_KEY) =>\n+                spec.mountReadOnly = Some(k._2.toBoolean)\n+              case Array(`name`, KUBERNETES_VOLUMES_OPTIONS_KEY, option) =>\n+                spec.optionsSpec.update(option, k._2)\n+              case _ =>\n+                None\n+            }\n+        }\n+    }\n+    volumes.toMap\n+  }\n+\n+  /**\n+   * Extract Spark hostPath volume configuration properties with a given name prefix and\n+   * return the result as a Map.\n+   *\n+   * @param sparkConf Spark configuration\n+   * @param prefix the given property name prefix\n+   * @return a Map storing with volume name as key and spec as value\n+   */\n+  def parseHostPathVolumesWithPrefix(",
    "line": 96
  }],
  "prId": 21095
}]