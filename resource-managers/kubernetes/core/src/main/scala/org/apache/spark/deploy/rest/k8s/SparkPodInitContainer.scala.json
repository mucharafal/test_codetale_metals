[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Probably good to put a configurable upper limit to the number of threads here, since the tasks they're running are probably not super short-lived.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-19T22:23:27Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.rest.k8s\n+\n+import java.io.File\n+import java.util.concurrent.TimeUnit\n+\n+import scala.concurrent.{ExecutionContext, Future}\n+\n+import org.apache.spark.{SecurityManager => SparkSecurityManager, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.{ThreadUtils, Utils}\n+\n+/**\n+ * Process that fetches files from a resource staging server and/or arbitrary remote locations.\n+ *\n+ * The init-container can handle fetching files from any of those sources, but not all of the\n+ * sources need to be specified. This allows for composing multiple instances of this container\n+ * with different configurations for different download sources, or using the same container to\n+ * download everything at once.\n+ */\n+private[spark] class SparkPodInitContainer(\n+    sparkConf: SparkConf,\n+    fileFetcher: FileFetcher) extends Logging {\n+\n+  private implicit val downloadExecutor = ExecutionContext.fromExecutorService(\n+    ThreadUtils.newDaemonCachedThreadPool(\"download-executor\"))"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "Done. Added `spark.kubernetes.initContainer.maxThreadPoolSize` with a default value of 5.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-20T00:51:04Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.rest.k8s\n+\n+import java.io.File\n+import java.util.concurrent.TimeUnit\n+\n+import scala.concurrent.{ExecutionContext, Future}\n+\n+import org.apache.spark.{SecurityManager => SparkSecurityManager, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.{ThreadUtils, Utils}\n+\n+/**\n+ * Process that fetches files from a resource staging server and/or arbitrary remote locations.\n+ *\n+ * The init-container can handle fetching files from any of those sources, but not all of the\n+ * sources need to be specified. This allows for composing multiple instances of this container\n+ * with different configurations for different download sources, or using the same container to\n+ * download everything at once.\n+ */\n+private[spark] class SparkPodInitContainer(\n+    sparkConf: SparkConf,\n+    fileFetcher: FileFetcher) extends Logging {\n+\n+  private implicit val downloadExecutor = ExecutionContext.fromExecutorService(\n+    ThreadUtils.newDaemonCachedThreadPool(\"download-executor\"))"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Use `Utils.stringToSeq`.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-19T22:24:24Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.rest.k8s\n+\n+import java.io.File\n+import java.util.concurrent.TimeUnit\n+\n+import scala.concurrent.{ExecutionContext, Future}\n+\n+import org.apache.spark.{SecurityManager => SparkSecurityManager, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.{ThreadUtils, Utils}\n+\n+/**\n+ * Process that fetches files from a resource staging server and/or arbitrary remote locations.\n+ *\n+ * The init-container can handle fetching files from any of those sources, but not all of the\n+ * sources need to be specified. This allows for composing multiple instances of this container\n+ * with different configurations for different download sources, or using the same container to\n+ * download everything at once.\n+ */\n+private[spark] class SparkPodInitContainer(\n+    sparkConf: SparkConf,\n+    fileFetcher: FileFetcher) extends Logging {\n+\n+  private implicit val downloadExecutor = ExecutionContext.fromExecutorService(\n+    ThreadUtils.newDaemonCachedThreadPool(\"download-executor\"))\n+\n+  private val jarsDownloadDir = new File(\n+    sparkConf.get(JARS_DOWNLOAD_LOCATION))\n+  private val filesDownloadDir = new File(\n+    sparkConf.get(FILES_DOWNLOAD_LOCATION))\n+\n+  private val remoteJars = sparkConf.get(INIT_CONTAINER_REMOTE_JARS)\n+  private val remoteFiles = sparkConf.get(INIT_CONTAINER_REMOTE_FILES)\n+\n+  private val downloadTimeoutMinutes = sparkConf.get(INIT_CONTAINER_MOUNT_TIMEOUT)\n+\n+  def run(): Unit = {\n+    logInfo(s\"Downloading remote jars: $remoteJars\")\n+    downloadFiles(\n+      remoteJars,\n+      jarsDownloadDir,\n+      s\"Remote jars download directory specified at $jarsDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    logInfo(s\"Downloading remote files: $remoteFiles\")\n+    downloadFiles(\n+      remoteFiles,\n+      filesDownloadDir,\n+      s\"Remote files download directory specified at $filesDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    downloadExecutor.shutdown()\n+    downloadExecutor.awaitTermination(downloadTimeoutMinutes, TimeUnit.MINUTES)\n+  }\n+\n+  private def downloadFiles(\n+      filesCommaSeparated: Option[String],\n+      downloadDir: File,\n+      errMessageOnDestinationNotADirectory: String): Unit = {\n+    if (filesCommaSeparated.isDefined) {\n+      require(downloadDir.isDirectory, errMessageOnDestinationNotADirectory)\n+    }\n+    filesCommaSeparated.map(_.split(\",\")).toSeq.flatten.foreach { file =>"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "Done.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-20T00:32:11Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.rest.k8s\n+\n+import java.io.File\n+import java.util.concurrent.TimeUnit\n+\n+import scala.concurrent.{ExecutionContext, Future}\n+\n+import org.apache.spark.{SecurityManager => SparkSecurityManager, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.{ThreadUtils, Utils}\n+\n+/**\n+ * Process that fetches files from a resource staging server and/or arbitrary remote locations.\n+ *\n+ * The init-container can handle fetching files from any of those sources, but not all of the\n+ * sources need to be specified. This allows for composing multiple instances of this container\n+ * with different configurations for different download sources, or using the same container to\n+ * download everything at once.\n+ */\n+private[spark] class SparkPodInitContainer(\n+    sparkConf: SparkConf,\n+    fileFetcher: FileFetcher) extends Logging {\n+\n+  private implicit val downloadExecutor = ExecutionContext.fromExecutorService(\n+    ThreadUtils.newDaemonCachedThreadPool(\"download-executor\"))\n+\n+  private val jarsDownloadDir = new File(\n+    sparkConf.get(JARS_DOWNLOAD_LOCATION))\n+  private val filesDownloadDir = new File(\n+    sparkConf.get(FILES_DOWNLOAD_LOCATION))\n+\n+  private val remoteJars = sparkConf.get(INIT_CONTAINER_REMOTE_JARS)\n+  private val remoteFiles = sparkConf.get(INIT_CONTAINER_REMOTE_FILES)\n+\n+  private val downloadTimeoutMinutes = sparkConf.get(INIT_CONTAINER_MOUNT_TIMEOUT)\n+\n+  def run(): Unit = {\n+    logInfo(s\"Downloading remote jars: $remoteJars\")\n+    downloadFiles(\n+      remoteJars,\n+      jarsDownloadDir,\n+      s\"Remote jars download directory specified at $jarsDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    logInfo(s\"Downloading remote files: $remoteFiles\")\n+    downloadFiles(\n+      remoteFiles,\n+      filesDownloadDir,\n+      s\"Remote files download directory specified at $filesDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    downloadExecutor.shutdown()\n+    downloadExecutor.awaitTermination(downloadTimeoutMinutes, TimeUnit.MINUTES)\n+  }\n+\n+  private def downloadFiles(\n+      filesCommaSeparated: Option[String],\n+      downloadDir: File,\n+      errMessageOnDestinationNotADirectory: String): Unit = {\n+    if (filesCommaSeparated.isDefined) {\n+      require(downloadDir.isDirectory, errMessageOnDestinationNotADirectory)\n+    }\n+    filesCommaSeparated.map(_.split(\",\")).toSeq.flatten.foreach { file =>"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Use `filesCommaSeparated.foreach { ...`.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-19T22:24:54Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.rest.k8s\n+\n+import java.io.File\n+import java.util.concurrent.TimeUnit\n+\n+import scala.concurrent.{ExecutionContext, Future}\n+\n+import org.apache.spark.{SecurityManager => SparkSecurityManager, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.{ThreadUtils, Utils}\n+\n+/**\n+ * Process that fetches files from a resource staging server and/or arbitrary remote locations.\n+ *\n+ * The init-container can handle fetching files from any of those sources, but not all of the\n+ * sources need to be specified. This allows for composing multiple instances of this container\n+ * with different configurations for different download sources, or using the same container to\n+ * download everything at once.\n+ */\n+private[spark] class SparkPodInitContainer(\n+    sparkConf: SparkConf,\n+    fileFetcher: FileFetcher) extends Logging {\n+\n+  private implicit val downloadExecutor = ExecutionContext.fromExecutorService(\n+    ThreadUtils.newDaemonCachedThreadPool(\"download-executor\"))\n+\n+  private val jarsDownloadDir = new File(\n+    sparkConf.get(JARS_DOWNLOAD_LOCATION))\n+  private val filesDownloadDir = new File(\n+    sparkConf.get(FILES_DOWNLOAD_LOCATION))\n+\n+  private val remoteJars = sparkConf.get(INIT_CONTAINER_REMOTE_JARS)\n+  private val remoteFiles = sparkConf.get(INIT_CONTAINER_REMOTE_FILES)\n+\n+  private val downloadTimeoutMinutes = sparkConf.get(INIT_CONTAINER_MOUNT_TIMEOUT)\n+\n+  def run(): Unit = {\n+    logInfo(s\"Downloading remote jars: $remoteJars\")\n+    downloadFiles(\n+      remoteJars,\n+      jarsDownloadDir,\n+      s\"Remote jars download directory specified at $jarsDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    logInfo(s\"Downloading remote files: $remoteFiles\")\n+    downloadFiles(\n+      remoteFiles,\n+      filesDownloadDir,\n+      s\"Remote files download directory specified at $filesDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    downloadExecutor.shutdown()\n+    downloadExecutor.awaitTermination(downloadTimeoutMinutes, TimeUnit.MINUTES)\n+  }\n+\n+  private def downloadFiles(\n+      filesCommaSeparated: Option[String],\n+      downloadDir: File,\n+      errMessageOnDestinationNotADirectory: String): Unit = {\n+    if (filesCommaSeparated.isDefined) {"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "Done.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-20T00:32:07Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.rest.k8s\n+\n+import java.io.File\n+import java.util.concurrent.TimeUnit\n+\n+import scala.concurrent.{ExecutionContext, Future}\n+\n+import org.apache.spark.{SecurityManager => SparkSecurityManager, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.{ThreadUtils, Utils}\n+\n+/**\n+ * Process that fetches files from a resource staging server and/or arbitrary remote locations.\n+ *\n+ * The init-container can handle fetching files from any of those sources, but not all of the\n+ * sources need to be specified. This allows for composing multiple instances of this container\n+ * with different configurations for different download sources, or using the same container to\n+ * download everything at once.\n+ */\n+private[spark] class SparkPodInitContainer(\n+    sparkConf: SparkConf,\n+    fileFetcher: FileFetcher) extends Logging {\n+\n+  private implicit val downloadExecutor = ExecutionContext.fromExecutorService(\n+    ThreadUtils.newDaemonCachedThreadPool(\"download-executor\"))\n+\n+  private val jarsDownloadDir = new File(\n+    sparkConf.get(JARS_DOWNLOAD_LOCATION))\n+  private val filesDownloadDir = new File(\n+    sparkConf.get(FILES_DOWNLOAD_LOCATION))\n+\n+  private val remoteJars = sparkConf.get(INIT_CONTAINER_REMOTE_JARS)\n+  private val remoteFiles = sparkConf.get(INIT_CONTAINER_REMOTE_FILES)\n+\n+  private val downloadTimeoutMinutes = sparkConf.get(INIT_CONTAINER_MOUNT_TIMEOUT)\n+\n+  def run(): Unit = {\n+    logInfo(s\"Downloading remote jars: $remoteJars\")\n+    downloadFiles(\n+      remoteJars,\n+      jarsDownloadDir,\n+      s\"Remote jars download directory specified at $jarsDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    logInfo(s\"Downloading remote files: $remoteFiles\")\n+    downloadFiles(\n+      remoteFiles,\n+      filesDownloadDir,\n+      s\"Remote files download directory specified at $filesDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    downloadExecutor.shutdown()\n+    downloadExecutor.awaitTermination(downloadTimeoutMinutes, TimeUnit.MINUTES)\n+  }\n+\n+  private def downloadFiles(\n+      filesCommaSeparated: Option[String],\n+      downloadDir: File,\n+      errMessageOnDestinationNotADirectory: String): Unit = {\n+    if (filesCommaSeparated.isDefined) {"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Fits in previous line.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-20T23:55:31Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.rest.k8s\n+\n+import java.io.File\n+import java.util.concurrent.TimeUnit\n+\n+import scala.concurrent.{ExecutionContext, Future}\n+\n+import org.apache.spark.{SecurityManager => SparkSecurityManager, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.{ThreadUtils, Utils}\n+\n+/**\n+ * Process that fetches files from a resource staging server and/or arbitrary remote locations.\n+ *\n+ * The init-container can handle fetching files from any of those sources, but not all of the\n+ * sources need to be specified. This allows for composing multiple instances of this container\n+ * with different configurations for different download sources, or using the same container to\n+ * download everything at once.\n+ */\n+private[spark] class SparkPodInitContainer(\n+    sparkConf: SparkConf,\n+    fileFetcher: FileFetcher) extends Logging {\n+\n+  private val maxThreadPoolSize = sparkConf.get(INIT_CONTAINER_MAX_THREAD_POOL_SIZE)\n+  private implicit val downloadExecutor = ExecutionContext.fromExecutorService(\n+    ThreadUtils.newDaemonCachedThreadPool(\"download-executor\", maxThreadPoolSize))\n+\n+  private val jarsDownloadDir = new File(\n+    sparkConf.get(JARS_DOWNLOAD_LOCATION))"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Fits in previous line.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-20T23:55:35Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.rest.k8s\n+\n+import java.io.File\n+import java.util.concurrent.TimeUnit\n+\n+import scala.concurrent.{ExecutionContext, Future}\n+\n+import org.apache.spark.{SecurityManager => SparkSecurityManager, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.{ThreadUtils, Utils}\n+\n+/**\n+ * Process that fetches files from a resource staging server and/or arbitrary remote locations.\n+ *\n+ * The init-container can handle fetching files from any of those sources, but not all of the\n+ * sources need to be specified. This allows for composing multiple instances of this container\n+ * with different configurations for different download sources, or using the same container to\n+ * download everything at once.\n+ */\n+private[spark] class SparkPodInitContainer(\n+    sparkConf: SparkConf,\n+    fileFetcher: FileFetcher) extends Logging {\n+\n+  private val maxThreadPoolSize = sparkConf.get(INIT_CONTAINER_MAX_THREAD_POOL_SIZE)\n+  private implicit val downloadExecutor = ExecutionContext.fromExecutorService(\n+    ThreadUtils.newDaemonCachedThreadPool(\"download-executor\", maxThreadPoolSize))\n+\n+  private val jarsDownloadDir = new File(\n+    sparkConf.get(JARS_DOWNLOAD_LOCATION))\n+  private val filesDownloadDir = new File(\n+    sparkConf.get(FILES_DOWNLOAD_LOCATION))"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nuke empty line.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-20T23:56:20Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.rest.k8s\n+\n+import java.io.File\n+import java.util.concurrent.TimeUnit\n+\n+import scala.concurrent.{ExecutionContext, Future}\n+\n+import org.apache.spark.{SecurityManager => SparkSecurityManager, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.{ThreadUtils, Utils}\n+\n+/**\n+ * Process that fetches files from a resource staging server and/or arbitrary remote locations.\n+ *\n+ * The init-container can handle fetching files from any of those sources, but not all of the\n+ * sources need to be specified. This allows for composing multiple instances of this container\n+ * with different configurations for different download sources, or using the same container to\n+ * download everything at once.\n+ */\n+private[spark] class SparkPodInitContainer(\n+    sparkConf: SparkConf,\n+    fileFetcher: FileFetcher) extends Logging {\n+\n+  private val maxThreadPoolSize = sparkConf.get(INIT_CONTAINER_MAX_THREAD_POOL_SIZE)\n+  private implicit val downloadExecutor = ExecutionContext.fromExecutorService(\n+    ThreadUtils.newDaemonCachedThreadPool(\"download-executor\", maxThreadPoolSize))\n+\n+  private val jarsDownloadDir = new File(\n+    sparkConf.get(JARS_DOWNLOAD_LOCATION))\n+  private val filesDownloadDir = new File(\n+    sparkConf.get(FILES_DOWNLOAD_LOCATION))\n+\n+  private val remoteJars = sparkConf.get(INIT_CONTAINER_REMOTE_JARS)\n+  private val remoteFiles = sparkConf.get(INIT_CONTAINER_REMOTE_FILES)\n+\n+  private val downloadTimeoutMinutes = sparkConf.get(INIT_CONTAINER_MOUNT_TIMEOUT)\n+\n+  def run(): Unit = {\n+    logInfo(s\"Downloading remote jars: $remoteJars\")\n+    downloadFiles(\n+      remoteJars,\n+      jarsDownloadDir,\n+      s\"Remote jars download directory specified at $jarsDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    logInfo(s\"Downloading remote files: $remoteFiles\")\n+    downloadFiles(\n+      remoteFiles,\n+      filesDownloadDir,\n+      s\"Remote files download directory specified at $filesDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    downloadExecutor.shutdown()\n+    downloadExecutor.awaitTermination(downloadTimeoutMinutes, TimeUnit.MINUTES)\n+  }\n+\n+  private def downloadFiles(\n+      filesCommaSeparated: Option[String],\n+      downloadDir: File,\n+      errMessageOnDestinationNotADirectory: String): Unit = {\n+    filesCommaSeparated.foreach { files =>\n+      require(downloadDir.isDirectory, errMessageOnDestinationNotADirectory)\n+      Utils.stringToSeq(files).foreach { file =>\n+        Future[Unit] {\n+          fileFetcher.fetchFile(file, downloadDir)\n+        }\n+"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "nit: `errMessageOnDestinationNotADirectory` -> `errMessage`?",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-25T17:23:32Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.rest.k8s\n+\n+import java.io.File\n+import java.util.concurrent.TimeUnit\n+\n+import scala.concurrent.{ExecutionContext, Future}\n+\n+import org.apache.spark.{SecurityManager => SparkSecurityManager, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.{ThreadUtils, Utils}\n+\n+/**\n+ * Process that fetches files from a resource staging server and/or arbitrary remote locations.\n+ *\n+ * The init-container can handle fetching files from any of those sources, but not all of the\n+ * sources need to be specified. This allows for composing multiple instances of this container\n+ * with different configurations for different download sources, or using the same container to\n+ * download everything at once.\n+ */\n+private[spark] class SparkPodInitContainer(\n+    sparkConf: SparkConf,\n+    fileFetcher: FileFetcher) extends Logging {\n+\n+  private val maxThreadPoolSize = sparkConf.get(INIT_CONTAINER_MAX_THREAD_POOL_SIZE)\n+  private implicit val downloadExecutor = ExecutionContext.fromExecutorService(\n+    ThreadUtils.newDaemonCachedThreadPool(\"download-executor\", maxThreadPoolSize))\n+\n+  private val jarsDownloadDir = new File(sparkConf.get(JARS_DOWNLOAD_LOCATION))\n+  private val filesDownloadDir = new File(sparkConf.get(FILES_DOWNLOAD_LOCATION))\n+\n+  private val remoteJars = sparkConf.get(INIT_CONTAINER_REMOTE_JARS)\n+  private val remoteFiles = sparkConf.get(INIT_CONTAINER_REMOTE_FILES)\n+\n+  private val downloadTimeoutMinutes = sparkConf.get(INIT_CONTAINER_MOUNT_TIMEOUT)\n+\n+  def run(): Unit = {\n+    logInfo(s\"Downloading remote jars: $remoteJars\")\n+    downloadFiles(\n+      remoteJars,\n+      jarsDownloadDir,\n+      s\"Remote jars download directory specified at $jarsDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    logInfo(s\"Downloading remote files: $remoteFiles\")\n+    downloadFiles(\n+      remoteFiles,\n+      filesDownloadDir,\n+      s\"Remote files download directory specified at $filesDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    downloadExecutor.shutdown()\n+    downloadExecutor.awaitTermination(downloadTimeoutMinutes, TimeUnit.MINUTES)\n+  }\n+\n+  private def downloadFiles(\n+      filesCommaSeparated: Option[String],\n+      downloadDir: File,\n+      errMessageOnDestinationNotADirectory: String): Unit = {"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "Done.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-25T18:00:03Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.rest.k8s\n+\n+import java.io.File\n+import java.util.concurrent.TimeUnit\n+\n+import scala.concurrent.{ExecutionContext, Future}\n+\n+import org.apache.spark.{SecurityManager => SparkSecurityManager, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.{ThreadUtils, Utils}\n+\n+/**\n+ * Process that fetches files from a resource staging server and/or arbitrary remote locations.\n+ *\n+ * The init-container can handle fetching files from any of those sources, but not all of the\n+ * sources need to be specified. This allows for composing multiple instances of this container\n+ * with different configurations for different download sources, or using the same container to\n+ * download everything at once.\n+ */\n+private[spark] class SparkPodInitContainer(\n+    sparkConf: SparkConf,\n+    fileFetcher: FileFetcher) extends Logging {\n+\n+  private val maxThreadPoolSize = sparkConf.get(INIT_CONTAINER_MAX_THREAD_POOL_SIZE)\n+  private implicit val downloadExecutor = ExecutionContext.fromExecutorService(\n+    ThreadUtils.newDaemonCachedThreadPool(\"download-executor\", maxThreadPoolSize))\n+\n+  private val jarsDownloadDir = new File(sparkConf.get(JARS_DOWNLOAD_LOCATION))\n+  private val filesDownloadDir = new File(sparkConf.get(FILES_DOWNLOAD_LOCATION))\n+\n+  private val remoteJars = sparkConf.get(INIT_CONTAINER_REMOTE_JARS)\n+  private val remoteFiles = sparkConf.get(INIT_CONTAINER_REMOTE_FILES)\n+\n+  private val downloadTimeoutMinutes = sparkConf.get(INIT_CONTAINER_MOUNT_TIMEOUT)\n+\n+  def run(): Unit = {\n+    logInfo(s\"Downloading remote jars: $remoteJars\")\n+    downloadFiles(\n+      remoteJars,\n+      jarsDownloadDir,\n+      s\"Remote jars download directory specified at $jarsDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    logInfo(s\"Downloading remote files: $remoteFiles\")\n+    downloadFiles(\n+      remoteFiles,\n+      filesDownloadDir,\n+      s\"Remote files download directory specified at $filesDownloadDir does not exist \" +\n+        \"or is not a directory.\")\n+\n+    downloadExecutor.shutdown()\n+    downloadExecutor.awaitTermination(downloadTimeoutMinutes, TimeUnit.MINUTES)\n+  }\n+\n+  private def downloadFiles(\n+      filesCommaSeparated: Option[String],\n+      downloadDir: File,\n+      errMessageOnDestinationNotADirectory: String): Unit = {"
  }],
  "prId": 19954
}]