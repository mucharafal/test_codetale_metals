[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Indent this block",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-01-21T20:26:11Z",
    "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.{Constants, KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String)(implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String)(implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      .delete()\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      client\n+        .pods\n+        .inNamespace(ns)\n+        .delete(pods.asJava)\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private [spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+      val pod = client\n+        .pods\n+        .inNamespace(ns)\n+        .withName(pName)\n+        .get()\n+\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+      printMessage(\"Application status (driver): \" +"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "does just .contains work here to check whether the tuple exists? you might not even need .asScala, not sure",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-01-21T20:26:51Z",
    "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.{Constants, KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String)(implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String)(implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      .delete()\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      client\n+        .pods\n+        .inNamespace(ns)\n+        .delete(pods.asJava)\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private [spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+      val pod = client\n+        .pods\n+        .inNamespace(ns)\n+        .withName(pName)\n+        .get()\n+\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] object K8sSubmitOps extends CommandLineLoggingUtils {\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((ns, pName))\n+      case Array(pName) => Some((\"default\", pName))\n+      case _ => None\n+    }\n+\n+    sIdParts match {\n+      case Some((ns, pName)) =>\n+        Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\n+          master,\n+          Some(ns),\n+          KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX,\n+          sparkConf,\n+          None,\n+          None)) { kubernetesClient =>\n+          implicit val client: KubernetesClient = kubernetesClient\n+          if (isGlob(pName)) {\n+            val pods = {\n+              kubernetesClient\n+                .pods\n+                .inNamespace(ns)\n+                .list()\n+                .getItems\n+                .asScala\n+                .filter { pod =>\n+                  val meta = pod.getMetadata\n+                  meta.getName.startsWith(pName.stripSuffix(\"*\")) &&\n+                    meta\n+                      .getLabels\n+                      .asScala\n+                      .exists(_.equals((SPARK_ROLE_LABEL, SPARK_POD_DRIVER_ROLE)))"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "getLabels returns a java map so it is not easy to compare both the key and the value at the same statement. I turn it to a scala map so I can check for the existence of the tuple. Contains on the scala map uses the key only.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-05T14:27:17Z",
    "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.{Constants, KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String)(implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String)(implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      .delete()\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      client\n+        .pods\n+        .inNamespace(ns)\n+        .delete(pods.asJava)\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private [spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+      val pod = client\n+        .pods\n+        .inNamespace(ns)\n+        .withName(pName)\n+        .get()\n+\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] object K8sSubmitOps extends CommandLineLoggingUtils {\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((ns, pName))\n+      case Array(pName) => Some((\"default\", pName))\n+      case _ => None\n+    }\n+\n+    sIdParts match {\n+      case Some((ns, pName)) =>\n+        Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\n+          master,\n+          Some(ns),\n+          KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX,\n+          sparkConf,\n+          None,\n+          None)) { kubernetesClient =>\n+          implicit val client: KubernetesClient = kubernetesClient\n+          if (isGlob(pName)) {\n+            val pods = {\n+              kubernetesClient\n+                .pods\n+                .inNamespace(ns)\n+                .list()\n+                .getItems\n+                .asScala\n+                .filter { pod =>\n+                  val meta = pod.getMetadata\n+                  meta.getName.startsWith(pName.stripSuffix(\"*\")) &&\n+                    meta\n+                      .getLabels\n+                      .asScala\n+                      .exists(_.equals((SPARK_ROLE_LABEL, SPARK_POD_DRIVER_ROLE)))"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I think this needs to unindent one step",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-01-21T20:27:10Z",
    "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.{Constants, KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String)(implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String)(implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      .delete()\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      client\n+        .pods\n+        .inNamespace(ns)\n+        .delete(pods.asJava)\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private [spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+      val pod = client\n+        .pods\n+        .inNamespace(ns)\n+        .withName(pName)\n+        .get()\n+\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] object K8sSubmitOps extends CommandLineLoggingUtils {\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((ns, pName))\n+      case Array(pName) => Some((\"default\", pName))\n+      case _ => None\n+    }\n+\n+    sIdParts match {\n+      case Some((ns, pName)) =>\n+        Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\n+          master,\n+          Some(ns),\n+          KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX,\n+          sparkConf,\n+          None,\n+          None)) { kubernetesClient =>\n+          implicit val client: KubernetesClient = kubernetesClient\n+          if (isGlob(pName)) {\n+            val pods = {\n+              kubernetesClient\n+                .pods\n+                .inNamespace(ns)\n+                .list()\n+                .getItems\n+                .asScala\n+                .filter { pod =>\n+                  val meta = pod.getMetadata\n+                  meta.getName.startsWith(pName.stripSuffix(\"*\")) &&\n+                    meta"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Is it 4 spaces for logical expressions (these are 2)?",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-05T14:23:11Z",
    "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.{Constants, KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String)(implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String)(implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      .delete()\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      client\n+        .pods\n+        .inNamespace(ns)\n+        .delete(pods.asJava)\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private [spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+      val pod = client\n+        .pods\n+        .inNamespace(ns)\n+        .withName(pName)\n+        .get()\n+\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] object K8sSubmitOps extends CommandLineLoggingUtils {\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((ns, pName))\n+      case Array(pName) => Some((\"default\", pName))\n+      case _ => None\n+    }\n+\n+    sIdParts match {\n+      case Some((ns, pName)) =>\n+        Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\n+          master,\n+          Some(ns),\n+          KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX,\n+          sparkConf,\n+          None,\n+          None)) { kubernetesClient =>\n+          implicit val client: KubernetesClient = kubernetesClient\n+          if (isGlob(pName)) {\n+            val pods = {\n+              kubernetesClient\n+                .pods\n+                .inNamespace(ns)\n+                .list()\n+                .getItems\n+                .asScala\n+                .filter { pod =>\n+                  val meta = pod.getMetadata\n+                  meta.getName.startsWith(pName.stripSuffix(\"*\")) &&\n+                    meta"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Remove space after private, here and below",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-07T14:50:56Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Unit tests for this stuff?",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-07T21:01:35Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Indentation looks weird this way. Do:\r\n\r\n```\r\nUtils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\r\n  ...\r\n  None)\r\n) { kubernetesClient =>\r\n  // code goes here\r\n}\r\n```\r\n",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-07T21:05:41Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      val nClient = client\n+        .pods\n+        .inNamespace(ns)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+              .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+              .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private [spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String, gracePerio: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+      val pod = client\n+        .pods\n+        .inNamespace(ns)\n+        .withName(pName)\n+        .get()\n+\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriod: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8sSparkSubmitOperationsClient extends SparkSubmitOperationsClient\n+  with CommandLineLoggingUtils {\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((ns, pName))\n+      case Array(pName) => Some((\"default\", pName))\n+      case _ => None\n+    }\n+\n+    sIdParts match {\n+      case Some((ns, pName)) =>\n+        Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\n+          master,\n+          Some(ns),\n+          KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX,\n+          sparkConf,\n+          None,\n+          None)) { kubernetesClient =>"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "isn't this the same as `meta.getLabels().get(SPARK_ROLE_LABEL) == SPARK_POD_DRIVER_ROLE`?",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-07T21:07:09Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      val nClient = client\n+        .pods\n+        .inNamespace(ns)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+              .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+              .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private [spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String, gracePerio: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+      val pod = client\n+        .pods\n+        .inNamespace(ns)\n+        .withName(pName)\n+        .get()\n+\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriod: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8sSparkSubmitOperationsClient extends SparkSubmitOperationsClient\n+  with CommandLineLoggingUtils {\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((ns, pName))\n+      case Array(pName) => Some((\"default\", pName))\n+      case _ => None\n+    }\n+\n+    sIdParts match {\n+      case Some((ns, pName)) =>\n+        Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\n+          master,\n+          Some(ns),\n+          KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX,\n+          sparkConf,\n+          None,\n+          None)) { kubernetesClient =>\n+          implicit val client: KubernetesClient = kubernetesClient\n+          if (isGlob(pName)) {\n+            val pods = {\n+              kubernetesClient\n+                .pods\n+                .inNamespace(ns)\n+                .list()\n+                .getItems\n+                .asScala\n+                .filter { pod =>\n+                  val meta = pod.getMetadata\n+                  meta.getName.startsWith(pName.stripSuffix(\"*\")) &&\n+                    meta"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Ping.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-13T19:03:00Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      val nClient = client\n+        .pods\n+        .inNamespace(ns)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+              .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+              .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private [spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String, gracePerio: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+      val pod = client\n+        .pods\n+        .inNamespace(ns)\n+        .withName(pName)\n+        .get()\n+\n+      printMessage(\"Application status (driver): \" +\n+        Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriod: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8sSparkSubmitOperationsClient extends SparkSubmitOperationsClient\n+  with CommandLineLoggingUtils {\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((ns, pName))\n+      case Array(pName) => Some((\"default\", pName))\n+      case _ => None\n+    }\n+\n+    sIdParts match {\n+      case Some((ns, pName)) =>\n+        Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\n+          master,\n+          Some(ns),\n+          KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX,\n+          sparkConf,\n+          None,\n+          None)) { kubernetesClient =>\n+          implicit val client: KubernetesClient = kubernetesClient\n+          if (isGlob(pName)) {\n+            val pods = {\n+              kubernetesClient\n+                .pods\n+                .inNamespace(ns)\n+                .list()\n+                .getItems\n+                .asScala\n+                .filter { pod =>\n+                  val meta = pod.getMetadata\n+                  meta.getName.startsWith(pName.stripSuffix(\"*\")) &&\n+                    meta"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: `.foreach { pod => ... }`",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-07T21:08:53Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "whole statement fits one line",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-07T21:09:05Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      val nClient = client"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "indentation",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-07T21:09:21Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      val nClient = client\n+        .pods\n+        .inNamespace(ns)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+              .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "indentation is wrong",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-07T21:09:54Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      val nClient = client\n+        .pods\n+        .inNamespace(ns)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+              .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+              .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private [spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String, gracePerio: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+      val pod = client"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "The implicit part should have 2 spaces or 4? Currently im using 4.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-08T14:15:55Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      val nClient = client\n+        .pods\n+        .inNamespace(ns)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+              .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+              .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private [spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String, gracePerio: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+      val pod = client"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "arguments = 4, code = 2.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-08T17:24:36Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private [spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach(pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\"))\n+      val nClient = client\n+        .pods\n+        .inNamespace(ns)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+              .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+              .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private [spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String, gracePerio: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+      val pod = client"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "If I understand the code correctly, the only advantage of this abstraction is that in the non-glob case you avoid fetching the pod data from the k8s server, and just issue a direct call to delete the pod.\r\n\r\nSeems to me the code would be a lot simpler if you got rid of that distinction, and all it would cost is one extra request to the api server to achieve that.\r\n\r\nOr is there something else I'm missing?",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-07T21:12:07Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Yes I am trying to avoid redundant api calls to the k8s api server. I was thinking about this trade-off as well. I made a choice.\r\nThe related methods have some differences in the implementation of the code too, as deletion does not happen with the same calls at the fabric8io client. Also I can add more ops in the future this way based on globs or not. ",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-08T14:10:38Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private [spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "These classes (except `K8sSparkSubmitOperationsClient`) can be just plain `private`, I'm almost sure.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-13T18:57:53Z",
    "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private[spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "will check.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-14T12:38:36Z",
    "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private[spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I swear I remember asking about this...\r\n\r\nBut if I submit an app to k8s, without specifying a namespace, is the namespace \"default\", or can it change depending on my k8s client config?\r\n\r\nIf the latter, this needs to behave accordingly.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-13T19:01:28Z",
    "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private[spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private[spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = client.pods.inNamespace(ns)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+               .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+               .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String, gracePerio: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val pod = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      .get()\n+\n+    printMessage(\"Application status (driver): \" +\n+      Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriod: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8sSparkSubmitOperationsClient extends SparkSubmitOperationsClient\n+  with CommandLineLoggingUtils {\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((ns, pName))\n+      case Array(pName) => Some((\"default\", pName))"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "It is the default, I documented it. I will write explicitly that no config can change that.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-02-14T12:11:07Z",
    "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private[spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private[spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = client.pods.inNamespace(ns)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+               .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+               .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String, gracePerio: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val pod = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      .get()\n+\n+    printMessage(\"Application status (driver): \" +\n+      Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriod: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8sSparkSubmitOperationsClient extends SparkSubmitOperationsClient\n+  with CommandLineLoggingUtils {\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((ns, pName))\n+      case Array(pName) => Some((\"default\", pName))"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "This is broken on minikube btw: https://github.com/kubernetes/minikube/issues/2117.\r\nAFAIK from the integration tests and the `KubeConfigBackend` logic, the ns used by the fabric8io client if none is specified is the \"default\". Will test if that works.\r\n \r\n",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-08T14:37:26Z",
    "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperationsClient}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private[spark] sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private[spark] class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriodSeconds: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = client.pods.inNamespace(ns)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+               .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+               .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String, gracePerio: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    val pod = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      .get()\n+\n+    printMessage(\"Application status (driver): \" +\n+      Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, gracePeriod: Option[Long])\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8sSparkSubmitOperationsClient extends SparkSubmitOperationsClient\n+  with CommandLineLoggingUtils {\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((ns, pName))\n+      case Array(pName) => Some((\"default\", pName))"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "Now the api is more generic.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-09T02:48:38Z",
    "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperation}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, sparkConf: SparkConf)"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "No need to use a new type here.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-09T12:26:59Z",
    "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.{SparkSubmitArguments, SparkSubmitOperation}\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, ns: String, sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: String, sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, ns: String, sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = client.pods.inNamespace(ns)\n+      val gracePeriodSeconds = getGracePeriod(sparkConf)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+               .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+               .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, ns: String, sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val pod = client\n+      .pods\n+      .inNamespace(ns)\n+      .withName(pName)\n+      .get()\n+\n+    printMessage(\"Application status (driver): \" +\n+      Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: String, sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8SSparkSubmitOperation extends SparkSubmitOperation\n+  with CommandLineLoggingUtils {\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((ns, pName))\n+      case Array(pName) => Some((\"default\", pName))\n+      case _ => None\n+    }\n+\n+    sIdParts match {\n+      case Some((ns, pName)) =>\n+        Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\n+          master,\n+          Some(ns),\n+          KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX,\n+          SparkKubernetesClientFactory.ClientType.Submission,",
    "line": 131
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "Not easy to return from one function these two types `MixedOperation[...` and `NonNamespaceOperation[...]`.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-09T20:59:55Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkSubmitOperation\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = {\n+     namespace match {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "They must have some common parent type since otherwise this wouldn't compile. A quick test tells me that type is `MixedOperation`.\r\n\r\nOr if the helper method is non-public you can cheat and not add a return type:\r\n\r\n```\r\nscala> def foo = { 1 }\r\nfoo: Int\r\n```\r\n\r\n(Spark's style checker will only complain about that if the method is public, IIRC.)",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-22T23:38:40Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkSubmitOperation\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = {\n+     namespace match {"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This looks a bit weird here. Prefer `Option(pod.get())` below.\r\n\r\nAlso, shouldn't you print a different message if the pod is not found? I see you do in `formatPodState`, but if the pod is not found I'd rather not have the header at all (like the `executeOnGlob` case).",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-12T22:19:49Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkSubmitOperation\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = {\n+     namespace match {\n+       case Some(ns) => client.pods.inNamespace(ns)\n+       case None => client.pods\n+     }\n+    }.withName(pName)\n+\n+    gracePeriodSeconds match {\n+      case Some(period) => podToDelete.withGracePeriod(period).delete()\n+      case _ => podToDelete.delete()\n+    }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = {\n+        namespace match {\n+          case Some(ns) => client.pods.inNamespace(ns)\n+          case None => client.pods\n+        }\n+      }\n+\n+      val gracePeriodSeconds = getGracePeriod(sparkConf)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+               .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+               .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val pod = {\n+      namespace match {\n+        case Some(ns) => client.pods.inNamespace(ns)\n+        case None => client.pods\n+      }\n+    }.withName(pName)\n+      .get()"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Fixed that.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-19T01:41:11Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkSubmitOperation\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = {\n+     namespace match {\n+       case Some(ns) => client.pods.inNamespace(ns)\n+       case None => client.pods\n+     }\n+    }.withName(pName)\n+\n+    gracePeriodSeconds match {\n+      case Some(period) => podToDelete.withGracePeriod(period).delete()\n+      case _ => podToDelete.delete()\n+    }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = {\n+        namespace match {\n+          case Some(ns) => client.pods.inNamespace(ns)\n+          case None => client.pods\n+        }\n+      }\n+\n+      val gracePeriodSeconds = getGracePeriod(sparkConf)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+               .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+               .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val pod = {\n+      namespace match {\n+        case Some(ns) => client.pods.inNamespace(ns)\n+        case None => client.pods\n+      }\n+    }.withName(pName)\n+      .get()"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Shouldn't this be an error?\r\n\r\nOr maybe you should use `.split(\":\", 2)`?\r\n\r\n(You seem to handle `None` below, but why wait until then?)",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-12T22:22:41Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkSubmitOperation\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = {\n+     namespace match {\n+       case Some(ns) => client.pods.inNamespace(ns)\n+       case None => client.pods\n+     }\n+    }.withName(pName)\n+\n+    gracePeriodSeconds match {\n+      case Some(period) => podToDelete.withGracePeriod(period).delete()\n+      case _ => podToDelete.delete()\n+    }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = {\n+        namespace match {\n+          case Some(ns) => client.pods.inNamespace(ns)\n+          case None => client.pods\n+        }\n+      }\n+\n+      val gracePeriodSeconds = getGracePeriod(sparkConf)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+               .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+               .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val pod = {\n+      namespace match {\n+        case Some(ns) => client.pods.inNamespace(ns)\n+        case None => client.pods\n+      }\n+    }.withName(pName)\n+      .get()\n+\n+    printMessage(\"Application status (driver): \" +\n+      Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8SSparkSubmitOperation extends SparkSubmitOperation\n+  with CommandLineLoggingUtils {\n+\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((Some(ns), pName))\n+      case Array(pName) => Some((None, pName))\n+      case _ => None"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "I like this pattern matching. I could handle it there and leave the other matching latter empty. Anyway I can update it.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-15T16:26:08Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkSubmitOperation\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = {\n+     namespace match {\n+       case Some(ns) => client.pods.inNamespace(ns)\n+       case None => client.pods\n+     }\n+    }.withName(pName)\n+\n+    gracePeriodSeconds match {\n+      case Some(period) => podToDelete.withGracePeriod(period).delete()\n+      case _ => podToDelete.delete()\n+    }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = {\n+        namespace match {\n+          case Some(ns) => client.pods.inNamespace(ns)\n+          case None => client.pods\n+        }\n+      }\n+\n+      val gracePeriodSeconds = getGracePeriod(sparkConf)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+               .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+               .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val pod = {\n+      namespace match {\n+        case Some(ns) => client.pods.inNamespace(ns)\n+        case None => client.pods\n+      }\n+    }.withName(pName)\n+      .get()\n+\n+    printMessage(\"Application status (driver): \" +\n+      Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8SSparkSubmitOperation extends SparkSubmitOperation\n+  with CommandLineLoggingUtils {\n+\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((Some(ns), pName))\n+      case Array(pName) => Some((None, pName))\n+      case _ => None"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Why not just call the argument `submissionId` in all these methods?",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-12T22:24:49Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkSubmitOperation\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = {\n+     namespace match {\n+       case Some(ns) => client.pods.inNamespace(ns)\n+       case None => client.pods\n+     }\n+    }.withName(pName)\n+\n+    gracePeriodSeconds match {\n+      case Some(period) => podToDelete.withGracePeriod(period).delete()\n+      case _ => podToDelete.delete()\n+    }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = {\n+        namespace match {\n+          case Some(ns) => client.pods.inNamespace(ns)\n+          case None => client.pods\n+        }\n+      }\n+\n+      val gracePeriodSeconds = getGracePeriod(sparkConf)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+               .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+               .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val pod = {\n+      namespace match {\n+        case Some(ns) => client.pods.inNamespace(ns)\n+        case None => client.pods\n+      }\n+    }.withName(pName)\n+      .get()\n+\n+    printMessage(\"Application status (driver): \" +\n+      Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8SSparkSubmitOperation extends SparkSubmitOperation\n+  with CommandLineLoggingUtils {\n+\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((Some(ns), pName))\n+      case Array(pName) => Some((None, pName))\n+      case _ => None\n+    }\n+\n+    sIdParts match {\n+      case Some((namespace, pName)) =>\n+        Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\n+          master,\n+          namespace,\n+          KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX,\n+          SparkKubernetesClientFactory.ClientType.Submission,\n+          sparkConf,\n+          None,\n+          None)\n+        ) { kubernetesClient =>\n+          implicit val client: KubernetesClient = kubernetesClient\n+          if (isGlob(pName)) {\n+            val ops = namespace match {\n+              case Some(ns) =>\n+                kubernetesClient\n+                  .pods\n+                  .inNamespace(ns)\n+              case None =>\n+                kubernetesClient\n+                  .pods\n+            }\n+            val pods = ops\n+              .list()\n+              .getItems\n+              .asScala\n+              .filter { pod =>\n+                val meta = pod.getMetadata\n+                meta.getName.startsWith(pName.stripSuffix(\"*\")) &&\n+                  meta.getLabels.get(SPARK_ROLE_LABEL) == SPARK_POD_DRIVER_ROLE\n+              }.toList\n+            op.executeOnGlob(pods, namespace, sparkConf)\n+          } else {\n+            op.executeOnPod(pName, namespace, sparkConf)\n+          }\n+        }\n+      case _ => printErrorAndExit(s\"submissionId: {$submissionId} is invalid.\")\n+    }\n+  }\n+\n+  override def kill(submissionToKill: String, conf: SparkConf): Unit = {\n+    printMessage(s\"Submitting a request to kill submission \" +\n+      s\"${submissionToKill} in ${conf.get(\"spark.master\")}. \" +\n+      s\"Grace period in secs: ${getGracePeriod(conf).getOrElse(\"not set.\")}\")\n+    execute(submissionToKill, conf, new KillApplication)\n+  }\n+\n+  override def printSubmissionStatus(submissionToPrintStatusFor: String, conf: SparkConf): Unit = {"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "I kept the old terminology but i can update it. If you check the spark submit uses for example `args.submissionToRequestStatusFor`...",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-15T16:12:21Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkSubmitOperation\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = {\n+     namespace match {\n+       case Some(ns) => client.pods.inNamespace(ns)\n+       case None => client.pods\n+     }\n+    }.withName(pName)\n+\n+    gracePeriodSeconds match {\n+      case Some(period) => podToDelete.withGracePeriod(period).delete()\n+      case _ => podToDelete.delete()\n+    }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = {\n+        namespace match {\n+          case Some(ns) => client.pods.inNamespace(ns)\n+          case None => client.pods\n+        }\n+      }\n+\n+      val gracePeriodSeconds = getGracePeriod(sparkConf)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+               .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+               .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val pod = {\n+      namespace match {\n+        case Some(ns) => client.pods.inNamespace(ns)\n+        case None => client.pods\n+      }\n+    }.withName(pName)\n+      .get()\n+\n+    printMessage(\"Application status (driver): \" +\n+      Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8SSparkSubmitOperation extends SparkSubmitOperation\n+  with CommandLineLoggingUtils {\n+\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((Some(ns), pName))\n+      case Array(pName) => Some((None, pName))\n+      case _ => None\n+    }\n+\n+    sIdParts match {\n+      case Some((namespace, pName)) =>\n+        Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\n+          master,\n+          namespace,\n+          KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX,\n+          SparkKubernetesClientFactory.ClientType.Submission,\n+          sparkConf,\n+          None,\n+          None)\n+        ) { kubernetesClient =>\n+          implicit val client: KubernetesClient = kubernetesClient\n+          if (isGlob(pName)) {\n+            val ops = namespace match {\n+              case Some(ns) =>\n+                kubernetesClient\n+                  .pods\n+                  .inNamespace(ns)\n+              case None =>\n+                kubernetesClient\n+                  .pods\n+            }\n+            val pods = ops\n+              .list()\n+              .getItems\n+              .asScala\n+              .filter { pod =>\n+                val meta = pod.getMetadata\n+                meta.getName.startsWith(pName.stripSuffix(\"*\")) &&\n+                  meta.getLabels.get(SPARK_ROLE_LABEL) == SPARK_POD_DRIVER_ROLE\n+              }.toList\n+            op.executeOnGlob(pods, namespace, sparkConf)\n+          } else {\n+            op.executeOnPod(pName, namespace, sparkConf)\n+          }\n+        }\n+      case _ => printErrorAndExit(s\"submissionId: {$submissionId} is invalid.\")\n+    }\n+  }\n+\n+  override def kill(submissionToKill: String, conf: SparkConf): Unit = {\n+    printMessage(s\"Submitting a request to kill submission \" +\n+      s\"${submissionToKill} in ${conf.get(\"spark.master\")}. \" +\n+      s\"Grace period in secs: ${getGracePeriod(conf).getOrElse(\"not set.\")}\")\n+    execute(submissionToKill, conf, new KillApplication)\n+  }\n+\n+  override def printSubmissionStatus(submissionToPrintStatusFor: String, conf: SparkConf): Unit = {"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Fixed that.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-19T01:47:32Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkSubmitOperation\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = {\n+     namespace match {\n+       case Some(ns) => client.pods.inNamespace(ns)\n+       case None => client.pods\n+     }\n+    }.withName(pName)\n+\n+    gracePeriodSeconds match {\n+      case Some(period) => podToDelete.withGracePeriod(period).delete()\n+      case _ => podToDelete.delete()\n+    }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = {\n+        namespace match {\n+          case Some(ns) => client.pods.inNamespace(ns)\n+          case None => client.pods\n+        }\n+      }\n+\n+      val gracePeriodSeconds = getGracePeriod(sparkConf)\n+      gracePeriodSeconds match {\n+        case Some(period) =>\n+          // this is not using the batch api because no option is provided\n+          // when using the grace period.\n+          pods.foreach { pod =>\n+             nClient\n+               .withName(pod.getMetadata.getName)\n+               .withGracePeriod(period)\n+               .delete()\n+          }\n+        case _ => nClient.delete(pods.asJava)\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private class ListStatus extends K8sSubmitOp {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val pod = {\n+      namespace match {\n+        case Some(ns) => client.pods.inNamespace(ns)\n+        case None => client.pods\n+      }\n+    }.withName(pName)\n+      .get()\n+\n+    printMessage(\"Application status (driver): \" +\n+      Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      for (pod <- pods) {\n+        printMessage(\"Application status (driver): \" +\n+          Option(pod).map(formatPodState).getOrElse(\"unknown.\"))\n+      }\n+    } else {\n+      printMessage(\"No applications found.\")\n+    }\n+  }\n+}\n+\n+private[spark] class K8SSparkSubmitOperation extends SparkSubmitOperation\n+  with CommandLineLoggingUtils {\n+\n+  private def isGlob(name: String): Boolean = {\n+    name.last == '*'\n+  }\n+\n+  def execute(submissionId: String, sparkConf: SparkConf, op: K8sSubmitOp): Unit = {\n+    val master = KubernetesUtils.parseMasterUrl(sparkConf.get(\"spark.master\"))\n+    val sIdParts = submissionId.split(\":\") match {\n+      case Array(ns, pName) => Some((Some(ns), pName))\n+      case Array(pName) => Some((None, pName))\n+      case _ => None\n+    }\n+\n+    sIdParts match {\n+      case Some((namespace, pName)) =>\n+        Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient(\n+          master,\n+          namespace,\n+          KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX,\n+          SparkKubernetesClientFactory.ClientType.Submission,\n+          sparkConf,\n+          None,\n+          None)\n+        ) { kubernetesClient =>\n+          implicit val client: KubernetesClient = kubernetesClient\n+          if (isGlob(pName)) {\n+            val ops = namespace match {\n+              case Some(ns) =>\n+                kubernetesClient\n+                  .pods\n+                  .inNamespace(ns)\n+              case None =>\n+                kubernetesClient\n+                  .pods\n+            }\n+            val pods = ops\n+              .list()\n+              .getItems\n+              .asScala\n+              .filter { pod =>\n+                val meta = pod.getMetadata\n+                meta.getName.startsWith(pName.stripSuffix(\"*\")) &&\n+                  meta.getLabels.get(SPARK_ROLE_LABEL) == SPARK_POD_DRIVER_ROLE\n+              }.toList\n+            op.executeOnGlob(pods, namespace, sparkConf)\n+          } else {\n+            op.executeOnPod(pName, namespace, sparkConf)\n+          }\n+        }\n+      case _ => printErrorAndExit(s\"submissionId: {$submissionId} is invalid.\")\n+    }\n+  }\n+\n+  override def kill(submissionToKill: String, conf: SparkConf): Unit = {\n+    printMessage(s\"Submitting a request to kill submission \" +\n+      s\"${submissionToKill} in ${conf.get(\"spark.master\")}. \" +\n+      s\"Grace period in secs: ${getGracePeriod(conf).getOrElse(\"not set.\")}\")\n+    execute(submissionToKill, conf, new KillApplication)\n+  }\n+\n+  override def printSubmissionStatus(submissionToPrintStatusFor: String, conf: SparkConf): Unit = {"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`getGracePeriod(sparkConf) match {` and save one line.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-22T23:24:33Z",
    "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkSubmitOperation\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = {\n+     namespace match {\n+       case Some(ns) => client.pods.inNamespace(ns)\n+       case None => client.pods\n+     }\n+    }.withName(pName)\n+\n+    if (Option(podToDelete).isDefined) {\n+      gracePeriodSeconds match {\n+        case Some(period) => podToDelete.withGracePeriod(period).delete()\n+        case _ => podToDelete.delete()\n+      }\n+    } else {\n+      printMessage(\"Application not found.\")\n+    }\n+  }\n+\n+  override def executeOnGlob(pods: List[Pod], namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    if (pods.nonEmpty) {\n+      pods.foreach { pod => printMessage(s\"Deleting driver pod: ${pod.getMetadata.getName}.\") }\n+      val nClient = {\n+        namespace match {\n+          case Some(ns) => client.pods.inNamespace(ns)\n+          case None => client.pods\n+        }\n+      }\n+\n+      val gracePeriodSeconds = getGracePeriod(sparkConf)\n+      gracePeriodSeconds match {"
  }],
  "prId": 23599
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Same here re: avoiding the `gracePeriodSeconds` variable.",
    "commit": "119f5a360b6064c4f033c9a34f0a5b4efcbe83a0",
    "createdAt": "2019-03-22T23:27:59Z",
    "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit\n+\n+import scala.collection.JavaConverters._\n+\n+import K8SSparkSubmitOperation.getGracePeriod\n+import io.fabric8.kubernetes.api.model.Pod\n+import io.fabric8.kubernetes.client.KubernetesClient\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkSubmitOperation\n+import org.apache.spark.deploy.k8s.{KubernetesUtils, SparkKubernetesClientFactory}\n+import org.apache.spark.deploy.k8s.Config.{KUBERNETES_AUTH_SUBMISSION_CONF_PREFIX, KUBERNETES_SUBMIT_GRACE_PERIOD}\n+import org.apache.spark.deploy.k8s.Constants.{SPARK_POD_DRIVER_ROLE, SPARK_ROLE_LABEL}\n+import org.apache.spark.deploy.k8s.KubernetesUtils.formatPodState\n+import org.apache.spark.util.{CommandLineLoggingUtils, Utils}\n+\n+private sealed trait K8sSubmitOp extends CommandLineLoggingUtils {\n+  def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+  def executeOnGlob(pods: List[Pod], ns: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit\n+}\n+\n+private class KillApplication extends K8sSubmitOp  {\n+  override def executeOnPod(pName: String, namespace: Option[String], sparkConf: SparkConf)\n+      (implicit client: KubernetesClient): Unit = {\n+    val gracePeriodSeconds = getGracePeriod(sparkConf)\n+    val podToDelete = {\n+     namespace match {\n+       case Some(ns) => client.pods.inNamespace(ns)\n+       case None => client.pods\n+     }\n+    }.withName(pName)\n+\n+    if (Option(podToDelete).isDefined) {\n+      gracePeriodSeconds match {"
  }],
  "prId": 23599
}]