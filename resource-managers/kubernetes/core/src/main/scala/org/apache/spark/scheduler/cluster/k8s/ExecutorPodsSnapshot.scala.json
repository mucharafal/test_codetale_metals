[{
  "comments": [{
    "author": {
      "login": "tnachen"
    },
    "body": "Can we add a test for this?",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-08-30T05:09:45Z",
    "diffHunk": "@@ -42,32 +43,47 @@ object ExecutorPodsSnapshot extends Logging {\n     ExecutorPodsSnapshot(toStatesByExecutorId(executorPods))\n   }\n \n-  def apply(): ExecutorPodsSnapshot = ExecutorPodsSnapshot(Map.empty[Long, ExecutorPodState])\n+  def apply(): ExecutorPodsSnapshot = ExecutorPodsSnapshot(Map.empty[Long, ExecutorState])\n \n-  private def toStatesByExecutorId(executorPods: Seq[Pod]): Map[Long, ExecutorPodState] = {\n+  private def toStatesByExecutorId(executorPods: Seq[Pod]): Map[Long, ExecutorState] = {\n     executorPods.map { pod =>\n       (pod.getMetadata.getLabels.get(SPARK_EXECUTOR_ID_LABEL).toLong, toState(pod))\n     }.toMap\n   }\n \n-  private def toState(pod: Pod): ExecutorPodState = {\n+  private def toState(pod: Pod): ExecutorState = {\n     if (isDeleted(pod)) {\n-      PodDeleted(pod)\n+      ExecutorPodDeleted(pod)\n     } else {\n       val phase = pod.getStatus.getPhase.toLowerCase(Locale.ROOT)\n       phase match {\n         case \"pending\" =>\n-          PodPending(pod)\n+          ExecutorPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // Checking executor container status is not terminated",
    "line": 18
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "Is the failedExecutorWithRuningSidecar bellow now what you're looking for?",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-17T01:11:30Z",
    "diffHunk": "@@ -42,32 +43,47 @@ object ExecutorPodsSnapshot extends Logging {\n     ExecutorPodsSnapshot(toStatesByExecutorId(executorPods))\n   }\n \n-  def apply(): ExecutorPodsSnapshot = ExecutorPodsSnapshot(Map.empty[Long, ExecutorPodState])\n+  def apply(): ExecutorPodsSnapshot = ExecutorPodsSnapshot(Map.empty[Long, ExecutorState])\n \n-  private def toStatesByExecutorId(executorPods: Seq[Pod]): Map[Long, ExecutorPodState] = {\n+  private def toStatesByExecutorId(executorPods: Seq[Pod]): Map[Long, ExecutorState] = {\n     executorPods.map { pod =>\n       (pod.getMetadata.getLabels.get(SPARK_EXECUTOR_ID_LABEL).toLong, toState(pod))\n     }.toMap\n   }\n \n-  private def toState(pod: Pod): ExecutorPodState = {\n+  private def toState(pod: Pod): ExecutorState = {\n     if (isDeleted(pod)) {\n-      PodDeleted(pod)\n+      ExecutorPodDeleted(pod)\n     } else {\n       val phase = pod.getStatus.getPhase.toLowerCase(Locale.ROOT)\n       phase match {\n         case \"pending\" =>\n-          PodPending(pod)\n+          ExecutorPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // Checking executor container status is not terminated",
    "line": 18
  }],
  "prId": 25614
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Hi, @jinxingwang .\r\n- First of all, in the shared repository like Apache Spark, we had better use **IDed** `TODO`. If this is needed, you had better use `TODO(SPARK-XXXXX)` style.\r\n- Second, please use the exact version instead of `upcoming` or `latest` because those words become obsolete very soon especially in K8s domain.\r\n- According to the PR content, it looks like you are saying we can skip this PR technically. Could you be more clear why we need to have this code?",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-06T22:19:06Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO: upcoming Kubernenetes feature will make this code redundant"
  }, {
    "author": {
      "login": "jinxingwang"
    },
    "body": "We needed because currently there is no solution from k8s yet, and this is a bug.\r\nAlso even there is a solution, that will require the users to upgrade k8s.",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-06T22:30:12Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO: upcoming Kubernenetes feature will make this code redundant"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Then, please enumerate the exact K8s versions in the PR description which you target in this PR. Also, you need to create another JIRA issue to remove this TODO (and your code) later.",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-06T22:32:22Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO: upcoming Kubernenetes feature will make this code redundant"
  }, {
    "author": {
      "login": "jinxingwang"
    },
    "body": "Will do, thanks!",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-06T22:36:02Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO: upcoming Kubernenetes feature will make this code redundant"
  }],
  "prId": 25614
}, {
  "comments": [{
    "author": {
      "login": "holdenk"
    },
    "body": "Same comment as above. If the container name is generally enforced elsehwere that's ok but if we're depending on Spark being the only one to launch we should see if there is another filter we could do (maybe a tag)?",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-09T15:43:45Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO: upcoming Kubernenetes feature will make this code redundant\n+          // https://github.com/kubernetes/enhancements/issues/753\n+          // Checking executor container status is not terminated\n+          // Pod status can still be running if sidecar container status is running\n+          val executorContainerStatusCode = pod.getStatus.getContainerStatuses.asScala.\n+            filter(_.getName == DEFAULT_EXECUTOR_CONTAINER_NAME).",
    "line": 21
  }, {
    "author": {
      "login": "jinxingwang"
    },
    "body": "I think you made a really good point, but as far as I know, there is no identifier of container expect the container name. maybe we have to force people use this default name.   ",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-09T16:51:17Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO: upcoming Kubernenetes feature will make this code redundant\n+          // https://github.com/kubernetes/enhancements/issues/753\n+          // Checking executor container status is not terminated\n+          // Pod status can still be running if sidecar container status is running\n+          val executorContainerStatusCode = pod.getStatus.getContainerStatuses.asScala.\n+            filter(_.getName == DEFAULT_EXECUTOR_CONTAINER_NAME).",
    "line": 21
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "Ok, this is probably a rare case but (for example) the Google K8s Spark folks launch their own containers I believe, so let's try and make not of this in the migration guide.",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-17T01:05:13Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO: upcoming Kubernenetes feature will make this code redundant\n+          // https://github.com/kubernetes/enhancements/issues/753\n+          // Checking executor container status is not terminated\n+          // Pod status can still be running if sidecar container status is running\n+          val executorContainerStatusCode = pod.getStatus.getContainerStatuses.asScala.\n+            filter(_.getName == DEFAULT_EXECUTOR_CONTAINER_NAME).",
    "line": 21
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "@holdenk @jinxingwang one idea is to introduce a conf option for the executor container name so it can be tracked in cluster mode in case it is modified by the pod template feature.",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-19T10:43:31Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO: upcoming Kubernenetes feature will make this code redundant\n+          // https://github.com/kubernetes/enhancements/issues/753\n+          // Checking executor container status is not terminated\n+          // Pod status can still be running if sidecar container status is running\n+          val executorContainerStatusCode = pod.getStatus.getContainerStatuses.asScala.\n+            filter(_.getName == DEFAULT_EXECUTOR_CONTAINER_NAME).",
    "line": 21
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "That would be a cool, I think we can probably just mention it in the migration guide if we don't, but if we add setting for configuring the container name I'm good with that too.",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-20T16:37:49Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO: upcoming Kubernenetes feature will make this code redundant\n+          // https://github.com/kubernetes/enhancements/issues/753\n+          // Checking executor container status is not terminated\n+          // Pod status can still be running if sidecar container status is running\n+          val executorContainerStatusCode = pod.getStatus.getContainerStatuses.asScala.\n+            filter(_.getName == DEFAULT_EXECUTOR_CONTAINER_NAME).",
    "line": 21
  }],
  "prId": 25614
}, {
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "What if the side car thing provides a service that we need eg. kerberos renewal, shouldnt we remove the executor pod asap and not wait for the Spark container error to happen? I think we should emit a log msg at least eg. \"Spark executor is running but pod is not healthy\". Or we could have a configurable property to allow removal if any container is failing. In addition, Pod restartPolicy is set to `Never` and the will be no recovery for the side car. I think we could provide a few more managements capabilities. Thoughts?",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-19T10:56:12Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO(SPARK-29023): Kubernenetes 1.17 sidecar container feature will\n+          // make this code redundant https://github.com/kubernetes/enhancements/issues/753\n+          // Checking executor container status is not terminated\n+          // Pod status can still be running if sidecar container status is running",
    "line": 19
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "That's a good point. I don't know how often the sidecar is \"critical\" to keep running along side Spark so I'll defer to other's judgement here.",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-20T16:40:00Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO(SPARK-29023): Kubernenetes 1.17 sidecar container feature will\n+          // make this code redundant https://github.com/kubernetes/enhancements/issues/753\n+          // Checking executor container status is not terminated\n+          // Pod status can still be running if sidecar container status is running",
    "line": 19
  }, {
    "author": {
      "login": "jinxingwang"
    },
    "body": "The current state is if any container is running, the pod will keep running, so there is no case \"Spark executor is running but pod is not healthy\" but will happen \"pod is healthy but Spark executor container(or any sidecar container) is not running \"\r\nMy change made \"main(executor)\" container reflect on the pod status.\r\nYour point is very good, that other sidecar also should be healthy when they should be. My thoughts on it are, sidecars are not as critical as \"main\" container in some case, and should not necessary cause pod to restart all the time. so I will like it to happen is to let \"main(executor)\" container determine if a pod should be restarted. which should be main container error out when any of its sidecar container is not healthy. \r\nLet me know what you guys think. thanks.",
    "commit": "b69ba8af1d5107806844510e1878b3813f1007aa",
    "createdAt": "2019-09-20T17:01:49Z",
    "diffHunk": "@@ -59,7 +61,24 @@ object ExecutorPodsSnapshot extends Logging {\n         case \"pending\" =>\n           PodPending(pod)\n         case \"running\" =>\n-          PodRunning(pod)\n+          // TODO(SPARK-29023): Kubernenetes 1.17 sidecar container feature will\n+          // make this code redundant https://github.com/kubernetes/enhancements/issues/753\n+          // Checking executor container status is not terminated\n+          // Pod status can still be running if sidecar container status is running",
    "line": 19
  }],
  "prId": 25614
}]