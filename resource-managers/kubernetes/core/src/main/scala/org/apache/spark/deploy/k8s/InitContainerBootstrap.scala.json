[{
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "nit: remove an extra line.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-15T08:05:35Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * This is separated out from the init-container steps API because this component can be reused to\n+ * set up the init-container for executors as well.\n+ */\n+private[spark] trait InitContainerBootstrap {\n+  /**\n+   * Bootstraps an init-container that downloads dependencies to be used by a main container.\n+   */\n+  def bootstrapInitContainer(\n+      originalPodWithInitContainer: PodWithDetachedInitContainer)\n+  : PodWithDetachedInitContainer\n+}\n+\n+private[spark] class InitContainerBootstrapImpl(\n+    initContainerImage: String,\n+    dockerImagePullPolicy: String,\n+    jarsDownloadPath: String,\n+    filesDownloadPath: String,\n+    downloadTimeoutMinutes: Long,\n+    initContainerConfigMapName: String,\n+    initContainerConfigMapKey: String,\n+    sparkRole: String,\n+    sparkConf: SparkConf)\n+  extends InitContainerBootstrap {\n+\n+  override def bootstrapInitContainer(\n+      podWithDetachedInitContainer: PodWithDetachedInitContainer): PodWithDetachedInitContainer = {\n+    val sharedVolumeMounts = Seq[VolumeMount](\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withMountPath(jarsDownloadPath)\n+        .build(),\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withMountPath(filesDownloadPath)\n+        .build())\n+\n+    val initContainerCustomEnvVarKeyPrefix = sparkRole match {\n+      case SPARK_POD_DRIVER_ROLE => KUBERNETES_DRIVER_ENV_KEY\n+      case SPARK_POD_EXECUTOR_ROLE => \"spark.executorEnv.\"\n+      case _ => throw new SparkException(s\"$sparkRole is not a valid Spark pod role\")\n+    }\n+    val initContainerCustomEnvVars = sparkConf.getAllWithPrefix(initContainerCustomEnvVarKeyPrefix)\n+      .toSeq\n+      .map(env =>\n+        new EnvVarBuilder()\n+          .withName(env._1)\n+          .withValue(env._2)\n+          .build())\n+\n+    val initContainer = new ContainerBuilder(podWithDetachedInitContainer.initContainer)\n+      .withName(s\"spark-init\")\n+      .withImage(initContainerImage)\n+      .withImagePullPolicy(dockerImagePullPolicy)\n+      .addAllToEnv(initContainerCustomEnvVars.asJava)\n+      .addNewVolumeMount()\n+        .withName(INIT_CONTAINER_PROPERTIES_FILE_VOLUME)\n+        .withMountPath(INIT_CONTAINER_PROPERTIES_FILE_DIR)\n+        .endVolumeMount()\n+      .addToVolumeMounts(sharedVolumeMounts: _*)\n+      .addToArgs(INIT_CONTAINER_PROPERTIES_FILE_PATH)\n+      .build()\n+\n+    val podWithBasicVolumes = new PodBuilder(podWithDetachedInitContainer.pod)\n+      .editSpec()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_PROPERTIES_FILE_VOLUME)\n+        .withNewConfigMap()\n+          .withName(initContainerConfigMapName)\n+          .addNewItem()\n+            .withKey(initContainerConfigMapKey)\n+            .withPath(INIT_CONTAINER_PROPERTIES_FILE_NAME)\n+            .endItem()\n+          .endConfigMap()\n+        .endVolume()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withEmptyDir(new EmptyDirVolumeSource())\n+        .endVolume()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withEmptyDir(new EmptyDirVolumeSource())\n+        .endVolume()\n+      .endSpec()\n+      .build()\n+\n+    val mainContainerWithMountedFiles = new ContainerBuilder(\n+      podWithDetachedInitContainer.mainContainer)\n+        .addToVolumeMounts(sharedVolumeMounts: _*)\n+        .addNewEnv()\n+          .withName(ENV_MOUNTED_FILES_DIR)\n+          .withValue(filesDownloadPath)\n+          .endEnv()\n+        .build()\n+\n+    PodWithDetachedInitContainer(\n+      podWithBasicVolumes,\n+      initContainer,\n+      mainContainerWithMountedFiles)\n+  }\n+"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "Done.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-15T16:45:43Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * This is separated out from the init-container steps API because this component can be reused to\n+ * set up the init-container for executors as well.\n+ */\n+private[spark] trait InitContainerBootstrap {\n+  /**\n+   * Bootstraps an init-container that downloads dependencies to be used by a main container.\n+   */\n+  def bootstrapInitContainer(\n+      originalPodWithInitContainer: PodWithDetachedInitContainer)\n+  : PodWithDetachedInitContainer\n+}\n+\n+private[spark] class InitContainerBootstrapImpl(\n+    initContainerImage: String,\n+    dockerImagePullPolicy: String,\n+    jarsDownloadPath: String,\n+    filesDownloadPath: String,\n+    downloadTimeoutMinutes: Long,\n+    initContainerConfigMapName: String,\n+    initContainerConfigMapKey: String,\n+    sparkRole: String,\n+    sparkConf: SparkConf)\n+  extends InitContainerBootstrap {\n+\n+  override def bootstrapInitContainer(\n+      podWithDetachedInitContainer: PodWithDetachedInitContainer): PodWithDetachedInitContainer = {\n+    val sharedVolumeMounts = Seq[VolumeMount](\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withMountPath(jarsDownloadPath)\n+        .build(),\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withMountPath(filesDownloadPath)\n+        .build())\n+\n+    val initContainerCustomEnvVarKeyPrefix = sparkRole match {\n+      case SPARK_POD_DRIVER_ROLE => KUBERNETES_DRIVER_ENV_KEY\n+      case SPARK_POD_EXECUTOR_ROLE => \"spark.executorEnv.\"\n+      case _ => throw new SparkException(s\"$sparkRole is not a valid Spark pod role\")\n+    }\n+    val initContainerCustomEnvVars = sparkConf.getAllWithPrefix(initContainerCustomEnvVarKeyPrefix)\n+      .toSeq\n+      .map(env =>\n+        new EnvVarBuilder()\n+          .withName(env._1)\n+          .withValue(env._2)\n+          .build())\n+\n+    val initContainer = new ContainerBuilder(podWithDetachedInitContainer.initContainer)\n+      .withName(s\"spark-init\")\n+      .withImage(initContainerImage)\n+      .withImagePullPolicy(dockerImagePullPolicy)\n+      .addAllToEnv(initContainerCustomEnvVars.asJava)\n+      .addNewVolumeMount()\n+        .withName(INIT_CONTAINER_PROPERTIES_FILE_VOLUME)\n+        .withMountPath(INIT_CONTAINER_PROPERTIES_FILE_DIR)\n+        .endVolumeMount()\n+      .addToVolumeMounts(sharedVolumeMounts: _*)\n+      .addToArgs(INIT_CONTAINER_PROPERTIES_FILE_PATH)\n+      .build()\n+\n+    val podWithBasicVolumes = new PodBuilder(podWithDetachedInitContainer.pod)\n+      .editSpec()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_PROPERTIES_FILE_VOLUME)\n+        .withNewConfigMap()\n+          .withName(initContainerConfigMapName)\n+          .addNewItem()\n+            .withKey(initContainerConfigMapKey)\n+            .withPath(INIT_CONTAINER_PROPERTIES_FILE_NAME)\n+            .endItem()\n+          .endConfigMap()\n+        .endVolume()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withEmptyDir(new EmptyDirVolumeSource())\n+        .endVolume()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withEmptyDir(new EmptyDirVolumeSource())\n+        .endVolume()\n+      .endSpec()\n+      .build()\n+\n+    val mainContainerWithMountedFiles = new ContainerBuilder(\n+      podWithDetachedInitContainer.mainContainer)\n+        .addToVolumeMounts(sharedVolumeMounts: _*)\n+        .addNewEnv()\n+          .withName(ENV_MOUNTED_FILES_DIR)\n+          .withValue(filesDownloadPath)\n+          .endEnv()\n+        .build()\n+\n+    PodWithDetachedInitContainer(\n+      podWithBasicVolumes,\n+      initContainer,\n+      mainContainerWithMountedFiles)\n+  }\n+"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "nit: remove `s`.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-15T08:06:55Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * This is separated out from the init-container steps API because this component can be reused to\n+ * set up the init-container for executors as well.\n+ */\n+private[spark] trait InitContainerBootstrap {\n+  /**\n+   * Bootstraps an init-container that downloads dependencies to be used by a main container.\n+   */\n+  def bootstrapInitContainer(\n+      originalPodWithInitContainer: PodWithDetachedInitContainer)\n+  : PodWithDetachedInitContainer\n+}\n+\n+private[spark] class InitContainerBootstrapImpl(\n+    initContainerImage: String,\n+    dockerImagePullPolicy: String,\n+    jarsDownloadPath: String,\n+    filesDownloadPath: String,\n+    downloadTimeoutMinutes: Long,\n+    initContainerConfigMapName: String,\n+    initContainerConfigMapKey: String,\n+    sparkRole: String,\n+    sparkConf: SparkConf)\n+  extends InitContainerBootstrap {\n+\n+  override def bootstrapInitContainer(\n+      podWithDetachedInitContainer: PodWithDetachedInitContainer): PodWithDetachedInitContainer = {\n+    val sharedVolumeMounts = Seq[VolumeMount](\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withMountPath(jarsDownloadPath)\n+        .build(),\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withMountPath(filesDownloadPath)\n+        .build())\n+\n+    val initContainerCustomEnvVarKeyPrefix = sparkRole match {\n+      case SPARK_POD_DRIVER_ROLE => KUBERNETES_DRIVER_ENV_KEY\n+      case SPARK_POD_EXECUTOR_ROLE => \"spark.executorEnv.\"\n+      case _ => throw new SparkException(s\"$sparkRole is not a valid Spark pod role\")\n+    }\n+    val initContainerCustomEnvVars = sparkConf.getAllWithPrefix(initContainerCustomEnvVarKeyPrefix)\n+      .toSeq\n+      .map(env =>\n+        new EnvVarBuilder()\n+          .withName(env._1)\n+          .withValue(env._2)\n+          .build())\n+\n+    val initContainer = new ContainerBuilder(podWithDetachedInitContainer.initContainer)\n+      .withName(s\"spark-init\")"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "Done.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-15T16:45:38Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * This is separated out from the init-container steps API because this component can be reused to\n+ * set up the init-container for executors as well.\n+ */\n+private[spark] trait InitContainerBootstrap {\n+  /**\n+   * Bootstraps an init-container that downloads dependencies to be used by a main container.\n+   */\n+  def bootstrapInitContainer(\n+      originalPodWithInitContainer: PodWithDetachedInitContainer)\n+  : PodWithDetachedInitContainer\n+}\n+\n+private[spark] class InitContainerBootstrapImpl(\n+    initContainerImage: String,\n+    dockerImagePullPolicy: String,\n+    jarsDownloadPath: String,\n+    filesDownloadPath: String,\n+    downloadTimeoutMinutes: Long,\n+    initContainerConfigMapName: String,\n+    initContainerConfigMapKey: String,\n+    sparkRole: String,\n+    sparkConf: SparkConf)\n+  extends InitContainerBootstrap {\n+\n+  override def bootstrapInitContainer(\n+      podWithDetachedInitContainer: PodWithDetachedInitContainer): PodWithDetachedInitContainer = {\n+    val sharedVolumeMounts = Seq[VolumeMount](\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withMountPath(jarsDownloadPath)\n+        .build(),\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withMountPath(filesDownloadPath)\n+        .build())\n+\n+    val initContainerCustomEnvVarKeyPrefix = sparkRole match {\n+      case SPARK_POD_DRIVER_ROLE => KUBERNETES_DRIVER_ENV_KEY\n+      case SPARK_POD_EXECUTOR_ROLE => \"spark.executorEnv.\"\n+      case _ => throw new SparkException(s\"$sparkRole is not a valid Spark pod role\")\n+    }\n+    val initContainerCustomEnvVars = sparkConf.getAllWithPrefix(initContainerCustomEnvVarKeyPrefix)\n+      .toSeq\n+      .map(env =>\n+        new EnvVarBuilder()\n+          .withName(env._1)\n+          .withValue(env._2)\n+          .build())\n+\n+    val initContainer = new ContainerBuilder(podWithDetachedInitContainer.initContainer)\n+      .withName(s\"spark-init\")"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`.map { env =>`",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-15T23:27:00Z",
    "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * This is separated out from the init-container steps API because this component can be reused to\n+ * set up the init-container for executors as well.\n+ */\n+private[spark] trait InitContainerBootstrap {\n+  /**\n+   * Bootstraps an init-container that downloads dependencies to be used by a main container.\n+   */\n+  def bootstrapInitContainer(\n+      originalPodWithInitContainer: PodWithDetachedInitContainer)\n+  : PodWithDetachedInitContainer\n+}\n+\n+private[spark] class InitContainerBootstrapImpl(\n+    initContainerImage: String,\n+    dockerImagePullPolicy: String,\n+    jarsDownloadPath: String,\n+    filesDownloadPath: String,\n+    downloadTimeoutMinutes: Long,\n+    initContainerConfigMapName: String,\n+    initContainerConfigMapKey: String,\n+    sparkRole: String,\n+    sparkConf: SparkConf)\n+  extends InitContainerBootstrap {\n+\n+  override def bootstrapInitContainer(\n+      podWithDetachedInitContainer: PodWithDetachedInitContainer): PodWithDetachedInitContainer = {\n+    val sharedVolumeMounts = Seq[VolumeMount](\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withMountPath(jarsDownloadPath)\n+        .build(),\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withMountPath(filesDownloadPath)\n+        .build())\n+\n+    val initContainerCustomEnvVarKeyPrefix = sparkRole match {\n+      case SPARK_POD_DRIVER_ROLE => KUBERNETES_DRIVER_ENV_KEY\n+      case SPARK_POD_EXECUTOR_ROLE => \"spark.executorEnv.\"\n+      case _ => throw new SparkException(s\"$sparkRole is not a valid Spark pod role\")\n+    }\n+    val initContainerCustomEnvVars = sparkConf.getAllWithPrefix(initContainerCustomEnvVarKeyPrefix)\n+      .toSeq\n+      .map(env =>"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "What's the purpose of all these traits that have a single implementation? That seems unnecessary.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-18T23:43:44Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * This is separated out from the init-container steps API because this component can be reused to\n+ * set up the init-container for executors as well.\n+ */\n+private[spark] trait InitContainerBootstrap {"
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "It's more idiomatic to mock a `trait` than a `class` and our unit tests always create mocks for every component that isn't the class under test.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-19T00:57:30Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * This is separated out from the init-container steps API because this component can be reused to\n+ * set up the init-container for executors as well.\n+ */\n+private[spark] trait InitContainerBootstrap {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> It's more idiomatic to mock a trait than a class \r\n\r\nWhy? You can mock classes just fine.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-19T01:01:38Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * This is separated out from the init-container steps API because this component can be reused to\n+ * set up the init-container for executors as well.\n+ */\n+private[spark] trait InitContainerBootstrap {"
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "It's probably fine to just use the class here, but some classes can't be mocked, such as final classes or classes with final methods. Having traits everywhere ensures that even if we change the classes down the road to have such characteristics, our tests won't break.\r\n\r\nThis also is not entirely without precedent. `TaskScheduler` is only implemented by `TaskSchedulerImpl` in the main scheduler code, as is `TaskContext` being extended only by `TaskContextImpl`. Putting a trait in front of an implementation communicates that it's expected for tests that dependency-inject instances of this to create stub implementations.\r\n\r\nBut we might be splitting hairs at this point, so using only the class could suffice until we run into problems from having done so.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-19T01:20:12Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * This is separated out from the init-container steps API because this component can be reused to\n+ * set up the init-container for executors as well.\n+ */\n+private[spark] trait InitContainerBootstrap {"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I commented about this in my previous review, but could you try to use shorter variable names throughout the PR?\r\n\r\nFor example, here, just repeating the name of the already long type to name the variable doesn't really help with readability. Imagine if you have two of those, are you going to start adding counters to the already long name?",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-18T23:46:29Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * This is separated out from the init-container steps API because this component can be reused to\n+ * set up the init-container for executors as well.\n+ */\n+private[spark] trait InitContainerBootstrap {\n+  /**\n+   * Bootstraps an init-container that downloads dependencies to be used by a main container.\n+   */\n+  def bootstrapInitContainer(\n+      originalPodWithInitContainer: PodWithDetachedInitContainer)\n+  : PodWithDetachedInitContainer\n+}\n+\n+private[spark] class InitContainerBootstrapImpl(\n+    initContainerImage: String,\n+    dockerImagePullPolicy: String,\n+    jarsDownloadPath: String,\n+    filesDownloadPath: String,\n+    downloadTimeoutMinutes: Long,\n+    initContainerConfigMapName: String,\n+    initContainerConfigMapKey: String,\n+    sparkRole: String,\n+    sparkConf: SparkConf)\n+  extends InitContainerBootstrap {\n+\n+  override def bootstrapInitContainer(\n+      podWithDetachedInitContainer: PodWithDetachedInitContainer): PodWithDetachedInitContainer = {"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "s/`env =>`/`case (key, value) =>`",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-19T21:31:20Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * Bootstraps an init-container for downloading remote dependencies. This is separated out from\n+ * the init-container steps API because this component can be used to bootstrap init-containers\n+ * for both the driver and executors.\n+ */\n+private[spark] class InitContainerBootstrap(\n+    initContainerImage: String,\n+    imagePullPolicy: String,\n+    jarsDownloadPath: String,\n+    filesDownloadPath: String,\n+    configMapName: String,\n+    configMapKey: String,\n+    sparkRole: String,\n+    sparkConf: SparkConf) {\n+\n+  /**\n+   * Bootstraps an init-container that downloads dependencies to be used by a main container.\n+   */\n+  def bootstrapInitContainer(\n+      original: PodWithDetachedInitContainer): PodWithDetachedInitContainer = {\n+    val sharedVolumeMounts = Seq[VolumeMount](\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withMountPath(jarsDownloadPath)\n+        .build(),\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withMountPath(filesDownloadPath)\n+        .build())\n+\n+    val customEnvVarKeyPrefix = sparkRole match {\n+      case SPARK_POD_DRIVER_ROLE => KUBERNETES_DRIVER_ENV_KEY\n+      case SPARK_POD_EXECUTOR_ROLE => \"spark.executorEnv.\"\n+      case _ => throw new SparkException(s\"$sparkRole is not a valid Spark pod role\")\n+    }\n+    val customEnvVars = sparkConf.getAllWithPrefix(customEnvVarKeyPrefix).toSeq.map { env =>"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "Done.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-20T00:31:16Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * Bootstraps an init-container for downloading remote dependencies. This is separated out from\n+ * the init-container steps API because this component can be used to bootstrap init-containers\n+ * for both the driver and executors.\n+ */\n+private[spark] class InitContainerBootstrap(\n+    initContainerImage: String,\n+    imagePullPolicy: String,\n+    jarsDownloadPath: String,\n+    filesDownloadPath: String,\n+    configMapName: String,\n+    configMapKey: String,\n+    sparkRole: String,\n+    sparkConf: SparkConf) {\n+\n+  /**\n+   * Bootstraps an init-container that downloads dependencies to be used by a main container.\n+   */\n+  def bootstrapInitContainer(\n+      original: PodWithDetachedInitContainer): PodWithDetachedInitContainer = {\n+    val sharedVolumeMounts = Seq[VolumeMount](\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withMountPath(jarsDownloadPath)\n+        .build(),\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withMountPath(filesDownloadPath)\n+        .build())\n+\n+    val customEnvVarKeyPrefix = sparkRole match {\n+      case SPARK_POD_DRIVER_ROLE => KUBERNETES_DRIVER_ENV_KEY\n+      case SPARK_POD_EXECUTOR_ROLE => \"spark.executorEnv.\"\n+      case _ => throw new SparkException(s\"$sparkRole is not a valid Spark pod role\")\n+    }\n+    val customEnvVars = sparkConf.getAllWithPrefix(customEnvVarKeyPrefix).toSeq.map { env =>"
  }],
  "prId": 19954
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Fits in previous line.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-19T21:34:29Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * Bootstraps an init-container for downloading remote dependencies. This is separated out from\n+ * the init-container steps API because this component can be used to bootstrap init-containers\n+ * for both the driver and executors.\n+ */\n+private[spark] class InitContainerBootstrap(\n+    initContainerImage: String,\n+    imagePullPolicy: String,\n+    jarsDownloadPath: String,\n+    filesDownloadPath: String,\n+    configMapName: String,\n+    configMapKey: String,\n+    sparkRole: String,\n+    sparkConf: SparkConf) {\n+\n+  /**\n+   * Bootstraps an init-container that downloads dependencies to be used by a main container.\n+   */\n+  def bootstrapInitContainer(\n+      original: PodWithDetachedInitContainer): PodWithDetachedInitContainer = {\n+    val sharedVolumeMounts = Seq[VolumeMount](\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withMountPath(jarsDownloadPath)\n+        .build(),\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withMountPath(filesDownloadPath)\n+        .build())\n+\n+    val customEnvVarKeyPrefix = sparkRole match {\n+      case SPARK_POD_DRIVER_ROLE => KUBERNETES_DRIVER_ENV_KEY\n+      case SPARK_POD_EXECUTOR_ROLE => \"spark.executorEnv.\"\n+      case _ => throw new SparkException(s\"$sparkRole is not a valid Spark pod role\")\n+    }\n+    val customEnvVars = sparkConf.getAllWithPrefix(customEnvVarKeyPrefix).toSeq.map { env =>\n+      new EnvVarBuilder()\n+        .withName(env._1)\n+        .withValue(env._2)\n+        .build()\n+    }\n+\n+    val initContainer = new ContainerBuilder(original.initContainer)\n+      .withName(\"spark-init\")\n+      .withImage(initContainerImage)\n+      .withImagePullPolicy(imagePullPolicy)\n+      .addAllToEnv(customEnvVars.asJava)\n+      .addNewVolumeMount()\n+        .withName(INIT_CONTAINER_PROPERTIES_FILE_VOLUME)\n+        .withMountPath(INIT_CONTAINER_PROPERTIES_FILE_DIR)\n+        .endVolumeMount()\n+      .addToVolumeMounts(sharedVolumeMounts: _*)\n+      .addToArgs(INIT_CONTAINER_PROPERTIES_FILE_PATH)\n+      .build()\n+\n+    val podWithBasicVolumes = new PodBuilder(original.pod)\n+      .editSpec()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_PROPERTIES_FILE_VOLUME)\n+        .withNewConfigMap()\n+          .withName(configMapName)\n+          .addNewItem()\n+            .withKey(configMapKey)\n+            .withPath(INIT_CONTAINER_PROPERTIES_FILE_NAME)\n+            .endItem()\n+          .endConfigMap()\n+        .endVolume()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withEmptyDir(new EmptyDirVolumeSource())\n+        .endVolume()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withEmptyDir(new EmptyDirVolumeSource())\n+        .endVolume()\n+      .endSpec()\n+      .build()\n+\n+    val mainContainer = new ContainerBuilder(\n+      original.mainContainer)"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "Done.",
    "commit": "28343fb50310826bc9962e785f25d1af9b3c3f4a",
    "createdAt": "2017-12-20T00:31:20Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.{ContainerBuilder, EmptyDirVolumeSource, EnvVarBuilder, PodBuilder, VolumeMount, VolumeMountBuilder}\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+\n+/**\n+ * Bootstraps an init-container for downloading remote dependencies. This is separated out from\n+ * the init-container steps API because this component can be used to bootstrap init-containers\n+ * for both the driver and executors.\n+ */\n+private[spark] class InitContainerBootstrap(\n+    initContainerImage: String,\n+    imagePullPolicy: String,\n+    jarsDownloadPath: String,\n+    filesDownloadPath: String,\n+    configMapName: String,\n+    configMapKey: String,\n+    sparkRole: String,\n+    sparkConf: SparkConf) {\n+\n+  /**\n+   * Bootstraps an init-container that downloads dependencies to be used by a main container.\n+   */\n+  def bootstrapInitContainer(\n+      original: PodWithDetachedInitContainer): PodWithDetachedInitContainer = {\n+    val sharedVolumeMounts = Seq[VolumeMount](\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withMountPath(jarsDownloadPath)\n+        .build(),\n+      new VolumeMountBuilder()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withMountPath(filesDownloadPath)\n+        .build())\n+\n+    val customEnvVarKeyPrefix = sparkRole match {\n+      case SPARK_POD_DRIVER_ROLE => KUBERNETES_DRIVER_ENV_KEY\n+      case SPARK_POD_EXECUTOR_ROLE => \"spark.executorEnv.\"\n+      case _ => throw new SparkException(s\"$sparkRole is not a valid Spark pod role\")\n+    }\n+    val customEnvVars = sparkConf.getAllWithPrefix(customEnvVarKeyPrefix).toSeq.map { env =>\n+      new EnvVarBuilder()\n+        .withName(env._1)\n+        .withValue(env._2)\n+        .build()\n+    }\n+\n+    val initContainer = new ContainerBuilder(original.initContainer)\n+      .withName(\"spark-init\")\n+      .withImage(initContainerImage)\n+      .withImagePullPolicy(imagePullPolicy)\n+      .addAllToEnv(customEnvVars.asJava)\n+      .addNewVolumeMount()\n+        .withName(INIT_CONTAINER_PROPERTIES_FILE_VOLUME)\n+        .withMountPath(INIT_CONTAINER_PROPERTIES_FILE_DIR)\n+        .endVolumeMount()\n+      .addToVolumeMounts(sharedVolumeMounts: _*)\n+      .addToArgs(INIT_CONTAINER_PROPERTIES_FILE_PATH)\n+      .build()\n+\n+    val podWithBasicVolumes = new PodBuilder(original.pod)\n+      .editSpec()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_PROPERTIES_FILE_VOLUME)\n+        .withNewConfigMap()\n+          .withName(configMapName)\n+          .addNewItem()\n+            .withKey(configMapKey)\n+            .withPath(INIT_CONTAINER_PROPERTIES_FILE_NAME)\n+            .endItem()\n+          .endConfigMap()\n+        .endVolume()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_DOWNLOAD_JARS_VOLUME_NAME)\n+        .withEmptyDir(new EmptyDirVolumeSource())\n+        .endVolume()\n+      .addNewVolume()\n+        .withName(INIT_CONTAINER_DOWNLOAD_FILES_VOLUME_NAME)\n+        .withEmptyDir(new EmptyDirVolumeSource())\n+        .endVolume()\n+      .endSpec()\n+      .build()\n+\n+    val mainContainer = new ContainerBuilder(\n+      original.mainContainer)"
  }],
  "prId": 19954
}]