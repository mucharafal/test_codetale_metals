[{
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "nit: `must be <= $MAX_SERVICE_NAME_LENGTH characters`",
    "commit": "cbcd30ea0a5eb75ed831f50707bc97035c0a3371",
    "createdAt": "2017-11-27T15:28:26Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit.steps\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.ServiceBuilder\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+import org.apache.spark.deploy.k8s.submit.KubernetesDriverSpec\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Clock\n+\n+/**\n+ * Allows the driver to be reachable by executor pods through a headless service. The service's\n+ * ports should correspond to the ports that the executor will reach the pod at for RPC.\n+ */\n+private[spark] class DriverServiceBootstrapStep(\n+    kubernetesResourceNamePrefix: String,\n+    driverLabels: Map[String, String],\n+    submissionSparkConf: SparkConf,\n+    clock: Clock) extends DriverConfigurationStep with Logging {\n+  import DriverServiceBootstrapStep._\n+\n+  override def configureDriver(driverSpec: KubernetesDriverSpec): KubernetesDriverSpec = {\n+    require(submissionSparkConf.getOption(DRIVER_BIND_ADDRESS_KEY).isEmpty,\n+      s\"$DRIVER_BIND_ADDRESS_KEY is not supported in Kubernetes mode, as the driver's bind\" +\n+      \" address is managed and set to the driver pod's IP address.\")\n+    require(submissionSparkConf.getOption(DRIVER_HOST_KEY).isEmpty,\n+      s\"$DRIVER_HOST_KEY is not supported in Kubernetes mode, as the driver's hostname will be\" +\n+      \" managed via a Kubernetes service.\")\n+\n+    val preferredServiceName = s\"$kubernetesResourceNamePrefix$DRIVER_SVC_POSTFIX\"\n+    val resolvedServiceName = if (preferredServiceName.length <= MAX_SERVICE_NAME_LENGTH) {\n+      preferredServiceName\n+    } else {\n+      val randomServiceId = clock.getTimeMillis()\n+      val shorterServiceName = s\"spark-$randomServiceId$DRIVER_SVC_POSTFIX\"\n+      logWarning(s\"Driver's hostname would preferably be $preferredServiceName, but this is\" +\n+        s\" too long (must be <= 63 characters). Falling back to use $shorterServiceName\" +"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "Done.",
    "commit": "cbcd30ea0a5eb75ed831f50707bc97035c0a3371",
    "createdAt": "2017-11-28T00:47:04Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit.steps\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.ServiceBuilder\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+import org.apache.spark.deploy.k8s.submit.KubernetesDriverSpec\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Clock\n+\n+/**\n+ * Allows the driver to be reachable by executor pods through a headless service. The service's\n+ * ports should correspond to the ports that the executor will reach the pod at for RPC.\n+ */\n+private[spark] class DriverServiceBootstrapStep(\n+    kubernetesResourceNamePrefix: String,\n+    driverLabels: Map[String, String],\n+    submissionSparkConf: SparkConf,\n+    clock: Clock) extends DriverConfigurationStep with Logging {\n+  import DriverServiceBootstrapStep._\n+\n+  override def configureDriver(driverSpec: KubernetesDriverSpec): KubernetesDriverSpec = {\n+    require(submissionSparkConf.getOption(DRIVER_BIND_ADDRESS_KEY).isEmpty,\n+      s\"$DRIVER_BIND_ADDRESS_KEY is not supported in Kubernetes mode, as the driver's bind\" +\n+      \" address is managed and set to the driver pod's IP address.\")\n+    require(submissionSparkConf.getOption(DRIVER_HOST_KEY).isEmpty,\n+      s\"$DRIVER_HOST_KEY is not supported in Kubernetes mode, as the driver's hostname will be\" +\n+      \" managed via a Kubernetes service.\")\n+\n+    val preferredServiceName = s\"$kubernetesResourceNamePrefix$DRIVER_SVC_POSTFIX\"\n+    val resolvedServiceName = if (preferredServiceName.length <= MAX_SERVICE_NAME_LENGTH) {\n+      preferredServiceName\n+    } else {\n+      val randomServiceId = clock.getTimeMillis()\n+      val shorterServiceName = s\"spark-$randomServiceId$DRIVER_SVC_POSTFIX\"\n+      logWarning(s\"Driver's hostname would preferably be $preferredServiceName, but this is\" +\n+        s\" too long (must be <= 63 characters). Falling back to use $shorterServiceName\" +"
  }],
  "prId": 19717
}, {
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "nit: ditto about concat strings.",
    "commit": "cbcd30ea0a5eb75ed831f50707bc97035c0a3371",
    "createdAt": "2017-11-28T07:37:03Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit.steps\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.ServiceBuilder\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+import org.apache.spark.deploy.k8s.submit.KubernetesDriverSpec\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Clock\n+\n+/**\n+ * Allows the driver to be reachable by executor pods through a headless service. The service's\n+ * ports should correspond to the ports that the executor will reach the pod at for RPC.\n+ */\n+private[spark] class DriverServiceBootstrapStep(\n+    kubernetesResourceNamePrefix: String,\n+    driverLabels: Map[String, String],\n+    submissionSparkConf: SparkConf,\n+    clock: Clock) extends DriverConfigurationStep with Logging {\n+  import DriverServiceBootstrapStep._\n+\n+  override def configureDriver(driverSpec: KubernetesDriverSpec): KubernetesDriverSpec = {\n+    require(submissionSparkConf.getOption(DRIVER_BIND_ADDRESS_KEY).isEmpty,\n+      s\"$DRIVER_BIND_ADDRESS_KEY is not supported in Kubernetes mode, as the driver's bind\" +\n+      \" address is managed and set to the driver pod's IP address.\")\n+    require(submissionSparkConf.getOption(DRIVER_HOST_KEY).isEmpty,\n+      s\"$DRIVER_HOST_KEY is not supported in Kubernetes mode, as the driver's hostname will be\" +\n+      \" managed via a Kubernetes service.\")"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "Done.",
    "commit": "cbcd30ea0a5eb75ed831f50707bc97035c0a3371",
    "createdAt": "2017-11-28T16:34:51Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit.steps\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.ServiceBuilder\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+import org.apache.spark.deploy.k8s.submit.KubernetesDriverSpec\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Clock\n+\n+/**\n+ * Allows the driver to be reachable by executor pods through a headless service. The service's\n+ * ports should correspond to the ports that the executor will reach the pod at for RPC.\n+ */\n+private[spark] class DriverServiceBootstrapStep(\n+    kubernetesResourceNamePrefix: String,\n+    driverLabels: Map[String, String],\n+    submissionSparkConf: SparkConf,\n+    clock: Clock) extends DriverConfigurationStep with Logging {\n+  import DriverServiceBootstrapStep._\n+\n+  override def configureDriver(driverSpec: KubernetesDriverSpec): KubernetesDriverSpec = {\n+    require(submissionSparkConf.getOption(DRIVER_BIND_ADDRESS_KEY).isEmpty,\n+      s\"$DRIVER_BIND_ADDRESS_KEY is not supported in Kubernetes mode, as the driver's bind\" +\n+      \" address is managed and set to the driver pod's IP address.\")\n+    require(submissionSparkConf.getOption(DRIVER_HOST_KEY).isEmpty,\n+      s\"$DRIVER_HOST_KEY is not supported in Kubernetes mode, as the driver's hostname will be\" +\n+      \" managed via a Kubernetes service.\")"
  }],
  "prId": 19717
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "`DRIVER_HOST_KEY`?",
    "commit": "cbcd30ea0a5eb75ed831f50707bc97035c0a3371",
    "createdAt": "2017-12-04T03:42:06Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit.steps\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.ServiceBuilder\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+import org.apache.spark.deploy.k8s.submit.KubernetesDriverSpec\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Clock\n+\n+/**\n+ * Allows the driver to be reachable by executor pods through a headless service. The service's\n+ * ports should correspond to the ports that the executor will reach the pod at for RPC.\n+ */\n+private[spark] class DriverServiceBootstrapStep(\n+    kubernetesResourceNamePrefix: String,\n+    driverLabels: Map[String, String],\n+    submissionSparkConf: SparkConf,\n+    clock: Clock) extends DriverConfigurationStep with Logging {\n+  import DriverServiceBootstrapStep._\n+\n+  override def configureDriver(driverSpec: KubernetesDriverSpec): KubernetesDriverSpec = {\n+    require(submissionSparkConf.getOption(DRIVER_BIND_ADDRESS_KEY).isEmpty,\n+      s\"$DRIVER_BIND_ADDRESS_KEY is not supported in Kubernetes mode, as the driver's bind \" +\n+      \"address is managed and set to the driver pod's IP address.\")\n+    require(submissionSparkConf.getOption(DRIVER_HOST_KEY).isEmpty,\n+      s\"$DRIVER_HOST_KEY is not supported in Kubernetes mode, as the driver's hostname will be \" +\n+      \"managed via a Kubernetes service.\")\n+\n+    val preferredServiceName = s\"$kubernetesResourceNamePrefix$DRIVER_SVC_POSTFIX\"\n+    val resolvedServiceName = if (preferredServiceName.length <= MAX_SERVICE_NAME_LENGTH) {\n+      preferredServiceName\n+    } else {\n+      val randomServiceId = clock.getTimeMillis()\n+      val shorterServiceName = s\"spark-$randomServiceId$DRIVER_SVC_POSTFIX\"\n+      logWarning(s\"Driver's hostname would preferably be $preferredServiceName, but this is \" +\n+        s\"too long (must be <= $MAX_SERVICE_NAME_LENGTH characters). Falling back to use \" +\n+        s\"$shorterServiceName as the driver service's name.\")\n+      shorterServiceName\n+    }\n+\n+    val driverPort = submissionSparkConf.getInt(\"spark.driver.port\", DEFAULT_DRIVER_PORT)\n+    val driverBlockManagerPort = submissionSparkConf.getInt(\n+        org.apache.spark.internal.config.DRIVER_BLOCK_MANAGER_PORT.key, DEFAULT_BLOCKMANAGER_PORT)\n+    val driverService = new ServiceBuilder()\n+      .withNewMetadata()\n+        .withName(resolvedServiceName)\n+        .endMetadata()\n+      .withNewSpec()\n+        .withClusterIP(\"None\")\n+        .withSelector(driverLabels.asJava)\n+        .addNewPort()\n+          .withName(DRIVER_PORT_NAME)\n+          .withPort(driverPort)\n+          .withNewTargetPort(driverPort)\n+          .endPort()\n+        .addNewPort()\n+          .withName(BLOCK_MANAGER_PORT_NAME)\n+          .withPort(driverBlockManagerPort)\n+          .withNewTargetPort(driverBlockManagerPort)\n+          .endPort()\n+        .endSpec()\n+      .build()\n+\n+    val namespace = submissionSparkConf.get(KUBERNETES_NAMESPACE)\n+    val driverHostname = s\"${driverService.getMetadata.getName}.$namespace.svc.cluster.local\"\n+    val resolvedSparkConf = driverSpec.driverSparkConf.clone()\n+      .set(org.apache.spark.internal.config.DRIVER_HOST_ADDRESS, driverHostname)"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "What do you meant here?",
    "commit": "cbcd30ea0a5eb75ed831f50707bc97035c0a3371",
    "createdAt": "2017-12-04T06:21:45Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit.steps\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.ServiceBuilder\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+import org.apache.spark.deploy.k8s.submit.KubernetesDriverSpec\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Clock\n+\n+/**\n+ * Allows the driver to be reachable by executor pods through a headless service. The service's\n+ * ports should correspond to the ports that the executor will reach the pod at for RPC.\n+ */\n+private[spark] class DriverServiceBootstrapStep(\n+    kubernetesResourceNamePrefix: String,\n+    driverLabels: Map[String, String],\n+    submissionSparkConf: SparkConf,\n+    clock: Clock) extends DriverConfigurationStep with Logging {\n+  import DriverServiceBootstrapStep._\n+\n+  override def configureDriver(driverSpec: KubernetesDriverSpec): KubernetesDriverSpec = {\n+    require(submissionSparkConf.getOption(DRIVER_BIND_ADDRESS_KEY).isEmpty,\n+      s\"$DRIVER_BIND_ADDRESS_KEY is not supported in Kubernetes mode, as the driver's bind \" +\n+      \"address is managed and set to the driver pod's IP address.\")\n+    require(submissionSparkConf.getOption(DRIVER_HOST_KEY).isEmpty,\n+      s\"$DRIVER_HOST_KEY is not supported in Kubernetes mode, as the driver's hostname will be \" +\n+      \"managed via a Kubernetes service.\")\n+\n+    val preferredServiceName = s\"$kubernetesResourceNamePrefix$DRIVER_SVC_POSTFIX\"\n+    val resolvedServiceName = if (preferredServiceName.length <= MAX_SERVICE_NAME_LENGTH) {\n+      preferredServiceName\n+    } else {\n+      val randomServiceId = clock.getTimeMillis()\n+      val shorterServiceName = s\"spark-$randomServiceId$DRIVER_SVC_POSTFIX\"\n+      logWarning(s\"Driver's hostname would preferably be $preferredServiceName, but this is \" +\n+        s\"too long (must be <= $MAX_SERVICE_NAME_LENGTH characters). Falling back to use \" +\n+        s\"$shorterServiceName as the driver service's name.\")\n+      shorterServiceName\n+    }\n+\n+    val driverPort = submissionSparkConf.getInt(\"spark.driver.port\", DEFAULT_DRIVER_PORT)\n+    val driverBlockManagerPort = submissionSparkConf.getInt(\n+        org.apache.spark.internal.config.DRIVER_BLOCK_MANAGER_PORT.key, DEFAULT_BLOCKMANAGER_PORT)\n+    val driverService = new ServiceBuilder()\n+      .withNewMetadata()\n+        .withName(resolvedServiceName)\n+        .endMetadata()\n+      .withNewSpec()\n+        .withClusterIP(\"None\")\n+        .withSelector(driverLabels.asJava)\n+        .addNewPort()\n+          .withName(DRIVER_PORT_NAME)\n+          .withPort(driverPort)\n+          .withNewTargetPort(driverPort)\n+          .endPort()\n+        .addNewPort()\n+          .withName(BLOCK_MANAGER_PORT_NAME)\n+          .withPort(driverBlockManagerPort)\n+          .withNewTargetPort(driverBlockManagerPort)\n+          .endPort()\n+        .endSpec()\n+      .build()\n+\n+    val namespace = submissionSparkConf.get(KUBERNETES_NAMESPACE)\n+    val driverHostname = s\"${driverService.getMetadata.getName}.$namespace.svc.cluster.local\"\n+    val resolvedSparkConf = driverSpec.driverSparkConf.clone()\n+      .set(org.apache.spark.internal.config.DRIVER_HOST_ADDRESS, driverHostname)"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "I meant isn't `org.apache.spark.internal.config.DRIVER_HOST_ADDRESS` just `DRIVER_HOST_KEY`?",
    "commit": "cbcd30ea0a5eb75ed831f50707bc97035c0a3371",
    "createdAt": "2017-12-04T07:25:07Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit.steps\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.ServiceBuilder\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+import org.apache.spark.deploy.k8s.submit.KubernetesDriverSpec\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Clock\n+\n+/**\n+ * Allows the driver to be reachable by executor pods through a headless service. The service's\n+ * ports should correspond to the ports that the executor will reach the pod at for RPC.\n+ */\n+private[spark] class DriverServiceBootstrapStep(\n+    kubernetesResourceNamePrefix: String,\n+    driverLabels: Map[String, String],\n+    submissionSparkConf: SparkConf,\n+    clock: Clock) extends DriverConfigurationStep with Logging {\n+  import DriverServiceBootstrapStep._\n+\n+  override def configureDriver(driverSpec: KubernetesDriverSpec): KubernetesDriverSpec = {\n+    require(submissionSparkConf.getOption(DRIVER_BIND_ADDRESS_KEY).isEmpty,\n+      s\"$DRIVER_BIND_ADDRESS_KEY is not supported in Kubernetes mode, as the driver's bind \" +\n+      \"address is managed and set to the driver pod's IP address.\")\n+    require(submissionSparkConf.getOption(DRIVER_HOST_KEY).isEmpty,\n+      s\"$DRIVER_HOST_KEY is not supported in Kubernetes mode, as the driver's hostname will be \" +\n+      \"managed via a Kubernetes service.\")\n+\n+    val preferredServiceName = s\"$kubernetesResourceNamePrefix$DRIVER_SVC_POSTFIX\"\n+    val resolvedServiceName = if (preferredServiceName.length <= MAX_SERVICE_NAME_LENGTH) {\n+      preferredServiceName\n+    } else {\n+      val randomServiceId = clock.getTimeMillis()\n+      val shorterServiceName = s\"spark-$randomServiceId$DRIVER_SVC_POSTFIX\"\n+      logWarning(s\"Driver's hostname would preferably be $preferredServiceName, but this is \" +\n+        s\"too long (must be <= $MAX_SERVICE_NAME_LENGTH characters). Falling back to use \" +\n+        s\"$shorterServiceName as the driver service's name.\")\n+      shorterServiceName\n+    }\n+\n+    val driverPort = submissionSparkConf.getInt(\"spark.driver.port\", DEFAULT_DRIVER_PORT)\n+    val driverBlockManagerPort = submissionSparkConf.getInt(\n+        org.apache.spark.internal.config.DRIVER_BLOCK_MANAGER_PORT.key, DEFAULT_BLOCKMANAGER_PORT)\n+    val driverService = new ServiceBuilder()\n+      .withNewMetadata()\n+        .withName(resolvedServiceName)\n+        .endMetadata()\n+      .withNewSpec()\n+        .withClusterIP(\"None\")\n+        .withSelector(driverLabels.asJava)\n+        .addNewPort()\n+          .withName(DRIVER_PORT_NAME)\n+          .withPort(driverPort)\n+          .withNewTargetPort(driverPort)\n+          .endPort()\n+        .addNewPort()\n+          .withName(BLOCK_MANAGER_PORT_NAME)\n+          .withPort(driverBlockManagerPort)\n+          .withNewTargetPort(driverBlockManagerPort)\n+          .endPort()\n+        .endSpec()\n+      .build()\n+\n+    val namespace = submissionSparkConf.get(KUBERNETES_NAMESPACE)\n+    val driverHostname = s\"${driverService.getMetadata.getName}.$namespace.svc.cluster.local\"\n+    val resolvedSparkConf = driverSpec.driverSparkConf.clone()\n+      .set(org.apache.spark.internal.config.DRIVER_HOST_ADDRESS, driverHostname)"
  }, {
    "author": {
      "login": "liyinan926"
    },
    "body": "Ah, yeah, done.",
    "commit": "cbcd30ea0a5eb75ed831f50707bc97035c0a3371",
    "createdAt": "2017-12-04T16:12:39Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.submit.steps\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.ServiceBuilder\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.k8s.Config._\n+import org.apache.spark.deploy.k8s.Constants._\n+import org.apache.spark.deploy.k8s.submit.KubernetesDriverSpec\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Clock\n+\n+/**\n+ * Allows the driver to be reachable by executor pods through a headless service. The service's\n+ * ports should correspond to the ports that the executor will reach the pod at for RPC.\n+ */\n+private[spark] class DriverServiceBootstrapStep(\n+    kubernetesResourceNamePrefix: String,\n+    driverLabels: Map[String, String],\n+    submissionSparkConf: SparkConf,\n+    clock: Clock) extends DriverConfigurationStep with Logging {\n+  import DriverServiceBootstrapStep._\n+\n+  override def configureDriver(driverSpec: KubernetesDriverSpec): KubernetesDriverSpec = {\n+    require(submissionSparkConf.getOption(DRIVER_BIND_ADDRESS_KEY).isEmpty,\n+      s\"$DRIVER_BIND_ADDRESS_KEY is not supported in Kubernetes mode, as the driver's bind \" +\n+      \"address is managed and set to the driver pod's IP address.\")\n+    require(submissionSparkConf.getOption(DRIVER_HOST_KEY).isEmpty,\n+      s\"$DRIVER_HOST_KEY is not supported in Kubernetes mode, as the driver's hostname will be \" +\n+      \"managed via a Kubernetes service.\")\n+\n+    val preferredServiceName = s\"$kubernetesResourceNamePrefix$DRIVER_SVC_POSTFIX\"\n+    val resolvedServiceName = if (preferredServiceName.length <= MAX_SERVICE_NAME_LENGTH) {\n+      preferredServiceName\n+    } else {\n+      val randomServiceId = clock.getTimeMillis()\n+      val shorterServiceName = s\"spark-$randomServiceId$DRIVER_SVC_POSTFIX\"\n+      logWarning(s\"Driver's hostname would preferably be $preferredServiceName, but this is \" +\n+        s\"too long (must be <= $MAX_SERVICE_NAME_LENGTH characters). Falling back to use \" +\n+        s\"$shorterServiceName as the driver service's name.\")\n+      shorterServiceName\n+    }\n+\n+    val driverPort = submissionSparkConf.getInt(\"spark.driver.port\", DEFAULT_DRIVER_PORT)\n+    val driverBlockManagerPort = submissionSparkConf.getInt(\n+        org.apache.spark.internal.config.DRIVER_BLOCK_MANAGER_PORT.key, DEFAULT_BLOCKMANAGER_PORT)\n+    val driverService = new ServiceBuilder()\n+      .withNewMetadata()\n+        .withName(resolvedServiceName)\n+        .endMetadata()\n+      .withNewSpec()\n+        .withClusterIP(\"None\")\n+        .withSelector(driverLabels.asJava)\n+        .addNewPort()\n+          .withName(DRIVER_PORT_NAME)\n+          .withPort(driverPort)\n+          .withNewTargetPort(driverPort)\n+          .endPort()\n+        .addNewPort()\n+          .withName(BLOCK_MANAGER_PORT_NAME)\n+          .withPort(driverBlockManagerPort)\n+          .withNewTargetPort(driverBlockManagerPort)\n+          .endPort()\n+        .endSpec()\n+      .build()\n+\n+    val namespace = submissionSparkConf.get(KUBERNETES_NAMESPACE)\n+    val driverHostname = s\"${driverService.getMetadata.getName}.$namespace.svc.cluster.local\"\n+    val resolvedSparkConf = driverSpec.driverSparkConf.clone()\n+      .set(org.apache.spark.internal.config.DRIVER_HOST_ADDRESS, driverHostname)"
  }],
  "prId": 19717
}]