[{
  "comments": [{
    "author": {
      "login": "rvesse"
    },
    "body": "Typo - `Wit` -> `With`",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-06T16:31:15Z",
    "diffHunk": "@@ -126,20 +134,53 @@ private[spark] class KerberosConfDriverFeatureStep(\n       HadoopBootstrapUtil.bootstrapSparkUserPod(\n         kubeTokenManager.getCurrentUser.getShortUserName,\n         hadoopBasedSparkPod))\n+\n+    if (keytab.isDefined) {\n+      val podWitKeytab = new PodBuilder(kerberizedPod.pod)"
  }],
  "prId": 22911
}, {
  "comments": [{
    "author": {
      "login": "ifilonenko"
    },
    "body": "nit: Why isn't this logic done in a `KubernetesDelegationTokenManager` or some Util class? It seems we are over-running this step with a lot of functionality? no? You are also just mocking via\r\n`when(step).createDelegationToken()`, I personally don't agree with the coverage brought up by this method of unit-testing but this is an extension of the discussion on a separate PR. i.e. I would mock the tokenManager and test to ensure that the `obtainDelegationTokens` take in a particular `creds` as an argument (also, so that one could test the if statement below).",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-14T22:36:33Z",
    "diffHunk": "@@ -69,97 +72,191 @@ private[spark] class KerberosConfDriverFeatureStep(\n     \"If a Kerberos keytab is specified you must also specify a Kerberos principal\")\n \n   KubernetesUtils.requireBothOrNeitherDefined(\n-    existingSecretName,\n-    existingSecretItemKey,\n+    existingDtSecret,\n+    existingDtItemKey,\n     \"If a secret data item-key where the data of the Kerberos Delegation Token is specified\" +\n       \" you must also specify the name of the secret\",\n     \"If a secret storing a Kerberos Delegation Token is specified you must also\" +\n       \" specify the item-key where the data is stored\")\n \n-  private val hadoopConfigurationFiles = hadoopConfDirSpec.hadoopConfDir.map { hConfDir =>\n-    HadoopBootstrapUtil.getHadoopConfFiles(hConfDir)\n+  if (!hasKerberosConf) {\n+    logInfo(\"You have not specified a krb5.conf file locally or via a ConfigMap. \" +\n+      \"Make sure that you have the krb5.conf locally on the driver image.\")\n   }\n-  private val newHadoopConfigMapName =\n-    if (hadoopConfDirSpec.hadoopConfigMapName.isEmpty) {\n-      Some(kubernetesConf.hadoopConfigMapName)\n-    } else {\n-      None\n-    }\n \n-  // Either use pre-existing secret or login to create new Secret with DT stored within\n-  private val kerberosConfSpec: Option[KerberosConfigSpec] = (for {\n-    secretName <- existingSecretName\n-    secretItemKey <- existingSecretItemKey\n-  } yield {\n-    KerberosConfigSpec(\n-      dtSecret = None,\n-      dtSecretName = secretName,\n-      dtSecretItemKey = secretItemKey,\n-      jobUserName = kubeTokenManager.getCurrentUser.getShortUserName)\n-  }).orElse(\n-    if (isKerberosEnabled) {\n-      Some(HadoopKerberosLogin.buildSpec(\n-        conf,\n-        kubernetesConf.appResourceNamePrefix,\n-        kubeTokenManager))\n-    } else {\n-      None\n+  // Create delegation tokens if needed. This is a lazy val so that it's not populated\n+  // unnecessarily. But it needs to be accessible to different methods in this class,\n+  // since it's not clear based solely on available configuration options that delegation\n+  // tokens are needed when other credentials are not available.\n+  private lazy val delegationTokens: Array[Byte] = if (keytab.isEmpty && existingDtSecret.isEmpty) {\n+    createDelegationTokens()\n+  } else {\n+    null\n+  }\n+\n+  private def needKeytabUpload: Boolean = keytab.exists(!Utils.isLocalUri(_))\n+\n+  private def dtSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-delegation-tokens\"\n+\n+  private def ktSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-kerberos-keytab\"\n+\n+  private def hasKerberosConf: Boolean = krb5CMap.isDefined | krb5File.isDefined\n+\n+  override def configurePod(original: SparkPod): SparkPod = {\n+    original.transform { case pod if hasKerberosConf =>\n+      val configMapVolume = if (krb5CMap.isDefined) {\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+            .withName(krb5CMap.get)\n+            .endConfigMap()\n+          .build()\n+      } else {\n+        val krb5Conf = new File(krb5File.get)\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+          .withName(kubernetesConf.krbConfigMapName)\n+          .withItems(new KeyToPathBuilder()\n+            .withKey(krb5Conf.getName())\n+            .withPath(krb5Conf.getName())\n+            .build())\n+          .endConfigMap()\n+          .build()\n+      }\n+\n+      val podWithVolume = new PodBuilder(pod.pod)\n+        .editSpec()\n+          .addNewVolumeLike(configMapVolume)\n+            .endVolume()\n+          .endSpec()\n+        .build()\n+\n+      val containerWithMount = new ContainerBuilder(pod.container)\n+        .addNewVolumeMount()\n+          .withName(KRB_FILE_VOLUME)\n+          .withMountPath(KRB_FILE_DIR_PATH + \"/krb5.conf\")\n+          .withSubPath(\"krb5.conf\")\n+          .endVolumeMount()\n+        .build()\n+\n+      SparkPod(podWithVolume, containerWithMount)\n+    }.transform {\n+      case pod if needKeytabUpload =>\n+        // If keytab is defined and is a submission-local file (not local: URI), then create a\n+        // secret for it. The keytab data will be stored in this secret below.\n+        val podWitKeytab = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(KERBEROS_KEYTAB_VOLUME)\n+              .withNewSecret()\n+                .withSecretName(ktSecretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithKeytab = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(KERBEROS_KEYTAB_VOLUME)\n+            .withMountPath(KERBEROS_KEYTAB_MOUNT_POINT)\n+            .endVolumeMount()\n+          .build()\n+\n+        SparkPod(podWitKeytab, containerWithKeytab)\n+\n+      case pod if existingDtSecret.isDefined | delegationTokens != null =>\n+        val secretName = existingDtSecret.getOrElse(dtSecretName)\n+        val itemKey = existingDtItemKey.getOrElse(KERBEROS_SECRET_KEY)\n+\n+        val podWithTokens = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+              .withNewSecret()\n+                .withSecretName(secretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithTokens = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+            .withMountPath(SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR)\n+            .endVolumeMount()\n+          .addNewEnv()\n+            .withName(ENV_HADOOP_TOKEN_FILE_LOCATION)\n+            .withValue(s\"$SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR/$itemKey\")\n+            .endEnv()\n+          .build()\n+\n+        SparkPod(podWithTokens, containerWithTokens)\n     }\n-  )\n-\n-  override def configurePod(pod: SparkPod): SparkPod = {\n-    val hadoopBasedSparkPod = HadoopBootstrapUtil.bootstrapHadoopConfDir(\n-      hadoopConfDirSpec.hadoopConfDir,\n-      newHadoopConfigMapName,\n-      hadoopConfDirSpec.hadoopConfigMapName,\n-      pod)\n-    kerberosConfSpec.map { hSpec =>\n-      HadoopBootstrapUtil.bootstrapKerberosPod(\n-        hSpec.dtSecretName,\n-        hSpec.dtSecretItemKey,\n-        hSpec.jobUserName,\n-        krb5File,\n-        Some(kubernetesConf.krbConfigMapName),\n-        krb5CMap,\n-        hadoopBasedSparkPod)\n-    }.getOrElse(\n-      HadoopBootstrapUtil.bootstrapSparkUserPod(\n-        kubeTokenManager.getCurrentUser.getShortUserName,\n-        hadoopBasedSparkPod))\n   }\n \n   override def getAdditionalPodSystemProperties(): Map[String, String] = {\n-    val resolvedConfValues = kerberosConfSpec.map { hSpec =>\n-      Map(KERBEROS_DT_SECRET_NAME -> hSpec.dtSecretName,\n-        KERBEROS_DT_SECRET_KEY -> hSpec.dtSecretItemKey,\n-        KERBEROS_SPARK_USER_NAME -> hSpec.jobUserName,\n-        KRB5_CONFIG_MAP_NAME -> krb5CMap.getOrElse(kubernetesConf.krbConfigMapName))\n-      }.getOrElse(\n-        Map(KERBEROS_SPARK_USER_NAME ->\n-          kubeTokenManager.getCurrentUser.getShortUserName))\n-    Map(HADOOP_CONFIG_MAP_NAME ->\n-      hadoopConfDirSpec.hadoopConfigMapName.getOrElse(\n-      kubernetesConf.hadoopConfigMapName)) ++ resolvedConfValues\n+    // If a submission-local keytab is provided, update the Spark config so that it knows the\n+    // path of the keytab in the driver container.\n+    if (needKeytabUpload) {\n+      val ktName = new File(keytab.get).getName()\n+      Map(KEYTAB.key -> s\"$KERBEROS_KEYTAB_MOUNT_POINT/$ktName\")\n+    } else {\n+      Map.empty\n+    }\n   }\n \n   override def getAdditionalKubernetesResources(): Seq[HasMetadata] = {\n-    val hadoopConfConfigMap = for {\n-      hName <- newHadoopConfigMapName\n-      hFiles <- hadoopConfigurationFiles\n-    } yield {\n-      HadoopBootstrapUtil.buildHadoopConfigMap(hName, hFiles)\n+    Seq[HasMetadata]() ++ {\n+      krb5File.map { path =>\n+        val file = new File(path)\n+        new ConfigMapBuilder()\n+          .withNewMetadata()\n+            .withName(kubernetesConf.krbConfigMapName)\n+            .endMetadata()\n+          .addToData(\n+            Map(file.getName() -> Files.toString(file, StandardCharsets.UTF_8)).asJava)\n+          .build()\n+      }\n+    } ++ {\n+      // If a submission-local keytab is provided, stash it in a secret.\n+      if (needKeytabUpload) {\n+        val kt = new File(keytab.get)\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(ktSecretName)\n+            .endMetadata()\n+          .addToData(kt.getName(), Base64.encodeBase64String(Files.toByteArray(kt)))\n+          .build())\n+      } else {\n+        Nil\n+      }\n+    } ++ {\n+      if (delegationTokens != null) {\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(dtSecretName)\n+            .endMetadata()\n+          .addToData(KERBEROS_SECRET_KEY, Base64.encodeBase64String(delegationTokens))\n+          .build())\n+      } else {\n+        Nil\n+      }\n     }\n+  }\n \n-    val krb5ConfigMap = krb5File.map { fileLocation =>\n-      HadoopBootstrapUtil.buildkrb5ConfigMap(\n-        kubernetesConf.krbConfigMapName,\n-        fileLocation)\n+  // Visible for testing.\n+  def createDelegationTokens(): Array[Byte] = {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> Why isn't this logic done in a KubernetesDelegationTokenManager or some Util class?\r\n\r\nBecause that's not needed. What exactly would doing that achieve?\r\n\r\n> I would mock the tokenManager and test to ensure that the obtainDelegationTokens take in a particular creds\r\n\r\nThat's not what the corresponding test is testing. It is testing that when delegation tokens are created, they are stashed in a secret. For that I'm mocking the creation of delegation tokens, because without any services to talk to, delegation tokens will not be created.\r\n\r\n(BTW, that's what mocks should be used for.)",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-14T22:42:04Z",
    "diffHunk": "@@ -69,97 +72,191 @@ private[spark] class KerberosConfDriverFeatureStep(\n     \"If a Kerberos keytab is specified you must also specify a Kerberos principal\")\n \n   KubernetesUtils.requireBothOrNeitherDefined(\n-    existingSecretName,\n-    existingSecretItemKey,\n+    existingDtSecret,\n+    existingDtItemKey,\n     \"If a secret data item-key where the data of the Kerberos Delegation Token is specified\" +\n       \" you must also specify the name of the secret\",\n     \"If a secret storing a Kerberos Delegation Token is specified you must also\" +\n       \" specify the item-key where the data is stored\")\n \n-  private val hadoopConfigurationFiles = hadoopConfDirSpec.hadoopConfDir.map { hConfDir =>\n-    HadoopBootstrapUtil.getHadoopConfFiles(hConfDir)\n+  if (!hasKerberosConf) {\n+    logInfo(\"You have not specified a krb5.conf file locally or via a ConfigMap. \" +\n+      \"Make sure that you have the krb5.conf locally on the driver image.\")\n   }\n-  private val newHadoopConfigMapName =\n-    if (hadoopConfDirSpec.hadoopConfigMapName.isEmpty) {\n-      Some(kubernetesConf.hadoopConfigMapName)\n-    } else {\n-      None\n-    }\n \n-  // Either use pre-existing secret or login to create new Secret with DT stored within\n-  private val kerberosConfSpec: Option[KerberosConfigSpec] = (for {\n-    secretName <- existingSecretName\n-    secretItemKey <- existingSecretItemKey\n-  } yield {\n-    KerberosConfigSpec(\n-      dtSecret = None,\n-      dtSecretName = secretName,\n-      dtSecretItemKey = secretItemKey,\n-      jobUserName = kubeTokenManager.getCurrentUser.getShortUserName)\n-  }).orElse(\n-    if (isKerberosEnabled) {\n-      Some(HadoopKerberosLogin.buildSpec(\n-        conf,\n-        kubernetesConf.appResourceNamePrefix,\n-        kubeTokenManager))\n-    } else {\n-      None\n+  // Create delegation tokens if needed. This is a lazy val so that it's not populated\n+  // unnecessarily. But it needs to be accessible to different methods in this class,\n+  // since it's not clear based solely on available configuration options that delegation\n+  // tokens are needed when other credentials are not available.\n+  private lazy val delegationTokens: Array[Byte] = if (keytab.isEmpty && existingDtSecret.isEmpty) {\n+    createDelegationTokens()\n+  } else {\n+    null\n+  }\n+\n+  private def needKeytabUpload: Boolean = keytab.exists(!Utils.isLocalUri(_))\n+\n+  private def dtSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-delegation-tokens\"\n+\n+  private def ktSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-kerberos-keytab\"\n+\n+  private def hasKerberosConf: Boolean = krb5CMap.isDefined | krb5File.isDefined\n+\n+  override def configurePod(original: SparkPod): SparkPod = {\n+    original.transform { case pod if hasKerberosConf =>\n+      val configMapVolume = if (krb5CMap.isDefined) {\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+            .withName(krb5CMap.get)\n+            .endConfigMap()\n+          .build()\n+      } else {\n+        val krb5Conf = new File(krb5File.get)\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+          .withName(kubernetesConf.krbConfigMapName)\n+          .withItems(new KeyToPathBuilder()\n+            .withKey(krb5Conf.getName())\n+            .withPath(krb5Conf.getName())\n+            .build())\n+          .endConfigMap()\n+          .build()\n+      }\n+\n+      val podWithVolume = new PodBuilder(pod.pod)\n+        .editSpec()\n+          .addNewVolumeLike(configMapVolume)\n+            .endVolume()\n+          .endSpec()\n+        .build()\n+\n+      val containerWithMount = new ContainerBuilder(pod.container)\n+        .addNewVolumeMount()\n+          .withName(KRB_FILE_VOLUME)\n+          .withMountPath(KRB_FILE_DIR_PATH + \"/krb5.conf\")\n+          .withSubPath(\"krb5.conf\")\n+          .endVolumeMount()\n+        .build()\n+\n+      SparkPod(podWithVolume, containerWithMount)\n+    }.transform {\n+      case pod if needKeytabUpload =>\n+        // If keytab is defined and is a submission-local file (not local: URI), then create a\n+        // secret for it. The keytab data will be stored in this secret below.\n+        val podWitKeytab = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(KERBEROS_KEYTAB_VOLUME)\n+              .withNewSecret()\n+                .withSecretName(ktSecretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithKeytab = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(KERBEROS_KEYTAB_VOLUME)\n+            .withMountPath(KERBEROS_KEYTAB_MOUNT_POINT)\n+            .endVolumeMount()\n+          .build()\n+\n+        SparkPod(podWitKeytab, containerWithKeytab)\n+\n+      case pod if existingDtSecret.isDefined | delegationTokens != null =>\n+        val secretName = existingDtSecret.getOrElse(dtSecretName)\n+        val itemKey = existingDtItemKey.getOrElse(KERBEROS_SECRET_KEY)\n+\n+        val podWithTokens = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+              .withNewSecret()\n+                .withSecretName(secretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithTokens = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+            .withMountPath(SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR)\n+            .endVolumeMount()\n+          .addNewEnv()\n+            .withName(ENV_HADOOP_TOKEN_FILE_LOCATION)\n+            .withValue(s\"$SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR/$itemKey\")\n+            .endEnv()\n+          .build()\n+\n+        SparkPod(podWithTokens, containerWithTokens)\n     }\n-  )\n-\n-  override def configurePod(pod: SparkPod): SparkPod = {\n-    val hadoopBasedSparkPod = HadoopBootstrapUtil.bootstrapHadoopConfDir(\n-      hadoopConfDirSpec.hadoopConfDir,\n-      newHadoopConfigMapName,\n-      hadoopConfDirSpec.hadoopConfigMapName,\n-      pod)\n-    kerberosConfSpec.map { hSpec =>\n-      HadoopBootstrapUtil.bootstrapKerberosPod(\n-        hSpec.dtSecretName,\n-        hSpec.dtSecretItemKey,\n-        hSpec.jobUserName,\n-        krb5File,\n-        Some(kubernetesConf.krbConfigMapName),\n-        krb5CMap,\n-        hadoopBasedSparkPod)\n-    }.getOrElse(\n-      HadoopBootstrapUtil.bootstrapSparkUserPod(\n-        kubeTokenManager.getCurrentUser.getShortUserName,\n-        hadoopBasedSparkPod))\n   }\n \n   override def getAdditionalPodSystemProperties(): Map[String, String] = {\n-    val resolvedConfValues = kerberosConfSpec.map { hSpec =>\n-      Map(KERBEROS_DT_SECRET_NAME -> hSpec.dtSecretName,\n-        KERBEROS_DT_SECRET_KEY -> hSpec.dtSecretItemKey,\n-        KERBEROS_SPARK_USER_NAME -> hSpec.jobUserName,\n-        KRB5_CONFIG_MAP_NAME -> krb5CMap.getOrElse(kubernetesConf.krbConfigMapName))\n-      }.getOrElse(\n-        Map(KERBEROS_SPARK_USER_NAME ->\n-          kubeTokenManager.getCurrentUser.getShortUserName))\n-    Map(HADOOP_CONFIG_MAP_NAME ->\n-      hadoopConfDirSpec.hadoopConfigMapName.getOrElse(\n-      kubernetesConf.hadoopConfigMapName)) ++ resolvedConfValues\n+    // If a submission-local keytab is provided, update the Spark config so that it knows the\n+    // path of the keytab in the driver container.\n+    if (needKeytabUpload) {\n+      val ktName = new File(keytab.get).getName()\n+      Map(KEYTAB.key -> s\"$KERBEROS_KEYTAB_MOUNT_POINT/$ktName\")\n+    } else {\n+      Map.empty\n+    }\n   }\n \n   override def getAdditionalKubernetesResources(): Seq[HasMetadata] = {\n-    val hadoopConfConfigMap = for {\n-      hName <- newHadoopConfigMapName\n-      hFiles <- hadoopConfigurationFiles\n-    } yield {\n-      HadoopBootstrapUtil.buildHadoopConfigMap(hName, hFiles)\n+    Seq[HasMetadata]() ++ {\n+      krb5File.map { path =>\n+        val file = new File(path)\n+        new ConfigMapBuilder()\n+          .withNewMetadata()\n+            .withName(kubernetesConf.krbConfigMapName)\n+            .endMetadata()\n+          .addToData(\n+            Map(file.getName() -> Files.toString(file, StandardCharsets.UTF_8)).asJava)\n+          .build()\n+      }\n+    } ++ {\n+      // If a submission-local keytab is provided, stash it in a secret.\n+      if (needKeytabUpload) {\n+        val kt = new File(keytab.get)\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(ktSecretName)\n+            .endMetadata()\n+          .addToData(kt.getName(), Base64.encodeBase64String(Files.toByteArray(kt)))\n+          .build())\n+      } else {\n+        Nil\n+      }\n+    } ++ {\n+      if (delegationTokens != null) {\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(dtSecretName)\n+            .endMetadata()\n+          .addToData(KERBEROS_SECRET_KEY, Base64.encodeBase64String(delegationTokens))\n+          .build())\n+      } else {\n+        Nil\n+      }\n     }\n+  }\n \n-    val krb5ConfigMap = krb5File.map { fileLocation =>\n-      HadoopBootstrapUtil.buildkrb5ConfigMap(\n-        kubernetesConf.krbConfigMapName,\n-        fileLocation)\n+  // Visible for testing.\n+  def createDelegationTokens(): Array[Byte] = {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> I'm mocking the creation of delegation tokens\r\n\r\nBTW there are other ways to achieve that, e.g. with `UserGroupInformation.createTestUser()` and `doAs`, but I think the current test is easier to understand.",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-14T23:01:32Z",
    "diffHunk": "@@ -69,97 +72,191 @@ private[spark] class KerberosConfDriverFeatureStep(\n     \"If a Kerberos keytab is specified you must also specify a Kerberos principal\")\n \n   KubernetesUtils.requireBothOrNeitherDefined(\n-    existingSecretName,\n-    existingSecretItemKey,\n+    existingDtSecret,\n+    existingDtItemKey,\n     \"If a secret data item-key where the data of the Kerberos Delegation Token is specified\" +\n       \" you must also specify the name of the secret\",\n     \"If a secret storing a Kerberos Delegation Token is specified you must also\" +\n       \" specify the item-key where the data is stored\")\n \n-  private val hadoopConfigurationFiles = hadoopConfDirSpec.hadoopConfDir.map { hConfDir =>\n-    HadoopBootstrapUtil.getHadoopConfFiles(hConfDir)\n+  if (!hasKerberosConf) {\n+    logInfo(\"You have not specified a krb5.conf file locally or via a ConfigMap. \" +\n+      \"Make sure that you have the krb5.conf locally on the driver image.\")\n   }\n-  private val newHadoopConfigMapName =\n-    if (hadoopConfDirSpec.hadoopConfigMapName.isEmpty) {\n-      Some(kubernetesConf.hadoopConfigMapName)\n-    } else {\n-      None\n-    }\n \n-  // Either use pre-existing secret or login to create new Secret with DT stored within\n-  private val kerberosConfSpec: Option[KerberosConfigSpec] = (for {\n-    secretName <- existingSecretName\n-    secretItemKey <- existingSecretItemKey\n-  } yield {\n-    KerberosConfigSpec(\n-      dtSecret = None,\n-      dtSecretName = secretName,\n-      dtSecretItemKey = secretItemKey,\n-      jobUserName = kubeTokenManager.getCurrentUser.getShortUserName)\n-  }).orElse(\n-    if (isKerberosEnabled) {\n-      Some(HadoopKerberosLogin.buildSpec(\n-        conf,\n-        kubernetesConf.appResourceNamePrefix,\n-        kubeTokenManager))\n-    } else {\n-      None\n+  // Create delegation tokens if needed. This is a lazy val so that it's not populated\n+  // unnecessarily. But it needs to be accessible to different methods in this class,\n+  // since it's not clear based solely on available configuration options that delegation\n+  // tokens are needed when other credentials are not available.\n+  private lazy val delegationTokens: Array[Byte] = if (keytab.isEmpty && existingDtSecret.isEmpty) {\n+    createDelegationTokens()\n+  } else {\n+    null\n+  }\n+\n+  private def needKeytabUpload: Boolean = keytab.exists(!Utils.isLocalUri(_))\n+\n+  private def dtSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-delegation-tokens\"\n+\n+  private def ktSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-kerberos-keytab\"\n+\n+  private def hasKerberosConf: Boolean = krb5CMap.isDefined | krb5File.isDefined\n+\n+  override def configurePod(original: SparkPod): SparkPod = {\n+    original.transform { case pod if hasKerberosConf =>\n+      val configMapVolume = if (krb5CMap.isDefined) {\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+            .withName(krb5CMap.get)\n+            .endConfigMap()\n+          .build()\n+      } else {\n+        val krb5Conf = new File(krb5File.get)\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+          .withName(kubernetesConf.krbConfigMapName)\n+          .withItems(new KeyToPathBuilder()\n+            .withKey(krb5Conf.getName())\n+            .withPath(krb5Conf.getName())\n+            .build())\n+          .endConfigMap()\n+          .build()\n+      }\n+\n+      val podWithVolume = new PodBuilder(pod.pod)\n+        .editSpec()\n+          .addNewVolumeLike(configMapVolume)\n+            .endVolume()\n+          .endSpec()\n+        .build()\n+\n+      val containerWithMount = new ContainerBuilder(pod.container)\n+        .addNewVolumeMount()\n+          .withName(KRB_FILE_VOLUME)\n+          .withMountPath(KRB_FILE_DIR_PATH + \"/krb5.conf\")\n+          .withSubPath(\"krb5.conf\")\n+          .endVolumeMount()\n+        .build()\n+\n+      SparkPod(podWithVolume, containerWithMount)\n+    }.transform {\n+      case pod if needKeytabUpload =>\n+        // If keytab is defined and is a submission-local file (not local: URI), then create a\n+        // secret for it. The keytab data will be stored in this secret below.\n+        val podWitKeytab = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(KERBEROS_KEYTAB_VOLUME)\n+              .withNewSecret()\n+                .withSecretName(ktSecretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithKeytab = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(KERBEROS_KEYTAB_VOLUME)\n+            .withMountPath(KERBEROS_KEYTAB_MOUNT_POINT)\n+            .endVolumeMount()\n+          .build()\n+\n+        SparkPod(podWitKeytab, containerWithKeytab)\n+\n+      case pod if existingDtSecret.isDefined | delegationTokens != null =>\n+        val secretName = existingDtSecret.getOrElse(dtSecretName)\n+        val itemKey = existingDtItemKey.getOrElse(KERBEROS_SECRET_KEY)\n+\n+        val podWithTokens = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+              .withNewSecret()\n+                .withSecretName(secretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithTokens = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+            .withMountPath(SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR)\n+            .endVolumeMount()\n+          .addNewEnv()\n+            .withName(ENV_HADOOP_TOKEN_FILE_LOCATION)\n+            .withValue(s\"$SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR/$itemKey\")\n+            .endEnv()\n+          .build()\n+\n+        SparkPod(podWithTokens, containerWithTokens)\n     }\n-  )\n-\n-  override def configurePod(pod: SparkPod): SparkPod = {\n-    val hadoopBasedSparkPod = HadoopBootstrapUtil.bootstrapHadoopConfDir(\n-      hadoopConfDirSpec.hadoopConfDir,\n-      newHadoopConfigMapName,\n-      hadoopConfDirSpec.hadoopConfigMapName,\n-      pod)\n-    kerberosConfSpec.map { hSpec =>\n-      HadoopBootstrapUtil.bootstrapKerberosPod(\n-        hSpec.dtSecretName,\n-        hSpec.dtSecretItemKey,\n-        hSpec.jobUserName,\n-        krb5File,\n-        Some(kubernetesConf.krbConfigMapName),\n-        krb5CMap,\n-        hadoopBasedSparkPod)\n-    }.getOrElse(\n-      HadoopBootstrapUtil.bootstrapSparkUserPod(\n-        kubeTokenManager.getCurrentUser.getShortUserName,\n-        hadoopBasedSparkPod))\n   }\n \n   override def getAdditionalPodSystemProperties(): Map[String, String] = {\n-    val resolvedConfValues = kerberosConfSpec.map { hSpec =>\n-      Map(KERBEROS_DT_SECRET_NAME -> hSpec.dtSecretName,\n-        KERBEROS_DT_SECRET_KEY -> hSpec.dtSecretItemKey,\n-        KERBEROS_SPARK_USER_NAME -> hSpec.jobUserName,\n-        KRB5_CONFIG_MAP_NAME -> krb5CMap.getOrElse(kubernetesConf.krbConfigMapName))\n-      }.getOrElse(\n-        Map(KERBEROS_SPARK_USER_NAME ->\n-          kubeTokenManager.getCurrentUser.getShortUserName))\n-    Map(HADOOP_CONFIG_MAP_NAME ->\n-      hadoopConfDirSpec.hadoopConfigMapName.getOrElse(\n-      kubernetesConf.hadoopConfigMapName)) ++ resolvedConfValues\n+    // If a submission-local keytab is provided, update the Spark config so that it knows the\n+    // path of the keytab in the driver container.\n+    if (needKeytabUpload) {\n+      val ktName = new File(keytab.get).getName()\n+      Map(KEYTAB.key -> s\"$KERBEROS_KEYTAB_MOUNT_POINT/$ktName\")\n+    } else {\n+      Map.empty\n+    }\n   }\n \n   override def getAdditionalKubernetesResources(): Seq[HasMetadata] = {\n-    val hadoopConfConfigMap = for {\n-      hName <- newHadoopConfigMapName\n-      hFiles <- hadoopConfigurationFiles\n-    } yield {\n-      HadoopBootstrapUtil.buildHadoopConfigMap(hName, hFiles)\n+    Seq[HasMetadata]() ++ {\n+      krb5File.map { path =>\n+        val file = new File(path)\n+        new ConfigMapBuilder()\n+          .withNewMetadata()\n+            .withName(kubernetesConf.krbConfigMapName)\n+            .endMetadata()\n+          .addToData(\n+            Map(file.getName() -> Files.toString(file, StandardCharsets.UTF_8)).asJava)\n+          .build()\n+      }\n+    } ++ {\n+      // If a submission-local keytab is provided, stash it in a secret.\n+      if (needKeytabUpload) {\n+        val kt = new File(keytab.get)\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(ktSecretName)\n+            .endMetadata()\n+          .addToData(kt.getName(), Base64.encodeBase64String(Files.toByteArray(kt)))\n+          .build())\n+      } else {\n+        Nil\n+      }\n+    } ++ {\n+      if (delegationTokens != null) {\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(dtSecretName)\n+            .endMetadata()\n+          .addToData(KERBEROS_SECRET_KEY, Base64.encodeBase64String(delegationTokens))\n+          .build())\n+      } else {\n+        Nil\n+      }\n     }\n+  }\n \n-    val krb5ConfigMap = krb5File.map { fileLocation =>\n-      HadoopBootstrapUtil.buildkrb5ConfigMap(\n-        kubernetesConf.krbConfigMapName,\n-        fileLocation)\n+  // Visible for testing.\n+  def createDelegationTokens(): Array[Byte] = {"
  }, {
    "author": {
      "login": "ifilonenko"
    },
    "body": "> Because that's not needed. What exactly would doing that achieve?\r\n\r\nI mean that is the function of a DelegationTokenManager, no? To handle nuances related to DT management, both for creation and renewal. _shrug_\r\n\r\n> This code is testing that when delegation tokens are created, they are stashed in a secret\r\n\r\nWell there is logic being introduced here beyond just `tokenManager.obtainDelegationToken()`, right? And if the purpose of the tests is to take the results from delegation token creation and put into a secret, then it would make sense to mock a `KubernetesDelegtionTokenManager` and just call `kdtm.obtainTokens()`, where this logic would be housed, or to leave it within this step. But regardless, I'd prefer that all parts of the logic are mocked. \r\n\r\nOnce again, a matter of opinion, that differs between unit-testing strategy. I'll loop in @mccheah\r\n\r\n> I think the current test is easier to understand.\r\n\r\nI agree, but is it comprehensive is what I am talking about here?",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-14T23:10:13Z",
    "diffHunk": "@@ -69,97 +72,191 @@ private[spark] class KerberosConfDriverFeatureStep(\n     \"If a Kerberos keytab is specified you must also specify a Kerberos principal\")\n \n   KubernetesUtils.requireBothOrNeitherDefined(\n-    existingSecretName,\n-    existingSecretItemKey,\n+    existingDtSecret,\n+    existingDtItemKey,\n     \"If a secret data item-key where the data of the Kerberos Delegation Token is specified\" +\n       \" you must also specify the name of the secret\",\n     \"If a secret storing a Kerberos Delegation Token is specified you must also\" +\n       \" specify the item-key where the data is stored\")\n \n-  private val hadoopConfigurationFiles = hadoopConfDirSpec.hadoopConfDir.map { hConfDir =>\n-    HadoopBootstrapUtil.getHadoopConfFiles(hConfDir)\n+  if (!hasKerberosConf) {\n+    logInfo(\"You have not specified a krb5.conf file locally or via a ConfigMap. \" +\n+      \"Make sure that you have the krb5.conf locally on the driver image.\")\n   }\n-  private val newHadoopConfigMapName =\n-    if (hadoopConfDirSpec.hadoopConfigMapName.isEmpty) {\n-      Some(kubernetesConf.hadoopConfigMapName)\n-    } else {\n-      None\n-    }\n \n-  // Either use pre-existing secret or login to create new Secret with DT stored within\n-  private val kerberosConfSpec: Option[KerberosConfigSpec] = (for {\n-    secretName <- existingSecretName\n-    secretItemKey <- existingSecretItemKey\n-  } yield {\n-    KerberosConfigSpec(\n-      dtSecret = None,\n-      dtSecretName = secretName,\n-      dtSecretItemKey = secretItemKey,\n-      jobUserName = kubeTokenManager.getCurrentUser.getShortUserName)\n-  }).orElse(\n-    if (isKerberosEnabled) {\n-      Some(HadoopKerberosLogin.buildSpec(\n-        conf,\n-        kubernetesConf.appResourceNamePrefix,\n-        kubeTokenManager))\n-    } else {\n-      None\n+  // Create delegation tokens if needed. This is a lazy val so that it's not populated\n+  // unnecessarily. But it needs to be accessible to different methods in this class,\n+  // since it's not clear based solely on available configuration options that delegation\n+  // tokens are needed when other credentials are not available.\n+  private lazy val delegationTokens: Array[Byte] = if (keytab.isEmpty && existingDtSecret.isEmpty) {\n+    createDelegationTokens()\n+  } else {\n+    null\n+  }\n+\n+  private def needKeytabUpload: Boolean = keytab.exists(!Utils.isLocalUri(_))\n+\n+  private def dtSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-delegation-tokens\"\n+\n+  private def ktSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-kerberos-keytab\"\n+\n+  private def hasKerberosConf: Boolean = krb5CMap.isDefined | krb5File.isDefined\n+\n+  override def configurePod(original: SparkPod): SparkPod = {\n+    original.transform { case pod if hasKerberosConf =>\n+      val configMapVolume = if (krb5CMap.isDefined) {\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+            .withName(krb5CMap.get)\n+            .endConfigMap()\n+          .build()\n+      } else {\n+        val krb5Conf = new File(krb5File.get)\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+          .withName(kubernetesConf.krbConfigMapName)\n+          .withItems(new KeyToPathBuilder()\n+            .withKey(krb5Conf.getName())\n+            .withPath(krb5Conf.getName())\n+            .build())\n+          .endConfigMap()\n+          .build()\n+      }\n+\n+      val podWithVolume = new PodBuilder(pod.pod)\n+        .editSpec()\n+          .addNewVolumeLike(configMapVolume)\n+            .endVolume()\n+          .endSpec()\n+        .build()\n+\n+      val containerWithMount = new ContainerBuilder(pod.container)\n+        .addNewVolumeMount()\n+          .withName(KRB_FILE_VOLUME)\n+          .withMountPath(KRB_FILE_DIR_PATH + \"/krb5.conf\")\n+          .withSubPath(\"krb5.conf\")\n+          .endVolumeMount()\n+        .build()\n+\n+      SparkPod(podWithVolume, containerWithMount)\n+    }.transform {\n+      case pod if needKeytabUpload =>\n+        // If keytab is defined and is a submission-local file (not local: URI), then create a\n+        // secret for it. The keytab data will be stored in this secret below.\n+        val podWitKeytab = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(KERBEROS_KEYTAB_VOLUME)\n+              .withNewSecret()\n+                .withSecretName(ktSecretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithKeytab = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(KERBEROS_KEYTAB_VOLUME)\n+            .withMountPath(KERBEROS_KEYTAB_MOUNT_POINT)\n+            .endVolumeMount()\n+          .build()\n+\n+        SparkPod(podWitKeytab, containerWithKeytab)\n+\n+      case pod if existingDtSecret.isDefined | delegationTokens != null =>\n+        val secretName = existingDtSecret.getOrElse(dtSecretName)\n+        val itemKey = existingDtItemKey.getOrElse(KERBEROS_SECRET_KEY)\n+\n+        val podWithTokens = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+              .withNewSecret()\n+                .withSecretName(secretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithTokens = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+            .withMountPath(SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR)\n+            .endVolumeMount()\n+          .addNewEnv()\n+            .withName(ENV_HADOOP_TOKEN_FILE_LOCATION)\n+            .withValue(s\"$SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR/$itemKey\")\n+            .endEnv()\n+          .build()\n+\n+        SparkPod(podWithTokens, containerWithTokens)\n     }\n-  )\n-\n-  override def configurePod(pod: SparkPod): SparkPod = {\n-    val hadoopBasedSparkPod = HadoopBootstrapUtil.bootstrapHadoopConfDir(\n-      hadoopConfDirSpec.hadoopConfDir,\n-      newHadoopConfigMapName,\n-      hadoopConfDirSpec.hadoopConfigMapName,\n-      pod)\n-    kerberosConfSpec.map { hSpec =>\n-      HadoopBootstrapUtil.bootstrapKerberosPod(\n-        hSpec.dtSecretName,\n-        hSpec.dtSecretItemKey,\n-        hSpec.jobUserName,\n-        krb5File,\n-        Some(kubernetesConf.krbConfigMapName),\n-        krb5CMap,\n-        hadoopBasedSparkPod)\n-    }.getOrElse(\n-      HadoopBootstrapUtil.bootstrapSparkUserPod(\n-        kubeTokenManager.getCurrentUser.getShortUserName,\n-        hadoopBasedSparkPod))\n   }\n \n   override def getAdditionalPodSystemProperties(): Map[String, String] = {\n-    val resolvedConfValues = kerberosConfSpec.map { hSpec =>\n-      Map(KERBEROS_DT_SECRET_NAME -> hSpec.dtSecretName,\n-        KERBEROS_DT_SECRET_KEY -> hSpec.dtSecretItemKey,\n-        KERBEROS_SPARK_USER_NAME -> hSpec.jobUserName,\n-        KRB5_CONFIG_MAP_NAME -> krb5CMap.getOrElse(kubernetesConf.krbConfigMapName))\n-      }.getOrElse(\n-        Map(KERBEROS_SPARK_USER_NAME ->\n-          kubeTokenManager.getCurrentUser.getShortUserName))\n-    Map(HADOOP_CONFIG_MAP_NAME ->\n-      hadoopConfDirSpec.hadoopConfigMapName.getOrElse(\n-      kubernetesConf.hadoopConfigMapName)) ++ resolvedConfValues\n+    // If a submission-local keytab is provided, update the Spark config so that it knows the\n+    // path of the keytab in the driver container.\n+    if (needKeytabUpload) {\n+      val ktName = new File(keytab.get).getName()\n+      Map(KEYTAB.key -> s\"$KERBEROS_KEYTAB_MOUNT_POINT/$ktName\")\n+    } else {\n+      Map.empty\n+    }\n   }\n \n   override def getAdditionalKubernetesResources(): Seq[HasMetadata] = {\n-    val hadoopConfConfigMap = for {\n-      hName <- newHadoopConfigMapName\n-      hFiles <- hadoopConfigurationFiles\n-    } yield {\n-      HadoopBootstrapUtil.buildHadoopConfigMap(hName, hFiles)\n+    Seq[HasMetadata]() ++ {\n+      krb5File.map { path =>\n+        val file = new File(path)\n+        new ConfigMapBuilder()\n+          .withNewMetadata()\n+            .withName(kubernetesConf.krbConfigMapName)\n+            .endMetadata()\n+          .addToData(\n+            Map(file.getName() -> Files.toString(file, StandardCharsets.UTF_8)).asJava)\n+          .build()\n+      }\n+    } ++ {\n+      // If a submission-local keytab is provided, stash it in a secret.\n+      if (needKeytabUpload) {\n+        val kt = new File(keytab.get)\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(ktSecretName)\n+            .endMetadata()\n+          .addToData(kt.getName(), Base64.encodeBase64String(Files.toByteArray(kt)))\n+          .build())\n+      } else {\n+        Nil\n+      }\n+    } ++ {\n+      if (delegationTokens != null) {\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(dtSecretName)\n+            .endMetadata()\n+          .addToData(KERBEROS_SECRET_KEY, Base64.encodeBase64String(delegationTokens))\n+          .build())\n+      } else {\n+        Nil\n+      }\n     }\n+  }\n \n-    val krb5ConfigMap = krb5File.map { fileLocation =>\n-      HadoopBootstrapUtil.buildkrb5ConfigMap(\n-        kubernetesConf.krbConfigMapName,\n-        fileLocation)\n+  // Visible for testing.\n+  def createDelegationTokens(): Array[Byte] = {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> that is the function of a DelegationTokenManager. To handle nuances related to DT management\r\n\r\nYes. And the test here is not interested in whether DT creation works or not. It's interested in that if they are created, then they are stashed in a secret.\r\n\r\n> then it would make sense to mock a KubernetesDelegtionTokenManager and just call kdtm.obtainTokens()\r\n\r\nWould it make you happier if instead of having instead of the current method, have this:\r\n\r\n```\r\ndef createDelegationTokens(creds: Credentials)\r\n```\r\n\r\nThe only extra thing you'd really be testing is the call to `SparkHadoopUtil.get.serialize`. I don't really see a lot of gains there.",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-14T23:15:14Z",
    "diffHunk": "@@ -69,97 +72,191 @@ private[spark] class KerberosConfDriverFeatureStep(\n     \"If a Kerberos keytab is specified you must also specify a Kerberos principal\")\n \n   KubernetesUtils.requireBothOrNeitherDefined(\n-    existingSecretName,\n-    existingSecretItemKey,\n+    existingDtSecret,\n+    existingDtItemKey,\n     \"If a secret data item-key where the data of the Kerberos Delegation Token is specified\" +\n       \" you must also specify the name of the secret\",\n     \"If a secret storing a Kerberos Delegation Token is specified you must also\" +\n       \" specify the item-key where the data is stored\")\n \n-  private val hadoopConfigurationFiles = hadoopConfDirSpec.hadoopConfDir.map { hConfDir =>\n-    HadoopBootstrapUtil.getHadoopConfFiles(hConfDir)\n+  if (!hasKerberosConf) {\n+    logInfo(\"You have not specified a krb5.conf file locally or via a ConfigMap. \" +\n+      \"Make sure that you have the krb5.conf locally on the driver image.\")\n   }\n-  private val newHadoopConfigMapName =\n-    if (hadoopConfDirSpec.hadoopConfigMapName.isEmpty) {\n-      Some(kubernetesConf.hadoopConfigMapName)\n-    } else {\n-      None\n-    }\n \n-  // Either use pre-existing secret or login to create new Secret with DT stored within\n-  private val kerberosConfSpec: Option[KerberosConfigSpec] = (for {\n-    secretName <- existingSecretName\n-    secretItemKey <- existingSecretItemKey\n-  } yield {\n-    KerberosConfigSpec(\n-      dtSecret = None,\n-      dtSecretName = secretName,\n-      dtSecretItemKey = secretItemKey,\n-      jobUserName = kubeTokenManager.getCurrentUser.getShortUserName)\n-  }).orElse(\n-    if (isKerberosEnabled) {\n-      Some(HadoopKerberosLogin.buildSpec(\n-        conf,\n-        kubernetesConf.appResourceNamePrefix,\n-        kubeTokenManager))\n-    } else {\n-      None\n+  // Create delegation tokens if needed. This is a lazy val so that it's not populated\n+  // unnecessarily. But it needs to be accessible to different methods in this class,\n+  // since it's not clear based solely on available configuration options that delegation\n+  // tokens are needed when other credentials are not available.\n+  private lazy val delegationTokens: Array[Byte] = if (keytab.isEmpty && existingDtSecret.isEmpty) {\n+    createDelegationTokens()\n+  } else {\n+    null\n+  }\n+\n+  private def needKeytabUpload: Boolean = keytab.exists(!Utils.isLocalUri(_))\n+\n+  private def dtSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-delegation-tokens\"\n+\n+  private def ktSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-kerberos-keytab\"\n+\n+  private def hasKerberosConf: Boolean = krb5CMap.isDefined | krb5File.isDefined\n+\n+  override def configurePod(original: SparkPod): SparkPod = {\n+    original.transform { case pod if hasKerberosConf =>\n+      val configMapVolume = if (krb5CMap.isDefined) {\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+            .withName(krb5CMap.get)\n+            .endConfigMap()\n+          .build()\n+      } else {\n+        val krb5Conf = new File(krb5File.get)\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+          .withName(kubernetesConf.krbConfigMapName)\n+          .withItems(new KeyToPathBuilder()\n+            .withKey(krb5Conf.getName())\n+            .withPath(krb5Conf.getName())\n+            .build())\n+          .endConfigMap()\n+          .build()\n+      }\n+\n+      val podWithVolume = new PodBuilder(pod.pod)\n+        .editSpec()\n+          .addNewVolumeLike(configMapVolume)\n+            .endVolume()\n+          .endSpec()\n+        .build()\n+\n+      val containerWithMount = new ContainerBuilder(pod.container)\n+        .addNewVolumeMount()\n+          .withName(KRB_FILE_VOLUME)\n+          .withMountPath(KRB_FILE_DIR_PATH + \"/krb5.conf\")\n+          .withSubPath(\"krb5.conf\")\n+          .endVolumeMount()\n+        .build()\n+\n+      SparkPod(podWithVolume, containerWithMount)\n+    }.transform {\n+      case pod if needKeytabUpload =>\n+        // If keytab is defined and is a submission-local file (not local: URI), then create a\n+        // secret for it. The keytab data will be stored in this secret below.\n+        val podWitKeytab = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(KERBEROS_KEYTAB_VOLUME)\n+              .withNewSecret()\n+                .withSecretName(ktSecretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithKeytab = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(KERBEROS_KEYTAB_VOLUME)\n+            .withMountPath(KERBEROS_KEYTAB_MOUNT_POINT)\n+            .endVolumeMount()\n+          .build()\n+\n+        SparkPod(podWitKeytab, containerWithKeytab)\n+\n+      case pod if existingDtSecret.isDefined | delegationTokens != null =>\n+        val secretName = existingDtSecret.getOrElse(dtSecretName)\n+        val itemKey = existingDtItemKey.getOrElse(KERBEROS_SECRET_KEY)\n+\n+        val podWithTokens = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+              .withNewSecret()\n+                .withSecretName(secretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithTokens = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+            .withMountPath(SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR)\n+            .endVolumeMount()\n+          .addNewEnv()\n+            .withName(ENV_HADOOP_TOKEN_FILE_LOCATION)\n+            .withValue(s\"$SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR/$itemKey\")\n+            .endEnv()\n+          .build()\n+\n+        SparkPod(podWithTokens, containerWithTokens)\n     }\n-  )\n-\n-  override def configurePod(pod: SparkPod): SparkPod = {\n-    val hadoopBasedSparkPod = HadoopBootstrapUtil.bootstrapHadoopConfDir(\n-      hadoopConfDirSpec.hadoopConfDir,\n-      newHadoopConfigMapName,\n-      hadoopConfDirSpec.hadoopConfigMapName,\n-      pod)\n-    kerberosConfSpec.map { hSpec =>\n-      HadoopBootstrapUtil.bootstrapKerberosPod(\n-        hSpec.dtSecretName,\n-        hSpec.dtSecretItemKey,\n-        hSpec.jobUserName,\n-        krb5File,\n-        Some(kubernetesConf.krbConfigMapName),\n-        krb5CMap,\n-        hadoopBasedSparkPod)\n-    }.getOrElse(\n-      HadoopBootstrapUtil.bootstrapSparkUserPod(\n-        kubeTokenManager.getCurrentUser.getShortUserName,\n-        hadoopBasedSparkPod))\n   }\n \n   override def getAdditionalPodSystemProperties(): Map[String, String] = {\n-    val resolvedConfValues = kerberosConfSpec.map { hSpec =>\n-      Map(KERBEROS_DT_SECRET_NAME -> hSpec.dtSecretName,\n-        KERBEROS_DT_SECRET_KEY -> hSpec.dtSecretItemKey,\n-        KERBEROS_SPARK_USER_NAME -> hSpec.jobUserName,\n-        KRB5_CONFIG_MAP_NAME -> krb5CMap.getOrElse(kubernetesConf.krbConfigMapName))\n-      }.getOrElse(\n-        Map(KERBEROS_SPARK_USER_NAME ->\n-          kubeTokenManager.getCurrentUser.getShortUserName))\n-    Map(HADOOP_CONFIG_MAP_NAME ->\n-      hadoopConfDirSpec.hadoopConfigMapName.getOrElse(\n-      kubernetesConf.hadoopConfigMapName)) ++ resolvedConfValues\n+    // If a submission-local keytab is provided, update the Spark config so that it knows the\n+    // path of the keytab in the driver container.\n+    if (needKeytabUpload) {\n+      val ktName = new File(keytab.get).getName()\n+      Map(KEYTAB.key -> s\"$KERBEROS_KEYTAB_MOUNT_POINT/$ktName\")\n+    } else {\n+      Map.empty\n+    }\n   }\n \n   override def getAdditionalKubernetesResources(): Seq[HasMetadata] = {\n-    val hadoopConfConfigMap = for {\n-      hName <- newHadoopConfigMapName\n-      hFiles <- hadoopConfigurationFiles\n-    } yield {\n-      HadoopBootstrapUtil.buildHadoopConfigMap(hName, hFiles)\n+    Seq[HasMetadata]() ++ {\n+      krb5File.map { path =>\n+        val file = new File(path)\n+        new ConfigMapBuilder()\n+          .withNewMetadata()\n+            .withName(kubernetesConf.krbConfigMapName)\n+            .endMetadata()\n+          .addToData(\n+            Map(file.getName() -> Files.toString(file, StandardCharsets.UTF_8)).asJava)\n+          .build()\n+      }\n+    } ++ {\n+      // If a submission-local keytab is provided, stash it in a secret.\n+      if (needKeytabUpload) {\n+        val kt = new File(keytab.get)\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(ktSecretName)\n+            .endMetadata()\n+          .addToData(kt.getName(), Base64.encodeBase64String(Files.toByteArray(kt)))\n+          .build())\n+      } else {\n+        Nil\n+      }\n+    } ++ {\n+      if (delegationTokens != null) {\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(dtSecretName)\n+            .endMetadata()\n+          .addToData(KERBEROS_SECRET_KEY, Base64.encodeBase64String(delegationTokens))\n+          .build())\n+      } else {\n+        Nil\n+      }\n     }\n+  }\n \n-    val krb5ConfigMap = krb5File.map { fileLocation =>\n-      HadoopBootstrapUtil.buildkrb5ConfigMap(\n-        kubernetesConf.krbConfigMapName,\n-        fileLocation)\n+  // Visible for testing.\n+  def createDelegationTokens(): Array[Byte] = {"
  }, {
    "author": {
      "login": "ifilonenko"
    },
    "body": "> Yes. And the test here is not interested in whether DT creation works or not.\r\n\r\nHmm, I somewhat disagree, but maybe I am just overly opinionated. I think that the function definition should be: \r\n`def createDelegationTokens(creds: Credentials, tm: HadoopDelegationTokenManager)` so that you can, most importantly imo, mock the `tm` to ensure that the result coming from that method results in the necessary tokens (and _if it is necessary_ to test that: if it returns nothing that no secret is created) \r\n",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-14T23:23:36Z",
    "diffHunk": "@@ -69,97 +72,191 @@ private[spark] class KerberosConfDriverFeatureStep(\n     \"If a Kerberos keytab is specified you must also specify a Kerberos principal\")\n \n   KubernetesUtils.requireBothOrNeitherDefined(\n-    existingSecretName,\n-    existingSecretItemKey,\n+    existingDtSecret,\n+    existingDtItemKey,\n     \"If a secret data item-key where the data of the Kerberos Delegation Token is specified\" +\n       \" you must also specify the name of the secret\",\n     \"If a secret storing a Kerberos Delegation Token is specified you must also\" +\n       \" specify the item-key where the data is stored\")\n \n-  private val hadoopConfigurationFiles = hadoopConfDirSpec.hadoopConfDir.map { hConfDir =>\n-    HadoopBootstrapUtil.getHadoopConfFiles(hConfDir)\n+  if (!hasKerberosConf) {\n+    logInfo(\"You have not specified a krb5.conf file locally or via a ConfigMap. \" +\n+      \"Make sure that you have the krb5.conf locally on the driver image.\")\n   }\n-  private val newHadoopConfigMapName =\n-    if (hadoopConfDirSpec.hadoopConfigMapName.isEmpty) {\n-      Some(kubernetesConf.hadoopConfigMapName)\n-    } else {\n-      None\n-    }\n \n-  // Either use pre-existing secret or login to create new Secret with DT stored within\n-  private val kerberosConfSpec: Option[KerberosConfigSpec] = (for {\n-    secretName <- existingSecretName\n-    secretItemKey <- existingSecretItemKey\n-  } yield {\n-    KerberosConfigSpec(\n-      dtSecret = None,\n-      dtSecretName = secretName,\n-      dtSecretItemKey = secretItemKey,\n-      jobUserName = kubeTokenManager.getCurrentUser.getShortUserName)\n-  }).orElse(\n-    if (isKerberosEnabled) {\n-      Some(HadoopKerberosLogin.buildSpec(\n-        conf,\n-        kubernetesConf.appResourceNamePrefix,\n-        kubeTokenManager))\n-    } else {\n-      None\n+  // Create delegation tokens if needed. This is a lazy val so that it's not populated\n+  // unnecessarily. But it needs to be accessible to different methods in this class,\n+  // since it's not clear based solely on available configuration options that delegation\n+  // tokens are needed when other credentials are not available.\n+  private lazy val delegationTokens: Array[Byte] = if (keytab.isEmpty && existingDtSecret.isEmpty) {\n+    createDelegationTokens()\n+  } else {\n+    null\n+  }\n+\n+  private def needKeytabUpload: Boolean = keytab.exists(!Utils.isLocalUri(_))\n+\n+  private def dtSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-delegation-tokens\"\n+\n+  private def ktSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-kerberos-keytab\"\n+\n+  private def hasKerberosConf: Boolean = krb5CMap.isDefined | krb5File.isDefined\n+\n+  override def configurePod(original: SparkPod): SparkPod = {\n+    original.transform { case pod if hasKerberosConf =>\n+      val configMapVolume = if (krb5CMap.isDefined) {\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+            .withName(krb5CMap.get)\n+            .endConfigMap()\n+          .build()\n+      } else {\n+        val krb5Conf = new File(krb5File.get)\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+          .withName(kubernetesConf.krbConfigMapName)\n+          .withItems(new KeyToPathBuilder()\n+            .withKey(krb5Conf.getName())\n+            .withPath(krb5Conf.getName())\n+            .build())\n+          .endConfigMap()\n+          .build()\n+      }\n+\n+      val podWithVolume = new PodBuilder(pod.pod)\n+        .editSpec()\n+          .addNewVolumeLike(configMapVolume)\n+            .endVolume()\n+          .endSpec()\n+        .build()\n+\n+      val containerWithMount = new ContainerBuilder(pod.container)\n+        .addNewVolumeMount()\n+          .withName(KRB_FILE_VOLUME)\n+          .withMountPath(KRB_FILE_DIR_PATH + \"/krb5.conf\")\n+          .withSubPath(\"krb5.conf\")\n+          .endVolumeMount()\n+        .build()\n+\n+      SparkPod(podWithVolume, containerWithMount)\n+    }.transform {\n+      case pod if needKeytabUpload =>\n+        // If keytab is defined and is a submission-local file (not local: URI), then create a\n+        // secret for it. The keytab data will be stored in this secret below.\n+        val podWitKeytab = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(KERBEROS_KEYTAB_VOLUME)\n+              .withNewSecret()\n+                .withSecretName(ktSecretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithKeytab = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(KERBEROS_KEYTAB_VOLUME)\n+            .withMountPath(KERBEROS_KEYTAB_MOUNT_POINT)\n+            .endVolumeMount()\n+          .build()\n+\n+        SparkPod(podWitKeytab, containerWithKeytab)\n+\n+      case pod if existingDtSecret.isDefined | delegationTokens != null =>\n+        val secretName = existingDtSecret.getOrElse(dtSecretName)\n+        val itemKey = existingDtItemKey.getOrElse(KERBEROS_SECRET_KEY)\n+\n+        val podWithTokens = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+              .withNewSecret()\n+                .withSecretName(secretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithTokens = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+            .withMountPath(SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR)\n+            .endVolumeMount()\n+          .addNewEnv()\n+            .withName(ENV_HADOOP_TOKEN_FILE_LOCATION)\n+            .withValue(s\"$SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR/$itemKey\")\n+            .endEnv()\n+          .build()\n+\n+        SparkPod(podWithTokens, containerWithTokens)\n     }\n-  )\n-\n-  override def configurePod(pod: SparkPod): SparkPod = {\n-    val hadoopBasedSparkPod = HadoopBootstrapUtil.bootstrapHadoopConfDir(\n-      hadoopConfDirSpec.hadoopConfDir,\n-      newHadoopConfigMapName,\n-      hadoopConfDirSpec.hadoopConfigMapName,\n-      pod)\n-    kerberosConfSpec.map { hSpec =>\n-      HadoopBootstrapUtil.bootstrapKerberosPod(\n-        hSpec.dtSecretName,\n-        hSpec.dtSecretItemKey,\n-        hSpec.jobUserName,\n-        krb5File,\n-        Some(kubernetesConf.krbConfigMapName),\n-        krb5CMap,\n-        hadoopBasedSparkPod)\n-    }.getOrElse(\n-      HadoopBootstrapUtil.bootstrapSparkUserPod(\n-        kubeTokenManager.getCurrentUser.getShortUserName,\n-        hadoopBasedSparkPod))\n   }\n \n   override def getAdditionalPodSystemProperties(): Map[String, String] = {\n-    val resolvedConfValues = kerberosConfSpec.map { hSpec =>\n-      Map(KERBEROS_DT_SECRET_NAME -> hSpec.dtSecretName,\n-        KERBEROS_DT_SECRET_KEY -> hSpec.dtSecretItemKey,\n-        KERBEROS_SPARK_USER_NAME -> hSpec.jobUserName,\n-        KRB5_CONFIG_MAP_NAME -> krb5CMap.getOrElse(kubernetesConf.krbConfigMapName))\n-      }.getOrElse(\n-        Map(KERBEROS_SPARK_USER_NAME ->\n-          kubeTokenManager.getCurrentUser.getShortUserName))\n-    Map(HADOOP_CONFIG_MAP_NAME ->\n-      hadoopConfDirSpec.hadoopConfigMapName.getOrElse(\n-      kubernetesConf.hadoopConfigMapName)) ++ resolvedConfValues\n+    // If a submission-local keytab is provided, update the Spark config so that it knows the\n+    // path of the keytab in the driver container.\n+    if (needKeytabUpload) {\n+      val ktName = new File(keytab.get).getName()\n+      Map(KEYTAB.key -> s\"$KERBEROS_KEYTAB_MOUNT_POINT/$ktName\")\n+    } else {\n+      Map.empty\n+    }\n   }\n \n   override def getAdditionalKubernetesResources(): Seq[HasMetadata] = {\n-    val hadoopConfConfigMap = for {\n-      hName <- newHadoopConfigMapName\n-      hFiles <- hadoopConfigurationFiles\n-    } yield {\n-      HadoopBootstrapUtil.buildHadoopConfigMap(hName, hFiles)\n+    Seq[HasMetadata]() ++ {\n+      krb5File.map { path =>\n+        val file = new File(path)\n+        new ConfigMapBuilder()\n+          .withNewMetadata()\n+            .withName(kubernetesConf.krbConfigMapName)\n+            .endMetadata()\n+          .addToData(\n+            Map(file.getName() -> Files.toString(file, StandardCharsets.UTF_8)).asJava)\n+          .build()\n+      }\n+    } ++ {\n+      // If a submission-local keytab is provided, stash it in a secret.\n+      if (needKeytabUpload) {\n+        val kt = new File(keytab.get)\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(ktSecretName)\n+            .endMetadata()\n+          .addToData(kt.getName(), Base64.encodeBase64String(Files.toByteArray(kt)))\n+          .build())\n+      } else {\n+        Nil\n+      }\n+    } ++ {\n+      if (delegationTokens != null) {\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(dtSecretName)\n+            .endMetadata()\n+          .addToData(KERBEROS_SECRET_KEY, Base64.encodeBase64String(delegationTokens))\n+          .build())\n+      } else {\n+        Nil\n+      }\n     }\n+  }\n \n-    val krb5ConfigMap = krb5File.map { fileLocation =>\n-      HadoopBootstrapUtil.buildkrb5ConfigMap(\n-        kubernetesConf.krbConfigMapName,\n-        fileLocation)\n+  // Visible for testing.\n+  def createDelegationTokens(): Array[Byte] = {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> Hmm, I somewhat disagree, but maybe I am just overly opinionated.\r\n\r\nThe code that creates delegation tokens is not in this class. If delegation token creation is to be tested, it needs to be tested in the test code for `HadoopDelegationTokenManager`.\r\n\r\nAll this class does is take the tokens that other class creates and stash them in a secret.\r\n\r\nI'll change this to not need a mock at all, mostly to make a point.",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-14T23:57:39Z",
    "diffHunk": "@@ -69,97 +72,191 @@ private[spark] class KerberosConfDriverFeatureStep(\n     \"If a Kerberos keytab is specified you must also specify a Kerberos principal\")\n \n   KubernetesUtils.requireBothOrNeitherDefined(\n-    existingSecretName,\n-    existingSecretItemKey,\n+    existingDtSecret,\n+    existingDtItemKey,\n     \"If a secret data item-key where the data of the Kerberos Delegation Token is specified\" +\n       \" you must also specify the name of the secret\",\n     \"If a secret storing a Kerberos Delegation Token is specified you must also\" +\n       \" specify the item-key where the data is stored\")\n \n-  private val hadoopConfigurationFiles = hadoopConfDirSpec.hadoopConfDir.map { hConfDir =>\n-    HadoopBootstrapUtil.getHadoopConfFiles(hConfDir)\n+  if (!hasKerberosConf) {\n+    logInfo(\"You have not specified a krb5.conf file locally or via a ConfigMap. \" +\n+      \"Make sure that you have the krb5.conf locally on the driver image.\")\n   }\n-  private val newHadoopConfigMapName =\n-    if (hadoopConfDirSpec.hadoopConfigMapName.isEmpty) {\n-      Some(kubernetesConf.hadoopConfigMapName)\n-    } else {\n-      None\n-    }\n \n-  // Either use pre-existing secret or login to create new Secret with DT stored within\n-  private val kerberosConfSpec: Option[KerberosConfigSpec] = (for {\n-    secretName <- existingSecretName\n-    secretItemKey <- existingSecretItemKey\n-  } yield {\n-    KerberosConfigSpec(\n-      dtSecret = None,\n-      dtSecretName = secretName,\n-      dtSecretItemKey = secretItemKey,\n-      jobUserName = kubeTokenManager.getCurrentUser.getShortUserName)\n-  }).orElse(\n-    if (isKerberosEnabled) {\n-      Some(HadoopKerberosLogin.buildSpec(\n-        conf,\n-        kubernetesConf.appResourceNamePrefix,\n-        kubeTokenManager))\n-    } else {\n-      None\n+  // Create delegation tokens if needed. This is a lazy val so that it's not populated\n+  // unnecessarily. But it needs to be accessible to different methods in this class,\n+  // since it's not clear based solely on available configuration options that delegation\n+  // tokens are needed when other credentials are not available.\n+  private lazy val delegationTokens: Array[Byte] = if (keytab.isEmpty && existingDtSecret.isEmpty) {\n+    createDelegationTokens()\n+  } else {\n+    null\n+  }\n+\n+  private def needKeytabUpload: Boolean = keytab.exists(!Utils.isLocalUri(_))\n+\n+  private def dtSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-delegation-tokens\"\n+\n+  private def ktSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-kerberos-keytab\"\n+\n+  private def hasKerberosConf: Boolean = krb5CMap.isDefined | krb5File.isDefined\n+\n+  override def configurePod(original: SparkPod): SparkPod = {\n+    original.transform { case pod if hasKerberosConf =>\n+      val configMapVolume = if (krb5CMap.isDefined) {\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+            .withName(krb5CMap.get)\n+            .endConfigMap()\n+          .build()\n+      } else {\n+        val krb5Conf = new File(krb5File.get)\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+          .withName(kubernetesConf.krbConfigMapName)\n+          .withItems(new KeyToPathBuilder()\n+            .withKey(krb5Conf.getName())\n+            .withPath(krb5Conf.getName())\n+            .build())\n+          .endConfigMap()\n+          .build()\n+      }\n+\n+      val podWithVolume = new PodBuilder(pod.pod)\n+        .editSpec()\n+          .addNewVolumeLike(configMapVolume)\n+            .endVolume()\n+          .endSpec()\n+        .build()\n+\n+      val containerWithMount = new ContainerBuilder(pod.container)\n+        .addNewVolumeMount()\n+          .withName(KRB_FILE_VOLUME)\n+          .withMountPath(KRB_FILE_DIR_PATH + \"/krb5.conf\")\n+          .withSubPath(\"krb5.conf\")\n+          .endVolumeMount()\n+        .build()\n+\n+      SparkPod(podWithVolume, containerWithMount)\n+    }.transform {\n+      case pod if needKeytabUpload =>\n+        // If keytab is defined and is a submission-local file (not local: URI), then create a\n+        // secret for it. The keytab data will be stored in this secret below.\n+        val podWitKeytab = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(KERBEROS_KEYTAB_VOLUME)\n+              .withNewSecret()\n+                .withSecretName(ktSecretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithKeytab = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(KERBEROS_KEYTAB_VOLUME)\n+            .withMountPath(KERBEROS_KEYTAB_MOUNT_POINT)\n+            .endVolumeMount()\n+          .build()\n+\n+        SparkPod(podWitKeytab, containerWithKeytab)\n+\n+      case pod if existingDtSecret.isDefined | delegationTokens != null =>\n+        val secretName = existingDtSecret.getOrElse(dtSecretName)\n+        val itemKey = existingDtItemKey.getOrElse(KERBEROS_SECRET_KEY)\n+\n+        val podWithTokens = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+              .withNewSecret()\n+                .withSecretName(secretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithTokens = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+            .withMountPath(SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR)\n+            .endVolumeMount()\n+          .addNewEnv()\n+            .withName(ENV_HADOOP_TOKEN_FILE_LOCATION)\n+            .withValue(s\"$SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR/$itemKey\")\n+            .endEnv()\n+          .build()\n+\n+        SparkPod(podWithTokens, containerWithTokens)\n     }\n-  )\n-\n-  override def configurePod(pod: SparkPod): SparkPod = {\n-    val hadoopBasedSparkPod = HadoopBootstrapUtil.bootstrapHadoopConfDir(\n-      hadoopConfDirSpec.hadoopConfDir,\n-      newHadoopConfigMapName,\n-      hadoopConfDirSpec.hadoopConfigMapName,\n-      pod)\n-    kerberosConfSpec.map { hSpec =>\n-      HadoopBootstrapUtil.bootstrapKerberosPod(\n-        hSpec.dtSecretName,\n-        hSpec.dtSecretItemKey,\n-        hSpec.jobUserName,\n-        krb5File,\n-        Some(kubernetesConf.krbConfigMapName),\n-        krb5CMap,\n-        hadoopBasedSparkPod)\n-    }.getOrElse(\n-      HadoopBootstrapUtil.bootstrapSparkUserPod(\n-        kubeTokenManager.getCurrentUser.getShortUserName,\n-        hadoopBasedSparkPod))\n   }\n \n   override def getAdditionalPodSystemProperties(): Map[String, String] = {\n-    val resolvedConfValues = kerberosConfSpec.map { hSpec =>\n-      Map(KERBEROS_DT_SECRET_NAME -> hSpec.dtSecretName,\n-        KERBEROS_DT_SECRET_KEY -> hSpec.dtSecretItemKey,\n-        KERBEROS_SPARK_USER_NAME -> hSpec.jobUserName,\n-        KRB5_CONFIG_MAP_NAME -> krb5CMap.getOrElse(kubernetesConf.krbConfigMapName))\n-      }.getOrElse(\n-        Map(KERBEROS_SPARK_USER_NAME ->\n-          kubeTokenManager.getCurrentUser.getShortUserName))\n-    Map(HADOOP_CONFIG_MAP_NAME ->\n-      hadoopConfDirSpec.hadoopConfigMapName.getOrElse(\n-      kubernetesConf.hadoopConfigMapName)) ++ resolvedConfValues\n+    // If a submission-local keytab is provided, update the Spark config so that it knows the\n+    // path of the keytab in the driver container.\n+    if (needKeytabUpload) {\n+      val ktName = new File(keytab.get).getName()\n+      Map(KEYTAB.key -> s\"$KERBEROS_KEYTAB_MOUNT_POINT/$ktName\")\n+    } else {\n+      Map.empty\n+    }\n   }\n \n   override def getAdditionalKubernetesResources(): Seq[HasMetadata] = {\n-    val hadoopConfConfigMap = for {\n-      hName <- newHadoopConfigMapName\n-      hFiles <- hadoopConfigurationFiles\n-    } yield {\n-      HadoopBootstrapUtil.buildHadoopConfigMap(hName, hFiles)\n+    Seq[HasMetadata]() ++ {\n+      krb5File.map { path =>\n+        val file = new File(path)\n+        new ConfigMapBuilder()\n+          .withNewMetadata()\n+            .withName(kubernetesConf.krbConfigMapName)\n+            .endMetadata()\n+          .addToData(\n+            Map(file.getName() -> Files.toString(file, StandardCharsets.UTF_8)).asJava)\n+          .build()\n+      }\n+    } ++ {\n+      // If a submission-local keytab is provided, stash it in a secret.\n+      if (needKeytabUpload) {\n+        val kt = new File(keytab.get)\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(ktSecretName)\n+            .endMetadata()\n+          .addToData(kt.getName(), Base64.encodeBase64String(Files.toByteArray(kt)))\n+          .build())\n+      } else {\n+        Nil\n+      }\n+    } ++ {\n+      if (delegationTokens != null) {\n+        Seq(new SecretBuilder()\n+          .withNewMetadata()\n+            .withName(dtSecretName)\n+            .endMetadata()\n+          .addToData(KERBEROS_SECRET_KEY, Base64.encodeBase64String(delegationTokens))\n+          .build())\n+      } else {\n+        Nil\n+      }\n     }\n+  }\n \n-    val krb5ConfigMap = krb5File.map { fileLocation =>\n-      HadoopBootstrapUtil.buildkrb5ConfigMap(\n-        kubernetesConf.krbConfigMapName,\n-        fileLocation)\n+  // Visible for testing.\n+  def createDelegationTokens(): Array[Byte] = {"
  }],
  "prId": 22911
}, {
  "comments": [{
    "author": {
      "login": "ifilonenko"
    },
    "body": "nit: is there a particular advantage gained by this style of Seq() building? I prefer the .toSeq approach as I personally don't like `if {...} else { Nil }`. Once again, why was the `Util` class removed? Isn't this a lot of logic to throw into this one step?",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-14T22:40:20Z",
    "diffHunk": "@@ -69,97 +72,191 @@ private[spark] class KerberosConfDriverFeatureStep(\n     \"If a Kerberos keytab is specified you must also specify a Kerberos principal\")\n \n   KubernetesUtils.requireBothOrNeitherDefined(\n-    existingSecretName,\n-    existingSecretItemKey,\n+    existingDtSecret,\n+    existingDtItemKey,\n     \"If a secret data item-key where the data of the Kerberos Delegation Token is specified\" +\n       \" you must also specify the name of the secret\",\n     \"If a secret storing a Kerberos Delegation Token is specified you must also\" +\n       \" specify the item-key where the data is stored\")\n \n-  private val hadoopConfigurationFiles = hadoopConfDirSpec.hadoopConfDir.map { hConfDir =>\n-    HadoopBootstrapUtil.getHadoopConfFiles(hConfDir)\n+  if (!hasKerberosConf) {\n+    logInfo(\"You have not specified a krb5.conf file locally or via a ConfigMap. \" +\n+      \"Make sure that you have the krb5.conf locally on the driver image.\")\n   }\n-  private val newHadoopConfigMapName =\n-    if (hadoopConfDirSpec.hadoopConfigMapName.isEmpty) {\n-      Some(kubernetesConf.hadoopConfigMapName)\n-    } else {\n-      None\n-    }\n \n-  // Either use pre-existing secret or login to create new Secret with DT stored within\n-  private val kerberosConfSpec: Option[KerberosConfigSpec] = (for {\n-    secretName <- existingSecretName\n-    secretItemKey <- existingSecretItemKey\n-  } yield {\n-    KerberosConfigSpec(\n-      dtSecret = None,\n-      dtSecretName = secretName,\n-      dtSecretItemKey = secretItemKey,\n-      jobUserName = kubeTokenManager.getCurrentUser.getShortUserName)\n-  }).orElse(\n-    if (isKerberosEnabled) {\n-      Some(HadoopKerberosLogin.buildSpec(\n-        conf,\n-        kubernetesConf.appResourceNamePrefix,\n-        kubeTokenManager))\n-    } else {\n-      None\n+  // Create delegation tokens if needed. This is a lazy val so that it's not populated\n+  // unnecessarily. But it needs to be accessible to different methods in this class,\n+  // since it's not clear based solely on available configuration options that delegation\n+  // tokens are needed when other credentials are not available.\n+  private lazy val delegationTokens: Array[Byte] = if (keytab.isEmpty && existingDtSecret.isEmpty) {\n+    createDelegationTokens()\n+  } else {\n+    null\n+  }\n+\n+  private def needKeytabUpload: Boolean = keytab.exists(!Utils.isLocalUri(_))\n+\n+  private def dtSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-delegation-tokens\"\n+\n+  private def ktSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-kerberos-keytab\"\n+\n+  private def hasKerberosConf: Boolean = krb5CMap.isDefined | krb5File.isDefined\n+\n+  override def configurePod(original: SparkPod): SparkPod = {\n+    original.transform { case pod if hasKerberosConf =>\n+      val configMapVolume = if (krb5CMap.isDefined) {\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+            .withName(krb5CMap.get)\n+            .endConfigMap()\n+          .build()\n+      } else {\n+        val krb5Conf = new File(krb5File.get)\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+          .withName(kubernetesConf.krbConfigMapName)\n+          .withItems(new KeyToPathBuilder()\n+            .withKey(krb5Conf.getName())\n+            .withPath(krb5Conf.getName())\n+            .build())\n+          .endConfigMap()\n+          .build()\n+      }\n+\n+      val podWithVolume = new PodBuilder(pod.pod)\n+        .editSpec()\n+          .addNewVolumeLike(configMapVolume)\n+            .endVolume()\n+          .endSpec()\n+        .build()\n+\n+      val containerWithMount = new ContainerBuilder(pod.container)\n+        .addNewVolumeMount()\n+          .withName(KRB_FILE_VOLUME)\n+          .withMountPath(KRB_FILE_DIR_PATH + \"/krb5.conf\")\n+          .withSubPath(\"krb5.conf\")\n+          .endVolumeMount()\n+        .build()\n+\n+      SparkPod(podWithVolume, containerWithMount)\n+    }.transform {\n+      case pod if needKeytabUpload =>\n+        // If keytab is defined and is a submission-local file (not local: URI), then create a\n+        // secret for it. The keytab data will be stored in this secret below.\n+        val podWitKeytab = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(KERBEROS_KEYTAB_VOLUME)\n+              .withNewSecret()\n+                .withSecretName(ktSecretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithKeytab = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(KERBEROS_KEYTAB_VOLUME)\n+            .withMountPath(KERBEROS_KEYTAB_MOUNT_POINT)\n+            .endVolumeMount()\n+          .build()\n+\n+        SparkPod(podWitKeytab, containerWithKeytab)\n+\n+      case pod if existingDtSecret.isDefined | delegationTokens != null =>\n+        val secretName = existingDtSecret.getOrElse(dtSecretName)\n+        val itemKey = existingDtItemKey.getOrElse(KERBEROS_SECRET_KEY)\n+\n+        val podWithTokens = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+              .withNewSecret()\n+                .withSecretName(secretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithTokens = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+            .withMountPath(SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR)\n+            .endVolumeMount()\n+          .addNewEnv()\n+            .withName(ENV_HADOOP_TOKEN_FILE_LOCATION)\n+            .withValue(s\"$SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR/$itemKey\")\n+            .endEnv()\n+          .build()\n+\n+        SparkPod(podWithTokens, containerWithTokens)\n     }\n-  )\n-\n-  override def configurePod(pod: SparkPod): SparkPod = {\n-    val hadoopBasedSparkPod = HadoopBootstrapUtil.bootstrapHadoopConfDir(\n-      hadoopConfDirSpec.hadoopConfDir,\n-      newHadoopConfigMapName,\n-      hadoopConfDirSpec.hadoopConfigMapName,\n-      pod)\n-    kerberosConfSpec.map { hSpec =>\n-      HadoopBootstrapUtil.bootstrapKerberosPod(\n-        hSpec.dtSecretName,\n-        hSpec.dtSecretItemKey,\n-        hSpec.jobUserName,\n-        krb5File,\n-        Some(kubernetesConf.krbConfigMapName),\n-        krb5CMap,\n-        hadoopBasedSparkPod)\n-    }.getOrElse(\n-      HadoopBootstrapUtil.bootstrapSparkUserPod(\n-        kubeTokenManager.getCurrentUser.getShortUserName,\n-        hadoopBasedSparkPod))\n   }\n \n   override def getAdditionalPodSystemProperties(): Map[String, String] = {\n-    val resolvedConfValues = kerberosConfSpec.map { hSpec =>\n-      Map(KERBEROS_DT_SECRET_NAME -> hSpec.dtSecretName,\n-        KERBEROS_DT_SECRET_KEY -> hSpec.dtSecretItemKey,\n-        KERBEROS_SPARK_USER_NAME -> hSpec.jobUserName,\n-        KRB5_CONFIG_MAP_NAME -> krb5CMap.getOrElse(kubernetesConf.krbConfigMapName))\n-      }.getOrElse(\n-        Map(KERBEROS_SPARK_USER_NAME ->\n-          kubeTokenManager.getCurrentUser.getShortUserName))\n-    Map(HADOOP_CONFIG_MAP_NAME ->\n-      hadoopConfDirSpec.hadoopConfigMapName.getOrElse(\n-      kubernetesConf.hadoopConfigMapName)) ++ resolvedConfValues\n+    // If a submission-local keytab is provided, update the Spark config so that it knows the\n+    // path of the keytab in the driver container.\n+    if (needKeytabUpload) {\n+      val ktName = new File(keytab.get).getName()\n+      Map(KEYTAB.key -> s\"$KERBEROS_KEYTAB_MOUNT_POINT/$ktName\")\n+    } else {\n+      Map.empty\n+    }\n   }\n \n   override def getAdditionalKubernetesResources(): Seq[HasMetadata] = {\n-    val hadoopConfConfigMap = for {\n-      hName <- newHadoopConfigMapName\n-      hFiles <- hadoopConfigurationFiles\n-    } yield {\n-      HadoopBootstrapUtil.buildHadoopConfigMap(hName, hFiles)\n+    Seq[HasMetadata]() ++ {",
    "line": 324
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "re: the style, same reasoning as the `transform` method I added. It avoids having to create a bunch of local variables and then concatenate them at the end.\r\n\r\nre: the Util class, it existed because the methods were being called from multiple feature steps. Now there's only one step that does that stuff, so the util class became unnecessary.",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-14T22:44:57Z",
    "diffHunk": "@@ -69,97 +72,191 @@ private[spark] class KerberosConfDriverFeatureStep(\n     \"If a Kerberos keytab is specified you must also specify a Kerberos principal\")\n \n   KubernetesUtils.requireBothOrNeitherDefined(\n-    existingSecretName,\n-    existingSecretItemKey,\n+    existingDtSecret,\n+    existingDtItemKey,\n     \"If a secret data item-key where the data of the Kerberos Delegation Token is specified\" +\n       \" you must also specify the name of the secret\",\n     \"If a secret storing a Kerberos Delegation Token is specified you must also\" +\n       \" specify the item-key where the data is stored\")\n \n-  private val hadoopConfigurationFiles = hadoopConfDirSpec.hadoopConfDir.map { hConfDir =>\n-    HadoopBootstrapUtil.getHadoopConfFiles(hConfDir)\n+  if (!hasKerberosConf) {\n+    logInfo(\"You have not specified a krb5.conf file locally or via a ConfigMap. \" +\n+      \"Make sure that you have the krb5.conf locally on the driver image.\")\n   }\n-  private val newHadoopConfigMapName =\n-    if (hadoopConfDirSpec.hadoopConfigMapName.isEmpty) {\n-      Some(kubernetesConf.hadoopConfigMapName)\n-    } else {\n-      None\n-    }\n \n-  // Either use pre-existing secret or login to create new Secret with DT stored within\n-  private val kerberosConfSpec: Option[KerberosConfigSpec] = (for {\n-    secretName <- existingSecretName\n-    secretItemKey <- existingSecretItemKey\n-  } yield {\n-    KerberosConfigSpec(\n-      dtSecret = None,\n-      dtSecretName = secretName,\n-      dtSecretItemKey = secretItemKey,\n-      jobUserName = kubeTokenManager.getCurrentUser.getShortUserName)\n-  }).orElse(\n-    if (isKerberosEnabled) {\n-      Some(HadoopKerberosLogin.buildSpec(\n-        conf,\n-        kubernetesConf.appResourceNamePrefix,\n-        kubeTokenManager))\n-    } else {\n-      None\n+  // Create delegation tokens if needed. This is a lazy val so that it's not populated\n+  // unnecessarily. But it needs to be accessible to different methods in this class,\n+  // since it's not clear based solely on available configuration options that delegation\n+  // tokens are needed when other credentials are not available.\n+  private lazy val delegationTokens: Array[Byte] = if (keytab.isEmpty && existingDtSecret.isEmpty) {\n+    createDelegationTokens()\n+  } else {\n+    null\n+  }\n+\n+  private def needKeytabUpload: Boolean = keytab.exists(!Utils.isLocalUri(_))\n+\n+  private def dtSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-delegation-tokens\"\n+\n+  private def ktSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-kerberos-keytab\"\n+\n+  private def hasKerberosConf: Boolean = krb5CMap.isDefined | krb5File.isDefined\n+\n+  override def configurePod(original: SparkPod): SparkPod = {\n+    original.transform { case pod if hasKerberosConf =>\n+      val configMapVolume = if (krb5CMap.isDefined) {\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+            .withName(krb5CMap.get)\n+            .endConfigMap()\n+          .build()\n+      } else {\n+        val krb5Conf = new File(krb5File.get)\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+          .withName(kubernetesConf.krbConfigMapName)\n+          .withItems(new KeyToPathBuilder()\n+            .withKey(krb5Conf.getName())\n+            .withPath(krb5Conf.getName())\n+            .build())\n+          .endConfigMap()\n+          .build()\n+      }\n+\n+      val podWithVolume = new PodBuilder(pod.pod)\n+        .editSpec()\n+          .addNewVolumeLike(configMapVolume)\n+            .endVolume()\n+          .endSpec()\n+        .build()\n+\n+      val containerWithMount = new ContainerBuilder(pod.container)\n+        .addNewVolumeMount()\n+          .withName(KRB_FILE_VOLUME)\n+          .withMountPath(KRB_FILE_DIR_PATH + \"/krb5.conf\")\n+          .withSubPath(\"krb5.conf\")\n+          .endVolumeMount()\n+        .build()\n+\n+      SparkPod(podWithVolume, containerWithMount)\n+    }.transform {\n+      case pod if needKeytabUpload =>\n+        // If keytab is defined and is a submission-local file (not local: URI), then create a\n+        // secret for it. The keytab data will be stored in this secret below.\n+        val podWitKeytab = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(KERBEROS_KEYTAB_VOLUME)\n+              .withNewSecret()\n+                .withSecretName(ktSecretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithKeytab = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(KERBEROS_KEYTAB_VOLUME)\n+            .withMountPath(KERBEROS_KEYTAB_MOUNT_POINT)\n+            .endVolumeMount()\n+          .build()\n+\n+        SparkPod(podWitKeytab, containerWithKeytab)\n+\n+      case pod if existingDtSecret.isDefined | delegationTokens != null =>\n+        val secretName = existingDtSecret.getOrElse(dtSecretName)\n+        val itemKey = existingDtItemKey.getOrElse(KERBEROS_SECRET_KEY)\n+\n+        val podWithTokens = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+              .withNewSecret()\n+                .withSecretName(secretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithTokens = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+            .withMountPath(SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR)\n+            .endVolumeMount()\n+          .addNewEnv()\n+            .withName(ENV_HADOOP_TOKEN_FILE_LOCATION)\n+            .withValue(s\"$SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR/$itemKey\")\n+            .endEnv()\n+          .build()\n+\n+        SparkPod(podWithTokens, containerWithTokens)\n     }\n-  )\n-\n-  override def configurePod(pod: SparkPod): SparkPod = {\n-    val hadoopBasedSparkPod = HadoopBootstrapUtil.bootstrapHadoopConfDir(\n-      hadoopConfDirSpec.hadoopConfDir,\n-      newHadoopConfigMapName,\n-      hadoopConfDirSpec.hadoopConfigMapName,\n-      pod)\n-    kerberosConfSpec.map { hSpec =>\n-      HadoopBootstrapUtil.bootstrapKerberosPod(\n-        hSpec.dtSecretName,\n-        hSpec.dtSecretItemKey,\n-        hSpec.jobUserName,\n-        krb5File,\n-        Some(kubernetesConf.krbConfigMapName),\n-        krb5CMap,\n-        hadoopBasedSparkPod)\n-    }.getOrElse(\n-      HadoopBootstrapUtil.bootstrapSparkUserPod(\n-        kubeTokenManager.getCurrentUser.getShortUserName,\n-        hadoopBasedSparkPod))\n   }\n \n   override def getAdditionalPodSystemProperties(): Map[String, String] = {\n-    val resolvedConfValues = kerberosConfSpec.map { hSpec =>\n-      Map(KERBEROS_DT_SECRET_NAME -> hSpec.dtSecretName,\n-        KERBEROS_DT_SECRET_KEY -> hSpec.dtSecretItemKey,\n-        KERBEROS_SPARK_USER_NAME -> hSpec.jobUserName,\n-        KRB5_CONFIG_MAP_NAME -> krb5CMap.getOrElse(kubernetesConf.krbConfigMapName))\n-      }.getOrElse(\n-        Map(KERBEROS_SPARK_USER_NAME ->\n-          kubeTokenManager.getCurrentUser.getShortUserName))\n-    Map(HADOOP_CONFIG_MAP_NAME ->\n-      hadoopConfDirSpec.hadoopConfigMapName.getOrElse(\n-      kubernetesConf.hadoopConfigMapName)) ++ resolvedConfValues\n+    // If a submission-local keytab is provided, update the Spark config so that it knows the\n+    // path of the keytab in the driver container.\n+    if (needKeytabUpload) {\n+      val ktName = new File(keytab.get).getName()\n+      Map(KEYTAB.key -> s\"$KERBEROS_KEYTAB_MOUNT_POINT/$ktName\")\n+    } else {\n+      Map.empty\n+    }\n   }\n \n   override def getAdditionalKubernetesResources(): Seq[HasMetadata] = {\n-    val hadoopConfConfigMap = for {\n-      hName <- newHadoopConfigMapName\n-      hFiles <- hadoopConfigurationFiles\n-    } yield {\n-      HadoopBootstrapUtil.buildHadoopConfigMap(hName, hFiles)\n+    Seq[HasMetadata]() ++ {",
    "line": 324
  }, {
    "author": {
      "login": "ifilonenko"
    },
    "body": "> the style, same reasoning as the transform method I added. It avoids having to create a bunch of local variables and then concatenate them at the end.\r\n\r\nThe `transform` I like because it gets rid of: \r\n```\r\n  val someIntermediateName = someOption.map { blah =>\r\n     // create the updated pod\r\n  }.getOrElse(previousPodName)\r\n```\r\nBut that is not what is happening here exactly. Personally, I thought that the previous approach (with local variables + concatonation) was quite clear and didn't really require a change. But its a matter of opinion.\r\n\r\n> Now there's only one step that does that stuff, so the util class became unnecessary.\r\n\r\nOkay I guess from a re-usability perspective that is true, but imo seems like a lot of logic going into this step. but once again, just a matter of opinion",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-14T22:54:43Z",
    "diffHunk": "@@ -69,97 +72,191 @@ private[spark] class KerberosConfDriverFeatureStep(\n     \"If a Kerberos keytab is specified you must also specify a Kerberos principal\")\n \n   KubernetesUtils.requireBothOrNeitherDefined(\n-    existingSecretName,\n-    existingSecretItemKey,\n+    existingDtSecret,\n+    existingDtItemKey,\n     \"If a secret data item-key where the data of the Kerberos Delegation Token is specified\" +\n       \" you must also specify the name of the secret\",\n     \"If a secret storing a Kerberos Delegation Token is specified you must also\" +\n       \" specify the item-key where the data is stored\")\n \n-  private val hadoopConfigurationFiles = hadoopConfDirSpec.hadoopConfDir.map { hConfDir =>\n-    HadoopBootstrapUtil.getHadoopConfFiles(hConfDir)\n+  if (!hasKerberosConf) {\n+    logInfo(\"You have not specified a krb5.conf file locally or via a ConfigMap. \" +\n+      \"Make sure that you have the krb5.conf locally on the driver image.\")\n   }\n-  private val newHadoopConfigMapName =\n-    if (hadoopConfDirSpec.hadoopConfigMapName.isEmpty) {\n-      Some(kubernetesConf.hadoopConfigMapName)\n-    } else {\n-      None\n-    }\n \n-  // Either use pre-existing secret or login to create new Secret with DT stored within\n-  private val kerberosConfSpec: Option[KerberosConfigSpec] = (for {\n-    secretName <- existingSecretName\n-    secretItemKey <- existingSecretItemKey\n-  } yield {\n-    KerberosConfigSpec(\n-      dtSecret = None,\n-      dtSecretName = secretName,\n-      dtSecretItemKey = secretItemKey,\n-      jobUserName = kubeTokenManager.getCurrentUser.getShortUserName)\n-  }).orElse(\n-    if (isKerberosEnabled) {\n-      Some(HadoopKerberosLogin.buildSpec(\n-        conf,\n-        kubernetesConf.appResourceNamePrefix,\n-        kubeTokenManager))\n-    } else {\n-      None\n+  // Create delegation tokens if needed. This is a lazy val so that it's not populated\n+  // unnecessarily. But it needs to be accessible to different methods in this class,\n+  // since it's not clear based solely on available configuration options that delegation\n+  // tokens are needed when other credentials are not available.\n+  private lazy val delegationTokens: Array[Byte] = if (keytab.isEmpty && existingDtSecret.isEmpty) {\n+    createDelegationTokens()\n+  } else {\n+    null\n+  }\n+\n+  private def needKeytabUpload: Boolean = keytab.exists(!Utils.isLocalUri(_))\n+\n+  private def dtSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-delegation-tokens\"\n+\n+  private def ktSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-kerberos-keytab\"\n+\n+  private def hasKerberosConf: Boolean = krb5CMap.isDefined | krb5File.isDefined\n+\n+  override def configurePod(original: SparkPod): SparkPod = {\n+    original.transform { case pod if hasKerberosConf =>\n+      val configMapVolume = if (krb5CMap.isDefined) {\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+            .withName(krb5CMap.get)\n+            .endConfigMap()\n+          .build()\n+      } else {\n+        val krb5Conf = new File(krb5File.get)\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+          .withName(kubernetesConf.krbConfigMapName)\n+          .withItems(new KeyToPathBuilder()\n+            .withKey(krb5Conf.getName())\n+            .withPath(krb5Conf.getName())\n+            .build())\n+          .endConfigMap()\n+          .build()\n+      }\n+\n+      val podWithVolume = new PodBuilder(pod.pod)\n+        .editSpec()\n+          .addNewVolumeLike(configMapVolume)\n+            .endVolume()\n+          .endSpec()\n+        .build()\n+\n+      val containerWithMount = new ContainerBuilder(pod.container)\n+        .addNewVolumeMount()\n+          .withName(KRB_FILE_VOLUME)\n+          .withMountPath(KRB_FILE_DIR_PATH + \"/krb5.conf\")\n+          .withSubPath(\"krb5.conf\")\n+          .endVolumeMount()\n+        .build()\n+\n+      SparkPod(podWithVolume, containerWithMount)\n+    }.transform {\n+      case pod if needKeytabUpload =>\n+        // If keytab is defined and is a submission-local file (not local: URI), then create a\n+        // secret for it. The keytab data will be stored in this secret below.\n+        val podWitKeytab = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(KERBEROS_KEYTAB_VOLUME)\n+              .withNewSecret()\n+                .withSecretName(ktSecretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithKeytab = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(KERBEROS_KEYTAB_VOLUME)\n+            .withMountPath(KERBEROS_KEYTAB_MOUNT_POINT)\n+            .endVolumeMount()\n+          .build()\n+\n+        SparkPod(podWitKeytab, containerWithKeytab)\n+\n+      case pod if existingDtSecret.isDefined | delegationTokens != null =>\n+        val secretName = existingDtSecret.getOrElse(dtSecretName)\n+        val itemKey = existingDtItemKey.getOrElse(KERBEROS_SECRET_KEY)\n+\n+        val podWithTokens = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+              .withNewSecret()\n+                .withSecretName(secretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithTokens = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+            .withMountPath(SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR)\n+            .endVolumeMount()\n+          .addNewEnv()\n+            .withName(ENV_HADOOP_TOKEN_FILE_LOCATION)\n+            .withValue(s\"$SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR/$itemKey\")\n+            .endEnv()\n+          .build()\n+\n+        SparkPod(podWithTokens, containerWithTokens)\n     }\n-  )\n-\n-  override def configurePod(pod: SparkPod): SparkPod = {\n-    val hadoopBasedSparkPod = HadoopBootstrapUtil.bootstrapHadoopConfDir(\n-      hadoopConfDirSpec.hadoopConfDir,\n-      newHadoopConfigMapName,\n-      hadoopConfDirSpec.hadoopConfigMapName,\n-      pod)\n-    kerberosConfSpec.map { hSpec =>\n-      HadoopBootstrapUtil.bootstrapKerberosPod(\n-        hSpec.dtSecretName,\n-        hSpec.dtSecretItemKey,\n-        hSpec.jobUserName,\n-        krb5File,\n-        Some(kubernetesConf.krbConfigMapName),\n-        krb5CMap,\n-        hadoopBasedSparkPod)\n-    }.getOrElse(\n-      HadoopBootstrapUtil.bootstrapSparkUserPod(\n-        kubeTokenManager.getCurrentUser.getShortUserName,\n-        hadoopBasedSparkPod))\n   }\n \n   override def getAdditionalPodSystemProperties(): Map[String, String] = {\n-    val resolvedConfValues = kerberosConfSpec.map { hSpec =>\n-      Map(KERBEROS_DT_SECRET_NAME -> hSpec.dtSecretName,\n-        KERBEROS_DT_SECRET_KEY -> hSpec.dtSecretItemKey,\n-        KERBEROS_SPARK_USER_NAME -> hSpec.jobUserName,\n-        KRB5_CONFIG_MAP_NAME -> krb5CMap.getOrElse(kubernetesConf.krbConfigMapName))\n-      }.getOrElse(\n-        Map(KERBEROS_SPARK_USER_NAME ->\n-          kubeTokenManager.getCurrentUser.getShortUserName))\n-    Map(HADOOP_CONFIG_MAP_NAME ->\n-      hadoopConfDirSpec.hadoopConfigMapName.getOrElse(\n-      kubernetesConf.hadoopConfigMapName)) ++ resolvedConfValues\n+    // If a submission-local keytab is provided, update the Spark config so that it knows the\n+    // path of the keytab in the driver container.\n+    if (needKeytabUpload) {\n+      val ktName = new File(keytab.get).getName()\n+      Map(KEYTAB.key -> s\"$KERBEROS_KEYTAB_MOUNT_POINT/$ktName\")\n+    } else {\n+      Map.empty\n+    }\n   }\n \n   override def getAdditionalKubernetesResources(): Seq[HasMetadata] = {\n-    val hadoopConfConfigMap = for {\n-      hName <- newHadoopConfigMapName\n-      hFiles <- hadoopConfigurationFiles\n-    } yield {\n-      HadoopBootstrapUtil.buildHadoopConfigMap(hName, hFiles)\n+    Seq[HasMetadata]() ++ {",
    "line": 324
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> seems like a lot of logic going into this step\r\n\r\nThe logic itself isn't really different from before. The only difference is that the \"what is done\" for each combination of configs now also lives here.\r\n\r\nIt could be broken down into separate steps, but then you'd have 3 related steps that need to agree on how to treat the configuration of the driver; e.g. if the step that adds they keytab runs, then the step that creates delegation tokens shouldn't run. And that makes the code harder to follow, because you have to look at multiple places to understand how this works.",
    "commit": "ccb39560298a5e54f144b8ba2a43d950289ccf34",
    "createdAt": "2018-11-14T22:57:51Z",
    "diffHunk": "@@ -69,97 +72,191 @@ private[spark] class KerberosConfDriverFeatureStep(\n     \"If a Kerberos keytab is specified you must also specify a Kerberos principal\")\n \n   KubernetesUtils.requireBothOrNeitherDefined(\n-    existingSecretName,\n-    existingSecretItemKey,\n+    existingDtSecret,\n+    existingDtItemKey,\n     \"If a secret data item-key where the data of the Kerberos Delegation Token is specified\" +\n       \" you must also specify the name of the secret\",\n     \"If a secret storing a Kerberos Delegation Token is specified you must also\" +\n       \" specify the item-key where the data is stored\")\n \n-  private val hadoopConfigurationFiles = hadoopConfDirSpec.hadoopConfDir.map { hConfDir =>\n-    HadoopBootstrapUtil.getHadoopConfFiles(hConfDir)\n+  if (!hasKerberosConf) {\n+    logInfo(\"You have not specified a krb5.conf file locally or via a ConfigMap. \" +\n+      \"Make sure that you have the krb5.conf locally on the driver image.\")\n   }\n-  private val newHadoopConfigMapName =\n-    if (hadoopConfDirSpec.hadoopConfigMapName.isEmpty) {\n-      Some(kubernetesConf.hadoopConfigMapName)\n-    } else {\n-      None\n-    }\n \n-  // Either use pre-existing secret or login to create new Secret with DT stored within\n-  private val kerberosConfSpec: Option[KerberosConfigSpec] = (for {\n-    secretName <- existingSecretName\n-    secretItemKey <- existingSecretItemKey\n-  } yield {\n-    KerberosConfigSpec(\n-      dtSecret = None,\n-      dtSecretName = secretName,\n-      dtSecretItemKey = secretItemKey,\n-      jobUserName = kubeTokenManager.getCurrentUser.getShortUserName)\n-  }).orElse(\n-    if (isKerberosEnabled) {\n-      Some(HadoopKerberosLogin.buildSpec(\n-        conf,\n-        kubernetesConf.appResourceNamePrefix,\n-        kubeTokenManager))\n-    } else {\n-      None\n+  // Create delegation tokens if needed. This is a lazy val so that it's not populated\n+  // unnecessarily. But it needs to be accessible to different methods in this class,\n+  // since it's not clear based solely on available configuration options that delegation\n+  // tokens are needed when other credentials are not available.\n+  private lazy val delegationTokens: Array[Byte] = if (keytab.isEmpty && existingDtSecret.isEmpty) {\n+    createDelegationTokens()\n+  } else {\n+    null\n+  }\n+\n+  private def needKeytabUpload: Boolean = keytab.exists(!Utils.isLocalUri(_))\n+\n+  private def dtSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-delegation-tokens\"\n+\n+  private def ktSecretName: String = s\"${kubernetesConf.appResourceNamePrefix}-kerberos-keytab\"\n+\n+  private def hasKerberosConf: Boolean = krb5CMap.isDefined | krb5File.isDefined\n+\n+  override def configurePod(original: SparkPod): SparkPod = {\n+    original.transform { case pod if hasKerberosConf =>\n+      val configMapVolume = if (krb5CMap.isDefined) {\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+            .withName(krb5CMap.get)\n+            .endConfigMap()\n+          .build()\n+      } else {\n+        val krb5Conf = new File(krb5File.get)\n+        new VolumeBuilder()\n+          .withName(KRB_FILE_VOLUME)\n+          .withNewConfigMap()\n+          .withName(kubernetesConf.krbConfigMapName)\n+          .withItems(new KeyToPathBuilder()\n+            .withKey(krb5Conf.getName())\n+            .withPath(krb5Conf.getName())\n+            .build())\n+          .endConfigMap()\n+          .build()\n+      }\n+\n+      val podWithVolume = new PodBuilder(pod.pod)\n+        .editSpec()\n+          .addNewVolumeLike(configMapVolume)\n+            .endVolume()\n+          .endSpec()\n+        .build()\n+\n+      val containerWithMount = new ContainerBuilder(pod.container)\n+        .addNewVolumeMount()\n+          .withName(KRB_FILE_VOLUME)\n+          .withMountPath(KRB_FILE_DIR_PATH + \"/krb5.conf\")\n+          .withSubPath(\"krb5.conf\")\n+          .endVolumeMount()\n+        .build()\n+\n+      SparkPod(podWithVolume, containerWithMount)\n+    }.transform {\n+      case pod if needKeytabUpload =>\n+        // If keytab is defined and is a submission-local file (not local: URI), then create a\n+        // secret for it. The keytab data will be stored in this secret below.\n+        val podWitKeytab = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(KERBEROS_KEYTAB_VOLUME)\n+              .withNewSecret()\n+                .withSecretName(ktSecretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithKeytab = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(KERBEROS_KEYTAB_VOLUME)\n+            .withMountPath(KERBEROS_KEYTAB_MOUNT_POINT)\n+            .endVolumeMount()\n+          .build()\n+\n+        SparkPod(podWitKeytab, containerWithKeytab)\n+\n+      case pod if existingDtSecret.isDefined | delegationTokens != null =>\n+        val secretName = existingDtSecret.getOrElse(dtSecretName)\n+        val itemKey = existingDtItemKey.getOrElse(KERBEROS_SECRET_KEY)\n+\n+        val podWithTokens = new PodBuilder(pod.pod)\n+          .editOrNewSpec()\n+            .addNewVolume()\n+              .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+              .withNewSecret()\n+                .withSecretName(secretName)\n+                .endSecret()\n+              .endVolume()\n+            .endSpec()\n+          .build()\n+\n+        val containerWithTokens = new ContainerBuilder(pod.container)\n+          .addNewVolumeMount()\n+            .withName(SPARK_APP_HADOOP_SECRET_VOLUME_NAME)\n+            .withMountPath(SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR)\n+            .endVolumeMount()\n+          .addNewEnv()\n+            .withName(ENV_HADOOP_TOKEN_FILE_LOCATION)\n+            .withValue(s\"$SPARK_APP_HADOOP_CREDENTIALS_BASE_DIR/$itemKey\")\n+            .endEnv()\n+          .build()\n+\n+        SparkPod(podWithTokens, containerWithTokens)\n     }\n-  )\n-\n-  override def configurePod(pod: SparkPod): SparkPod = {\n-    val hadoopBasedSparkPod = HadoopBootstrapUtil.bootstrapHadoopConfDir(\n-      hadoopConfDirSpec.hadoopConfDir,\n-      newHadoopConfigMapName,\n-      hadoopConfDirSpec.hadoopConfigMapName,\n-      pod)\n-    kerberosConfSpec.map { hSpec =>\n-      HadoopBootstrapUtil.bootstrapKerberosPod(\n-        hSpec.dtSecretName,\n-        hSpec.dtSecretItemKey,\n-        hSpec.jobUserName,\n-        krb5File,\n-        Some(kubernetesConf.krbConfigMapName),\n-        krb5CMap,\n-        hadoopBasedSparkPod)\n-    }.getOrElse(\n-      HadoopBootstrapUtil.bootstrapSparkUserPod(\n-        kubeTokenManager.getCurrentUser.getShortUserName,\n-        hadoopBasedSparkPod))\n   }\n \n   override def getAdditionalPodSystemProperties(): Map[String, String] = {\n-    val resolvedConfValues = kerberosConfSpec.map { hSpec =>\n-      Map(KERBEROS_DT_SECRET_NAME -> hSpec.dtSecretName,\n-        KERBEROS_DT_SECRET_KEY -> hSpec.dtSecretItemKey,\n-        KERBEROS_SPARK_USER_NAME -> hSpec.jobUserName,\n-        KRB5_CONFIG_MAP_NAME -> krb5CMap.getOrElse(kubernetesConf.krbConfigMapName))\n-      }.getOrElse(\n-        Map(KERBEROS_SPARK_USER_NAME ->\n-          kubeTokenManager.getCurrentUser.getShortUserName))\n-    Map(HADOOP_CONFIG_MAP_NAME ->\n-      hadoopConfDirSpec.hadoopConfigMapName.getOrElse(\n-      kubernetesConf.hadoopConfigMapName)) ++ resolvedConfValues\n+    // If a submission-local keytab is provided, update the Spark config so that it knows the\n+    // path of the keytab in the driver container.\n+    if (needKeytabUpload) {\n+      val ktName = new File(keytab.get).getName()\n+      Map(KEYTAB.key -> s\"$KERBEROS_KEYTAB_MOUNT_POINT/$ktName\")\n+    } else {\n+      Map.empty\n+    }\n   }\n \n   override def getAdditionalKubernetesResources(): Seq[HasMetadata] = {\n-    val hadoopConfConfigMap = for {\n-      hName <- newHadoopConfigMapName\n-      hFiles <- hadoopConfigurationFiles\n-    } yield {\n-      HadoopBootstrapUtil.buildHadoopConfigMap(hName, hFiles)\n+    Seq[HasMetadata]() ++ {",
    "line": 324
  }],
  "prId": 22911
}]