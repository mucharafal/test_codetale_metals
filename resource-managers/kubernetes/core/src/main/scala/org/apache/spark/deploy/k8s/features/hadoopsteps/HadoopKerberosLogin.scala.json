[{
  "comments": [{
    "author": {
      "login": "liyinan926"
    },
    "body": "If you choose to keep the `KubernetesHadoopDelegationTokenManager`, can a `HadoopDelegationTokenManager` be embedded in a `KubernetesHadoopDelegationTokenManager`?",
    "commit": "dd95fcab754e71e9465f4e46818c3cef09e86c8b",
    "createdAt": "2018-10-01T16:43:10Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.features.hadoopsteps\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.SecretBuilder\n+import org.apache.commons.codec.binary.Base64\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Constants._\n+import org.apache.spark.deploy.k8s.security.KubernetesHadoopDelegationTokenManager\n+import org.apache.spark.deploy.security.HadoopDelegationTokenManager\n+\n+ /**\n+  * This logic does all the heavy lifting for Delegation Token creation. This step\n+  * assumes that the job user has either specified a principal and keytab or ran\n+  * $kinit before running spark-submit. By running UGI.getCurrentUser we are able\n+  * to obtain the current user, either signed in via $kinit or keytab. With the\n+  * Job User principal you then retrieve the delegation token from the NameNode\n+  * and store values in DelegationToken. Lastly, the class puts the data into\n+  * a secret. All this is defined in a KerberosConfigSpec.\n+  */\n+private[spark] object HadoopKerberosLogin {\n+   def buildSpec(\n+     submissionSparkConf: SparkConf,\n+     kubernetesResourceNamePrefix : String,\n+     tokenManager: KubernetesHadoopDelegationTokenManager): KerberosConfigSpec = {\n+     val hadoopConf = SparkHadoopUtil.get.newConfiguration(submissionSparkConf)\n+     if (!tokenManager.isSecurityEnabled) {\n+       throw new SparkException(\"Hadoop not configured with Kerberos\")\n+     }\n+     // The JobUserUGI will be taken fom the Local Ticket Cache or via keytab+principal\n+     // The login happens in the SparkSubmit so login logic is not necessary\n+     val jobUserUGI = tokenManager.getCurrentUser\n+     val originalCredentials = jobUserUGI.getCredentials\n+     val hadoopTokenManager: HadoopDelegationTokenManager ="
  }],
  "prId": 21669
}, {
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "Type declaration isn't needed here.",
    "commit": "dd95fcab754e71e9465f4e46818c3cef09e86c8b",
    "createdAt": "2018-10-04T00:18:11Z",
    "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.features.hadoopsteps\n+\n+import scala.collection.JavaConverters._\n+\n+import io.fabric8.kubernetes.api.model.SecretBuilder\n+import org.apache.commons.codec.binary.Base64\n+\n+import org.apache.spark.{SparkConf, SparkException}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.k8s.Constants._\n+import org.apache.spark.deploy.k8s.security.KubernetesHadoopDelegationTokenManager\n+import org.apache.spark.deploy.security.HadoopDelegationTokenManager\n+\n+ /**\n+  * This logic does all the heavy lifting for Delegation Token creation. This step\n+  * assumes that the job user has either specified a principal and keytab or ran\n+  * $kinit before running spark-submit. By running UGI.getCurrentUser we are able\n+  * to obtain the current user, either signed in via $kinit or keytab. With the\n+  * Job User principal you then retrieve the delegation token from the NameNode\n+  * and store values in DelegationToken. Lastly, the class puts the data into\n+  * a secret. All this is defined in a KerberosConfigSpec.\n+  */\n+private[spark] object HadoopKerberosLogin {\n+   def buildSpec(\n+     submissionSparkConf: SparkConf,\n+     kubernetesResourceNamePrefix : String,\n+     tokenManager: KubernetesHadoopDelegationTokenManager): KerberosConfigSpec = {\n+     val hadoopConf = SparkHadoopUtil.get.newConfiguration(submissionSparkConf)\n+     if (!tokenManager.isSecurityEnabled) {\n+       throw new SparkException(\"Hadoop not configured with Kerberos\")\n+     }\n+     // The JobUserUGI will be taken fom the Local Ticket Cache or via keytab+principal\n+     // The login happens in the SparkSubmit so login logic is not necessary\n+     val jobUserUGI = tokenManager.getCurrentUser\n+     val originalCredentials = jobUserUGI.getCredentials\n+     val hadoopTokenManager: HadoopDelegationTokenManager ="
  }],
  "prId": 21669
}]