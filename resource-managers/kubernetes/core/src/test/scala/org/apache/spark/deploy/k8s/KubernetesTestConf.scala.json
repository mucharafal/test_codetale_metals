[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Is this for reducing the amount of logging?\r\n\r\nIf so, isn't this a bit dangerous? Because this option doesn't really control logging, but whether to wait for the app. If there's too much log noise you could set the report interval to a really large value.\r\n\r\nMaybe that doesn't matter for unit tests, but it feels a bit odd.",
    "commit": "232fc22184459d4e635957e9412a0e12ae35b00e",
    "createdAt": "2019-09-27T18:47:04Z",
    "diffHunk": "@@ -35,7 +35,7 @@ object KubernetesTestConf {\n   val RESOURCE_PREFIX = \"prefix\"\n   val EXECUTOR_ID = \"1\"\n \n-  private val DEFAULT_CONF = new SparkConf(false)\n+  private val DEFAULT_CONF = new SparkConf(false).set(WAIT_FOR_APP_COMPLETION, false)"
  }, {
    "author": {
      "login": "yaooqinn"
    },
    "body": "https://github.com/apache/spark/blob/7912ab85a6fc086b814d93e7c71af1f50515517a/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/deploy/k8s/Config.scala#L205\r\n\r\nAs the `spark.kubernetes.report.interval` is always positive, I guess if WAIT_FOR_APP_COMPLETION is true, the logging is inevitably on whether in a long or short interval.\r\n\r\nI don't think this is dangerous, because in fact this only controls the logic of LoggingPodStatusWatcher before or after this change. \r\nFor unit tests, this will only take effect in `k8s.submit.ClientSuite`, if it feels a bit odd to you, I can set this test by test in that test class\r\n\r\nalso cc @erikerlandson\r\n",
    "commit": "232fc22184459d4e635957e9412a0e12ae35b00e",
    "createdAt": "2019-09-28T01:17:44Z",
    "diffHunk": "@@ -35,7 +35,7 @@ object KubernetesTestConf {\n   val RESOURCE_PREFIX = \"prefix\"\n   val EXECUTOR_ID = \"1\"\n \n-  private val DEFAULT_CONF = new SparkConf(false)\n+  private val DEFAULT_CONF = new SparkConf(false).set(WAIT_FOR_APP_COMPLETION, false)"
  }],
  "prId": 25648
}]