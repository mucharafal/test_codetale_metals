[{
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "Nit: The second call to `exists` can be `contains` instead, so that we don't pass a function object that ignores the argument. Alternatively, both `exists` calls can be removed:\r\n\r\n```\r\nspec.getHostAliases.asScala.flatMap(_.getHostnames).contains(\"hostname\")\r\n```",
    "commit": "e217e56ffadca8ffdb7991e390fe630a5d563898",
    "createdAt": "2018-12-11T02:29:38Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import java.io.File\n+\n+import io.fabric8.kubernetes.api.model.{Config => _, _}\n+import io.fabric8.kubernetes.client.KubernetesClient\n+import io.fabric8.kubernetes.client.dsl.{MixedOperation, PodResource}\n+import org.mockito.Matchers.any\n+import org.mockito.Mockito.{mock, never, verify, when}\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.{SparkConf, SparkException, SparkFunSuite}\n+import org.apache.spark.deploy.k8s._\n+import org.apache.spark.internal.config.ConfigEntry\n+\n+abstract class PodBuilderSuite extends SparkFunSuite {\n+\n+  protected def templateFileConf: ConfigEntry[_]\n+\n+  protected def buildPod(sparkConf: SparkConf, client: KubernetesClient): SparkPod\n+\n+  private val baseConf = new SparkConf(false)\n+    .set(Config.CONTAINER_IMAGE, \"spark-executor:latest\")\n+\n+  test(\"use empty initial pod if template is not specified\") {\n+    val client = mock(classOf[KubernetesClient])\n+    buildPod(baseConf.clone(), client)\n+    verify(client, never()).pods()\n+  }\n+\n+  test(\"load pod template if specified\") {\n+    val client = mockKubernetesClient()\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val pod = buildPod(sparkConf, client)\n+    verifyPod(pod)\n+  }\n+\n+  test(\"complain about misconfigured pod template\") {\n+    val client = mockKubernetesClient(\n+      new PodBuilder()\n+        .withNewMetadata()\n+        .addToLabels(\"test-label-key\", \"test-label-value\")\n+        .endMetadata()\n+        .build())\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val exception = intercept[SparkException] {\n+      buildPod(sparkConf, client)\n+    }\n+    assert(exception.getMessage.contains(\"Could not load pod from template file.\"))\n+  }\n+\n+  private def mockKubernetesClient(pod: Pod = podWithSupportedFeatures()): KubernetesClient = {\n+    val kubernetesClient = mock(classOf[KubernetesClient])\n+    val pods =\n+      mock(classOf[MixedOperation[Pod, PodList, DoneablePod, PodResource[Pod, DoneablePod]]])\n+    val podResource = mock(classOf[PodResource[Pod, DoneablePod]])\n+    when(kubernetesClient.pods()).thenReturn(pods)\n+    when(pods.load(any(classOf[File]))).thenReturn(podResource)\n+    when(podResource.get()).thenReturn(pod)\n+    kubernetesClient\n+  }\n+\n+  private def verifyPod(pod: SparkPod): Unit = {\n+    val metadata = pod.pod.getMetadata\n+    assert(metadata.getLabels.containsKey(\"test-label-key\"))\n+    assert(metadata.getAnnotations.containsKey(\"test-annotation-key\"))\n+    assert(metadata.getNamespace === \"namespace\")\n+    assert(metadata.getOwnerReferences.asScala.exists(_.getName == \"owner-reference\"))\n+    val spec = pod.pod.getSpec\n+    assert(!spec.getContainers.asScala.exists(_.getName == \"executor-container\"))\n+    assert(spec.getDnsPolicy === \"dns-policy\")\n+    assert(spec.getHostAliases.asScala.exists(_.getHostnames.asScala.exists(_ == \"hostname\")))",
    "line": 88
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I'm not modifying this code, just moving it from its previous location.",
    "commit": "e217e56ffadca8ffdb7991e390fe630a5d563898",
    "createdAt": "2018-12-11T21:55:02Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import java.io.File\n+\n+import io.fabric8.kubernetes.api.model.{Config => _, _}\n+import io.fabric8.kubernetes.client.KubernetesClient\n+import io.fabric8.kubernetes.client.dsl.{MixedOperation, PodResource}\n+import org.mockito.Matchers.any\n+import org.mockito.Mockito.{mock, never, verify, when}\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.{SparkConf, SparkException, SparkFunSuite}\n+import org.apache.spark.deploy.k8s._\n+import org.apache.spark.internal.config.ConfigEntry\n+\n+abstract class PodBuilderSuite extends SparkFunSuite {\n+\n+  protected def templateFileConf: ConfigEntry[_]\n+\n+  protected def buildPod(sparkConf: SparkConf, client: KubernetesClient): SparkPod\n+\n+  private val baseConf = new SparkConf(false)\n+    .set(Config.CONTAINER_IMAGE, \"spark-executor:latest\")\n+\n+  test(\"use empty initial pod if template is not specified\") {\n+    val client = mock(classOf[KubernetesClient])\n+    buildPod(baseConf.clone(), client)\n+    verify(client, never()).pods()\n+  }\n+\n+  test(\"load pod template if specified\") {\n+    val client = mockKubernetesClient()\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val pod = buildPod(sparkConf, client)\n+    verifyPod(pod)\n+  }\n+\n+  test(\"complain about misconfigured pod template\") {\n+    val client = mockKubernetesClient(\n+      new PodBuilder()\n+        .withNewMetadata()\n+        .addToLabels(\"test-label-key\", \"test-label-value\")\n+        .endMetadata()\n+        .build())\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val exception = intercept[SparkException] {\n+      buildPod(sparkConf, client)\n+    }\n+    assert(exception.getMessage.contains(\"Could not load pod from template file.\"))\n+  }\n+\n+  private def mockKubernetesClient(pod: Pod = podWithSupportedFeatures()): KubernetesClient = {\n+    val kubernetesClient = mock(classOf[KubernetesClient])\n+    val pods =\n+      mock(classOf[MixedOperation[Pod, PodList, DoneablePod, PodResource[Pod, DoneablePod]]])\n+    val podResource = mock(classOf[PodResource[Pod, DoneablePod]])\n+    when(kubernetesClient.pods()).thenReturn(pods)\n+    when(pods.load(any(classOf[File]))).thenReturn(podResource)\n+    when(podResource.get()).thenReturn(pod)\n+    kubernetesClient\n+  }\n+\n+  private def verifyPod(pod: SparkPod): Unit = {\n+    val metadata = pod.pod.getMetadata\n+    assert(metadata.getLabels.containsKey(\"test-label-key\"))\n+    assert(metadata.getAnnotations.containsKey(\"test-annotation-key\"))\n+    assert(metadata.getNamespace === \"namespace\")\n+    assert(metadata.getOwnerReferences.asScala.exists(_.getName == \"owner-reference\"))\n+    val spec = pod.pod.getSpec\n+    assert(!spec.getContainers.asScala.exists(_.getName == \"executor-container\"))\n+    assert(spec.getDnsPolicy === \"dns-policy\")\n+    assert(spec.getHostAliases.asScala.exists(_.getHostnames.asScala.exists(_ == \"hostname\")))",
    "line": 88
  }],
  "prId": 23220
}, {
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "Nit: Use `.asScala.map(_.getName).contains(\"executor-container\")`. Similar changes come up throughout this test.",
    "commit": "e217e56ffadca8ffdb7991e390fe630a5d563898",
    "createdAt": "2018-12-11T02:30:30Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import java.io.File\n+\n+import io.fabric8.kubernetes.api.model.{Config => _, _}\n+import io.fabric8.kubernetes.client.KubernetesClient\n+import io.fabric8.kubernetes.client.dsl.{MixedOperation, PodResource}\n+import org.mockito.Matchers.any\n+import org.mockito.Mockito.{mock, never, verify, when}\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.{SparkConf, SparkException, SparkFunSuite}\n+import org.apache.spark.deploy.k8s._\n+import org.apache.spark.internal.config.ConfigEntry\n+\n+abstract class PodBuilderSuite extends SparkFunSuite {\n+\n+  protected def templateFileConf: ConfigEntry[_]\n+\n+  protected def buildPod(sparkConf: SparkConf, client: KubernetesClient): SparkPod\n+\n+  private val baseConf = new SparkConf(false)\n+    .set(Config.CONTAINER_IMAGE, \"spark-executor:latest\")\n+\n+  test(\"use empty initial pod if template is not specified\") {\n+    val client = mock(classOf[KubernetesClient])\n+    buildPod(baseConf.clone(), client)\n+    verify(client, never()).pods()\n+  }\n+\n+  test(\"load pod template if specified\") {\n+    val client = mockKubernetesClient()\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val pod = buildPod(sparkConf, client)\n+    verifyPod(pod)\n+  }\n+\n+  test(\"complain about misconfigured pod template\") {\n+    val client = mockKubernetesClient(\n+      new PodBuilder()\n+        .withNewMetadata()\n+        .addToLabels(\"test-label-key\", \"test-label-value\")\n+        .endMetadata()\n+        .build())\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val exception = intercept[SparkException] {\n+      buildPod(sparkConf, client)\n+    }\n+    assert(exception.getMessage.contains(\"Could not load pod from template file.\"))\n+  }\n+\n+  private def mockKubernetesClient(pod: Pod = podWithSupportedFeatures()): KubernetesClient = {\n+    val kubernetesClient = mock(classOf[KubernetesClient])\n+    val pods =\n+      mock(classOf[MixedOperation[Pod, PodList, DoneablePod, PodResource[Pod, DoneablePod]]])\n+    val podResource = mock(classOf[PodResource[Pod, DoneablePod]])\n+    when(kubernetesClient.pods()).thenReturn(pods)\n+    when(pods.load(any(classOf[File]))).thenReturn(podResource)\n+    when(podResource.get()).thenReturn(pod)\n+    kubernetesClient\n+  }\n+\n+  private def verifyPod(pod: SparkPod): Unit = {\n+    val metadata = pod.pod.getMetadata\n+    assert(metadata.getLabels.containsKey(\"test-label-key\"))\n+    assert(metadata.getAnnotations.containsKey(\"test-annotation-key\"))\n+    assert(metadata.getNamespace === \"namespace\")\n+    assert(metadata.getOwnerReferences.asScala.exists(_.getName == \"owner-reference\"))\n+    val spec = pod.pod.getSpec\n+    assert(!spec.getContainers.asScala.exists(_.getName == \"executor-container\"))",
    "line": 86
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I'm not modifying this code, just moving it from its previous location.",
    "commit": "e217e56ffadca8ffdb7991e390fe630a5d563898",
    "createdAt": "2018-12-11T21:54:58Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import java.io.File\n+\n+import io.fabric8.kubernetes.api.model.{Config => _, _}\n+import io.fabric8.kubernetes.client.KubernetesClient\n+import io.fabric8.kubernetes.client.dsl.{MixedOperation, PodResource}\n+import org.mockito.Matchers.any\n+import org.mockito.Mockito.{mock, never, verify, when}\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.{SparkConf, SparkException, SparkFunSuite}\n+import org.apache.spark.deploy.k8s._\n+import org.apache.spark.internal.config.ConfigEntry\n+\n+abstract class PodBuilderSuite extends SparkFunSuite {\n+\n+  protected def templateFileConf: ConfigEntry[_]\n+\n+  protected def buildPod(sparkConf: SparkConf, client: KubernetesClient): SparkPod\n+\n+  private val baseConf = new SparkConf(false)\n+    .set(Config.CONTAINER_IMAGE, \"spark-executor:latest\")\n+\n+  test(\"use empty initial pod if template is not specified\") {\n+    val client = mock(classOf[KubernetesClient])\n+    buildPod(baseConf.clone(), client)\n+    verify(client, never()).pods()\n+  }\n+\n+  test(\"load pod template if specified\") {\n+    val client = mockKubernetesClient()\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val pod = buildPod(sparkConf, client)\n+    verifyPod(pod)\n+  }\n+\n+  test(\"complain about misconfigured pod template\") {\n+    val client = mockKubernetesClient(\n+      new PodBuilder()\n+        .withNewMetadata()\n+        .addToLabels(\"test-label-key\", \"test-label-value\")\n+        .endMetadata()\n+        .build())\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val exception = intercept[SparkException] {\n+      buildPod(sparkConf, client)\n+    }\n+    assert(exception.getMessage.contains(\"Could not load pod from template file.\"))\n+  }\n+\n+  private def mockKubernetesClient(pod: Pod = podWithSupportedFeatures()): KubernetesClient = {\n+    val kubernetesClient = mock(classOf[KubernetesClient])\n+    val pods =\n+      mock(classOf[MixedOperation[Pod, PodList, DoneablePod, PodResource[Pod, DoneablePod]]])\n+    val podResource = mock(classOf[PodResource[Pod, DoneablePod]])\n+    when(kubernetesClient.pods()).thenReturn(pods)\n+    when(pods.load(any(classOf[File]))).thenReturn(podResource)\n+    when(podResource.get()).thenReturn(pod)\n+    kubernetesClient\n+  }\n+\n+  private def verifyPod(pod: SparkPod): Unit = {\n+    val metadata = pod.pod.getMetadata\n+    assert(metadata.getLabels.containsKey(\"test-label-key\"))\n+    assert(metadata.getAnnotations.containsKey(\"test-annotation-key\"))\n+    assert(metadata.getNamespace === \"namespace\")\n+    assert(metadata.getOwnerReferences.asScala.exists(_.getName == \"owner-reference\"))\n+    val spec = pod.pod.getSpec\n+    assert(!spec.getContainers.asScala.exists(_.getName == \"executor-container\"))",
    "line": 86
  }],
  "prId": 23220
}, {
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "The number of things this test checks is remarkable, and it is very much possible to accidentally omit checking the application of a specific feature when a new one is added for either the driver or executor. This is why we had the overridable feature steps in the original incarnation of these tests. Not mocking the substeps leads us to need to check that some specific aspect of each step has been applied. Can we go back to mocking the different steps so that this test can be more easily modified when we add more features? Or else can we abstract away the idea that these steps are applied without this test itself needing to know what the step itself actually does?",
    "commit": "e217e56ffadca8ffdb7991e390fe630a5d563898",
    "createdAt": "2018-12-11T02:33:43Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import java.io.File\n+\n+import io.fabric8.kubernetes.api.model.{Config => _, _}\n+import io.fabric8.kubernetes.client.KubernetesClient\n+import io.fabric8.kubernetes.client.dsl.{MixedOperation, PodResource}\n+import org.mockito.Matchers.any\n+import org.mockito.Mockito.{mock, never, verify, when}\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.{SparkConf, SparkException, SparkFunSuite}\n+import org.apache.spark.deploy.k8s._\n+import org.apache.spark.internal.config.ConfigEntry\n+\n+abstract class PodBuilderSuite extends SparkFunSuite {\n+\n+  protected def templateFileConf: ConfigEntry[_]\n+\n+  protected def buildPod(sparkConf: SparkConf, client: KubernetesClient): SparkPod\n+\n+  private val baseConf = new SparkConf(false)\n+    .set(Config.CONTAINER_IMAGE, \"spark-executor:latest\")\n+\n+  test(\"use empty initial pod if template is not specified\") {\n+    val client = mock(classOf[KubernetesClient])\n+    buildPod(baseConf.clone(), client)\n+    verify(client, never()).pods()\n+  }\n+\n+  test(\"load pod template if specified\") {\n+    val client = mockKubernetesClient()\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val pod = buildPod(sparkConf, client)\n+    verifyPod(pod)\n+  }\n+\n+  test(\"complain about misconfigured pod template\") {\n+    val client = mockKubernetesClient(\n+      new PodBuilder()\n+        .withNewMetadata()\n+        .addToLabels(\"test-label-key\", \"test-label-value\")\n+        .endMetadata()\n+        .build())\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val exception = intercept[SparkException] {\n+      buildPod(sparkConf, client)\n+    }\n+    assert(exception.getMessage.contains(\"Could not load pod from template file.\"))\n+  }\n+\n+  private def mockKubernetesClient(pod: Pod = podWithSupportedFeatures()): KubernetesClient = {\n+    val kubernetesClient = mock(classOf[KubernetesClient])\n+    val pods =\n+      mock(classOf[MixedOperation[Pod, PodList, DoneablePod, PodResource[Pod, DoneablePod]]])\n+    val podResource = mock(classOf[PodResource[Pod, DoneablePod]])\n+    when(kubernetesClient.pods()).thenReturn(pods)\n+    when(pods.load(any(classOf[File]))).thenReturn(podResource)\n+    when(podResource.get()).thenReturn(pod)\n+    kubernetesClient\n+  }\n+\n+  private def verifyPod(pod: SparkPod): Unit = {",
    "line": 79
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "Another factor of my concern about is that for each individual assertion, it is unclear which step the assertion is tied to. This reads a lot more like an ETE test than a unit test.",
    "commit": "e217e56ffadca8ffdb7991e390fe630a5d563898",
    "createdAt": "2018-12-11T02:42:26Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import java.io.File\n+\n+import io.fabric8.kubernetes.api.model.{Config => _, _}\n+import io.fabric8.kubernetes.client.KubernetesClient\n+import io.fabric8.kubernetes.client.dsl.{MixedOperation, PodResource}\n+import org.mockito.Matchers.any\n+import org.mockito.Mockito.{mock, never, verify, when}\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.{SparkConf, SparkException, SparkFunSuite}\n+import org.apache.spark.deploy.k8s._\n+import org.apache.spark.internal.config.ConfigEntry\n+\n+abstract class PodBuilderSuite extends SparkFunSuite {\n+\n+  protected def templateFileConf: ConfigEntry[_]\n+\n+  protected def buildPod(sparkConf: SparkConf, client: KubernetesClient): SparkPod\n+\n+  private val baseConf = new SparkConf(false)\n+    .set(Config.CONTAINER_IMAGE, \"spark-executor:latest\")\n+\n+  test(\"use empty initial pod if template is not specified\") {\n+    val client = mock(classOf[KubernetesClient])\n+    buildPod(baseConf.clone(), client)\n+    verify(client, never()).pods()\n+  }\n+\n+  test(\"load pod template if specified\") {\n+    val client = mockKubernetesClient()\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val pod = buildPod(sparkConf, client)\n+    verifyPod(pod)\n+  }\n+\n+  test(\"complain about misconfigured pod template\") {\n+    val client = mockKubernetesClient(\n+      new PodBuilder()\n+        .withNewMetadata()\n+        .addToLabels(\"test-label-key\", \"test-label-value\")\n+        .endMetadata()\n+        .build())\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val exception = intercept[SparkException] {\n+      buildPod(sparkConf, client)\n+    }\n+    assert(exception.getMessage.contains(\"Could not load pod from template file.\"))\n+  }\n+\n+  private def mockKubernetesClient(pod: Pod = podWithSupportedFeatures()): KubernetesClient = {\n+    val kubernetesClient = mock(classOf[KubernetesClient])\n+    val pods =\n+      mock(classOf[MixedOperation[Pod, PodList, DoneablePod, PodResource[Pod, DoneablePod]]])\n+    val podResource = mock(classOf[PodResource[Pod, DoneablePod]])\n+    when(kubernetesClient.pods()).thenReturn(pods)\n+    when(pods.load(any(classOf[File]))).thenReturn(podResource)\n+    when(podResource.get()).thenReturn(pod)\n+    kubernetesClient\n+  }\n+\n+  private def verifyPod(pod: SparkPod): Unit = {",
    "line": 79
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I actually did not write this test. I copy & pasted it with zero modifications from the previous class, and I'd prefer to keep it that way.\r\n\r\nThat's also an argument for *not* restoring the mocks, which would go against what this change is doing. This test should account for modifications made by other steps, since if they modify something unexpected, that can change the semantics of the feature (pod template support).",
    "commit": "e217e56ffadca8ffdb7991e390fe630a5d563898",
    "createdAt": "2018-12-11T21:54:17Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import java.io.File\n+\n+import io.fabric8.kubernetes.api.model.{Config => _, _}\n+import io.fabric8.kubernetes.client.KubernetesClient\n+import io.fabric8.kubernetes.client.dsl.{MixedOperation, PodResource}\n+import org.mockito.Matchers.any\n+import org.mockito.Mockito.{mock, never, verify, when}\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.{SparkConf, SparkException, SparkFunSuite}\n+import org.apache.spark.deploy.k8s._\n+import org.apache.spark.internal.config.ConfigEntry\n+\n+abstract class PodBuilderSuite extends SparkFunSuite {\n+\n+  protected def templateFileConf: ConfigEntry[_]\n+\n+  protected def buildPod(sparkConf: SparkConf, client: KubernetesClient): SparkPod\n+\n+  private val baseConf = new SparkConf(false)\n+    .set(Config.CONTAINER_IMAGE, \"spark-executor:latest\")\n+\n+  test(\"use empty initial pod if template is not specified\") {\n+    val client = mock(classOf[KubernetesClient])\n+    buildPod(baseConf.clone(), client)\n+    verify(client, never()).pods()\n+  }\n+\n+  test(\"load pod template if specified\") {\n+    val client = mockKubernetesClient()\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val pod = buildPod(sparkConf, client)\n+    verifyPod(pod)\n+  }\n+\n+  test(\"complain about misconfigured pod template\") {\n+    val client = mockKubernetesClient(\n+      new PodBuilder()\n+        .withNewMetadata()\n+        .addToLabels(\"test-label-key\", \"test-label-value\")\n+        .endMetadata()\n+        .build())\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val exception = intercept[SparkException] {\n+      buildPod(sparkConf, client)\n+    }\n+    assert(exception.getMessage.contains(\"Could not load pod from template file.\"))\n+  }\n+\n+  private def mockKubernetesClient(pod: Pod = podWithSupportedFeatures()): KubernetesClient = {\n+    val kubernetesClient = mock(classOf[KubernetesClient])\n+    val pods =\n+      mock(classOf[MixedOperation[Pod, PodList, DoneablePod, PodResource[Pod, DoneablePod]]])\n+    val podResource = mock(classOf[PodResource[Pod, DoneablePod]])\n+    when(kubernetesClient.pods()).thenReturn(pods)\n+    when(pods.load(any(classOf[File]))).thenReturn(podResource)\n+    when(podResource.get()).thenReturn(pod)\n+    kubernetesClient\n+  }\n+\n+  private def verifyPod(pod: SparkPod): Unit = {",
    "line": 79
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "> That's also an argument for not restoring the mocks, which would go against what this change is doing. This test should account for modifications made by other steps, since if they modify something unexpected, that can change the semantics of the feature (pod template support).\r\n\r\nWouldn't most of those unexpected changes come from the unit tests of the individual steps? Granted this test can catch when a change in one step impacts behavior in another step, which is important. Given that this isn't changing prior code I'm fine with leaving this as-is and addressing again later if it becomes a problem.",
    "commit": "e217e56ffadca8ffdb7991e390fe630a5d563898",
    "createdAt": "2018-12-11T23:39:40Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s\n+\n+import java.io.File\n+\n+import io.fabric8.kubernetes.api.model.{Config => _, _}\n+import io.fabric8.kubernetes.client.KubernetesClient\n+import io.fabric8.kubernetes.client.dsl.{MixedOperation, PodResource}\n+import org.mockito.Matchers.any\n+import org.mockito.Mockito.{mock, never, verify, when}\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.{SparkConf, SparkException, SparkFunSuite}\n+import org.apache.spark.deploy.k8s._\n+import org.apache.spark.internal.config.ConfigEntry\n+\n+abstract class PodBuilderSuite extends SparkFunSuite {\n+\n+  protected def templateFileConf: ConfigEntry[_]\n+\n+  protected def buildPod(sparkConf: SparkConf, client: KubernetesClient): SparkPod\n+\n+  private val baseConf = new SparkConf(false)\n+    .set(Config.CONTAINER_IMAGE, \"spark-executor:latest\")\n+\n+  test(\"use empty initial pod if template is not specified\") {\n+    val client = mock(classOf[KubernetesClient])\n+    buildPod(baseConf.clone(), client)\n+    verify(client, never()).pods()\n+  }\n+\n+  test(\"load pod template if specified\") {\n+    val client = mockKubernetesClient()\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val pod = buildPod(sparkConf, client)\n+    verifyPod(pod)\n+  }\n+\n+  test(\"complain about misconfigured pod template\") {\n+    val client = mockKubernetesClient(\n+      new PodBuilder()\n+        .withNewMetadata()\n+        .addToLabels(\"test-label-key\", \"test-label-value\")\n+        .endMetadata()\n+        .build())\n+    val sparkConf = baseConf.clone().set(templateFileConf.key, \"template-file.yaml\")\n+    val exception = intercept[SparkException] {\n+      buildPod(sparkConf, client)\n+    }\n+    assert(exception.getMessage.contains(\"Could not load pod from template file.\"))\n+  }\n+\n+  private def mockKubernetesClient(pod: Pod = podWithSupportedFeatures()): KubernetesClient = {\n+    val kubernetesClient = mock(classOf[KubernetesClient])\n+    val pods =\n+      mock(classOf[MixedOperation[Pod, PodList, DoneablePod, PodResource[Pod, DoneablePod]]])\n+    val podResource = mock(classOf[PodResource[Pod, DoneablePod]])\n+    when(kubernetesClient.pods()).thenReturn(pods)\n+    when(pods.load(any(classOf[File]))).thenReturn(podResource)\n+    when(podResource.get()).thenReturn(pod)\n+    kubernetesClient\n+  }\n+\n+  private def verifyPod(pod: SparkPod): Unit = {",
    "line": 79
  }],
  "prId": 23220
}]