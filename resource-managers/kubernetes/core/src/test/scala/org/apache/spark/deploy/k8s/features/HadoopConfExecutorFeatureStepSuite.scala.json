[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "use `assert(foo.isEmpty)`, no need for a message. Also in a bunch of places below.",
    "commit": "f2948a0622f6f6d34834ba4525e573cc81b4ed7b",
    "createdAt": "2018-11-13T18:30:44Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.features\n+\n+import org.mockito.{Mock, MockitoAnnotations}\n+import org.mockito.Matchers.{eq => Eq}\n+import org.mockito.Mockito.when\n+import org.mockito.invocation.InvocationOnMock\n+import org.mockito.stubbing.Answer\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.k8s.{KubernetesConf, KubernetesExecutorSpecificConf, SparkPod}\n+import org.apache.spark.deploy.k8s.Constants.HADOOP_CONFIG_MAP_NAME\n+import org.apache.spark.deploy.k8s.features.hadooputils.HadoopBootstrapUtil\n+\n+class HadoopConfExecutorFeatureStepSuite extends SparkFunSuite with BeforeAndAfter {\n+  private val hadoopConfMapName = \"HADOOP_CONF_NAME\"\n+  private val sparkPod = SparkPod.initialPod()\n+\n+  @Mock\n+  private var kubernetesConf: KubernetesConf[KubernetesExecutorSpecificConf] = _\n+\n+  @Mock\n+  private var hadoopBootstrapUtil: HadoopBootstrapUtil = _\n+\n+  before {\n+    MockitoAnnotations.initMocks(this)\n+    val sparkConf = new SparkConf(false)\n+      .set(HADOOP_CONFIG_MAP_NAME, hadoopConfMapName)\n+    when(kubernetesConf.sparkConf).thenReturn(sparkConf)\n+  }\n+\n+  test(\"bootstrapHadoopConf being applied to a base spark pod\") {\n+    when(hadoopBootstrapUtil.bootstrapHadoopConfDir(\n+      Eq(None),\n+      Eq(None),\n+      Eq(Some(hadoopConfMapName)),\n+      Eq(sparkPod)\n+    )).thenAnswer(new Answer[SparkPod] {\n+      override def answer(invocation: InvocationOnMock) : SparkPod = {\n+        KubernetesFeaturesTestUtils.hadoopConfBootPod(\n+          invocation.getArgumentAt(3, classOf[SparkPod]))\n+      }\n+    })\n+    val hConfStep = new HadoopConfExecutorFeatureStep(kubernetesConf, hadoopBootstrapUtil)\n+    val pod = hConfStep.configurePod(sparkPod)\n+    KubernetesFeaturesTestUtils.podHasLabels(pod.pod, Map(\"bootstrap-hconf\" -> \"true\"))\n+    assert(hConfStep.getAdditionalPodSystemProperties() == Map.empty,"
  }],
  "prId": 22760
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "So after I spent some time cleaning other code in the k8s backend, I started to really dislike this kind of test that over-mocks things. This test is actually just a result of a lot of other things that I think are wrong in the current code (not just kerberos-related, but in the k8s backend in general).\r\n\r\nBasically you have a lot of code and mocks here to test a single thing: that the feature step is calling this one method with the parameters you expect.\r\n\r\nIf instead the feature step was written to be more easily testable, this wouldn't be needed. You wouldn't need to mock anything, and it would just run the normal code and you'd assert that the resulting pod has what you expect.\r\n\r\nI filed SPARK-25874 to fix all this stuff (with a few sub-tasks), and I'm now thinking it's better to do that first. It would simplify the tests here a lot. It would avoid all this noisy and IMO unnecessary mocking. And we'd have better tests. You can look at my p.o.c. code linked from that bug to see what I mean.\r\n\r\nAs another data point, to address the comments on SPARK-25815 I'm having to rewrite a bunch of code in this area. So all these tests would have to be largely rewritten (on which PR, it depends on which one goes in first).\r\n\r\nSo, long story short, checking this in would mean I'd be rewriting all this code very, very soon. So I'm not seeing a lot of gains here...",
    "commit": "f2948a0622f6f6d34834ba4525e573cc81b4ed7b",
    "createdAt": "2018-11-13T18:45:44Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.features\n+\n+import org.mockito.{Mock, MockitoAnnotations}\n+import org.mockito.Matchers.{eq => Eq}\n+import org.mockito.Mockito.when\n+import org.mockito.invocation.InvocationOnMock\n+import org.mockito.stubbing.Answer\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.k8s.{KubernetesConf, KubernetesExecutorSpecificConf, SparkPod}\n+import org.apache.spark.deploy.k8s.Constants.HADOOP_CONFIG_MAP_NAME\n+import org.apache.spark.deploy.k8s.features.hadooputils.HadoopBootstrapUtil\n+\n+class HadoopConfExecutorFeatureStepSuite extends SparkFunSuite with BeforeAndAfter {\n+  private val hadoopConfMapName = \"HADOOP_CONF_NAME\"\n+  private val sparkPod = SparkPod.initialPod()\n+\n+  @Mock\n+  private var kubernetesConf: KubernetesConf[KubernetesExecutorSpecificConf] = _\n+\n+  @Mock\n+  private var hadoopBootstrapUtil: HadoopBootstrapUtil = _\n+\n+  before {\n+    MockitoAnnotations.initMocks(this)\n+    val sparkConf = new SparkConf(false)\n+      .set(HADOOP_CONFIG_MAP_NAME, hadoopConfMapName)\n+    when(kubernetesConf.sparkConf).thenReturn(sparkConf)\n+  }\n+\n+  test(\"bootstrapHadoopConf being applied to a base spark pod\") {\n+    when(hadoopBootstrapUtil.bootstrapHadoopConfDir(",
    "line": 49
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "Instead of mocks would we implement stub subclasses then? The purpose of the mocks is to make every unit test run only code that is in the class under test, plus utility methods. I think the only alternative to mocks is writing stub implementations, and it's not clear how much more / less boilerplate that would be also. If the stub subclasses lead to less boilerplate than mocks then we should go with that.",
    "commit": "f2948a0622f6f6d34834ba4525e573cc81b4ed7b",
    "createdAt": "2018-11-13T19:52:09Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.features\n+\n+import org.mockito.{Mock, MockitoAnnotations}\n+import org.mockito.Matchers.{eq => Eq}\n+import org.mockito.Mockito.when\n+import org.mockito.invocation.InvocationOnMock\n+import org.mockito.stubbing.Answer\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.k8s.{KubernetesConf, KubernetesExecutorSpecificConf, SparkPod}\n+import org.apache.spark.deploy.k8s.Constants.HADOOP_CONFIG_MAP_NAME\n+import org.apache.spark.deploy.k8s.features.hadooputils.HadoopBootstrapUtil\n+\n+class HadoopConfExecutorFeatureStepSuite extends SparkFunSuite with BeforeAndAfter {\n+  private val hadoopConfMapName = \"HADOOP_CONF_NAME\"\n+  private val sparkPod = SparkPod.initialPod()\n+\n+  @Mock\n+  private var kubernetesConf: KubernetesConf[KubernetesExecutorSpecificConf] = _\n+\n+  @Mock\n+  private var hadoopBootstrapUtil: HadoopBootstrapUtil = _\n+\n+  before {\n+    MockitoAnnotations.initMocks(this)\n+    val sparkConf = new SparkConf(false)\n+      .set(HADOOP_CONFIG_MAP_NAME, hadoopConfMapName)\n+    when(kubernetesConf.sparkConf).thenReturn(sparkConf)\n+  }\n+\n+  test(\"bootstrapHadoopConf being applied to a base spark pod\") {\n+    when(hadoopBootstrapUtil.bootstrapHadoopConfDir(",
    "line": 49
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> The purpose of the mocks is to make every unit test run only code that is in the class under test\r\n\r\nFirst, let me clarify that I'm against what I think is the excessive use of mocks in these tests; and by that I mean mostly mocking a whole bunch of things using mockito.\r\n\r\nYou can mock things without mockito. e.g. if what you want is to provide the test with a specific mock configuration, it's pretty trivial to do that with existing classes. Tests do this all over the code base without having to mock `SparkConf` or any other classes. \r\n\r\n(This is currently more painful than it should be in the k8s backend, which is one of the things I'm trying to fix with my cleanups.)\r\n\r\nSo let's use this particular test here as an example. What is it testing?\r\n\r\nI think it should be testing that if a user has set the appropriate configuration in their `SparkConf`, that this step will mount a volume with the user's Hadoop configuration in the final pod. Is that what the code here is testing?\r\n\r\nI don't think so. It's testing that a specific method call is being made with certain parameters. A much better test would be to actually let the code in the step run and do its thing, and test the final result for expected things (in this case, the hadoop conf being mounted).\r\n\r\nOr thinking another way: how can you actually break this test, without removing that one method call from the step implementation? Since both the inputs and the output of that call are mocked here.",
    "commit": "f2948a0622f6f6d34834ba4525e573cc81b4ed7b",
    "createdAt": "2018-11-13T20:29:59Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.features\n+\n+import org.mockito.{Mock, MockitoAnnotations}\n+import org.mockito.Matchers.{eq => Eq}\n+import org.mockito.Mockito.when\n+import org.mockito.invocation.InvocationOnMock\n+import org.mockito.stubbing.Answer\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.k8s.{KubernetesConf, KubernetesExecutorSpecificConf, SparkPod}\n+import org.apache.spark.deploy.k8s.Constants.HADOOP_CONFIG_MAP_NAME\n+import org.apache.spark.deploy.k8s.features.hadooputils.HadoopBootstrapUtil\n+\n+class HadoopConfExecutorFeatureStepSuite extends SparkFunSuite with BeforeAndAfter {\n+  private val hadoopConfMapName = \"HADOOP_CONF_NAME\"\n+  private val sparkPod = SparkPod.initialPod()\n+\n+  @Mock\n+  private var kubernetesConf: KubernetesConf[KubernetesExecutorSpecificConf] = _\n+\n+  @Mock\n+  private var hadoopBootstrapUtil: HadoopBootstrapUtil = _\n+\n+  before {\n+    MockitoAnnotations.initMocks(this)\n+    val sparkConf = new SparkConf(false)\n+      .set(HADOOP_CONFIG_MAP_NAME, hadoopConfMapName)\n+    when(kubernetesConf.sparkConf).thenReturn(sparkConf)\n+  }\n+\n+  test(\"bootstrapHadoopConf being applied to a base spark pod\") {\n+    when(hadoopBootstrapUtil.bootstrapHadoopConfDir(",
    "line": 49
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "There is a point of over-mocking, I agree. I think `KubernetesConf` shouldn't be mocked in most cases because it's just a structure. This is similar to not mocking something like a case class or a hash map. I also don't think we need to use Mockito Answers here - that could be done with stub implementations of the submodule. I didn't have a strong enough conviction of not using Mockito answers, but in general I think we should favor stub implementations over `Answer`; it's more readable.\r\n\r\nI think it's fine though that we want to test \"We're calling this submodule with these parameters\", because the rest of the module's correctness is unit-test covered in the unit tests of that submodule. The general premise we'd like to follow is that a unit test should only execute code that is in the class under test. In other words, in this concrete case, since `HadoopBootstrapUtil` is a separate class, no code in `HadoopBootstrapUtil` should be run as part of the test. The class under test is responsible for calling the utility submodule with certain arguments but is not concerned about what that submodule actually does. Thus the test also doesn't have to be concerned here about what that submodule actually does, but should check that the submodule was actually called. If we want to check the submodule's correctness, we unit test the submodule.\r\n\r\nNow - did we need a submodule to begin with? We could have, for example, kept HadoopBootstrapUtil not really be a submodule at all, but just a `static` call on a utility method. I think that's debatable - it makes each test need to cover a larger amount of code; that is, we no longer test the utility method in isolation, which is what we get here. Therefore it's unclear if HadoopBootstrapUtil being its own object that can be stubbed, is the right approach.",
    "commit": "f2948a0622f6f6d34834ba4525e573cc81b4ed7b",
    "createdAt": "2018-11-13T23:04:05Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.features\n+\n+import org.mockito.{Mock, MockitoAnnotations}\n+import org.mockito.Matchers.{eq => Eq}\n+import org.mockito.Mockito.when\n+import org.mockito.invocation.InvocationOnMock\n+import org.mockito.stubbing.Answer\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.k8s.{KubernetesConf, KubernetesExecutorSpecificConf, SparkPod}\n+import org.apache.spark.deploy.k8s.Constants.HADOOP_CONFIG_MAP_NAME\n+import org.apache.spark.deploy.k8s.features.hadooputils.HadoopBootstrapUtil\n+\n+class HadoopConfExecutorFeatureStepSuite extends SparkFunSuite with BeforeAndAfter {\n+  private val hadoopConfMapName = \"HADOOP_CONF_NAME\"\n+  private val sparkPod = SparkPod.initialPod()\n+\n+  @Mock\n+  private var kubernetesConf: KubernetesConf[KubernetesExecutorSpecificConf] = _\n+\n+  @Mock\n+  private var hadoopBootstrapUtil: HadoopBootstrapUtil = _\n+\n+  before {\n+    MockitoAnnotations.initMocks(this)\n+    val sparkConf = new SparkConf(false)\n+      .set(HADOOP_CONFIG_MAP_NAME, hadoopConfMapName)\n+    when(kubernetesConf.sparkConf).thenReturn(sparkConf)\n+  }\n+\n+  test(\"bootstrapHadoopConf being applied to a base spark pod\") {\n+    when(hadoopBootstrapUtil.bootstrapHadoopConfDir(",
    "line": 49
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> I think it's fine though that we want to test \"We're calling this submodule with these parameters\"\r\n\r\nI think that's a very restrictive view of testing. I prefer my previous interpretation: the goal of this step is to mount a volume if a certain config is set. Whether it does that by calling into another module or not, it doesn't matter. That's what should be tested. You're taking \"white box testing\" to an extreme here - you're testing specific lines of code in the implementation instead of testing the contract (\"for these inputs generate these outputs\").\r\n\r\nIf it's done via another module, and you want to have unit tests for that module too, that's fine. But  then you get into your other question...\r\n\r\nLooking from the other side: if you change the implementation in a way that breaks this test, but keeps the actual functionality, what good was this test doing?\r\n\r\n> did we need a submodule to begin with?\r\n\r\nMy answer to that question is no - and as part of my updates to SPARK-25815 I'll be removing that class. But that's kinda orthogonal to my point.",
    "commit": "f2948a0622f6f6d34834ba4525e573cc81b4ed7b",
    "createdAt": "2018-11-13T23:45:21Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy.k8s.features\n+\n+import org.mockito.{Mock, MockitoAnnotations}\n+import org.mockito.Matchers.{eq => Eq}\n+import org.mockito.Mockito.when\n+import org.mockito.invocation.InvocationOnMock\n+import org.mockito.stubbing.Answer\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.k8s.{KubernetesConf, KubernetesExecutorSpecificConf, SparkPod}\n+import org.apache.spark.deploy.k8s.Constants.HADOOP_CONFIG_MAP_NAME\n+import org.apache.spark.deploy.k8s.features.hadooputils.HadoopBootstrapUtil\n+\n+class HadoopConfExecutorFeatureStepSuite extends SparkFunSuite with BeforeAndAfter {\n+  private val hadoopConfMapName = \"HADOOP_CONF_NAME\"\n+  private val sparkPod = SparkPod.initialPod()\n+\n+  @Mock\n+  private var kubernetesConf: KubernetesConf[KubernetesExecutorSpecificConf] = _\n+\n+  @Mock\n+  private var hadoopBootstrapUtil: HadoopBootstrapUtil = _\n+\n+  before {\n+    MockitoAnnotations.initMocks(this)\n+    val sparkConf = new SparkConf(false)\n+      .set(HADOOP_CONFIG_MAP_NAME, hadoopConfMapName)\n+    when(kubernetesConf.sparkConf).thenReturn(sparkConf)\n+  }\n+\n+  test(\"bootstrapHadoopConf being applied to a base spark pod\") {\n+    when(hadoopBootstrapUtil.bootstrapHadoopConfDir(",
    "line": 49
  }],
  "prId": 22760
}]