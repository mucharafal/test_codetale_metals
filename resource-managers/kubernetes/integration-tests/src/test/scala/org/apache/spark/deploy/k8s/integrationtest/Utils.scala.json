[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "@skonto . In this PR, you copied `getExamplesJarAbsolutePath` to `getTestFileAbsolutePath` and removed all instances using `getExamplesJarAbsolutePath`. Do we think we need to maintain the unused function, `getExamplesJarAbsolutePath`?\r\n\r\nIn this case, I'd like to recommend you to generalize the existing function by renaming.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-28T03:09:39Z",
    "diffHunk": "@@ -131,4 +133,41 @@ object Utils extends Logging {\n         s\"under spark home test dir ${sparkHomeDir.toAbsolutePath}!\")\n     }\n   }\n+\n+  def getTestFileAbsolutePath(fileName: String, sparkHomeDir: Path): String = {",
    "line": 23
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Hmmm let me check.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-11-08T20:19:28Z",
    "diffHunk": "@@ -131,4 +133,41 @@ object Utils extends Logging {\n         s\"under spark home test dir ${sparkHomeDir.toAbsolutePath}!\")\n     }\n   }\n+\n+  def getTestFileAbsolutePath(fileName: String, sparkHomeDir: Path): String = {",
    "line": 23
  }],
  "prId": 25870
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "In one file, you remove the empty line at the end.\r\n- https://github.com/apache/spark/pull/25870/files#diff-7effa575514dd61752ece0b40fc2ad23L173\r\nAnd here, you are adding a new empty line. ðŸ˜„ .\r\n\r\nLet's remove this redundant empty line.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-28T03:10:45Z",
    "diffHunk": "@@ -131,4 +133,41 @@ object Utils extends Logging {\n         s\"under spark home test dir ${sparkHomeDir.toAbsolutePath}!\")\n     }\n   }\n+\n+  def getTestFileAbsolutePath(fileName: String, sparkHomeDir: Path): String = {\n+    val filePathsFound = Files\n+      .walk(sparkHomeDir)\n+      .filter(Files.isRegularFile(_))\n+      .filter((f: Path) => {f.toFile.getName == fileName})\n+    // we should not have more than one here under current test build dir\n+    // we only need one though\n+    val filePath = filePathsFound\n+      .iterator()\n+      .asScala\n+      .map(_.toAbsolutePath.toString)\n+      .toArray\n+      .headOption\n+    filePath match {\n+      case Some(file) => file\n+      case _ => throw new SparkException(s\"No valid $fileName file was found \" +\n+        s\"under spark home test dir ${sparkHomeDir.toAbsolutePath}!\")\n+    }\n+  }\n+\n+  def createZipFile(inFile: String, outFile: String): Unit = {\n+    try {\n+      val fileToZip = new File(inFile)\n+      val fis = new FileInputStream(fileToZip)\n+      val fos = new FileOutputStream(outFile)\n+      val zipOut = new ZipOutputStream(fos)\n+      val zipEntry = new ZipEntry(fileToZip.getName)\n+      zipOut.putNextEntry(zipEntry)\n+      IOUtils.copy(fis, zipOut)\n+      IOUtils.closeQuietly(fis)\n+      IOUtils.closeQuietly(zipOut)\n+    } catch {\n+      case e: Exception => log.error(s\"Failed to zip file: $inFile\"); throw e\n+    }\n+  }\n }\n+",
    "line": 59
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "@dongjoon-hyun did I ok :) Usually I add an `\\n` at the end as an old-school practice for sanity reasons (eg. git diffs, which might be a good reason) and some people do it: https://unix.stackexchange.com/questions/18743/whats-the-point-in-adding-a-new-line-to-the-end-of-a-file\r\nhttps://thoughtbot.com/blog/no-newline-at-end-of-file\r\nI also kept this practice from my old C++ days... but anyway sometimes I confuse myself too :)",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-11-08T20:34:40Z",
    "diffHunk": "@@ -131,4 +133,41 @@ object Utils extends Logging {\n         s\"under spark home test dir ${sparkHomeDir.toAbsolutePath}!\")\n     }\n   }\n+\n+  def getTestFileAbsolutePath(fileName: String, sparkHomeDir: Path): String = {\n+    val filePathsFound = Files\n+      .walk(sparkHomeDir)\n+      .filter(Files.isRegularFile(_))\n+      .filter((f: Path) => {f.toFile.getName == fileName})\n+    // we should not have more than one here under current test build dir\n+    // we only need one though\n+    val filePath = filePathsFound\n+      .iterator()\n+      .asScala\n+      .map(_.toAbsolutePath.toString)\n+      .toArray\n+      .headOption\n+    filePath match {\n+      case Some(file) => file\n+      case _ => throw new SparkException(s\"No valid $fileName file was found \" +\n+        s\"under spark home test dir ${sparkHomeDir.toAbsolutePath}!\")\n+    }\n+  }\n+\n+  def createZipFile(inFile: String, outFile: String): Unit = {\n+    try {\n+      val fileToZip = new File(inFile)\n+      val fis = new FileInputStream(fileToZip)\n+      val fos = new FileOutputStream(outFile)\n+      val zipOut = new ZipOutputStream(fos)\n+      val zipEntry = new ZipEntry(fileToZip.getName)\n+      zipOut.putNextEntry(zipEntry)\n+      IOUtils.copy(fis, zipOut)\n+      IOUtils.closeQuietly(fis)\n+      IOUtils.closeQuietly(zipOut)\n+    } catch {\n+      case e: Exception => log.error(s\"Failed to zip file: $inFile\"); throw e\n+    }\n+  }\n }\n+",
    "line": 59
  }],
  "prId": 25870
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Do we need to have `log.error` additionally when we re-throw the same `e`? Since the test case will fail eventually, I think we can skip the whole `try ... catch` effort.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-28T03:16:35Z",
    "diffHunk": "@@ -131,4 +133,41 @@ object Utils extends Logging {\n         s\"under spark home test dir ${sparkHomeDir.toAbsolutePath}!\")\n     }\n   }\n+\n+  def getTestFileAbsolutePath(fileName: String, sparkHomeDir: Path): String = {\n+    val filePathsFound = Files\n+      .walk(sparkHomeDir)\n+      .filter(Files.isRegularFile(_))\n+      .filter((f: Path) => {f.toFile.getName == fileName})\n+    // we should not have more than one here under current test build dir\n+    // we only need one though\n+    val filePath = filePathsFound\n+      .iterator()\n+      .asScala\n+      .map(_.toAbsolutePath.toString)\n+      .toArray\n+      .headOption\n+    filePath match {\n+      case Some(file) => file\n+      case _ => throw new SparkException(s\"No valid $fileName file was found \" +\n+        s\"under spark home test dir ${sparkHomeDir.toAbsolutePath}!\")\n+    }\n+  }\n+\n+  def createZipFile(inFile: String, outFile: String): Unit = {\n+    try {\n+      val fileToZip = new File(inFile)\n+      val fis = new FileInputStream(fileToZip)\n+      val fos = new FileOutputStream(outFile)\n+      val zipOut = new ZipOutputStream(fos)\n+      val zipEntry = new ZipEntry(fileToZip.getName)\n+      zipOut.putNextEntry(zipEntry)\n+      IOUtils.copy(fis, zipOut)\n+      IOUtils.closeQuietly(fis)\n+      IOUtils.closeQuietly(zipOut)\n+    } catch {\n+      case e: Exception => log.error(s\"Failed to zip file: $inFile\"); throw e",
    "line": 55
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "I added this so I can print the message for the failure. I can remove and see how informative the exception is.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-11-08T20:37:58Z",
    "diffHunk": "@@ -131,4 +133,41 @@ object Utils extends Logging {\n         s\"under spark home test dir ${sparkHomeDir.toAbsolutePath}!\")\n     }\n   }\n+\n+  def getTestFileAbsolutePath(fileName: String, sparkHomeDir: Path): String = {\n+    val filePathsFound = Files\n+      .walk(sparkHomeDir)\n+      .filter(Files.isRegularFile(_))\n+      .filter((f: Path) => {f.toFile.getName == fileName})\n+    // we should not have more than one here under current test build dir\n+    // we only need one though\n+    val filePath = filePathsFound\n+      .iterator()\n+      .asScala\n+      .map(_.toAbsolutePath.toString)\n+      .toArray\n+      .headOption\n+    filePath match {\n+      case Some(file) => file\n+      case _ => throw new SparkException(s\"No valid $fileName file was found \" +\n+        s\"under spark home test dir ${sparkHomeDir.toAbsolutePath}!\")\n+    }\n+  }\n+\n+  def createZipFile(inFile: String, outFile: String): Unit = {\n+    try {\n+      val fileToZip = new File(inFile)\n+      val fis = new FileInputStream(fileToZip)\n+      val fos = new FileOutputStream(outFile)\n+      val zipOut = new ZipOutputStream(fos)\n+      val zipEntry = new ZipEntry(fileToZip.getName)\n+      zipOut.putNextEntry(zipEntry)\n+      IOUtils.copy(fis, zipOut)\n+      IOUtils.closeQuietly(fis)\n+      IOUtils.closeQuietly(zipOut)\n+    } catch {\n+      case e: Exception => log.error(s\"Failed to zip file: $inFile\"); throw e",
    "line": 55
  }],
  "prId": 25870
}]