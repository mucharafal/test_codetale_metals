[{
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "instead of watching for deletion make sure we are able to create the resources if some previous resource is still being deleted. ",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-09-20T15:33:39Z",
    "diffHunk": "@@ -125,16 +125,16 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n       .endSpec()\n       .build()\n \n-    kubernetesTestComponents\n+    Eventually.eventually(TIMEOUT, INTERVAL) (kubernetesTestComponents\n       .kubernetesClient\n       .services()\n-      .create(cephService)\n+      .create(cephService))\n \n-    kubernetesTestComponents\n+    Eventually.eventually(TIMEOUT, INTERVAL) (kubernetesTestComponents",
    "line": 14
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "Maybe make that as a comment since most people won't go back to the PR to understand what is going.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-01T01:24:58Z",
    "diffHunk": "@@ -125,16 +125,16 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n       .endSpec()\n       .build()\n \n-    kubernetesTestComponents\n+    Eventually.eventually(TIMEOUT, INTERVAL) (kubernetesTestComponents\n       .kubernetesClient\n       .services()\n-      .create(cephService)\n+      .create(cephService))\n \n-    kubernetesTestComponents\n+    Eventually.eventually(TIMEOUT, INTERVAL) (kubernetesTestComponents",
    "line": 14
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "I added a comment above of each statement to clarify this.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-16T13:28:28Z",
    "diffHunk": "@@ -125,16 +125,16 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n       .endSpec()\n       .build()\n \n-    kubernetesTestComponents\n+    Eventually.eventually(TIMEOUT, INTERVAL) (kubernetesTestComponents\n       .kubernetesClient\n       .services()\n-      .create(cephService)\n+      .create(cephService))\n \n-    kubernetesTestComponents\n+    Eventually.eventually(TIMEOUT, INTERVAL) (kubernetesTestComponents",
    "line": 14
  }],
  "prId": 25870
}, {
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "I can refactor this part to have the properties set once as they are shared with the existing test. In general I think we should separate the Suites in the future to allow better setup for before and after conditions.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-09-20T22:31:10Z",
    "diffHunk": "@@ -183,6 +185,50 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n     }\n   }\n \n+  test(\"Launcher python client dependencies\", k8sTestTag, MinikubeTag) {\n+    try {\n+      setupCephStorage()\n+      val cephUrlStr = getServiceUrl(svcName)\n+      val cephUrl = new URL(cephUrlStr)\n+      val cephHost = cephUrl.getHost\n+      val cephPort = cephUrl.getPort\n+      val examplesJar = Utils.getTestFileAbsolutePath(Utils.getExamplesJarName(), sparkHomeDir)\n+\n+      val (accessKey, secretKey) = getCephCredentials()\n+      sparkAppConf\n+        .set(\"spark.kubernetes.container.image\", pyImage)\n+        .set(\"spark.kubernetes.pyspark.pythonVersion\", \"2\")\n+        .set(\"spark.hadoop.fs.s3a.access.key\", accessKey)\n+        .set(\"spark.hadoop.fs.s3a.secret.key\", secretKey)\n+        .set(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n+        .set(\"spark.hadoop.fs.s3a.endpoint\", s\"$cephHost:$cephPort\")\n+        .set(\"spark.kubernetes.file.upload.path\", s\"s3a://$bucket\")\n+        .set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n+        .set(\"spark.jars.packages\", \"com.amazonaws:aws-java-sdk:\" +\n+          \"1.7.4,org.apache.hadoop:hadoop-aws:2.7.6\")\n+        .set(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\")",
    "line": 89
  }],
  "prId": 25870
}, {
  "comments": [{
    "author": {
      "login": "holdenk"
    },
    "body": "Lets not use Python 2 since this is targeted for Spark 3 I believe.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-17T06:05:46Z",
    "diffHunk": "@@ -183,6 +187,62 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n     }\n   }\n \n+  test(\"Launcher python client dependencies using py\", k8sTestTag, MinikubeTag) {\n+    val depsFile = Utils.getTestFileAbsolutePath(\"py_container_checks.py\", sparkHomeDir)\n+    testPythonDeps(depsFile)\n+  }\n+\n+  test(\"Launcher python client dependencies using a zip file\", k8sTestTag, MinikubeTag) {\n+    val inDepsFile = Utils.getTestFileAbsolutePath(\"py_container_checks.py\", sparkHomeDir)\n+    val outDepsFile = s\"${inDepsFile.substring(0, inDepsFile.lastIndexOf(\".\"))}.zip\"\n+    Utils.createZipFile(inDepsFile, outDepsFile)\n+    testPythonDeps(outDepsFile)\n+  }\n+\n+  private def testPythonDeps(depsFile: String): Unit = {\n+    try {\n+      setupCephStorage()\n+      val cephUrlStr = getServiceUrl(svcName)\n+      val cephUrl = new URL(cephUrlStr)\n+      val cephHost = cephUrl.getHost\n+      val cephPort = cephUrl.getPort\n+      val examplesJar = Utils.getTestFileAbsolutePath(Utils.getExamplesJarName(), sparkHomeDir)\n+\n+      val (accessKey, secretKey) = getCephCredentials()\n+      sparkAppConf\n+        .set(\"spark.kubernetes.container.image\", pyImage)\n+        .set(\"spark.kubernetes.pyspark.pythonVersion\", \"2\")"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "I got used to 2 for years will miss it :) Sure will change.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-18T12:06:00Z",
    "diffHunk": "@@ -183,6 +187,62 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n     }\n   }\n \n+  test(\"Launcher python client dependencies using py\", k8sTestTag, MinikubeTag) {\n+    val depsFile = Utils.getTestFileAbsolutePath(\"py_container_checks.py\", sparkHomeDir)\n+    testPythonDeps(depsFile)\n+  }\n+\n+  test(\"Launcher python client dependencies using a zip file\", k8sTestTag, MinikubeTag) {\n+    val inDepsFile = Utils.getTestFileAbsolutePath(\"py_container_checks.py\", sparkHomeDir)\n+    val outDepsFile = s\"${inDepsFile.substring(0, inDepsFile.lastIndexOf(\".\"))}.zip\"\n+    Utils.createZipFile(inDepsFile, outDepsFile)\n+    testPythonDeps(outDepsFile)\n+  }\n+\n+  private def testPythonDeps(depsFile: String): Unit = {\n+    try {\n+      setupCephStorage()\n+      val cephUrlStr = getServiceUrl(svcName)\n+      val cephUrl = new URL(cephUrlStr)\n+      val cephHost = cephUrl.getHost\n+      val cephPort = cephUrl.getPort\n+      val examplesJar = Utils.getTestFileAbsolutePath(Utils.getExamplesJarName(), sparkHomeDir)\n+\n+      val (accessKey, secretKey) = getCephCredentials()\n+      sparkAppConf\n+        .set(\"spark.kubernetes.container.image\", pyImage)\n+        .set(\"spark.kubernetes.pyspark.pythonVersion\", \"2\")"
  }],
  "prId": 25870
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Is this relevant to this PR? If this aims to the flakiness of the existing test suite, we should make another PR before this one.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-28T02:51:21Z",
    "diffHunk": "@@ -125,16 +125,18 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n       .endSpec()\n       .build()\n \n-    kubernetesTestComponents\n+    // try until the service from a previous test is deleted\n+    Eventually.eventually(TIMEOUT, INTERVAL) (kubernetesTestComponents",
    "line": 6
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Nope this is to address waiting for the elimination of the running service from a previous test. In this suite I have two tests that use Ceph-nano and for each test I start the service from scratch so all tests start from a clean state.\r\n`Eventually` provides an easy retry mechanism until the previous service is removed and the new can succeed. If I remove `eventually` the new service may fail due to the previous one being terminated. The alternative is to block and wait for the old service to be removed when a tests finished and deletes its resources.. I found `eventually` being an easy way not to block and succeed. Check next:\r\n```\r\nTest1 {\r\nAllocate resources\r\nDelete resources // <- K8s client delete calls dont block\r\n}\r\n\r\nTest2 {\r\nAllocate resources\r\nDelete resources\r\n}\r\n```\r\nSetting ```eventually(Allocate resources)``` solves this.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-11-08T20:18:36Z",
    "diffHunk": "@@ -125,16 +125,18 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n       .endSpec()\n       .build()\n \n-    kubernetesTestComponents\n+    // try until the service from a previous test is deleted\n+    Eventually.eventually(TIMEOUT, INTERVAL) (kubernetesTestComponents",
    "line": 6
  }],
  "prId": 25870
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "ditto.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-28T02:51:57Z",
    "diffHunk": "@@ -125,16 +125,18 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n       .endSpec()\n       .build()\n \n-    kubernetesTestComponents\n+    // try until the service from a previous test is deleted\n+    Eventually.eventually(TIMEOUT, INTERVAL) (kubernetesTestComponents\n       .kubernetesClient\n       .services()\n-      .create(cephService)\n+      .create(cephService))\n \n-    kubernetesTestComponents\n+    // try until the stateful set of a previous test is deleted",
    "line": 13
  }],
  "prId": 25870
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "ditto for the above two `.withGracePeriod(0)`s.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-28T02:52:34Z",
    "diffHunk": "@@ -143,24 +145,26 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n       .apps()\n       .statefulSets()\n       .withName(cName)\n+      .withGracePeriod(0)\n       .delete()\n \n     kubernetesTestComponents\n       .kubernetesClient\n       .services()\n       .withName(svcName)\n+      .withGracePeriod(0)",
    "line": 34
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "We want to remove resources asap so grace period forces it, we dont want that?",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-11-08T20:38:27Z",
    "diffHunk": "@@ -143,24 +145,26 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n       .apps()\n       .statefulSets()\n       .withName(cName)\n+      .withGracePeriod(0)\n       .delete()\n \n     kubernetesTestComponents\n       .kubernetesClient\n       .services()\n       .withName(svcName)\n+      .withGracePeriod(0)",
    "line": 34
  }],
  "prId": 25870
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "`using py`?  I'm not sure but, maybe, you wanted `using a python file`?",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-28T02:53:51Z",
    "diffHunk": "@@ -183,6 +187,62 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n     }\n   }\n \n+  test(\"Launcher python client dependencies using py\", k8sTestTag, MinikubeTag) {",
    "line": 56
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "yes correct.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-11-08T20:20:28Z",
    "diffHunk": "@@ -183,6 +187,62 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n     }\n   }\n \n+  test(\"Launcher python client dependencies using py\", k8sTestTag, MinikubeTag) {",
    "line": 56
  }],
  "prId": 25870
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "+1 for refactor from line 203 ~ 243. We had better avoid this kind duplication.\r\nAs you suggested, please make this part as a utility function for the existing test and this new test.\r\n\r\nThe whole `try ... catch` statement should be inside the utility function. And the utility function should accept the test logic like\r\n```\r\nrunSparkRemoteCheckAndVerifyCompletion(appResource = examplesJar,\r\n        appArgs = Array(fileName),\r\n        timeout = Option(DEPS_TIMEOUT))\r\n```\r\nor\r\n```\r\nval pySparkFiles = Utils.getTestFileAbsolutePath(\"pyfiles.py\", sparkHomeDir )\r\n      val pyContainerChecks = depsFile\r\n      runSparkApplicationAndVerifyCompletion(\r\n        appResource = pySparkFiles,\r\n        mainClass = \"\",\r\n        expectedLogOnCompletion = Seq(\r\n          \"Python runtime version check is: True\",\r\n          \"Python environment version check is: True\",\r\n          \"Python runtime version check for executor is: True\"),\r\n        appArgs = Array(\"python\"),\r\n        driverPodChecker = doBasicDriverPyPodCheck,\r\n        executorPodChecker = doBasicExecutorPyPodCheck,\r\n        appLocator = appLocator,\r\n        isJVM = false,\r\n        pyFiles = Some(pyContainerChecks))\r\n```",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-10-28T03:04:22Z",
    "diffHunk": "@@ -183,6 +187,62 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n     }\n   }\n \n+  test(\"Launcher python client dependencies using py\", k8sTestTag, MinikubeTag) {\n+    val depsFile = Utils.getTestFileAbsolutePath(\"py_container_checks.py\", sparkHomeDir)\n+    testPythonDeps(depsFile)\n+  }\n+\n+  test(\"Launcher python client dependencies using a zip file\", k8sTestTag, MinikubeTag) {\n+    val inDepsFile = Utils.getTestFileAbsolutePath(\"py_container_checks.py\", sparkHomeDir)\n+    val outDepsFile = s\"${inDepsFile.substring(0, inDepsFile.lastIndexOf(\".\"))}.zip\"\n+    Utils.createZipFile(inDepsFile, outDepsFile)\n+    testPythonDeps(outDepsFile)\n+  }\n+\n+  private def testPythonDeps(depsFile: String): Unit = {\n+    try {\n+      setupCephStorage()\n+      val cephUrlStr = getServiceUrl(svcName)\n+      val cephUrl = new URL(cephUrlStr)\n+      val cephHost = cephUrl.getHost\n+      val cephPort = cephUrl.getPort\n+      val examplesJar = Utils.getTestFileAbsolutePath(Utils.getExamplesJarName(), sparkHomeDir)\n+\n+      val (accessKey, secretKey) = getCephCredentials()\n+      sparkAppConf\n+        .set(\"spark.kubernetes.container.image\", pyImage)\n+        .set(\"spark.kubernetes.pyspark.pythonVersion\", \"3\")\n+        .set(\"spark.hadoop.fs.s3a.access.key\", accessKey)\n+        .set(\"spark.hadoop.fs.s3a.secret.key\", secretKey)\n+        .set(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n+        .set(\"spark.hadoop.fs.s3a.endpoint\", s\"$cephHost:$cephPort\")\n+        .set(\"spark.kubernetes.file.upload.path\", s\"s3a://$bucket\")\n+        .set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n+        .set(\"spark.jars.packages\", \"com.amazonaws:aws-java-sdk:\" +\n+          \"1.7.4,org.apache.hadoop:hadoop-aws:2.7.6\")\n+        .set(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\")\n+      createS3Bucket(accessKey, secretKey, cephUrlStr)",
    "line": 90
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "ok.",
    "commit": "f8df2273f426a92c6742b1520d7fc480ba75c975",
    "createdAt": "2019-11-08T20:20:00Z",
    "diffHunk": "@@ -183,6 +187,62 @@ private[spark] trait DepsTestsSuite { k8sSuite: KubernetesSuite =>\n     }\n   }\n \n+  test(\"Launcher python client dependencies using py\", k8sTestTag, MinikubeTag) {\n+    val depsFile = Utils.getTestFileAbsolutePath(\"py_container_checks.py\", sparkHomeDir)\n+    testPythonDeps(depsFile)\n+  }\n+\n+  test(\"Launcher python client dependencies using a zip file\", k8sTestTag, MinikubeTag) {\n+    val inDepsFile = Utils.getTestFileAbsolutePath(\"py_container_checks.py\", sparkHomeDir)\n+    val outDepsFile = s\"${inDepsFile.substring(0, inDepsFile.lastIndexOf(\".\"))}.zip\"\n+    Utils.createZipFile(inDepsFile, outDepsFile)\n+    testPythonDeps(outDepsFile)\n+  }\n+\n+  private def testPythonDeps(depsFile: String): Unit = {\n+    try {\n+      setupCephStorage()\n+      val cephUrlStr = getServiceUrl(svcName)\n+      val cephUrl = new URL(cephUrlStr)\n+      val cephHost = cephUrl.getHost\n+      val cephPort = cephUrl.getPort\n+      val examplesJar = Utils.getTestFileAbsolutePath(Utils.getExamplesJarName(), sparkHomeDir)\n+\n+      val (accessKey, secretKey) = getCephCredentials()\n+      sparkAppConf\n+        .set(\"spark.kubernetes.container.image\", pyImage)\n+        .set(\"spark.kubernetes.pyspark.pythonVersion\", \"3\")\n+        .set(\"spark.hadoop.fs.s3a.access.key\", accessKey)\n+        .set(\"spark.hadoop.fs.s3a.secret.key\", secretKey)\n+        .set(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n+        .set(\"spark.hadoop.fs.s3a.endpoint\", s\"$cephHost:$cephPort\")\n+        .set(\"spark.kubernetes.file.upload.path\", s\"s3a://$bucket\")\n+        .set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n+        .set(\"spark.jars.packages\", \"com.amazonaws:aws-java-sdk:\" +\n+          \"1.7.4,org.apache.hadoop:hadoop-aws:2.7.6\")\n+        .set(\"spark.driver.extraJavaOptions\", \"-Divy.cache.dir=/tmp -Divy.home=/tmp\")\n+      createS3Bucket(accessKey, secretKey, cephUrlStr)",
    "line": 90
  }],
  "prId": 25870
}]