[{
  "comments": [{
    "author": {
      "login": "foxish"
    },
    "body": "I'm wondering if we should add these tests to a separate class? This file is growing in size and we can separate them out a bit for better code understanding.",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-02T20:17:52Z",
    "diffHunk": "@@ -74,10 +76,12 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n     testBackend = IntegrationTestBackendFactory.getTestBackend\n     testBackend.initialize()\n     kubernetesTestComponents = new KubernetesTestComponents(testBackend.getKubernetesClient)\n+    createTestSecret()"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "You are right probably we should. Ok let me try do this.",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-02T20:24:54Z",
    "diffHunk": "@@ -74,10 +76,12 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n     testBackend = IntegrationTestBackendFactory.getTestBackend\n     testBackend.initialize()\n     kubernetesTestComponents = new KubernetesTestComponents(testBackend.getKubernetesClient)\n+    createTestSecret()"
  }],
  "prId": 21652
}, {
  "comments": [{
    "author": {
      "login": "foxish"
    },
    "body": "nit: indentation",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-02T20:18:29Z",
    "diffHunk": "@@ -150,6 +179,28 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n       })\n   }\n \n+  test(\"Run SparkPi with env and mount secrets.\") {\n+    sparkAppConf\n+      .set(s\"spark.kubernetes.driver.secrets.$ENV_SECRET_NAME\", SECRET_MOUNT_PATH)\n+      .set(s\"spark.kubernetes.driver.secretKeyRef.USERNAME\", s\"$ENV_SECRET_NAME:username\")\n+      .set(s\"spark.kubernetes.driver.secretKeyRef.PASSWORD\", s\"$ENV_SECRET_NAME:password\")\n+      .set(s\"spark.kubernetes.executor.secrets.$ENV_SECRET_NAME\", SECRET_MOUNT_PATH)\n+      .set(s\"spark.kubernetes.executor.secretKeyRef.USERNAME\", s\"$ENV_SECRET_NAME:username\")\n+      .set(s\"spark.kubernetes.executor.secretKeyRef.PASSWORD\", s\"$ENV_SECRET_NAME:password\")\n+\n+    runSparkPiAndVerifyCompletion(\n+      driverPodChecker = (driverPod: Pod) => {\n+        doBasicDriverPodCheck(driverPod)\n+          checkSecrets(driverPod)"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "will fix.",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-02T20:24:33Z",
    "diffHunk": "@@ -150,6 +179,28 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n       })\n   }\n \n+  test(\"Run SparkPi with env and mount secrets.\") {\n+    sparkAppConf\n+      .set(s\"spark.kubernetes.driver.secrets.$ENV_SECRET_NAME\", SECRET_MOUNT_PATH)\n+      .set(s\"spark.kubernetes.driver.secretKeyRef.USERNAME\", s\"$ENV_SECRET_NAME:username\")\n+      .set(s\"spark.kubernetes.driver.secretKeyRef.PASSWORD\", s\"$ENV_SECRET_NAME:password\")\n+      .set(s\"spark.kubernetes.executor.secrets.$ENV_SECRET_NAME\", SECRET_MOUNT_PATH)\n+      .set(s\"spark.kubernetes.executor.secretKeyRef.USERNAME\", s\"$ENV_SECRET_NAME:username\")\n+      .set(s\"spark.kubernetes.executor.secretKeyRef.PASSWORD\", s\"$ENV_SECRET_NAME:password\")\n+\n+    runSparkPiAndVerifyCompletion(\n+      driverPodChecker = (driverPod: Pod) => {\n+        doBasicDriverPodCheck(driverPod)\n+          checkSecrets(driverPod)"
  }],
  "prId": 21652
}, {
  "comments": [{
    "author": {
      "login": "ssuchter"
    },
    "body": "This is a pretty quick timeout. Is there some way to have a longer timeout but to return instantly if the watch command exits? E.g. some kind of \"join\" method call on the watch instance that itself has a timeout?",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-02T20:21:05Z",
    "diffHunk": "@@ -265,6 +323,37 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n     assert(envVars(\"ENV2\") === \"VALUE2\")\n   }\n \n+  private def executeCommand(cmd: String*)(implicit podName: String): String = {\n+    val out = new ByteArrayOutputStream()\n+    val watch = kubernetesTestComponents\n+      .kubernetesClient\n+      .pods()\n+      .withName(podName)\n+      .readingInput(System.in)\n+      .writingOutput(out)\n+      .writingError(System.err)\n+      .withTTY()\n+      .exec(cmd.toArray: _*)\n+    // wait to get some result back\n+    Thread.sleep(1000)"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Ok will have a look. It does work because I guess its minikube and it is fast, I didn't see any issues. But might be a problem don't know.",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-02T20:24:26Z",
    "diffHunk": "@@ -265,6 +323,37 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n     assert(envVars(\"ENV2\") === \"VALUE2\")\n   }\n \n+  private def executeCommand(cmd: String*)(implicit podName: String): String = {\n+    val out = new ByteArrayOutputStream()\n+    val watch = kubernetesTestComponents\n+      .kubernetesClient\n+      .pods()\n+      .withName(podName)\n+      .readingInput(System.in)\n+      .writingOutput(out)\n+      .writingError(System.err)\n+      .withTTY()\n+      .exec(cmd.toArray: _*)\n+    // wait to get some result back\n+    Thread.sleep(1000)"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "@ssuchter I tried the approach here: https://github.com/fabric8io/kubernetes-client/blob/master/kubernetes-examples/src/main/java/io/fabric8/kubernetes/examples/ExecLoopExample.java\r\nand also mentioned here:\r\nhttps://github.com/fabric8io/kubernetes-client/blob/master/kubernetes-examples/src/main/java/io/fabric8/kubernetes/examples/ExecPipesExample.java#L60\r\nLatches were not useful to me. The examples there use the timeout approach (actually I recall that I looked at the examples before writing the code here).\r\nThe ideal approach would be to check continuously on the watch output on a future (eg. look what this class does: https://github.com/fabric8io/kubernetes-client/blob/9b2128ca5f2362991c99640d8a0325d60741644c/kubernetes-client/src/main/java/io/fabric8/kubernetes/client/utils/InputStreamPumper.java) and wait until it completes with some time out. But that didnt work well so far for me.\r\nSo I guess that sleep is the most easy solution.",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-04T13:57:22Z",
    "diffHunk": "@@ -265,6 +323,37 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n     assert(envVars(\"ENV2\") === \"VALUE2\")\n   }\n \n+  private def executeCommand(cmd: String*)(implicit podName: String): String = {\n+    val out = new ByteArrayOutputStream()\n+    val watch = kubernetesTestComponents\n+      .kubernetesClient\n+      .pods()\n+      .withName(podName)\n+      .readingInput(System.in)\n+      .writingOutput(out)\n+      .writingError(System.err)\n+      .withTTY()\n+      .exec(cmd.toArray: _*)\n+    // wait to get some result back\n+    Thread.sleep(1000)"
  }],
  "prId": 21652
}, {
  "comments": [{
    "author": {
      "login": "ssuchter"
    },
    "body": "Should this be done before every test, or just the one that is using the secrets?",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-02T20:23:10Z",
    "diffHunk": "@@ -74,10 +76,12 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n     testBackend = IntegrationTestBackendFactory.getTestBackend\n     testBackend.initialize()\n     kubernetesTestComponents = new KubernetesTestComponents(testBackend.getKubernetesClient)\n+    createTestSecret()"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "I guess we can add it before the specific test. My rationale was that this is something I require before the tests are run.",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-04T10:32:00Z",
    "diffHunk": "@@ -74,10 +76,12 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n     testBackend = IntegrationTestBackendFactory.getTestBackend\n     testBackend.initialize()\n     kubernetesTestComponents = new KubernetesTestComponents(testBackend.getKubernetesClient)\n+    createTestSecret()"
  }],
  "prId": 21652
}, {
  "comments": [{
    "author": {
      "login": "ssuchter"
    },
    "body": "Same question about every test versus just one of them.",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-02T20:23:24Z",
    "diffHunk": "@@ -74,10 +76,12 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n     testBackend = IntegrationTestBackendFactory.getTestBackend\n     testBackend.initialize()\n     kubernetesTestComponents = new KubernetesTestComponents(testBackend.getKubernetesClient)\n+    createTestSecret()\n   }\n \n   override def afterAll(): Unit = {\n     testBackend.cleanUp()\n+    deleteTestSecret()"
  }],
  "prId": 21652
}, {
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "@ssuchter moved the secret creation in here. I had the idea of using before and after and checking for a flag to identify the current test (scalatest with FunSuite does not give you that AFAIK) but I think this is cleaner. ",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-04T14:01:12Z",
    "diffHunk": "@@ -150,6 +177,33 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n       })\n   }\n \n+  test(\"Run SparkPi with env and mount secrets.\") {\n+    createTestSecret()\n+    sparkAppConf\n+      .set(s\"spark.kubernetes.driver.secrets.$ENV_SECRET_NAME\", SECRET_MOUNT_PATH)\n+      .set(s\"spark.kubernetes.driver.secretKeyRef.USERNAME\", s\"$ENV_SECRET_NAME:username\")\n+      .set(s\"spark.kubernetes.driver.secretKeyRef.PASSWORD\", s\"$ENV_SECRET_NAME:password\")\n+      .set(s\"spark.kubernetes.executor.secrets.$ENV_SECRET_NAME\", SECRET_MOUNT_PATH)\n+      .set(s\"spark.kubernetes.executor.secretKeyRef.USERNAME\", s\"$ENV_SECRET_NAME:username\")\n+      .set(s\"spark.kubernetes.executor.secretKeyRef.PASSWORD\", s\"$ENV_SECRET_NAME:password\")\n+    try {\n+      runSparkPiAndVerifyCompletion(\n+        driverPodChecker = (driverPod: Pod) => {\n+          doBasicDriverPodCheck(driverPod)\n+          checkSecrets(driverPod)\n+        },\n+        executorPodChecker = (executorPod: Pod) => {\n+          doBasicExecutorPodCheck(executorPod)\n+          checkSecrets(executorPod)\n+        },\n+        appArgs = Array(\"1000\") // give it enough time for all execs to be visible\n+      )\n+    } finally {"
  }],
  "prId": 21652
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Do you really need protected vs `private[k8s]` or something? I don't know enough to have much of an opinion though. The `protected` just looked a little unusual for member variables.",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-05T23:24:32Z",
    "diffHunk": "@@ -31,19 +31,18 @@ import scala.collection.JavaConverters._\n import org.apache.spark.SparkFunSuite\n import org.apache.spark.deploy.k8s.integrationtest.backend.{IntegrationTestBackend, IntegrationTestBackendFactory}\n import org.apache.spark.deploy.k8s.integrationtest.config._\n-import org.apache.spark.launcher.SparkLauncher\n \n private[spark] class KubernetesSuite extends SparkFunSuite\n-  with BeforeAndAfterAll with BeforeAndAfter {\n+  with BeforeAndAfterAll with BeforeAndAfter with BasicTestsSuite with SecretsTestsSuite {\n \n   import KubernetesSuite._\n \n   private var testBackend: IntegrationTestBackend = _\n   private var sparkHomeDir: Path = _\n-  private var kubernetesTestComponents: KubernetesTestComponents = _\n-  private var sparkAppConf: SparkAppConf = _\n+  protected var kubernetesTestComponents: KubernetesTestComponents = _"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Just want to get them available at the derived classes. What it does it just gives minimal visibility of the variables. private[k8s] gives broader access AFAIK.",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-10T14:12:58Z",
    "diffHunk": "@@ -31,19 +31,18 @@ import scala.collection.JavaConverters._\n import org.apache.spark.SparkFunSuite\n import org.apache.spark.deploy.k8s.integrationtest.backend.{IntegrationTestBackend, IntegrationTestBackendFactory}\n import org.apache.spark.deploy.k8s.integrationtest.config._\n-import org.apache.spark.launcher.SparkLauncher\n \n private[spark] class KubernetesSuite extends SparkFunSuite\n-  with BeforeAndAfterAll with BeforeAndAfter {\n+  with BeforeAndAfterAll with BeforeAndAfter with BasicTestsSuite with SecretsTestsSuite {\n \n   import KubernetesSuite._\n \n   private var testBackend: IntegrationTestBackend = _\n   private var sparkHomeDir: Path = _\n-  private var kubernetesTestComponents: KubernetesTestComponents = _\n-  private var sparkAppConf: SparkAppConf = _\n+  protected var kubernetesTestComponents: KubernetesTestComponents = _"
  }],
  "prId": 21652
}, {
  "comments": [{
    "author": {
      "login": "liyinan926"
    },
    "body": "Why you have to add this?",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-06T05:54:12Z",
    "diffHunk": "@@ -232,6 +149,13 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n     }\n \n     Eventually.eventually(TIMEOUT, INTERVAL) {\n+      val driverPod = kubernetesTestComponents.kubernetesClient"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Will double check If I saw an issue or was a left over from a refactoring.",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-10T14:43:57Z",
    "diffHunk": "@@ -232,6 +149,13 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n     }\n \n     Eventually.eventually(TIMEOUT, INTERVAL) {\n+      val driverPod = kubernetesTestComponents.kubernetesClient"
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Will remove it.",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-12T11:57:10Z",
    "diffHunk": "@@ -232,6 +149,13 @@ private[spark] class KubernetesSuite extends SparkFunSuite\n     }\n \n     Eventually.eventually(TIMEOUT, INTERVAL) {\n+      val driverPod = kubernetesTestComponents.kubernetesClient"
  }],
  "prId": 21652
}, {
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "In the future if we dont like this pattern we can just create autonomous test suits and scala test will pick them up. This is a starting point for separating tests and putting them in different files.\r\n",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-17T16:59:37Z",
    "diffHunk": "@@ -29,25 +29,27 @@ import org.scalatest.time.{Minutes, Seconds, Span}\n import scala.collection.JavaConverters._\n \n import org.apache.spark.SparkFunSuite\n+import org.apache.spark.deploy.k8s.integrationtest.TestConfig._\n import org.apache.spark.deploy.k8s.integrationtest.backend.{IntegrationTestBackend, IntegrationTestBackendFactory}\n-import org.apache.spark.deploy.k8s.integrationtest.config._\n-import org.apache.spark.launcher.SparkLauncher\n \n private[spark] class KubernetesSuite extends SparkFunSuite\n-  with BeforeAndAfterAll with BeforeAndAfter {\n+  with BeforeAndAfterAll with BeforeAndAfter with BasicTestsSuite with SecretsTestsSuite\n+  with PythonTestsSuite {",
    "line": 12
  }, {
    "author": {
      "login": "ifilonenko"
    },
    "body": "This seems a bit cumbersome but is advantageous should we add a flag in our PRB for triggering just base tests, + python, +r, and for the Kerberos integration tests (which are quite sizeable) + Kerberos. I like the decision to separate tests. I think it is appropriate. ",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-17T17:14:30Z",
    "diffHunk": "@@ -29,25 +29,27 @@ import org.scalatest.time.{Minutes, Seconds, Span}\n import scala.collection.JavaConverters._\n \n import org.apache.spark.SparkFunSuite\n+import org.apache.spark.deploy.k8s.integrationtest.TestConfig._\n import org.apache.spark.deploy.k8s.integrationtest.backend.{IntegrationTestBackend, IntegrationTestBackendFactory}\n-import org.apache.spark.deploy.k8s.integrationtest.config._\n-import org.apache.spark.launcher.SparkLauncher\n \n private[spark] class KubernetesSuite extends SparkFunSuite\n-  with BeforeAndAfterAll with BeforeAndAfter {\n+  with BeforeAndAfterAll with BeforeAndAfter with BasicTestsSuite with SecretsTestsSuite\n+  with PythonTestsSuite {",
    "line": 12
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "Where do you think we should put the flag? ",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-17T19:49:33Z",
    "diffHunk": "@@ -29,25 +29,27 @@ import org.scalatest.time.{Minutes, Seconds, Span}\n import scala.collection.JavaConverters._\n \n import org.apache.spark.SparkFunSuite\n+import org.apache.spark.deploy.k8s.integrationtest.TestConfig._\n import org.apache.spark.deploy.k8s.integrationtest.backend.{IntegrationTestBackend, IntegrationTestBackendFactory}\n-import org.apache.spark.deploy.k8s.integrationtest.config._\n-import org.apache.spark.launcher.SparkLauncher\n \n private[spark] class KubernetesSuite extends SparkFunSuite\n-  with BeforeAndAfterAll with BeforeAndAfter {\n+  with BeforeAndAfterAll with BeforeAndAfter with BasicTestsSuite with SecretsTestsSuite\n+  with PythonTestsSuite {",
    "line": 12
  }, {
    "author": {
      "login": "ifilonenko"
    },
    "body": "Probably a mvn flag i.e. —python, —r, —kerberos",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-17T21:05:47Z",
    "diffHunk": "@@ -29,25 +29,27 @@ import org.scalatest.time.{Minutes, Seconds, Span}\n import scala.collection.JavaConverters._\n \n import org.apache.spark.SparkFunSuite\n+import org.apache.spark.deploy.k8s.integrationtest.TestConfig._\n import org.apache.spark.deploy.k8s.integrationtest.backend.{IntegrationTestBackend, IntegrationTestBackendFactory}\n-import org.apache.spark.deploy.k8s.integrationtest.config._\n-import org.apache.spark.launcher.SparkLauncher\n \n private[spark] class KubernetesSuite extends SparkFunSuite\n-  with BeforeAndAfterAll with BeforeAndAfter {\n+  with BeforeAndAfterAll with BeforeAndAfter with BasicTestsSuite with SecretsTestsSuite\n+  with PythonTestsSuite {",
    "line": 12
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "I think we can do that in another PR right? ",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-18T09:05:39Z",
    "diffHunk": "@@ -29,25 +29,27 @@ import org.scalatest.time.{Minutes, Seconds, Span}\n import scala.collection.JavaConverters._\n \n import org.apache.spark.SparkFunSuite\n+import org.apache.spark.deploy.k8s.integrationtest.TestConfig._\n import org.apache.spark.deploy.k8s.integrationtest.backend.{IntegrationTestBackend, IntegrationTestBackendFactory}\n-import org.apache.spark.deploy.k8s.integrationtest.config._\n-import org.apache.spark.launcher.SparkLauncher\n \n private[spark] class KubernetesSuite extends SparkFunSuite\n-  with BeforeAndAfterAll with BeforeAndAfter {\n+  with BeforeAndAfterAll with BeforeAndAfter with BasicTestsSuite with SecretsTestsSuite\n+  with PythonTestsSuite {",
    "line": 12
  }, {
    "author": {
      "login": "ifilonenko"
    },
    "body": "SGTM",
    "commit": "67df340d943d38afd1ea4c12c02b417b5434970f",
    "createdAt": "2018-07-18T16:30:15Z",
    "diffHunk": "@@ -29,25 +29,27 @@ import org.scalatest.time.{Minutes, Seconds, Span}\n import scala.collection.JavaConverters._\n \n import org.apache.spark.SparkFunSuite\n+import org.apache.spark.deploy.k8s.integrationtest.TestConfig._\n import org.apache.spark.deploy.k8s.integrationtest.backend.{IntegrationTestBackend, IntegrationTestBackendFactory}\n-import org.apache.spark.deploy.k8s.integrationtest.config._\n-import org.apache.spark.launcher.SparkLauncher\n \n private[spark] class KubernetesSuite extends SparkFunSuite\n-  with BeforeAndAfterAll with BeforeAndAfter {\n+  with BeforeAndAfterAll with BeforeAndAfter with BasicTestsSuite with SecretsTestsSuite\n+  with PythonTestsSuite {",
    "line": 12
  }],
  "prId": 21652
}]