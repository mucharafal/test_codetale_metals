[{
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "Is this the submission client starting a server, and then the pod needs to be able to connect to the submission client host and port? An alternative is to deploy a separate pod that does this so that network communications are pod-to-pod instead of pod-to-host.",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-08T22:49:20Z",
    "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import io.fabric8.kubernetes.api.model.Service\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  private def startSocketServer(): (String, Int, ServerSocket) = {"
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "If we do it that way it's a lot easier to clear the resources and avoid trouble with sockets hanging open on the Jenkins bare metal host, for example we can just delete the whole server pod.",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-08T22:53:24Z",
    "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import io.fabric8.kubernetes.api.model.Service\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  private def startSocketServer(): (String, Int, ServerSocket) = {"
  }],
  "prId": 22639
}, {
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "Specify encoding as UTF-8.",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-08T22:50:37Z",
    "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import io.fabric8.kubernetes.api.model.Service\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  private def startSocketServer(): (String, Int, ServerSocket) = {\n+    val hostname = util.Utils.localHostName()\n+    val hostAddress: String = InetAddress.getByName(hostname).getHostAddress\n+    val serverSocket = new ServerSocket()\n+    serverSocket.bind(new InetSocketAddress(hostAddress, 0))\n+    val host = serverSocket.getInetAddress.getHostAddress\n+    val port = serverSocket.getLocalPort\n+    logInfo(s\"Started test server socket at $host:$port\")\n+    Future {\n+      while (!serverSocket.isClosed) {\n+        val socket: Socket = serverSocket.accept()\n+        logInfo(s\"Received connection on $socket\")\n+        for (i <- 1 to 10 ) {\n+          if (socket.isConnected && !serverSocket.isClosed) {\n+            socket.getOutputStream.write(\"spark-streaming-kube test.\\n\".getBytes())"
  }],
  "prId": 22639
}, {
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "Why the underscore in `_driverPodName`? If it's a name conflict, I would presume the driver pod name is available elsewhere already and we can just use the local var and not have an argument.",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-08T22:54:58Z",
    "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import io.fabric8.kubernetes.api.model.Service\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  private def startSocketServer(): (String, Int, ServerSocket) = {\n+    val hostname = util.Utils.localHostName()\n+    val hostAddress: String = InetAddress.getByName(hostname).getHostAddress\n+    val serverSocket = new ServerSocket()\n+    serverSocket.bind(new InetSocketAddress(hostAddress, 0))\n+    val host = serverSocket.getInetAddress.getHostAddress\n+    val port = serverSocket.getLocalPort\n+    logInfo(s\"Started test server socket at $host:$port\")\n+    Future {\n+      while (!serverSocket.isClosed) {\n+        val socket: Socket = serverSocket.accept()\n+        logInfo(s\"Received connection on $socket\")\n+        for (i <- 1 to 10 ) {\n+          if (socket.isConnected && !serverSocket.isClosed) {\n+            socket.getOutputStream.write(\"spark-streaming-kube test.\\n\".getBytes())\n+            socket.getOutputStream.flush()\n+            Thread.sleep(100)\n+          }\n+        }\n+        socket.close()\n+      }\n+    }\n+    (host, port, serverSocket)\n+  }\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val (driverPort: Int, blockManagerPort: Int, driverService: Service) =\n+      driverServiceSetup(driverPodName)\n+    try {\n+      val driverPod = setupSparkStreamingPod(\"client\", driverPodName)\n+        .addToArgs(\"--conf\", s\"spark.driver.host=\"\n+          + s\"${driverService.getMetadata.getName}.${kubernetesTestComponents.namespace}.svc\")\n+        .addToArgs(\"--conf\", s\"spark.driver.port=$driverPort\")\n+        .addToArgs(\"--conf\", s\"spark.driver.blockManager.port=$blockManagerPort\")\n+        .addToArgs(\"streaming.NetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog(driverPodName)\n+          .contains(\"spark-streaming-kube\"), \"The application did not complete.\")\n+      }\n+    } finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.streaming.NetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.sql.streaming.StructuredNetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val (driverPort: Int, blockManagerPort: Int, driverService: Service) =\n+      driverServiceSetup(driverPodName)\n+    try {\n+      val driverPod = setupSparkStreamingPod(\"client\", driverPodName)\n+        .addToArgs(\"--conf\",\n+          s\"spark.driver.host=\" +\n+            s\"${driverService.getMetadata.getName}.${kubernetesTestComponents.namespace}.svc\")\n+        .addToArgs(\"--conf\", s\"spark.driver.port=$driverPort\")\n+        .addToArgs(\"--conf\", s\"spark.driver.blockManager.port=$blockManagerPort\")\n+        .addToArgs(\"sql.streaming.StructuredNetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      val TIMEOUT = PatienceConfiguration.Timeout(Span(3, Minutes))\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog(driverPodName).contains(\"spark-streaming-kube\"),\n+          \"The application did not complete.\")\n+      }\n+    }\n+    finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  private def getRunLog(_driverPodName: String): String = kubernetesTestComponents.kubernetesClient"
  }],
  "prId": 22639
}, {
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "If we're creating the pod manually, the deploy mode should always be client and not cluster, so this should just be hardcoded, and the argument removed from the function signature.",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-08T22:56:05Z",
    "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import io.fabric8.kubernetes.api.model.Service\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  private def startSocketServer(): (String, Int, ServerSocket) = {\n+    val hostname = util.Utils.localHostName()\n+    val hostAddress: String = InetAddress.getByName(hostname).getHostAddress\n+    val serverSocket = new ServerSocket()\n+    serverSocket.bind(new InetSocketAddress(hostAddress, 0))\n+    val host = serverSocket.getInetAddress.getHostAddress\n+    val port = serverSocket.getLocalPort\n+    logInfo(s\"Started test server socket at $host:$port\")\n+    Future {\n+      while (!serverSocket.isClosed) {\n+        val socket: Socket = serverSocket.accept()\n+        logInfo(s\"Received connection on $socket\")\n+        for (i <- 1 to 10 ) {\n+          if (socket.isConnected && !serverSocket.isClosed) {\n+            socket.getOutputStream.write(\"spark-streaming-kube test.\\n\".getBytes())\n+            socket.getOutputStream.flush()\n+            Thread.sleep(100)\n+          }\n+        }\n+        socket.close()\n+      }\n+    }\n+    (host, port, serverSocket)\n+  }\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val (driverPort: Int, blockManagerPort: Int, driverService: Service) =\n+      driverServiceSetup(driverPodName)\n+    try {\n+      val driverPod = setupSparkStreamingPod(\"client\", driverPodName)\n+        .addToArgs(\"--conf\", s\"spark.driver.host=\"\n+          + s\"${driverService.getMetadata.getName}.${kubernetesTestComponents.namespace}.svc\")\n+        .addToArgs(\"--conf\", s\"spark.driver.port=$driverPort\")\n+        .addToArgs(\"--conf\", s\"spark.driver.blockManager.port=$blockManagerPort\")\n+        .addToArgs(\"streaming.NetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog(driverPodName)\n+          .contains(\"spark-streaming-kube\"), \"The application did not complete.\")\n+      }\n+    } finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.streaming.NetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.sql.streaming.StructuredNetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val (driverPort: Int, blockManagerPort: Int, driverService: Service) =\n+      driverServiceSetup(driverPodName)\n+    try {\n+      val driverPod = setupSparkStreamingPod(\"client\", driverPodName)\n+        .addToArgs(\"--conf\",\n+          s\"spark.driver.host=\" +\n+            s\"${driverService.getMetadata.getName}.${kubernetesTestComponents.namespace}.svc\")\n+        .addToArgs(\"--conf\", s\"spark.driver.port=$driverPort\")\n+        .addToArgs(\"--conf\", s\"spark.driver.blockManager.port=$blockManagerPort\")\n+        .addToArgs(\"sql.streaming.StructuredNetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      val TIMEOUT = PatienceConfiguration.Timeout(Span(3, Minutes))\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog(driverPodName).contains(\"spark-streaming-kube\"),\n+          \"The application did not complete.\")\n+      }\n+    }\n+    finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  private def getRunLog(_driverPodName: String): String = kubernetesTestComponents.kubernetesClient\n+    .pods()\n+    .withName(_driverPodName)\n+    .getLog\n+\n+  private def setupSparkStreamingPod(mode: String, _driverPodName: String) = {\n+    val labels = Map(\"spark-app-selector\" -> _driverPodName)\n+    testBackend\n+      .getKubernetesClient\n+      .pods()\n+      .inNamespace(kubernetesTestComponents.namespace)\n+      .createNew()\n+      .withNewMetadata()\n+      .withName(_driverPodName)\n+      .withLabels(labels.asJava)\n+      .endMetadata()\n+      .withNewSpec()\n+      .withServiceAccountName(kubernetesTestComponents.serviceAccountName)\n+      .addNewContainer()\n+      .withName(\"spark-example\")\n+      .withImage(image)\n+      .withImagePullPolicy(\"IfNotPresent\")\n+      .withCommand(\"/opt/spark/bin/run-example\")\n+      .addToArgs(\"--master\", s\"k8s://https://kubernetes.default.svc\")\n+      .addToArgs(\"--deploy-mode\", mode)"
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "Also why are we running in client mode if we're going to be deploying a pod anyways? We can deploy this in cluster mode using spark submit and then set up the service in front of the pod anyways.",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-08T22:58:00Z",
    "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import io.fabric8.kubernetes.api.model.Service\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  private def startSocketServer(): (String, Int, ServerSocket) = {\n+    val hostname = util.Utils.localHostName()\n+    val hostAddress: String = InetAddress.getByName(hostname).getHostAddress\n+    val serverSocket = new ServerSocket()\n+    serverSocket.bind(new InetSocketAddress(hostAddress, 0))\n+    val host = serverSocket.getInetAddress.getHostAddress\n+    val port = serverSocket.getLocalPort\n+    logInfo(s\"Started test server socket at $host:$port\")\n+    Future {\n+      while (!serverSocket.isClosed) {\n+        val socket: Socket = serverSocket.accept()\n+        logInfo(s\"Received connection on $socket\")\n+        for (i <- 1 to 10 ) {\n+          if (socket.isConnected && !serverSocket.isClosed) {\n+            socket.getOutputStream.write(\"spark-streaming-kube test.\\n\".getBytes())\n+            socket.getOutputStream.flush()\n+            Thread.sleep(100)\n+          }\n+        }\n+        socket.close()\n+      }\n+    }\n+    (host, port, serverSocket)\n+  }\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val (driverPort: Int, blockManagerPort: Int, driverService: Service) =\n+      driverServiceSetup(driverPodName)\n+    try {\n+      val driverPod = setupSparkStreamingPod(\"client\", driverPodName)\n+        .addToArgs(\"--conf\", s\"spark.driver.host=\"\n+          + s\"${driverService.getMetadata.getName}.${kubernetesTestComponents.namespace}.svc\")\n+        .addToArgs(\"--conf\", s\"spark.driver.port=$driverPort\")\n+        .addToArgs(\"--conf\", s\"spark.driver.blockManager.port=$blockManagerPort\")\n+        .addToArgs(\"streaming.NetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog(driverPodName)\n+          .contains(\"spark-streaming-kube\"), \"The application did not complete.\")\n+      }\n+    } finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.streaming.NetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.sql.streaming.StructuredNetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val (driverPort: Int, blockManagerPort: Int, driverService: Service) =\n+      driverServiceSetup(driverPodName)\n+    try {\n+      val driverPod = setupSparkStreamingPod(\"client\", driverPodName)\n+        .addToArgs(\"--conf\",\n+          s\"spark.driver.host=\" +\n+            s\"${driverService.getMetadata.getName}.${kubernetesTestComponents.namespace}.svc\")\n+        .addToArgs(\"--conf\", s\"spark.driver.port=$driverPort\")\n+        .addToArgs(\"--conf\", s\"spark.driver.blockManager.port=$blockManagerPort\")\n+        .addToArgs(\"sql.streaming.StructuredNetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      val TIMEOUT = PatienceConfiguration.Timeout(Span(3, Minutes))\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog(driverPodName).contains(\"spark-streaming-kube\"),\n+          \"The application did not complete.\")\n+      }\n+    }\n+    finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  private def getRunLog(_driverPodName: String): String = kubernetesTestComponents.kubernetesClient\n+    .pods()\n+    .withName(_driverPodName)\n+    .getLog\n+\n+  private def setupSparkStreamingPod(mode: String, _driverPodName: String) = {\n+    val labels = Map(\"spark-app-selector\" -> _driverPodName)\n+    testBackend\n+      .getKubernetesClient\n+      .pods()\n+      .inNamespace(kubernetesTestComponents.namespace)\n+      .createNew()\n+      .withNewMetadata()\n+      .withName(_driverPodName)\n+      .withLabels(labels.asJava)\n+      .endMetadata()\n+      .withNewSpec()\n+      .withServiceAccountName(kubernetesTestComponents.serviceAccountName)\n+      .addNewContainer()\n+      .withName(\"spark-example\")\n+      .withImage(image)\n+      .withImagePullPolicy(\"IfNotPresent\")\n+      .withCommand(\"/opt/spark/bin/run-example\")\n+      .addToArgs(\"--master\", s\"k8s://https://kubernetes.default.svc\")\n+      .addToArgs(\"--deploy-mode\", mode)"
  }],
  "prId": 22639
}, {
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "driverPort and blockManagerPort can be constants in a companion object.",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-08T22:56:59Z",
    "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import io.fabric8.kubernetes.api.model.Service\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  private def startSocketServer(): (String, Int, ServerSocket) = {\n+    val hostname = util.Utils.localHostName()\n+    val hostAddress: String = InetAddress.getByName(hostname).getHostAddress\n+    val serverSocket = new ServerSocket()\n+    serverSocket.bind(new InetSocketAddress(hostAddress, 0))\n+    val host = serverSocket.getInetAddress.getHostAddress\n+    val port = serverSocket.getLocalPort\n+    logInfo(s\"Started test server socket at $host:$port\")\n+    Future {\n+      while (!serverSocket.isClosed) {\n+        val socket: Socket = serverSocket.accept()\n+        logInfo(s\"Received connection on $socket\")\n+        for (i <- 1 to 10 ) {\n+          if (socket.isConnected && !serverSocket.isClosed) {\n+            socket.getOutputStream.write(\"spark-streaming-kube test.\\n\".getBytes())\n+            socket.getOutputStream.flush()\n+            Thread.sleep(100)\n+          }\n+        }\n+        socket.close()\n+      }\n+    }\n+    (host, port, serverSocket)\n+  }\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val (driverPort: Int, blockManagerPort: Int, driverService: Service) =\n+      driverServiceSetup(driverPodName)\n+    try {\n+      val driverPod = setupSparkStreamingPod(\"client\", driverPodName)\n+        .addToArgs(\"--conf\", s\"spark.driver.host=\"\n+          + s\"${driverService.getMetadata.getName}.${kubernetesTestComponents.namespace}.svc\")\n+        .addToArgs(\"--conf\", s\"spark.driver.port=$driverPort\")\n+        .addToArgs(\"--conf\", s\"spark.driver.blockManager.port=$blockManagerPort\")\n+        .addToArgs(\"streaming.NetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog(driverPodName)\n+          .contains(\"spark-streaming-kube\"), \"The application did not complete.\")\n+      }\n+    } finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.streaming.NetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.sql.streaming.StructuredNetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val (driverPort: Int, blockManagerPort: Int, driverService: Service) =\n+      driverServiceSetup(driverPodName)\n+    try {\n+      val driverPod = setupSparkStreamingPod(\"client\", driverPodName)\n+        .addToArgs(\"--conf\",\n+          s\"spark.driver.host=\" +\n+            s\"${driverService.getMetadata.getName}.${kubernetesTestComponents.namespace}.svc\")\n+        .addToArgs(\"--conf\", s\"spark.driver.port=$driverPort\")\n+        .addToArgs(\"--conf\", s\"spark.driver.blockManager.port=$blockManagerPort\")\n+        .addToArgs(\"sql.streaming.StructuredNetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      val TIMEOUT = PatienceConfiguration.Timeout(Span(3, Minutes))\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog(driverPodName).contains(\"spark-streaming-kube\"),\n+          \"The application did not complete.\")\n+      }\n+    }\n+    finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  private def getRunLog(_driverPodName: String): String = kubernetesTestComponents.kubernetesClient\n+    .pods()\n+    .withName(_driverPodName)\n+    .getLog\n+\n+  private def setupSparkStreamingPod(mode: String, _driverPodName: String) = {\n+    val labels = Map(\"spark-app-selector\" -> _driverPodName)\n+    testBackend\n+      .getKubernetesClient\n+      .pods()\n+      .inNamespace(kubernetesTestComponents.namespace)\n+      .createNew()\n+      .withNewMetadata()\n+      .withName(_driverPodName)\n+      .withLabels(labels.asJava)\n+      .endMetadata()\n+      .withNewSpec()\n+      .withServiceAccountName(kubernetesTestComponents.serviceAccountName)\n+      .addNewContainer()\n+      .withName(\"spark-example\")\n+      .withImage(image)\n+      .withImagePullPolicy(\"IfNotPresent\")\n+      .withCommand(\"/opt/spark/bin/run-example\")\n+      .addToArgs(\"--master\", s\"k8s://https://kubernetes.default.svc\")\n+      .addToArgs(\"--deploy-mode\", mode)\n+      .addToArgs(\"--conf\", s\"spark.kubernetes.container.image=$image\")\n+      .addToArgs(\"--conf\",\n+        s\"spark.kubernetes.namespace=${kubernetesTestComponents.namespace}\")\n+      .addToArgs(\"--conf\", \"spark.kubernetes.authenticate.oauthTokenFile=\" +\n+        \"/var/run/secrets/kubernetes.io/serviceaccount/token\")\n+      .addToArgs(\"--conf\", \"spark.kubernetes.authenticate.caCertFile=\" +\n+        \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\")\n+      .addToArgs(\"--conf\", s\"spark.kubernetes.driver.pod.name=${_driverPodName}\")\n+      .addToArgs(\"--conf\", \"spark.executor.memory=500m\")\n+      .addToArgs(\"--conf\", \"spark.executor.cores=2\")\n+      .addToArgs(\"--conf\", \"spark.executor.instances=1\")\n+\n+  }\n+\n+  private def driverServiceSetup(_driverPodName: String): (Int, Int, Service) = {\n+    val labels = Map(\"spark-app-selector\" -> _driverPodName)\n+    val driverPort = 7077"
  }],
  "prId": 22639
}, {
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "We could use a custom source as an alternative for feeding the stream. Re-using existing code is also nice.",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-11T13:40:17Z",
    "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.deploy.k8s.integrationtest.TestConstants._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  import StreamingCompatibilitySuite._\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()",
    "line": 41
  }, {
    "author": {
      "login": "ScrapCodes"
    },
    "body": "Please correct my understanding, a custom source has to either live in examples, or a separate image has to be published with the class path of the custom source. \r\n",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-15T09:58:40Z",
    "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.deploy.k8s.integrationtest.TestConstants._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  import StreamingCompatibilitySuite._\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()",
    "line": 41
  }, {
    "author": {
      "login": "skonto"
    },
    "body": "I am more inclined to add in the examples. Just an alternative option.",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2019-01-15T14:54:08Z",
    "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.deploy.k8s.integrationtest.TestConstants._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  import StreamingCompatibilitySuite._\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()",
    "line": 41
  }],
  "prId": 22639
}, {
  "comments": [{
    "author": {
      "login": "ifilonenko"
    },
    "body": "The flakiness of the tests seems to be in relation to this service account. Investigate the necessary rbac.yml that would need to be set to ensure that these failures don't come up? ",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-16T19:55:19Z",
    "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.deploy.k8s.integrationtest.TestConstants._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  import StreamingCompatibilitySuite._\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val driverService = driverServiceSetup\n+    try {\n+      setupSparkStreamingPod(driverService.getMetadata.getName)\n+        .addToArgs(\"streaming.NetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog.contains(\"spark-streaming-kube\"), \"The application did not complete.\")\n+      }\n+    } finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.streaming.NetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.sql.streaming.StructuredNetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val driverService = driverServiceSetup\n+    try {\n+      setupSparkStreamingPod(driverService.getMetadata.getName)\n+        .addToArgs(\"sql.streaming.StructuredNetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      val TIMEOUT = PatienceConfiguration.Timeout(Span(3, Minutes))\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog.contains(\"spark-streaming-kube\"),\n+          \"The application did not complete.\")\n+      }\n+    }\n+    finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  private def getRunLog: String = kubernetesTestComponents.kubernetesClient\n+    .pods()\n+    .withName(driverPodName)\n+    .getLog\n+\n+  private def setupSparkStreamingPod(driverServiceName: String) = {\n+    val labels = Map(\"spark-app-selector\" -> driverPodName)\n+    testBackend\n+      .getKubernetesClient\n+      .pods()\n+      .inNamespace(kubernetesTestComponents.namespace)\n+      .createNew()\n+      .withNewMetadata()\n+      .withName(driverPodName)\n+      .withLabels(labels.asJava)\n+      .endMetadata()\n+      .withNewSpec()\n+      .withServiceAccountName(kubernetesTestComponents.serviceAccountName)",
    "line": 133
  }, {
    "author": {
      "login": "ScrapCodes"
    },
    "body": "The same is used in \"run in client mode\" test.",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-22T04:24:29Z",
    "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.deploy.k8s.integrationtest.TestConstants._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  import StreamingCompatibilitySuite._\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val driverService = driverServiceSetup\n+    try {\n+      setupSparkStreamingPod(driverService.getMetadata.getName)\n+        .addToArgs(\"streaming.NetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog.contains(\"spark-streaming-kube\"), \"The application did not complete.\")\n+      }\n+    } finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.streaming.NetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.sql.streaming.StructuredNetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val driverService = driverServiceSetup\n+    try {\n+      setupSparkStreamingPod(driverService.getMetadata.getName)\n+        .addToArgs(\"sql.streaming.StructuredNetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      val TIMEOUT = PatienceConfiguration.Timeout(Span(3, Minutes))\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog.contains(\"spark-streaming-kube\"),\n+          \"The application did not complete.\")\n+      }\n+    }\n+    finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  private def getRunLog: String = kubernetesTestComponents.kubernetesClient\n+    .pods()\n+    .withName(driverPodName)\n+    .getLog\n+\n+  private def setupSparkStreamingPod(driverServiceName: String) = {\n+    val labels = Map(\"spark-app-selector\" -> driverPodName)\n+    testBackend\n+      .getKubernetesClient\n+      .pods()\n+      .inNamespace(kubernetesTestComponents.namespace)\n+      .createNew()\n+      .withNewMetadata()\n+      .withName(driverPodName)\n+      .withLabels(labels.asJava)\n+      .endMetadata()\n+      .withNewSpec()\n+      .withServiceAccountName(kubernetesTestComponents.serviceAccountName)",
    "line": 133
  }, {
    "author": {
      "login": "ScrapCodes"
    },
    "body": "I am not sure, what is causing it. Do you have any clue?",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-22T06:43:56Z",
    "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.deploy.k8s.integrationtest.TestConstants._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  import StreamingCompatibilitySuite._\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val driverService = driverServiceSetup\n+    try {\n+      setupSparkStreamingPod(driverService.getMetadata.getName)\n+        .addToArgs(\"streaming.NetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog.contains(\"spark-streaming-kube\"), \"The application did not complete.\")\n+      }\n+    } finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.streaming.NetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.sql.streaming.StructuredNetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val driverService = driverServiceSetup\n+    try {\n+      setupSparkStreamingPod(driverService.getMetadata.getName)\n+        .addToArgs(\"sql.streaming.StructuredNetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      val TIMEOUT = PatienceConfiguration.Timeout(Span(3, Minutes))\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog.contains(\"spark-streaming-kube\"),\n+          \"The application did not complete.\")\n+      }\n+    }\n+    finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  private def getRunLog: String = kubernetesTestComponents.kubernetesClient\n+    .pods()\n+    .withName(driverPodName)\n+    .getLog\n+\n+  private def setupSparkStreamingPod(driverServiceName: String) = {\n+    val labels = Map(\"spark-app-selector\" -> driverPodName)\n+    testBackend\n+      .getKubernetesClient\n+      .pods()\n+      .inNamespace(kubernetesTestComponents.namespace)\n+      .createNew()\n+      .withNewMetadata()\n+      .withName(driverPodName)\n+      .withLabels(labels.asJava)\n+      .endMetadata()\n+      .withNewSpec()\n+      .withServiceAccountName(kubernetesTestComponents.serviceAccountName)",
    "line": 133
  }, {
    "author": {
      "login": "ifilonenko"
    },
    "body": "I don't believe this was solved in the Client mode tests, despite the addition of the `spark-rbac.yml` I think this might require investigation outside of the scope of this PR. ",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-22T17:20:04Z",
    "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.deploy.k8s.integrationtest.TestConstants._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  import StreamingCompatibilitySuite._\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val driverService = driverServiceSetup\n+    try {\n+      setupSparkStreamingPod(driverService.getMetadata.getName)\n+        .addToArgs(\"streaming.NetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog.contains(\"spark-streaming-kube\"), \"The application did not complete.\")\n+      }\n+    } finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.streaming.NetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.sql.streaming.StructuredNetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val driverService = driverServiceSetup\n+    try {\n+      setupSparkStreamingPod(driverService.getMetadata.getName)\n+        .addToArgs(\"sql.streaming.StructuredNetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      val TIMEOUT = PatienceConfiguration.Timeout(Span(3, Minutes))\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog.contains(\"spark-streaming-kube\"),\n+          \"The application did not complete.\")\n+      }\n+    }\n+    finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  private def getRunLog: String = kubernetesTestComponents.kubernetesClient\n+    .pods()\n+    .withName(driverPodName)\n+    .getLog\n+\n+  private def setupSparkStreamingPod(driverServiceName: String) = {\n+    val labels = Map(\"spark-app-selector\" -> driverPodName)\n+    testBackend\n+      .getKubernetesClient\n+      .pods()\n+      .inNamespace(kubernetesTestComponents.namespace)\n+      .createNew()\n+      .withNewMetadata()\n+      .withName(driverPodName)\n+      .withLabels(labels.asJava)\n+      .endMetadata()\n+      .withNewSpec()\n+      .withServiceAccountName(kubernetesTestComponents.serviceAccountName)",
    "line": 133
  }, {
    "author": {
      "login": "ScrapCodes"
    },
    "body": "I have run these tests on my own setup of minikube, and I am unable to reproduce the failure that occurred on jenkins. It is possible that is related to how minikube is setup on jenkins.",
    "commit": "c63c54e393d2634efeb44743845e050991e3b1bc",
    "createdAt": "2018-10-30T08:51:55Z",
    "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.k8s.integrationtest\n+\n+import java.net._\n+\n+import scala.collection.JavaConverters._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.Future\n+\n+import org.scalatest.concurrent.{Eventually, PatienceConfiguration}\n+import org.scalatest.time.{Minutes, Span}\n+\n+import org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite._\n+import org.apache.spark.deploy.k8s.integrationtest.TestConstants._\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util\n+\n+private[spark] trait StreamingCompatibilitySuite {\n+\n+  k8sSuite: KubernetesSuite =>\n+\n+  import StreamingCompatibilitySuite._\n+\n+  test(\"Run spark streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val driverService = driverServiceSetup\n+    try {\n+      setupSparkStreamingPod(driverService.getMetadata.getName)\n+        .addToArgs(\"streaming.NetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog.contains(\"spark-streaming-kube\"), \"The application did not complete.\")\n+      }\n+    } finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.streaming.NetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in cluster mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    try {\n+      runSparkJVMCheckAndVerifyCompletion(\n+        mainClass = \"org.apache.spark.examples.sql.streaming.StructuredNetworkWordCount\",\n+        appArgs = Array[String](host, port.toString),\n+        expectedJVMValue = Seq(\"spark-streaming-kube\"))\n+    } finally {\n+      serverSocket.close()\n+    }\n+  }\n+\n+  test(\"Run spark structured streaming in client mode.\", k8sTestTag) {\n+    val (host, port, serverSocket) = startSocketServer()\n+    val driverService = driverServiceSetup\n+    try {\n+      setupSparkStreamingPod(driverService.getMetadata.getName)\n+        .addToArgs(\"sql.streaming.StructuredNetworkWordCount\")\n+        .addToArgs(host, port.toString)\n+        .endContainer()\n+        .endSpec()\n+        .done()\n+\n+      val TIMEOUT = PatienceConfiguration.Timeout(Span(3, Minutes))\n+      Eventually.eventually(TIMEOUT, INTERVAL) {\n+        assert(getRunLog.contains(\"spark-streaming-kube\"),\n+          \"The application did not complete.\")\n+      }\n+    }\n+    finally {\n+      // Have to delete the service manually since it doesn't have an owner reference\n+      kubernetesTestComponents\n+        .kubernetesClient\n+        .services()\n+        .inNamespace(kubernetesTestComponents.namespace)\n+        .delete(driverService)\n+      serverSocket.close()\n+    }\n+  }\n+\n+  private def getRunLog: String = kubernetesTestComponents.kubernetesClient\n+    .pods()\n+    .withName(driverPodName)\n+    .getLog\n+\n+  private def setupSparkStreamingPod(driverServiceName: String) = {\n+    val labels = Map(\"spark-app-selector\" -> driverPodName)\n+    testBackend\n+      .getKubernetesClient\n+      .pods()\n+      .inNamespace(kubernetesTestComponents.namespace)\n+      .createNew()\n+      .withNewMetadata()\n+      .withName(driverPodName)\n+      .withLabels(labels.asJava)\n+      .endMetadata()\n+      .withNewSpec()\n+      .withServiceAccountName(kubernetesTestComponents.serviceAccountName)",
    "line": 133
  }],
  "prId": 22639
}]