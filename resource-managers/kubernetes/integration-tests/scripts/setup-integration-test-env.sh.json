[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I think this is too strict. You should be able to build images from the build directory too.",
    "commit": "fbb54713c84f5f2fba523a8040f0b555d7b51cf7",
    "createdAt": "2019-02-12T20:30:42Z",
    "diffHunk": "@@ -58,15 +58,15 @@ while (( \"$#\" )); do\n   shift\n done\n \n-if [[ $SPARK_TGZ == \"N/A\" ]];\n+rm -rf $UNPACKED_SPARK_TGZ\n+if [[ $SPARK_TGZ == \"N/A\" && $IMAGE_TAG == \"N/A\" ]];",
    "line": 14
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "So @vanzin  is the idea that if neither a SPARK_TGZ or an IMAGE_TAG is specified we'd dynamically build the image on request? Or what do you mean?",
    "commit": "fbb54713c84f5f2fba523a8040f0b555d7b51cf7",
    "createdAt": "2019-03-07T20:14:45Z",
    "diffHunk": "@@ -58,15 +58,15 @@ while (( \"$#\" )); do\n   shift\n done\n \n-if [[ $SPARK_TGZ == \"N/A\" ]];\n+rm -rf $UNPACKED_SPARK_TGZ\n+if [[ $SPARK_TGZ == \"N/A\" && $IMAGE_TAG == \"N/A\" ]];",
    "line": 14
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "That would be my expectation.\r\n\r\nHaving to build a tgz before running the ITs slows down the process. So does manually having to build the images before running the ITs.\r\n\r\nIf invoking the ITs means \"I'll test whatever version of Spark is currently built in your build directory\", it speeds up everything.\r\n\r\n(Kinda what running the ITs through sbt does.)",
    "commit": "fbb54713c84f5f2fba523a8040f0b555d7b51cf7",
    "createdAt": "2019-03-07T20:45:53Z",
    "diffHunk": "@@ -58,15 +58,15 @@ while (( \"$#\" )); do\n   shift\n done\n \n-if [[ $SPARK_TGZ == \"N/A\" ]];\n+rm -rf $UNPACKED_SPARK_TGZ\n+if [[ $SPARK_TGZ == \"N/A\" && $IMAGE_TAG == \"N/A\" ]];",
    "line": 14
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "Sounds reasonable, I'll switch that over.",
    "commit": "fbb54713c84f5f2fba523a8040f0b555d7b51cf7",
    "createdAt": "2019-03-07T20:58:41Z",
    "diffHunk": "@@ -58,15 +58,15 @@ while (( \"$#\" )); do\n   shift\n done\n \n-if [[ $SPARK_TGZ == \"N/A\" ]];\n+rm -rf $UNPACKED_SPARK_TGZ\n+if [[ $SPARK_TGZ == \"N/A\" && $IMAGE_TAG == \"N/A\" ]];",
    "line": 14
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "We still want to special case this option I think, but it now runs successfully without an image tag or an release tgz specified. cc @vanzin ",
    "commit": "fbb54713c84f5f2fba523a8040f0b555d7b51cf7",
    "createdAt": "2019-03-07T23:24:29Z",
    "diffHunk": "@@ -58,15 +58,15 @@ while (( \"$#\" )); do\n   shift\n done\n \n-if [[ $SPARK_TGZ == \"N/A\" ]];\n+rm -rf $UNPACKED_SPARK_TGZ\n+if [[ $SPARK_TGZ == \"N/A\" && $IMAGE_TAG == \"N/A\" ]];",
    "line": 14
  }],
  "prId": 23380
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "If you want to enable `-e` I'm pretty sure you can just comment this out. The R integration tests are disabled currently because they don't work for some reason (SPARK-25152).",
    "commit": "fbb54713c84f5f2fba523a8040f0b555d7b51cf7",
    "createdAt": "2019-03-08T18:28:01Z",
    "diffHunk": "@@ -58,50 +59,59 @@ while (( \"$#\" )); do\n   shift\n done\n \n-if [[ $SPARK_TGZ == \"N/A\" ]];\n+rm -rf \"$UNPACKED_SPARK_TGZ\"\n+if [[ $SPARK_TGZ == \"N/A\" && $IMAGE_TAG == \"N/A\" ]];\n then\n-  echo \"Must specify a Spark tarball to build Docker images against with --spark-tgz.\" && exit 1;\n+  # If there is no spark image tag to test with and no src dir, build from current\n+  SCRIPT_DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" >/dev/null 2>&1 && pwd )\"\n+  SPARK_INPUT_DIR=\"$(cd \"$SCRIPT_DIR/\"../../../../  >/dev/null 2>&1 && pwd )\"\n+  DOCKER_FILE_BASE_PATH=\"$SPARK_INPUT_DIR/resource-managers/kubernetes/docker/src/main/dockerfiles/spark\"\n+elif [[ $IMAGE_TAG == \"N/A\" ]];\n+then\n+  # If there is a test src tarball and no image tag we will want to build from that\n+  mkdir -p $UNPACKED_SPARK_TGZ\n+  tar -xzvf $SPARK_TGZ --strip-components=1 -C $UNPACKED_SPARK_TGZ;\n+  SPARK_INPUT_DIR=\"$UNPACKED_SPARK_TGZ\"\n+  DOCKER_FILE_BASE_PATH=\"$SPARK_INPUT_DIR/kubernetes/dockerfiles/spark\"\n fi\n \n-rm -rf $UNPACKED_SPARK_TGZ\n-mkdir -p $UNPACKED_SPARK_TGZ\n-tar -xzvf $SPARK_TGZ --strip-components=1 -C $UNPACKED_SPARK_TGZ;\n \n+# If there is a specific Spark image skip building and extraction/copy\n if [[ $IMAGE_TAG == \"N/A\" ]];\n then\n   IMAGE_TAG=$(uuidgen);\n-  cd $UNPACKED_SPARK_TGZ\n+  cd $SPARK_INPUT_DIR\n \n   # Build PySpark image\n-  LANGUAGE_BINDING_BUILD_ARGS=\"-p $UNPACKED_SPARK_TGZ/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\"\n+  LANGUAGE_BINDING_BUILD_ARGS=\"-p $DOCKER_FILE_BASE_PATH/bindings/python/Dockerfile\"\n \n   # Build SparkR image\n-  LANGUAGE_BINDING_BUILD_ARGS=\"$LANGUAGE_BINDING_BUILD_ARGS -R $UNPACKED_SPARK_TGZ/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\"\n+  LANGUAGE_BINDING_BUILD_ARGS=\"$LANGUAGE_BINDING_BUILD_ARGS -R $DOCKER_FILE_BASE_PATH/bindings/R/Dockerfile\""
  }],
  "prId": 23380
}]