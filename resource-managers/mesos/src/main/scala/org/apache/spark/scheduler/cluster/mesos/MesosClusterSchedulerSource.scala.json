[{
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "This causes a scala style error:\r\njava.util.Date is in wrong order relative to java.util.concurrent.TimeUnit",
    "commit": "50c1c1e810fa27480ae7e72640cc8f67b44a60f1",
    "createdAt": "2018-06-12T10:23:33Z",
    "diffHunk": "@@ -17,25 +17,170 @@\n \n package org.apache.spark.scheduler.cluster.mesos\n \n-import com.codahale.metrics.{Gauge, MetricRegistry}\n+import java.util.concurrent.TimeUnit\n+import java.util.Date"
  }, {
    "author": {
      "login": "nickbp"
    },
    "body": "Reordered",
    "commit": "50c1c1e810fa27480ae7e72640cc8f67b44a60f1",
    "createdAt": "2018-07-05T19:47:42Z",
    "diffHunk": "@@ -17,25 +17,170 @@\n \n package org.apache.spark.scheduler.cluster.mesos\n \n-import com.codahale.metrics.{Gauge, MetricRegistry}\n+import java.util.concurrent.TimeUnit\n+import java.util.Date"
  }],
  "prId": 21516
}, {
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "Counter is unused import.",
    "commit": "50c1c1e810fa27480ae7e72640cc8f67b44a60f1",
    "createdAt": "2018-06-12T10:24:05Z",
    "diffHunk": "@@ -17,25 +17,170 @@\n \n package org.apache.spark.scheduler.cluster.mesos\n \n-import com.codahale.metrics.{Gauge, MetricRegistry}\n+import java.util.concurrent.TimeUnit\n+import java.util.Date\n \n+import scala.collection.mutable.HashMap\n+\n+import com.codahale.metrics.{Counter, Gauge, MetricRegistry, Timer}"
  }, {
    "author": {
      "login": "nickbp"
    },
    "body": "Removed",
    "commit": "50c1c1e810fa27480ae7e72640cc8f67b44a60f1",
    "createdAt": "2018-07-05T19:47:48Z",
    "diffHunk": "@@ -17,25 +17,170 @@\n \n package org.apache.spark.scheduler.cluster.mesos\n \n-import com.codahale.metrics.{Gauge, MetricRegistry}\n+import java.util.concurrent.TimeUnit\n+import java.util.Date\n \n+import scala.collection.mutable.HashMap\n+\n+import com.codahale.metrics.{Counter, Gauge, MetricRegistry, Timer}"
  }],
  "prId": 21516
}, {
  "comments": [{
    "author": {
      "login": "skonto"
    },
    "body": "How about desc.retryState.isEmpty()?",
    "commit": "50c1c1e810fa27480ae7e72640cc8f67b44a60f1",
    "createdAt": "2018-06-12T10:25:11Z",
    "diffHunk": "@@ -17,25 +17,170 @@\n \n package org.apache.spark.scheduler.cluster.mesos\n \n-import com.codahale.metrics.{Gauge, MetricRegistry}\n+import java.util.concurrent.TimeUnit\n+import java.util.Date\n \n+import scala.collection.mutable.HashMap\n+\n+import com.codahale.metrics.{Counter, Gauge, MetricRegistry, Timer}\n+import org.apache.mesos.Protos.{TaskState => MesosTaskState}\n+\n+import org.apache.spark.TaskState\n+import org.apache.spark.deploy.mesos.MesosDriverDescription\n import org.apache.spark.metrics.source.Source\n \n private[mesos] class MesosClusterSchedulerSource(scheduler: MesosClusterScheduler)\n-  extends Source {\n+  extends Source with MesosSchedulerUtils {\n+\n+  // Submission state transitions, to derive metrics from:\n+  // - submit():\n+  //     From: NULL\n+  //     To:   queuedDrivers\n+  // - offers/scheduleTasks():\n+  //     From: queuedDrivers and any pendingRetryDrivers scheduled for retry\n+  //     To:   launchedDrivers if success, or\n+  //           finishedDrivers(fail) if exception\n+  // - taskStatus/statusUpdate():\n+  //     From: launchedDrivers\n+  //     To:   finishedDrivers(success) if success (or fail and not eligible to retry), or\n+  //           pendingRetryDrivers if failed (and eligible to retry)\n+  // - pruning/retireDriver():\n+  //     From: finishedDrivers:\n+  //     To:   NULL\n \n   override val sourceName: String = \"mesos_cluster\"\n-  override val metricRegistry: MetricRegistry = new MetricRegistry()\n+  override val metricRegistry: MetricRegistry = new MetricRegistry\n \n-  metricRegistry.register(MetricRegistry.name(\"waitingDrivers\"), new Gauge[Int] {\n+  // PULL METRICS:\n+  // These gauge metrics are periodically polled/pulled by the metrics system\n+\n+  metricRegistry.register(MetricRegistry.name(\"driver\", \"waiting\"), new Gauge[Int] {\n     override def getValue: Int = scheduler.getQueuedDriversSize\n   })\n \n-  metricRegistry.register(MetricRegistry.name(\"launchedDrivers\"), new Gauge[Int] {\n+  metricRegistry.register(MetricRegistry.name(\"driver\", \"launched\"), new Gauge[Int] {\n     override def getValue: Int = scheduler.getLaunchedDriversSize\n   })\n \n-  metricRegistry.register(MetricRegistry.name(\"retryDrivers\"), new Gauge[Int] {\n+  metricRegistry.register(MetricRegistry.name(\"driver\", \"retry\"), new Gauge[Int] {\n     override def getValue: Int = scheduler.getPendingRetryDriversSize\n   })\n+\n+  metricRegistry.register(MetricRegistry.name(\"driver\", \"finished\"), new Gauge[Int] {\n+    override def getValue: Int = scheduler.getFinishedDriversSize\n+  })\n+\n+  // PUSH METRICS:\n+  // These metrics are updated directly as events occur\n+\n+  private val queuedCounter = metricRegistry.counter(MetricRegistry.name(\"driver\", \"waiting_count\"))\n+  private val launchedCounter =\n+    metricRegistry.counter(MetricRegistry.name(\"driver\", \"launched_count\"))\n+  private val retryCounter = metricRegistry.counter(MetricRegistry.name(\"driver\", \"retry_count\"))\n+  private val exceptionCounter =\n+    metricRegistry.counter(MetricRegistry.name(\"driver\", \"exception_count\"))\n+  private val finishedCounter =\n+    metricRegistry.counter(MetricRegistry.name(\"driver\", \"finished_count\"))\n+\n+  // Same as finishedCounter above, except grouped by MesosTaskState.\n+  private val finishedMesosStateCounters = MesosTaskState.values\n+    // Avoid registering 'finished' metrics for states that aren't considered finished:\n+    .filter(state => TaskState.isFinished(mesosToTaskState(state)))\n+    .map(state => (state, metricRegistry.counter(\n+      MetricRegistry.name(\"driver\", \"finished_count_mesos_state\", state.name.toLowerCase))))\n+    .toMap\n+  private val finishedMesosUnknownStateCounter =\n+    metricRegistry.counter(MetricRegistry.name(\"driver\", \"finished_count_mesos_state\", \"UNKNOWN\"))\n+\n+  // Duration from submission to FIRST launch.\n+  // This omits retries since those would exaggerate the time since original submission.\n+  private val submitToFirstLaunch =\n+    metricRegistry.timer(MetricRegistry.name(\"driver\", \"submit_to_first_launch\"))\n+  // Duration from initial submission to an exception.\n+  private val submitToException =\n+    metricRegistry.timer(MetricRegistry.name(\"driver\", \"submit_to_exception\"))\n+\n+  // Duration from (most recent) launch to a retry.\n+  private val launchToRetry = metricRegistry.timer(MetricRegistry.name(\"driver\", \"launch_to_retry\"))\n+\n+  // Duration from initial submission to finished.\n+  private val submitToFinish =\n+    metricRegistry.timer(MetricRegistry.name(\"driver\", \"submit_to_finish\"))\n+  // Duration from (most recent) launch to finished.\n+  private val launchToFinish =\n+    metricRegistry.timer(MetricRegistry.name(\"driver\", \"launch_to_finish\"))\n+\n+  // Same as submitToFinish and launchToFinish above, except grouped by Spark TaskState.\n+  class FinishStateTimers(state: String) {\n+    val submitToFinish =\n+      metricRegistry.timer(MetricRegistry.name(\"driver\", \"submit_to_finish_state\", state))\n+    val launchToFinish =\n+      metricRegistry.timer(MetricRegistry.name(\"driver\", \"launch_to_finish_state\", state))\n+  }\n+  private val finishSparkStateTimers = HashMap.empty[TaskState.TaskState, FinishStateTimers]\n+  for (state <- TaskState.values) {\n+    // Avoid registering 'finished' metrics for states that aren't considered finished:\n+    if (TaskState.isFinished(state)) {\n+      finishSparkStateTimers += (state -> new FinishStateTimers(state.toString.toLowerCase))\n+    }\n+  }\n+  private val submitToFinishUnknownState = metricRegistry.timer(\n+    MetricRegistry.name(\"driver\", \"submit_to_finish_state\", \"UNKNOWN\"))\n+  private val launchToFinishUnknownState = metricRegistry.timer(\n+    MetricRegistry.name(\"driver\", \"launch_to_finish_state\", \"UNKNOWN\"))\n+\n+  // Histogram of retry counts at retry scheduling\n+  private val retryCount = metricRegistry.histogram(MetricRegistry.name(\"driver\", \"retry_counts\"))\n+\n+  // Records when a submission initially enters the launch queue.\n+  def recordQueuedDriver(): Unit = queuedCounter.inc\n+\n+  // Records when a submission has failed an attempt and is eligible to be retried\n+  def recordRetryingDriver(state: MesosClusterSubmissionState): Unit = {\n+    state.driverDescription.retryState.foreach(retryState => retryCount.update(retryState.retries))\n+    recordTimeSince(state.startDate, launchToRetry)\n+    retryCounter.inc\n+  }\n+\n+  // Records when a submission is launched.\n+  def recordLaunchedDriver(desc: MesosDriverDescription): Unit = {\n+    if (!desc.retryState.isDefined) {"
  }, {
    "author": {
      "login": "nickbp"
    },
    "body": "Switched to `isEmpty`",
    "commit": "50c1c1e810fa27480ae7e72640cc8f67b44a60f1",
    "createdAt": "2018-07-05T19:49:33Z",
    "diffHunk": "@@ -17,25 +17,170 @@\n \n package org.apache.spark.scheduler.cluster.mesos\n \n-import com.codahale.metrics.{Gauge, MetricRegistry}\n+import java.util.concurrent.TimeUnit\n+import java.util.Date\n \n+import scala.collection.mutable.HashMap\n+\n+import com.codahale.metrics.{Counter, Gauge, MetricRegistry, Timer}\n+import org.apache.mesos.Protos.{TaskState => MesosTaskState}\n+\n+import org.apache.spark.TaskState\n+import org.apache.spark.deploy.mesos.MesosDriverDescription\n import org.apache.spark.metrics.source.Source\n \n private[mesos] class MesosClusterSchedulerSource(scheduler: MesosClusterScheduler)\n-  extends Source {\n+  extends Source with MesosSchedulerUtils {\n+\n+  // Submission state transitions, to derive metrics from:\n+  // - submit():\n+  //     From: NULL\n+  //     To:   queuedDrivers\n+  // - offers/scheduleTasks():\n+  //     From: queuedDrivers and any pendingRetryDrivers scheduled for retry\n+  //     To:   launchedDrivers if success, or\n+  //           finishedDrivers(fail) if exception\n+  // - taskStatus/statusUpdate():\n+  //     From: launchedDrivers\n+  //     To:   finishedDrivers(success) if success (or fail and not eligible to retry), or\n+  //           pendingRetryDrivers if failed (and eligible to retry)\n+  // - pruning/retireDriver():\n+  //     From: finishedDrivers:\n+  //     To:   NULL\n \n   override val sourceName: String = \"mesos_cluster\"\n-  override val metricRegistry: MetricRegistry = new MetricRegistry()\n+  override val metricRegistry: MetricRegistry = new MetricRegistry\n \n-  metricRegistry.register(MetricRegistry.name(\"waitingDrivers\"), new Gauge[Int] {\n+  // PULL METRICS:\n+  // These gauge metrics are periodically polled/pulled by the metrics system\n+\n+  metricRegistry.register(MetricRegistry.name(\"driver\", \"waiting\"), new Gauge[Int] {\n     override def getValue: Int = scheduler.getQueuedDriversSize\n   })\n \n-  metricRegistry.register(MetricRegistry.name(\"launchedDrivers\"), new Gauge[Int] {\n+  metricRegistry.register(MetricRegistry.name(\"driver\", \"launched\"), new Gauge[Int] {\n     override def getValue: Int = scheduler.getLaunchedDriversSize\n   })\n \n-  metricRegistry.register(MetricRegistry.name(\"retryDrivers\"), new Gauge[Int] {\n+  metricRegistry.register(MetricRegistry.name(\"driver\", \"retry\"), new Gauge[Int] {\n     override def getValue: Int = scheduler.getPendingRetryDriversSize\n   })\n+\n+  metricRegistry.register(MetricRegistry.name(\"driver\", \"finished\"), new Gauge[Int] {\n+    override def getValue: Int = scheduler.getFinishedDriversSize\n+  })\n+\n+  // PUSH METRICS:\n+  // These metrics are updated directly as events occur\n+\n+  private val queuedCounter = metricRegistry.counter(MetricRegistry.name(\"driver\", \"waiting_count\"))\n+  private val launchedCounter =\n+    metricRegistry.counter(MetricRegistry.name(\"driver\", \"launched_count\"))\n+  private val retryCounter = metricRegistry.counter(MetricRegistry.name(\"driver\", \"retry_count\"))\n+  private val exceptionCounter =\n+    metricRegistry.counter(MetricRegistry.name(\"driver\", \"exception_count\"))\n+  private val finishedCounter =\n+    metricRegistry.counter(MetricRegistry.name(\"driver\", \"finished_count\"))\n+\n+  // Same as finishedCounter above, except grouped by MesosTaskState.\n+  private val finishedMesosStateCounters = MesosTaskState.values\n+    // Avoid registering 'finished' metrics for states that aren't considered finished:\n+    .filter(state => TaskState.isFinished(mesosToTaskState(state)))\n+    .map(state => (state, metricRegistry.counter(\n+      MetricRegistry.name(\"driver\", \"finished_count_mesos_state\", state.name.toLowerCase))))\n+    .toMap\n+  private val finishedMesosUnknownStateCounter =\n+    metricRegistry.counter(MetricRegistry.name(\"driver\", \"finished_count_mesos_state\", \"UNKNOWN\"))\n+\n+  // Duration from submission to FIRST launch.\n+  // This omits retries since those would exaggerate the time since original submission.\n+  private val submitToFirstLaunch =\n+    metricRegistry.timer(MetricRegistry.name(\"driver\", \"submit_to_first_launch\"))\n+  // Duration from initial submission to an exception.\n+  private val submitToException =\n+    metricRegistry.timer(MetricRegistry.name(\"driver\", \"submit_to_exception\"))\n+\n+  // Duration from (most recent) launch to a retry.\n+  private val launchToRetry = metricRegistry.timer(MetricRegistry.name(\"driver\", \"launch_to_retry\"))\n+\n+  // Duration from initial submission to finished.\n+  private val submitToFinish =\n+    metricRegistry.timer(MetricRegistry.name(\"driver\", \"submit_to_finish\"))\n+  // Duration from (most recent) launch to finished.\n+  private val launchToFinish =\n+    metricRegistry.timer(MetricRegistry.name(\"driver\", \"launch_to_finish\"))\n+\n+  // Same as submitToFinish and launchToFinish above, except grouped by Spark TaskState.\n+  class FinishStateTimers(state: String) {\n+    val submitToFinish =\n+      metricRegistry.timer(MetricRegistry.name(\"driver\", \"submit_to_finish_state\", state))\n+    val launchToFinish =\n+      metricRegistry.timer(MetricRegistry.name(\"driver\", \"launch_to_finish_state\", state))\n+  }\n+  private val finishSparkStateTimers = HashMap.empty[TaskState.TaskState, FinishStateTimers]\n+  for (state <- TaskState.values) {\n+    // Avoid registering 'finished' metrics for states that aren't considered finished:\n+    if (TaskState.isFinished(state)) {\n+      finishSparkStateTimers += (state -> new FinishStateTimers(state.toString.toLowerCase))\n+    }\n+  }\n+  private val submitToFinishUnknownState = metricRegistry.timer(\n+    MetricRegistry.name(\"driver\", \"submit_to_finish_state\", \"UNKNOWN\"))\n+  private val launchToFinishUnknownState = metricRegistry.timer(\n+    MetricRegistry.name(\"driver\", \"launch_to_finish_state\", \"UNKNOWN\"))\n+\n+  // Histogram of retry counts at retry scheduling\n+  private val retryCount = metricRegistry.histogram(MetricRegistry.name(\"driver\", \"retry_counts\"))\n+\n+  // Records when a submission initially enters the launch queue.\n+  def recordQueuedDriver(): Unit = queuedCounter.inc\n+\n+  // Records when a submission has failed an attempt and is eligible to be retried\n+  def recordRetryingDriver(state: MesosClusterSubmissionState): Unit = {\n+    state.driverDescription.retryState.foreach(retryState => retryCount.update(retryState.retries))\n+    recordTimeSince(state.startDate, launchToRetry)\n+    retryCounter.inc\n+  }\n+\n+  // Records when a submission is launched.\n+  def recordLaunchedDriver(desc: MesosDriverDescription): Unit = {\n+    if (!desc.retryState.isDefined) {"
  }],
  "prId": 21516
}]