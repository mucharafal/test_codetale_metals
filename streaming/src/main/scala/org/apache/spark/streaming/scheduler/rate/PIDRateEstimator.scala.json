[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "@dragos @huitseeker Could you change the documentation to make it easier to understand in the context of streaming? For example, its not clear what is \"error\" in the context of streaming. So these docs needs to be expanded to explain how the processing and scheduling delay is used to estimate the rate, and how the parameters proportional and integral controls the processing. And what are recommended ranges for these parameters, and how do you control them.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-27T23:12:51Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming.\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current"
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "Currently they are not user-configurable, should we do that? I think it's too much control for most people, but on the other hand it's the only knobs we have, short of writing another rate estimator altogether.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-28T10:12:56Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming.\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Is there any reason for this synchronized? Do you think this will be called from multiple threads?\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-27T23:19:19Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming.\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error,\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors,\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+      ): Option[Double] = {\n+\n+    this.synchronized {"
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "This may be called by different threads, either due to the streaming listener bus being asynchronous, or the rate controller using a future when calling this method. Probably it's unlikely to have concurrent runs, but at least for visibility of updates we need some form of synchronization. We could remove this and make all fields `volatile`, but I'm not 100% clear if there's really no chance of running concurrently in some degenerate situation.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-28T10:19:00Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming.\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error,\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors,\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+      ): Option[Double] = {\n+\n+    this.synchronized {"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "What is the `set point`? \n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-29T21:25:37Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired setpoint. In the"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "two space on this line `)`\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-29T21:29:53Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired setpoint. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+      ): Option[Double] = {"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Please use the consistent naming. speed --> rate\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-29T21:36:47Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired setpoint. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+      ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingSpeed = elements.toDouble / processingDelay * 1000"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Could you make the names more semantically meaningful? How about: error --> changeInRate?\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-29T21:37:07Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired setpoint. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+      ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingSpeed = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingSpeed"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Why is the latestRate considered as the set point (that's my assumption since the error is calculated between the observed value and the set point, according to PID theory)? @huitseeker \n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-29T22:06:53Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired setpoint. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+      ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingSpeed = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingSpeed"
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "Since @huitseeker seems to be away, I'll answer this.\n\nThe `latestRate` is what we considered the desired value at the previous batch update. With the new information we got for the last batch interval, we compute a current rate, and compare to what we asked for, that's constitutes our error that needs correction.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-30T10:05:06Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired setpoint. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+      ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingSpeed = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingSpeed"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Its hard to understand what sumError mean in terms of the rates and all? Can you write down the physical interpretation of this sumError? And also make the name better accordingly? \ncc @huitseeker\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-29T21:38:02Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired setpoint. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+      ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingSpeed = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingSpeed\n+\n+        // in elements/second\n+        val sumError = schedulingDelay.toDouble * processingSpeed / batchIntervalMillis"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "So I am trying to understand this. \n(scheduling delay / batch interval) = approx the number of batches the system is delayed. Lets call it numDelayedBatches.\nNow you are multiplying numDelayedBatches X processingSpeed. So you are scaling the current processing rate with number of batches that are delayed. Right?\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-29T21:57:10Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired setpoint. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+      ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingSpeed = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingSpeed\n+\n+        // in elements/second\n+        val sumError = schedulingDelay.toDouble * processingSpeed / batchIntervalMillis"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "dragos"
    },
    "body": "Carrying over conversation from previous thread that got lost due to rebase\n\n> Could you make the names more semantically meaningful? How about: error --> changeInRate?\n> @tdas\n> tdas added a note 14 hours ago\n> Why is the latestRate considered as the set point (that's my assumption since the error is calculated between the observed value and the set point, according to PID theory)? @huitseeker\n> @dragos  \n> dragos added a note 2 hours ago\n> Since @huitseeker seems to be away, I'll answer this.\n> \n> The latestRate is what we considered the desired value at the previous batch update. With the new information we got for the last batch interval, we compute a current rate, and compare to what we asked for, that's constitutes our error that needs correction.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-30T11:44:16Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+    ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingRate = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingRate"
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "Here I'd prefer to keep this as `error`, as I think most people reading this code would have more troubles mapping things to PID terminology than to Spark Streaming terminology, and all PID docs will mention error and correction.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-30T11:46:51Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+    ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingRate = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingRate"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "But that is exactly the problem, people who are reading the streaming code (like me) is more like to know streaming than PID concepts, and if the code does not make it clear in terms of streaming, it is super hard to relate to. So I am fine with keep this as `error` as long as there is a explanation in terms of streaming stuff along with it. Just like what you added for historicalError.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-30T21:11:51Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+    ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingRate = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingRate"
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "I'll add the explanation.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-31T09:05:32Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+    ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingRate = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingRate"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "dragos"
    },
    "body": "Carrying over conversation from previous thread that got lost due to rebase\n\n> Its hard to understand what sumError mean in terms of the rates and all? Can you write down the physical interpretation of this sumError? And also make the name better accordingly? \n> cc @huitseeker\n> @tdas\n> tdas added a note 14 hours ago\n> So I am trying to understand this. \n> (scheduling delay / batch interval) = approx the number of batches the system is delayed. Lets call it numDelayedBatches.\n> Now you are multiplying numDelayedBatches X processingSpeed. So you are scaling the current processing rate with number of batches that are delayed. Right?\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-30T11:44:48Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+    ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingRate = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingRate\n+\n+        // in elements/second\n+        val sumError = schedulingDelay.toDouble * processingRate / batchIntervalMillis"
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "Here's the gist of it:\n- we consider `schedulingDelay` as an indication of accumulated error, which corresponds to the integral part in a PID controller. Intuitively it makes sense: the fact that there is a delay means we had too many elements in previous batches, and the system can't process them in the given batch interval\n\nThe challenge is to transform this indication from _time_ to a rate, which is the quantity that our PID is measuring (and controlling). Here's the reasoning:\n- a scheduling delay `s` corresponds to `s * processingRate` _overflowing_ elements. Those are elements that couldn't be processed in previous batches, leading to this delay. We assume the processingRate didn't change too much (since it's mostly a measure of the cluster performance, with small variations like checkpointing), but a good approximation\n-  from the number of overflowing elements we can calculate the rate at which they would be cleared by dividing it by the batch interval. This rate is our \"historical\" error, or integral part, since if we subtracted this rate from the previous \"calculated rate\", there wouldn't have been any overflowing elements, and the scheduling delay would have been zero.\n\nThere's some additional details about units of measure, since schedulingDelay and the batchInterval are in milliseconds but rates are in elements/second, but if you do the math you'll notice that the 1000s cancel out.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-30T13:26:27Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+    ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingRate = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingRate\n+\n+        // in elements/second\n+        val sumError = schedulingDelay.toDouble * processingRate / batchIntervalMillis"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Let's actually convert all the parameters to be all positive. Would be more intuitive to say that the proportional parameter can be set between 0 - 1 -- 1 = max aggressive and 0 = least aggressive\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-30T19:19:11Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "elements --> numElements\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-30T19:19:38Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,"
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "I don't really like this convention. We already have types in Scala, but fine.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-31T09:05:06Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Well the goals is to stay consistent with the surrounding codebase you are contributing to, isnt it? \nWe have made it clear that we do not always use Scala convention and rather have our own style guide that we think makes the code easier to read and understand, even by non-scala folks.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-31T09:17:28Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This is good, but there are grammatical issues. Please revise. E.g. \"from\" should be capitalized if it was to be start of a sentence.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-30T21:10:57Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+\n+  def compute(time: Long, // in milliseconds\n+      elements: Long,\n+      processingDelay: Long, // in milliseconds\n+      schedulingDelay: Long // in milliseconds\n+    ): Option[Double] = {\n+\n+    this.synchronized {\n+      if (time > latestTime && processingDelay > 0 && batchIntervalMillis > 0) {\n+\n+        // in seconds, should be close to batchDuration\n+        val delaySinceUpdate = (time - latestTime).toDouble / 1000\n+\n+        // in elements/second\n+        val processingRate = elements.toDouble / processingDelay * 1000\n+\n+        // in elements/second\n+        val error = latestRate - processingRate\n+\n+        // The error integral, based on schedulingDelay as an indicator for accumulated errors\n+        // a scheduling delay s corresponds to s * processingRate overflowing elements. Those\n+        // are elements that couldn't be processed in previous batches, leading to this delay.\n+        // We assume the processingRate didn't change too much.\n+        // from the number of overflowing elements we can calculate the rate at which they would be"
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Please define the range, along with the explanation. (assuming with make it positive) the acceptable range is 0 - 1 where 1 is most aggressive to updating the current rate, and 0 least aggressive. Also the range should be verified, for all the parameters. \n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-30T21:14:53Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1."
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "I don't think we should limit the range to [0, 1]. There is no such limit in a typical PID controller, and I'm not sure we stand much to gain. These are just constants. We could require them to be strictly positive and modify the formula, but we're departing from PID theory. Presumably that makes sense in our domain.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-31T08:52:27Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1."
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Anything more than 1 means that you are compensating more than feasible. Consider this. say there is a workload with 1 second batches where the system can process 5 records in 0.8 seconds. Say the rate limit was 10. After first batch with 5 recods in 0.8 seconds process delay (no scheduling delay), the calculation would be (assuming proportional = 1.5)\n\n```\nerror = rateLimit - numRecords/procDelay 10 - (5/0.8) = 10 - 6.25 = 3.75\nnewRate = rateLimit - 1.5 * error = 10 - 1.5 * 3.75 = 4.375 \n```\n\n4.375 is less than 5 records that the system can handle in 0.8 secs. This is wrong, that is going to happen for proportional > 1. With proportional = 1, the calculation is.\n`new rate = 10 - 1.0 * (10 - (5/0.8)) = 6.25`\nThis same as it had processed in the previous batch. Perfectly feasible.\n\nSo it does not make sense to allow parameters that obviously detrimental. \nAnd if we make the constraint too tight, we can always relax it later if the community asks for it. But not the other way round.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-31T09:15:05Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1."
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Should verify the values of the parameters. \n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-31T00:48:51Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction. A value too large would\n+ *        make the controller overshoot the setpoint, while a small value would make the\n+ *        controller too insensitive. The default value is -1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This term accelerates the movement towards the setpoint, but a large\n+ *        value may lead to overshooting. The default value is -0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This term is not used very often,\n+ *        as it impacts stability of the system. The default value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = -1D,\n+    integral: Double = -.2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(",
    "line": 55
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Did you see my earlier comment about > 1 not being practically feasible.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-31T09:48:21Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction and should be positive or zero.\n+ *        A value too large would make the controller overshoot the setpoint, while a small value\n+ *        would make the controller too insensitive. The default value is 1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This value should be positive or 0. This term accelerates the movement\n+ *        towards the desired value, but a large value may lead to overshooting. The default value\n+ *        is 0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This value should be positive or 0.\n+ *        This term is not used very often, as it impacts stability of the system. The default\n+ *        value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = 1D,\n+    integral: Double = .2D,\n+    derivative: Double = 0D)\n+  extends RateEstimator {\n+\n+  private var firstRun: Boolean = true\n+  private var latestTime: Long = -1L\n+  private var latestRate: Double = -1D\n+  private var latestError: Double = -1L\n+\n+  require(\n+    batchIntervalMillis > 0,\n+    s\"Specified batch interval $batchIntervalMillis in PIDRateEstimator is invalid.\")\n+  require(\n+    proportional >= 0,\n+    s\"Proportional term $proportional in PIDRateEstimator should be >= 0.\")",
    "line": 60
  }],
  "prId": 7648
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: I dont particularly mind, but is there any particular reason for having D at the end everywhere. Looks pretty weird.\n",
    "commit": "aa5b097e3d58f07feb830f0ff5456088064b7fff",
    "createdAt": "2015-07-31T09:54:43Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler.rate\n+\n+/**\n+ * Implements a proportional-integral-derivative (PID) controller which acts on\n+ * the speed of ingestion of elements into Spark Streaming. A PID controller works\n+ * by calculating an '''error''' between a measured output and a desired value. In the\n+ * case of Spark Streaming the error is the difference between the measured processing\n+ * rate (number of elements/processing delay) and the previous rate.\n+ *\n+ * @see https://en.wikipedia.org/wiki/PID_controller\n+ *\n+ * @param batchDurationMillis the batch duration, in milliseconds\n+ * @param proportional how much the correction should depend on the current\n+ *        error. This term usually provides the bulk of correction and should be positive or zero.\n+ *        A value too large would make the controller overshoot the setpoint, while a small value\n+ *        would make the controller too insensitive. The default value is 1.\n+ * @param integral how much the correction should depend on the accumulation\n+ *        of past errors. This value should be positive or 0. This term accelerates the movement\n+ *        towards the desired value, but a large value may lead to overshooting. The default value\n+ *        is 0.2.\n+ * @param derivative how much the correction should depend on a prediction\n+ *        of future errors, based on current rate of change. This value should be positive or 0.\n+ *        This term is not used very often, as it impacts stability of the system. The default\n+ *        value is 0.\n+ */\n+private[streaming] class PIDRateEstimator(\n+    batchIntervalMillis: Long,\n+    proportional: Double = 1D,",
    "line": 45
  }],
  "prId": 7648
}]