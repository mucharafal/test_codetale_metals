[{
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "nit: `validTime` should be in a new line.\n",
    "commit": "fd6b83e617c357949bfa44e135c0ba63e1502b29",
    "createdAt": "2015-11-26T06:43:21Z",
    "diffHunk": "@@ -132,22 +132,39 @@ class InternalTrackStateDStream[K: ClassTag, V: ClassTag, S: ClassTag, E: ClassT\n   /** Method that generates a RDD for the given time */\n   override def compute(validTime: Time): Option[RDD[TrackStateRDDRecord[K, S, E]]] = {\n     // Get the previous state or create a new empty state RDD\n-    val prevStateRDD = getOrCompute(validTime - slideDuration).getOrElse {\n-      TrackStateRDD.createFromPairRDD[K, V, S, E](\n-        spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n-        partitioner, validTime\n-      )\n+    val prevStateRDD = getOrCompute(validTime - slideDuration) match {\n+      case Some(rdd) =>\n+        if (rdd.partitioner != Some(partitioner)) {\n+          // If the RDD is not partitioned the right way, let us repartition it using the\n+          // partition index as the key. This is to ensure that state RDD is always partitioned\n+          // before creating another state RDD using it\n+          val kvRDD = rdd.mapPartitions { iter =>\n+            iter.map { x => (TaskContext.get().partitionId(), x)}\n+          }\n+          kvRDD.partitionBy(partitioner).mapPartitions(iter => iter.map { _._2 },\n+            preservesPartitioning = true)\n+        } else {\n+          rdd\n+        }\n+      case None =>\n+        TrackStateRDD.createFromPairRDD[K, V, S, E](\n+          spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n+          partitioner, validTime"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Done.\n",
    "commit": "fd6b83e617c357949bfa44e135c0ba63e1502b29",
    "createdAt": "2015-12-01T00:59:20Z",
    "diffHunk": "@@ -132,22 +132,39 @@ class InternalTrackStateDStream[K: ClassTag, V: ClassTag, S: ClassTag, E: ClassT\n   /** Method that generates a RDD for the given time */\n   override def compute(validTime: Time): Option[RDD[TrackStateRDDRecord[K, S, E]]] = {\n     // Get the previous state or create a new empty state RDD\n-    val prevStateRDD = getOrCompute(validTime - slideDuration).getOrElse {\n-      TrackStateRDD.createFromPairRDD[K, V, S, E](\n-        spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n-        partitioner, validTime\n-      )\n+    val prevStateRDD = getOrCompute(validTime - slideDuration) match {\n+      case Some(rdd) =>\n+        if (rdd.partitioner != Some(partitioner)) {\n+          // If the RDD is not partitioned the right way, let us repartition it using the\n+          // partition index as the key. This is to ensure that state RDD is always partitioned\n+          // before creating another state RDD using it\n+          val kvRDD = rdd.mapPartitions { iter =>\n+            iter.map { x => (TaskContext.get().partitionId(), x)}\n+          }\n+          kvRDD.partitionBy(partitioner).mapPartitions(iter => iter.map { _._2 },\n+            preservesPartitioning = true)\n+        } else {\n+          rdd\n+        }\n+      case None =>\n+        TrackStateRDD.createFromPairRDD[K, V, S, E](\n+          spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n+          partitioner, validTime"
  }],
  "prId": 9988
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "If the user specifies a custom `partitioner`, we cannot use `partitioner` on the `partitionId`s.\n",
    "commit": "fd6b83e617c357949bfa44e135c0ba63e1502b29",
    "createdAt": "2015-11-26T06:51:11Z",
    "diffHunk": "@@ -132,22 +132,39 @@ class InternalTrackStateDStream[K: ClassTag, V: ClassTag, S: ClassTag, E: ClassT\n   /** Method that generates a RDD for the given time */\n   override def compute(validTime: Time): Option[RDD[TrackStateRDDRecord[K, S, E]]] = {\n     // Get the previous state or create a new empty state RDD\n-    val prevStateRDD = getOrCompute(validTime - slideDuration).getOrElse {\n-      TrackStateRDD.createFromPairRDD[K, V, S, E](\n-        spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n-        partitioner, validTime\n-      )\n+    val prevStateRDD = getOrCompute(validTime - slideDuration) match {\n+      case Some(rdd) =>\n+        if (rdd.partitioner != Some(partitioner)) {\n+          // If the RDD is not partitioned the right way, let us repartition it using the\n+          // partition index as the key. This is to ensure that state RDD is always partitioned\n+          // before creating another state RDD using it\n+          val kvRDD = rdd.mapPartitions { iter =>\n+            iter.map { x => (TaskContext.get().partitionId(), x)}\n+          }\n+          kvRDD.partitionBy(partitioner).mapPartitions(iter => iter.map { _._2 },"
  }],
  "prId": 9988
}]