[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Doesnt it return a list of executors?\n",
    "commit": "137b257fabaa198706528a008394f41ca247782a",
    "createdAt": "2015-07-13T21:27:06Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.util.Random\n+\n+import org.apache.spark.streaming.scheduler.ReceiverState._\n+\n+private[streaming] case class ReceiverTrackingInfo(\n+    receiverId: Int,\n+    state: ReceiverState,\n+    scheduledLocations: Option[Seq[String]],\n+    runningLocation: Option[String])\n+\n+private[streaming] trait ReceiverScheduler {\n+\n+  /**\n+   * Return a candidate executor list to run the receiver. If the list is empty, the caller can run"
  }],
  "prId": 7276
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Can give a detailed description of algorithm that is used here. How the weights and stuff work? Its not immediately obvious from the code, so I am not sure how to verify the correctness of the algorithm.\n",
    "commit": "137b257fabaa198706528a008394f41ca247782a",
    "createdAt": "2015-07-13T22:24:50Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.util.Random\n+\n+import org.apache.spark.streaming.scheduler.ReceiverState._\n+\n+private[streaming] case class ReceiverTrackingInfo(\n+    receiverId: Int,\n+    state: ReceiverState,\n+    scheduledLocations: Option[Seq[String]],\n+    runningLocation: Option[String])\n+\n+private[streaming] trait ReceiverScheduler {\n+\n+  /**\n+   * Return a candidate executor list to run the receiver. If the list is empty, the caller can run\n+   * this receiver in arbitrary executor.\n+   */\n+  def scheduleReceiver(\n+      receiverId: Int,\n+      preferredLocation: Option[String],\n+      receiverTrackingInfoMap: Map[Int, ReceiverTrackingInfo],\n+      executors: Seq[String]): Seq[String]\n+}\n+\n+/**\n+ * A ReceiverScheduler trying to balance executors' load.\n+ */"
  }],
  "prId": 7276
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: Keep the tuple creation code consistent, either `a -> b` or `(a, b)`, in these lines.\n",
    "commit": "137b257fabaa198706528a008394f41ca247782a",
    "createdAt": "2015-07-13T22:28:33Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.util.Random\n+\n+import org.apache.spark.streaming.scheduler.ReceiverState._\n+\n+private[streaming] case class ReceiverTrackingInfo(\n+    receiverId: Int,\n+    state: ReceiverState,\n+    scheduledLocations: Option[Seq[String]],\n+    runningLocation: Option[String])\n+\n+private[streaming] trait ReceiverScheduler {\n+\n+  /**\n+   * Return a candidate executor list to run the receiver. If the list is empty, the caller can run\n+   * this receiver in arbitrary executor.\n+   */\n+  def scheduleReceiver(\n+      receiverId: Int,\n+      preferredLocation: Option[String],\n+      receiverTrackingInfoMap: Map[Int, ReceiverTrackingInfo],\n+      executors: Seq[String]): Seq[String]\n+}\n+\n+/**\n+ * A ReceiverScheduler trying to balance executors' load.\n+ */\n+private[streaming] class LoadBalanceReceiverSchedulerImpl extends ReceiverScheduler {\n+\n+  def scheduleReceiver(\n+      receiverId: Int,\n+      preferredLocation: Option[String],\n+      receiverTrackingInfoMap: Map[Int, ReceiverTrackingInfo],\n+      executors: Seq[String]): Seq[String] = {\n+    if (executors.isEmpty) {\n+      return Seq.empty\n+    }\n+\n+    // Always try to schedule to the preferred locations\n+    val locations = mutable.Set[String]()\n+    locations ++= preferredLocation\n+\n+    val executorWeights = receiverTrackingInfoMap.filter { case (id, _) =>\n+      // Ignore the receiver to be scheduled. It may be still running.\n+      id != receiverId\n+    }.values.flatMap { receiverTrackingInfo =>\n+      receiverTrackingInfo.state match {\n+        case ReceiverState.INACTIVE => Nil\n+        case ReceiverState.SCHEDULED =>\n+          val scheduledLocations = receiverTrackingInfo.scheduledLocations.get\n+          // The probability that a scheduled receiver will run in an executor is\n+          // 1.0 / scheduledLocations.size\n+          scheduledLocations.map(location => (location, 1.0 / scheduledLocations.size))"
  }],
  "prId": 7276
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Ignore this comment if this code is not performance-critical, but I wonder whether writing imperative code that updates a mutable hashmap might be more efficient here than materializing all of the values for each group. If we don't go the imperative route, maybe there's still a more efficient functional way to handle this by doing an aggregate-by-key instead of group-by followed by aggregate.  Disregard this comment if perf. isn't a factor here, though.\n",
    "commit": "137b257fabaa198706528a008394f41ca247782a",
    "createdAt": "2015-07-13T22:35:48Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.util.Random\n+\n+import org.apache.spark.streaming.scheduler.ReceiverState._\n+\n+private[streaming] case class ReceiverTrackingInfo(\n+    receiverId: Int,\n+    state: ReceiverState,\n+    scheduledLocations: Option[Seq[String]],\n+    runningLocation: Option[String])\n+\n+private[streaming] trait ReceiverScheduler {\n+\n+  /**\n+   * Return a candidate executor list to run the receiver. If the list is empty, the caller can run\n+   * this receiver in arbitrary executor.\n+   */\n+  def scheduleReceiver(\n+      receiverId: Int,\n+      preferredLocation: Option[String],\n+      receiverTrackingInfoMap: Map[Int, ReceiverTrackingInfo],\n+      executors: Seq[String]): Seq[String]\n+}\n+\n+/**\n+ * A ReceiverScheduler trying to balance executors' load.\n+ */\n+private[streaming] class LoadBalanceReceiverSchedulerImpl extends ReceiverScheduler {\n+\n+  def scheduleReceiver(\n+      receiverId: Int,\n+      preferredLocation: Option[String],\n+      receiverTrackingInfoMap: Map[Int, ReceiverTrackingInfo],\n+      executors: Seq[String]): Seq[String] = {\n+    if (executors.isEmpty) {\n+      return Seq.empty\n+    }\n+\n+    // Always try to schedule to the preferred locations\n+    val locations = mutable.Set[String]()\n+    locations ++= preferredLocation\n+\n+    val executorWeights = receiverTrackingInfoMap.filter { case (id, _) =>\n+      // Ignore the receiver to be scheduled. It may be still running.\n+      id != receiverId\n+    }.values.flatMap { receiverTrackingInfo =>\n+      receiverTrackingInfo.state match {\n+        case ReceiverState.INACTIVE => Nil\n+        case ReceiverState.SCHEDULED =>\n+          val scheduledLocations = receiverTrackingInfo.scheduledLocations.get\n+          // The probability that a scheduled receiver will run in an executor is\n+          // 1.0 / scheduledLocations.size\n+          scheduledLocations.map(location => (location, 1.0 / scheduledLocations.size))\n+        case ReceiverState.ACTIVE => Seq(receiverTrackingInfo.runningLocation.get -> 1.0)\n+      }\n+    }.groupBy(_._1).mapValues(_.map(_._2).sum) // Sum weights for each executor"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "perf really isnt a factor. The max cardinality that I can imagine for any of these is 100s.\n",
    "commit": "137b257fabaa198706528a008394f41ca247782a",
    "createdAt": "2015-07-14T00:54:09Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.util.Random\n+\n+import org.apache.spark.streaming.scheduler.ReceiverState._\n+\n+private[streaming] case class ReceiverTrackingInfo(\n+    receiverId: Int,\n+    state: ReceiverState,\n+    scheduledLocations: Option[Seq[String]],\n+    runningLocation: Option[String])\n+\n+private[streaming] trait ReceiverScheduler {\n+\n+  /**\n+   * Return a candidate executor list to run the receiver. If the list is empty, the caller can run\n+   * this receiver in arbitrary executor.\n+   */\n+  def scheduleReceiver(\n+      receiverId: Int,\n+      preferredLocation: Option[String],\n+      receiverTrackingInfoMap: Map[Int, ReceiverTrackingInfo],\n+      executors: Seq[String]): Seq[String]\n+}\n+\n+/**\n+ * A ReceiverScheduler trying to balance executors' load.\n+ */\n+private[streaming] class LoadBalanceReceiverSchedulerImpl extends ReceiverScheduler {\n+\n+  def scheduleReceiver(\n+      receiverId: Int,\n+      preferredLocation: Option[String],\n+      receiverTrackingInfoMap: Map[Int, ReceiverTrackingInfo],\n+      executors: Seq[String]): Seq[String] = {\n+    if (executors.isEmpty) {\n+      return Seq.empty\n+    }\n+\n+    // Always try to schedule to the preferred locations\n+    val locations = mutable.Set[String]()\n+    locations ++= preferredLocation\n+\n+    val executorWeights = receiverTrackingInfoMap.filter { case (id, _) =>\n+      // Ignore the receiver to be scheduled. It may be still running.\n+      id != receiverId\n+    }.values.flatMap { receiverTrackingInfo =>\n+      receiverTrackingInfo.state match {\n+        case ReceiverState.INACTIVE => Nil\n+        case ReceiverState.SCHEDULED =>\n+          val scheduledLocations = receiverTrackingInfo.scheduledLocations.get\n+          // The probability that a scheduled receiver will run in an executor is\n+          // 1.0 / scheduledLocations.size\n+          scheduledLocations.map(location => (location, 1.0 / scheduledLocations.size))\n+        case ReceiverState.ACTIVE => Seq(receiverTrackingInfo.runningLocation.get -> 1.0)\n+      }\n+    }.groupBy(_._1).mapValues(_.map(_._2).sum) // Sum weights for each executor"
  }],
  "prId": 7276
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Another high level point. Now there are three things. ReceiverTracker, ReceiverLauncher and ReceiverScheduler. Its super confusing to reason what does what. I think I am inclined change the ReceiverScheduler name to ReceiverSchedulingPolicy, so that it clear that its just a policy and not an \"active\" module at the level of ReceiverTracker and ReceiverScheduling policy. \n",
    "commit": "137b257fabaa198706528a008394f41ca247782a",
    "createdAt": "2015-07-14T21:23:42Z",
    "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.util.Random\n+\n+import org.apache.spark.streaming.scheduler.ReceiverState._\n+\n+private[streaming] case class ReceiverTrackingInfo(\n+    receiverId: Int,\n+    state: ReceiverState,\n+    scheduledLocations: Option[Seq[String]],\n+    runningLocation: Option[String])\n+\n+private[streaming] trait ReceiverScheduler {"
  }],
  "prId": 7276
}]