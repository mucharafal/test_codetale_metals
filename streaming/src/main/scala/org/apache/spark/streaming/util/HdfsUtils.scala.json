[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Minor style nit but the extra newline here looks strange.  I'd put the `this.synchronized` on this line, too.\n",
    "commit": "e4bee2065293d7373c43fe5636dd9971dede257e",
    "createdAt": "2014-10-22T05:51:33Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.util\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FSDataInputStream, FSDataOutputStream, Path}\n+\n+private[streaming] object HdfsUtils {\n+\n+  def getOutputStream(path: String, conf: Configuration): FSDataOutputStream = {\n+    // HDFS is not thread-safe when getFileSystem is called, so synchronize on that\n+\n+    val dfsPath = new Path(path)\n+    val dfs ="
  }],
  "prId": 2882
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Space after the `if`.\n",
    "commit": "e4bee2065293d7373c43fe5636dd9971dede257e",
    "createdAt": "2014-10-22T05:54:25Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.util\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FSDataInputStream, FSDataOutputStream, Path}\n+\n+private[streaming] object HdfsUtils {\n+\n+  def getOutputStream(path: String, conf: Configuration): FSDataOutputStream = {\n+    // HDFS is not thread-safe when getFileSystem is called, so synchronize on that\n+\n+    val dfsPath = new Path(path)\n+    val dfs =\n+      this.synchronized {\n+        dfsPath.getFileSystem(conf)\n+      }\n+    // If the file exists and we have append support, append instead of creating a new file\n+    val stream: FSDataOutputStream = {\n+      if (dfs.isFile(dfsPath)) {\n+        if (conf.getBoolean(\"hdfs.append.support\", false)) {\n+          dfs.append(dfsPath)\n+        } else {\n+          throw new IllegalStateException(\"File exists and there is no append support!\")\n+        }\n+      } else {\n+        dfs.create(dfsPath)\n+      }\n+    }\n+    stream\n+  }\n+\n+  def getInputStream(path: String, conf: Configuration): FSDataInputStream = {\n+    val dfsPath = new Path(path)\n+    val dfs = this.synchronized {\n+      dfsPath.getFileSystem(conf)\n+    }\n+    val instream = dfs.open(dfsPath)\n+    instream\n+  }\n+\n+  def checkState(state: Boolean, errorMsg: => String) {\n+    if(!state) {"
  }],
  "prId": 2882
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Same here; I'd move the next line onto this line.\n",
    "commit": "e4bee2065293d7373c43fe5636dd9971dede257e",
    "createdAt": "2014-10-22T05:54:41Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.util\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FSDataInputStream, FSDataOutputStream, Path}\n+\n+private[streaming] object HdfsUtils {\n+\n+  def getOutputStream(path: String, conf: Configuration): FSDataOutputStream = {\n+    // HDFS is not thread-safe when getFileSystem is called, so synchronize on that\n+\n+    val dfsPath = new Path(path)\n+    val dfs =\n+      this.synchronized {\n+        dfsPath.getFileSystem(conf)\n+      }\n+    // If the file exists and we have append support, append instead of creating a new file\n+    val stream: FSDataOutputStream = {\n+      if (dfs.isFile(dfsPath)) {\n+        if (conf.getBoolean(\"hdfs.append.support\", false)) {\n+          dfs.append(dfsPath)\n+        } else {\n+          throw new IllegalStateException(\"File exists and there is no append support!\")\n+        }\n+      } else {\n+        dfs.create(dfsPath)\n+      }\n+    }\n+    stream\n+  }\n+\n+  def getInputStream(path: String, conf: Configuration): FSDataInputStream = {\n+    val dfsPath = new Path(path)\n+    val dfs = this.synchronized {\n+      dfsPath.getFileSystem(conf)\n+    }\n+    val instream = dfs.open(dfsPath)\n+    instream\n+  }\n+\n+  def checkState(state: Boolean, errorMsg: => String) {\n+    if(!state) {\n+      throw new IllegalStateException(errorMsg)\n+    }\n+  }\n+\n+  def getBlockLocations(path: String, conf: Configuration): Option[Array[String]] = {\n+    val dfsPath = new Path(path)\n+    val dfs ="
  }],
  "prId": 2882
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "It looks like this comment is no longer relevant, or perhaps like it should be moved somewhere else?\n",
    "commit": "e4bee2065293d7373c43fe5636dd9971dede257e",
    "createdAt": "2014-10-24T00:36:53Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.util\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{LocalFileSystem, FSDataInputStream, FSDataOutputStream, Path}\n+\n+private[streaming] object HdfsUtils {\n+\n+  def getOutputStream(path: String, conf: Configuration): FSDataOutputStream = {\n+    // HDFS is not thread-safe when getFileSystem is called, so synchronize on that"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Moved.\n",
    "commit": "e4bee2065293d7373c43fe5636dd9971dede257e",
    "createdAt": "2014-10-24T00:51:47Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.util\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{LocalFileSystem, FSDataInputStream, FSDataOutputStream, Path}\n+\n+private[streaming] object HdfsUtils {\n+\n+  def getOutputStream(path: String, conf: Configuration): FSDataOutputStream = {\n+    // HDFS is not thread-safe when getFileSystem is called, so synchronize on that"
  }],
  "prId": 2882
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Based on the old comment, does this need synchronization?\n",
    "commit": "e4bee2065293d7373c43fe5636dd9971dede257e",
    "createdAt": "2014-10-24T00:37:41Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.util\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{LocalFileSystem, FSDataInputStream, FSDataOutputStream, Path}\n+\n+private[streaming] object HdfsUtils {\n+\n+  def getOutputStream(path: String, conf: Configuration): FSDataOutputStream = {\n+    // HDFS is not thread-safe when getFileSystem is called, so synchronize on that\n+    val dfsPath = new Path(path)\n+    val dfs = getFileSystemForPath(dfsPath, conf)\n+    // If the file exists and we have append support, append instead of creating a new file\n+    val stream: FSDataOutputStream = {\n+      if (dfs.isFile(dfsPath)) {\n+        if (conf.getBoolean(\"hdfs.append.support\", false)) {\n+          dfs.append(dfsPath)\n+        } else {\n+          throw new IllegalStateException(\"File exists and there is no append support!\")\n+        }\n+      } else {\n+        dfs.create(dfsPath)\n+      }\n+    }\n+    stream\n+  }\n+\n+  def getInputStream(path: String, conf: Configuration): FSDataInputStream = {\n+    val dfsPath = new Path(path)\n+    val dfs = getFileSystemForPath(dfsPath, conf)\n+    val instream = dfs.open(dfsPath)\n+    instream\n+  }\n+\n+  def checkState(state: Boolean, errorMsg: => String) {\n+    if (!state) {\n+      throw new IllegalStateException(errorMsg)\n+    }\n+  }\n+\n+  def getBlockLocations(path: String, conf: Configuration): Option[Array[String]] = {\n+    val dfsPath = new Path(path)\n+    val dfs = getFileSystemForPath(dfsPath, conf)\n+    val fileStatus = dfs.getFileStatus(dfsPath)\n+    val blockLocs = Option(dfs.getFileBlockLocations(fileStatus, 0, fileStatus.getLen))\n+    blockLocs.map(_.flatMap(_.getHosts))\n+  }\n+\n+  def getFileSystemForPath(path: Path, conf: Configuration) = synchronized {\n+    val fs = path.getFileSystem(conf)"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "@harishreedharan Can you elaborate on why `getFileSystem` is not thread-safe? References?\nAnd if it is indeed not thread-safe, then doing synchronization here does not solve the problem because other threads in spark could be access getFileSystem at the same time.\n",
    "commit": "e4bee2065293d7373c43fe5636dd9971dede257e",
    "createdAt": "2014-10-24T00:56:27Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.util\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{LocalFileSystem, FSDataInputStream, FSDataOutputStream, Path}\n+\n+private[streaming] object HdfsUtils {\n+\n+  def getOutputStream(path: String, conf: Configuration): FSDataOutputStream = {\n+    // HDFS is not thread-safe when getFileSystem is called, so synchronize on that\n+    val dfsPath = new Path(path)\n+    val dfs = getFileSystemForPath(dfsPath, conf)\n+    // If the file exists and we have append support, append instead of creating a new file\n+    val stream: FSDataOutputStream = {\n+      if (dfs.isFile(dfsPath)) {\n+        if (conf.getBoolean(\"hdfs.append.support\", false)) {\n+          dfs.append(dfsPath)\n+        } else {\n+          throw new IllegalStateException(\"File exists and there is no append support!\")\n+        }\n+      } else {\n+        dfs.create(dfsPath)\n+      }\n+    }\n+    stream\n+  }\n+\n+  def getInputStream(path: String, conf: Configuration): FSDataInputStream = {\n+    val dfsPath = new Path(path)\n+    val dfs = getFileSystemForPath(dfsPath, conf)\n+    val instream = dfs.open(dfsPath)\n+    instream\n+  }\n+\n+  def checkState(state: Boolean, errorMsg: => String) {\n+    if (!state) {\n+      throw new IllegalStateException(errorMsg)\n+    }\n+  }\n+\n+  def getBlockLocations(path: String, conf: Configuration): Option[Array[String]] = {\n+    val dfsPath = new Path(path)\n+    val dfs = getFileSystemForPath(dfsPath, conf)\n+    val fileStatus = dfs.getFileStatus(dfsPath)\n+    val blockLocs = Option(dfs.getFileBlockLocations(fileStatus, 0, fileStatus.getLen))\n+    blockLocs.map(_.flatMap(_.getHosts))\n+  }\n+\n+  def getFileSystemForPath(path: Path, conf: Configuration) = synchronized {\n+    val fs = path.getFileSystem(conf)"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "@aarondav, is this that same file system issue that you mentioned to me?\n",
    "commit": "e4bee2065293d7373c43fe5636dd9971dede257e",
    "createdAt": "2014-10-24T00:57:53Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.util\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{LocalFileSystem, FSDataInputStream, FSDataOutputStream, Path}\n+\n+private[streaming] object HdfsUtils {\n+\n+  def getOutputStream(path: String, conf: Configuration): FSDataOutputStream = {\n+    // HDFS is not thread-safe when getFileSystem is called, so synchronize on that\n+    val dfsPath = new Path(path)\n+    val dfs = getFileSystemForPath(dfsPath, conf)\n+    // If the file exists and we have append support, append instead of creating a new file\n+    val stream: FSDataOutputStream = {\n+      if (dfs.isFile(dfsPath)) {\n+        if (conf.getBoolean(\"hdfs.append.support\", false)) {\n+          dfs.append(dfsPath)\n+        } else {\n+          throw new IllegalStateException(\"File exists and there is no append support!\")\n+        }\n+      } else {\n+        dfs.create(dfsPath)\n+      }\n+    }\n+    stream\n+  }\n+\n+  def getInputStream(path: String, conf: Configuration): FSDataInputStream = {\n+    val dfsPath = new Path(path)\n+    val dfs = getFileSystemForPath(dfsPath, conf)\n+    val instream = dfs.open(dfsPath)\n+    instream\n+  }\n+\n+  def checkState(state: Boolean, errorMsg: => String) {\n+    if (!state) {\n+      throw new IllegalStateException(errorMsg)\n+    }\n+  }\n+\n+  def getBlockLocations(path: String, conf: Configuration): Option[Array[String]] = {\n+    val dfsPath = new Path(path)\n+    val dfs = getFileSystemForPath(dfsPath, conf)\n+    val fileStatus = dfs.getFileStatus(dfsPath)\n+    val blockLocs = Option(dfs.getFileBlockLocations(fileStatus, 0, fileStatus.getLen))\n+    blockLocs.map(_.flatMap(_.getHosts))\n+  }\n+\n+  def getFileSystemForPath(path: Path, conf: Configuration) = synchronized {\n+    val fs = path.getFileSystem(conf)"
  }],
  "prId": 2882
}]