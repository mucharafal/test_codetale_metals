[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "We should stick to existing naming conventions for this configuration. So for lets have `spark.streaming.driver.wal.closeFileAfterWrite` and same for `...receiver...`\n\nSo this should be a configuration like the rollingIntervalSecs\n",
    "commit": "a8dcd8750da25e740b7fbcbb12dc334255e636ca",
    "createdAt": "2015-10-27T00:12:28Z",
    "diffHunk": "@@ -39,6 +39,7 @@ private[streaming] object WriteAheadLogUtils extends Logging {\n \n   val DEFAULT_ROLLING_INTERVAL_SECS = 60\n   val DEFAULT_MAX_FAILURES = 3\n+  val WAL_CLOSE_AFTER_WRITE = \"spark.streaming.writeAheadLog.closeAfterWrite\""
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "Do receivers by default use local disk for WAL?\n",
    "commit": "a8dcd8750da25e740b7fbcbb12dc334255e636ca",
    "createdAt": "2015-10-27T00:15:39Z",
    "diffHunk": "@@ -39,6 +39,7 @@ private[streaming] object WriteAheadLogUtils extends Logging {\n \n   val DEFAULT_ROLLING_INTERVAL_SECS = 60\n   val DEFAULT_MAX_FAILURES = 3\n+  val WAL_CLOSE_AFTER_WRITE = \"spark.streaming.writeAheadLog.closeAfterWrite\""
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Wouldn't the config in that case be something like `spark.streaming.driver.writeAheadLog.closeFileAfterWrite` ? \n",
    "commit": "a8dcd8750da25e740b7fbcbb12dc334255e636ca",
    "createdAt": "2015-10-27T00:18:36Z",
    "diffHunk": "@@ -39,6 +39,7 @@ private[streaming] object WriteAheadLogUtils extends Logging {\n \n   val DEFAULT_ROLLING_INTERVAL_SECS = 60\n   val DEFAULT_MAX_FAILURES = 3\n+  val WAL_CLOSE_AFTER_WRITE = \"spark.streaming.writeAheadLog.closeAfterWrite\""
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "yeah yeah ... i shortened to make the point .. .sorry if that wasnt clear. \n@brkyvz receivers by default do not use WAL\n",
    "commit": "a8dcd8750da25e740b7fbcbb12dc334255e636ca",
    "createdAt": "2015-10-27T00:41:06Z",
    "diffHunk": "@@ -39,6 +39,7 @@ private[streaming] object WriteAheadLogUtils extends Logging {\n \n   val DEFAULT_ROLLING_INTERVAL_SECS = 60\n   val DEFAULT_MAX_FAILURES = 3\n+  val WAL_CLOSE_AFTER_WRITE = \"spark.streaming.writeAheadLog.closeAfterWrite\""
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "@tdas Noticed that this is going to be super hard. How are we going to differentiate between a receiver WAL and a driver WAL in the write method of FileBasedWAL?\n",
    "commit": "a8dcd8750da25e740b7fbcbb12dc334255e636ca",
    "createdAt": "2015-10-27T02:46:58Z",
    "diffHunk": "@@ -39,6 +39,7 @@ private[streaming] object WriteAheadLogUtils extends Logging {\n \n   val DEFAULT_ROLLING_INTERVAL_SECS = 60\n   val DEFAULT_MAX_FAILURES = 3\n+  val WAL_CLOSE_AFTER_WRITE = \"spark.streaming.writeAheadLog.closeAfterWrite\""
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "NVM, worked around it\n",
    "commit": "a8dcd8750da25e740b7fbcbb12dc334255e636ca",
    "createdAt": "2015-10-27T02:49:10Z",
    "diffHunk": "@@ -39,6 +39,7 @@ private[streaming] object WriteAheadLogUtils extends Logging {\n \n   val DEFAULT_ROLLING_INTERVAL_SECS = 60\n   val DEFAULT_MAX_FAILURES = 3\n+  val WAL_CLOSE_AFTER_WRITE = \"spark.streaming.writeAheadLog.closeAfterWrite\""
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Take a look at how rollingIntervalSecs is implemented. That also has\nseparate configurations for driver and receiver\n\nOn Mon, Oct 26, 2015 at 7:47 PM, Burak Yavuz notifications@github.com\nwrote:\n\n> In\n> streaming/src/main/scala/org/apache/spark/streaming/util/WriteAheadLogUtils.scala\n> https://github.com/apache/spark/pull/9285#discussion_r43079268:\n> \n> > @@ -39,6 +39,7 @@ private[streaming] object WriteAheadLogUtils extends Logging {\n> > \n> >    val DEFAULT_ROLLING_INTERVAL_SECS = 60\n> >    val DEFAULT_MAX_FAILURES = 3\n> > -  val WAL_CLOSE_AFTER_WRITE = \"spark.streaming.writeAheadLog.closeAfterWrite\"\n> \n> @tdas https://github.com/tdas Noticed that this is going to be super\n> hard. How are we going to differentiate between a receiver WAL and a driver\n> WAL in the write method of FileBasedWAL?\n> \n> â€”\n> Reply to this email directly or view it on GitHub\n> https://github.com/apache/spark/pull/9285/files#r43079268.\n",
    "commit": "a8dcd8750da25e740b7fbcbb12dc334255e636ca",
    "createdAt": "2015-10-27T02:50:29Z",
    "diffHunk": "@@ -39,6 +39,7 @@ private[streaming] object WriteAheadLogUtils extends Logging {\n \n   val DEFAULT_ROLLING_INTERVAL_SECS = 60\n   val DEFAULT_MAX_FAILURES = 3\n+  val WAL_CLOSE_AFTER_WRITE = \"spark.streaming.writeAheadLog.closeAfterWrite\""
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "Done\n",
    "commit": "a8dcd8750da25e740b7fbcbb12dc334255e636ca",
    "createdAt": "2015-10-27T02:55:42Z",
    "diffHunk": "@@ -39,6 +39,7 @@ private[streaming] object WriteAheadLogUtils extends Logging {\n \n   val DEFAULT_ROLLING_INTERVAL_SECS = 60\n   val DEFAULT_MAX_FAILURES = 3\n+  val WAL_CLOSE_AFTER_WRITE = \"spark.streaming.writeAheadLog.closeAfterWrite\""
  }],
  "prId": 9285
}]