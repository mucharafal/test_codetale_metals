[{
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "Usually the term `Executor` is used for something you dispatch tasks to (like the spark executor or java's thread pool executor). This seems more like a class that manages the lifecycle of a receiver... what about naming this `NetworkReceieverSupervisor`?\n\nAlso - is this made an abstract class for the purpose of testing - or do you expect to have multiple implementations of this?\n",
    "commit": "ea27b38e262bafb0f97575eb7c2d941af9a5e62f",
    "createdAt": "2014-04-17T07:04:36Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.receiver\n+\n+import java.nio.ByteBuffer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.storage.StreamBlockId\n+import java.util.concurrent.CountDownLatch\n+import scala.concurrent._\n+import ExecutionContext.Implicits.global\n+\n+/**\n+ * Abstract class that is responsible for executing a NetworkReceiver in the worker.\n+ * It provides all the necessary interfaces for handling the data received by the receiver.\n+ */\n+private[streaming] abstract class NetworkReceiverExecutor("
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "I like that name better as well. Will change. Its for the purpose of testing. Only one real implementation (other than the fake one in tests) - NetworkReceiverExecutorImpl ties the executor logic with BlockManager and NetworkInputTracker.\n",
    "commit": "ea27b38e262bafb0f97575eb7c2d941af9a5e62f",
    "createdAt": "2014-04-17T23:53:30Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.receiver\n+\n+import java.nio.ByteBuffer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.storage.StreamBlockId\n+import java.util.concurrent.CountDownLatch\n+import scala.concurrent._\n+import ExecutionContext.Implicits.global\n+\n+/**\n+ * Abstract class that is responsible for executing a NetworkReceiver in the worker.\n+ * It provides all the necessary interfaces for handling the data received by the receiver.\n+ */\n+private[streaming] abstract class NetworkReceiverExecutor("
  }],
  "prId": 300
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "of objects\n",
    "commit": "ea27b38e262bafb0f97575eb7c2d941af9a5e62f",
    "createdAt": "2014-04-17T07:12:28Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.receiver\n+\n+import java.nio.ByteBuffer\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.storage.StreamBlockId\n+import java.util.concurrent.CountDownLatch\n+import scala.concurrent._\n+import ExecutionContext.Implicits.global\n+\n+/**\n+ * Abstract class that is responsible for executing a NetworkReceiver in the worker.\n+ * It provides all the necessary interfaces for handling the data received by the receiver.\n+ */\n+private[streaming] abstract class NetworkReceiverExecutor(\n+    receiver: NetworkReceiver[_],\n+    conf: SparkConf\n+  ) extends Logging {\n+\n+\n+  /** Enumeration to identify current state of the StreamingContext */\n+  object NetworkReceiverState extends Enumeration {\n+    type CheckpointState = Value\n+    val Initialized, Started, Stopped = Value\n+  }\n+  import NetworkReceiverState._\n+\n+  // Attach the executor to the receiver\n+  receiver.attachExecutor(this)\n+\n+  /** Receiver id */\n+  protected val receiverId = receiver.receiverId\n+\n+  /** Message associated with the stopping of the receiver */\n+  protected var stopMessage = \"\"\n+\n+  /** Exception associated with the stopping of the receiver */\n+  protected var stopException: Throwable = null\n+\n+  /** Has the receiver been marked for stop. */\n+  private val stopLatch = new CountDownLatch(1)\n+\n+  /** Time between a receiver is stopped */\n+  private val restartDelay = conf.getInt(\"spark.streaming.receiverRestartDelay\", 2000)\n+\n+  /** State of the receiver */\n+  private[streaming] var receiverState = Initialized\n+\n+  /** Push a single data item to backend data store. */\n+  def pushSingle(data: Any)\n+\n+  /** Push a byte buffer to backend data store. */\n+  def pushBytes(\n+      bytes: ByteBuffer,\n+      optionalMetadata: Option[Any],\n+      optionalBlockId: Option[StreamBlockId]\n+    )\n+\n+  /** Push an iterator of objects as a block to backend data store. */\n+  def pushIterator(\n+      iterator: Iterator[_],\n+      optionalMetadata: Option[Any],\n+      optionalBlockId: Option[StreamBlockId]\n+    )\n+\n+  /** Push an ArrayBuffer of object as a block to back data store. */"
  }],
  "prId": 300
}]