[{
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "could this be called `EmittedStateDStream`? I don't think the term \"Record\" has clear semantics here - why introduce a new term? It might be good to tie it back to the terms already defined (i.e. State).\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-05T06:43:12Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+\n+abstract class EmittedRecordsDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag]("
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Very valid concern, that what I needed feedback on. But \"EmittedState\" implies state is emitted.... which is wrong. How about simply `EmittedDStream`?\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-05T06:47:09Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+\n+abstract class EmittedRecordsDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag]("
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "I see - i guess it depends what you define as state. I think of `S` as \"stored state\" and `T` as \"emitted state\". Maybe that's off? I think `EmittedDStream` could be okay, it's a bit awkward but I think still better than adding a new term.\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-05T07:06:28Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+\n+abstract class EmittedRecordsDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag]("
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "What exactly does this do? EmittedDStream seems unclear.\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-05T18:02:18Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+\n+abstract class EmittedRecordsDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag]("
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "This is the stream of records T generated after apply the function `(K, Option[V], State[S]) => Option[T]`\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-06T01:56:25Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+\n+abstract class EmittedRecordsDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag]("
  }],
  "prId": 9256
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "snapshotStream?\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-05T19:16:10Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+\n+abstract class EmittedRecordsDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    ssc: StreamingContext) extends DStream[T](ssc) {\n+\n+  def stateSnapshots(): DStream[(K, S)]"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "snapshots of what?\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-06T01:55:27Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+\n+abstract class EmittedRecordsDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    ssc: StreamingContext) extends DStream[T](ssc) {\n+\n+  def stateSnapshots(): DStream[(K, S)]"
  }],
  "prId": 9256
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "`parent.getOrCompute(validTime)` could return `None`\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-06T00:47:11Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+\n+abstract class EmittedRecordsDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    ssc: StreamingContext) extends DStream[T](ssc) {\n+\n+  def stateSnapshots(): DStream[(K, S)]\n+}\n+\n+\n+private[streaming] class EmittedRecordsDStreamImpl[\n+    K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    trackStateDStream: TrackStateDStream[K, V, S, T])\n+  extends EmittedRecordsDStream[K, V, S, T](trackStateDStream.context) {\n+\n+  override def slideDuration: Duration = trackStateDStream.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(trackStateDStream)\n+\n+  override def compute(validTime: Time): Option[RDD[T]] = {\n+    trackStateDStream.getOrCompute(validTime).map { _.flatMap[T] { _.emittedRecords } }\n+  }\n+\n+  def stateSnapshots(): DStream[(K, S)] = {\n+    trackStateDStream.flatMap[(K, S)] {\n+      _.stateMap.getAll().map { case (k, s, _) => (k, s) }.toTraversable }\n+  }\n+}\n+\n+/**\n+ * A DStream that allows per-key state to be maintains, and arbitrary records to be generated\n+ * based on updates to the state.\n+ *\n+ * @param parent Parent (key, value) stream that is the source\n+ * @param spec Specifications of the trackStateByKey operation\n+ * @tparam K   Key type\n+ * @tparam V   Value type\n+ * @tparam S   Type of the state maintained\n+ * @tparam T   Type of the eiitted records\n+ */\n+private[streaming] class TrackStateDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    parent: DStream[(K, V)], spec: TrackStateSpecImpl[K, V, S, T])\n+  extends DStream[TrackStateRDDRecord[K, S, T]](parent.context) {\n+\n+  persist(StorageLevel.MEMORY_ONLY)\n+\n+  private val partitioner = spec.getPartitioner().getOrElse(\n+    new HashPartitioner(ssc.sc.defaultParallelism))\n+\n+  private val trackingFunction = spec.getFunction()\n+\n+  override def slideDuration: Duration = parent.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(parent)\n+\n+  override val mustCheckpoint = true\n+\n+  /** Method that generates a RDD for the given time */\n+  override def compute(validTime: Time): Option[RDD[TrackStateRDDRecord[K, S, T]]] = {\n+    val prevStateRDD = getOrCompute(validTime - slideDuration).getOrElse {\n+      TrackStateRDD.createFromPairRDD[K, V, S, T](\n+        spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n+        partitioner,\n+        validTime.milliseconds\n+      )\n+    }\n+    val newDataRDD = parent.getOrCompute(validTime).get"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "In practice it really cannot, but yeah its better to account for None's\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-06T01:57:18Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+\n+abstract class EmittedRecordsDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    ssc: StreamingContext) extends DStream[T](ssc) {\n+\n+  def stateSnapshots(): DStream[(K, S)]\n+}\n+\n+\n+private[streaming] class EmittedRecordsDStreamImpl[\n+    K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    trackStateDStream: TrackStateDStream[K, V, S, T])\n+  extends EmittedRecordsDStream[K, V, S, T](trackStateDStream.context) {\n+\n+  override def slideDuration: Duration = trackStateDStream.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(trackStateDStream)\n+\n+  override def compute(validTime: Time): Option[RDD[T]] = {\n+    trackStateDStream.getOrCompute(validTime).map { _.flatMap[T] { _.emittedRecords } }\n+  }\n+\n+  def stateSnapshots(): DStream[(K, S)] = {\n+    trackStateDStream.flatMap[(K, S)] {\n+      _.stateMap.getAll().map { case (k, s, _) => (k, s) }.toTraversable }\n+  }\n+}\n+\n+/**\n+ * A DStream that allows per-key state to be maintains, and arbitrary records to be generated\n+ * based on updates to the state.\n+ *\n+ * @param parent Parent (key, value) stream that is the source\n+ * @param spec Specifications of the trackStateByKey operation\n+ * @tparam K   Key type\n+ * @tparam V   Value type\n+ * @tparam S   Type of the state maintained\n+ * @tparam T   Type of the eiitted records\n+ */\n+private[streaming] class TrackStateDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    parent: DStream[(K, V)], spec: TrackStateSpecImpl[K, V, S, T])\n+  extends DStream[TrackStateRDDRecord[K, S, T]](parent.context) {\n+\n+  persist(StorageLevel.MEMORY_ONLY)\n+\n+  private val partitioner = spec.getPartitioner().getOrElse(\n+    new HashPartitioner(ssc.sc.defaultParallelism))\n+\n+  private val trackingFunction = spec.getFunction()\n+\n+  override def slideDuration: Duration = parent.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(parent)\n+\n+  override val mustCheckpoint = true\n+\n+  /** Method that generates a RDD for the given time */\n+  override def compute(validTime: Time): Option[RDD[TrackStateRDDRecord[K, S, T]]] = {\n+    val prevStateRDD = getOrCompute(validTime - slideDuration).getOrElse {\n+      TrackStateRDD.createFromPairRDD[K, V, S, T](\n+        spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n+        partitioner,\n+        validTime.milliseconds\n+      )\n+    }\n+    val newDataRDD = parent.getOrCompute(validTime).get"
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "> In practice it really cannot, but yeah its better to account for None's\n\nA user custom DStream may return `None`.\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-06T02:13:47Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+\n+abstract class EmittedRecordsDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    ssc: StreamingContext) extends DStream[T](ssc) {\n+\n+  def stateSnapshots(): DStream[(K, S)]\n+}\n+\n+\n+private[streaming] class EmittedRecordsDStreamImpl[\n+    K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    trackStateDStream: TrackStateDStream[K, V, S, T])\n+  extends EmittedRecordsDStream[K, V, S, T](trackStateDStream.context) {\n+\n+  override def slideDuration: Duration = trackStateDStream.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(trackStateDStream)\n+\n+  override def compute(validTime: Time): Option[RDD[T]] = {\n+    trackStateDStream.getOrCompute(validTime).map { _.flatMap[T] { _.emittedRecords } }\n+  }\n+\n+  def stateSnapshots(): DStream[(K, S)] = {\n+    trackStateDStream.flatMap[(K, S)] {\n+      _.stateMap.getAll().map { case (k, s, _) => (k, s) }.toTraversable }\n+  }\n+}\n+\n+/**\n+ * A DStream that allows per-key state to be maintains, and arbitrary records to be generated\n+ * based on updates to the state.\n+ *\n+ * @param parent Parent (key, value) stream that is the source\n+ * @param spec Specifications of the trackStateByKey operation\n+ * @tparam K   Key type\n+ * @tparam V   Value type\n+ * @tparam S   Type of the state maintained\n+ * @tparam T   Type of the eiitted records\n+ */\n+private[streaming] class TrackStateDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    parent: DStream[(K, V)], spec: TrackStateSpecImpl[K, V, S, T])\n+  extends DStream[TrackStateRDDRecord[K, S, T]](parent.context) {\n+\n+  persist(StorageLevel.MEMORY_ONLY)\n+\n+  private val partitioner = spec.getPartitioner().getOrElse(\n+    new HashPartitioner(ssc.sc.defaultParallelism))\n+\n+  private val trackingFunction = spec.getFunction()\n+\n+  override def slideDuration: Duration = parent.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(parent)\n+\n+  override val mustCheckpoint = true\n+\n+  /** Method that generates a RDD for the given time */\n+  override def compute(validTime: Time): Option[RDD[TrackStateRDDRecord[K, S, T]]] = {\n+    val prevStateRDD = getOrCompute(validTime - slideDuration).getOrElse {\n+      TrackStateRDD.createFromPairRDD[K, V, S, T](\n+        spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n+        partitioner,\n+        validTime.milliseconds\n+      )\n+    }\n+    val newDataRDD = parent.getOrCompute(validTime).get"
  }],
  "prId": 9256
}, {
  "comments": [{
    "author": {
      "login": "huitseeker"
    },
    "body": "The way this variable is used invites intervals that are multiple of the batch interval, and this may be something to document.\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-06T21:26:42Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+/**\n+ * :: Experimental ::\n+ * DStream representing the stream of records emitted after the `trackStateByKey` operation\n+ * on a [[org.apache.spark.streaming.dstream.PairDStreamFunctions pair DStream]] in Scala.\n+ * Additionally, it also gives access to the stream of state snapshots, that is, the state data of\n+ * all keys after a batch has updated them.\n+ *\n+ * @tparam K Class of the state key\n+ * @tparam S Class of the state data\n+ * @tparam T Class of the emitted records\n+ */\n+@Experimental\n+sealed abstract class EmittedRecordsDStream[K, S, T: ClassTag](\n+    ssc: StreamingContext) extends DStream[T](ssc) {\n+\n+  /** Return a pair DStream where each RDD is the snapshot of the state of all the keys. */\n+  def stateSnapshots(): DStream[(K, S)]\n+}\n+\n+/** Internal implementation of the [[EmittedRecordsDStream]] */\n+private[streaming] class EmittedRecordsDStreamImpl[\n+    K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    trackStateDStream: TrackStateDStream[K, V, S, T])\n+  extends EmittedRecordsDStream[K, S, T](trackStateDStream.context) {\n+\n+  override def slideDuration: Duration = trackStateDStream.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(trackStateDStream)\n+\n+  override def compute(validTime: Time): Option[RDD[T]] = {\n+    trackStateDStream.getOrCompute(validTime).map { _.flatMap[T] { _.emittedRecords } }\n+  }\n+\n+  def stateSnapshots(): DStream[(K, S)] = {\n+    trackStateDStream.flatMap[(K, S)] {\n+      _.stateMap.getAll().map { case (k, s, _) => (k, s) }.toTraversable }\n+  }\n+}\n+\n+/**\n+ * A DStream that allows per-key state to be maintains, and arbitrary records to be generated\n+ * based on updates to the state.\n+ *\n+ * @param parent Parent (key, value) stream that is the source\n+ * @param spec Specifications of the trackStateByKey operation\n+ * @tparam K   Key type\n+ * @tparam V   Value type\n+ * @tparam S   Type of the state maintained\n+ * @tparam T   Type of the eiitted records\n+ */\n+private[streaming] class TrackStateDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    parent: DStream[(K, V)], spec: StateSpecImpl[K, V, S, T])\n+  extends DStream[TrackStateRDDRecord[K, S, T]](parent.context) {\n+\n+  persist(StorageLevel.MEMORY_ONLY)\n+\n+  private val partitioner = spec.getPartitioner().getOrElse(\n+    new HashPartitioner(ssc.sc.defaultParallelism))\n+\n+  private val trackingFunction = spec.getFunction()\n+\n+  override def slideDuration: Duration = parent.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(parent)\n+\n+  override val mustCheckpoint = true\n+\n+  /** Method that generates a RDD for the given time */\n+  override def compute(validTime: Time): Option[RDD[TrackStateRDDRecord[K, S, T]]] = {\n+    val prevStateRDD = getOrCompute(validTime - slideDuration).getOrElse {\n+      TrackStateRDD.createFromPairRDD[K, V, S, T](\n+        spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n+        partitioner,\n+        validTime.milliseconds\n+      )\n+    }\n+    val newDataRDD = parent.getOrCompute(validTime).get\n+    val partitionedDataRDD = newDataRDD.partitionBy(partitioner)\n+    val timeoutThresholdTime = spec.getTimeoutInterval().map { interval =>\n+      (validTime - interval).milliseconds"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Not really. If the batch interval is 1 minute, one can specify 39 seconds as the threshold. And states that have been idle more >= 39 seconds will be removed at some point. The system (currently) does not guarantee exactly when the idle states will be marked for timeout. Now I am considering whether to document that or not. \n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-07T01:45:08Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+/**\n+ * :: Experimental ::\n+ * DStream representing the stream of records emitted after the `trackStateByKey` operation\n+ * on a [[org.apache.spark.streaming.dstream.PairDStreamFunctions pair DStream]] in Scala.\n+ * Additionally, it also gives access to the stream of state snapshots, that is, the state data of\n+ * all keys after a batch has updated them.\n+ *\n+ * @tparam K Class of the state key\n+ * @tparam S Class of the state data\n+ * @tparam T Class of the emitted records\n+ */\n+@Experimental\n+sealed abstract class EmittedRecordsDStream[K, S, T: ClassTag](\n+    ssc: StreamingContext) extends DStream[T](ssc) {\n+\n+  /** Return a pair DStream where each RDD is the snapshot of the state of all the keys. */\n+  def stateSnapshots(): DStream[(K, S)]\n+}\n+\n+/** Internal implementation of the [[EmittedRecordsDStream]] */\n+private[streaming] class EmittedRecordsDStreamImpl[\n+    K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    trackStateDStream: TrackStateDStream[K, V, S, T])\n+  extends EmittedRecordsDStream[K, S, T](trackStateDStream.context) {\n+\n+  override def slideDuration: Duration = trackStateDStream.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(trackStateDStream)\n+\n+  override def compute(validTime: Time): Option[RDD[T]] = {\n+    trackStateDStream.getOrCompute(validTime).map { _.flatMap[T] { _.emittedRecords } }\n+  }\n+\n+  def stateSnapshots(): DStream[(K, S)] = {\n+    trackStateDStream.flatMap[(K, S)] {\n+      _.stateMap.getAll().map { case (k, s, _) => (k, s) }.toTraversable }\n+  }\n+}\n+\n+/**\n+ * A DStream that allows per-key state to be maintains, and arbitrary records to be generated\n+ * based on updates to the state.\n+ *\n+ * @param parent Parent (key, value) stream that is the source\n+ * @param spec Specifications of the trackStateByKey operation\n+ * @tparam K   Key type\n+ * @tparam V   Value type\n+ * @tparam S   Type of the state maintained\n+ * @tparam T   Type of the eiitted records\n+ */\n+private[streaming] class TrackStateDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    parent: DStream[(K, V)], spec: StateSpecImpl[K, V, S, T])\n+  extends DStream[TrackStateRDDRecord[K, S, T]](parent.context) {\n+\n+  persist(StorageLevel.MEMORY_ONLY)\n+\n+  private val partitioner = spec.getPartitioner().getOrElse(\n+    new HashPartitioner(ssc.sc.defaultParallelism))\n+\n+  private val trackingFunction = spec.getFunction()\n+\n+  override def slideDuration: Duration = parent.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(parent)\n+\n+  override val mustCheckpoint = true\n+\n+  /** Method that generates a RDD for the given time */\n+  override def compute(validTime: Time): Option[RDD[TrackStateRDDRecord[K, S, T]]] = {\n+    val prevStateRDD = getOrCompute(validTime - slideDuration).getOrElse {\n+      TrackStateRDD.createFromPairRDD[K, V, S, T](\n+        spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n+        partitioner,\n+        validTime.milliseconds\n+      )\n+    }\n+    val newDataRDD = parent.getOrCompute(validTime).get\n+    val partitionedDataRDD = newDataRDD.partitionBy(partitioner)\n+    val timeoutThresholdTime = spec.getTimeoutInterval().map { interval =>\n+      (validTime - interval).milliseconds"
  }, {
    "author": {
      "login": "mateiz"
    },
    "body": "You should definitely say that the timeout isn't exact in the docs\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-07T16:25:48Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+/**\n+ * :: Experimental ::\n+ * DStream representing the stream of records emitted after the `trackStateByKey` operation\n+ * on a [[org.apache.spark.streaming.dstream.PairDStreamFunctions pair DStream]] in Scala.\n+ * Additionally, it also gives access to the stream of state snapshots, that is, the state data of\n+ * all keys after a batch has updated them.\n+ *\n+ * @tparam K Class of the state key\n+ * @tparam S Class of the state data\n+ * @tparam T Class of the emitted records\n+ */\n+@Experimental\n+sealed abstract class EmittedRecordsDStream[K, S, T: ClassTag](\n+    ssc: StreamingContext) extends DStream[T](ssc) {\n+\n+  /** Return a pair DStream where each RDD is the snapshot of the state of all the keys. */\n+  def stateSnapshots(): DStream[(K, S)]\n+}\n+\n+/** Internal implementation of the [[EmittedRecordsDStream]] */\n+private[streaming] class EmittedRecordsDStreamImpl[\n+    K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    trackStateDStream: TrackStateDStream[K, V, S, T])\n+  extends EmittedRecordsDStream[K, S, T](trackStateDStream.context) {\n+\n+  override def slideDuration: Duration = trackStateDStream.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(trackStateDStream)\n+\n+  override def compute(validTime: Time): Option[RDD[T]] = {\n+    trackStateDStream.getOrCompute(validTime).map { _.flatMap[T] { _.emittedRecords } }\n+  }\n+\n+  def stateSnapshots(): DStream[(K, S)] = {\n+    trackStateDStream.flatMap[(K, S)] {\n+      _.stateMap.getAll().map { case (k, s, _) => (k, s) }.toTraversable }\n+  }\n+}\n+\n+/**\n+ * A DStream that allows per-key state to be maintains, and arbitrary records to be generated\n+ * based on updates to the state.\n+ *\n+ * @param parent Parent (key, value) stream that is the source\n+ * @param spec Specifications of the trackStateByKey operation\n+ * @tparam K   Key type\n+ * @tparam V   Value type\n+ * @tparam S   Type of the state maintained\n+ * @tparam T   Type of the eiitted records\n+ */\n+private[streaming] class TrackStateDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    parent: DStream[(K, V)], spec: StateSpecImpl[K, V, S, T])\n+  extends DStream[TrackStateRDDRecord[K, S, T]](parent.context) {\n+\n+  persist(StorageLevel.MEMORY_ONLY)\n+\n+  private val partitioner = spec.getPartitioner().getOrElse(\n+    new HashPartitioner(ssc.sc.defaultParallelism))\n+\n+  private val trackingFunction = spec.getFunction()\n+\n+  override def slideDuration: Duration = parent.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(parent)\n+\n+  override val mustCheckpoint = true\n+\n+  /** Method that generates a RDD for the given time */\n+  override def compute(validTime: Time): Option[RDD[TrackStateRDDRecord[K, S, T]]] = {\n+    val prevStateRDD = getOrCompute(validTime - slideDuration).getOrElse {\n+      TrackStateRDD.createFromPairRDD[K, V, S, T](\n+        spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n+        partitioner,\n+        validTime.milliseconds\n+      )\n+    }\n+    val newDataRDD = parent.getOrCompute(validTime).get\n+    val partitionedDataRDD = newDataRDD.partitionBy(partitioner)\n+    val timeoutThresholdTime = spec.getTimeoutInterval().map { interval =>\n+      (validTime - interval).milliseconds"
  }, {
    "author": {
      "login": "mateiz"
    },
    "body": "(And maybe also say what it takes to make it exact, i.e. if your timeout is a multiple of the batch interval).\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-07T16:26:07Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+/**\n+ * :: Experimental ::\n+ * DStream representing the stream of records emitted after the `trackStateByKey` operation\n+ * on a [[org.apache.spark.streaming.dstream.PairDStreamFunctions pair DStream]] in Scala.\n+ * Additionally, it also gives access to the stream of state snapshots, that is, the state data of\n+ * all keys after a batch has updated them.\n+ *\n+ * @tparam K Class of the state key\n+ * @tparam S Class of the state data\n+ * @tparam T Class of the emitted records\n+ */\n+@Experimental\n+sealed abstract class EmittedRecordsDStream[K, S, T: ClassTag](\n+    ssc: StreamingContext) extends DStream[T](ssc) {\n+\n+  /** Return a pair DStream where each RDD is the snapshot of the state of all the keys. */\n+  def stateSnapshots(): DStream[(K, S)]\n+}\n+\n+/** Internal implementation of the [[EmittedRecordsDStream]] */\n+private[streaming] class EmittedRecordsDStreamImpl[\n+    K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    trackStateDStream: TrackStateDStream[K, V, S, T])\n+  extends EmittedRecordsDStream[K, S, T](trackStateDStream.context) {\n+\n+  override def slideDuration: Duration = trackStateDStream.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(trackStateDStream)\n+\n+  override def compute(validTime: Time): Option[RDD[T]] = {\n+    trackStateDStream.getOrCompute(validTime).map { _.flatMap[T] { _.emittedRecords } }\n+  }\n+\n+  def stateSnapshots(): DStream[(K, S)] = {\n+    trackStateDStream.flatMap[(K, S)] {\n+      _.stateMap.getAll().map { case (k, s, _) => (k, s) }.toTraversable }\n+  }\n+}\n+\n+/**\n+ * A DStream that allows per-key state to be maintains, and arbitrary records to be generated\n+ * based on updates to the state.\n+ *\n+ * @param parent Parent (key, value) stream that is the source\n+ * @param spec Specifications of the trackStateByKey operation\n+ * @tparam K   Key type\n+ * @tparam V   Value type\n+ * @tparam S   Type of the state maintained\n+ * @tparam T   Type of the eiitted records\n+ */\n+private[streaming] class TrackStateDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    parent: DStream[(K, V)], spec: StateSpecImpl[K, V, S, T])\n+  extends DStream[TrackStateRDDRecord[K, S, T]](parent.context) {\n+\n+  persist(StorageLevel.MEMORY_ONLY)\n+\n+  private val partitioner = spec.getPartitioner().getOrElse(\n+    new HashPartitioner(ssc.sc.defaultParallelism))\n+\n+  private val trackingFunction = spec.getFunction()\n+\n+  override def slideDuration: Duration = parent.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(parent)\n+\n+  override val mustCheckpoint = true\n+\n+  /** Method that generates a RDD for the given time */\n+  override def compute(validTime: Time): Option[RDD[TrackStateRDDRecord[K, S, T]]] = {\n+    val prevStateRDD = getOrCompute(validTime - slideDuration).getOrElse {\n+      TrackStateRDD.createFromPairRDD[K, V, S, T](\n+        spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n+        partitioner,\n+        validTime.milliseconds\n+      )\n+    }\n+    val newDataRDD = parent.getOrCompute(validTime).get\n+    val partitionedDataRDD = newDataRDD.partitionBy(partitioner)\n+    val timeoutThresholdTime = spec.getTimeoutInterval().map { interval =>\n+      (validTime - interval).milliseconds"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Actually, in the current implementation, there is no way to make it exact. Since we dont maintain an timestamp-index in the data structure yet, we need to do full scans to find timedout records. And we do full scans infrequently, only at the timeof checkpointing. So the timeouts will occur only at checkpoint interval. Now documenting to that granularity is confusing and it is likely to change in the future.\n\nNonetheless, i will document that the exact time of timing out isnt guaranteed.\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-09T07:31:31Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+/**\n+ * :: Experimental ::\n+ * DStream representing the stream of records emitted after the `trackStateByKey` operation\n+ * on a [[org.apache.spark.streaming.dstream.PairDStreamFunctions pair DStream]] in Scala.\n+ * Additionally, it also gives access to the stream of state snapshots, that is, the state data of\n+ * all keys after a batch has updated them.\n+ *\n+ * @tparam K Class of the state key\n+ * @tparam S Class of the state data\n+ * @tparam T Class of the emitted records\n+ */\n+@Experimental\n+sealed abstract class EmittedRecordsDStream[K, S, T: ClassTag](\n+    ssc: StreamingContext) extends DStream[T](ssc) {\n+\n+  /** Return a pair DStream where each RDD is the snapshot of the state of all the keys. */\n+  def stateSnapshots(): DStream[(K, S)]\n+}\n+\n+/** Internal implementation of the [[EmittedRecordsDStream]] */\n+private[streaming] class EmittedRecordsDStreamImpl[\n+    K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    trackStateDStream: TrackStateDStream[K, V, S, T])\n+  extends EmittedRecordsDStream[K, S, T](trackStateDStream.context) {\n+\n+  override def slideDuration: Duration = trackStateDStream.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(trackStateDStream)\n+\n+  override def compute(validTime: Time): Option[RDD[T]] = {\n+    trackStateDStream.getOrCompute(validTime).map { _.flatMap[T] { _.emittedRecords } }\n+  }\n+\n+  def stateSnapshots(): DStream[(K, S)] = {\n+    trackStateDStream.flatMap[(K, S)] {\n+      _.stateMap.getAll().map { case (k, s, _) => (k, s) }.toTraversable }\n+  }\n+}\n+\n+/**\n+ * A DStream that allows per-key state to be maintains, and arbitrary records to be generated\n+ * based on updates to the state.\n+ *\n+ * @param parent Parent (key, value) stream that is the source\n+ * @param spec Specifications of the trackStateByKey operation\n+ * @tparam K   Key type\n+ * @tparam V   Value type\n+ * @tparam S   Type of the state maintained\n+ * @tparam T   Type of the eiitted records\n+ */\n+private[streaming] class TrackStateDStream[K: ClassTag, V: ClassTag, S: ClassTag, T: ClassTag](\n+    parent: DStream[(K, V)], spec: StateSpecImpl[K, V, S, T])\n+  extends DStream[TrackStateRDDRecord[K, S, T]](parent.context) {\n+\n+  persist(StorageLevel.MEMORY_ONLY)\n+\n+  private val partitioner = spec.getPartitioner().getOrElse(\n+    new HashPartitioner(ssc.sc.defaultParallelism))\n+\n+  private val trackingFunction = spec.getFunction()\n+\n+  override def slideDuration: Duration = parent.slideDuration\n+\n+  override def dependencies: List[DStream[_]] = List(parent)\n+\n+  override val mustCheckpoint = true\n+\n+  /** Method that generates a RDD for the given time */\n+  override def compute(validTime: Time): Option[RDD[TrackStateRDDRecord[K, S, T]]] = {\n+    val prevStateRDD = getOrCompute(validTime - slideDuration).getOrElse {\n+      TrackStateRDD.createFromPairRDD[K, V, S, T](\n+        spec.getInitialStateRDD().getOrElse(new EmptyRDD[(K, S)](ssc.sparkContext)),\n+        partitioner,\n+        validTime.milliseconds\n+      )\n+    }\n+    val newDataRDD = parent.getOrCompute(validTime).get\n+    val partitionedDataRDD = newDataRDD.partitionBy(partitioner)\n+    val timeoutThresholdTime = spec.getTimeoutInterval().map { interval =>\n+      (validTime - interval).milliseconds"
  }],
  "prId": 9256
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "@rxin  @pwendell Is `EmittedRecordsDStream` is good or should we change this? Things that have been suggested. \n1. EmittedDStream - Pro: shorter, no ref to \"record\". Con: Emitted what? states? \n2. StateDStream - Logic: DStream generated by `trackStateByKey`. Pro: shorter. Con: sounds like a stream of states (similar to updateStateByKey), but that this is not. \n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-07T01:40:06Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+/**\n+ * :: Experimental ::\n+ * DStream representing the stream of records emitted after the `trackStateByKey` operation\n+ * on a [[org.apache.spark.streaming.dstream.PairDStreamFunctions pair DStream]] in Scala.\n+ * Additionally, it also gives access to the stream of state snapshots, that is, the state data of\n+ * all keys after a batch has updated them.\n+ *\n+ * @tparam K Class of the state key\n+ * @tparam S Class of the state data\n+ * @tparam T Class of the emitted records\n+ */\n+@Experimental\n+sealed abstract class EmittedRecordsDStream[K, S, T: ClassTag]("
  }, {
    "author": {
      "login": "mateiz"
    },
    "body": "I'd just call it EmittedDStream.\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-07T15:54:00Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+/**\n+ * :: Experimental ::\n+ * DStream representing the stream of records emitted after the `trackStateByKey` operation\n+ * on a [[org.apache.spark.streaming.dstream.PairDStreamFunctions pair DStream]] in Scala.\n+ * Additionally, it also gives access to the stream of state snapshots, that is, the state data of\n+ * all keys after a batch has updated them.\n+ *\n+ * @tparam K Class of the state key\n+ * @tparam S Class of the state data\n+ * @tparam T Class of the emitted records\n+ */\n+@Experimental\n+sealed abstract class EmittedRecordsDStream[K, S, T: ClassTag]("
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Sounds too generic to me, and its hard to associate `EmittedDStream` with `trackStateByKey`. Let me throw in another  suggestion - `TrackStateDStream` - a dstream generated by `trackStateByKey`. Easy to associate.\nCurrently `TrackStateDStream` is the internal one, but we can rename that differently.\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-09T07:26:10Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+/**\n+ * :: Experimental ::\n+ * DStream representing the stream of records emitted after the `trackStateByKey` operation\n+ * on a [[org.apache.spark.streaming.dstream.PairDStreamFunctions pair DStream]] in Scala.\n+ * Additionally, it also gives access to the stream of state snapshots, that is, the state data of\n+ * all keys after a batch has updated them.\n+ *\n+ * @tparam K Class of the state key\n+ * @tparam S Class of the state data\n+ * @tparam T Class of the emitted records\n+ */\n+@Experimental\n+sealed abstract class EmittedRecordsDStream[K, S, T: ClassTag]("
  }, {
    "author": {
      "login": "mateiz"
    },
    "body": "TrackStateDStream sounds good\n",
    "commit": "ae64786fd937002a2cc1f80518d54e970a6bbb21",
    "createdAt": "2015-11-09T16:58:21Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.dstream\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark._\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.rdd.{EmptyRDD, RDD}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.rdd.{TrackStateRDD, TrackStateRDDRecord}\n+\n+/**\n+ * :: Experimental ::\n+ * DStream representing the stream of records emitted after the `trackStateByKey` operation\n+ * on a [[org.apache.spark.streaming.dstream.PairDStreamFunctions pair DStream]] in Scala.\n+ * Additionally, it also gives access to the stream of state snapshots, that is, the state data of\n+ * all keys after a batch has updated them.\n+ *\n+ * @tparam K Class of the state key\n+ * @tparam S Class of the state data\n+ * @tparam T Class of the emitted records\n+ */\n+@Experimental\n+sealed abstract class EmittedRecordsDStream[K, S, T: ClassTag]("
  }],
  "prId": 9256
}]