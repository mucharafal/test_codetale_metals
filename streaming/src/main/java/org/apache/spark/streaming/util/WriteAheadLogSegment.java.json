[{
  "comments": [{
    "author": {
      "login": "harishreedharan"
    },
    "body": "represents\n",
    "commit": "2c431fd559faa5c1934db176b05c152ee8236248",
    "createdAt": "2015-04-27T04:49:25Z",
    "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.util;\n+\n+/**\n+ * This is an interface that represent the information required by any implementation of"
  }],
  "prId": 5645
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "It might be good to say something like 'Represents an opaque identifier that references metadata required to read a specific piece of data\".\n",
    "commit": "2c431fd559faa5c1934db176b05c152ee8236248",
    "createdAt": "2015-04-28T01:56:32Z",
    "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.util;\n+\n+/**\n+ * This is an interface that represent the information required by any implementation of\n+ * a WriteAheadLog to read a written record."
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Saying \"opaque\" is kind of confusing. Its opaque to Spark, but not to whoever is implementing the WAL. And its not for referring to arbitrary piece of data, but specifically for referring to a record that has been written using a specific WriteAheadLog implementation.\n",
    "commit": "2c431fd559faa5c1934db176b05c152ee8236248",
    "createdAt": "2015-04-28T03:02:29Z",
    "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.util;\n+\n+/**\n+ * This is an interface that represent the information required by any implementation of\n+ * a WriteAheadLog to read a written record."
  }],
  "prId": 5645
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "I wonder if we should more explicitly build the serialization of these segment identifiers into this interface. One extreme option is to have the segment identifiers actually be byte buffers and ask the user to deal on their own with serializing them.\n\nThe main concerns I have are the following:\n1. Individual implementations of this must be java Serializable, but it's not possible to reflect that in the interface.\n2. If those implementations want to evolve over different versions for instance they add a new field to the segment identifier, it will be tricky for them to do in a way that's backwards compatible (they'll have to write a custom externalization logic, which isn't really used for backwards compatibility).\n",
    "commit": "2c431fd559faa5c1934db176b05c152ee8236248",
    "createdAt": "2015-04-28T02:14:01Z",
    "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.util;\n+\n+/**\n+ * This is an interface that represent the information required by any implementation of\n+ * a WriteAheadLog to read a written record.\n+ */\n+@org.apache.spark.annotation.DeveloperApi\n+public interface WriteAheadLogSegment extends java.io.Serializable {"
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "Also could we call this a `WALSegmentHandle` or something? This isn't the segment itself it's just an identifier.\n",
    "commit": "2c431fd559faa5c1934db176b05c152ee8236248",
    "createdAt": "2015-04-28T02:24:25Z",
    "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.util;\n+\n+/**\n+ * This is an interface that represent the information required by any implementation of\n+ * a WriteAheadLog to read a written record.\n+ */\n+@org.apache.spark.annotation.DeveloperApi\n+public interface WriteAheadLogSegment extends java.io.Serializable {"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "1. Well, for advanced users who want to implement their own WAL implementation will have to ensure that the segment info is serializable, no matter whether we expose an interface or a bytebuffer. In fact, exposing an interface avoids them from writing the code to serialize and return a bytebuffer in a usual case, which is easier to user. Also this interface is expected to be called not faster than 100s of time per second. So does not require super high serialization efficiency. Even if they want, they can always make the implementation extend Externalizable.\n2. That is a good point. There are easy workaround even if we dont make this a ByteBuffer. They can put a bytebuffer within their implementation `class MyWALSegment(byteBuffer: ByteBuffer) extends WALSegment`. Now for people who dont care about backward compatibility, making it a bytebuffer make it harder for them to implement. For others who do care about backward compatibility, they will have to write custom externalization logic either way, while returning bytebuffer or returning MyWALSegment.\n",
    "commit": "2c431fd559faa5c1934db176b05c152ee8236248",
    "createdAt": "2015-04-28T03:23:23Z",
    "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.util;\n+\n+/**\n+ * This is an interface that represent the information required by any implementation of\n+ * a WriteAheadLog to read a written record.\n+ */\n+@org.apache.spark.annotation.DeveloperApi\n+public interface WriteAheadLogSegment extends java.io.Serializable {"
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "But in the current approach, they can't for instance use kryo or protobuf to serialize, unless they do something really crazy like use an externalizable hook to then call into Kryo. I guess I'm just thinking ahead to how this will evolve. However, if we want to have this in the future we can always create an alternative version that is additive, so I don't feel strongly at all\n",
    "commit": "2c431fd559faa5c1934db176b05c152ee8236248",
    "createdAt": "2015-04-28T04:31:01Z",
    "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.util;\n+\n+/**\n+ * This is an interface that represent the information required by any implementation of\n+ * a WriteAheadLog to read a written record.\n+ */\n+@org.apache.spark.annotation.DeveloperApi\n+public interface WriteAheadLogSegment extends java.io.Serializable {"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Actually, this is an interface, so I am not sure we can create an alternate\nmethod without breaking binary compatibility.\nWell, they could leave the serialization of MyWALSegment to Java, which is\njust a wrapper for a ByteBuffer/byte array which contains all the real\ndata. If that sounds too complicated, then may be we should do bytes. And\nprobably we should simply use byte array instead of ByteBuffer, as we\nprobably dont need to deal with direct byte buffers here.\n\nOn Mon, Apr 27, 2015 at 9:31 PM, Patrick Wendell notifications@github.com\nwrote:\n\n> In\n> streaming/src/main/java/org/apache/spark/streaming/util/WriteAheadLogSegment.java\n> https://github.com/apache/spark/pull/5645#discussion_r29213656:\n> \n> > - *\n> > - \\* Unless required by applicable law or agreed to in writing, software\n> > - \\* distributed under the License is distributed on an \"AS IS\" BASIS,\n> > - \\* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n> > - \\* See the License for the specific language governing permissions and\n> > - \\* limitations under the License.\n> > - _/\n> >   +\n> >   +package org.apache.spark.streaming.util;\n> >   +\n> >   +/_*\n> > - \\* This is an interface that represent the information required by any implementation of\n> > - \\* a WriteAheadLog to read a written record.\n> > - */\n> >   +@org.apache.spark.annotation.DeveloperApi\n> >   +public interface WriteAheadLogSegment extends java.io.Serializable {\n> \n> But in the current approach, they can't for instance use kryo or protobuf\n> to serialize, unless they do something really crazy like use an\n> externalizable hook to then call into Kryo. I guess I'm just thinking ahead\n> to how this will evolve. However, if we want to have this in the future we\n> can always create an alternative version that is additive, so I don't feel\n> strongly at all\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/apache/spark/pull/5645/files#r29213656.\n",
    "commit": "2c431fd559faa5c1934db176b05c152ee8236248",
    "createdAt": "2015-04-28T08:23:35Z",
    "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.util;\n+\n+/**\n+ * This is an interface that represent the information required by any implementation of\n+ * a WriteAheadLog to read a written record.\n+ */\n+@org.apache.spark.annotation.DeveloperApi\n+public interface WriteAheadLogSegment extends java.io.Serializable {"
  }],
  "prId": 5645
}]