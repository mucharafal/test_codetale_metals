[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "This might happen to be OK, but now the dir is not deleted between tests. Is that going to be OK?\n",
    "commit": "d680a2f47f25daf2a9fe18a84fe081a688348fb9",
    "createdAt": "2016-11-06T14:23:03Z",
    "diffHunk": "@@ -38,19 +38,16 @@ class MapWithStateSuite extends SparkFunSuite\n   protected val batchDuration = Seconds(1)\n \n   before {\n-    StreamingContext.getActive().foreach { _.stop(stopSparkContext = false) }\n-    checkpointDir = Utils.createTempDir(\"checkpoint\")\n+    StreamingContext.getActive().foreach(_.stop(stopSparkContext = false))\n   }\n \n   after {\n-    StreamingContext.getActive().foreach { _.stop(stopSparkContext = false) }\n-    if (checkpointDir != null) {\n-      Utils.deleteRecursively(checkpointDir)\n-    }\n+    StreamingContext.getActive().foreach(_.stop(stopSparkContext = false))\n   }\n \n   override def beforeAll(): Unit = {\n     super.beforeAll()\n+    checkpointDir = Utils.createTempDir(\"checkpoint\")"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Actually, it seems the original codes are already fine in here.. I took a look and ran several tests and it seems now I may understand why @taoli91 tried to fix the codes like this.\n\nIt seems somehow the state in `ReceiverTracker` went wrong on Windows and ended up without closing `checkpointDir`. It seems the original test was failed[1] due to the issue in `ReceiverTracker`. So, I think he tried to only create/delete the folder once[2] and ensure stopping `ReceivedBlockTracker` in `ReceiverTracker` regardless of the state.\n\nI tested this with manually stopping  `ReceivedBlockTracker` regardless of the state (the original proposal) and it seems fine without the changes in here, `MapWithStateSuite.scala`[3]. Of course,  it is fine with this change[4]. \n\n[1]https://ci.appveyor.com/project/spark-test/spark/build/56-F88EDDAF-E576-4787-9530-A4185FC46B1E\n[2]https://ci.appveyor.com/project/spark-test/spark/build/57-test-MapWithStateSuite\n[3]https://ci.appveyor.com/project/spark-test/spark/build/58-test-MapWithStateSuite\n[4]https://ci.appveyor.com/project/spark-test/spark/build/59-test-MapWithStateSuite\n",
    "commit": "d680a2f47f25daf2a9fe18a84fe081a688348fb9",
    "createdAt": "2016-11-07T12:42:46Z",
    "diffHunk": "@@ -38,19 +38,16 @@ class MapWithStateSuite extends SparkFunSuite\n   protected val batchDuration = Seconds(1)\n \n   before {\n-    StreamingContext.getActive().foreach { _.stop(stopSparkContext = false) }\n-    checkpointDir = Utils.createTempDir(\"checkpoint\")\n+    StreamingContext.getActive().foreach(_.stop(stopSparkContext = false))\n   }\n \n   after {\n-    StreamingContext.getActive().foreach { _.stop(stopSparkContext = false) }\n-    if (checkpointDir != null) {\n-      Utils.deleteRecursively(checkpointDir)\n-    }\n+    StreamingContext.getActive().foreach(_.stop(stopSparkContext = false))\n   }\n \n   override def beforeAll(): Unit = {\n     super.beforeAll()\n+    checkpointDir = Utils.createTempDir(\"checkpoint\")"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I believe this change is not valid. I will get rid of this. Thank you for pointing this out.\n",
    "commit": "d680a2f47f25daf2a9fe18a84fe081a688348fb9",
    "createdAt": "2016-11-07T12:44:30Z",
    "diffHunk": "@@ -38,19 +38,16 @@ class MapWithStateSuite extends SparkFunSuite\n   protected val batchDuration = Seconds(1)\n \n   before {\n-    StreamingContext.getActive().foreach { _.stop(stopSparkContext = false) }\n-    checkpointDir = Utils.createTempDir(\"checkpoint\")\n+    StreamingContext.getActive().foreach(_.stop(stopSparkContext = false))\n   }\n \n   after {\n-    StreamingContext.getActive().foreach { _.stop(stopSparkContext = false) }\n-    if (checkpointDir != null) {\n-      Utils.deleteRecursively(checkpointDir)\n-    }\n+    StreamingContext.getActive().foreach(_.stop(stopSparkContext = false))\n   }\n \n   override def beforeAll(): Unit = {\n     super.beforeAll()\n+    checkpointDir = Utils.createTempDir(\"checkpoint\")"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "BTW, the reason why [1][2] were failed on Windows (without ensuring stopping `ReceivedBlockTracker`) seems, the directory, `checkpointDir`, is being opened so it fails to delete the directory throwing an exception.\n",
    "commit": "d680a2f47f25daf2a9fe18a84fe081a688348fb9",
    "createdAt": "2016-11-07T12:50:10Z",
    "diffHunk": "@@ -38,19 +38,16 @@ class MapWithStateSuite extends SparkFunSuite\n   protected val batchDuration = Seconds(1)\n \n   before {\n-    StreamingContext.getActive().foreach { _.stop(stopSparkContext = false) }\n-    checkpointDir = Utils.createTempDir(\"checkpoint\")\n+    StreamingContext.getActive().foreach(_.stop(stopSparkContext = false))\n   }\n \n   after {\n-    StreamingContext.getActive().foreach { _.stop(stopSparkContext = false) }\n-    if (checkpointDir != null) {\n-      Utils.deleteRecursively(checkpointDir)\n-    }\n+    StreamingContext.getActive().foreach(_.stop(stopSparkContext = false))\n   }\n \n   override def beforeAll(): Unit = {\n     super.beforeAll()\n+    checkpointDir = Utils.createTempDir(\"checkpoint\")"
  }],
  "prId": 15618
}]