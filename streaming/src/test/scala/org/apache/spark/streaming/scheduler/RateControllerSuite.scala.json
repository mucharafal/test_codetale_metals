[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: extra line\n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-24T06:50:02Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+\n+"
  }],
  "prId": 7600
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "reach -> each\n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-27T21:30:23Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+class RateControllerSuite extends TestSuiteBase {\n+\n+  override def actuallyWait: Boolean = true\n+\n+  test(\"rate controller publishes updates\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    val dstream = new MockRateLimitDStream(ssc, Seq(Seq(1)), 1)\n+    val output = new TestOutputStreamWithPartitions(dstream)\n+    output.register()\n+    runStreams(ssc, 1, 1)\n+\n+    eventually(timeout(2.seconds)) {\n+      assert(dstream.publishCalls === 1)\n+    }\n+  }\n+\n+  test(\"receiver rate controller updates reach receivers\") {"
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "It's really \"reach\". There's only one receiver in my test, so it would be a stretch to describe it that way.\n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-28T09:30:27Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+class RateControllerSuite extends TestSuiteBase {\n+\n+  override def actuallyWait: Boolean = true\n+\n+  test(\"rate controller publishes updates\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    val dstream = new MockRateLimitDStream(ssc, Seq(Seq(1)), 1)\n+    val output = new TestOutputStreamWithPartitions(dstream)\n+    output.register()\n+    runStreams(ssc, 1, 1)\n+\n+    eventually(timeout(2.seconds)) {\n+      assert(dstream.publishCalls === 1)\n+    }\n+  }\n+\n+  test(\"receiver rate controller updates reach receivers\") {"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "right. Its technically correct, but hard to read which is why my brain messed it up. How about \"publish rates reach receivers\"?\n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-28T09:35:14Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+class RateControllerSuite extends TestSuiteBase {\n+\n+  override def actuallyWait: Boolean = true\n+\n+  test(\"rate controller publishes updates\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    val dstream = new MockRateLimitDStream(ssc, Seq(Seq(1)), 1)\n+    val output = new TestOutputStreamWithPartitions(dstream)\n+    output.register()\n+    runStreams(ssc, 1, 1)\n+\n+    eventually(timeout(2.seconds)) {\n+      assert(dstream.publishCalls === 1)\n+    }\n+  }\n+\n+  test(\"receiver rate controller updates reach receivers\") {"
  }],
  "prId": 7600
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This old style of using `TestSuiteBase` and defining `streamingContext` in every test and making runStreams stop the context is actually very flaky, as failure before `runStream` will end up leaking an active SparkContext and failing all subsequent Spark tests. Its being used in many places and I hope to upgrade them at some point. So the two alternatives of using TestSuiteBase are\n1. Use [`usingStreamingContext`](https://github.com/apache/spark/blob/1f6b0b1234cc03aa2e07aea7fec2de7563885238/streaming/src/test/scala/org/apache/spark/streaming/TestSuiteBase.scala#L270) - This ensure the context are stopped no matter what fails. But it ends up creating a new SpakrContext for every test. \n2. The 2nd alternative is to share SparkContext and use before-after methods as I have done it in this [suite](https://github.com/apache/spark/blob/master/extras/kinesis-asl/src/test/scala/org/apache/spark/streaming/kinesis/KinesisStreamSuite.scala). \n\nPlease update the testsuites here with either of the two methods. This would also simplify the testsuite because you really dont need any of the output and TestOutputStreamWithPartitions stuff. All you need to do is see whether the rate is updated. \n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-27T21:43:06Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+class RateControllerSuite extends TestSuiteBase {\n+\n+  override def actuallyWait: Boolean = true\n+\n+  test(\"rate controller publishes updates\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    val dstream = new MockRateLimitDStream(ssc, Seq(Seq(1)), 1)\n+    val output = new TestOutputStreamWithPartitions(dstream)"
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "Good point about leaking contexts, I'll see what I can do. Since `runStreams` stops the context, we'll stop it twice (I know, it only logs a warning, but still it seems suboptimal).\n\nI'd like to keep using `runStreams`, otherwise I'll have to duplicate some of its implementation. The output testing is collateral, but not bad in itself, at least not worse than duplicating the logic around manual clock advancing. I _do_ need to simulate running for a few batch intervals to see how the rate gets updated. \n\nLastly, this _particular_ test doesn't need it, but I updated to be similar to the others here, and I think it \"ties the suit together\" :). If you insist I can revert it, but the other two tests, that actually run the whole pipeline to see rate updates in action, still need `runStreams`\n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-28T09:23:19Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+class RateControllerSuite extends TestSuiteBase {\n+\n+  override def actuallyWait: Boolean = true\n+\n+  test(\"rate controller publishes updates\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    val dstream = new MockRateLimitDStream(ssc, Seq(Seq(1)), 1)\n+    val output = new TestOutputStreamWithPartitions(dstream)"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Tests that update the rate and checks whether receiver gets the update should not require running the batches. \n\nIf you need runStreams just to \"wait\" the batches run, then it is cleaner to just use normal clock (no manual clock) and then just use eventually to wait for the necessary condition to be fulfilled. Now, in some places, you are calling runstreams, as well as using eventually.  This change would simplify it further \n\n```\nssc.start()\n\neventualy(...) {\n}\n```\n\nRegarding stopping it twice, if you are anyways adding code in a `try..catch` or `after` to stop the context, might as well use just `usingStreamingContext` or just `after/afterAll` forget about the `TestSuiteBased` and `runStreams`\n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-28T13:18:23Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+class RateControllerSuite extends TestSuiteBase {\n+\n+  override def actuallyWait: Boolean = true\n+\n+  test(\"rate controller publishes updates\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    val dstream = new MockRateLimitDStream(ssc, Seq(Seq(1)), 1)\n+    val output = new TestOutputStreamWithPartitions(dstream)"
  }],
  "prId": 7600
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "As I said in the other thread, this `output` stuff is totally superfluous.\n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-28T13:19:53Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+class RateControllerSuite extends TestSuiteBase {\n+\n+  override def actuallyWait: Boolean = true\n+\n+  test(\"rate controller publishes updates\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val dstream = new MockRateLimitDStream(ssc, Seq(Seq(1)), 1)\n+      val output = new TestOutputStreamWithPartitions(dstream)\n+      output.register()\n+      runStreams(ssc, 1, 1)\n+\n+      eventually(timeout(2.seconds)) {\n+        assert(dstream.publishCalls === 1)\n+      }\n+    }\n+  }\n+\n+  test(\"receiver rate controller updates reach receivers\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val dstream = new RateLimitInputDStream(ssc) {\n+        override val rateController =\n+          Some(new ReceiverRateController(id, new ConstantEstimator(200.0)))\n+      }\n+      SingletonDummyReceiver.reset()\n+\n+      val output = new TestOutputStreamWithPartitions(dstream)"
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "It's not, as long as I use `runStreams`. Nothing happens if I don't have any output stream. This test is an end-to-end test, so I need to get batch updates, calculate the rate, and set it back. If there's no output stream, no job gets created.\n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-28T16:26:27Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+class RateControllerSuite extends TestSuiteBase {\n+\n+  override def actuallyWait: Boolean = true\n+\n+  test(\"rate controller publishes updates\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val dstream = new MockRateLimitDStream(ssc, Seq(Seq(1)), 1)\n+      val output = new TestOutputStreamWithPartitions(dstream)\n+      output.register()\n+      runStreams(ssc, 1, 1)\n+\n+      eventually(timeout(2.seconds)) {\n+        assert(dstream.publishCalls === 1)\n+      }\n+    }\n+  }\n+\n+  test(\"receiver rate controller updates reach receivers\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val dstream = new RateLimitInputDStream(ssc) {\n+        override val rateController =\n+          Some(new ReceiverRateController(id, new ConstantEstimator(200.0)))\n+      }\n+      SingletonDummyReceiver.reset()\n+\n+      val output = new TestOutputStreamWithPartitions(dstream)"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "You just need to call `register` on the `RateLimitInputDStream` or any transformed DStream.\n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-28T19:18:17Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+class RateControllerSuite extends TestSuiteBase {\n+\n+  override def actuallyWait: Boolean = true\n+\n+  test(\"rate controller publishes updates\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val dstream = new MockRateLimitDStream(ssc, Seq(Seq(1)), 1)\n+      val output = new TestOutputStreamWithPartitions(dstream)\n+      output.register()\n+      runStreams(ssc, 1, 1)\n+\n+      eventually(timeout(2.seconds)) {\n+        assert(dstream.publishCalls === 1)\n+      }\n+    }\n+  }\n+\n+  test(\"receiver rate controller updates reach receivers\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val dstream = new RateLimitInputDStream(ssc) {\n+        override val rateController =\n+          Some(new ReceiverRateController(id, new ConstantEstimator(200.0)))\n+      }\n+      SingletonDummyReceiver.reset()\n+\n+      val output = new TestOutputStreamWithPartitions(dstream)"
  }],
  "prId": 7600
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This is going to be a flaky test. There is no guarantee that this 20 ms sleep will be 20 ms. Can very well be 100 ms. And it cannot be guaranteed that will always get a the 100, 200, 300 will be received by receiver by the time 4 batches are over through `runStreams`. This going to be SUPER FLAKY. The non-flaky way of doing this \n1. run streamingContext normally in real time (no real need for `runStreams`, just `ssc.start()`)\n2. test using `eventually { observedRates should contain theSameElementsAs (rates :+ Long.MaxValue) }`, no need to run anything in the background and all.\n3. `observedRates` must be a synchronized hashset. \n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-28T20:31:42Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+class RateControllerSuite extends TestSuiteBase {\n+\n+  override def actuallyWait: Boolean = true\n+\n+  test(\"rate controller publishes updates\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val dstream = new MockRateLimitDStream(ssc, Seq(Seq(1)), 1)\n+      val output = new TestOutputStreamWithPartitions(dstream)\n+      output.register()\n+      runStreams(ssc, 1, 1)\n+\n+      eventually(timeout(2.seconds)) {\n+        assert(dstream.publishCalls === 1)\n+      }\n+    }\n+  }\n+\n+  test(\"publish rates reach receivers\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val dstream = new RateLimitInputDStream(ssc) {\n+        override val rateController =\n+          Some(new ReceiverRateController(id, new ConstantEstimator(200.0)))\n+      }\n+      SingletonDummyReceiver.reset()\n+\n+      val output = new TestOutputStreamWithPartitions(dstream)\n+      output.register()\n+      runStreams(ssc, 2, 2)\n+\n+      eventually(timeout(5.seconds)) {\n+        assert(dstream.getCurrentRateLimit === Some(200))\n+      }\n+    }\n+  }\n+\n+  test(\"multiple publish rates reach receivers\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val rates = Seq(100L, 200L, 300L)\n+\n+      val dstream = new RateLimitInputDStream(ssc) {\n+        override val rateController =\n+          Some(new ReceiverRateController(id, new ConstantEstimator(rates.map(_.toDouble): _*)))\n+      }\n+      SingletonDummyReceiver.reset()\n+\n+      val output = new TestOutputStreamWithPartitions(dstream)\n+      output.register()\n+\n+      val observedRates = mutable.HashSet.empty[Long]\n+\n+      @volatile var done = false\n+      runInBackground {\n+        while (!done) {\n+          try {\n+            dstream.getCurrentRateLimit.foreach(observedRates += _)\n+          } catch {\n+            case NonFatal(_) => () // don't stop if the executor wasn't installed yet\n+          }\n+          Thread.sleep(20)"
  }, {
    "author": {
      "login": "dragos"
    },
    "body": "Ok, in the interest of closing this PR I will do the changes you request ASAP.\n\nHowever, in the interest of understanding,  I ran it 100 times without it failing once. If you have evidence of it being **SUPER FLAKY** in practice, do you mind sharing it here?\n\nI guess the reason I'm not seeing these failures is that even if theoretically the delay could be higher, say 100ms, since the batch interval is 1s, you'd still sample it 10 times. And looking at the implementation of `SystemClock`, it's still based on `Thread.sleep`, so any systematic delay (say, system under heavy load) will affect both this test and the batch interval sampling rate.\n\nBTW, `eventually` is using `Thread.sleep` as well (15ms between attempts, by default), so I guess the same considerations regarding flakiness should apply.\n",
    "commit": "f168c9476fc7104d3d3f92702793e0d9116117d0",
    "createdAt": "2015-07-29T09:44:40Z",
    "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+import scala.util.control.NonFatal\n+\n+import org.scalatest.Matchers._\n+import org.scalatest.concurrent.Eventually._\n+import org.scalatest.time.SpanSugar._\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.scheduler.rate.RateEstimator\n+\n+class RateControllerSuite extends TestSuiteBase {\n+\n+  override def actuallyWait: Boolean = true\n+\n+  test(\"rate controller publishes updates\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val dstream = new MockRateLimitDStream(ssc, Seq(Seq(1)), 1)\n+      val output = new TestOutputStreamWithPartitions(dstream)\n+      output.register()\n+      runStreams(ssc, 1, 1)\n+\n+      eventually(timeout(2.seconds)) {\n+        assert(dstream.publishCalls === 1)\n+      }\n+    }\n+  }\n+\n+  test(\"publish rates reach receivers\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val dstream = new RateLimitInputDStream(ssc) {\n+        override val rateController =\n+          Some(new ReceiverRateController(id, new ConstantEstimator(200.0)))\n+      }\n+      SingletonDummyReceiver.reset()\n+\n+      val output = new TestOutputStreamWithPartitions(dstream)\n+      output.register()\n+      runStreams(ssc, 2, 2)\n+\n+      eventually(timeout(5.seconds)) {\n+        assert(dstream.getCurrentRateLimit === Some(200))\n+      }\n+    }\n+  }\n+\n+  test(\"multiple publish rates reach receivers\") {\n+    val ssc = new StreamingContext(conf, batchDuration)\n+    withStreamingContext(ssc) { ssc =>\n+      val rates = Seq(100L, 200L, 300L)\n+\n+      val dstream = new RateLimitInputDStream(ssc) {\n+        override val rateController =\n+          Some(new ReceiverRateController(id, new ConstantEstimator(rates.map(_.toDouble): _*)))\n+      }\n+      SingletonDummyReceiver.reset()\n+\n+      val output = new TestOutputStreamWithPartitions(dstream)\n+      output.register()\n+\n+      val observedRates = mutable.HashSet.empty[Long]\n+\n+      @volatile var done = false\n+      runInBackground {\n+        while (!done) {\n+          try {\n+            dstream.getCurrentRateLimit.foreach(observedRates += _)\n+          } catch {\n+            case NonFatal(_) => () // don't stop if the executor wasn't installed yet\n+          }\n+          Thread.sleep(20)"
  }],
  "prId": 7600
}]