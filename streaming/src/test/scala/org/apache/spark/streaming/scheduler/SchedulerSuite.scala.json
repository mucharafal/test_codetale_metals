[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Since this code is in ReceiverTracker, please make this the ReceiverTrackerSuite.\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-13T02:08:35Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {"
  }],
  "prId": 6607
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "preferredLocation --> preferred location \n(why use camel case in text, unless it refers to a classname?)\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-13T02:11:09Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {"
  }],
  "prId": 6607
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "You dont test the sizes of the location(x) arrays.\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-13T02:13:15Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")"
  }, {
    "author": {
      "login": "nishkamravi2"
    },
    "body": "Seems redundant\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-17T09:37:09Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "What if the scheduling algorithm allocates it to extra nodes that it should not?\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-18T00:56:24Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")"
  }, {
    "author": {
      "login": "nishkamravi2"
    },
    "body": "In any case, adding a couple more checks doesn't hurt, so will do.\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-18T08:24:38Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")"
  }],
  "prId": 6607
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "There is a lot of duplicate code here. You can put all of the duplicate code in a function, say, \n`def testScheduling(numHosts: Int, numReceivers: Int, receiverToPrefLocations: Map[Int, Int],  expectedSchedule: Seq(Seq(Int)))`\n then you can write all of these unit tests as one-liners\n\n```\ntestScheduling(3, 3, Map.empty, Seq(Seq(1), Seq(2), Seq(3))\ntestScheduling(5, 3, Map.empty, Seq(Seq(1, 2), Seq(3, 4), Seq(5))\ntestScheduling(2, 3, Map.empty, Seq(Seq(1), Seq(2), Seq())\ntestScheduling(3, 3, Map(1 -> 3), Seq(Seq(3), Seq(1), Seq(2), )\n```\n\nIn fact all of them can be one or two `test`s\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-13T02:19:24Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)"
  }, {
    "author": {
      "login": "nishkamravi2"
    },
    "body": "Makes structure brittle, takes away code readability\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-17T09:37:13Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "What do you mean \"structure brittle\" ? What structure? The current approach definitely a lot more verbose than what it can be. \n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-18T00:54:46Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)"
  }, {
    "author": {
      "login": "nishkamravi2"
    },
    "body": "Structure of the four tests, which could evolve separately as opposed to being centralized. The way these tests are written is pretty consistent with the rest of spark test suites, which can be easily read and debugged independently at the cost of slight code duplication. Take a look at JobCancellationSuite for example. What you're suggesting is elegant but adds complexity and makes the code hard to read. If we had a dozen such tests, the verbosity would bother me too. Will try and reduce the number of asserts, I think some of them are redundant. \n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-18T08:26:47Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Well I am not sure how you claim that they are consistent with rest of test suites. As a counterexample, see RDDSuite. How about this for being easier to read? \n\n```\ntestScheduling(numHosts = 3, numReceivers = 3, allocation = \" 1 | 2 | 3 \")\ntestScheduling(numHosts = 5, numReceivers = 3, allocation = \" 1, 2 | 3, 4 | 5 \")\n```\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-18T22:58:31Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)"
  }, {
    "author": {
      "login": "nishkamravi2"
    },
    "body": "Not sure if you looked at JobCancellationSuite as an example. Anyways, this representation is definitely cleaner, let's try and incorporate it in the PR.\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-19T09:03:22Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Glad we reached a consensus! Looking forward to the update.\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-19T23:50:14Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)"
  }],
  "prId": 6607
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Make this private class so that its not used outside this class.\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-13T02:22:48Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(2)(0) === \"Host3\")\n+    assert(locations(0)(1) === \"Host4\")\n+    assert(locations(1)(1) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - all have preferredLocation\") {\n+    val numReceivers = 5;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver(host = Some(\"Host\" + i)))\n+    val executors: List[String] = List(\"Host1\", \"Host5\", \"Host4\", \"Host3\", \"Host2\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(1)(0) === \"Host2\")\n+    assert(locations(4)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - some have preferredLocation\") {\n+    val numReceivers = 3;\n+    val receivers: Seq[Receiver[_]] = Seq(\n+      new DummyReceiver(host = Some(\"Host2\")),\n+      new DummyReceiver,\n+      new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host2\")\n+    assert(locations(1)(0) === \"Host1\")\n+    assert(locations(2)(0) === \"Host2\")\n+    assert(locations(1)(1) === \"Host3\")\n+  }\n+}\n+\n+/**\n+ * Dummy receiver implementation\n+ */\n+class DummyReceiver(host: Option[String] = None) extends Receiver[Int](StorageLevel.MEMORY_ONLY) {"
  }],
  "prId": 6607
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "In this case, Host2 is being used twice, while ideally Host2 should be used only once. There are enough hosts for 3 receivers that receiver3 does not need to be allocated to host2 again.\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-13T02:26:08Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(2)(0) === \"Host3\")\n+    assert(locations(0)(1) === \"Host4\")\n+    assert(locations(1)(1) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - all have preferredLocation\") {\n+    val numReceivers = 5;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver(host = Some(\"Host\" + i)))\n+    val executors: List[String] = List(\"Host1\", \"Host5\", \"Host4\", \"Host3\", \"Host2\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(1)(0) === \"Host2\")\n+    assert(locations(4)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - some have preferredLocation\") {\n+    val numReceivers = 3;\n+    val receivers: Seq[Receiver[_]] = Seq(\n+      new DummyReceiver(host = Some(\"Host2\")),\n+      new DummyReceiver,\n+      new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host2\")"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "I think the algorithm needs to be tweaked a little bit more\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-13T02:26:24Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(2)(0) === \"Host3\")\n+    assert(locations(0)(1) === \"Host4\")\n+    assert(locations(1)(1) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - all have preferredLocation\") {\n+    val numReceivers = 5;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver(host = Some(\"Host\" + i)))\n+    val executors: List[String] = List(\"Host1\", \"Host5\", \"Host4\", \"Host3\", \"Host2\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(1)(0) === \"Host2\")\n+    assert(locations(4)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - some have preferredLocation\") {\n+    val numReceivers = 3;\n+    val receivers: Seq[Receiver[_]] = Seq(\n+      new DummyReceiver(host = Some(\"Host2\")),\n+      new DummyReceiver,\n+      new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host2\")"
  }, {
    "author": {
      "login": "nishkamravi2"
    },
    "body": "That would require priority scheduling, mere tweaking will not do. Mixed receiver type in a single app is a corner case scenario, yet to be encountered in practice. Adding support for it (as we have done in this PR) is different from designing the algorithm around it in an attempt to make the corner case performant.\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-17T09:39:43Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(2)(0) === \"Host3\")\n+    assert(locations(0)(1) === \"Host4\")\n+    assert(locations(1)(1) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - all have preferredLocation\") {\n+    val numReceivers = 5;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver(host = Some(\"Host\" + i)))\n+    val executors: List[String] = List(\"Host1\", \"Host5\", \"Host4\", \"Host3\", \"Host2\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(1)(0) === \"Host2\")\n+    assert(locations(4)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - some have preferredLocation\") {\n+    val numReceivers = 3;\n+    val receivers: Seq[Receiver[_]] = Seq(\n+      new DummyReceiver(host = Some(\"Host2\")),\n+      new DummyReceiver,\n+      new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host2\")"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Alright, we can address this later. This logic is good for now.\n",
    "commit": "191881901f087fdc5484f6c44b856a8843ee5968",
    "createdAt": "2015-06-18T21:34:19Z",
    "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.scheduler\n+\n+import org.apache.spark.streaming._\n+import org.apache.spark.SparkConf\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.receiver._\n+import org.apache.spark.util.Utils\n+\n+/** Testsuite for receiver scheduling */\n+class SchedulerSuite extends TestSuiteBase {\n+  val sparkConf = new SparkConf().setMaster(\"local[8]\").setAppName(\"test\")\n+  val ssc = new StreamingContext(sparkConf, Milliseconds(100))\n+  val tracker = new ReceiverTracker(ssc)\n+  val launcher = new tracker.ReceiverLauncher()\n+\n+  test(\"receiver scheduling - no preferredLocation\") {\n+    val numReceivers = 10;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(4)(0) === \"Host5\")\n+    assert(locations(5)(0) === \"Host1\")\n+    assert(locations(9)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - no preferredLocation, numExecutors > numReceivers\") {\n+    val numReceivers = 3;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host1\")\n+    assert(locations(2)(0) === \"Host3\")\n+    assert(locations(0)(1) === \"Host4\")\n+    assert(locations(1)(1) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - all have preferredLocation\") {\n+    val numReceivers = 5;\n+    val receivers = (1 to numReceivers).map(i => new DummyReceiver(host = Some(\"Host\" + i)))\n+    val executors: List[String] = List(\"Host1\", \"Host5\", \"Host4\", \"Host3\", \"Host2\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(1)(0) === \"Host2\")\n+    assert(locations(4)(0) === \"Host5\")\n+  }\n+\n+  test(\"receiver scheduling - some have preferredLocation\") {\n+    val numReceivers = 3;\n+    val receivers: Seq[Receiver[_]] = Seq(\n+      new DummyReceiver(host = Some(\"Host2\")),\n+      new DummyReceiver,\n+      new DummyReceiver)\n+    val executors: List[String] = List(\"Host1\", \"Host2\", \"Host3\", \"Host4\", \"Host5\")\n+    val locations = launcher.scheduleReceivers(receivers, executors)\n+    assert(locations(0)(0) === \"Host2\")"
  }],
  "prId": 6607
}]