[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "Is the swift jar not included in hadoop-client? Is there a way to specify this through Maven dependencies rather than manually including the path?\n",
    "commit": "9233fef3450846fc6ff1e7e7e3c75191a543a573",
    "createdAt": "2014-06-08T21:01:49Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+---\n+layout: global\n+title: Accessing Openstack Swift storage from Spark\n+---\n+\n+# Accessing Openstack Swift storage from Spark\n+\n+Spark's file interface allows it to process data in Openstack Swift using the same URI formats that are supported for Hadoop. You can specify a path in Swift as input through a URI of the form `swift://<container.service_provider>/path`. You will also need to set your Swift security credentials, through `SparkContext.hadoopConfiguration`. \n+\n+#Configuring Hadoop to use Openstack Swift\n+Openstack Swift driver was merged in Hadoop verion 2.3.0 ([Swift driver](https://issues.apache.org/jira/browse/HADOOP-8545))  Users that wish to use previous Hadoop versions will need to configure Swift driver manually. \n+<h2>Hadoop 2.3.0 and above.</h2>\n+An Openstack Swift driver was merged into Haddop 2.3.0 . Current Hadoop driver requieres Swift to use Keystone authentication. There are additional efforts to support temp auth for Hadoop [Hadoop-10420](https://issues.apache.org/jira/browse/HADOOP-10420).\n+To configure Hadoop to work with Swift one need to modify core-sites.xml of Hadoop and setup Swift FS.\n+  \n+    <configuration>\n+      <property>\n+\t  <name>fs.swift.impl</name>\n+\t    <value>org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem</value>\n+\t  </property>\n+    </configuration>\n+\n+\n+<h2>Configuring Spark - stand alone cluster</h2>\n+You need to configure the compute-classpath.sh and add Hadoop classpath for "
  }],
  "prId": 1010
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "Is this needed? Can we just put this in core-site.xml under conf? (Basically removing the configuring Hadoop section)\n",
    "commit": "9233fef3450846fc6ff1e7e7e3c75191a543a573",
    "createdAt": "2014-06-11T06:02:56Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+yout: global\n+title: Accessing Openstack Swift storage from Spark\n+---\n+\n+# Accessing Openstack Swift storage from Spark\n+\n+Spark's file interface allows it to process data in Openstack Swift using the same URI \n+formats that are supported for Hadoop. You can specify a path in Swift as input through a \n+URI of the form `swift://<container.service_provider>/path`. You will also need to set your \n+Swift security credentials, through `SparkContext.hadoopConfiguration`. \n+\n+#Configuring Hadoop to use Openstack Swift\n+Openstack Swift driver was merged in Hadoop verion 2.3.0 ([Swift driver](https://issues.apache.org/jira/browse/HADOOP-8545)).  Users that wish to use previous Hadoop versions will need to configure Swift driver manually. Current Swift driver \n+requieres Swift to use Keystone authentication method. There are recent efforts to support \n+also temp auth [Hadoop-10420](https://issues.apache.org/jira/browse/HADOOP-10420).\n+To configure Hadoop to work with Swift one need to modify core-sites.xml of Hadoop and \n+setup Swift FS.\n+  \n+\t<configuration>"
  }],
  "prId": 1010
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "Might make sense to make a table or a bullet list for this, instead of just comma separate lists.\n",
    "commit": "9233fef3450846fc6ff1e7e7e3c75191a543a573",
    "createdAt": "2014-06-11T06:06:06Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+yout: global\n+title: Accessing Openstack Swift storage from Spark\n+---\n+\n+# Accessing Openstack Swift storage from Spark\n+\n+Spark's file interface allows it to process data in Openstack Swift using the same URI \n+formats that are supported for Hadoop. You can specify a path in Swift as input through a \n+URI of the form `swift://<container.service_provider>/path`. You will also need to set your \n+Swift security credentials, through `SparkContext.hadoopConfiguration`. \n+\n+#Configuring Hadoop to use Openstack Swift\n+Openstack Swift driver was merged in Hadoop verion 2.3.0 ([Swift driver](https://issues.apache.org/jira/browse/HADOOP-8545)).  Users that wish to use previous Hadoop versions will need to configure Swift driver manually. Current Swift driver \n+requieres Swift to use Keystone authentication method. There are recent efforts to support \n+also temp auth [Hadoop-10420](https://issues.apache.org/jira/browse/HADOOP-10420).\n+To configure Hadoop to work with Swift one need to modify core-sites.xml of Hadoop and \n+setup Swift FS.\n+  \n+\t<configuration>\n+\t\t<property>\n+\t\t\t<name>fs.swift.impl</name>\n+\t\t\t<value>org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem</value>\n+\t\t</property>\n+\t</configuration>\n+\n+#Configuring Swift \n+Proxy server of Swift should include `list_endpoints` middleware. More information \n+available [here] (https://github.com/openstack/swift/blob/master/swift/common/middleware/list_endpoints.py)\n+\n+#Configuring Spark\n+To use Swift driver, Spark need to be compiled with `hadoop-openstack-2.3.0.jar` \n+distributted with Hadoop 2.3.0.  For the Maven builds, Spark's main pom.xml should include \n+\n+\t<swift.version>2.3.0</swift.version>\n+\n+\n+\t<dependency>\n+\t\t<groupId>org.apache.hadoop</groupId>\n+\t\t<artifactId>hadoop-openstack</artifactId>\n+\t\t<version>${swift.version}</version>\n+\t</dependency>\n+\n+in addition, pom.xml of the `core` and `yarn` projects should include\n+\n+\t<dependency>\n+\t\t<groupId>org.apache.hadoop</groupId>\n+\t\t<artifactId>hadoop-openstack</artifactId>\n+\t</dependency>\n+\n+\n+Additional parameters has to be provided to the Swift driver. Swift driver will use those \n+parameters to perform authentication in Keystone prior  accessing Swift. List of mandatory \n+parameters is : `fs.swift.service.<PROVIDER>.auth.url`, "
  }],
  "prId": 1010
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "This is still doable at runtime by setting the job conf, isn't it?\n",
    "commit": "9233fef3450846fc6ff1e7e7e3c75191a543a573",
    "createdAt": "2014-06-11T06:06:41Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+yout: global\n+title: Accessing Openstack Swift storage from Spark\n+---\n+\n+# Accessing Openstack Swift storage from Spark\n+\n+Spark's file interface allows it to process data in Openstack Swift using the same URI \n+formats that are supported for Hadoop. You can specify a path in Swift as input through a \n+URI of the form `swift://<container.service_provider>/path`. You will also need to set your \n+Swift security credentials, through `SparkContext.hadoopConfiguration`. \n+\n+#Configuring Hadoop to use Openstack Swift\n+Openstack Swift driver was merged in Hadoop verion 2.3.0 ([Swift driver](https://issues.apache.org/jira/browse/HADOOP-8545)).  Users that wish to use previous Hadoop versions will need to configure Swift driver manually. Current Swift driver \n+requieres Swift to use Keystone authentication method. There are recent efforts to support \n+also temp auth [Hadoop-10420](https://issues.apache.org/jira/browse/HADOOP-10420).\n+To configure Hadoop to work with Swift one need to modify core-sites.xml of Hadoop and \n+setup Swift FS.\n+  \n+\t<configuration>\n+\t\t<property>\n+\t\t\t<name>fs.swift.impl</name>\n+\t\t\t<value>org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem</value>\n+\t\t</property>\n+\t</configuration>\n+\n+#Configuring Swift \n+Proxy server of Swift should include `list_endpoints` middleware. More information \n+available [here] (https://github.com/openstack/swift/blob/master/swift/common/middleware/list_endpoints.py)\n+\n+#Configuring Spark\n+To use Swift driver, Spark need to be compiled with `hadoop-openstack-2.3.0.jar` \n+distributted with Hadoop 2.3.0.  For the Maven builds, Spark's main pom.xml should include \n+\n+\t<swift.version>2.3.0</swift.version>\n+\n+\n+\t<dependency>\n+\t\t<groupId>org.apache.hadoop</groupId>\n+\t\t<artifactId>hadoop-openstack</artifactId>\n+\t\t<version>${swift.version}</version>\n+\t</dependency>\n+\n+in addition, pom.xml of the `core` and `yarn` projects should include\n+\n+\t<dependency>\n+\t\t<groupId>org.apache.hadoop</groupId>\n+\t\t<artifactId>hadoop-openstack</artifactId>\n+\t</dependency>\n+\n+\n+Additional parameters has to be provided to the Swift driver. Swift driver will use those \n+parameters to perform authentication in Keystone prior  accessing Swift. List of mandatory \n+parameters is : `fs.swift.service.<PROVIDER>.auth.url`, \n+`fs.swift.service.<PROVIDER>.auth.endpoint.prefix`, `fs.swift.service.<PROVIDER>.tenant`, \n+`fs.swift.service.<PROVIDER>.username`,\n+`fs.swift.service.<PROVIDER>.password`, `fs.swift.service.<PROVIDER>.http.port`, \n+`fs.swift.service.<PROVIDER>.http.port`, `fs.swift.service.<PROVIDER>.public`, where \n+`PROVIDER` is any name. `fs.swift.service.<PROVIDER>.auth.url` should point to the Keystone \n+authentication URL.\n+\n+Create core-sites.xml with the mandatory parameters and place it under /spark/conf \n+directory. For example:\n+\n+\n+\t<property>\n+\t\t<name>fs.swift.service.<PROVIDER>.auth.url</name>\n+\t\t<value>http://127.0.0.1:5000/v2.0/tokens</value>\n+\t</property>\n+\t<property>\n+\t\t<name>fs.swift.service.<PROVIDER>.auth.endpoint.prefix</name>\n+\t\t<value>endpoints</value>\n+\t</property>\n+\t\t<name>fs.swift.service.<PROVIDER>.http.port</name>\n+\t\t<value>8080</value>\n+\t</property>\n+\t<property>\n+\t\t<name>fs.swift.service.<PROVIDER>.region</name>\n+\t\t<value>RegionOne</value>\n+\t</property>\n+\t<property>\n+\t\t<name>fs.swift.service.<PROVIDER>.public</name>\n+\t\t<value>true</value>\n+\t</property>\n+\n+We left with `fs.swift.service.<PROVIDER>.tenant`, `fs.swift.service.<PROVIDER>.username`, \n+`fs.swift.service.<PROVIDER>.password`. The best way to provide those parameters to "
  }],
  "prId": 1010
}]