[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I can see providing the sum maybe, but sum of squares (not squared sum right?)? is that useful? I know it's _available_ as a statistic, but i think the question is what will people expect to see here as compared to say https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html This doesn't provide sum although it provides percentiles, but I don't know if we should compute those.",
    "commit": "dcf792b943b11748403d3139e27bcf8c440c6652",
    "createdAt": "2019-11-20T14:27:05Z",
    "diffHunk": "@@ -109,7 +109,8 @@ Refer to the [`ChiSquareTest` Python docs](api/python/index.html#pyspark.ml.stat\n ## Summarizer\n \n We provide vector column summary statistics for `Dataframe` through `Summarizer`.\n-Available metrics are the column-wise max, min, mean, variance, and number of nonzeros, as well as the total count.\n+Available metrics are the column-wise max, min, mean, sum, variance, std, squared sum, and number of nonzeros,"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "I can also see providing stddev instead of variance, but now we'd provide both, which is a little redundant, and we don't want to take away variance as it would unnecessarily break backwards compatibility. I don't know if the sqrt is such a big deal to compute.",
    "commit": "dcf792b943b11748403d3139e27bcf8c440c6652",
    "createdAt": "2019-11-20T14:27:54Z",
    "diffHunk": "@@ -109,7 +109,8 @@ Refer to the [`ChiSquareTest` Python docs](api/python/index.html#pyspark.ml.stat\n ## Summarizer\n \n We provide vector column summary statistics for `Dataframe` through `Summarizer`.\n-Available metrics are the column-wise max, min, mean, variance, and number of nonzeros, as well as the total count.\n+Available metrics are the column-wise max, min, mean, sum, variance, std, squared sum, and number of nonzeros,"
  }, {
    "author": {
      "login": "zhengruifeng"
    },
    "body": "This PR is mainly for convenience:\r\n1, `sum`: existing summarizer does not provide sum of weights, so if I want to compute `sum` in NaiveBayes, I need to use two udafs like `.agg(sum(w).as(\"weightSum\"), Summarizer.metrics(\"mean\", \"count\").summary(validateUDF(col($(featuresCol))), w))`, and then I need to call `BLAS.scal(weightSum, mean)`\r\n2, `std`: I noticed that `std` is more widely used than `variance`;\r\n3, `weightSum`: it is provided in `mllib.MultivariateOnlineSummarizer`, I donot know why `Summarizer` do not expose it.\r\n\r\nIn general I guess that the exisintg OPs of Vectors are not enough, if we can provide new OPs like `sqrt`,`square`,`abs` (like `np.sqrt`,`np.square`,`np.abs` in numpy), then we do not need to add above `std`,`sumL2`.",
    "commit": "dcf792b943b11748403d3139e27bcf8c440c6652",
    "createdAt": "2019-11-21T01:41:22Z",
    "diffHunk": "@@ -109,7 +109,8 @@ Refer to the [`ChiSquareTest` Python docs](api/python/index.html#pyspark.ml.stat\n ## Summarizer\n \n We provide vector column summary statistics for `Dataframe` through `Summarizer`.\n-Available metrics are the column-wise max, min, mean, variance, and number of nonzeros, as well as the total count.\n+Available metrics are the column-wise max, min, mean, sum, variance, std, squared sum, and number of nonzeros,"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "sum and std I can understand. Maybe not weightSum? not sure.\r\nWhat new ops are you imagining here as an alternative? You can already take the sqrt of variance without any new ops.",
    "commit": "dcf792b943b11748403d3139e27bcf8c440c6652",
    "createdAt": "2019-11-21T01:47:28Z",
    "diffHunk": "@@ -109,7 +109,8 @@ Refer to the [`ChiSquareTest` Python docs](api/python/index.html#pyspark.ml.stat\n ## Summarizer\n \n We provide vector column summary statistics for `Dataframe` through `Summarizer`.\n-Available metrics are the column-wise max, min, mean, variance, and number of nonzeros, as well as the total count.\n+Available metrics are the column-wise max, min, mean, sum, variance, std, squared sum, and number of nonzeros,"
  }, {
    "author": {
      "login": "zhengruifeng"
    },
    "body": "Ok, I will update the metrics to only add `std` and `sum`.\r\n\r\n> What new ops are you imagining here as an alternative? \r\n\r\nI guess we may add ops `sqrt`, `square` in `ml.Vector`.\r\n",
    "commit": "dcf792b943b11748403d3139e27bcf8c440c6652",
    "createdAt": "2019-11-25T09:27:55Z",
    "diffHunk": "@@ -109,7 +109,8 @@ Refer to the [`ChiSquareTest` Python docs](api/python/index.html#pyspark.ml.stat\n ## Summarizer\n \n We provide vector column summary statistics for `Dataframe` through `Summarizer`.\n-Available metrics are the column-wise max, min, mean, variance, and number of nonzeros, as well as the total count.\n+Available metrics are the column-wise max, min, mean, sum, variance, std, squared sum, and number of nonzeros,"
  }],
  "prId": 26596
}]