[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "For consistency with the other data sources, `Datasets` -> `Files`?",
    "commit": "17995f92bf4f7b6831f129b558669346a5eafedf",
    "createdAt": "2018-10-18T07:12:20Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+---\n+layout: global\n+title: Other Data Sources\n+displayTitle: Other Data Sources\n+---\n+\n+* Table of contents\n+{:toc}\n+\n+## ORC Files\n+\n+Since Spark 2.3, Spark supports a vectorized ORC reader with a new ORC file format for ORC files.\n+To do that, the following configurations are newly added. The vectorized reader is used for the\n+native ORC tables (e.g., the ones created using the clause `USING ORC`) when `spark.sql.orc.impl`\n+is set to `native` and `spark.sql.orc.enableVectorizedReader` is set to `true`. For the Hive ORC\n+serde tables (e.g., the ones created using the clause `USING HIVE OPTIONS (fileFormat 'ORC')`),\n+the vectorized reader is used when `spark.sql.hive.convertMetastoreOrc` is also set to `true`.\n+\n+<table class=\"table\">\n+  <tr><th><b>Property Name</b></th><th><b>Default</b></th><th><b>Meaning</b></th></tr>\n+  <tr>\n+    <td><code>spark.sql.orc.impl</code></td>\n+    <td><code>native</code></td>\n+    <td>The name of ORC implementation. It can be one of <code>native</code> and <code>hive</code>. <code>native</code> means the native ORC support that is built on Apache ORC 1.4. `hive` means the ORC library in Hive 1.2.1.</td>\n+  </tr>\n+  <tr>\n+    <td><code>spark.sql.orc.enableVectorizedReader</code></td>\n+    <td><code>true</code></td>\n+    <td>Enables vectorized orc decoding in <code>native</code> implementation. If <code>false</code>, a new non-vectorized ORC reader is used in <code>native</code> implementation. For <code>hive</code> implementation, this is ignored.</td>\n+  </tr>\n+</table>\n+\n+## JSON Datasets"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Maybe keep `Datasets`? As the below description `Note that the file that is offered as a json file is not a typical JSON file`. WDYT?",
    "commit": "17995f92bf4f7b6831f129b558669346a5eafedf",
    "createdAt": "2018-10-18T07:58:13Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+---\n+layout: global\n+title: Other Data Sources\n+displayTitle: Other Data Sources\n+---\n+\n+* Table of contents\n+{:toc}\n+\n+## ORC Files\n+\n+Since Spark 2.3, Spark supports a vectorized ORC reader with a new ORC file format for ORC files.\n+To do that, the following configurations are newly added. The vectorized reader is used for the\n+native ORC tables (e.g., the ones created using the clause `USING ORC`) when `spark.sql.orc.impl`\n+is set to `native` and `spark.sql.orc.enableVectorizedReader` is set to `true`. For the Hive ORC\n+serde tables (e.g., the ones created using the clause `USING HIVE OPTIONS (fileFormat 'ORC')`),\n+the vectorized reader is used when `spark.sql.hive.convertMetastoreOrc` is also set to `true`.\n+\n+<table class=\"table\">\n+  <tr><th><b>Property Name</b></th><th><b>Default</b></th><th><b>Meaning</b></th></tr>\n+  <tr>\n+    <td><code>spark.sql.orc.impl</code></td>\n+    <td><code>native</code></td>\n+    <td>The name of ORC implementation. It can be one of <code>native</code> and <code>hive</code>. <code>native</code> means the native ORC support that is built on Apache ORC 1.4. `hive` means the ORC library in Hive 1.2.1.</td>\n+  </tr>\n+  <tr>\n+    <td><code>spark.sql.orc.enableVectorizedReader</code></td>\n+    <td><code>true</code></td>\n+    <td>Enables vectorized orc decoding in <code>native</code> implementation. If <code>false</code>, a new non-vectorized ORC reader is used in <code>native</code> implementation. For <code>hive</code> implementation, this is ignored.</td>\n+  </tr>\n+</table>\n+\n+## JSON Datasets"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "We support a typical JSON file, don't we?\r\n> For a regular multi-line JSON file, set the `multiLine` option to `true`.\r\n\r\nIMO, that notice means we provides more flexibility.",
    "commit": "17995f92bf4f7b6831f129b558669346a5eafedf",
    "createdAt": "2018-10-18T08:31:56Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+---\n+layout: global\n+title: Other Data Sources\n+displayTitle: Other Data Sources\n+---\n+\n+* Table of contents\n+{:toc}\n+\n+## ORC Files\n+\n+Since Spark 2.3, Spark supports a vectorized ORC reader with a new ORC file format for ORC files.\n+To do that, the following configurations are newly added. The vectorized reader is used for the\n+native ORC tables (e.g., the ones created using the clause `USING ORC`) when `spark.sql.orc.impl`\n+is set to `native` and `spark.sql.orc.enableVectorizedReader` is set to `true`. For the Hive ORC\n+serde tables (e.g., the ones created using the clause `USING HIVE OPTIONS (fileFormat 'ORC')`),\n+the vectorized reader is used when `spark.sql.hive.convertMetastoreOrc` is also set to `true`.\n+\n+<table class=\"table\">\n+  <tr><th><b>Property Name</b></th><th><b>Default</b></th><th><b>Meaning</b></th></tr>\n+  <tr>\n+    <td><code>spark.sql.orc.impl</code></td>\n+    <td><code>native</code></td>\n+    <td>The name of ORC implementation. It can be one of <code>native</code> and <code>hive</code>. <code>native</code> means the native ORC support that is built on Apache ORC 1.4. `hive` means the ORC library in Hive 1.2.1.</td>\n+  </tr>\n+  <tr>\n+    <td><code>spark.sql.orc.enableVectorizedReader</code></td>\n+    <td><code>true</code></td>\n+    <td>Enables vectorized orc decoding in <code>native</code> implementation. If <code>false</code>, a new non-vectorized ORC reader is used in <code>native</code> implementation. For <code>hive</code> implementation, this is ignored.</td>\n+  </tr>\n+</table>\n+\n+## JSON Datasets"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Got it, will change it soon.",
    "commit": "17995f92bf4f7b6831f129b558669346a5eafedf",
    "createdAt": "2018-10-18T09:06:38Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+---\n+layout: global\n+title: Other Data Sources\n+displayTitle: Other Data Sources\n+---\n+\n+* Table of contents\n+{:toc}\n+\n+## ORC Files\n+\n+Since Spark 2.3, Spark supports a vectorized ORC reader with a new ORC file format for ORC files.\n+To do that, the following configurations are newly added. The vectorized reader is used for the\n+native ORC tables (e.g., the ones created using the clause `USING ORC`) when `spark.sql.orc.impl`\n+is set to `native` and `spark.sql.orc.enableVectorizedReader` is set to `true`. For the Hive ORC\n+serde tables (e.g., the ones created using the clause `USING HIVE OPTIONS (fileFormat 'ORC')`),\n+the vectorized reader is used when `spark.sql.hive.convertMetastoreOrc` is also set to `true`.\n+\n+<table class=\"table\">\n+  <tr><th><b>Property Name</b></th><th><b>Default</b></th><th><b>Meaning</b></th></tr>\n+  <tr>\n+    <td><code>spark.sql.orc.impl</code></td>\n+    <td><code>native</code></td>\n+    <td>The name of ORC implementation. It can be one of <code>native</code> and <code>hive</code>. <code>native</code> means the native ORC support that is built on Apache ORC 1.4. `hive` means the ORC library in Hive 1.2.1.</td>\n+  </tr>\n+  <tr>\n+    <td><code>spark.sql.orc.enableVectorizedReader</code></td>\n+    <td><code>true</code></td>\n+    <td>Enables vectorized orc decoding in <code>native</code> implementation. If <code>false</code>, a new non-vectorized ORC reader is used in <code>native</code> implementation. For <code>hive</code> implementation, this is ignored.</td>\n+  </tr>\n+</table>\n+\n+## JSON Datasets"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Done in 17995f9. Thanks!",
    "commit": "17995f92bf4f7b6831f129b558669346a5eafedf",
    "createdAt": "2018-10-18T12:43:20Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+---\n+layout: global\n+title: Other Data Sources\n+displayTitle: Other Data Sources\n+---\n+\n+* Table of contents\n+{:toc}\n+\n+## ORC Files\n+\n+Since Spark 2.3, Spark supports a vectorized ORC reader with a new ORC file format for ORC files.\n+To do that, the following configurations are newly added. The vectorized reader is used for the\n+native ORC tables (e.g., the ones created using the clause `USING ORC`) when `spark.sql.orc.impl`\n+is set to `native` and `spark.sql.orc.enableVectorizedReader` is set to `true`. For the Hive ORC\n+serde tables (e.g., the ones created using the clause `USING HIVE OPTIONS (fileFormat 'ORC')`),\n+the vectorized reader is used when `spark.sql.hive.convertMetastoreOrc` is also set to `true`.\n+\n+<table class=\"table\">\n+  <tr><th><b>Property Name</b></th><th><b>Default</b></th><th><b>Meaning</b></th></tr>\n+  <tr>\n+    <td><code>spark.sql.orc.impl</code></td>\n+    <td><code>native</code></td>\n+    <td>The name of ORC implementation. It can be one of <code>native</code> and <code>hive</code>. <code>native</code> means the native ORC support that is built on Apache ORC 1.4. `hive` means the ORC library in Hive 1.2.1.</td>\n+  </tr>\n+  <tr>\n+    <td><code>spark.sql.orc.enableVectorizedReader</code></td>\n+    <td><code>true</code></td>\n+    <td>Enables vectorized orc decoding in <code>native</code> implementation. If <code>false</code>, a new non-vectorized ORC reader is used in <code>native</code> implementation. For <code>hive</code> implementation, this is ignored.</td>\n+  </tr>\n+</table>\n+\n+## JSON Datasets"
  }],
  "prId": 22746
}]