[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`0 - 255` -> `0 to 255`\n",
    "commit": "ef96916254bd1f1f3eacbed98dbfe383dd1338e5",
    "createdAt": "2015-06-29T05:49:36Z",
    "diffHunk": "@@ -405,7 +405,7 @@ Note that the user can also construct a `ChiSqSelectorModel` by hand by providin\n \n #### Example\n \n-The following example shows the basic use of ChiSqSelector.\n+The following example shows the basic use of ChiSqSelector. The data set used has a feature matrix consisting of greyscale values that vary from 0 - 255 for each feature."
  }],
  "prId": 7029
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "remove the extra space after 50\n",
    "commit": "ef96916254bd1f1f3eacbed98dbfe383dd1338e5",
    "createdAt": "2015-06-29T05:49:37Z",
    "diffHunk": "@@ -419,10 +419,11 @@ import org.apache.spark.mllib.feature.ChiSqSelector\n // Load some data in libsvm format\n val data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_libsvm_data.txt\")\n // Discretize data in 16 equal bins since ChiSqSelector requires categorical features\n+// Even though features are doubles, the ChiSqSelector treats each unique value as a category\n val discretizedData = data.map { lp =>\n-  LabeledPoint(lp.label, Vectors.dense(lp.features.toArray.map { x => x / 16 } ) )\n+  LabeledPoint(lp.label, Vectors.dense(lp.features.toArray.map { x => (x / 16).floor } ) )\n }\n-// Create ChiSqSelector that will select 50 features\n+// Create ChiSqSelector that will select top 50  of 692 features"
  }],
  "prId": 7029
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "do not use tab\n",
    "commit": "ef96916254bd1f1f3eacbed98dbfe383dd1338e5",
    "createdAt": "2015-06-29T05:49:39Z",
    "diffHunk": "@@ -451,19 +452,20 @@ JavaRDD<LabeledPoint> points = MLUtils.loadLibSVMFile(sc.sc(),\n     \"data/mllib/sample_libsvm_data.txt\").toJavaRDD().cache();\n \n // Discretize data in 16 equal bins since ChiSqSelector requires categorical features\n+// Even though features are doubles, the ChiSqSelector treats each unique value as a category\n JavaRDD<LabeledPoint> discretizedData = points.map(\n     new Function<LabeledPoint, LabeledPoint>() {\n       @Override\n       public LabeledPoint call(LabeledPoint lp) {\n         final double[] discretizedFeatures = new double[lp.features().size()];\n         for (int i = 0; i < lp.features().size(); ++i) {\n-          discretizedFeatures[i] = lp.features().apply(i) / 16;\n+        \tdiscretizedFeatures[i] = Math.floor(lp.features().apply(i) / 16);"
  }],
  "prId": 7029
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "remove the extra space after `50`\n",
    "commit": "ef96916254bd1f1f3eacbed98dbfe383dd1338e5",
    "createdAt": "2015-06-29T05:49:40Z",
    "diffHunk": "@@ -451,19 +452,20 @@ JavaRDD<LabeledPoint> points = MLUtils.loadLibSVMFile(sc.sc(),\n     \"data/mllib/sample_libsvm_data.txt\").toJavaRDD().cache();\n \n // Discretize data in 16 equal bins since ChiSqSelector requires categorical features\n+// Even though features are doubles, the ChiSqSelector treats each unique value as a category\n JavaRDD<LabeledPoint> discretizedData = points.map(\n     new Function<LabeledPoint, LabeledPoint>() {\n       @Override\n       public LabeledPoint call(LabeledPoint lp) {\n         final double[] discretizedFeatures = new double[lp.features().size()];\n         for (int i = 0; i < lp.features().size(); ++i) {\n-          discretizedFeatures[i] = lp.features().apply(i) / 16;\n+        \tdiscretizedFeatures[i] = Math.floor(lp.features().apply(i) / 16);\n         }\n         return new LabeledPoint(lp.label(), Vectors.dense(discretizedFeatures));\n       }\n     });\n \n-// Create ChiSqSelector that will select 50 features\n+// Create ChiSqSelector that will select top 50  of 692 features"
  }],
  "prId": 7029
}]