[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We can define a parse function to make the code more readable. Btw, we use 4 space indentation in Python, following PEP8.\n\n``` python\ndef parseLine(line):\n    parts = line.split(',')\n    label = float(parts[0])\n    features = Vector.dense([float(x) for x in parts[1].split(' ')])\n    return LabeledPoint(label, features)\n\ndata = sc.textFile('data/mllib/sample_naive_bayes_data.txt').map(parseLine)\n```\n",
    "commit": "1cdd7b5a03e99810fe8ecc340fd933d7294ff15e",
    "createdAt": "2015-03-01T18:34:09Z",
    "diffHunk": "@@ -115,22 +115,31 @@ used for evaluation and prediction.\n \n Note that the Python API does not yet support model save/load but will in the future.\n \n-<!-- TODO: Make Python's example consistent with Scala's and Java's. -->\n {% highlight python %}\n-from pyspark.mllib.regression import LabeledPoint\n from pyspark.mllib.classification import NaiveBayes\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.regression import LabeledPoint\n+\n+data = sc.textFile(\"data/mllib/sample_naive_bayes_data.txt\")\n+\n+# Preprocessing\n+splitData = data.map(lambda line: line.split(','))\n+parsedData = splitData.map("
  }],
  "prId": 4834
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`data into` -> `data approximately into`.\n",
    "commit": "1cdd7b5a03e99810fe8ecc340fd933d7294ff15e",
    "createdAt": "2015-03-01T18:34:31Z",
    "diffHunk": "@@ -115,22 +115,31 @@ used for evaluation and prediction.\n \n Note that the Python API does not yet support model save/load but will in the future.\n \n-<!-- TODO: Make Python's example consistent with Scala's and Java's. -->\n {% highlight python %}\n-from pyspark.mllib.regression import LabeledPoint\n from pyspark.mllib.classification import NaiveBayes\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.regression import LabeledPoint\n+\n+data = sc.textFile(\"data/mllib/sample_naive_bayes_data.txt\")\n+\n+# Preprocessing\n+splitData = data.map(lambda line: line.split(','))\n+parsedData = splitData.map(\n+  lambda parts: LabeledPoint(\n+    float(parts[0]),\n+    Vectors.dense(map(lambda x: float(x), parts[1].split(' ')))\n+    )\n+  )\n \n-# an RDD of LabeledPoint\n-data = sc.parallelize([\n-  LabeledPoint(0.0, [0.0, 0.0])\n-  ... # more labeled points\n-])\n+# Split data into training (60%) and test (40%)"
  }],
  "prId": 4834
}]