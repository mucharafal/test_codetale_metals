[{
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Provide an example command to build the sdist package?\n",
    "commit": "e1398552469288de3829eb889fec0de2ba568f15",
    "createdAt": "2016-10-28T08:40:09Z",
    "diffHunk": "@@ -259,6 +259,12 @@ or\n Java 8 tests are automatically enabled when a Java 8 JDK is detected.\n If you have JDK 8 installed but it is not the system default, you can set JAVA_HOME to point to JDK 8 before running the tests.\n \n+## PySpark pip installable\n+\n+If your are building Spark for use in a Python environment and you wish to pip install it, you will first need to build the Spark JARs as described above. Then you can construct an sdist package suitable for setup.py and pip installable package."
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "Sounds like a good idea, I'll add that. Its currently built as part of make-release too but incase someone wants to roll their own patches should cover it.\n",
    "commit": "e1398552469288de3829eb889fec0de2ba568f15",
    "createdAt": "2016-10-28T10:32:18Z",
    "diffHunk": "@@ -259,6 +259,12 @@ or\n Java 8 tests are automatically enabled when a Java 8 JDK is detected.\n If you have JDK 8 installed but it is not the system default, you can set JAVA_HOME to point to JDK 8 before running the tests.\n \n+## PySpark pip installable\n+\n+If your are building Spark for use in a Python environment and you wish to pip install it, you will first need to build the Spark JARs as described above. Then you can construct an sdist package suitable for setup.py and pip installable package."
  }],
  "prId": 15659
}, {
  "comments": [{
    "author": {
      "login": "rgbkrk"
    },
    "body": "I just noticed a typo above here:\n\n...If you are...\n",
    "commit": "e1398552469288de3829eb889fec0de2ba568f15",
    "createdAt": "2016-10-30T15:34:56Z",
    "diffHunk": "@@ -263,6 +263,8 @@ If you have JDK 8 installed but it is not the system default, you can set JAVA_H\n \n If your are building Spark for use in a Python environment and you wish to pip install it, you will first need to build the Spark JARs as described above. Then you can construct an sdist package suitable for setup.py and pip installable package.\n "
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "Thanks :)\n",
    "commit": "e1398552469288de3829eb889fec0de2ba568f15",
    "createdAt": "2016-10-31T01:11:05Z",
    "diffHunk": "@@ -263,6 +263,8 @@ If you have JDK 8 installed but it is not the system default, you can set JAVA_H\n \n If your are building Spark for use in a Python environment and you wish to pip install it, you will first need to build the Spark JARs as described above. Then you can construct an sdist package suitable for setup.py and pip installable package.\n "
  }],
  "prId": 15659
}, {
  "comments": [{
    "author": {
      "login": "nchammas"
    },
    "body": "Just to confirm, if I run this:\n\n```\n./dev/make-distribution.sh --pip\n```\n\nIt should take care of both building the right JARs _and_ building the Python package.\n\nThen I just run:\n\n```\npip install -e ./python/\n```\n\nto install Spark into my Python environment.\n\nIs that all correct?\n",
    "commit": "e1398552469288de3829eb889fec0de2ba568f15",
    "createdAt": "2016-11-05T16:11:35Z",
    "diffHunk": "@@ -259,6 +259,14 @@ or\n Java 8 tests are automatically enabled when a Java 8 JDK is detected.\n If you have JDK 8 installed but it is not the system default, you can set JAVA_HOME to point to JDK 8 before running the tests.\n \n+## PySpark pip installable\n+\n+If you are building Spark for use in a Python environment and you wish to pip install it, you will first need to build the Spark JARs as described above. Then you can construct an sdist package suitable for setup.py and pip installable package.\n+\n+    cd python; python setup.py sdist",
    "line": 8
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "So `make-distribution.sh` will copy the files into the distribution directory. If you just want to test the pip install part `./build/sbt package;cd python; python setup.py sdist; cd dist; pip install *.tar.gz` should do the trick.\n",
    "commit": "e1398552469288de3829eb889fec0de2ba568f15",
    "createdAt": "2016-11-05T22:53:20Z",
    "diffHunk": "@@ -259,6 +259,14 @@ or\n Java 8 tests are automatically enabled when a Java 8 JDK is detected.\n If you have JDK 8 installed but it is not the system default, you can set JAVA_HOME to point to JDK 8 before running the tests.\n \n+## PySpark pip installable\n+\n+If you are building Spark for use in a Python environment and you wish to pip install it, you will first need to build the Spark JARs as described above. Then you can construct an sdist package suitable for setup.py and pip installable package.\n+\n+    cd python; python setup.py sdist",
    "line": 8
  }],
  "prId": 15659
}]