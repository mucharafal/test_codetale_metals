[{
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "pathGlobFilter  -> binaryFile",
    "commit": "847ff7f51f8f3f351e3c0cc5776b0408cc6dc0e6",
    "createdAt": "2019-04-29T08:08:15Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+---\n+layout: global\n+title: Binary File Data Source\n+displayTitle: Binary File Data Source\n+license: |\n+  Licensed to the Apache Software Foundation (ASF) under one or more\n+  contributor license agreements.  See the NOTICE file distributed with\n+  this work for additional information regarding copyright ownership.\n+  The ASF licenses this file to You under the Apache License, Version 2.0\n+  (the \"License\"); you may not use this file except in compliance with\n+  the License.  You may obtain a copy of the License at\n+ \n+     http://www.apache.org/licenses/LICENSE-2.0\n+ \n+  Unless required by applicable law or agreed to in writing, software\n+  distributed under the License is distributed on an \"AS IS\" BASIS,\n+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  See the License for the specific language governing permissions and\n+  limitations under the License.\n+---\n+\n+Since Spark 3.0, Spark supports binary file data source,\n+which reads binary files and converts each file into a single record that contains the raw content\n+and metadata of the file.\n+It produces a DataFrame with the following columns and possibly partition columns:\n+* `path`: StringType\n+* `modificationTime`: TimestampType\n+* `length`: LongType\n+* `content`: BinaryType\n+\n+It supports the following read option:\n+<table class=\"table\">\n+  <tr><th><b>Property Name</b></th><th><b>Default</b></th><th><b>Meaning</b></th></tr>\n+  <tr>\n+    <td><code>pathGlobFilter</code></td>\n+    <td>none (accepts all)</td>\n+    <td>\n+    An optional glob pattern to only include files with paths matching the pattern.\n+    The syntax follows <code>org.apache.hadoop.fs.GlobFilter</code>.\n+    It does not change the behaivor of partition discovery.\n+    </td>\n+  </tr>\n+</table>\n+\n+To read whole binary files, you need to specify the data source `format` as `binaryFile`.\n+For example, the following code reads all PNG files from the input directory:\n+\n+<div class=\"codetabs\">\n+<div data-lang=\"scala\" markdown=\"1\">\n+{% highlight scala %}\n+\n+spark.read.format(\"binaryFile\").option(\"pathGlobFilter\", \"*.png\").load(\"/path/to/data\")\n+\n+{% endhighlight %}\n+</div>\n+\n+<div data-lang=\"java\" markdown=\"1\">\n+{% highlight java %}\n+\n+spark.read().format(\"binaryFile\").option(\"pathGlobFilter\", \"*.png\").load(\"/path/to/data\");\n+\n+{% endhighlight %}\n+</div>\n+<div data-lang=\"python\" markdown=\"1\">\n+{% highlight python %}\n+\n+spark.read.format(\"pathGlobFilter\").option(\"pathGlobFilter\", \"*.png\").load(\"/path/to/data\")"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Thanks for the catch! Updated.",
    "commit": "847ff7f51f8f3f351e3c0cc5776b0408cc6dc0e6",
    "createdAt": "2019-04-29T13:26:12Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+---\n+layout: global\n+title: Binary File Data Source\n+displayTitle: Binary File Data Source\n+license: |\n+  Licensed to the Apache Software Foundation (ASF) under one or more\n+  contributor license agreements.  See the NOTICE file distributed with\n+  this work for additional information regarding copyright ownership.\n+  The ASF licenses this file to You under the Apache License, Version 2.0\n+  (the \"License\"); you may not use this file except in compliance with\n+  the License.  You may obtain a copy of the License at\n+ \n+     http://www.apache.org/licenses/LICENSE-2.0\n+ \n+  Unless required by applicable law or agreed to in writing, software\n+  distributed under the License is distributed on an \"AS IS\" BASIS,\n+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  See the License for the specific language governing permissions and\n+  limitations under the License.\n+---\n+\n+Since Spark 3.0, Spark supports binary file data source,\n+which reads binary files and converts each file into a single record that contains the raw content\n+and metadata of the file.\n+It produces a DataFrame with the following columns and possibly partition columns:\n+* `path`: StringType\n+* `modificationTime`: TimestampType\n+* `length`: LongType\n+* `content`: BinaryType\n+\n+It supports the following read option:\n+<table class=\"table\">\n+  <tr><th><b>Property Name</b></th><th><b>Default</b></th><th><b>Meaning</b></th></tr>\n+  <tr>\n+    <td><code>pathGlobFilter</code></td>\n+    <td>none (accepts all)</td>\n+    <td>\n+    An optional glob pattern to only include files with paths matching the pattern.\n+    The syntax follows <code>org.apache.hadoop.fs.GlobFilter</code>.\n+    It does not change the behaivor of partition discovery.\n+    </td>\n+  </tr>\n+</table>\n+\n+To read whole binary files, you need to specify the data source `format` as `binaryFile`.\n+For example, the following code reads all PNG files from the input directory:\n+\n+<div class=\"codetabs\">\n+<div data-lang=\"scala\" markdown=\"1\">\n+{% highlight scala %}\n+\n+spark.read.format(\"binaryFile\").option(\"pathGlobFilter\", \"*.png\").load(\"/path/to/data\")\n+\n+{% endhighlight %}\n+</div>\n+\n+<div data-lang=\"java\" markdown=\"1\">\n+{% highlight java %}\n+\n+spark.read().format(\"binaryFile\").option(\"pathGlobFilter\", \"*.png\").load(\"/path/to/data\");\n+\n+{% endhighlight %}\n+</div>\n+<div data-lang=\"python\" markdown=\"1\">\n+{% highlight python %}\n+\n+spark.read.format(\"pathGlobFilter\").option(\"pathGlobFilter\", \"*.png\").load(\"/path/to/data\")"
  }],
  "prId": 24484
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "typo: behaivor -> behavior ",
    "commit": "847ff7f51f8f3f351e3c0cc5776b0408cc6dc0e6",
    "createdAt": "2019-04-29T09:58:56Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+---\n+layout: global\n+title: Binary File Data Source\n+displayTitle: Binary File Data Source\n+license: |\n+  Licensed to the Apache Software Foundation (ASF) under one or more\n+  contributor license agreements.  See the NOTICE file distributed with\n+  this work for additional information regarding copyright ownership.\n+  The ASF licenses this file to You under the Apache License, Version 2.0\n+  (the \"License\"); you may not use this file except in compliance with\n+  the License.  You may obtain a copy of the License at\n+ \n+     http://www.apache.org/licenses/LICENSE-2.0\n+ \n+  Unless required by applicable law or agreed to in writing, software\n+  distributed under the License is distributed on an \"AS IS\" BASIS,\n+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  See the License for the specific language governing permissions and\n+  limitations under the License.\n+---\n+\n+Since Spark 3.0, Spark supports binary file data source,\n+which reads binary files and converts each file into a single record that contains the raw content\n+and metadata of the file.\n+It produces a DataFrame with the following columns and possibly partition columns:\n+* `path`: StringType\n+* `modificationTime`: TimestampType\n+* `length`: LongType\n+* `content`: BinaryType\n+\n+It supports the following read option:\n+<table class=\"table\">\n+  <tr><th><b>Property Name</b></th><th><b>Default</b></th><th><b>Meaning</b></th></tr>\n+  <tr>\n+    <td><code>pathGlobFilter</code></td>\n+    <td>none (accepts all)</td>\n+    <td>\n+    An optional glob pattern to only include files with paths matching the pattern.\n+    The syntax follows <code>org.apache.hadoop.fs.GlobFilter</code>.\n+    It does not change the behaivor of partition discovery."
  }],
  "prId": 24484
}]