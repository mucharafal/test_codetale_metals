[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "nit. `1.2.1 You` -> `1.2.1. You`",
    "commit": "17995f92bf4f7b6831f129b558669346a5eafedf",
    "createdAt": "2018-10-18T07:17:02Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+---\n+layout: global\n+title: Distributed SQL Engine\n+displayTitle: Distributed SQL Engine\n+---\n+\n+* Table of contents\n+{:toc}\n+\n+Spark SQL can also act as a distributed query engine using its JDBC/ODBC or command-line interface.\n+In this mode, end-users or applications can interact with Spark SQL directly to run SQL queries,\n+without the need to write any code.\n+\n+## Running the Thrift JDBC/ODBC server\n+\n+The Thrift JDBC/ODBC server implemented here corresponds to the [`HiveServer2`](https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2)\n+in Hive 1.2.1 You can test the JDBC server with the beeline script that comes with either Spark or Hive 1.2.1."
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Thanks, done in 27b066d.",
    "commit": "17995f92bf4f7b6831f129b558669346a5eafedf",
    "createdAt": "2018-10-18T08:17:22Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+---\n+layout: global\n+title: Distributed SQL Engine\n+displayTitle: Distributed SQL Engine\n+---\n+\n+* Table of contents\n+{:toc}\n+\n+Spark SQL can also act as a distributed query engine using its JDBC/ODBC or command-line interface.\n+In this mode, end-users or applications can interact with Spark SQL directly to run SQL queries,\n+without the need to write any code.\n+\n+## Running the Thrift JDBC/ODBC server\n+\n+The Thrift JDBC/ODBC server implemented here corresponds to the [`HiveServer2`](https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2)\n+in Hive 1.2.1 You can test the JDBC server with the beeline script that comes with either Spark or Hive 1.2.1."
  }],
  "prId": 22746
}, {
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "super nit: this line can be concatenated with the previous line.",
    "commit": "17995f92bf4f7b6831f129b558669346a5eafedf",
    "createdAt": "2018-10-18T09:52:57Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+---\n+layout: global\n+title: Distributed SQL Engine\n+displayTitle: Distributed SQL Engine\n+---\n+\n+* Table of contents\n+{:toc}\n+\n+Spark SQL can also act as a distributed query engine using its JDBC/ODBC or command-line interface.\n+In this mode, end-users or applications can interact with Spark SQL directly to run SQL queries,\n+without the need to write any code.\n+\n+## Running the Thrift JDBC/ODBC server\n+\n+The Thrift JDBC/ODBC server implemented here corresponds to the [`HiveServer2`](https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2)\n+in Hive 1.2.1. You can test the JDBC server with the beeline script that comes with either Spark or Hive 1.2.1.\n+\n+To start the JDBC/ODBC server, run the following in the Spark directory:\n+\n+    ./sbin/start-thriftserver.sh\n+\n+This script accepts all `bin/spark-submit` command line options, plus a `--hiveconf` option to\n+specify Hive properties. You may run `./sbin/start-thriftserver.sh --help` for a complete list of\n+all available options. By default, the server listens on localhost:10000. You may override this\n+behaviour via either environment variables, i.e.:\n+\n+{% highlight bash %}\n+export HIVE_SERVER2_THRIFT_PORT=<listening-port>\n+export HIVE_SERVER2_THRIFT_BIND_HOST=<listening-host>\n+./sbin/start-thriftserver.sh \\\n+  --master <master-uri> \\\n+  ...\n+{% endhighlight %}\n+\n+or system properties:\n+\n+{% highlight bash %}\n+./sbin/start-thriftserver.sh \\\n+  --hiveconf hive.server2.thrift.port=<listening-port> \\\n+  --hiveconf hive.server2.thrift.bind.host=<listening-host> \\\n+  --master <master-uri>\n+  ...\n+{% endhighlight %}\n+\n+Now you can use beeline to test the Thrift JDBC/ODBC server:\n+\n+    ./bin/beeline\n+\n+Connect to the JDBC/ODBC server in beeline with:\n+\n+    beeline> !connect jdbc:hive2://localhost:10000\n+\n+Beeline will ask you for a username and password. In non-secure mode, simply enter the username on\n+your machine and a blank password. For secure mode, please follow the instructions given in the\n+[beeline documentation](https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients).\n+\n+Configuration of Hive is done by placing your `hive-site.xml`, `core-site.xml` and `hdfs-site.xml` files in `conf/`.\n+\n+You may also use the beeline script that comes with Hive.\n+\n+Thrift JDBC server also supports sending thrift RPC messages over HTTP transport.\n+Use the following setting to enable HTTP mode as system property or in `hive-site.xml` file in `conf/`:\n+\n+    hive.server2.transport.mode - Set this to value: http\n+    hive.server2.thrift.http.port - HTTP port number to listen on; default is 10001\n+    hive.server2.http.endpoint - HTTP endpoint; default is cliservice\n+\n+To test, use beeline to connect to the JDBC/ODBC server in http mode with:\n+\n+    beeline> !connect jdbc:hive2://<host>:<port>/<database>?hive.server2.transport.mode=http;hive.server2.thrift.http.path=<http_endpoint>\n+\n+\n+## Running the Spark SQL CLI\n+\n+The Spark SQL CLI is a convenient tool to run the Hive metastore service in local mode and execute\n+queries input from the command line. Note that the Spark SQL CLI cannot talk to the Thrift JDBC server.\n+\n+To start the Spark SQL CLI, run the following in the Spark directory:\n+\n+    ./bin/spark-sql\n+\n+Configuration of Hive is done by placing your `hive-site.xml`, `core-site.xml` and `hdfs-site.xml` files in `conf/`.\n+You may run `./bin/spark-sql --help` for a complete list of all available\n+options."
  }],
  "prId": 22746
}]