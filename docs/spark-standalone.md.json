[{
  "comments": [{
    "author": {
      "login": "attilapiros"
    },
    "body": "Why have you changed this default value in the documentation? As I see it is still false.\r\n\r\nhttps://github.com/apache/spark/blob/b15423361bc28c4cd2216683eb852fdbec3ea58f/core/src/main/scala/org/apache/spark/internal/config/Worker.scala#L31-L33",
    "commit": "475d27817b6ef37eed9b7b39fee709427811f0d6",
    "createdAt": "2019-03-12T14:47:06Z",
    "diffHunk": "@@ -235,10 +235,11 @@ SPARK_WORKER_OPTS supports the following system properties:\n <tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr>\n <tr>\n   <td><code>spark.worker.cleanup.enabled</code></td>\n-  <td>false</td>\n+  <td>true</td>"
  }, {
    "author": {
      "login": "weixiuli"
    },
    "body": "sorry,i missed it.",
    "commit": "475d27817b6ef37eed9b7b39fee709427811f0d6",
    "createdAt": "2019-03-13T01:12:20Z",
    "diffHunk": "@@ -235,10 +235,11 @@ SPARK_WORKER_OPTS supports the following system properties:\n <tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr>\n <tr>\n   <td><code>spark.worker.cleanup.enabled</code></td>\n-  <td>false</td>\n+  <td>true</td>"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "I believe attila meant to revert your change to the docs, not to change the default",
    "commit": "475d27817b6ef37eed9b7b39fee709427811f0d6",
    "createdAt": "2019-03-15T22:00:52Z",
    "diffHunk": "@@ -235,10 +235,11 @@ SPARK_WORKER_OPTS supports the following system properties:\n <tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr>\n <tr>\n   <td><code>spark.worker.cleanup.enabled</code></td>\n-  <td>false</td>\n+  <td>true</td>"
  }],
  "prId": 23393
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "Some minor rewordings:\r\n\r\n```\r\nStore External Shuffle service state on local disk so that when the external shuffle service is restarted, it will\r\nautomatically reload info on current executors.  This only affects standalone mode (yarn always has this behavior\r\nenabled).  You should also enable <code>spark.worker.cleanup.enabled</code>, to ensure that the state\r\neventually gets cleaned up.  This config may be removed in the future.\r\n```",
    "commit": "475d27817b6ef37eed9b7b39fee709427811f0d6",
    "createdAt": "2019-03-15T22:03:50Z",
    "diffHunk": "@@ -260,6 +261,17 @@ SPARK_WORKER_OPTS supports the following system properties:\n     especially if you run jobs very frequently.\n   </td>\n </tr>\n+<tr>\n+  <td><spark.shuffle.service.db.enabled</code></td>\n+  <td>true</td>\n+  <td>\n+    Enable record RegisteredExecutors information by leveldb, which can be reloaded and\n+    used again when the external shuffle service is restarted. Note that this only affects standalone\n+    mode, its has always on for yarn. We should Enable `spark.worker.cleanup.enabled` to remove the entry\n+    (It will leave an entry in the DB forever when an application is stopped while the external shuffle\n+    service is down) in the leveldb with WorkDirCleanup. It may be removed in the future."
  }, {
    "author": {
      "login": "weixiuli"
    },
    "body": "Very clear description, thank you.",
    "commit": "475d27817b6ef37eed9b7b39fee709427811f0d6",
    "createdAt": "2019-03-16T00:40:30Z",
    "diffHunk": "@@ -260,6 +261,17 @@ SPARK_WORKER_OPTS supports the following system properties:\n     especially if you run jobs very frequently.\n   </td>\n </tr>\n+<tr>\n+  <td><spark.shuffle.service.db.enabled</code></td>\n+  <td>true</td>\n+  <td>\n+    Enable record RegisteredExecutors information by leveldb, which can be reloaded and\n+    used again when the external shuffle service is restarted. Note that this only affects standalone\n+    mode, its has always on for yarn. We should Enable `spark.worker.cleanup.enabled` to remove the entry\n+    (It will leave an entry in the DB forever when an application is stopped while the external shuffle\n+    service is down) in the leveldb with WorkDirCleanup. It may be removed in the future."
  }],
  "prId": 23393
}]