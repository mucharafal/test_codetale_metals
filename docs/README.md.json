[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Let me take out this change in this PR, actually. It makes backporting harder",
    "commit": "2e1e7da3111129907704f02e8d20a2894f22465d",
    "createdAt": "2018-07-10T01:49:24Z",
    "diffHunk": "@@ -69,7 +69,8 @@ You can build just the Spark scaladoc and javadoc by running `build/sbt unidoc`\n \n Similarly, you can build just the PySpark docs by running `make html` from the\n `$SPARK_HOME/python/docs` directory. Documentation is only generated for classes that are listed as\n-public in `__init__.py`. The SparkR docs can be built by running `$SPARK_HOME/R/create-docs.sh`, and\n+public in `__init__.py`. You can also set `SPHINXPYTHON` to specify the Python executable to use with Sphinx.\n+ The SparkR docs can be built by running `$SPARK_HOME/R/create-docs.sh`, and"
  }],
  "prId": 21659
}]