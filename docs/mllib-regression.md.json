[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Use the DOI link http://doi.org/10.1198/TECH.2010.10111 instead, which probably lives longer.\n",
    "commit": "67fe773f4046abc12d6f116afe285e68df5ce6ae",
    "createdAt": "2015-02-11T21:02:47Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+---\n+layout: global\n+title: Naive Bayes - MLlib\n+displayTitle: <a href=\"mllib-guide.html\">MLlib</a> - Regression\n+---\n+\n+## Regression\n+[Regression](http://en.wikipedia.org/wiki/Regression_analysis) is a statistical process\n+for estimating the relationships among variables. It includes many techniques for modeling\n+and analyzing several variables, when the focus is on the relationship between\n+a dependent variable and one or more independent variables.\n+\n+## Isotonic regression\n+[Isotonic regression](http://en.wikipedia.org/wiki/Isotonic_regression)\n+belongs to the family of regression algorithms. Formally isotonic regression is a problem where\n+given a finite set of real numbers `$Y = {y_1, y_2, ..., y_n}$` representing observed responses\n+and `$X = {x_1, x_2, ..., x_n}$` the unknown response values to be fitted\n+finding a function that minimises\n+\n+`\\begin{equation}\n+  f(x) = \\sum_{i=1}^n w_i (y_i - x_i)^2\n+\\end{equation}`\n+\n+with respect to complete order subject to\n+`$x_1\\le x_2\\le ...\\le x_n$` where `$w_i$` are positive weights.\n+The resulting function is called isotonic regression and it is unique.\n+It can be viewed as least squares problem under order restriction.\n+Essentially isotonic regression is a\n+[monotonic function](http://en.wikipedia.org/wiki/Monotonic_function)\n+best fitting the original data points.\n+\n+MLlib supports a\n+[pool adjacent violators algorithm](http://www.stat.cmu.edu/~ryantibs/papers/neariso.pdf)"
  }],
  "prId": 4536
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Same here: http://doi.org/10.1007/978-3-642-99789-1_10\n",
    "commit": "67fe773f4046abc12d6f116afe285e68df5ce6ae",
    "createdAt": "2015-02-11T21:02:49Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+---\n+layout: global\n+title: Naive Bayes - MLlib\n+displayTitle: <a href=\"mllib-guide.html\">MLlib</a> - Regression\n+---\n+\n+## Regression\n+[Regression](http://en.wikipedia.org/wiki/Regression_analysis) is a statistical process\n+for estimating the relationships among variables. It includes many techniques for modeling\n+and analyzing several variables, when the focus is on the relationship between\n+a dependent variable and one or more independent variables.\n+\n+## Isotonic regression\n+[Isotonic regression](http://en.wikipedia.org/wiki/Isotonic_regression)\n+belongs to the family of regression algorithms. Formally isotonic regression is a problem where\n+given a finite set of real numbers `$Y = {y_1, y_2, ..., y_n}$` representing observed responses\n+and `$X = {x_1, x_2, ..., x_n}$` the unknown response values to be fitted\n+finding a function that minimises\n+\n+`\\begin{equation}\n+  f(x) = \\sum_{i=1}^n w_i (y_i - x_i)^2\n+\\end{equation}`\n+\n+with respect to complete order subject to\n+`$x_1\\le x_2\\le ...\\le x_n$` where `$w_i$` are positive weights.\n+The resulting function is called isotonic regression and it is unique.\n+It can be viewed as least squares problem under order restriction.\n+Essentially isotonic regression is a\n+[monotonic function](http://en.wikipedia.org/wiki/Monotonic_function)\n+best fitting the original data points.\n+\n+MLlib supports a\n+[pool adjacent violators algorithm](http://www.stat.cmu.edu/~ryantibs/papers/neariso.pdf)\n+which uses an approach to\n+[parallelizing isotonic regression](http://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR96640.pdf)."
  }],
  "prId": 4536
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "I don't think we need to link `Tuple3`.\n",
    "commit": "67fe773f4046abc12d6f116afe285e68df5ce6ae",
    "createdAt": "2015-02-11T21:02:54Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+---\n+layout: global\n+title: Naive Bayes - MLlib\n+displayTitle: <a href=\"mllib-guide.html\">MLlib</a> - Regression\n+---\n+\n+## Regression\n+[Regression](http://en.wikipedia.org/wiki/Regression_analysis) is a statistical process\n+for estimating the relationships among variables. It includes many techniques for modeling\n+and analyzing several variables, when the focus is on the relationship between\n+a dependent variable and one or more independent variables.\n+\n+## Isotonic regression\n+[Isotonic regression](http://en.wikipedia.org/wiki/Isotonic_regression)\n+belongs to the family of regression algorithms. Formally isotonic regression is a problem where\n+given a finite set of real numbers `$Y = {y_1, y_2, ..., y_n}$` representing observed responses\n+and `$X = {x_1, x_2, ..., x_n}$` the unknown response values to be fitted\n+finding a function that minimises\n+\n+`\\begin{equation}\n+  f(x) = \\sum_{i=1}^n w_i (y_i - x_i)^2\n+\\end{equation}`\n+\n+with respect to complete order subject to\n+`$x_1\\le x_2\\le ...\\le x_n$` where `$w_i$` are positive weights.\n+The resulting function is called isotonic regression and it is unique.\n+It can be viewed as least squares problem under order restriction.\n+Essentially isotonic regression is a\n+[monotonic function](http://en.wikipedia.org/wiki/Monotonic_function)\n+best fitting the original data points.\n+\n+MLlib supports a\n+[pool adjacent violators algorithm](http://www.stat.cmu.edu/~ryantibs/papers/neariso.pdf)\n+which uses an approach to\n+[parallelizing isotonic regression](http://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR96640.pdf).\n+The training input is a RDD of\n+[tuples](http://www.scala-lang.org/api/2.10.3/index.html#scala.Tuple3)"
  }],
  "prId": 4536
}]