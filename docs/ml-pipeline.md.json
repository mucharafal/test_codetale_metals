[{
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "an ML -> a ML",
    "commit": "5366d169ca6b1c5f590ad1beaa15ac74cf731234",
    "createdAt": "2018-02-13T09:10:10Z",
    "diffHunk": "@@ -188,9 +188,36 @@ Parameters belong to specific instances of `Estimator`s and `Transformer`s.\n For example, if we have two `LogisticRegression` instances `lr1` and `lr2`, then we can build a `ParamMap` with both `maxIter` parameters specified: `ParamMap(lr1.maxIter -> 10, lr2.maxIter -> 20)`.\n This is useful if there are two algorithms with the `maxIter` parameter in a `Pipeline`.\n \n-## Saving and Loading Pipelines\n+## ML persistence: Saving and Loading Pipelines\n \n-Often times it is worth it to save a model or a pipeline to disk for later use. In Spark 1.6, a model import/export functionality was added to the Pipeline API. Most basic transformers are supported as well as some of the more basic ML models. Please refer to the algorithm's API documentation to see if saving and loading is supported.\n+Often times it is worth it to save a model or a pipeline to disk for later use. In Spark 1.6, a model import/export functionality was added to the Pipeline API.\n+As of Spark 2.3, the DataFrame-based API in `spark.ml` and `pyspark.ml` has complete coverage.\n+\n+ML persistence works across Scala, Java and Python.  However, R currently uses a modified format,\n+so models saved in R can only be loaded back in R; this should be fixed in the future and is\n+tracked in [SPARK-15572](https://issues.apache.org/jira/browse/SPARK-15572).\n+\n+### Backwards compatibility for ML persistence\n+\n+In general, MLlib maintains backwards compatibility for ML persistence.  I.e., if you save an ML",
    "line": 17
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Oh, I was in this too before. IIRC, I was confused of an RDD vs a RDD. I learnt English uses \"an\" vs \"a\" by how it sounds. I believe \"an em-el\" is correct :).",
    "commit": "5366d169ca6b1c5f590ad1beaa15ac74cf731234",
    "createdAt": "2018-02-13T12:22:10Z",
    "diffHunk": "@@ -188,9 +188,36 @@ Parameters belong to specific instances of `Estimator`s and `Transformer`s.\n For example, if we have two `LogisticRegression` instances `lr1` and `lr2`, then we can build a `ParamMap` with both `maxIter` parameters specified: `ParamMap(lr1.maxIter -> 10, lr2.maxIter -> 20)`.\n This is useful if there are two algorithms with the `maxIter` parameter in a `Pipeline`.\n \n-## Saving and Loading Pipelines\n+## ML persistence: Saving and Loading Pipelines\n \n-Often times it is worth it to save a model or a pipeline to disk for later use. In Spark 1.6, a model import/export functionality was added to the Pipeline API. Most basic transformers are supported as well as some of the more basic ML models. Please refer to the algorithm's API documentation to see if saving and loading is supported.\n+Often times it is worth it to save a model or a pipeline to disk for later use. In Spark 1.6, a model import/export functionality was added to the Pipeline API.\n+As of Spark 2.3, the DataFrame-based API in `spark.ml` and `pyspark.ml` has complete coverage.\n+\n+ML persistence works across Scala, Java and Python.  However, R currently uses a modified format,\n+so models saved in R can only be loaded back in R; this should be fixed in the future and is\n+tracked in [SPARK-15572](https://issues.apache.org/jira/browse/SPARK-15572).\n+\n+### Backwards compatibility for ML persistence\n+\n+In general, MLlib maintains backwards compatibility for ML persistence.  I.e., if you save an ML",
    "line": 17
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "Yep, what @HyukjinKwon said.  Gotta love the irregularities of the language!",
    "commit": "5366d169ca6b1c5f590ad1beaa15ac74cf731234",
    "createdAt": "2018-02-13T19:17:44Z",
    "diffHunk": "@@ -188,9 +188,36 @@ Parameters belong to specific instances of `Estimator`s and `Transformer`s.\n For example, if we have two `LogisticRegression` instances `lr1` and `lr2`, then we can build a `ParamMap` with both `maxIter` parameters specified: `ParamMap(lr1.maxIter -> 10, lr2.maxIter -> 20)`.\n This is useful if there are two algorithms with the `maxIter` parameter in a `Pipeline`.\n \n-## Saving and Loading Pipelines\n+## ML persistence: Saving and Loading Pipelines\n \n-Often times it is worth it to save a model or a pipeline to disk for later use. In Spark 1.6, a model import/export functionality was added to the Pipeline API. Most basic transformers are supported as well as some of the more basic ML models. Please refer to the algorithm's API documentation to see if saving and loading is supported.\n+Often times it is worth it to save a model or a pipeline to disk for later use. In Spark 1.6, a model import/export functionality was added to the Pipeline API.\n+As of Spark 2.3, the DataFrame-based API in `spark.ml` and `pyspark.ml` has complete coverage.\n+\n+ML persistence works across Scala, Java and Python.  However, R currently uses a modified format,\n+so models saved in R can only be loaded back in R; this should be fixed in the future and is\n+tracked in [SPARK-15572](https://issues.apache.org/jira/browse/SPARK-15572).\n+\n+### Backwards compatibility for ML persistence\n+\n+In general, MLlib maintains backwards compatibility for ML persistence.  I.e., if you save an ML",
    "line": 17
  }],
  "prId": 20592
}]