[{
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "should be `####` I think?",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-20T04:15:31Z",
    "diffHunk": "@@ -450,6 +450,42 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution",
    "line": 4
  }, {
    "author": {
      "login": "adrian555"
    },
    "body": "This will be the same level as \"Applying User-Defined Function\" where its parent topic is \"SparkDataFrame Operations\". So the heading is with three `#`.",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-20T20:57:16Z",
    "diffHunk": "@@ -450,6 +450,42 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution",
    "line": 4
  }],
  "prId": 22455
}, {
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "perhaps a more complete example - like `summarize(groupBy(df, df$waiting), count = n(df$waiting))`",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-20T04:18:02Z",
    "diffHunk": "@@ -450,6 +450,42 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution\n+\n+If the eager execution is enabled, the data will be returned to R client immediately when the `SparkDataFrame` is created. Eager execution can be enabled by setting the configuration property `spark.sql.repl.eagerEval.enabled` to `true` when the `SparkSession` is started up.\n+\n+<div data-lang=\"r\" markdown=\"1\">\n+{% highlight r %}\n+\n+# Start up spark session with eager execution enabled\n+sparkR.session(master = \"local[*]\", sparkConfig = list(spark.sql.repl.eagerEval.enabled = \"true\"))\n+\n+df <- createDataFrame(faithful)",
    "line": 19
  }, {
    "author": {
      "login": "adrian555"
    },
    "body": "Done",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-20T20:57:22Z",
    "diffHunk": "@@ -450,6 +450,42 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution\n+\n+If the eager execution is enabled, the data will be returned to R client immediately when the `SparkDataFrame` is created. Eager execution can be enabled by setting the configuration property `spark.sql.repl.eagerEval.enabled` to `true` when the `SparkSession` is started up.\n+\n+<div data-lang=\"r\" markdown=\"1\">\n+{% highlight r %}\n+\n+# Start up spark session with eager execution enabled\n+sparkR.session(master = \"local[*]\", sparkConfig = list(spark.sql.repl.eagerEval.enabled = \"true\"))\n+\n+df <- createDataFrame(faithful)",
    "line": 19
  }],
  "prId": 22455
}, {
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "we could also start here by saying \"Similar to R data.frame`...",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-20T04:18:35Z",
    "diffHunk": "@@ -450,6 +450,42 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution\n+\n+If the eager execution is enabled, the data will be returned to R client immediately when the `SparkDataFrame` is created. Eager execution can be enabled by setting the configuration property `spark.sql.repl.eagerEval.enabled` to `true` when the `SparkSession` is started up.\n+\n+<div data-lang=\"r\" markdown=\"1\">\n+{% highlight r %}\n+\n+# Start up spark session with eager execution enabled\n+sparkR.session(master = \"local[*]\", sparkConfig = list(spark.sql.repl.eagerEval.enabled = \"true\"))\n+\n+df <- createDataFrame(faithful)\n+\n+# Instead of displaying the SparkDataFrame class, displays the data returned"
  }, {
    "author": {
      "login": "adrian555"
    },
    "body": "Done",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-20T20:57:26Z",
    "diffHunk": "@@ -450,6 +450,42 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution\n+\n+If the eager execution is enabled, the data will be returned to R client immediately when the `SparkDataFrame` is created. Eager execution can be enabled by setting the configuration property `spark.sql.repl.eagerEval.enabled` to `true` when the `SparkSession` is started up.\n+\n+<div data-lang=\"r\" markdown=\"1\">\n+{% highlight r %}\n+\n+# Start up spark session with eager execution enabled\n+sparkR.session(master = \"local[*]\", sparkConfig = list(spark.sql.repl.eagerEval.enabled = \"true\"))\n+\n+df <- createDataFrame(faithful)\n+\n+# Instead of displaying the SparkDataFrame class, displays the data returned"
  }],
  "prId": 22455
}, {
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "change to `Note that the `SparkSession` created by `sparkR` shell by default does not `",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-20T04:19:10Z",
    "diffHunk": "@@ -450,6 +450,42 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution\n+\n+If the eager execution is enabled, the data will be returned to R client immediately when the `SparkDataFrame` is created. Eager execution can be enabled by setting the configuration property `spark.sql.repl.eagerEval.enabled` to `true` when the `SparkSession` is started up.\n+\n+<div data-lang=\"r\" markdown=\"1\">\n+{% highlight r %}\n+\n+# Start up spark session with eager execution enabled\n+sparkR.session(master = \"local[*]\", sparkConfig = list(spark.sql.repl.eagerEval.enabled = \"true\"))\n+\n+df <- createDataFrame(faithful)\n+\n+# Instead of displaying the SparkDataFrame class, displays the data returned\n+df\n+\n+##+---------+-------+                                                             \n+##|eruptions|waiting|\n+##+---------+-------+\n+##|      3.6|   79.0|\n+##|      1.8|   54.0|\n+##|    3.333|   74.0|\n+##|    2.283|   62.0|\n+##|    4.533|   85.0|\n+##|    2.883|   55.0|\n+##|      4.7|   88.0|\n+##|      3.6|   85.0|\n+##|     1.95|   51.0|\n+##|     4.35|   85.0|\n+##+---------+-------+\n+##only showing top 10 rows\n+\n+{% endhighlight %} \n+</div>\n+\n+Note that the `SparkSession` created by `sparkR` shell does not have eager execution enabled. You can stop the current session and start up a new session like above to enable."
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "actually I think the suggestion should be to set that in the `sparkR` command line as spark conf?",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-20T04:19:48Z",
    "diffHunk": "@@ -450,6 +450,42 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution\n+\n+If the eager execution is enabled, the data will be returned to R client immediately when the `SparkDataFrame` is created. Eager execution can be enabled by setting the configuration property `spark.sql.repl.eagerEval.enabled` to `true` when the `SparkSession` is started up.\n+\n+<div data-lang=\"r\" markdown=\"1\">\n+{% highlight r %}\n+\n+# Start up spark session with eager execution enabled\n+sparkR.session(master = \"local[*]\", sparkConfig = list(spark.sql.repl.eagerEval.enabled = \"true\"))\n+\n+df <- createDataFrame(faithful)\n+\n+# Instead of displaying the SparkDataFrame class, displays the data returned\n+df\n+\n+##+---------+-------+                                                             \n+##|eruptions|waiting|\n+##+---------+-------+\n+##|      3.6|   79.0|\n+##|      1.8|   54.0|\n+##|    3.333|   74.0|\n+##|    2.283|   62.0|\n+##|    4.533|   85.0|\n+##|    2.883|   55.0|\n+##|      4.7|   88.0|\n+##|      3.6|   85.0|\n+##|     1.95|   51.0|\n+##|     4.35|   85.0|\n+##+---------+-------+\n+##only showing top 10 rows\n+\n+{% endhighlight %} \n+</div>\n+\n+Note that the `SparkSession` created by `sparkR` shell does not have eager execution enabled. You can stop the current session and start up a new session like above to enable."
  }, {
    "author": {
      "login": "adrian555"
    },
    "body": "Changed to this: \r\n```\r\nNote that to enable eager execution through `sparkR` command, add `spark.sql.repl.eagerEval.enabled=true` configuration property to the `--conf` option.\r\n```",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-20T20:57:30Z",
    "diffHunk": "@@ -450,6 +450,42 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution\n+\n+If the eager execution is enabled, the data will be returned to R client immediately when the `SparkDataFrame` is created. Eager execution can be enabled by setting the configuration property `spark.sql.repl.eagerEval.enabled` to `true` when the `SparkSession` is started up.\n+\n+<div data-lang=\"r\" markdown=\"1\">\n+{% highlight r %}\n+\n+# Start up spark session with eager execution enabled\n+sparkR.session(master = \"local[*]\", sparkConfig = list(spark.sql.repl.eagerEval.enabled = \"true\"))\n+\n+df <- createDataFrame(faithful)\n+\n+# Instead of displaying the SparkDataFrame class, displays the data returned\n+df\n+\n+##+---------+-------+                                                             \n+##|eruptions|waiting|\n+##+---------+-------+\n+##|      3.6|   79.0|\n+##|      1.8|   54.0|\n+##|    3.333|   74.0|\n+##|    2.283|   62.0|\n+##|    4.533|   85.0|\n+##|    2.883|   55.0|\n+##|      4.7|   88.0|\n+##|      3.6|   85.0|\n+##|     1.95|   51.0|\n+##|     4.35|   85.0|\n+##+---------+-------+\n+##only showing top 10 rows\n+\n+{% endhighlight %} \n+</div>\n+\n+Note that the `SparkSession` created by `sparkR` shell does not have eager execution enabled. You can stop the current session and start up a new session like above to enable."
  }],
  "prId": 22455
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Let's note the default values.",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-24T16:15:50Z",
    "diffHunk": "@@ -450,6 +450,48 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution\n+\n+If the eager execution is enabled, the data will be returned to R client immediately when the `SparkDataFrame` is created. Eager execution can be enabled by setting the configuration property `spark.sql.repl.eagerEval.enabled` to `true` when the `SparkSession` is started up.\n+\n+Maximum number of rows and maximum number of characters per column of data to display can be controlled by `spark.sql.repl.eagerEval.maxNumRows` and `spark.sql.repl.eagerEval.truncate` configuration properties, respectively."
  }, {
    "author": {
      "login": "adrian555"
    },
    "body": "Done",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-24T18:20:26Z",
    "diffHunk": "@@ -450,6 +450,48 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution\n+\n+If the eager execution is enabled, the data will be returned to R client immediately when the `SparkDataFrame` is created. Eager execution can be enabled by setting the configuration property `spark.sql.repl.eagerEval.enabled` to `true` when the `SparkSession` is started up.\n+\n+Maximum number of rows and maximum number of characters per column of data to display can be controlled by `spark.sql.repl.eagerEval.maxNumRows` and `spark.sql.repl.eagerEval.truncate` configuration properties, respectively."
  }],
  "prId": 22455
}, {
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "`sparkR command` - I think should be `sparkR shell`?",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-25T01:07:21Z",
    "diffHunk": "@@ -450,6 +450,48 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution\n+\n+If eager execution is enabled, the data will be returned to R client immediately when the `SparkDataFrame` is created. By default, eager execution is not enabled and can be enabled by setting the configuration property `spark.sql.repl.eagerEval.enabled` to `true` when the `SparkSession` is started up.\n+\n+Maximum number of rows and maximum number of characters per column of data to display can be controlled by `spark.sql.repl.eagerEval.maxNumRows` and `spark.sql.repl.eagerEval.truncate` configuration properties, respectively. These properties are only effective when eager execution is enabled. If these properties are not set explicitly, by default, data up to 20 rows and up to 20 characters per column will be showed.\n+\n+<div data-lang=\"r\" markdown=\"1\">\n+{% highlight r %}\n+\n+# Start up spark session with eager execution enabled\n+sparkR.session(master = \"local[*]\",\n+               sparkConfig = list(spark.sql.repl.eagerEval.enabled = \"true\",\n+                                  spark.sql.repl.eagerEval.maxNumRows = as.integer(10)))\n+\n+# Create a grouped and sorted SparkDataFrame\n+df <- createDataFrame(faithful)\n+df2 <- arrange(summarize(groupBy(df, df$waiting), count = n(df$waiting)), \"waiting\")\n+\n+# Similar to R data.frame, displays the data returned, instead of SparkDataFrame class string\n+df2\n+\n+##+-------+-----+\n+##|waiting|count|\n+##+-------+-----+\n+##|   43.0|    1|\n+##|   45.0|    3|\n+##|   46.0|    5|\n+##|   47.0|    4|\n+##|   48.0|    3|\n+##|   49.0|    5|\n+##|   50.0|    5|\n+##|   51.0|    6|\n+##|   52.0|    5|\n+##|   53.0|    7|\n+##+-------+-----+\n+##only showing top 10 rows\n+\n+{% endhighlight %} \n+</div>\n+\n+Note that to enable eager execution through `sparkR` command, add `spark.sql.repl.eagerEval.enabled=true` configuration property to the `--conf` option."
  }, {
    "author": {
      "login": "adrian555"
    },
    "body": "In the same doc \"From Data Sources\", it has `either be added by specifying --packages with spark-submit or sparkR commands`, that is why I used `command` instead of `shell`. I would think that `script`, `shell` and `command` are exchangeable here. But if viewed by the angle that `sparkR` ends with a R execution env, maybe `shell` makes more sense. :)\r\n\r\nSo I made the change.",
    "commit": "2d2c3c638062633193642931e8c81e80151dd09d",
    "createdAt": "2018-09-25T17:52:37Z",
    "diffHunk": "@@ -450,6 +450,48 @@ print(model.summaries)\n {% endhighlight %}\n </div>\n \n+### Eager execution\n+\n+If eager execution is enabled, the data will be returned to R client immediately when the `SparkDataFrame` is created. By default, eager execution is not enabled and can be enabled by setting the configuration property `spark.sql.repl.eagerEval.enabled` to `true` when the `SparkSession` is started up.\n+\n+Maximum number of rows and maximum number of characters per column of data to display can be controlled by `spark.sql.repl.eagerEval.maxNumRows` and `spark.sql.repl.eagerEval.truncate` configuration properties, respectively. These properties are only effective when eager execution is enabled. If these properties are not set explicitly, by default, data up to 20 rows and up to 20 characters per column will be showed.\n+\n+<div data-lang=\"r\" markdown=\"1\">\n+{% highlight r %}\n+\n+# Start up spark session with eager execution enabled\n+sparkR.session(master = \"local[*]\",\n+               sparkConfig = list(spark.sql.repl.eagerEval.enabled = \"true\",\n+                                  spark.sql.repl.eagerEval.maxNumRows = as.integer(10)))\n+\n+# Create a grouped and sorted SparkDataFrame\n+df <- createDataFrame(faithful)\n+df2 <- arrange(summarize(groupBy(df, df$waiting), count = n(df$waiting)), \"waiting\")\n+\n+# Similar to R data.frame, displays the data returned, instead of SparkDataFrame class string\n+df2\n+\n+##+-------+-----+\n+##|waiting|count|\n+##+-------+-----+\n+##|   43.0|    1|\n+##|   45.0|    3|\n+##|   46.0|    5|\n+##|   47.0|    4|\n+##|   48.0|    3|\n+##|   49.0|    5|\n+##|   50.0|    5|\n+##|   51.0|    6|\n+##|   52.0|    5|\n+##|   53.0|    7|\n+##+-------+-----+\n+##only showing top 10 rows\n+\n+{% endhighlight %} \n+</div>\n+\n+Note that to enable eager execution through `sparkR` command, add `spark.sql.repl.eagerEval.enabled=true` configuration property to the `--conf` option."
  }],
  "prId": 22455
}]