[{
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "`valid` -> `valid and visible`",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-09-22T22:48:00Z",
    "diffHunk": "@@ -19,4 +19,148 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+`CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid in the current session. No persistent entry is made "
  }, {
    "author": {
      "login": "dilipbiswal"
    },
    "body": "@gatorsmile thanks.. fixed.",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-09-23T05:16:41Z",
    "diffHunk": "@@ -19,4 +19,148 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+`CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid in the current session. No persistent entry is made "
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "integet -> integral",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-09-22T22:50:40Z",
    "diffHunk": "@@ -19,4 +19,148 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+`CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid in the current session. No persistent entry is made \n+    in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes in `Hive` as follows:\n+    <ul>\n+      <li>Should extend UDF or UDAF in org.apache.hadoop.hive.ql.exec</li>\n+      <li>Should extend AbstractGenericUDAFResolver, GenericUDF, or GenericUDTF in org.apache.hadoop.hive.ql.udf.generic.</li>\n+    </ul>\n+  </dd>\n+  <dt><code><em>resource_locations</em></code></dt>\n+  <dd>\n+    Specifies the list of resources that contain the implementation of the function\n+    along with its dependencies. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        USING { { (JAR | FILE ) resource_uri} , ...}\n+      </code>\n+  </dd>\n+</dl>\n+\n+### Examples\n+{% highlight sql %}\n+-- 1. Create a simple UDF `SimpleUdf` that adds the supplied integet value by 10."
  }, {
    "author": {
      "login": "dilipbiswal"
    },
    "body": "@gatorsmile fixed.",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-09-23T05:16:44Z",
    "diffHunk": "@@ -19,4 +19,148 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+`CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid in the current session. No persistent entry is made \n+    in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes in `Hive` as follows:\n+    <ul>\n+      <li>Should extend UDF or UDAF in org.apache.hadoop.hive.ql.exec</li>\n+      <li>Should extend AbstractGenericUDAFResolver, GenericUDF, or GenericUDTF in org.apache.hadoop.hive.ql.udf.generic.</li>\n+    </ul>\n+  </dd>\n+  <dt><code><em>resource_locations</em></code></dt>\n+  <dd>\n+    Specifies the list of resources that contain the implementation of the function\n+    along with its dependencies. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        USING { { (JAR | FILE ) resource_uri} , ...}\n+      </code>\n+  </dd>\n+</dl>\n+\n+### Examples\n+{% highlight sql %}\n+-- 1. Create a simple UDF `SimpleUdf` that adds the supplied integet value by 10."
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "UserDefinedAggregateFunction. We also support this. ",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-09-22T22:53:06Z",
    "diffHunk": "@@ -19,4 +19,148 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+`CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid in the current session. No persistent entry is made \n+    in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes in `Hive` as follows:"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Also we can extend org.apache.spark.sql.api.java.UDF0,... UDF22. see https://github.com/apache/spark/blob/master/sql/core/src/test/java/test/org/apache/spark/sql/JavaStringLength.java ",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-09-22T22:58:19Z",
    "diffHunk": "@@ -19,4 +19,148 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+`CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid in the current session. No persistent entry is made \n+    in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes in `Hive` as follows:"
  }, {
    "author": {
      "login": "dilipbiswal"
    },
    "body": "@gatorsmile I have created a place holder link for custom scalar functions. There is already a place holder for aggregate functions and a lot of content is already in place.",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-09-23T05:17:44Z",
    "diffHunk": "@@ -19,4 +19,148 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+`CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid in the current session. No persistent entry is made \n+    in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes in `Hive` as follows:"
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "We also need to explain we can create/register temporary SQL functions via Python/Scala/Java APIs. ",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-09-22T23:00:06Z",
    "diffHunk": "@@ -19,4 +19,148 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+`CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time."
  }, {
    "author": {
      "login": "dilipbiswal"
    },
    "body": "@gatorsmile I have created a place holder link for custom scalar functions. There is already a place holder for aggregate functions and a lot of content is already in place.",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-09-23T05:18:00Z",
    "diffHunk": "@@ -19,4 +19,148 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+`CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time."
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "duplicate?",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-10-14T05:39:28Z",
    "diffHunk": "@@ -19,4 +19,154 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+The `CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time. In addition to the\n+SQL interface, spark allows users to create custom user defined scalar and\n+aggregate functions using Scala, Python and Java APIs. Please refer to \n+[scalar_functions](sql-getting-started.html#scalar-functions) and \n+[aggregate functions](sql-getting-started#aggregations) for more information.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid and visible in the current session. No persistent\n+    entry is made in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes as follows:\n+    <ul>\n+      <li>Should extend <code>UDF</code> or <code>UDAF</code> in <code>org.apache.hadoop.hive.ql.exec</code> package.</li>\n+      <li>Should extend <code>AbstractGenericUDAFResolver</code>, <code>GenericUDF</code>, or\n+          <code>GenericUDTF</code> in <code>org.apache.hadoop.hive.ql.udf.generic</code> package.</li>\n+      <li>Should extend <code>UserDefinedAggregateFunction</code> in <code>org.apache.spark.sql.expressions</code> package.</li>\n+    </ul>\n+  </dd>\n+  <dt><code><em>resource_locations</em></code></dt>\n+  <dd>\n+    Specifies the list of resources that contain the implementation of the function\n+    along with its dependencies. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        USING { { (JAR | FILE ) resource_uri} , ...}\n+      </code>\n+  </dd>\n+</dl>\n+\n+### Examples\n+{% highlight sql %}\n+-- 1. Create a simple UDF `SimpleUdf` that adds the supplied integral value by 10.\n+--    import org.apache.hadoop.hive.ql.exec.UDF;\n+--    public class SimpleUdf extends UDF {\n+--      public int evaluate(int value) {\n+--      return value + 10;\n+--      }\n+--    }\n+-- 2. Compile and place it in a jar file called `SimpleUdf.jar` in /tmp.\n+\n+-- Create a table called `test` and insert two rows.\n+CREATE TABLE test(c1 INT);\n+INSERT INTO test VALUES (1), (2);\n+\n+-- Create a permanent function called `simple_udf`. \n+CREATE FUNCTION simple_udf AS 'SimpleUdf'\n+  USING JAR '/tmp/SimpleUdf.jar';\n+\n+-- Verify that the function is in the registry.\n+SHOW USER FUNCTIONS;\n+  +------------------+\n+  |          function|\n+  +------------------+\n+  |default.simple_udf|\n+  +------------------+\n+\n+-- Invoke the function. Every selected value should be incremented by 10.\n+SELECT simple_udf(c1) AS function_return_value FROM t1;\n+  +---------------------+                                                         \n+  |function_return_value|\n+  +---------------------+\n+  |                   11|\n+  |                   12|\n+  +---------------------+\n+\n+-- Created a temporary function.\n+CREATE TEMPORARY FUNCTION simple_temp_udf AS 'SimpleUdf' \n+  USING JAR '/tmp/SimpleUdf.jar';\n+\n+-- Verify that the newly created temporary function is in the registry.\n+-- Please note that the temporary function does not have a qualified\n+-- database associated with it.\n+SHOW USER FUNCTIONS;\n+  +------------------+\n+  |          function|\n+  +------------------+\n+  |default.simple_udf|\n+  |   simple_temp_udf|\n+  +------------------+\n+\n+-- 1. Mofify `SimpleUdf`'s implementation to add supplied integral value by 20.\n+--    import org.apache.hadoop.hive.ql.exec.UDF;\n+  \n+--    public class SimpleUdfR extends UDF {\n+--      public int evaluate(int value) {\n+--      return value + 20;\n+--      }\n+--    }\n+-- 2. Compile and place it in a jar file called `SimpleUdfR.jar` in /tmp.\n+\n+-- Replace the implementation of `simple_udf`\n+CREATE OR REPLACE FUNCTION simple_udf AS 'SimpleUdfR'\n+  USING JAR '/tmp/SimpleUdfR.jar';\n+\n+-- Invoke the function. Every selected value should be incremented by 20.\n+SELECT simple_udf(c1) AS function_return_value FROM t1;\n++---------------------+                                                         \n+|function_return_value|\n++---------------------+\n+|                   21|\n+|                   22|\n++---------------------+\n+\n+{% endhighlight %}\n+\n+### Related statements\n+- [SHOW FUNCTIONS](sql-ref-syntax-aux-show-functions.html)\n+- [DESCRIBE FUNCTION](sql-ref-syntax-aux-describe-function.html)\n+- [DESCRIBE FUNCTION](sql-ref-syntax-aux-describe-function.html)"
  }, {
    "author": {
      "login": "dilipbiswal"
    },
    "body": "@gatorsmile oops.. thanks for catching it. Will fix.",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-10-14T05:42:41Z",
    "diffHunk": "@@ -19,4 +19,154 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+The `CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time. In addition to the\n+SQL interface, spark allows users to create custom user defined scalar and\n+aggregate functions using Scala, Python and Java APIs. Please refer to \n+[scalar_functions](sql-getting-started.html#scalar-functions) and \n+[aggregate functions](sql-getting-started#aggregations) for more information.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid and visible in the current session. No persistent\n+    entry is made in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes as follows:\n+    <ul>\n+      <li>Should extend <code>UDF</code> or <code>UDAF</code> in <code>org.apache.hadoop.hive.ql.exec</code> package.</li>\n+      <li>Should extend <code>AbstractGenericUDAFResolver</code>, <code>GenericUDF</code>, or\n+          <code>GenericUDTF</code> in <code>org.apache.hadoop.hive.ql.udf.generic</code> package.</li>\n+      <li>Should extend <code>UserDefinedAggregateFunction</code> in <code>org.apache.spark.sql.expressions</code> package.</li>\n+    </ul>\n+  </dd>\n+  <dt><code><em>resource_locations</em></code></dt>\n+  <dd>\n+    Specifies the list of resources that contain the implementation of the function\n+    along with its dependencies. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        USING { { (JAR | FILE ) resource_uri} , ...}\n+      </code>\n+  </dd>\n+</dl>\n+\n+### Examples\n+{% highlight sql %}\n+-- 1. Create a simple UDF `SimpleUdf` that adds the supplied integral value by 10.\n+--    import org.apache.hadoop.hive.ql.exec.UDF;\n+--    public class SimpleUdf extends UDF {\n+--      public int evaluate(int value) {\n+--      return value + 10;\n+--      }\n+--    }\n+-- 2. Compile and place it in a jar file called `SimpleUdf.jar` in /tmp.\n+\n+-- Create a table called `test` and insert two rows.\n+CREATE TABLE test(c1 INT);\n+INSERT INTO test VALUES (1), (2);\n+\n+-- Create a permanent function called `simple_udf`. \n+CREATE FUNCTION simple_udf AS 'SimpleUdf'\n+  USING JAR '/tmp/SimpleUdf.jar';\n+\n+-- Verify that the function is in the registry.\n+SHOW USER FUNCTIONS;\n+  +------------------+\n+  |          function|\n+  +------------------+\n+  |default.simple_udf|\n+  +------------------+\n+\n+-- Invoke the function. Every selected value should be incremented by 10.\n+SELECT simple_udf(c1) AS function_return_value FROM t1;\n+  +---------------------+                                                         \n+  |function_return_value|\n+  +---------------------+\n+  |                   11|\n+  |                   12|\n+  +---------------------+\n+\n+-- Created a temporary function.\n+CREATE TEMPORARY FUNCTION simple_temp_udf AS 'SimpleUdf' \n+  USING JAR '/tmp/SimpleUdf.jar';\n+\n+-- Verify that the newly created temporary function is in the registry.\n+-- Please note that the temporary function does not have a qualified\n+-- database associated with it.\n+SHOW USER FUNCTIONS;\n+  +------------------+\n+  |          function|\n+  +------------------+\n+  |default.simple_udf|\n+  |   simple_temp_udf|\n+  +------------------+\n+\n+-- 1. Mofify `SimpleUdf`'s implementation to add supplied integral value by 20.\n+--    import org.apache.hadoop.hive.ql.exec.UDF;\n+  \n+--    public class SimpleUdfR extends UDF {\n+--      public int evaluate(int value) {\n+--      return value + 20;\n+--      }\n+--    }\n+-- 2. Compile and place it in a jar file called `SimpleUdfR.jar` in /tmp.\n+\n+-- Replace the implementation of `simple_udf`\n+CREATE OR REPLACE FUNCTION simple_udf AS 'SimpleUdfR'\n+  USING JAR '/tmp/SimpleUdfR.jar';\n+\n+-- Invoke the function. Every selected value should be incremented by 20.\n+SELECT simple_udf(c1) AS function_return_value FROM t1;\n++---------------------+                                                         \n+|function_return_value|\n++---------------------+\n+|                   21|\n+|                   22|\n++---------------------+\n+\n+{% endhighlight %}\n+\n+### Related statements\n+- [SHOW FUNCTIONS](sql-ref-syntax-aux-show-functions.html)\n+- [DESCRIBE FUNCTION](sql-ref-syntax-aux-describe-function.html)\n+- [DESCRIBE FUNCTION](sql-ref-syntax-aux-describe-function.html)"
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Nit: remove comma",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-10-21T17:09:57Z",
    "diffHunk": "@@ -19,4 +19,153 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+The `CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time. In addition to the\n+SQL interface, spark allows users to create custom user defined scalar and\n+aggregate functions using Scala, Python and Java APIs. Please refer to \n+[scalar_functions](sql-getting-started.html#scalar-functions) and \n+[aggregate functions](sql-getting-started#aggregations) for more information.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid and visible in the current session. No persistent\n+    entry is made in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already"
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Nit: code-format `TEMPORARY`?",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-10-21T17:10:09Z",
    "diffHunk": "@@ -19,4 +19,153 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+The `CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time. In addition to the\n+SQL interface, spark allows users to create custom user defined scalar and\n+aggregate functions using Scala, Python and Java APIs. Please refer to \n+[scalar_functions](sql-getting-started.html#scalar-functions) and \n+[aggregate functions](sql-getting-started#aggregations) for more information.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the"
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "for the function",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-10-21T17:10:15Z",
    "diffHunk": "@@ -19,4 +19,153 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+The `CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time. In addition to the\n+SQL interface, spark allows users to create custom user defined scalar and\n+aggregate functions using Scala, Python and Java APIs. Please refer to \n+[scalar_functions](sql-getting-started.html#scalar-functions) and \n+[aggregate functions](sql-getting-started#aggregations) for more information.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful"
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "remove 'from'",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-10-21T17:10:38Z",
    "diffHunk": "@@ -19,4 +19,153 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+The `CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time. In addition to the\n+SQL interface, spark allows users to create custom user defined scalar and\n+aggregate functions using Scala, Python and Java APIs. Please refer to \n+[scalar_functions](sql-getting-started.html#scalar-functions) and \n+[aggregate functions](sql-getting-started#aggregations) for more information.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid and visible in the current session. No persistent\n+    entry is made in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes as follows:"
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "\"increments\" rather than \"adds\"?",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-10-21T17:11:07Z",
    "diffHunk": "@@ -19,4 +19,153 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+The `CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time. In addition to the\n+SQL interface, spark allows users to create custom user defined scalar and\n+aggregate functions using Scala, Python and Java APIs. Please refer to \n+[scalar_functions](sql-getting-started.html#scalar-functions) and \n+[aggregate functions](sql-getting-started#aggregations) for more information.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid and visible in the current session. No persistent\n+    entry is made in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes as follows:\n+    <ul>\n+      <li>Should extend <code>UDF</code> or <code>UDAF</code> in <code>org.apache.hadoop.hive.ql.exec</code> package.</li>\n+      <li>Should extend <code>AbstractGenericUDAFResolver</code>, <code>GenericUDF</code>, or\n+          <code>GenericUDTF</code> in <code>org.apache.hadoop.hive.ql.udf.generic</code> package.</li>\n+      <li>Should extend <code>UserDefinedAggregateFunction</code> in <code>org.apache.spark.sql.expressions</code> package.</li>\n+    </ul>\n+  </dd>\n+  <dt><code><em>resource_locations</em></code></dt>\n+  <dd>\n+    Specifies the list of resources that contain the implementation of the function\n+    along with its dependencies. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        USING { { (JAR | FILE ) resource_uri} , ...}\n+      </code>\n+  </dd>\n+</dl>\n+\n+### Examples\n+{% highlight sql %}\n+-- 1. Create a simple UDF `SimpleUdf` that adds the supplied integral value by 10."
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Nit: indent this more",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-10-21T17:11:18Z",
    "diffHunk": "@@ -19,4 +19,153 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+The `CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time. In addition to the\n+SQL interface, spark allows users to create custom user defined scalar and\n+aggregate functions using Scala, Python and Java APIs. Please refer to \n+[scalar_functions](sql-getting-started.html#scalar-functions) and \n+[aggregate functions](sql-getting-started#aggregations) for more information.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid and visible in the current session. No persistent\n+    entry is made in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes as follows:\n+    <ul>\n+      <li>Should extend <code>UDF</code> or <code>UDAF</code> in <code>org.apache.hadoop.hive.ql.exec</code> package.</li>\n+      <li>Should extend <code>AbstractGenericUDAFResolver</code>, <code>GenericUDF</code>, or\n+          <code>GenericUDTF</code> in <code>org.apache.hadoop.hive.ql.udf.generic</code> package.</li>\n+      <li>Should extend <code>UserDefinedAggregateFunction</code> in <code>org.apache.spark.sql.expressions</code> package.</li>\n+    </ul>\n+  </dd>\n+  <dt><code><em>resource_locations</em></code></dt>\n+  <dd>\n+    Specifies the list of resources that contain the implementation of the function\n+    along with its dependencies. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        USING { { (JAR | FILE ) resource_uri} , ...}\n+      </code>\n+  </dd>\n+</dl>\n+\n+### Examples\n+{% highlight sql %}\n+-- 1. Create a simple UDF `SimpleUdf` that adds the supplied integral value by 10.\n+--    import org.apache.hadoop.hive.ql.exec.UDF;\n+--    public class SimpleUdf extends UDF {\n+--      public int evaluate(int value) {\n+--      return value + 10;"
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Nit: jar -> JAR",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-10-21T17:11:32Z",
    "diffHunk": "@@ -19,4 +19,153 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+The `CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time. In addition to the\n+SQL interface, spark allows users to create custom user defined scalar and\n+aggregate functions using Scala, Python and Java APIs. Please refer to \n+[scalar_functions](sql-getting-started.html#scalar-functions) and \n+[aggregate functions](sql-getting-started#aggregations) for more information.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid and visible in the current session. No persistent\n+    entry is made in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes as follows:\n+    <ul>\n+      <li>Should extend <code>UDF</code> or <code>UDAF</code> in <code>org.apache.hadoop.hive.ql.exec</code> package.</li>\n+      <li>Should extend <code>AbstractGenericUDAFResolver</code>, <code>GenericUDF</code>, or\n+          <code>GenericUDTF</code> in <code>org.apache.hadoop.hive.ql.udf.generic</code> package.</li>\n+      <li>Should extend <code>UserDefinedAggregateFunction</code> in <code>org.apache.spark.sql.expressions</code> package.</li>\n+    </ul>\n+  </dd>\n+  <dt><code><em>resource_locations</em></code></dt>\n+  <dd>\n+    Specifies the list of resources that contain the implementation of the function\n+    along with its dependencies. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        USING { { (JAR | FILE ) resource_uri} , ...}\n+      </code>\n+  </dd>\n+</dl>\n+\n+### Examples\n+{% highlight sql %}\n+-- 1. Create a simple UDF `SimpleUdf` that adds the supplied integral value by 10.\n+--    import org.apache.hadoop.hive.ql.exec.UDF;\n+--    public class SimpleUdf extends UDF {\n+--      public int evaluate(int value) {\n+--      return value + 10;\n+--      }\n+--    }\n+-- 2. Compile and place it in a jar file called `SimpleUdf.jar` in /tmp."
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Mofify -> Modify",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-10-21T17:11:45Z",
    "diffHunk": "@@ -19,4 +19,153 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+The `CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time. In addition to the\n+SQL interface, spark allows users to create custom user defined scalar and\n+aggregate functions using Scala, Python and Java APIs. Please refer to \n+[scalar_functions](sql-getting-started.html#scalar-functions) and \n+[aggregate functions](sql-getting-started#aggregations) for more information.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid and visible in the current session. No persistent\n+    entry is made in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes as follows:\n+    <ul>\n+      <li>Should extend <code>UDF</code> or <code>UDAF</code> in <code>org.apache.hadoop.hive.ql.exec</code> package.</li>\n+      <li>Should extend <code>AbstractGenericUDAFResolver</code>, <code>GenericUDF</code>, or\n+          <code>GenericUDTF</code> in <code>org.apache.hadoop.hive.ql.udf.generic</code> package.</li>\n+      <li>Should extend <code>UserDefinedAggregateFunction</code> in <code>org.apache.spark.sql.expressions</code> package.</li>\n+    </ul>\n+  </dd>\n+  <dt><code><em>resource_locations</em></code></dt>\n+  <dd>\n+    Specifies the list of resources that contain the implementation of the function\n+    along with its dependencies. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        USING { { (JAR | FILE ) resource_uri} , ...}\n+      </code>\n+  </dd>\n+</dl>\n+\n+### Examples\n+{% highlight sql %}\n+-- 1. Create a simple UDF `SimpleUdf` that adds the supplied integral value by 10.\n+--    import org.apache.hadoop.hive.ql.exec.UDF;\n+--    public class SimpleUdf extends UDF {\n+--      public int evaluate(int value) {\n+--      return value + 10;\n+--      }\n+--    }\n+-- 2. Compile and place it in a jar file called `SimpleUdf.jar` in /tmp.\n+\n+-- Create a table called `test` and insert two rows.\n+CREATE TABLE test(c1 INT);\n+INSERT INTO test VALUES (1), (2);\n+\n+-- Create a permanent function called `simple_udf`. \n+CREATE FUNCTION simple_udf AS 'SimpleUdf'\n+  USING JAR '/tmp/SimpleUdf.jar';\n+\n+-- Verify that the function is in the registry.\n+SHOW USER FUNCTIONS;\n+  +------------------+\n+  |          function|\n+  +------------------+\n+  |default.simple_udf|\n+  +------------------+\n+\n+-- Invoke the function. Every selected value should be incremented by 10.\n+SELECT simple_udf(c1) AS function_return_value FROM t1;\n+  +---------------------+                                                         \n+  |function_return_value|\n+  +---------------------+\n+  |                   11|\n+  |                   12|\n+  +---------------------+\n+\n+-- Created a temporary function.\n+CREATE TEMPORARY FUNCTION simple_temp_udf AS 'SimpleUdf' \n+  USING JAR '/tmp/SimpleUdf.jar';\n+\n+-- Verify that the newly created temporary function is in the registry.\n+-- Please note that the temporary function does not have a qualified\n+-- database associated with it.\n+SHOW USER FUNCTIONS;\n+  +------------------+\n+  |          function|\n+  +------------------+\n+  |default.simple_udf|\n+  |   simple_temp_udf|\n+  +------------------+\n+\n+-- 1. Mofify `SimpleUdf`'s implementation to add supplied integral value by 20."
  }],
  "prId": 25894
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Indent here",
    "commit": "0a964c5dfd49e848142392279d4db509920ebd8d",
    "createdAt": "2019-10-21T17:11:52Z",
    "diffHunk": "@@ -19,4 +19,153 @@ license: |\n   limitations under the License.\n ---\n \n-**This page is under construction**\n+### Description\n+The `CREATE FUNCTION` statement is used to create a temporary or permanent function\n+in Spark. Temporary functions are scoped at a session level where as permanent\n+functions are created in the persistent catalog and are made available to\n+all sessions. The resources specified in the `USING` clause are made available\n+to all executors when they are executed for the first time. In addition to the\n+SQL interface, spark allows users to create custom user defined scalar and\n+aggregate functions using Scala, Python and Java APIs. Please refer to \n+[scalar_functions](sql-getting-started.html#scalar-functions) and \n+[aggregate functions](sql-getting-started#aggregations) for more information.\n+\n+### Syntax\n+{% highlight sql %}\n+CREATE [ OR REPLACE ] [ TEMPORARY ] FUNCTION [ IF NOT EXISTS ]\n+    function_name AS class_name [ resource_locations ]\n+{% endhighlight %}\n+\n+### Parameters\n+<dl>\n+  <dt><code><em>OR REPLACE</em></code></dt>\n+  <dd>\n+    If specified, the resources for function are reloaded. This is mainly useful\n+    to pick up any changes made to the implementation of the function. This\n+    parameter is mutually exclusive to <code>IF NOT EXISTS</code> and can not\n+    be specified together.\n+  </dd>\n+  <dt><code><em>TEMPORARY</em></code></dt>\n+  <dd>\n+    Indicates the scope of function being created. When TEMPORARY is specified, the\n+    created function is valid and visible in the current session. No persistent\n+    entry is made in the catalog for these kind of functions.\n+  </dd>\n+  <dt><code><em>IF NOT EXISTS</em></code></dt>\n+  <dd>\n+    If specified, creates the function only when it does not exist. The creation\n+    of function succeeds (no error is thrown), if the specified function already\n+    exists in the system. This parameter is mutually exclusive to <code> OR REPLACE</code> \n+    and can not be specified together.\n+  </dd>\n+  <dt><code><em>function_name</em></code></dt>\n+  <dd>\n+    Specifies a name of funnction to be created. The function name may be\n+    optionally qualified with a database name. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        [database_name.]function_name\n+      </code>\n+  </dd>\n+  <dt><code><em>class_name</em></code></dt>\n+  <dd>\n+    Specifies the name of the class that provides the implementation for function to be created.\n+    The implementing class should extend from one of the base classes as follows:\n+    <ul>\n+      <li>Should extend <code>UDF</code> or <code>UDAF</code> in <code>org.apache.hadoop.hive.ql.exec</code> package.</li>\n+      <li>Should extend <code>AbstractGenericUDAFResolver</code>, <code>GenericUDF</code>, or\n+          <code>GenericUDTF</code> in <code>org.apache.hadoop.hive.ql.udf.generic</code> package.</li>\n+      <li>Should extend <code>UserDefinedAggregateFunction</code> in <code>org.apache.spark.sql.expressions</code> package.</li>\n+    </ul>\n+  </dd>\n+  <dt><code><em>resource_locations</em></code></dt>\n+  <dd>\n+    Specifies the list of resources that contain the implementation of the function\n+    along with its dependencies. <br><br>\n+    <b>Syntax:</b>\n+      <code>\n+        USING { { (JAR | FILE ) resource_uri} , ...}\n+      </code>\n+  </dd>\n+</dl>\n+\n+### Examples\n+{% highlight sql %}\n+-- 1. Create a simple UDF `SimpleUdf` that adds the supplied integral value by 10.\n+--    import org.apache.hadoop.hive.ql.exec.UDF;\n+--    public class SimpleUdf extends UDF {\n+--      public int evaluate(int value) {\n+--      return value + 10;\n+--      }\n+--    }\n+-- 2. Compile and place it in a jar file called `SimpleUdf.jar` in /tmp.\n+\n+-- Create a table called `test` and insert two rows.\n+CREATE TABLE test(c1 INT);\n+INSERT INTO test VALUES (1), (2);\n+\n+-- Create a permanent function called `simple_udf`. \n+CREATE FUNCTION simple_udf AS 'SimpleUdf'\n+  USING JAR '/tmp/SimpleUdf.jar';\n+\n+-- Verify that the function is in the registry.\n+SHOW USER FUNCTIONS;\n+  +------------------+\n+  |          function|\n+  +------------------+\n+  |default.simple_udf|\n+  +------------------+\n+\n+-- Invoke the function. Every selected value should be incremented by 10.\n+SELECT simple_udf(c1) AS function_return_value FROM t1;\n+  +---------------------+                                                         \n+  |function_return_value|\n+  +---------------------+\n+  |                   11|\n+  |                   12|\n+  +---------------------+\n+\n+-- Created a temporary function.\n+CREATE TEMPORARY FUNCTION simple_temp_udf AS 'SimpleUdf' \n+  USING JAR '/tmp/SimpleUdf.jar';\n+\n+-- Verify that the newly created temporary function is in the registry.\n+-- Please note that the temporary function does not have a qualified\n+-- database associated with it.\n+SHOW USER FUNCTIONS;\n+  +------------------+\n+  |          function|\n+  +------------------+\n+  |default.simple_udf|\n+  |   simple_temp_udf|\n+  +------------------+\n+\n+-- 1. Mofify `SimpleUdf`'s implementation to add supplied integral value by 20.\n+--    import org.apache.hadoop.hive.ql.exec.UDF;\n+  \n+--    public class SimpleUdfR extends UDF {\n+--      public int evaluate(int value) {\n+--      return value + 20;"
  }],
  "prId": 25894
}]