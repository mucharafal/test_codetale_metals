[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "this migration guide should have been added when we switch to Scala 2.12.",
    "commit": "e0053af5e5b927ad3681fb2d61585a3d993bc3f1",
    "createdAt": "2019-01-09T11:15:59Z",
    "diffHunk": "@@ -43,6 +43,8 @@ displayTitle: Spark SQL Upgrading Guide\n \n   - Since Spark 3.0, JSON datasource and JSON function `schema_of_json` infer TimestampType from string values if they match to the pattern defined by the JSON option `timestampFormat`. Set JSON option `inferTimestamp` to `false` to disable such type inferring.\n \n+  - In Spark version 2.4 and earlier, if `org.apache.spark.sql.functions.udf(Any, DataType)` gets a Scala closure with primitive-type argument, the returned UDF will return null if the input values is null. Since Spark 3.0, the UDF will return the default value of the Java type if the input value is null. For example, `val f = udf((x: Int) => x, IntegerType)`, `f($\"x\")` will return null in Spark 2.4 and earlier if column `x` is null, and return 0 in Spark 3.0."
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "should this say this is because of Scala 2.12?",
    "commit": "e0053af5e5b927ad3681fb2d61585a3d993bc3f1",
    "createdAt": "2019-01-10T07:30:23Z",
    "diffHunk": "@@ -43,6 +43,8 @@ displayTitle: Spark SQL Upgrading Guide\n \n   - Since Spark 3.0, JSON datasource and JSON function `schema_of_json` infer TimestampType from string values if they match to the pattern defined by the JSON option `timestampFormat`. Set JSON option `inferTimestamp` to `false` to disable such type inferring.\n \n+  - In Spark version 2.4 and earlier, if `org.apache.spark.sql.functions.udf(Any, DataType)` gets a Scala closure with primitive-type argument, the returned UDF will return null if the input values is null. Since Spark 3.0, the UDF will return the default value of the Java type if the input value is null. For example, `val f = udf((x: Int) => x, IntegerType)`, `f($\"x\")` will return null in Spark 2.4 and earlier if column `x` is null, and return 0 in Spark 3.0."
  }],
  "prId": 23498
}]