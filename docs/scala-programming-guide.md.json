[{
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "Not your change, but I think this should say \"will be persisted in memory or on disk on the nodes\"\n",
    "commit": "11793ce7e18a3ac2b6c0d562841f60d6c8ac19ec",
    "createdAt": "2014-05-06T17:59:50Z",
    "diffHunk": "@@ -278,10 +278,13 @@ iterative algorithms with Spark and for interactive use from the interpreter.\n You can mark an RDD to be persisted using the `persist()` or `cache()` methods on it. The first time\n it is computed in an action, it will be kept in memory on the nodes. The cache is fault-tolerant --"
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "Oh sorry - nevermind, this is explained below and this case only refers to calling `persist()` without arguments.\n",
    "commit": "11793ce7e18a3ac2b6c0d562841f60d6c8ac19ec",
    "createdAt": "2014-05-06T18:02:20Z",
    "diffHunk": "@@ -278,10 +278,13 @@ iterative algorithms with Spark and for interactive use from the interpreter.\n You can mark an RDD to be persisted using the `persist()` or `cache()` methods on it. The first time\n it is computed in an action, it will be kept in memory on the nodes. The cache is fault-tolerant --"
  }],
  "prId": 668
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "It's a great idea to have this here. This is a totally non-obvious fact and I think many users would like to know this.\n\nMy only thought is, would you mind moving this to the end of the \"RDD Persistence\" section. Also, at this point in the guide I don't think the concept of stages or jobs has been introduced. So it might be good to have something like:\n\n```\nSpark sometimes automatically persists intermediate state from RDD operations, even without users calling\npersist() or cache(). In particular, if a shuffle happens when computing an RDD, Spark will keep the outputs\nfrom the map side of the shuffle on disk to avoid re-computing the entire dependency graph if an RDD\n is re-used. We still recommend users call persist() if they plan to re-use an RDD iteratively.\n```\n",
    "commit": "11793ce7e18a3ac2b6c0d562841f60d6c8ac19ec",
    "createdAt": "2014-05-06T18:26:34Z",
    "diffHunk": "@@ -278,10 +278,13 @@ iterative algorithms with Spark and for interactive use from the interpreter.\n You can mark an RDD to be persisted using the `persist()` or `cache()` methods on it. The first time\n it is computed in an action, it will be kept in memory on the nodes. The cache is fault-tolerant --\n if any partition of an RDD is lost, it will automatically be recomputed using the transformations\n-that originally created it.\n+that originally created it. Note: in a multi-stage job, Spark saves the map output files from map"
  }],
  "prId": 668
}]