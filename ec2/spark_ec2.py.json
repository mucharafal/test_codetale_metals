[{
  "comments": [{
    "author": {
      "login": "nchammas"
    },
    "body": "I noticed we were overwriting `conn` here so I removed this line, though it's unrelated to this patch.\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-07T22:28:06Z",
    "diffHunk": "@@ -706,9 +697,7 @@ def wait_for_cluster_state(conn, opts, cluster_instances, cluster_state):\n     sys.stdout.flush()\n \n     start_time = datetime.now()\n-\n     num_attempts = 0\n-    conn = ec2.connect_to_region(opts.region)",
    "line": 111
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "what does this do? Why is it safe to remove?\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-08T19:52:49Z",
    "diffHunk": "@@ -706,9 +697,7 @@ def wait_for_cluster_state(conn, opts, cluster_instances, cluster_state):\n     sys.stdout.flush()\n \n     start_time = datetime.now()\n-\n     num_attempts = 0\n-    conn = ec2.connect_to_region(opts.region)",
    "line": 111
  }, {
    "author": {
      "login": "nchammas"
    },
    "body": "It opens a connection to EC2. But since we are [already passed in a connection as `conn`](https://github.com/apache/spark/pull/3939#discussion-diff-22621704L693), there is no need to recreate this.\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-08T22:03:26Z",
    "diffHunk": "@@ -706,9 +697,7 @@ def wait_for_cluster_state(conn, opts, cluster_instances, cluster_state):\n     sys.stdout.flush()\n \n     start_time = datetime.now()\n-\n     num_attempts = 0\n-    conn = ec2.connect_to_region(opts.region)",
    "line": 111
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "I see. That does seem to be the case\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-09T01:39:59Z",
    "diffHunk": "@@ -706,9 +697,7 @@ def wait_for_cluster_state(conn, opts, cluster_instances, cluster_state):\n     sys.stdout.flush()\n \n     start_time = datetime.now()\n-\n     num_attempts = 0\n-    conn = ec2.connect_to_region(opts.region)",
    "line": 111
  }],
  "prId": 3939
}, {
  "comments": [{
    "author": {
      "login": "nchammas"
    },
    "body": "@shivaram @JoshRosen Do you know why we allow versions to be passed in as `v1.2.0` (with a leading `v`)? Is it safe to remove this option?\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-07T22:48:02Z",
    "diffHunk": "@@ -815,13 +804,11 @@ def deploy_files(conn, root_dir, opts, master_nodes, slave_nodes, modules):\n     cluster_url = \"%s:7077\" % active_master\n \n     if \".\" in opts.spark_version:\n-        # Pre-built spark & shark deploy\n-        (spark_v, shark_v) = get_spark_shark_version(opts)\n+        # Pre-built Spark deploy\n+        spark_v = opts.spark_version.replace(\"v\", \"\")"
  }, {
    "author": {
      "login": "shivaram"
    },
    "body": "Well our git tags are `v1.2.0` etc. so it kind of makes sense to support it\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-07T23:14:46Z",
    "diffHunk": "@@ -815,13 +804,11 @@ def deploy_files(conn, root_dir, opts, master_nodes, slave_nodes, modules):\n     cluster_url = \"%s:7077\" % active_master\n \n     if \".\" in opts.spark_version:\n-        # Pre-built spark & shark deploy\n-        (spark_v, shark_v) = get_spark_shark_version(opts)\n+        # Pre-built Spark deploy\n+        spark_v = opts.spark_version.replace(\"v\", \"\")"
  }, {
    "author": {
      "login": "nchammas"
    },
    "body": ":ok: :+1: \n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-07T23:21:24Z",
    "diffHunk": "@@ -815,13 +804,11 @@ def deploy_files(conn, root_dir, opts, master_nodes, slave_nodes, modules):\n     cluster_url = \"%s:7077\" % active_master\n \n     if \".\" in opts.spark_version:\n-        # Pre-built spark & shark deploy\n-        (spark_v, shark_v) = get_spark_shark_version(opts)\n+        # Pre-built Spark deploy\n+        spark_v = opts.spark_version.replace(\"v\", \"\")"
  }],
  "prId": 3939
}, {
  "comments": [{
    "author": {
      "login": "nchammas"
    },
    "body": "I moved this validation down here because it's very frustrating to wait upwards of 6 minutes for a cluster to launch before finding out that you fat-fingered the version of Spark you wanted.\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-07T22:49:02Z",
    "diffHunk": "@@ -983,6 +969,12 @@ def real_main():\n     (opts, action, cluster_name) = parse_args()\n \n     # Input parameter validation\n+    if \".\" in opts.spark_version:"
  }, {
    "author": {
      "login": "shivaram"
    },
    "body": "Minor comment: Since we do this spark_version.replace(\"v\", \"\") in two places it might make sense to keep the old function but name it as `get_spark_version` (or `check_get_spark_version`). You can then call it once here and once while constructing the template variables\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-08T05:30:44Z",
    "diffHunk": "@@ -983,6 +969,12 @@ def real_main():\n     (opts, action, cluster_name) = parse_args()\n \n     # Input parameter validation\n+    if \".\" in opts.spark_version:"
  }, {
    "author": {
      "login": "nchammas"
    },
    "body": "Will do. I asked about getting rid of the `replace(\"v\", \"\")` so I wouldn't have to do that, but that didn't fly. :)\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-08T18:31:55Z",
    "diffHunk": "@@ -983,6 +969,12 @@ def real_main():\n     (opts, action, cluster_name) = parse_args()\n \n     # Input parameter validation\n+    if \".\" in opts.spark_version:"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "+1 on failing fast here\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-08T19:54:51Z",
    "diffHunk": "@@ -983,6 +969,12 @@ def real_main():\n     (opts, action, cluster_name) = parse_args()\n \n     # Input parameter validation\n+    if \".\" in opts.spark_version:"
  }],
  "prId": 3939
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "not your code, but where is `0.9.2`?\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-08T19:50:22Z",
    "diffHunk": "@@ -39,10 +39,24 @@\n from optparse import OptionParser\n from sys import stderr\n \n+VALID_SPARK_VERSIONS = set([\n+    \"0.7.3\",\n+    \"0.8.0\",\n+    \"0.8.1\",\n+    \"0.9.0\",\n+    \"0.9.1\",",
    "line": 9
  }, {
    "author": {
      "login": "nchammas"
    },
    "body": "Added.\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-08T22:03:51Z",
    "diffHunk": "@@ -39,10 +39,24 @@\n from optparse import OptionParser\n from sys import stderr\n \n+VALID_SPARK_VERSIONS = set([\n+    \"0.7.3\",\n+    \"0.8.0\",\n+    \"0.8.1\",\n+    \"0.9.0\",\n+    \"0.9.1\",",
    "line": 9
  }],
  "prId": 3939
}, {
  "comments": [{
    "author": {
      "login": "nchammas"
    },
    "body": "FYI: I added validation of git hashes here.\n",
    "commit": "66e0841132331d0283ffdbd7a8e8203a67bd9d77",
    "createdAt": "2015-01-08T22:53:47Z",
    "diffHunk": "@@ -236,6 +252,26 @@ def get_or_make_group(conn, name, vpc_id):\n         return conn.create_security_group(name, \"Spark EC2 group\", vpc_id)\n \n \n+def get_validate_spark_version(version, repo):\n+    if \".\" in version:\n+        version = version.replace(\"v\", \"\")\n+        if version not in VALID_SPARK_VERSIONS:\n+            print >> stderr, \"Don't know about Spark version: {v}\".format(v=version)\n+            sys.exit(1)\n+        return version\n+    else:",
    "line": 50
  }],
  "prId": 3939
}]