[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Eh, should we remove those same conditions?",
    "commit": "3b7414d9adf55ef74ce2d81403e570e5d6951a05",
    "createdAt": "2018-09-29T10:47:48Z",
    "diffHunk": "@@ -18,50 +18,55 @@\n library(testthat)\n library(SparkR)\n \n-# Turn all warnings into errors\n-options(\"warn\" = 2)\n+# SPARK-25572\n+if (identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {\n \n-if (.Platform$OS.type == \"windows\") {\n-  Sys.setenv(TZ = \"GMT\")\n-}\n+  # Turn all warnings into errors\n+  options(\"warn\" = 2)\n \n-# Setup global test environment\n-# Install Spark first to set SPARK_HOME\n+  if (.Platform$OS.type == \"windows\") {\n+    Sys.setenv(TZ = \"GMT\")\n+  }\n \n-# NOTE(shivaram): We set overwrite to handle any old tar.gz files or directories left behind on\n-# CRAN machines. For Jenkins we should already have SPARK_HOME set.\n-install.spark(overwrite = TRUE)\n+  # Setup global test environment\n+  # Install Spark first to set SPARK_HOME\n \n-sparkRDir <- file.path(Sys.getenv(\"SPARK_HOME\"), \"R\")\n-sparkRWhitelistSQLDirs <- c(\"spark-warehouse\", \"metastore_db\")\n-invisible(lapply(sparkRWhitelistSQLDirs,\n-                 function(x) { unlink(file.path(sparkRDir, x), recursive = TRUE, force = TRUE)}))\n-sparkRFilesBefore <- list.files(path = sparkRDir, all.files = TRUE)\n+  # NOTE(shivaram): We set overwrite to handle any old tar.gz files or directories left behind on\n+  # CRAN machines. For Jenkins we should already have SPARK_HOME set.\n+  install.spark(overwrite = TRUE)\n \n-sparkRTestMaster <- \"local[1]\"\n-sparkRTestConfig <- list()\n-if (identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {\n-  sparkRTestMaster <- \"\"\n-} else {\n-  # Disable hsperfdata on CRAN\n-  old_java_opt <- Sys.getenv(\"_JAVA_OPTIONS\")\n-  Sys.setenv(\"_JAVA_OPTIONS\" = paste(\"-XX:-UsePerfData\", old_java_opt))\n-  tmpDir <- tempdir()\n-  tmpArg <- paste0(\"-Djava.io.tmpdir=\", tmpDir)\n-  sparkRTestConfig <- list(spark.driver.extraJavaOptions = tmpArg,\n-                           spark.executor.extraJavaOptions = tmpArg)\n-}\n+  sparkRDir <- file.path(Sys.getenv(\"SPARK_HOME\"), \"R\")\n+  sparkRWhitelistSQLDirs <- c(\"spark-warehouse\", \"metastore_db\")\n+  invisible(lapply(sparkRWhitelistSQLDirs,\n+                   function(x) { unlink(file.path(sparkRDir, x), recursive = TRUE, force = TRUE)}))\n+  sparkRFilesBefore <- list.files(path = sparkRDir, all.files = TRUE)\n \n-test_package(\"SparkR\")\n+  sparkRTestMaster <- \"local[1]\"\n+  sparkRTestConfig <- list()\n+  if (identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {\n+    sparkRTestMaster <- \"\"\n+  } else {\n+    # Disable hsperfdata on CRAN\n+    old_java_opt <- Sys.getenv(\"_JAVA_OPTIONS\")\n+    Sys.setenv(\"_JAVA_OPTIONS\" = paste(\"-XX:-UsePerfData\", old_java_opt))\n+    tmpDir <- tempdir()\n+    tmpArg <- paste0(\"-Djava.io.tmpdir=\", tmpDir)\n+    sparkRTestConfig <- list(spark.driver.extraJavaOptions = tmpArg,\n+                             spark.executor.extraJavaOptions = tmpArg)\n+  }\n \n-if (identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {\n-  # set random seed for predictable results. mostly for base's sample() in tree and classification\n-  set.seed(42)\n-  # for testthat 1.0.2 later, change reporter from \"summary\" to default_reporter()\n-  testthat:::run_tests(\"SparkR\",\n-                       file.path(sparkRDir, \"pkg\", \"tests\", \"fulltests\"),\n-                       NULL,\n-                       \"summary\")\n-}\n+  test_package(\"SparkR\")\n+\n+  if (identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {",
    "line": 81
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "We are trying this now - we can clean it up if this works\r\n",
    "commit": "3b7414d9adf55ef74ce2d81403e570e5d6951a05",
    "createdAt": "2018-09-29T21:46:25Z",
    "diffHunk": "@@ -18,50 +18,55 @@\n library(testthat)\n library(SparkR)\n \n-# Turn all warnings into errors\n-options(\"warn\" = 2)\n+# SPARK-25572\n+if (identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {\n \n-if (.Platform$OS.type == \"windows\") {\n-  Sys.setenv(TZ = \"GMT\")\n-}\n+  # Turn all warnings into errors\n+  options(\"warn\" = 2)\n \n-# Setup global test environment\n-# Install Spark first to set SPARK_HOME\n+  if (.Platform$OS.type == \"windows\") {\n+    Sys.setenv(TZ = \"GMT\")\n+  }\n \n-# NOTE(shivaram): We set overwrite to handle any old tar.gz files or directories left behind on\n-# CRAN machines. For Jenkins we should already have SPARK_HOME set.\n-install.spark(overwrite = TRUE)\n+  # Setup global test environment\n+  # Install Spark first to set SPARK_HOME\n \n-sparkRDir <- file.path(Sys.getenv(\"SPARK_HOME\"), \"R\")\n-sparkRWhitelistSQLDirs <- c(\"spark-warehouse\", \"metastore_db\")\n-invisible(lapply(sparkRWhitelistSQLDirs,\n-                 function(x) { unlink(file.path(sparkRDir, x), recursive = TRUE, force = TRUE)}))\n-sparkRFilesBefore <- list.files(path = sparkRDir, all.files = TRUE)\n+  # NOTE(shivaram): We set overwrite to handle any old tar.gz files or directories left behind on\n+  # CRAN machines. For Jenkins we should already have SPARK_HOME set.\n+  install.spark(overwrite = TRUE)\n \n-sparkRTestMaster <- \"local[1]\"\n-sparkRTestConfig <- list()\n-if (identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {\n-  sparkRTestMaster <- \"\"\n-} else {\n-  # Disable hsperfdata on CRAN\n-  old_java_opt <- Sys.getenv(\"_JAVA_OPTIONS\")\n-  Sys.setenv(\"_JAVA_OPTIONS\" = paste(\"-XX:-UsePerfData\", old_java_opt))\n-  tmpDir <- tempdir()\n-  tmpArg <- paste0(\"-Djava.io.tmpdir=\", tmpDir)\n-  sparkRTestConfig <- list(spark.driver.extraJavaOptions = tmpArg,\n-                           spark.executor.extraJavaOptions = tmpArg)\n-}\n+  sparkRDir <- file.path(Sys.getenv(\"SPARK_HOME\"), \"R\")\n+  sparkRWhitelistSQLDirs <- c(\"spark-warehouse\", \"metastore_db\")\n+  invisible(lapply(sparkRWhitelistSQLDirs,\n+                   function(x) { unlink(file.path(sparkRDir, x), recursive = TRUE, force = TRUE)}))\n+  sparkRFilesBefore <- list.files(path = sparkRDir, all.files = TRUE)\n \n-test_package(\"SparkR\")\n+  sparkRTestMaster <- \"local[1]\"\n+  sparkRTestConfig <- list()\n+  if (identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {\n+    sparkRTestMaster <- \"\"\n+  } else {\n+    # Disable hsperfdata on CRAN\n+    old_java_opt <- Sys.getenv(\"_JAVA_OPTIONS\")\n+    Sys.setenv(\"_JAVA_OPTIONS\" = paste(\"-XX:-UsePerfData\", old_java_opt))\n+    tmpDir <- tempdir()\n+    tmpArg <- paste0(\"-Djava.io.tmpdir=\", tmpDir)\n+    sparkRTestConfig <- list(spark.driver.extraJavaOptions = tmpArg,\n+                             spark.executor.extraJavaOptions = tmpArg)\n+  }\n \n-if (identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {\n-  # set random seed for predictable results. mostly for base's sample() in tree and classification\n-  set.seed(42)\n-  # for testthat 1.0.2 later, change reporter from \"summary\" to default_reporter()\n-  testthat:::run_tests(\"SparkR\",\n-                       file.path(sparkRDir, \"pkg\", \"tests\", \"fulltests\"),\n-                       NULL,\n-                       \"summary\")\n-}\n+  test_package(\"SparkR\")\n+\n+  if (identical(Sys.getenv(\"NOT_CRAN\"), \"true\")) {",
    "line": 81
  }],
  "prId": 22589
}]