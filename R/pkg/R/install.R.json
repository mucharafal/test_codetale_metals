[{
  "comments": [{
    "author": {
      "login": "shivaram"
    },
    "body": "any reason to  change the return value here ?",
    "commit": "9b21c1125998b09607dc40c57dcd579d322b6f6e",
    "createdAt": "2017-01-16T17:42:55Z",
    "diffHunk": "@@ -54,7 +54,7 @@\n #'                 }\n #' @param overwrite If \\code{TRUE}, download and overwrite the existing tar file in localDir\n #'                  and force re-install Spark (in case the local directory or file is corrupted)\n-#' @return \\code{install.spark} returns the local directory where Spark is found or installed\n+#' @return the (invisible) local directory where Spark is found or installed",
    "line": 5
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "it wasn't actually - it was always invisible - see [here](https://github.com/apache/spark/pull/16589/files/9b21c1125998b09607dc40c57dcd579d322b6f6e#diff-48b5d60aba76122785461e1c2b125f51R150), just not documented as such. Also referencing the method name and saying `returns` again is redundant as this would go to the return section of the generated doc.\r\n",
    "commit": "9b21c1125998b09607dc40c57dcd579d322b6f6e",
    "createdAt": "2017-01-16T18:33:36Z",
    "diffHunk": "@@ -54,7 +54,7 @@\n #'                 }\n #' @param overwrite If \\code{TRUE}, download and overwrite the existing tar file in localDir\n #'                  and force re-install Spark (in case the local directory or file is corrupted)\n-#' @return \\code{install.spark} returns the local directory where Spark is found or installed\n+#' @return the (invisible) local directory where Spark is found or installed",
    "line": 5
  }, {
    "author": {
      "login": "shivaram"
    },
    "body": "Got it. Thanks",
    "commit": "9b21c1125998b09607dc40c57dcd579d322b6f6e",
    "createdAt": "2017-01-16T19:08:01Z",
    "diffHunk": "@@ -54,7 +54,7 @@\n #'                 }\n #' @param overwrite If \\code{TRUE}, download and overwrite the existing tar file in localDir\n #'                  and force re-install Spark (in case the local directory or file is corrupted)\n-#' @return \\code{install.spark} returns the local directory where Spark is found or installed\n+#' @return the (invisible) local directory where Spark is found or installed",
    "line": 5
  }],
  "prId": 16589
}, {
  "comments": [{
    "author": {
      "login": "shivaram"
    },
    "body": "Any reason to not use this `Fetch failed from` error message and instead use the error message from `download.file`",
    "commit": "9b21c1125998b09607dc40c57dcd579d322b6f6e",
    "createdAt": "2017-01-16T17:47:43Z",
    "diffHunk": "@@ -201,14 +221,20 @@ directDownloadTar <- function(mirrorUrl, version, hadoopVersion, packageName, pa\n   msg <- sprintf(fmt, version, ifelse(hadoopVersion == \"without\", \"Free build\", hadoopVersion),\n                  packageRemotePath)\n   message(msg)\n-  downloadUrl(packageRemotePath, packageLocalPath, paste0(\"Fetch failed from \", mirrorUrl))\n+  downloadUrl(packageRemotePath, packageLocalPath)",
    "line": 85
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "It's still there. Both messages `Fetch failed` and error message from `download.file` were there before.\r\n\r\nBefore it is passing the url string several method calls deep, instead, I handle the error up in the stack and display the same message like in [here L121](https://github.com/apache/spark/pull/16589/files/9b21c1125998b09607dc40c57dcd579d322b6f6e#diff-48b5d60aba76122785461e1c2b125f51R121), and with url [here L176](https://github.com/apache/spark/pull/16589/files/9b21c1125998b09607dc40c57dcd579d322b6f6e#diff-48b5d60aba76122785461e1c2b125f51R176)\r\n",
    "commit": "9b21c1125998b09607dc40c57dcd579d322b6f6e",
    "createdAt": "2017-01-16T18:38:01Z",
    "diffHunk": "@@ -201,14 +221,20 @@ directDownloadTar <- function(mirrorUrl, version, hadoopVersion, packageName, pa\n   msg <- sprintf(fmt, version, ifelse(hadoopVersion == \"without\", \"Free build\", hadoopVersion),\n                  packageRemotePath)\n   message(msg)\n-  downloadUrl(packageRemotePath, packageLocalPath, paste0(\"Fetch failed from \", mirrorUrl))\n+  downloadUrl(packageRemotePath, packageLocalPath)",
    "line": 85
  }, {
    "author": {
      "login": "shivaram"
    },
    "body": "I didn't relate this to the update in L176 - I think this is fine. In general I think this file has gotten a little unwieldy with error messages coming from different functions. I wonder if there is a better way to refactor things to setup some expectations on where errors are thrown etc.",
    "commit": "9b21c1125998b09607dc40c57dcd579d322b6f6e",
    "createdAt": "2017-01-18T04:56:33Z",
    "diffHunk": "@@ -201,14 +221,20 @@ directDownloadTar <- function(mirrorUrl, version, hadoopVersion, packageName, pa\n   msg <- sprintf(fmt, version, ifelse(hadoopVersion == \"without\", \"Free build\", hadoopVersion),\n                  packageRemotePath)\n   message(msg)\n-  downloadUrl(packageRemotePath, packageLocalPath, paste0(\"Fetch failed from \", mirrorUrl))\n+  downloadUrl(packageRemotePath, packageLocalPath)",
    "line": 85
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "yea I agree. I guess I'm trying to bubble up error messages to the top level but generally without exception to throw is making this non-trivial (never thought I'd say that!)\r\n\r\npassing all the extra pieces of info around just to display them in error messages doesn't seem very intuitive either..",
    "commit": "9b21c1125998b09607dc40c57dcd579d322b6f6e",
    "createdAt": "2017-01-18T05:18:57Z",
    "diffHunk": "@@ -201,14 +221,20 @@ directDownloadTar <- function(mirrorUrl, version, hadoopVersion, packageName, pa\n   msg <- sprintf(fmt, version, ifelse(hadoopVersion == \"without\", \"Free build\", hadoopVersion),\n                  packageRemotePath)\n   message(msg)\n-  downloadUrl(packageRemotePath, packageLocalPath, paste0(\"Fetch failed from \", mirrorUrl))\n+  downloadUrl(packageRemotePath, packageLocalPath)",
    "line": 85
  }],
  "prId": 16589
}]