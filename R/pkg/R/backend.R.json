[{
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "`-1` -> `+1`?\n",
    "commit": "666b60947b46ca013b9a0a7dd014f2e6580ceb50",
    "createdAt": "2016-10-19T21:31:14Z",
    "diffHunk": "@@ -108,13 +108,27 @@ invokeJava <- function(isStatic, objId, methodName, ...) {\n   conn <- get(\".sparkRCon\", .sparkREnv)\n   writeBin(requestMessage, conn)\n \n-  # TODO: check the status code to output error information\n   returnStatus <- readInt(conn)\n+  handleErrors(returnStatus, conn)\n+\n+  # Backend will send -1 as keep alive value to prevent various connection timeouts"
  }],
  "prId": 15471
}, {
  "comments": [{
    "author": {
      "login": "QCTW"
    },
    "body": "Shoudn't it have a retry limit for the returnStatus check to avoid infinite loop?\r\n\r\nI have an infinite loop when the it is called by Toree sparkr_runner.R with error message \"Failed to connect JVM: Error in socketConnection(host = hostname, port = port, server = FALSE, : argument \"timeout\" is missing, with no default\"",
    "commit": "666b60947b46ca013b9a0a7dd014f2e6580ceb50",
    "createdAt": "2017-07-17T17:34:20Z",
    "diffHunk": "@@ -108,13 +108,27 @@ invokeJava <- function(isStatic, objId, methodName, ...) {\n   conn <- get(\".sparkRCon\", .sparkREnv)\n   writeBin(requestMessage, conn)\n \n-  # TODO: check the status code to output error information\n   returnStatus <- readInt(conn)\n+  handleErrors(returnStatus, conn)\n+\n+  # Backend will send -1 as keep alive value to prevent various connection timeouts\n+  # on very long running jobs. See spark.r.heartBeatInterval\n+  while (returnStatus == 1) {"
  }, {
    "author": {
      "login": "shivaram"
    },
    "body": "@falaki @felixcheung any thoughts on this ?",
    "commit": "666b60947b46ca013b9a0a7dd014f2e6580ceb50",
    "createdAt": "2017-07-19T16:41:49Z",
    "diffHunk": "@@ -108,13 +108,27 @@ invokeJava <- function(isStatic, objId, methodName, ...) {\n   conn <- get(\".sparkRCon\", .sparkREnv)\n   writeBin(requestMessage, conn)\n \n-  # TODO: check the status code to output error information\n   returnStatus <- readInt(conn)\n+  handleErrors(returnStatus, conn)\n+\n+  # Backend will send -1 as keep alive value to prevent various connection timeouts\n+  # on very long running jobs. See spark.r.heartBeatInterval\n+  while (returnStatus == 1) {"
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "+1 I think it's a good idea to avoid infinite loop in general.\r\nhow is toree calling this?\r\ncould you open a JIRA?\r\n",
    "commit": "666b60947b46ca013b9a0a7dd014f2e6580ceb50",
    "createdAt": "2017-07-19T17:24:24Z",
    "diffHunk": "@@ -108,13 +108,27 @@ invokeJava <- function(isStatic, objId, methodName, ...) {\n   conn <- get(\".sparkRCon\", .sparkREnv)\n   writeBin(requestMessage, conn)\n \n-  # TODO: check the status code to output error information\n   returnStatus <- readInt(conn)\n+  handleErrors(returnStatus, conn)\n+\n+  # Backend will send -1 as keep alive value to prevent various connection timeouts\n+  # on very long running jobs. See spark.r.heartBeatInterval\n+  while (returnStatus == 1) {"
  }],
  "prId": 15471
}]