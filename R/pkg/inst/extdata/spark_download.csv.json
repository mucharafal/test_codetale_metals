[{
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "I wouldn't recommend hardcoding or relying on certain mirrors - apache mirrors are sort of dynamic - it's better to pull from \nhttp://www.apache.org/dyn/closer.cgi?as_json=1\nlike\nhttp://www.apache.org/dyn/closer.lua/spark/spark-1.6.2/spark-1.6.2-bin-hadoop2.6.tgz\n",
    "commit": "3aeb4ebe7b18f5b26914cdf730cced3eb536f48d",
    "createdAt": "2016-07-19T21:31:55Z",
    "diffHunk": "@@ -0,0 +1,2 @@\n+\"url\",\"default\"\n+\"http://apache.osuosl.org\",TRUE"
  }, {
    "author": {
      "login": "junyangq"
    },
    "body": "Combined with the previous comment: It turns out this would be similar to what sparklyr did. They provide a remote table as well as one shipped with the package that lists supported versions and their download addresses. \n",
    "commit": "3aeb4ebe7b18f5b26914cdf730cced3eb536f48d",
    "createdAt": "2016-07-19T23:03:40Z",
    "diffHunk": "@@ -0,0 +1,2 @@\n+\"url\",\"default\"\n+\"http://apache.osuosl.org\",TRUE"
  }, {
    "author": {
      "login": "sun-rui"
    },
    "body": "I don't see the strong reason for a CSV file listing available mirrors. Because we can support apache dynamic mirrors, and install_spark() has a parameter allowing user to pass a vector of mirror sites.\n",
    "commit": "3aeb4ebe7b18f5b26914cdf730cced3eb536f48d",
    "createdAt": "2016-07-21T15:31:45Z",
    "diffHunk": "@@ -0,0 +1,2 @@\n+\"url\",\"default\"\n+\"http://apache.osuosl.org\",TRUE"
  }, {
    "author": {
      "login": "junyangq"
    },
    "body": "Yeah, using apache dynamic mirror is great as long as the address does not change. The reason I was thinking of maintaining a (remote) csv file is that we are able to apply any change of the mirror sites without touching the R package...\n",
    "commit": "3aeb4ebe7b18f5b26914cdf730cced3eb536f48d",
    "createdAt": "2016-07-21T17:59:03Z",
    "diffHunk": "@@ -0,0 +1,2 @@\n+\"url\",\"default\"\n+\"http://apache.osuosl.org\",TRUE"
  }],
  "prId": 14258
}]