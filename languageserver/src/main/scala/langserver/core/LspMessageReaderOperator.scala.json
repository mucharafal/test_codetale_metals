[
  {
    "id" : "7b7a16bd-ccba-47ca-9546-347ce9f7454a",
    "prId" : 160,
    "comments" : [
      {
        "id" : "46f68b3a-7eb2-41be-83a9-da9aa8bae85e",
        "parentId" : null,
        "author" : {
          "login" : "ShaneDelmore",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/4604933?v=4"
        },
        "body" : "I chose to use a state machine here in case the header delimiter was broken up across multiple batches.  Not sure how I feel about the verbosity yet.",
        "createdAt" : "2017-12-30T06:36:11Z",
        "updatedAt" : "2018-01-02T01:53:49Z",
        "lastEditedBy" : {
          "login" : "ShaneDelmore",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/4604933?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "6f0d95b7-5c8d-41da-85f5-c08446d8cb5e",
        "parentId" : "46f68b3a-7eb2-41be-83a9-da9aa8bae85e",
        "author" : {
          "login" : "olafurpg",
          "name" : null,
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/1408093?v=4"
        },
        "body" : "I have a feeling we may be able to avoid this state machine by using fastparse-bytes http://www.lihaoyi.com/fastparse/#ByteParsers `Bytes ++ Bytes` and `Bytes.apply(index: Int)` are near constant. `.parse` takes an optional starting index which can be used to start parsing from somewhere inside the index.\r\n\r\n",
        "createdAt" : "2017-12-30T18:19:38Z",
        "updatedAt" : "2018-01-02T01:53:49Z",
        "lastEditedBy" : {
          "login" : "olafurpg",
          "name" : null,
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/1408093?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "fdfaabdedafe21bb43375518f71a14495fb71c23",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,95 @@\n+package langserver.core\n+\n+import langserver.messages.UnparsedLspMessage\n+import monix.execution.Ack.Continue\n+import monix.execution.{Ack, Scheduler}\n+import monix.reactive.observables.ObservableLike.Operator\n+import monix.reactive.observers.Subscriber\n+\n+import scala.concurrent.Future\n+\n+/*\n+  Splits incoming bytes into unparsed LspMessages\n+ */\n+object LspMessageReaderOperator extends Operator[Array[Byte], List[UnparsedLspMessage]]{\n+  //move this into LspMessage?\n+  val CONTENT_LENGTH_KEY = \"Content-Length\"\n+  def parseHeaders(input: String): Map[String, String] = {\n+    val result = input.lines\n+      .filter(_.nonEmpty)\n+      .map(_.split(\":\"))\n+      .map { case Array(k, v) => k -> v.trim }\n+      .toMap\n+    assert(result.contains(CONTENT_LENGTH_KEY), \"Could not parse Content-Length from header\")\n+    result\n+  }\n+\n+  sealed trait HeaderDelimiter {"
  },
  {
    "id" : "d7e8a912-d40e-416e-977e-678e22967e0f",
    "prId" : 160,
    "comments" : [
      {
        "id" : "8898766c-72fb-41c9-99fc-d355886ca8e3",
        "parentId" : null,
        "author" : {
          "login" : "gabro",
          "name" : null,
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/691940?u=5aaf176f5da60764f857b8f8c6842217f737627f&v=4"
        },
        "body" : "super minor, but instead of `\"UTF-8\"` you can do\r\n\r\n```scala\r\nimport java.nio.charset.StandardCharsets.UTF_8\r\nnew String(unusedBuffer.result(), UTF_8)\r\n```\r\n\r\nsame with other Java operations that require a charset, like `getBytes`.",
        "createdAt" : "2017-12-30T12:36:02Z",
        "updatedAt" : "2018-01-02T01:53:49Z",
        "lastEditedBy" : {
          "login" : "gabro",
          "name" : null,
          "avatarUrl" : "https://avatars0.githubusercontent.com/u/691940?u=5aaf176f5da60764f857b8f8c6842217f737627f&v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      },
      {
        "id" : "bda354ea-3225-4268-9e40-c107da13c752",
        "parentId" : "8898766c-72fb-41c9-99fc-d355886ca8e3",
        "author" : {
          "login" : "ShaneDelmore",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/4604933?v=4"
        },
        "body" : "👍 ",
        "createdAt" : "2017-12-30T17:57:55Z",
        "updatedAt" : "2018-01-02T01:53:49Z",
        "lastEditedBy" : {
          "login" : "ShaneDelmore",
          "name" : null,
          "avatarUrl" : "https://avatars1.githubusercontent.com/u/4604933?v=4"
        },
        "tags" : [
          {
            "value" : "outdated"
          }
        ]
      }
    ],
    "commit" : "fdfaabdedafe21bb43375518f71a14495fb71c23",
    "line" : null,
    "diffHunk" : "@@ -0,0 +1,95 @@\n+package langserver.core\n+\n+import langserver.messages.UnparsedLspMessage\n+import monix.execution.Ack.Continue\n+import monix.execution.{Ack, Scheduler}\n+import monix.reactive.observables.ObservableLike.Operator\n+import monix.reactive.observers.Subscriber\n+\n+import scala.concurrent.Future\n+\n+/*\n+  Splits incoming bytes into unparsed LspMessages\n+ */\n+object LspMessageReaderOperator extends Operator[Array[Byte], List[UnparsedLspMessage]]{\n+  //move this into LspMessage?\n+  val CONTENT_LENGTH_KEY = \"Content-Length\"\n+  def parseHeaders(input: String): Map[String, String] = {\n+    val result = input.lines\n+      .filter(_.nonEmpty)\n+      .map(_.split(\":\"))\n+      .map { case Array(k, v) => k -> v.trim }\n+      .toMap\n+    assert(result.contains(CONTENT_LENGTH_KEY), \"Could not parse Content-Length from header\")\n+    result\n+  }\n+\n+  sealed trait HeaderDelimiter {\n+    val CR: Byte = '\\r'.toByte\n+    val NL: Byte = '\\n'.toByte\n+    def getNext(byte: Byte): HeaderDelimiter = this match {\n+      case _ if !((byte == CR) || (byte == NL)) => NotStarted //exit early if not interesting byte\n+      case NotStarted if byte == CR => MatchedOneByte\n+      case MatchedOneByte if byte == NL => MatchedTwoBytes\n+      case MatchedTwoBytes if byte == CR => MatchedThreeBytes\n+      case MatchedThreeBytes if byte == NL => CompleteHeaderDelimiter\n+      case CompleteHeaderDelimiter if byte == CR => MatchedOneByte\n+      case _ => NotStarted //If we don't find the next byte we are looking for reset the search state\n+    }\n+  }\n+  case object NotStarted extends HeaderDelimiter\n+  case object MatchedOneByte extends HeaderDelimiter\n+  case object MatchedTwoBytes extends HeaderDelimiter\n+  case object MatchedThreeBytes extends HeaderDelimiter\n+  case object CompleteHeaderDelimiter extends HeaderDelimiter\n+\n+  def apply(out: Subscriber[List[UnparsedLspMessage]]): Subscriber[Array[Byte]] =\n+    new Subscriber[Array[Byte]] {\n+      //There are two reasons to stop reading bytes, either \\r\\n\\r\\n has been reached\n+      //or n bytes have been read\n+      private val unusedBuffer = Array.newBuilder[Byte]\n+      private var bytesNeeded = 0\n+      private var headerDelimiterState: HeaderDelimiter = NotStarted\n+      private var headers: Map[String, String] = Map()\n+\n+      implicit def scheduler: Scheduler = out.scheduler\n+      override def onError(ex: Throwable): Unit = out.onError(ex)\n+      override def onComplete(): Unit = out.onComplete()\n+\n+      override def onNext(elem: Array[Byte]): Future[Ack] = {\n+        val messages = List.newBuilder[UnparsedLspMessage]\n+        //I opted for simplicity of implementation over performance here.\n+        //Performance could be improved by operating over segments of bytes instead of a byte at a time\n+        def loop(idx: Int): Unit = {\n+          val byte = elem(idx)\n+          unusedBuffer += byte //buffer bytes until we have a complete header or body\n+          headerDelimiterState match {\n+            case CompleteHeaderDelimiter if bytesNeeded == 1 =>\n+              //We just got the last byte needed, fetch contents now\n+              headerDelimiterState == NotStarted\n+              bytesNeeded = 0\n+              val msg = UnparsedLspMessage(headers, unusedBuffer.result())\n+              unusedBuffer.clear()\n+              headers = Map[String, String]()\n+              messages += msg\n+            case CompleteHeaderDelimiter => //waiting for content bytes\n+              bytesNeeded -= 1\n+            case _ => //waiting for header delimiter\n+              headerDelimiterState = headerDelimiterState.getNext(byte)\n+              if (headerDelimiterState == CompleteHeaderDelimiter) {\n+                val header = new String(unusedBuffer.result(), \"UTF-8\")"
  }
]