[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "I think it is ok to just shadow the class member targetStorageLevel rather than adding a weird _ at the end ...\n",
    "commit": "ce17d9581a3e716d755993e464a271d77b536a5e",
    "createdAt": "2014-06-03T20:08:19Z",
    "diffHunk": "@@ -118,11 +130,60 @@ class EdgeRDD[@specialized ED: ClassTag, VD: ClassTag](\n       (f: (VertexId, VertexId, ED, ED2) => ED3): EdgeRDD[ED3, VD] = {\n     val ed2Tag = classTag[ED2]\n     val ed3Tag = classTag[ED3]\n-    new EdgeRDD[ED3, VD](partitionsRDD.zipPartitions(other.partitionsRDD, true) {\n+    this.withPartitionsRDD[ED3, VD](partitionsRDD.zipPartitions(other.partitionsRDD, true) {\n       (thisIter, otherIter) =>\n         val (pid, thisEPart) = thisIter.next()\n         val (_, otherEPart) = otherIter.next()\n         Iterator(Tuple2(pid, thisEPart.innerJoin(otherEPart)(f)(ed2Tag, ed3Tag)))\n     })\n   }\n+\n+  /** Replaces the vertex partitions while preserving all other properties of the VertexRDD. */\n+  private[graphx] def withPartitionsRDD[ED2: ClassTag, VD2: ClassTag](\n+      partitionsRDD_ : RDD[(PartitionID, EdgePartition[ED2, VD2])]): EdgeRDD[ED2, VD2] = {\n+    new EdgeRDD(partitionsRDD_, targetStorageLevel)\n+  }\n+\n+  /**\n+   * Changes the target storage level while preserving all other properties of the\n+   * EdgeRDD. Operations on the returned EdgeRDD will preserve this storage level.\n+   *\n+   * This does not actually trigger a cache; to do this, call\n+   * [[org.apache.spark.graphx.EdgeRDD#cache]] on the returned EdgeRDD.\n+   */\n+  private[graphx] def withTargetStorageLevel(\n+      targetStorageLevel_ : StorageLevel): EdgeRDD[ED, VD] = {"
  }],
  "prId": 946
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Should EdgeRDD be marked `@DeveloperAPI`? Or can users use it directly? This is technically a binary-compat breaking change (though it doesn't affect source compat).\n",
    "commit": "ce17d9581a3e716d755993e464a271d77b536a5e",
    "createdAt": "2014-06-03T21:12:00Z",
    "diffHunk": "@@ -32,7 +33,8 @@ import org.apache.spark.graphx.impl.EdgePartition\n  * `impl.ReplicatedVertexView`.\n  */\n class EdgeRDD[@specialized ED: ClassTag, VD: ClassTag](\n-    val partitionsRDD: RDD[(PartitionID, EdgePartition[ED, VD])])\n+    val partitionsRDD: RDD[(PartitionID, EdgePartition[ED, VD])],\n+    val targetStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY)\n   extends RDD[Edge[ED]](partitionsRDD.context, List(new OneToOneDependency(partitionsRDD))) {",
    "line": 15
  }, {
    "author": {
      "login": "mateiz"
    },
    "body": "BTW you could avoid the breakage by having separate 2-arg and 3-arg constructors but if this is an internal API it's fine to leave it. Just wanted to ask whether users call this directly.\n",
    "commit": "ce17d9581a3e716d755993e464a271d77b536a5e",
    "createdAt": "2014-06-03T21:12:53Z",
    "diffHunk": "@@ -32,7 +33,8 @@ import org.apache.spark.graphx.impl.EdgePartition\n  * `impl.ReplicatedVertexView`.\n  */\n class EdgeRDD[@specialized ED: ClassTag, VD: ClassTag](\n-    val partitionsRDD: RDD[(PartitionID, EdgePartition[ED, VD])])\n+    val partitionsRDD: RDD[(PartitionID, EdgePartition[ED, VD])],\n+    val targetStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY)\n   extends RDD[Edge[ED]](partitionsRDD.context, List(new OneToOneDependency(partitionsRDD))) {",
    "line": 15
  }, {
    "author": {
      "login": "ankurdave"
    },
    "body": "Users may manipulate it directly, because it's returned by `Graph#edges`, but they should never call the constructor. I actually wanted to make this constructor private, but that interfered with Scala specialization.\n",
    "commit": "ce17d9581a3e716d755993e464a271d77b536a5e",
    "createdAt": "2014-06-03T21:13:39Z",
    "diffHunk": "@@ -32,7 +33,8 @@ import org.apache.spark.graphx.impl.EdgePartition\n  * `impl.ReplicatedVertexView`.\n  */\n class EdgeRDD[@specialized ED: ClassTag, VD: ClassTag](\n-    val partitionsRDD: RDD[(PartitionID, EdgePartition[ED, VD])])\n+    val partitionsRDD: RDD[(PartitionID, EdgePartition[ED, VD])],\n+    val targetStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY)\n   extends RDD[Edge[ED]](partitionsRDD.context, List(new OneToOneDependency(partitionsRDD))) {",
    "line": 15
  }, {
    "author": {
      "login": "mateiz"
    },
    "body": "Ah, weird. Probably long-term the way to do it might be to create a `trait EdgeRDD` that users see, and an `EdgeRDDImpl` that is `private[graphx]`.\n",
    "commit": "ce17d9581a3e716d755993e464a271d77b536a5e",
    "createdAt": "2014-06-03T21:15:25Z",
    "diffHunk": "@@ -32,7 +33,8 @@ import org.apache.spark.graphx.impl.EdgePartition\n  * `impl.ReplicatedVertexView`.\n  */\n class EdgeRDD[@specialized ED: ClassTag, VD: ClassTag](\n-    val partitionsRDD: RDD[(PartitionID, EdgePartition[ED, VD])])\n+    val partitionsRDD: RDD[(PartitionID, EdgePartition[ED, VD])],\n+    val targetStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY)\n   extends RDD[Edge[ED]](partitionsRDD.context, List(new OneToOneDependency(partitionsRDD))) {",
    "line": 15
  }],
  "prId": 946
}]