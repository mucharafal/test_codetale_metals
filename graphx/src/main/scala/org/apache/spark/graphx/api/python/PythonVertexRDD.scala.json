[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Do we need both constructors, or can we just make the first one Py4J-friendly?\n",
    "commit": "d0a747901af273c5eb8578ec191cc7673f6efce5",
    "createdAt": "2015-01-26T19:17:32Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graphx.api.python\n+\n+import java.io.{DataOutputStream, FileOutputStream}\n+import java.util.{ArrayList => JArrayList, List => JList, Map => JMap}\n+\n+import org.apache.spark.Accumulator\n+import org.apache.spark.api.java.{JavaRDD, JavaSparkContext}\n+import org.apache.spark.api.python.{PythonBroadcast, PythonRDD}\n+import org.apache.spark.broadcast.Broadcast\n+import org.apache.spark.graphx.VertexId\n+import org.apache.spark.graphx.api.java.JavaVertexRDD\n+import org.apache.spark.storage.StorageLevel\n+\n+private[graphx] class PythonVertexRDD(\n+    @transient parent: JavaRDD[_],\n+    command: Array[Byte],\n+    envVars: JMap[String, String],\n+    pythonIncludes: JList[String],\n+    preservePartitioning: Boolean,\n+    pythonExec: String,\n+    broadcastVars: JList[Broadcast[PythonBroadcast]],\n+    accumulator: Accumulator[JList[Array[Byte]]],\n+    targetStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY)\n+  extends PythonRDD (parent, command, envVars,\n+                     pythonIncludes, preservePartitioning,\n+                     pythonExec, broadcastVars, accumulator) {\n+\n+  def this(@transient parent: JavaVertexRDD[_],",
    "line": 45
  }, {
    "author": {
      "login": "kdatta"
    },
    "body": "I'll try to change this..\n",
    "commit": "d0a747901af273c5eb8578ec191cc7673f6efce5",
    "createdAt": "2015-01-26T19:31:39Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graphx.api.python\n+\n+import java.io.{DataOutputStream, FileOutputStream}\n+import java.util.{ArrayList => JArrayList, List => JList, Map => JMap}\n+\n+import org.apache.spark.Accumulator\n+import org.apache.spark.api.java.{JavaRDD, JavaSparkContext}\n+import org.apache.spark.api.python.{PythonBroadcast, PythonRDD}\n+import org.apache.spark.broadcast.Broadcast\n+import org.apache.spark.graphx.VertexId\n+import org.apache.spark.graphx.api.java.JavaVertexRDD\n+import org.apache.spark.storage.StorageLevel\n+\n+private[graphx] class PythonVertexRDD(\n+    @transient parent: JavaRDD[_],\n+    command: Array[Byte],\n+    envVars: JMap[String, String],\n+    pythonIncludes: JList[String],\n+    preservePartitioning: Boolean,\n+    pythonExec: String,\n+    broadcastVars: JList[Broadcast[PythonBroadcast]],\n+    accumulator: Accumulator[JList[Array[Byte]]],\n+    targetStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY)\n+  extends PythonRDD (parent, command, envVars,\n+                     pythonIncludes, preservePartitioning,\n+                     pythonExec, broadcastVars, accumulator) {\n+\n+  def this(@transient parent: JavaVertexRDD[_],",
    "line": 45
  }],
  "prId": 4205
}]