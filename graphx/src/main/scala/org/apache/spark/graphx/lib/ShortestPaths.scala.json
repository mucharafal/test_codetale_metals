[{
  "comments": [{
    "author": {
      "login": "jegonzal"
    },
    "body": "The scala map data-structures can be pretty costly and inefficient.  Instead you could use an array containing the distances and then maintain a global map (shared by broadcast variable) with the mapping from vertex id to index in the array.  This should also reduce the memory overhead substantially since each vertex will not need to maintain its own locally Map data structure.\n",
    "commit": "88d80da1dab8be71716ed572a5a1e721cf1c015c",
    "createdAt": "2014-04-23T18:31:46Z",
    "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graphx.lib\n+\n+import org.apache.spark.graphx._\n+\n+object ShortestPaths {\n+  type SPMap = Map[VertexId, Int] // map of landmarks -> minimum distance to landmark",
    "line": 23
  }, {
    "author": {
      "login": "jegonzal"
    },
    "body": "Essentially remap the \"landmarks\" to a consecutive landmark id set and then on the initial creation of spGraph you would require using the single broadcast map but from then on no map data structures would be required. \n",
    "commit": "88d80da1dab8be71716ed572a5a1e721cf1c015c",
    "createdAt": "2014-04-23T18:41:05Z",
    "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graphx.lib\n+\n+import org.apache.spark.graphx._\n+\n+object ShortestPaths {\n+  type SPMap = Map[VertexId, Int] // map of landmarks -> minimum distance to landmark",
    "line": 23
  }],
  "prId": 10
}, {
  "comments": [{
    "author": {
      "login": "jegonzal"
    },
    "body": "It might be worth considering adding support for edge weights instead of assuming all edges are length 1.\n",
    "commit": "88d80da1dab8be71716ed572a5a1e721cf1c015c",
    "createdAt": "2014-04-23T18:43:25Z",
    "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graphx.lib\n+\n+import org.apache.spark.graphx._\n+\n+object ShortestPaths {\n+  type SPMap = Map[VertexId, Int] // map of landmarks -> minimum distance to landmark\n+  def SPMap(x: (VertexId, Int)*) = Map(x: _*)\n+  def increment(spmap: SPMap): SPMap = spmap.map { case (v, d) => v -> (d + 1) }\n+  def plus(spmap1: SPMap, spmap2: SPMap): SPMap =\n+    (spmap1.keySet ++ spmap2.keySet).map{\n+      k => k -> scala.math.min(spmap1.getOrElse(k, Int.MaxValue), spmap2.getOrElse(k, Int.MaxValue))\n+    }.toMap\n+\n+  /**\n+   * Compute the shortest paths to each landmark for each vertex and\n+   * return an RDD with the map of landmarks to their shortest-path\n+   * lengths.\n+   *\n+   * @tparam VD the shortest paths map for the vertex\n+   * @tparam ED the incremented shortest-paths map of the originating\n+   * vertex (discarded in the computation)\n+   *\n+   * @param graph the graph for which to compute the shortest paths\n+   * @param landmarks the list of landmark vertex ids\n+   *\n+   * @return a graph with vertex attributes containing a map of the\n+   * shortest paths to each landmark\n+   */\n+  def run[VD, ED](graph: Graph[VD, ED], landmarks: Seq[VertexId])\n+    (implicit m1: Manifest[VD], m2: Manifest[ED]): Graph[SPMap, SPMap] = {\n+\n+    val spGraph = graph\n+      .mapVertices{ (vid, attr) =>\n+        if (landmarks.contains(vid)) SPMap(vid -> 0)\n+        else SPMap()\n+      }\n+      .mapTriplets{ edge => edge.srcAttr }\n+\n+    val initialMessage = SPMap()\n+\n+    def vertexProgram(id: VertexId, attr: SPMap, msg: SPMap): SPMap = {\n+      plus(attr, msg)\n+    }\n+\n+    def sendMessage(edge: EdgeTriplet[SPMap, SPMap]): Iterator[(VertexId, SPMap)] = {\n+      val newAttr = increment(edge.srcAttr)",
    "line": 63
  }],
  "prId": 10
}, {
  "comments": [{
    "author": {
      "login": "jegonzal"
    },
    "body": "If we switch to an array implementation of the map then perhaps set the distance to MaxInt (or MaxDouble if we switch to weighted edge).\n",
    "commit": "88d80da1dab8be71716ed572a5a1e721cf1c015c",
    "createdAt": "2014-04-23T18:44:58Z",
    "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graphx.lib\n+\n+import org.apache.spark.graphx._\n+\n+object ShortestPaths {\n+  type SPMap = Map[VertexId, Int] // map of landmarks -> minimum distance to landmark\n+  def SPMap(x: (VertexId, Int)*) = Map(x: _*)\n+  def increment(spmap: SPMap): SPMap = spmap.map { case (v, d) => v -> (d + 1) }\n+  def plus(spmap1: SPMap, spmap2: SPMap): SPMap =\n+    (spmap1.keySet ++ spmap2.keySet).map{\n+      k => k -> scala.math.min(spmap1.getOrElse(k, Int.MaxValue), spmap2.getOrElse(k, Int.MaxValue))\n+    }.toMap\n+\n+  /**\n+   * Compute the shortest paths to each landmark for each vertex and\n+   * return an RDD with the map of landmarks to their shortest-path\n+   * lengths.\n+   *\n+   * @tparam VD the shortest paths map for the vertex\n+   * @tparam ED the incremented shortest-paths map of the originating\n+   * vertex (discarded in the computation)\n+   *\n+   * @param graph the graph for which to compute the shortest paths\n+   * @param landmarks the list of landmark vertex ids\n+   *\n+   * @return a graph with vertex attributes containing a map of the\n+   * shortest paths to each landmark\n+   */\n+  def run[VD, ED](graph: Graph[VD, ED], landmarks: Seq[VertexId])\n+    (implicit m1: Manifest[VD], m2: Manifest[ED]): Graph[SPMap, SPMap] = {\n+\n+    val spGraph = graph\n+      .mapVertices{ (vid, attr) =>\n+        if (landmarks.contains(vid)) SPMap(vid -> 0)\n+        else SPMap()",
    "line": 52
  }],
  "prId": 10
}, {
  "comments": [{
    "author": {
      "login": "ankurdave"
    },
    "body": "What does this mapTriplets call do? It doesn't seem that we access edge.attr later on.\n",
    "commit": "88d80da1dab8be71716ed572a5a1e721cf1c015c",
    "createdAt": "2014-04-29T18:18:35Z",
    "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.graphx.lib\n+\n+import org.apache.spark.graphx._\n+\n+object ShortestPaths {\n+  type SPMap = Map[VertexId, Int] // map of landmarks -> minimum distance to landmark\n+  def SPMap(x: (VertexId, Int)*) = Map(x: _*)\n+  def increment(spmap: SPMap): SPMap = spmap.map { case (v, d) => v -> (d + 1) }\n+  def plus(spmap1: SPMap, spmap2: SPMap): SPMap =\n+    (spmap1.keySet ++ spmap2.keySet).map{\n+      k => k -> scala.math.min(spmap1.getOrElse(k, Int.MaxValue), spmap2.getOrElse(k, Int.MaxValue))\n+    }.toMap\n+\n+  /**\n+   * Compute the shortest paths to each landmark for each vertex and\n+   * return an RDD with the map of landmarks to their shortest-path\n+   * lengths.\n+   *\n+   * @tparam VD the shortest paths map for the vertex\n+   * @tparam ED the incremented shortest-paths map of the originating\n+   * vertex (discarded in the computation)\n+   *\n+   * @param graph the graph for which to compute the shortest paths\n+   * @param landmarks the list of landmark vertex ids\n+   *\n+   * @return a graph with vertex attributes containing a map of the\n+   * shortest paths to each landmark\n+   */\n+  def run[VD, ED](graph: Graph[VD, ED], landmarks: Seq[VertexId])\n+    (implicit m1: Manifest[VD], m2: Manifest[ED]): Graph[SPMap, SPMap] = {\n+\n+    val spGraph = graph\n+      .mapVertices{ (vid, attr) =>\n+        if (landmarks.contains(vid)) SPMap(vid -> 0)\n+        else SPMap()\n+      }\n+      .mapTriplets{ edge => edge.srcAttr }",
    "line": 54
  }],
  "prId": 10
}]