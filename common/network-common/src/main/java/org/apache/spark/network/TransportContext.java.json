[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Hmm... I think there is some waste here. Not all channels actually need the chunk fetch handler. Basically only the shuffle server (external or not) does. So for all other cases - RpcEnv server and clients, shuffle clients - you'd have this new thread pool just sitting there.\r\n\r\nIt would be good to avoid that.",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-08-22T18:58:59Z",
    "diffHunk": "@@ -144,14 +161,17 @@ public TransportChannelHandler initializePipeline(\n       RpcHandler channelRpcHandler) {\n     try {\n       TransportChannelHandler channelHandler = createChannelHandler(channel, channelRpcHandler);\n+      ChunkFetchRequestHandler chunkFetchHandler = createChunkFetchHandler(channelHandler, channelRpcHandler);\n       channel.pipeline()\n         .addLast(\"encoder\", ENCODER)\n         .addLast(TransportFrameDecoder.HANDLER_NAME, NettyUtils.createFrameDecoder())\n         .addLast(\"decoder\", DECODER)\n         .addLast(\"idleStateHandler\", new IdleStateHandler(0, 0, conf.connectionTimeoutMs() / 1000))\n         // NOTE: Chunks are currently guaranteed to be returned in the order of request, but this\n         // would require more logic to guarantee if this were not part of the same event loop.\n-        .addLast(\"handler\", channelHandler);\n+        .addLast(\"handler\", channelHandler)\n+        // Use a separate EventLoopGroup to handle ChunkFetchRequest messages.\n+        .addLast(chunkFetchWorkers, \"chunkFetchHandler\", chunkFetchHandler);"
  }, {
    "author": {
      "login": "redsanket"
    },
    "body": "yes i did notice that... makes sense",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-08-24T14:06:41Z",
    "diffHunk": "@@ -144,14 +161,17 @@ public TransportChannelHandler initializePipeline(\n       RpcHandler channelRpcHandler) {\n     try {\n       TransportChannelHandler channelHandler = createChannelHandler(channel, channelRpcHandler);\n+      ChunkFetchRequestHandler chunkFetchHandler = createChunkFetchHandler(channelHandler, channelRpcHandler);\n       channel.pipeline()\n         .addLast(\"encoder\", ENCODER)\n         .addLast(TransportFrameDecoder.HANDLER_NAME, NettyUtils.createFrameDecoder())\n         .addLast(\"decoder\", DECODER)\n         .addLast(\"idleStateHandler\", new IdleStateHandler(0, 0, conf.connectionTimeoutMs() / 1000))\n         // NOTE: Chunks are currently guaranteed to be returned in the order of request, but this\n         // would require more logic to guarantee if this were not part of the same event loop.\n-        .addLast(\"handler\", channelHandler);\n+        .addLast(\"handler\", channelHandler)\n+        // Use a separate EventLoopGroup to handle ChunkFetchRequest messages.\n+        .addLast(chunkFetchWorkers, \"chunkFetchHandler\", chunkFetchHandler);"
  }],
  "prId": 22173
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "I think synchronized(this.getClass()) is not recommended due to it not handling inheritance and such.  Use synchronized(TransportContext.class)",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-09-18T14:44:25Z",
    "diffHunk": "@@ -88,6 +97,16 @@ public TransportContext(\n     this.conf = conf;\n     this.rpcHandler = rpcHandler;\n     this.closeIdleConnections = closeIdleConnections;\n+\n+    synchronized(this.getClass()) {"
  }],
  "prId": 22173
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "fix spacing here, line up conf.getModuleName with the chunkFetchWorkers",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-09-18T14:47:29Z",
    "diffHunk": "@@ -88,6 +97,16 @@ public TransportContext(\n     this.conf = conf;\n     this.rpcHandler = rpcHandler;\n     this.closeIdleConnections = closeIdleConnections;\n+\n+    synchronized(this.getClass()) {\n+      if (chunkFetchWorkers == null && conf.getModuleName() != null &&\n+              conf.getModuleName().equalsIgnoreCase(\"shuffle\")) {"
  }],
  "prId": 22173
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "for consistency perhaps name thread shuffle-chunk-fetch-handler",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-09-18T14:50:59Z",
    "diffHunk": "@@ -88,6 +97,16 @@ public TransportContext(\n     this.conf = conf;\n     this.rpcHandler = rpcHandler;\n     this.closeIdleConnections = closeIdleConnections;\n+\n+    synchronized(this.getClass()) {\n+      if (chunkFetchWorkers == null && conf.getModuleName() != null &&\n+              conf.getModuleName().equalsIgnoreCase(\"shuffle\")) {\n+        chunkFetchWorkers = NettyUtils.createEventLoop(\n+            IOMode.valueOf(conf.ioMode()),\n+            conf.chunkFetchHandlerThreads(),\n+            \"chunk-fetch-handler\");"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "like you mention if we can not create the event loop when on the client side that would be best",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-09-18T19:22:09Z",
    "diffHunk": "@@ -88,6 +97,16 @@ public TransportContext(\n     this.conf = conf;\n     this.rpcHandler = rpcHandler;\n     this.closeIdleConnections = closeIdleConnections;\n+\n+    synchronized(this.getClass()) {\n+      if (chunkFetchWorkers == null && conf.getModuleName() != null &&\n+              conf.getModuleName().equalsIgnoreCase(\"shuffle\")) {\n+        chunkFetchWorkers = NettyUtils.createEventLoop(\n+            IOMode.valueOf(conf.ioMode()),\n+            conf.chunkFetchHandlerThreads(),\n+            \"chunk-fetch-handler\");"
  }],
  "prId": 22173
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "fix spacing, only indented 2 spaces",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-09-18T14:52:40Z",
    "diffHunk": "@@ -144,14 +163,21 @@ public TransportChannelHandler initializePipeline(\n       RpcHandler channelRpcHandler) {\n     try {\n       TransportChannelHandler channelHandler = createChannelHandler(channel, channelRpcHandler);\n-      channel.pipeline()\n+      ChunkFetchRequestHandler chunkFetchHandler =\n+              createChunkFetchHandler(channelHandler, channelRpcHandler);"
  }],
  "prId": 22173
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "fix indentation",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-09-18T15:51:37Z",
    "diffHunk": "@@ -144,14 +163,21 @@ public TransportChannelHandler initializePipeline(\n       RpcHandler channelRpcHandler) {\n     try {\n       TransportChannelHandler channelHandler = createChannelHandler(channel, channelRpcHandler);\n-      channel.pipeline()\n+      ChunkFetchRequestHandler chunkFetchHandler =\n+              createChunkFetchHandler(channelHandler, channelRpcHandler);\n+      ChannelPipeline pipeline = channel.pipeline()\n         .addLast(\"encoder\", ENCODER)\n         .addLast(TransportFrameDecoder.HANDLER_NAME, NettyUtils.createFrameDecoder())\n         .addLast(\"decoder\", DECODER)\n-        .addLast(\"idleStateHandler\", new IdleStateHandler(0, 0, conf.connectionTimeoutMs() / 1000))\n+        .addLast(\"idleStateHandler\",\n+                new IdleStateHandler(0, 0, conf.connectionTimeoutMs() / 1000))"
  }],
  "prId": 22173
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "identation 2 spaces inside return",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-09-19T18:54:56Z",
    "diffHunk": "@@ -173,5 +213,14 @@ private TransportChannelHandler createChannelHandler(Channel channel, RpcHandler\n       conf.connectionTimeoutMs(), closeIdleConnections);\n   }\n \n+  /**\n+   * Creates the dedicated ChannelHandler for ChunkFetchRequest messages.\n+   */\n+  private ChunkFetchRequestHandler createChunkFetchHandler(TransportChannelHandler channelHandler,\n+      RpcHandler rpcHandler) {\n+    return new ChunkFetchRequestHandler(channelHandler.getClient(),\n+        rpcHandler.getStreamManager(), conf.maxChunksBeingTransferred());"
  }],
  "prId": 22173
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "we should make this more clear.  Because with external shuffle off, we want this on client mode as well since its really both a client and server.  Perhaps we could change name to be isClientOnly, we should put some java docs on the function to describe the parameter as well.",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-09-19T19:00:27Z",
    "diffHunk": "@@ -77,17 +82,43 @@\n   private static final MessageEncoder ENCODER = MessageEncoder.INSTANCE;\n   private static final MessageDecoder DECODER = MessageDecoder.INSTANCE;\n \n+  // Separate thread pool for handling ChunkFetchRequest. This helps to enable throttling\n+  // max number of TransportServer worker threads that are blocked on writing response\n+  // of ChunkFetchRequest message back to the client via the underlying channel.\n+  private static EventLoopGroup chunkFetchWorkers;\n+\n   public TransportContext(TransportConf conf, RpcHandler rpcHandler) {\n-    this(conf, rpcHandler, false);\n+    this(conf, rpcHandler, false, false);\n   }\n \n   public TransportContext(\n       TransportConf conf,\n       RpcHandler rpcHandler,\n       boolean closeIdleConnections) {\n+    this(conf, rpcHandler, closeIdleConnections, false);\n+  }\n+\n+  public TransportContext(\n+      TransportConf conf,\n+      RpcHandler rpcHandler,\n+      boolean closeIdleConnections,\n+      boolean isClient) {"
  }, {
    "author": {
      "login": "redsanket"
    },
    "body": "sure... anything to make is more clear",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-09-19T19:13:13Z",
    "diffHunk": "@@ -77,17 +82,43 @@\n   private static final MessageEncoder ENCODER = MessageEncoder.INSTANCE;\n   private static final MessageDecoder DECODER = MessageDecoder.INSTANCE;\n \n+  // Separate thread pool for handling ChunkFetchRequest. This helps to enable throttling\n+  // max number of TransportServer worker threads that are blocked on writing response\n+  // of ChunkFetchRequest message back to the client via the underlying channel.\n+  private static EventLoopGroup chunkFetchWorkers;\n+\n   public TransportContext(TransportConf conf, RpcHandler rpcHandler) {\n-    this(conf, rpcHandler, false);\n+    this(conf, rpcHandler, false, false);\n   }\n \n   public TransportContext(\n       TransportConf conf,\n       RpcHandler rpcHandler,\n       boolean closeIdleConnections) {\n+    this(conf, rpcHandler, closeIdleConnections, false);\n+  }\n+\n+  public TransportContext(\n+      TransportConf conf,\n+      RpcHandler rpcHandler,\n+      boolean closeIdleConnections,\n+      boolean isClient) {"
  }],
  "prId": 22173
}, {
  "comments": [{
    "author": {
      "login": "redsanket"
    },
    "body": "I think for comments we follow the same spacing convention as observed here so sticking with it...",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-09-19T19:46:07Z",
    "diffHunk": "@@ -98,21 +98,32 @@ public TransportContext(\n     this(conf, rpcHandler, closeIdleConnections, false);\n   }\n \n+    /**\n+     *\n+     * @param conf TransportConf\n+     * @param rpcHandler RpcHandler responsible for handling requests and responses.\n+     * @param closeIdleConnections Close idle connections if is set to true.\n+     * @param isClientOnly This config is more important when external shuffle is enabled."
  }],
  "prId": 22173
}, {
  "comments": [{
    "author": {
      "login": "redsanket"
    },
    "body": "I hope we follow a similar indentation for all other java docs so sticking with it",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-09-19T19:54:10Z",
    "diffHunk": "@@ -77,17 +82,54 @@\n   private static final MessageEncoder ENCODER = MessageEncoder.INSTANCE;\n   private static final MessageDecoder DECODER = MessageDecoder.INSTANCE;\n \n+  // Separate thread pool for handling ChunkFetchRequest. This helps to enable throttling\n+  // max number of TransportServer worker threads that are blocked on writing response\n+  // of ChunkFetchRequest message back to the client via the underlying channel.\n+  private static EventLoopGroup chunkFetchWorkers;\n+\n   public TransportContext(TransportConf conf, RpcHandler rpcHandler) {\n-    this(conf, rpcHandler, false);\n+    this(conf, rpcHandler, false, false);\n   }\n \n   public TransportContext(\n       TransportConf conf,\n       RpcHandler rpcHandler,\n       boolean closeIdleConnections) {\n+    this(conf, rpcHandler, closeIdleConnections, false);\n+  }\n+\n+    /**\n+     *\n+     * @param conf TransportConf\n+     * @param rpcHandler RpcHandler responsible for handling requests and responses.\n+     * @param closeIdleConnections Close idle connections if it is set to true.\n+     * @param isClientOnly This config is more important when external shuffle is enabled.\n+     *                     It stops creating extra event loop and subsequent thread pool\n+     *                     for shuffle clients to handle chunked fetch requests.\n+     *                     In the case when external shuffle is disabled, the executors are both\n+     *                     client and server so both share the same event loop which is trivial."
  }],
  "prId": 22173
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "Is there any special reason that this must be a global one? I have not yet looked the details. But looks like this may cause ChunkFetchIntegrationSuite flaky as there is no isolation between tests. ",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-10-08T22:23:15Z",
    "diffHunk": "@@ -77,17 +82,54 @@\n   private static final MessageEncoder ENCODER = MessageEncoder.INSTANCE;\n   private static final MessageDecoder DECODER = MessageDecoder.INSTANCE;\n \n+  // Separate thread pool for handling ChunkFetchRequest. This helps to enable throttling\n+  // max number of TransportServer worker threads that are blocked on writing response\n+  // of ChunkFetchRequest message back to the client via the underlying channel.\n+  private static EventLoopGroup chunkFetchWorkers;",
    "line": 38
  }, {
    "author": {
      "login": "redsanket"
    },
    "body": "I haven't been able to reproduce this but the number of threads used for this tests are 2* number of cores or spark.shuffle.io.serverThreads.",
    "commit": "0348ec8d5570aab9d744043a3d6a88950f4aeb5c",
    "createdAt": "2018-10-22T20:04:22Z",
    "diffHunk": "@@ -77,17 +82,54 @@\n   private static final MessageEncoder ENCODER = MessageEncoder.INSTANCE;\n   private static final MessageDecoder DECODER = MessageDecoder.INSTANCE;\n \n+  // Separate thread pool for handling ChunkFetchRequest. This helps to enable throttling\n+  // max number of TransportServer worker threads that are blocked on writing response\n+  // of ChunkFetchRequest message back to the client via the underlying channel.\n+  private static EventLoopGroup chunkFetchWorkers;",
    "line": 38
  }],
  "prId": 22173
}]