[{
  "comments": [{
    "author": {
      "login": "nchammas"
    },
    "body": "Why did this get changed from `RELEASE` to `jars`?\n",
    "commit": "e1398552469288de3829eb889fec0de2ba568f15",
    "createdAt": "2016-10-27T14:39:45Z",
    "diffHunk": "@@ -36,7 +36,7 @@ else\n fi\n \n # Find Spark jars.\n-if [ -f \"${SPARK_HOME}/RELEASE\" ]; then\n+if [ -d \"${SPARK_HOME}/jars\" ]; then",
    "line": 23
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "Because both pip installed PySpark and RELEASE Spark have jars in the jars directory, it seems more reasonable to just check if the jars directory exists directly rather than checking for a file which indicates that the JARs directory is present.\n",
    "commit": "e1398552469288de3829eb889fec0de2ba568f15",
    "createdAt": "2016-10-27T15:26:07Z",
    "diffHunk": "@@ -36,7 +36,7 @@ else\n fi\n \n # Find Spark jars.\n-if [ -f \"${SPARK_HOME}/RELEASE\" ]; then\n+if [ -d \"${SPARK_HOME}/jars\" ]; then",
    "line": 23
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Makes sense. This seems reasonable to me.\n",
    "commit": "e1398552469288de3829eb889fec0de2ba568f15",
    "createdAt": "2016-11-12T00:03:51Z",
    "diffHunk": "@@ -36,7 +36,7 @@ else\n fi\n \n # Find Spark jars.\n-if [ -f \"${SPARK_HOME}/RELEASE\" ]; then\n+if [ -d \"${SPARK_HOME}/jars\" ]; then",
    "line": 23
  }],
  "prId": 15659
}]