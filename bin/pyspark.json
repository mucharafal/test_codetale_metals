[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Why is this change necessary?\n",
    "commit": "64561e4e503eafb958f6769383ba3b37edbe5fa2",
    "createdAt": "2014-09-30T00:01:13Z",
    "diffHunk": "@@ -87,11 +87,7 @@ export PYSPARK_SUBMIT_ARGS\n if [[ -n \"$SPARK_TESTING\" ]]; then\n   unset YARN_CONF_DIR\n   unset HADOOP_CONF_DIR\n-  if [[ -n \"$PYSPARK_DOC_TEST\" ]]; then\n-    exec \"$PYSPARK_PYTHON\" -m doctest $1\n-  else\n-    exec \"$PYSPARK_PYTHON\" $1\n-  fi\n+  exec \"$PYSPARK_PYTHON\" $1"
  }, {
    "author": {
      "login": "davies"
    },
    "body": "it's not necessary, it's part of refactor run-tests, do we need to create a separate PR for this?\n",
    "commit": "64561e4e503eafb958f6769383ba3b37edbe5fa2",
    "createdAt": "2014-09-30T05:50:41Z",
    "diffHunk": "@@ -87,11 +87,7 @@ export PYSPARK_SUBMIT_ARGS\n if [[ -n \"$SPARK_TESTING\" ]]; then\n   unset YARN_CONF_DIR\n   unset HADOOP_CONF_DIR\n-  if [[ -n \"$PYSPARK_DOC_TEST\" ]]; then\n-    exec \"$PYSPARK_PYTHON\" -m doctest $1\n-  else\n-    exec \"$PYSPARK_PYTHON\" $1\n-  fi\n+  exec \"$PYSPARK_PYTHON\" $1"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "If that is easy to do, then that is a better idea. Since this PR is already so big, lets change as little of the existing infrastructure as possible. Otherwise if existing pyspark breaks in some weird way, it will be hard to revert this commit, without reverting all of pysparkstreaming.\n",
    "commit": "64561e4e503eafb958f6769383ba3b37edbe5fa2",
    "createdAt": "2014-09-30T05:59:26Z",
    "diffHunk": "@@ -87,11 +87,7 @@ export PYSPARK_SUBMIT_ARGS\n if [[ -n \"$SPARK_TESTING\" ]]; then\n   unset YARN_CONF_DIR\n   unset HADOOP_CONF_DIR\n-  if [[ -n \"$PYSPARK_DOC_TEST\" ]]; then\n-    exec \"$PYSPARK_PYTHON\" -m doctest $1\n-  else\n-    exec \"$PYSPARK_PYTHON\" $1\n-  fi\n+  exec \"$PYSPARK_PYTHON\" $1"
  }],
  "prId": 2538
}]