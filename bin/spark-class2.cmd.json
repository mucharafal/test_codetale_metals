[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "This is not working yet. See commit message https://github.com/andrewor14/spark/commit/83ebe601032867327988940073de4ee08a42c3fe for more detail.\n",
    "commit": "881a8f0d03046bf074776a8e6c820a99fad02d11",
    "createdAt": "2014-08-26T06:34:56Z",
    "diffHunk": "@@ -115,5 +125,27 @@ rem Figure out where java is.\n set RUNNER=java\n if not \"x%JAVA_HOME%\"==\"x\" set RUNNER=%JAVA_HOME%\\bin\\java\n \n-\"%RUNNER%\" -cp \"%CLASSPATH%\" %JAVA_OPTS% %*\n+rem In Spark submit client mode, the driver is launched in the same JVM as Spark submit itself.\n+rem Here we must parse the properties file for relevant \"spark.driver.*\" configs before launching\n+rem the driver JVM itself. Instead of handling this complexity in Bash, we launch a separate JVM\n+rem to prepare the launch environment of this driver JVM.\n+\n+rem In this case, leave out the main class (org.apache.spark.deploy.SparkSubmit) and use our own.\n+rem Leaving out the first argument is surprisingly difficult to do in Windows. Note that this must\n+rem be done here because the Windows \"shift\" command does not work in a conditional block.\n+set BOOTSTRAP_ARGS=\n+shift\n+:start_parse\n+if \"%~1\" == \"\" goto end_parse\n+set BOOTSTRAP_ARGS=%BOOTSTRAP_ARGS% %~1\n+shift\n+goto start_parse\n+:end_parse\n+\n+if not [%SPARK_SUBMIT_BOOTSTRAP_DRIVER%] == [] (\n+  set SPARK_CLASS=1\n+  \"%RUNNER%\" org.apache.spark.deploy.SparkSubmitDriverBootstrapper %BOOTSTRAP_ARGS%",
    "line": 76
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "This should be fixed in this commit https://github.com/andrewor14/spark/commit/f97daa20c184fb4b68d7ff5de1172a8e94e38b2f\n",
    "commit": "881a8f0d03046bf074776a8e6c820a99fad02d11",
    "createdAt": "2014-08-27T00:33:26Z",
    "diffHunk": "@@ -115,5 +125,27 @@ rem Figure out where java is.\n set RUNNER=java\n if not \"x%JAVA_HOME%\"==\"x\" set RUNNER=%JAVA_HOME%\\bin\\java\n \n-\"%RUNNER%\" -cp \"%CLASSPATH%\" %JAVA_OPTS% %*\n+rem In Spark submit client mode, the driver is launched in the same JVM as Spark submit itself.\n+rem Here we must parse the properties file for relevant \"spark.driver.*\" configs before launching\n+rem the driver JVM itself. Instead of handling this complexity in Bash, we launch a separate JVM\n+rem to prepare the launch environment of this driver JVM.\n+\n+rem In this case, leave out the main class (org.apache.spark.deploy.SparkSubmit) and use our own.\n+rem Leaving out the first argument is surprisingly difficult to do in Windows. Note that this must\n+rem be done here because the Windows \"shift\" command does not work in a conditional block.\n+set BOOTSTRAP_ARGS=\n+shift\n+:start_parse\n+if \"%~1\" == \"\" goto end_parse\n+set BOOTSTRAP_ARGS=%BOOTSTRAP_ARGS% %~1\n+shift\n+goto start_parse\n+:end_parse\n+\n+if not [%SPARK_SUBMIT_BOOTSTRAP_DRIVER%] == [] (\n+  set SPARK_CLASS=1\n+  \"%RUNNER%\" org.apache.spark.deploy.SparkSubmitDriverBootstrapper %BOOTSTRAP_ARGS%",
    "line": 76
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "JK, this was actually fixed in https://github.com/andrewor14/spark/commit/35caecc899796da1ad4851185644ff591d479270\n",
    "commit": "881a8f0d03046bf074776a8e6c820a99fad02d11",
    "createdAt": "2014-08-27T01:29:25Z",
    "diffHunk": "@@ -115,5 +125,27 @@ rem Figure out where java is.\n set RUNNER=java\n if not \"x%JAVA_HOME%\"==\"x\" set RUNNER=%JAVA_HOME%\\bin\\java\n \n-\"%RUNNER%\" -cp \"%CLASSPATH%\" %JAVA_OPTS% %*\n+rem In Spark submit client mode, the driver is launched in the same JVM as Spark submit itself.\n+rem Here we must parse the properties file for relevant \"spark.driver.*\" configs before launching\n+rem the driver JVM itself. Instead of handling this complexity in Bash, we launch a separate JVM\n+rem to prepare the launch environment of this driver JVM.\n+\n+rem In this case, leave out the main class (org.apache.spark.deploy.SparkSubmit) and use our own.\n+rem Leaving out the first argument is surprisingly difficult to do in Windows. Note that this must\n+rem be done here because the Windows \"shift\" command does not work in a conditional block.\n+set BOOTSTRAP_ARGS=\n+shift\n+:start_parse\n+if \"%~1\" == \"\" goto end_parse\n+set BOOTSTRAP_ARGS=%BOOTSTRAP_ARGS% %~1\n+shift\n+goto start_parse\n+:end_parse\n+\n+if not [%SPARK_SUBMIT_BOOTSTRAP_DRIVER%] == [] (\n+  set SPARK_CLASS=1\n+  \"%RUNNER%\" org.apache.spark.deploy.SparkSubmitDriverBootstrapper %BOOTSTRAP_ARGS%",
    "line": 76
  }],
  "prId": 2129
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "The `!VAR_NAME!` syntax is explained here: https://github.com/andrewor14/spark/commit/72004c2b6bd502244cb1e9e055d26bd1f064ce5a. If we used `%VAR_NAME%`, this wouldn't pick up the latest value set in L76 because we're inside a conditional.\n",
    "commit": "881a8f0d03046bf074776a8e6c820a99fad02d11",
    "createdAt": "2014-08-27T03:55:30Z",
    "diffHunk": "@@ -67,10 +69,18 @@ rem Executors use SPARK_JAVA_OPTS + SPARK_EXECUTOR_MEMORY.\n   set OUR_JAVA_OPTS=%SPARK_JAVA_OPTS% %SPARK_EXECUTOR_OPTS%\n   if not \"x%SPARK_EXECUTOR_MEMORY%\"==\"x\" set OUR_JAVA_MEM=%SPARK_EXECUTOR_MEMORY%\n \n-rem All drivers use SPARK_JAVA_OPTS + SPARK_DRIVER_MEMORY. The repl also uses SPARK_REPL_OPTS.\n-) else if \"%1\"==\"org.apache.spark.repl.Main\" (\n-  set OUR_JAVA_OPTS=%SPARK_JAVA_OPTS% %SPARK_REPL_OPTS%\n+rem Spark submit uses SPARK_JAVA_OPTS + SPARK_SUBMIT_OPTS +\n+rem SPARK_DRIVER_MEMORY + SPARK_SUBMIT_DRIVER_MEMORY.\n+rem The repl also uses SPARK_REPL_OPTS.\n+) else if \"%1\"==\"org.apache.spark.deploy.SparkSubmit\" (\n+  set OUR_JAVA_OPTS=%SPARK_JAVA_OPTS% %SPARK_SUBMIT_OPTS% %SPARK_REPL_OPTS%\n+  if not \"x%SPARK_SUBMIT_LIBRARY_PATH%\"==\"x\" (\n+    set OUR_JAVA_OPTS=!OUR_JAVA_OPTS! -Djava.library.path=%SPARK_SUBMIT_LIBRARY_PATH%",
    "line": 31
  }],
  "prId": 2129
}]