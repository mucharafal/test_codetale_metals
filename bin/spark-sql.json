[{
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Please remove the extra newline.\n",
    "commit": "8ef8751da568481b4abf3c87601bc2a16115d7c3",
    "createdAt": "2014-08-11T15:49:39Z",
    "diffHunk": "@@ -53,42 +57,26 @@ function ensure_arg_number {\n   fi\n }\n \n-if [[ \"$@\" = --help ]] || [[ \"$@\" = -h ]]; then\n+if [[ \"$@\" = *--help ]] || [[ \"$@\" = *-h ]]; then\n   usage\n   exit 0\n fi\n \n-CLI_ARGS=()\n-SUBMISSION_ARGS=()\n-\n-while (($#)); do\n-  case $1 in\n-    -d | --define | --database | -f | -h | --hiveconf | --hivevar | -i | -p)\n-      ensure_arg_number $# 2\n-      CLI_ARGS+=($1); shift\n-      CLI_ARGS+=($1); shift\n-      ;;\n-\n-    -e)\n-      ensure_arg_number $# 2\n-      CLI_ARGS+=($1); shift\n-      CLI_ARGS+=(\\\"$1\\\"); shift\n-      ;;\n \n-    -s | --silent)\n-      CLI_ARGS+=($1); shift\n-      ;;\n+function verifyApplicationOpts() {\n \n-    -v | --verbose)\n-      # Both SparkSubmit and SparkSQLCLIDriver recognizes -v | --verbose\n-      CLI_ARGS+=($1)\n-      SUBMISSION_ARGS+=($1); shift\n-      ;;\n-\n-    *)\n-      SUBMISSION_ARGS+=($1); shift\n-      ;;\n-  esac\n-done\n+  while (($#)); do\n+  "
  }],
  "prId": 1886
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Indentation not right.\n",
    "commit": "8ef8751da568481b4abf3c87601bc2a16115d7c3",
    "createdAt": "2014-08-11T15:49:54Z",
    "diffHunk": "@@ -53,42 +57,26 @@ function ensure_arg_number {\n   fi\n }\n \n-if [[ \"$@\" = --help ]] || [[ \"$@\" = -h ]]; then\n+if [[ \"$@\" = *--help ]] || [[ \"$@\" = *-h ]]; then\n   usage\n   exit 0\n fi\n \n-CLI_ARGS=()\n-SUBMISSION_ARGS=()\n-\n-while (($#)); do\n-  case $1 in\n-    -d | --define | --database | -f | -h | --hiveconf | --hivevar | -i | -p)\n-      ensure_arg_number $# 2\n-      CLI_ARGS+=($1); shift\n-      CLI_ARGS+=($1); shift\n-      ;;\n-\n-    -e)\n-      ensure_arg_number $# 2\n-      CLI_ARGS+=($1); shift\n-      CLI_ARGS+=(\\\"$1\\\"); shift\n-      ;;\n \n-    -s | --silent)\n-      CLI_ARGS+=($1); shift\n-      ;;\n+function verifyApplicationOpts() {\n \n-    -v | --verbose)\n-      # Both SparkSubmit and SparkSQLCLIDriver recognizes -v | --verbose\n-      CLI_ARGS+=($1)\n-      SUBMISSION_ARGS+=($1); shift\n-      ;;\n-\n-    *)\n-      SUBMISSION_ARGS+=($1); shift\n-      ;;\n-  esac\n-done\n+  while (($#)); do\n+  \n+    case \"$1\" in\n+      -d | --define | --database | -f | -h | --hiveconf | --hivevar | -i | -p | -e)\n+        ensure_arg_number $# 2\n+        shift\n+        ;;\n+      *) shift\n+       ;;"
  }, {
    "author": {
      "login": "sarutak"
    },
    "body": "Ah, sorry my foolish mistake...\n",
    "commit": "8ef8751da568481b4abf3c87601bc2a16115d7c3",
    "createdAt": "2014-08-11T17:04:46Z",
    "diffHunk": "@@ -53,42 +57,26 @@ function ensure_arg_number {\n   fi\n }\n \n-if [[ \"$@\" = --help ]] || [[ \"$@\" = -h ]]; then\n+if [[ \"$@\" = *--help ]] || [[ \"$@\" = *-h ]]; then\n   usage\n   exit 0\n fi\n \n-CLI_ARGS=()\n-SUBMISSION_ARGS=()\n-\n-while (($#)); do\n-  case $1 in\n-    -d | --define | --database | -f | -h | --hiveconf | --hivevar | -i | -p)\n-      ensure_arg_number $# 2\n-      CLI_ARGS+=($1); shift\n-      CLI_ARGS+=($1); shift\n-      ;;\n-\n-    -e)\n-      ensure_arg_number $# 2\n-      CLI_ARGS+=($1); shift\n-      CLI_ARGS+=(\\\"$1\\\"); shift\n-      ;;\n \n-    -s | --silent)\n-      CLI_ARGS+=($1); shift\n-      ;;\n+function verifyApplicationOpts() {\n \n-    -v | --verbose)\n-      # Both SparkSubmit and SparkSQLCLIDriver recognizes -v | --verbose\n-      CLI_ARGS+=($1)\n-      SUBMISSION_ARGS+=($1); shift\n-      ;;\n-\n-    *)\n-      SUBMISSION_ARGS+=($1); shift\n-      ;;\n-  esac\n-done\n+  while (($#)); do\n+  \n+    case \"$1\" in\n+      -d | --define | --database | -f | -h | --hiveconf | --hivevar | -i | -p | -e)\n+        ensure_arg_number $# 2\n+        shift\n+        ;;\n+      *) shift\n+       ;;"
  }],
  "prId": 1886
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Maybe we can remove this and just let `SparkSQLCLIDriver` to verify these application specific options?\n",
    "commit": "8ef8751da568481b4abf3c87601bc2a16115d7c3",
    "createdAt": "2014-08-11T15:52:16Z",
    "diffHunk": "@@ -53,42 +57,26 @@ function ensure_arg_number {\n   fi\n }\n \n-if [[ \"$@\" = --help ]] || [[ \"$@\" = -h ]]; then\n+if [[ \"$@\" = *--help ]] || [[ \"$@\" = *-h ]]; then\n   usage\n   exit 0\n fi\n \n-CLI_ARGS=()\n-SUBMISSION_ARGS=()\n-\n-while (($#)); do\n-  case $1 in\n-    -d | --define | --database | -f | -h | --hiveconf | --hivevar | -i | -p)\n-      ensure_arg_number $# 2\n-      CLI_ARGS+=($1); shift\n-      CLI_ARGS+=($1); shift\n-      ;;\n-\n-    -e)\n-      ensure_arg_number $# 2\n-      CLI_ARGS+=($1); shift\n-      CLI_ARGS+=(\\\"$1\\\"); shift\n-      ;;\n \n-    -s | --silent)\n-      CLI_ARGS+=($1); shift\n-      ;;\n+function verifyApplicationOpts() {"
  }],
  "prId": 1886
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Actually the `eval` here has to be removed since we've already quoted things. You may try the following to verify:\n\n``` bash\n./bin/spark-sql --name \"a b\"\n```\n",
    "commit": "8ef8751da568481b4abf3c87601bc2a16115d7c3",
    "createdAt": "2014-08-11T18:29:41Z",
    "diffHunk": "@@ -43,52 +47,9 @@ function usage {\n   $FWDIR/bin/spark-class $CLASS --help 2>&1 | grep -v \"$pattern\" 1>&2\n }\n \n-function ensure_arg_number {\n-  arg_number=$1\n-  at_least=$2\n-\n-  if [[ $arg_number -lt $at_least ]]; then\n-    usage\n-    exit 1\n-  fi\n-}\n-\n-if [[ \"$@\" = --help ]] || [[ \"$@\" = -h ]]; then\n+if [[ \"$@\" = *--help ]] || [[ \"$@\" = *-h ]]; then\n   usage\n   exit 0\n fi\n \n-CLI_ARGS=()\n-SUBMISSION_ARGS=()\n-\n-while (($#)); do\n-  case $1 in\n-    -d | --define | --database | -f | -h | --hiveconf | --hivevar | -i | -p)\n-      ensure_arg_number $# 2\n-      CLI_ARGS+=($1); shift\n-      CLI_ARGS+=($1); shift\n-      ;;\n-\n-    -e)\n-      ensure_arg_number $# 2\n-      CLI_ARGS+=($1); shift\n-      CLI_ARGS+=(\\\"$1\\\"); shift\n-      ;;\n-\n-    -s | --silent)\n-      CLI_ARGS+=($1); shift\n-      ;;\n-\n-    -v | --verbose)\n-      # Both SparkSubmit and SparkSQLCLIDriver recognizes -v | --verbose\n-      CLI_ARGS+=($1)\n-      SUBMISSION_ARGS+=($1); shift\n-      ;;\n-\n-    *)\n-      SUBMISSION_ARGS+=($1); shift\n-      ;;\n-  esac\n-done\n-\n-eval exec \"$FWDIR\"/bin/spark-submit --class $CLASS ${SUBMISSION_ARGS[*]} spark-internal ${CLI_ARGS[*]}\n+eval exec \"$FWDIR\"/bin/spark-submit --class $CLASS \"${SUBMISSION_OPTS[@]}\" spark-internal \"${APPLICATION_OPTS[@]}\""
  }],
  "prId": 1886
}]