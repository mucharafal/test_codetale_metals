[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "I think that this is redundant, actually, since the value always appears after the key, we know the key's length, and we always store the key and value in the same memory block.\n\nIf I remove this, we'll have an extra 32 bits of space in the long array that we can use for something else.  Moving to a 64-bit hashcode probably won't make a huge difference.  Is there another good use for this space?\n",
    "commit": "eeee512bd94d463f741170e904ae186e238f997c",
    "createdAt": "2015-04-27T23:22:35Z",
    "diffHunk": "@@ -0,0 +1,618 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.unsafe.map;\n+\n+import java.lang.Override;\n+import java.lang.UnsupportedOperationException;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.spark.unsafe.*;\n+import org.apache.spark.unsafe.array.ByteArrayMethods;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.bitset.BitSet;\n+import org.apache.spark.unsafe.hash.Murmur3_x86_32;\n+import org.apache.spark.unsafe.memory.*;\n+\n+/**\n+ * An append-only hash map where keys and values are contiguous regions of bytes.\n+ * <p>\n+ * This is backed by a power-of-2-sized hash table, using quadratic probing with triangular numbers,\n+ * which is guaranteed to exhaust the space.\n+ * <p>\n+ * Note that even though we use long for indexing, the map can support up to 2^31 keys because\n+ * we use 32 bit MurmurHash. In either case, if the key cardinality is so high, you should probably\n+ * be using sorting instead of hashing for better cache locality.\n+ * <p>\n+ * This class is not thread safe.\n+ */\n+public final class BytesToBytesMap {\n+\n+  private static final Murmur3_x86_32 HASHER = new Murmur3_x86_32(0);\n+\n+  private static final HashMapGrowthStrategy growthStrategy = HashMapGrowthStrategy.DOUBLING;\n+\n+  /** Bit mask for the lower 51 bits of a long. */\n+  private static final long MASK_LONG_LOWER_51_BITS = 0x7FFFFFFFFFFFFL;\n+\n+  /** Bit mask for the upper 13 bits of a long */\n+  private static final long MASK_LONG_UPPER_13_BITS = ~MASK_LONG_LOWER_51_BITS;\n+\n+  /** Bit mask for the lower 32 bits of a long */\n+  private static final long MASK_LONG_LOWER_32_BITS = 0xFFFFFFFFL;\n+\n+  private final MemoryAllocator allocator;\n+\n+  /**\n+   * Tracks whether we're using in-heap or off-heap addresses.\n+   */\n+  private final boolean inHeap;\n+\n+  /**\n+   * A linked list for tracking all allocated data pages so that we can free all of our memory.\n+   */\n+  private final List<MemoryBlock> dataPages = new LinkedList<MemoryBlock>();\n+\n+  /**\n+   * The data page that will be used to store keys and values for new hashtable entries. When this\n+   * page becomes full, a new page will be allocated and this pointer will change to point to that\n+   * new page.\n+   */\n+  private MemoryBlock currentDataPage = null;\n+\n+  /**\n+   * Offset into `currentDataPage` that points to the location where new data can be inserted into\n+   * the page.\n+   */\n+  private long pageCursor = 0;\n+\n+  /**\n+   * Similar to an operating system's page table, this array maps page numbers into base object\n+   * pointers, allowing us to translate between the hashtable's internal 64-bit address\n+   * representation and the baseObject+offset representation which we use to support both in- and\n+   * off-heap addresses. When using an off-heap allocator, every entry in this map will be `null`.\n+   * When using an in-heap allocator, the entries in this map will point to pages' base objects.\n+   * Entries are added to this map as new data pages are allocated.\n+   */\n+  private final Object[] pageTable = new Object[PAGE_TABLE_SIZE];\n+\n+  /**\n+   * When using an in-heap allocator, this holds the current page number.\n+   */\n+  private int currentPageNumber = -1;\n+\n+  /**\n+   * The number of entries in the page table.\n+   */\n+  private static final int PAGE_TABLE_SIZE = (int) 1L << 13;\n+\n+  /**\n+   * The size of the data pages that hold key and value data. Map entries cannot span multiple\n+   * pages, so this limits the maximum entry size.\n+   */\n+  private static final long PAGE_SIZE_BYTES = 1L << 26; // 64 megabytes\n+\n+  // This choice of page table size and page size means that we can address up to 500 gigabytes\n+  // of memory.\n+\n+  /**\n+   * A single array to store the key and value.\n+   *\n+   * Position {@code 2 * i} in the array is used to track a pointer to the key at index {@code i},\n+   * while position {@code 2 * i + 1} in the array holds the upper bits of the key's hashcode plus\n+   * the relative offset from the key pointer to the value at index {@code i}.\n+   */\n+  private LongArray longArray;\n+\n+  /**\n+   * A {@link BitSet} used to track location of the map where the key is set.\n+   * Size of the bitset should be half of the size of the long array.\n+   */\n+  private BitSet bitset;\n+\n+  private final double loadFactor;\n+\n+  /**\n+   * Number of keys defined in the map.\n+   */\n+  private int size;\n+\n+  /**\n+   * The map will be expanded once the number of keys exceeds this threshold.\n+   */\n+  private int growthThreshold;\n+\n+  /**\n+   * Mask for truncating hashcodes so that they do not exceed the long array's size.\n+   */\n+  private int mask;\n+\n+  /**\n+   * Return value of {@link BytesToBytesMap#lookup(Object, long, int)}.\n+   */\n+  private final Location loc;\n+\n+  private final boolean enablePerfMetrics;\n+\n+  private long timeSpentResizingMs = 0;\n+\n+  private long numProbes = 0;\n+\n+  private long numKeyLookups = 0;\n+\n+  private long numHashCollisions = 0;\n+\n+  public BytesToBytesMap(\n+      MemoryAllocator allocator,\n+      int initialCapacity,\n+      double loadFactor,\n+      boolean enablePerfMetrics) {\n+    this.inHeap = allocator instanceof HeapMemoryAllocator;\n+    this.allocator = allocator;\n+    this.loadFactor = loadFactor;\n+    this.loc = new Location();\n+    this.enablePerfMetrics = enablePerfMetrics;\n+    allocate(initialCapacity);\n+  }\n+\n+  public BytesToBytesMap(MemoryAllocator allocator, int initialCapacity) {\n+    this(allocator, initialCapacity, 0.70, false);\n+  }\n+\n+  public BytesToBytesMap(\n+      MemoryAllocator allocator,\n+      int initialCapacity,\n+      boolean enablePerfMetrics) {\n+    this(allocator, initialCapacity, 0.70, enablePerfMetrics);\n+  }\n+\n+  @Override\n+  protected void finalize() throws Throwable {\n+    try {\n+      // In case the programmer forgot to call `free()`, try to perform that cleanup now:\n+      free();\n+    } finally {\n+      super.finalize();\n+    }\n+  }\n+\n+  /**\n+   * Returns the number of keys defined in the map.\n+   */\n+  public int size() { return size; }\n+\n+  /**\n+   * Returns an iterator for iterating over the entries of this map.\n+   *\n+   * For efficiency, all calls to `next()` will return the same {@link Location} object.\n+   *\n+   * If any other lookups or operations are performed on this map while iterating over it, including\n+   * `lookup()`, the behavior of the returned iterator is undefined.\n+   */\n+  public Iterator<Location> iterator() {\n+    return new Iterator<Location>() {\n+\n+      private int nextPos = bitset.nextSetBit(0);\n+\n+      @Override\n+      public boolean hasNext() {\n+        return nextPos != -1;\n+      }\n+\n+      @Override\n+      public Location next() {\n+        final int pos = nextPos;\n+        nextPos = bitset.nextSetBit(nextPos + 1);\n+        return loc.with(pos, 0, true);\n+      }\n+\n+      @Override\n+      public void remove() {\n+        throw new UnsupportedOperationException();\n+      }\n+    };\n+  }\n+\n+  /**\n+   * Looks up a key, and return a {@link Location} handle that can be used to test existence\n+   * and read/write values.\n+   *\n+   * This function always return the same {@link Location} instance to avoid object allocation.\n+   */\n+  public Location lookup(\n+      Object keyBaseObject,\n+      long keyBaseOffset,\n+      int keyRowLengthBytes) {\n+    if (enablePerfMetrics) {\n+      numKeyLookups++;\n+    }\n+    final int hashcode = HASHER.hashUnsafeWords(keyBaseObject, keyBaseOffset, keyRowLengthBytes);\n+    int pos = hashcode & mask;\n+    int step = 1;\n+    while (true) {\n+      if (enablePerfMetrics) {\n+        numProbes++;\n+      }\n+      if (!bitset.isSet(pos)) {\n+        // This is a new key.\n+        return loc.with(pos, hashcode, false);\n+      } else {\n+        long stored = longArray.get(pos * 2 + 1);\n+        if (((int) (stored & MASK_LONG_LOWER_32_BITS)) == hashcode) {\n+          // Full hash code matches.  Let's compare the keys for equality.\n+          loc.with(pos, hashcode, true);\n+          if (loc.getKeyLength() == keyRowLengthBytes) {\n+            final MemoryLocation keyAddress = loc.getKeyAddress();\n+            final Object storedKeyBaseObject = keyAddress.getBaseObject();\n+            final long storedKeyBaseOffset = keyAddress.getBaseOffset();\n+            final boolean areEqual = ByteArrayMethods.wordAlignedArrayEquals(\n+              keyBaseObject,\n+              keyBaseOffset,\n+              storedKeyBaseObject,\n+              storedKeyBaseOffset,\n+              keyRowLengthBytes\n+            );\n+            if (areEqual) {\n+              return loc;\n+            } else {\n+              if (enablePerfMetrics) {\n+                numHashCollisions++;\n+              }\n+            }\n+          }\n+        }\n+      }\n+      pos = (pos + step) & mask;\n+      step++;\n+    }\n+  }\n+\n+  /**\n+   * Handle returned by {@link BytesToBytesMap#lookup(Object, long, int)} function.\n+   */\n+  public final class Location {\n+    /** An index into the hash map's Long array */\n+    private int pos;\n+    /** True if this location points to a position where a key is defined, false otherwise */\n+    private boolean isDefined;\n+    /**\n+     * The hashcode of the most recent key passed to\n+     * {@link BytesToBytesMap#lookup(Object, long, int)}. Caching this hashcode here allows us to\n+     * avoid re-hashing the key when storing a value for that key.\n+     */\n+    private int keyHashcode;\n+    private final MemoryLocation keyMemoryLocation = new MemoryLocation();\n+    private final MemoryLocation valueMemoryLocation = new MemoryLocation();\n+    private int keyLength;\n+    private int valueLength;\n+\n+    private void updateAddressesAndSizes(long fullKeyAddress, long offsetFromKeyToValue) {\n+      if (inHeap) {\n+        final Object page = getPage(fullKeyAddress);\n+        final long keyOffsetInPage = getOffsetInPage(fullKeyAddress);\n+        keyMemoryLocation.setObjAndOffset(page, keyOffsetInPage + 8);\n+        valueMemoryLocation.setObjAndOffset(page, keyOffsetInPage + 8 + offsetFromKeyToValue);\n+        keyLength = (int) PlatformDependent.UNSAFE.getLong(page, keyOffsetInPage);\n+        valueLength =\n+          (int) PlatformDependent.UNSAFE.getLong(page, keyOffsetInPage + offsetFromKeyToValue);\n+      } else {\n+        keyMemoryLocation.setObjAndOffset(null, fullKeyAddress + 8);\n+        valueMemoryLocation.setObjAndOffset(null, fullKeyAddress + 8 + offsetFromKeyToValue);\n+        keyLength = (int) PlatformDependent.UNSAFE.getLong(fullKeyAddress);\n+        valueLength = (int) PlatformDependent.UNSAFE.getLong(fullKeyAddress + offsetFromKeyToValue);\n+      }\n+    }\n+\n+    Location with(int pos, int keyHashcode, boolean isDefined) {\n+      this.pos = pos;\n+      this.isDefined = isDefined;\n+      this.keyHashcode = keyHashcode;\n+      if (isDefined) {\n+        final long fullKeyAddress = longArray.get(pos * 2);\n+        final long offsetFromKeyToValue =\n+          (longArray.get(pos * 2 + 1) & ~MASK_LONG_LOWER_32_BITS) >>> 32;\n+        updateAddressesAndSizes(fullKeyAddress, offsetFromKeyToValue);\n+      }\n+      return this;\n+    }\n+\n+    /**\n+     * Returns true if the key is defined at this position, and false otherwise.\n+     */\n+    public boolean isDefined() {\n+      return isDefined;\n+    }\n+\n+    private Object getPage(long fullKeyAddress) {\n+      assert (inHeap);\n+      final int keyPageNumber = (int) ((fullKeyAddress & MASK_LONG_UPPER_13_BITS) >>> 51);\n+      assert (keyPageNumber >= 0 && keyPageNumber < PAGE_TABLE_SIZE);\n+      assert (keyPageNumber <= currentPageNumber);\n+      final Object page = pageTable[keyPageNumber];\n+      assert (page != null);\n+      return page;\n+    }\n+\n+    private long getOffsetInPage(long fullKeyAddress) {\n+      assert (inHeap);\n+      return (fullKeyAddress & MASK_LONG_LOWER_51_BITS);\n+    }\n+\n+    /**\n+     * Returns the address of the key defined at this position.\n+     * This points to the first byte of the key data.\n+     * Unspecified behavior if the key is not defined.\n+     * For efficiency reasons, calls to this method always returns the same MemoryLocation object.\n+     */\n+    public MemoryLocation getKeyAddress() {\n+      assert (isDefined);\n+      return keyMemoryLocation;\n+    }\n+\n+    /**\n+     * Returns the length of the key defined at this position.\n+     * Unspecified behavior if the key is not defined.\n+     */\n+    public int getKeyLength() {\n+      assert (isDefined);\n+      return keyLength;\n+    }\n+\n+    /**\n+     * Returns the address of the value defined at this position.\n+     * This points to the first byte of the value data.\n+     * Unspecified behavior if the key is not defined.\n+     * For efficiency reasons, calls to this method always returns the same MemoryLocation object.\n+     */\n+    public MemoryLocation getValueAddress() {\n+      assert (isDefined);\n+      return valueMemoryLocation;\n+    }\n+\n+    /**\n+     * Returns the length of the value defined at this position.\n+     * Unspecified behavior if the key is not defined.\n+     */\n+    public int getValueLength() {\n+      assert (isDefined);\n+      return valueLength;\n+    }\n+\n+    /**\n+     * Store a new key and value. This method may only be called once for a given key; if you want\n+     * to update the value associated with a key, then you can directly manipulate the bytes stored\n+     * at the value address.\n+     * <p>\n+     * It is only valid to call this method immediately after calling `lookup()` using the same key.\n+     * <p>\n+     * After calling this method, calls to `get[Key|Value]Address()` and `get[Key|Value]Length`\n+     * will return information on the data stored by this `putNewKey` call.\n+     * <p>\n+     * As an example usage, here's the proper way to store a new key:\n+     * <p>\n+     * <pre>\n+     *   Location loc = map.lookup(keyBaseOffset, keyBaseObject, keyLengthInBytes);\n+     *   if (!loc.isDefined()) {\n+     *     loc.putNewKey(keyBaseOffset, keyBaseObject, keyLengthInBytes, ...)\n+     *   }\n+     * </pre>\n+     * <p>\n+     * Unspecified behavior if the key is not defined.\n+     */\n+    public void putNewKey(\n+        Object keyBaseObject,\n+        long keyBaseOffset,\n+        int keyLengthBytes,\n+        Object valueBaseObject,\n+        long valueBaseOffset,\n+        int valueLengthBytes) {\n+      assert (!isDefined) : \"Can only set value once for a key\";\n+      isDefined = true;\n+      assert (keyLengthBytes % 8 == 0);\n+      assert (valueLengthBytes % 8 == 0);\n+      // Here, we'll copy the data into our data pages. Because we only store a relative offset from\n+      // the key address instead of storing the absolute address of the value, the key and value\n+      // must be stored in the same memory page.\n+      final long requiredSize = 8 + 8 + keyLengthBytes + valueLengthBytes;\n+      assert(requiredSize <= PAGE_SIZE_BYTES);\n+      size++;\n+      bitset.set(pos);\n+\n+      // If there's not enough space in the current page, allocate a new page:\n+      if (currentDataPage == null || PAGE_SIZE_BYTES - pageCursor < requiredSize) {\n+        MemoryBlock newPage = allocator.allocate(PAGE_SIZE_BYTES);\n+        dataPages.add(newPage);\n+        pageCursor = 0;\n+        currentPageNumber++;\n+        pageTable[currentPageNumber] = newPage.getBaseObject();\n+        currentDataPage = newPage;\n+      }\n+\n+      // Compute all of our offsets up-front:\n+      final Object pageBaseObject = currentDataPage.getBaseObject();\n+      final long pageBaseOffset = currentDataPage.getBaseOffset();\n+      final long keySizeOffsetInPage = pageBaseOffset + pageCursor;\n+      pageCursor += 8;\n+      final long keyDataOffsetInPage = pageBaseOffset + pageCursor;\n+      pageCursor += keyLengthBytes;\n+      final long valueSizeOffsetInPage = pageBaseOffset + pageCursor;\n+      pageCursor += 8;\n+      final long valueDataOffsetInPage = pageBaseOffset + pageCursor;\n+      pageCursor += valueLengthBytes;\n+      final long relativeOffsetFromKeyToValue = valueSizeOffsetInPage - keySizeOffsetInPage;"
  }],
  "prId": 5725
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "this is no longer true - we use 32-bit int for index now.\n",
    "commit": "eeee512bd94d463f741170e904ae186e238f997c",
    "createdAt": "2015-04-28T05:44:27Z",
    "diffHunk": "@@ -0,0 +1,552 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.unsafe.map;\n+\n+import java.lang.Override;\n+import java.lang.UnsupportedOperationException;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.spark.unsafe.*;\n+import org.apache.spark.unsafe.array.ByteArrayMethods;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.bitset.BitSet;\n+import org.apache.spark.unsafe.hash.Murmur3_x86_32;\n+import org.apache.spark.unsafe.memory.*;\n+\n+/**\n+ * An append-only hash map where keys and values are contiguous regions of bytes.\n+ * <p>\n+ * This is backed by a power-of-2-sized hash table, using quadratic probing with triangular numbers,\n+ * which is guaranteed to exhaust the space.\n+ * <p>\n+ * Note that even though we use long for indexing, the map can support up to 2^31 keys because"
  }],
  "prId": 5725
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "should be nano sec\n",
    "commit": "eeee512bd94d463f741170e904ae186e238f997c",
    "createdAt": "2015-04-28T05:47:35Z",
    "diffHunk": "@@ -0,0 +1,552 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.unsafe.map;\n+\n+import java.lang.Override;\n+import java.lang.UnsupportedOperationException;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.spark.unsafe.*;\n+import org.apache.spark.unsafe.array.ByteArrayMethods;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.bitset.BitSet;\n+import org.apache.spark.unsafe.hash.Murmur3_x86_32;\n+import org.apache.spark.unsafe.memory.*;\n+\n+/**\n+ * An append-only hash map where keys and values are contiguous regions of bytes.\n+ * <p>\n+ * This is backed by a power-of-2-sized hash table, using quadratic probing with triangular numbers,\n+ * which is guaranteed to exhaust the space.\n+ * <p>\n+ * Note that even though we use long for indexing, the map can support up to 2^31 keys because\n+ * we use 32 bit MurmurHash. In either case, if the key cardinality is so high, you should probably\n+ * be using sorting instead of hashing for better cache locality.\n+ * <p>\n+ * This class is not thread safe.\n+ */\n+public final class BytesToBytesMap {\n+\n+  private static final Murmur3_x86_32 HASHER = new Murmur3_x86_32(0);\n+\n+  private static final HashMapGrowthStrategy growthStrategy = HashMapGrowthStrategy.DOUBLING;\n+\n+  private final MemoryManager memoryManager;\n+\n+  /**\n+   * A linked list for tracking all allocated data pages so that we can free all of our memory.\n+   */\n+  private final List<MemoryBlock> dataPages = new LinkedList<MemoryBlock>();\n+\n+  /**\n+   * The data page that will be used to store keys and values for new hashtable entries. When this\n+   * page becomes full, a new page will be allocated and this pointer will change to point to that\n+   * new page.\n+   */\n+  private MemoryBlock currentDataPage = null;\n+\n+  /**\n+   * Offset into `currentDataPage` that points to the location where new data can be inserted into\n+   * the page.\n+   */\n+  private long pageCursor = 0;\n+\n+  /**\n+   * The size of the data pages that hold key and value data. Map entries cannot span multiple\n+   * pages, so this limits the maximum entry size.\n+   */\n+  private static final long PAGE_SIZE_BYTES = 1L << 26; // 64 megabytes\n+\n+  // This choice of page table size and page size means that we can address up to 500 gigabytes\n+  // of memory.\n+\n+  /**\n+   * A single array to store the key and value.\n+   *\n+   * Position {@code 2 * i} in the array is used to track a pointer to the key at index {@code i},\n+   * while position {@code 2 * i + 1} in the array holds key's full 32-bit hashcode.\n+   */\n+  private LongArray longArray;\n+  // TODO: we're wasting 32 bits of space here; we can probably store fewer bits of the hashcode\n+  // and exploit word-alignment to use fewer bits to hold the address.  This might let us store\n+  // only one long per map entry, increasing the chance that this array will fit in cache at the\n+  // expense of maybe performing more lookups if we have hash collisions.  Say that we stored only\n+  // 27 bits of the hashcode and 37 bits of the address.  37 bits is enough to address 1 terabyte\n+  // of RAM given word-alignment.  If we use 13 bits of this for our page table, that gives us a\n+  // maximum page size of 2^24 * 8 = ~134 megabytes per page. This change will require us to store\n+  // full base addresses in the page table for off-heap mode so that we can reconstruct the full\n+  // absolute memory addresses.\n+\n+  /**\n+   * A {@link BitSet} used to track location of the map where the key is set.\n+   * Size of the bitset should be half of the size of the long array.\n+   */\n+  private BitSet bitset;\n+\n+  private final double loadFactor;\n+\n+  /**\n+   * Number of keys defined in the map.\n+   */\n+  private int size;\n+\n+  /**\n+   * The map will be expanded once the number of keys exceeds this threshold.\n+   */\n+  private int growthThreshold;\n+\n+  /**\n+   * Mask for truncating hashcodes so that they do not exceed the long array's size.\n+   */\n+  private int mask;\n+\n+  /**\n+   * Return value of {@link BytesToBytesMap#lookup(Object, long, int)}.\n+   */\n+  private final Location loc;\n+\n+  private final boolean enablePerfMetrics;\n+\n+  private long timeSpentResizingMs = 0;"
  }],
  "prId": 5725
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "call out explicitly the strength reduction here. Essentially a mod operation, but done using a bit mask since this is power-of-2 sized hash map.\n",
    "commit": "eeee512bd94d463f741170e904ae186e238f997c",
    "createdAt": "2015-04-28T08:08:29Z",
    "diffHunk": "@@ -0,0 +1,552 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.unsafe.map;\n+\n+import java.lang.Override;\n+import java.lang.UnsupportedOperationException;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.spark.unsafe.*;\n+import org.apache.spark.unsafe.array.ByteArrayMethods;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.bitset.BitSet;\n+import org.apache.spark.unsafe.hash.Murmur3_x86_32;\n+import org.apache.spark.unsafe.memory.*;\n+\n+/**\n+ * An append-only hash map where keys and values are contiguous regions of bytes.\n+ * <p>\n+ * This is backed by a power-of-2-sized hash table, using quadratic probing with triangular numbers,\n+ * which is guaranteed to exhaust the space.\n+ * <p>\n+ * Note that even though we use long for indexing, the map can support up to 2^31 keys because\n+ * we use 32 bit MurmurHash. In either case, if the key cardinality is so high, you should probably\n+ * be using sorting instead of hashing for better cache locality.\n+ * <p>\n+ * This class is not thread safe.\n+ */\n+public final class BytesToBytesMap {\n+\n+  private static final Murmur3_x86_32 HASHER = new Murmur3_x86_32(0);\n+\n+  private static final HashMapGrowthStrategy growthStrategy = HashMapGrowthStrategy.DOUBLING;\n+\n+  private final MemoryManager memoryManager;\n+\n+  /**\n+   * A linked list for tracking all allocated data pages so that we can free all of our memory.\n+   */\n+  private final List<MemoryBlock> dataPages = new LinkedList<MemoryBlock>();\n+\n+  /**\n+   * The data page that will be used to store keys and values for new hashtable entries. When this\n+   * page becomes full, a new page will be allocated and this pointer will change to point to that\n+   * new page.\n+   */\n+  private MemoryBlock currentDataPage = null;\n+\n+  /**\n+   * Offset into `currentDataPage` that points to the location where new data can be inserted into\n+   * the page.\n+   */\n+  private long pageCursor = 0;\n+\n+  /**\n+   * The size of the data pages that hold key and value data. Map entries cannot span multiple\n+   * pages, so this limits the maximum entry size.\n+   */\n+  private static final long PAGE_SIZE_BYTES = 1L << 26; // 64 megabytes\n+\n+  // This choice of page table size and page size means that we can address up to 500 gigabytes\n+  // of memory.\n+\n+  /**\n+   * A single array to store the key and value.\n+   *\n+   * Position {@code 2 * i} in the array is used to track a pointer to the key at index {@code i},\n+   * while position {@code 2 * i + 1} in the array holds key's full 32-bit hashcode.\n+   */\n+  private LongArray longArray;\n+  // TODO: we're wasting 32 bits of space here; we can probably store fewer bits of the hashcode\n+  // and exploit word-alignment to use fewer bits to hold the address.  This might let us store\n+  // only one long per map entry, increasing the chance that this array will fit in cache at the\n+  // expense of maybe performing more lookups if we have hash collisions.  Say that we stored only\n+  // 27 bits of the hashcode and 37 bits of the address.  37 bits is enough to address 1 terabyte\n+  // of RAM given word-alignment.  If we use 13 bits of this for our page table, that gives us a\n+  // maximum page size of 2^24 * 8 = ~134 megabytes per page. This change will require us to store\n+  // full base addresses in the page table for off-heap mode so that we can reconstruct the full\n+  // absolute memory addresses.\n+\n+  /**\n+   * A {@link BitSet} used to track location of the map where the key is set.\n+   * Size of the bitset should be half of the size of the long array.\n+   */\n+  private BitSet bitset;\n+\n+  private final double loadFactor;\n+\n+  /**\n+   * Number of keys defined in the map.\n+   */\n+  private int size;\n+\n+  /**\n+   * The map will be expanded once the number of keys exceeds this threshold.\n+   */\n+  private int growthThreshold;\n+\n+  /**\n+   * Mask for truncating hashcodes so that they do not exceed the long array's size.",
    "line": 116
  }],
  "prId": 5725
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "should say what the 8 + 8 are (key len + value len?)\n",
    "commit": "eeee512bd94d463f741170e904ae186e238f997c",
    "createdAt": "2015-04-28T08:09:23Z",
    "diffHunk": "@@ -0,0 +1,552 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.unsafe.map;\n+\n+import java.lang.Override;\n+import java.lang.UnsupportedOperationException;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.spark.unsafe.*;\n+import org.apache.spark.unsafe.array.ByteArrayMethods;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.bitset.BitSet;\n+import org.apache.spark.unsafe.hash.Murmur3_x86_32;\n+import org.apache.spark.unsafe.memory.*;\n+\n+/**\n+ * An append-only hash map where keys and values are contiguous regions of bytes.\n+ * <p>\n+ * This is backed by a power-of-2-sized hash table, using quadratic probing with triangular numbers,\n+ * which is guaranteed to exhaust the space.\n+ * <p>\n+ * Note that even though we use long for indexing, the map can support up to 2^31 keys because\n+ * we use 32 bit MurmurHash. In either case, if the key cardinality is so high, you should probably\n+ * be using sorting instead of hashing for better cache locality.\n+ * <p>\n+ * This class is not thread safe.\n+ */\n+public final class BytesToBytesMap {\n+\n+  private static final Murmur3_x86_32 HASHER = new Murmur3_x86_32(0);\n+\n+  private static final HashMapGrowthStrategy growthStrategy = HashMapGrowthStrategy.DOUBLING;\n+\n+  private final MemoryManager memoryManager;\n+\n+  /**\n+   * A linked list for tracking all allocated data pages so that we can free all of our memory.\n+   */\n+  private final List<MemoryBlock> dataPages = new LinkedList<MemoryBlock>();\n+\n+  /**\n+   * The data page that will be used to store keys and values for new hashtable entries. When this\n+   * page becomes full, a new page will be allocated and this pointer will change to point to that\n+   * new page.\n+   */\n+  private MemoryBlock currentDataPage = null;\n+\n+  /**\n+   * Offset into `currentDataPage` that points to the location where new data can be inserted into\n+   * the page.\n+   */\n+  private long pageCursor = 0;\n+\n+  /**\n+   * The size of the data pages that hold key and value data. Map entries cannot span multiple\n+   * pages, so this limits the maximum entry size.\n+   */\n+  private static final long PAGE_SIZE_BYTES = 1L << 26; // 64 megabytes\n+\n+  // This choice of page table size and page size means that we can address up to 500 gigabytes\n+  // of memory.\n+\n+  /**\n+   * A single array to store the key and value.\n+   *\n+   * Position {@code 2 * i} in the array is used to track a pointer to the key at index {@code i},\n+   * while position {@code 2 * i + 1} in the array holds key's full 32-bit hashcode.\n+   */\n+  private LongArray longArray;\n+  // TODO: we're wasting 32 bits of space here; we can probably store fewer bits of the hashcode\n+  // and exploit word-alignment to use fewer bits to hold the address.  This might let us store\n+  // only one long per map entry, increasing the chance that this array will fit in cache at the\n+  // expense of maybe performing more lookups if we have hash collisions.  Say that we stored only\n+  // 27 bits of the hashcode and 37 bits of the address.  37 bits is enough to address 1 terabyte\n+  // of RAM given word-alignment.  If we use 13 bits of this for our page table, that gives us a\n+  // maximum page size of 2^24 * 8 = ~134 megabytes per page. This change will require us to store\n+  // full base addresses in the page table for off-heap mode so that we can reconstruct the full\n+  // absolute memory addresses.\n+\n+  /**\n+   * A {@link BitSet} used to track location of the map where the key is set.\n+   * Size of the bitset should be half of the size of the long array.\n+   */\n+  private BitSet bitset;\n+\n+  private final double loadFactor;\n+\n+  /**\n+   * Number of keys defined in the map.\n+   */\n+  private int size;\n+\n+  /**\n+   * The map will be expanded once the number of keys exceeds this threshold.\n+   */\n+  private int growthThreshold;\n+\n+  /**\n+   * Mask for truncating hashcodes so that they do not exceed the long array's size.\n+   */\n+  private int mask;\n+\n+  /**\n+   * Return value of {@link BytesToBytesMap#lookup(Object, long, int)}.\n+   */\n+  private final Location loc;\n+\n+  private final boolean enablePerfMetrics;\n+\n+  private long timeSpentResizingMs = 0;\n+\n+  private long numProbes = 0;\n+\n+  private long numKeyLookups = 0;\n+\n+  private long numHashCollisions = 0;\n+\n+  public BytesToBytesMap(\n+      MemoryManager memoryManager,\n+      int initialCapacity,\n+      double loadFactor,\n+      boolean enablePerfMetrics) {\n+    this.memoryManager = memoryManager;\n+    this.loadFactor = loadFactor;\n+    this.loc = new Location();\n+    this.enablePerfMetrics = enablePerfMetrics;\n+    allocate(initialCapacity);\n+  }\n+\n+  public BytesToBytesMap(MemoryManager memoryManager, int initialCapacity) {\n+    this(memoryManager, initialCapacity, 0.70, false);\n+  }\n+\n+  public BytesToBytesMap(\n+      MemoryManager memoryManager,\n+      int initialCapacity,\n+      boolean enablePerfMetrics) {\n+    this(memoryManager, initialCapacity, 0.70, enablePerfMetrics);\n+  }\n+\n+  @Override\n+  protected void finalize() throws Throwable {\n+    try {\n+      // In case the programmer forgot to call `free()`, try to perform that cleanup now:\n+      free();\n+    } finally {\n+      super.finalize();\n+    }\n+  }\n+\n+  /**\n+   * Returns the number of keys defined in the map.\n+   */\n+  public int size() { return size; }\n+\n+  /**\n+   * Returns an iterator for iterating over the entries of this map.\n+   *\n+   * For efficiency, all calls to `next()` will return the same {@link Location} object.\n+   *\n+   * If any other lookups or operations are performed on this map while iterating over it, including\n+   * `lookup()`, the behavior of the returned iterator is undefined.\n+   */\n+  public Iterator<Location> iterator() {\n+    return new Iterator<Location>() {\n+\n+      private int nextPos = bitset.nextSetBit(0);\n+\n+      @Override\n+      public boolean hasNext() {\n+        return nextPos != -1;\n+      }\n+\n+      @Override\n+      public Location next() {\n+        final int pos = nextPos;\n+        nextPos = bitset.nextSetBit(nextPos + 1);\n+        return loc.with(pos, 0, true);\n+      }\n+\n+      @Override\n+      public void remove() {\n+        throw new UnsupportedOperationException();\n+      }\n+    };\n+  }\n+\n+  /**\n+   * Looks up a key, and return a {@link Location} handle that can be used to test existence\n+   * and read/write values.\n+   *\n+   * This function always return the same {@link Location} instance to avoid object allocation.\n+   */\n+  public Location lookup(\n+      Object keyBaseObject,\n+      long keyBaseOffset,\n+      int keyRowLengthBytes) {\n+    if (enablePerfMetrics) {\n+      numKeyLookups++;\n+    }\n+    final int hashcode = HASHER.hashUnsafeWords(keyBaseObject, keyBaseOffset, keyRowLengthBytes);\n+    int pos = hashcode & mask;\n+    int step = 1;\n+    while (true) {\n+      if (enablePerfMetrics) {\n+        numProbes++;\n+      }\n+      if (!bitset.isSet(pos)) {\n+        // This is a new key.\n+        return loc.with(pos, hashcode, false);\n+      } else {\n+        long stored = longArray.get(pos * 2 + 1);\n+        if ((int) (stored) == hashcode) {\n+          // Full hash code matches.  Let's compare the keys for equality.\n+          loc.with(pos, hashcode, true);\n+          if (loc.getKeyLength() == keyRowLengthBytes) {\n+            final MemoryLocation keyAddress = loc.getKeyAddress();\n+            final Object storedKeyBaseObject = keyAddress.getBaseObject();\n+            final long storedKeyBaseOffset = keyAddress.getBaseOffset();\n+            final boolean areEqual = ByteArrayMethods.wordAlignedArrayEquals(\n+              keyBaseObject,\n+              keyBaseOffset,\n+              storedKeyBaseObject,\n+              storedKeyBaseOffset,\n+              keyRowLengthBytes\n+            );\n+            if (areEqual) {\n+              return loc;\n+            } else {\n+              if (enablePerfMetrics) {\n+                numHashCollisions++;\n+              }\n+            }\n+          }\n+        }\n+      }\n+      pos = (pos + step) & mask;\n+      step++;\n+    }\n+  }\n+\n+  /**\n+   * Handle returned by {@link BytesToBytesMap#lookup(Object, long, int)} function.\n+   */\n+  public final class Location {\n+    /** An index into the hash map's Long array */\n+    private int pos;\n+    /** True if this location points to a position where a key is defined, false otherwise */\n+    private boolean isDefined;\n+    /**\n+     * The hashcode of the most recent key passed to\n+     * {@link BytesToBytesMap#lookup(Object, long, int)}. Caching this hashcode here allows us to\n+     * avoid re-hashing the key when storing a value for that key.\n+     */\n+    private int keyHashcode;\n+    private final MemoryLocation keyMemoryLocation = new MemoryLocation();\n+    private final MemoryLocation valueMemoryLocation = new MemoryLocation();\n+    private int keyLength;\n+    private int valueLength;\n+\n+    private void updateAddressesAndSizes(long fullKeyAddress) {\n+        final Object page = memoryManager.getPage(fullKeyAddress);\n+        final long keyOffsetInPage = memoryManager.getOffsetInPage(fullKeyAddress);\n+        keyMemoryLocation.setObjAndOffset(page, keyOffsetInPage + 8);\n+        keyLength = (int) PlatformDependent.UNSAFE.getLong(page, keyOffsetInPage);\n+        valueMemoryLocation.setObjAndOffset(page, keyOffsetInPage + 8 + keyLength + 8);\n+        valueLength = (int) PlatformDependent.UNSAFE.getLong(page, keyOffsetInPage + 8 + keyLength);\n+    }\n+\n+    Location with(int pos, int keyHashcode, boolean isDefined) {\n+      this.pos = pos;\n+      this.isDefined = isDefined;\n+      this.keyHashcode = keyHashcode;\n+      if (isDefined) {\n+        final long fullKeyAddress = longArray.get(pos * 2);\n+        updateAddressesAndSizes(fullKeyAddress);\n+      }\n+      return this;\n+    }\n+\n+    /**\n+     * Returns true if the key is defined at this position, and false otherwise.\n+     */\n+    public boolean isDefined() {\n+      return isDefined;\n+    }\n+\n+    /**\n+     * Returns the address of the key defined at this position.\n+     * This points to the first byte of the key data.\n+     * Unspecified behavior if the key is not defined.\n+     * For efficiency reasons, calls to this method always returns the same MemoryLocation object.\n+     */\n+    public MemoryLocation getKeyAddress() {\n+      assert (isDefined);\n+      return keyMemoryLocation;\n+    }\n+\n+    /**\n+     * Returns the length of the key defined at this position.\n+     * Unspecified behavior if the key is not defined.\n+     */\n+    public int getKeyLength() {\n+      assert (isDefined);\n+      return keyLength;\n+    }\n+\n+    /**\n+     * Returns the address of the value defined at this position.\n+     * This points to the first byte of the value data.\n+     * Unspecified behavior if the key is not defined.\n+     * For efficiency reasons, calls to this method always returns the same MemoryLocation object.\n+     */\n+    public MemoryLocation getValueAddress() {\n+      assert (isDefined);\n+      return valueMemoryLocation;\n+    }\n+\n+    /**\n+     * Returns the length of the value defined at this position.\n+     * Unspecified behavior if the key is not defined.\n+     */\n+    public int getValueLength() {\n+      assert (isDefined);\n+      return valueLength;\n+    }\n+\n+    /**\n+     * Store a new key and value. This method may only be called once for a given key; if you want\n+     * to update the value associated with a key, then you can directly manipulate the bytes stored\n+     * at the value address.\n+     * <p>\n+     * It is only valid to call this method immediately after calling `lookup()` using the same key.\n+     * <p>\n+     * After calling this method, calls to `get[Key|Value]Address()` and `get[Key|Value]Length`\n+     * will return information on the data stored by this `putNewKey` call.\n+     * <p>\n+     * As an example usage, here's the proper way to store a new key:\n+     * <p>\n+     * <pre>\n+     *   Location loc = map.lookup(keyBaseOffset, keyBaseObject, keyLengthInBytes);\n+     *   if (!loc.isDefined()) {\n+     *     loc.putNewKey(keyBaseOffset, keyBaseObject, keyLengthInBytes, ...)\n+     *   }\n+     * </pre>\n+     * <p>\n+     * Unspecified behavior if the key is not defined.\n+     */\n+    public void putNewKey(\n+        Object keyBaseObject,\n+        long keyBaseOffset,\n+        int keyLengthBytes,\n+        Object valueBaseObject,\n+        long valueBaseOffset,\n+        int valueLengthBytes) {\n+      assert (!isDefined) : \"Can only set value once for a key\";\n+      isDefined = true;\n+      assert (keyLengthBytes % 8 == 0);\n+      assert (valueLengthBytes % 8 == 0);\n+      // Here, we'll copy the data into our data pages. Because we only store a relative offset from\n+      // the key address instead of storing the absolute address of the value, the key and value\n+      // must be stored in the same memory page.\n+      final long requiredSize = 8 + 8 + keyLengthBytes + valueLengthBytes;"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Yep, that's key length and value length.  I use the same pattern in a couple of other places, so maybe I can pull this into a constant or add comments there, too.\n",
    "commit": "eeee512bd94d463f741170e904ae186e238f997c",
    "createdAt": "2015-04-28T17:36:43Z",
    "diffHunk": "@@ -0,0 +1,552 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.unsafe.map;\n+\n+import java.lang.Override;\n+import java.lang.UnsupportedOperationException;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.spark.unsafe.*;\n+import org.apache.spark.unsafe.array.ByteArrayMethods;\n+import org.apache.spark.unsafe.array.LongArray;\n+import org.apache.spark.unsafe.bitset.BitSet;\n+import org.apache.spark.unsafe.hash.Murmur3_x86_32;\n+import org.apache.spark.unsafe.memory.*;\n+\n+/**\n+ * An append-only hash map where keys and values are contiguous regions of bytes.\n+ * <p>\n+ * This is backed by a power-of-2-sized hash table, using quadratic probing with triangular numbers,\n+ * which is guaranteed to exhaust the space.\n+ * <p>\n+ * Note that even though we use long for indexing, the map can support up to 2^31 keys because\n+ * we use 32 bit MurmurHash. In either case, if the key cardinality is so high, you should probably\n+ * be using sorting instead of hashing for better cache locality.\n+ * <p>\n+ * This class is not thread safe.\n+ */\n+public final class BytesToBytesMap {\n+\n+  private static final Murmur3_x86_32 HASHER = new Murmur3_x86_32(0);\n+\n+  private static final HashMapGrowthStrategy growthStrategy = HashMapGrowthStrategy.DOUBLING;\n+\n+  private final MemoryManager memoryManager;\n+\n+  /**\n+   * A linked list for tracking all allocated data pages so that we can free all of our memory.\n+   */\n+  private final List<MemoryBlock> dataPages = new LinkedList<MemoryBlock>();\n+\n+  /**\n+   * The data page that will be used to store keys and values for new hashtable entries. When this\n+   * page becomes full, a new page will be allocated and this pointer will change to point to that\n+   * new page.\n+   */\n+  private MemoryBlock currentDataPage = null;\n+\n+  /**\n+   * Offset into `currentDataPage` that points to the location where new data can be inserted into\n+   * the page.\n+   */\n+  private long pageCursor = 0;\n+\n+  /**\n+   * The size of the data pages that hold key and value data. Map entries cannot span multiple\n+   * pages, so this limits the maximum entry size.\n+   */\n+  private static final long PAGE_SIZE_BYTES = 1L << 26; // 64 megabytes\n+\n+  // This choice of page table size and page size means that we can address up to 500 gigabytes\n+  // of memory.\n+\n+  /**\n+   * A single array to store the key and value.\n+   *\n+   * Position {@code 2 * i} in the array is used to track a pointer to the key at index {@code i},\n+   * while position {@code 2 * i + 1} in the array holds key's full 32-bit hashcode.\n+   */\n+  private LongArray longArray;\n+  // TODO: we're wasting 32 bits of space here; we can probably store fewer bits of the hashcode\n+  // and exploit word-alignment to use fewer bits to hold the address.  This might let us store\n+  // only one long per map entry, increasing the chance that this array will fit in cache at the\n+  // expense of maybe performing more lookups if we have hash collisions.  Say that we stored only\n+  // 27 bits of the hashcode and 37 bits of the address.  37 bits is enough to address 1 terabyte\n+  // of RAM given word-alignment.  If we use 13 bits of this for our page table, that gives us a\n+  // maximum page size of 2^24 * 8 = ~134 megabytes per page. This change will require us to store\n+  // full base addresses in the page table for off-heap mode so that we can reconstruct the full\n+  // absolute memory addresses.\n+\n+  /**\n+   * A {@link BitSet} used to track location of the map where the key is set.\n+   * Size of the bitset should be half of the size of the long array.\n+   */\n+  private BitSet bitset;\n+\n+  private final double loadFactor;\n+\n+  /**\n+   * Number of keys defined in the map.\n+   */\n+  private int size;\n+\n+  /**\n+   * The map will be expanded once the number of keys exceeds this threshold.\n+   */\n+  private int growthThreshold;\n+\n+  /**\n+   * Mask for truncating hashcodes so that they do not exceed the long array's size.\n+   */\n+  private int mask;\n+\n+  /**\n+   * Return value of {@link BytesToBytesMap#lookup(Object, long, int)}.\n+   */\n+  private final Location loc;\n+\n+  private final boolean enablePerfMetrics;\n+\n+  private long timeSpentResizingMs = 0;\n+\n+  private long numProbes = 0;\n+\n+  private long numKeyLookups = 0;\n+\n+  private long numHashCollisions = 0;\n+\n+  public BytesToBytesMap(\n+      MemoryManager memoryManager,\n+      int initialCapacity,\n+      double loadFactor,\n+      boolean enablePerfMetrics) {\n+    this.memoryManager = memoryManager;\n+    this.loadFactor = loadFactor;\n+    this.loc = new Location();\n+    this.enablePerfMetrics = enablePerfMetrics;\n+    allocate(initialCapacity);\n+  }\n+\n+  public BytesToBytesMap(MemoryManager memoryManager, int initialCapacity) {\n+    this(memoryManager, initialCapacity, 0.70, false);\n+  }\n+\n+  public BytesToBytesMap(\n+      MemoryManager memoryManager,\n+      int initialCapacity,\n+      boolean enablePerfMetrics) {\n+    this(memoryManager, initialCapacity, 0.70, enablePerfMetrics);\n+  }\n+\n+  @Override\n+  protected void finalize() throws Throwable {\n+    try {\n+      // In case the programmer forgot to call `free()`, try to perform that cleanup now:\n+      free();\n+    } finally {\n+      super.finalize();\n+    }\n+  }\n+\n+  /**\n+   * Returns the number of keys defined in the map.\n+   */\n+  public int size() { return size; }\n+\n+  /**\n+   * Returns an iterator for iterating over the entries of this map.\n+   *\n+   * For efficiency, all calls to `next()` will return the same {@link Location} object.\n+   *\n+   * If any other lookups or operations are performed on this map while iterating over it, including\n+   * `lookup()`, the behavior of the returned iterator is undefined.\n+   */\n+  public Iterator<Location> iterator() {\n+    return new Iterator<Location>() {\n+\n+      private int nextPos = bitset.nextSetBit(0);\n+\n+      @Override\n+      public boolean hasNext() {\n+        return nextPos != -1;\n+      }\n+\n+      @Override\n+      public Location next() {\n+        final int pos = nextPos;\n+        nextPos = bitset.nextSetBit(nextPos + 1);\n+        return loc.with(pos, 0, true);\n+      }\n+\n+      @Override\n+      public void remove() {\n+        throw new UnsupportedOperationException();\n+      }\n+    };\n+  }\n+\n+  /**\n+   * Looks up a key, and return a {@link Location} handle that can be used to test existence\n+   * and read/write values.\n+   *\n+   * This function always return the same {@link Location} instance to avoid object allocation.\n+   */\n+  public Location lookup(\n+      Object keyBaseObject,\n+      long keyBaseOffset,\n+      int keyRowLengthBytes) {\n+    if (enablePerfMetrics) {\n+      numKeyLookups++;\n+    }\n+    final int hashcode = HASHER.hashUnsafeWords(keyBaseObject, keyBaseOffset, keyRowLengthBytes);\n+    int pos = hashcode & mask;\n+    int step = 1;\n+    while (true) {\n+      if (enablePerfMetrics) {\n+        numProbes++;\n+      }\n+      if (!bitset.isSet(pos)) {\n+        // This is a new key.\n+        return loc.with(pos, hashcode, false);\n+      } else {\n+        long stored = longArray.get(pos * 2 + 1);\n+        if ((int) (stored) == hashcode) {\n+          // Full hash code matches.  Let's compare the keys for equality.\n+          loc.with(pos, hashcode, true);\n+          if (loc.getKeyLength() == keyRowLengthBytes) {\n+            final MemoryLocation keyAddress = loc.getKeyAddress();\n+            final Object storedKeyBaseObject = keyAddress.getBaseObject();\n+            final long storedKeyBaseOffset = keyAddress.getBaseOffset();\n+            final boolean areEqual = ByteArrayMethods.wordAlignedArrayEquals(\n+              keyBaseObject,\n+              keyBaseOffset,\n+              storedKeyBaseObject,\n+              storedKeyBaseOffset,\n+              keyRowLengthBytes\n+            );\n+            if (areEqual) {\n+              return loc;\n+            } else {\n+              if (enablePerfMetrics) {\n+                numHashCollisions++;\n+              }\n+            }\n+          }\n+        }\n+      }\n+      pos = (pos + step) & mask;\n+      step++;\n+    }\n+  }\n+\n+  /**\n+   * Handle returned by {@link BytesToBytesMap#lookup(Object, long, int)} function.\n+   */\n+  public final class Location {\n+    /** An index into the hash map's Long array */\n+    private int pos;\n+    /** True if this location points to a position where a key is defined, false otherwise */\n+    private boolean isDefined;\n+    /**\n+     * The hashcode of the most recent key passed to\n+     * {@link BytesToBytesMap#lookup(Object, long, int)}. Caching this hashcode here allows us to\n+     * avoid re-hashing the key when storing a value for that key.\n+     */\n+    private int keyHashcode;\n+    private final MemoryLocation keyMemoryLocation = new MemoryLocation();\n+    private final MemoryLocation valueMemoryLocation = new MemoryLocation();\n+    private int keyLength;\n+    private int valueLength;\n+\n+    private void updateAddressesAndSizes(long fullKeyAddress) {\n+        final Object page = memoryManager.getPage(fullKeyAddress);\n+        final long keyOffsetInPage = memoryManager.getOffsetInPage(fullKeyAddress);\n+        keyMemoryLocation.setObjAndOffset(page, keyOffsetInPage + 8);\n+        keyLength = (int) PlatformDependent.UNSAFE.getLong(page, keyOffsetInPage);\n+        valueMemoryLocation.setObjAndOffset(page, keyOffsetInPage + 8 + keyLength + 8);\n+        valueLength = (int) PlatformDependent.UNSAFE.getLong(page, keyOffsetInPage + 8 + keyLength);\n+    }\n+\n+    Location with(int pos, int keyHashcode, boolean isDefined) {\n+      this.pos = pos;\n+      this.isDefined = isDefined;\n+      this.keyHashcode = keyHashcode;\n+      if (isDefined) {\n+        final long fullKeyAddress = longArray.get(pos * 2);\n+        updateAddressesAndSizes(fullKeyAddress);\n+      }\n+      return this;\n+    }\n+\n+    /**\n+     * Returns true if the key is defined at this position, and false otherwise.\n+     */\n+    public boolean isDefined() {\n+      return isDefined;\n+    }\n+\n+    /**\n+     * Returns the address of the key defined at this position.\n+     * This points to the first byte of the key data.\n+     * Unspecified behavior if the key is not defined.\n+     * For efficiency reasons, calls to this method always returns the same MemoryLocation object.\n+     */\n+    public MemoryLocation getKeyAddress() {\n+      assert (isDefined);\n+      return keyMemoryLocation;\n+    }\n+\n+    /**\n+     * Returns the length of the key defined at this position.\n+     * Unspecified behavior if the key is not defined.\n+     */\n+    public int getKeyLength() {\n+      assert (isDefined);\n+      return keyLength;\n+    }\n+\n+    /**\n+     * Returns the address of the value defined at this position.\n+     * This points to the first byte of the value data.\n+     * Unspecified behavior if the key is not defined.\n+     * For efficiency reasons, calls to this method always returns the same MemoryLocation object.\n+     */\n+    public MemoryLocation getValueAddress() {\n+      assert (isDefined);\n+      return valueMemoryLocation;\n+    }\n+\n+    /**\n+     * Returns the length of the value defined at this position.\n+     * Unspecified behavior if the key is not defined.\n+     */\n+    public int getValueLength() {\n+      assert (isDefined);\n+      return valueLength;\n+    }\n+\n+    /**\n+     * Store a new key and value. This method may only be called once for a given key; if you want\n+     * to update the value associated with a key, then you can directly manipulate the bytes stored\n+     * at the value address.\n+     * <p>\n+     * It is only valid to call this method immediately after calling `lookup()` using the same key.\n+     * <p>\n+     * After calling this method, calls to `get[Key|Value]Address()` and `get[Key|Value]Length`\n+     * will return information on the data stored by this `putNewKey` call.\n+     * <p>\n+     * As an example usage, here's the proper way to store a new key:\n+     * <p>\n+     * <pre>\n+     *   Location loc = map.lookup(keyBaseOffset, keyBaseObject, keyLengthInBytes);\n+     *   if (!loc.isDefined()) {\n+     *     loc.putNewKey(keyBaseOffset, keyBaseObject, keyLengthInBytes, ...)\n+     *   }\n+     * </pre>\n+     * <p>\n+     * Unspecified behavior if the key is not defined.\n+     */\n+    public void putNewKey(\n+        Object keyBaseObject,\n+        long keyBaseOffset,\n+        int keyLengthBytes,\n+        Object valueBaseObject,\n+        long valueBaseOffset,\n+        int valueLengthBytes) {\n+      assert (!isDefined) : \"Can only set value once for a key\";\n+      isDefined = true;\n+      assert (keyLengthBytes % 8 == 0);\n+      assert (valueLengthBytes % 8 == 0);\n+      // Here, we'll copy the data into our data pages. Because we only store a relative offset from\n+      // the key address instead of storing the absolute address of the value, the key and value\n+      // must be stored in the same memory page.\n+      final long requiredSize = 8 + 8 + keyLengthBytes + valueLengthBytes;"
  }],
  "prId": 5725
}]