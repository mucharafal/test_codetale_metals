[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "For these `TODO`s, if they don't land in the first version then we should comment out the methods as well.  I think we should keep the TODOs as a reminder of what's missing, but shouldn't have empty methods.\n",
    "commit": "d0a747901af273c5eb8578ec191cc7673f6efce5",
    "createdAt": "2015-01-26T19:24:24Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python bindings for Graph[VertexRDD, EdgeRDD] in GraphX\n+\"\"\"\n+\n+import itertools\n+from pyspark import PickleSerializer, RDD, StorageLevel, SparkContext\n+from pyspark.graphx import VertexRDD, EdgeRDD\n+\n+from pyspark.graphx.partitionstrategy import PartitionStrategy\n+from pyspark.rdd import PipelinedRDD\n+from pyspark.serializers import BatchedSerializer\n+\n+__all__ = [\"Graph\"]\n+\n+class Graph(object):\n+    def __init__(self, vertex_jrdd, edge_jrdd,\n+                 partition_strategy=PartitionStrategy.EdgePartition1D):\n+        self._vertex_jrdd = VertexRDD(vertex_jrdd, vertex_jrdd.context,\n+                                      BatchedSerializer(PickleSerializer()))\n+        self._edge_jrdd = EdgeRDD(edge_jrdd, edge_jrdd.context,\n+                                  BatchedSerializer(PickleSerializer()))\n+        self._partition_strategy = partition_strategy\n+        self._jsc = vertex_jrdd.context\n+\n+    def persist(self, storageLevel):\n+        self._vertex_jrdd.persist(storageLevel)\n+        self._edge_jrdd.persist(storageLevel)\n+        return\n+\n+    def cache(self):\n+        self._vertex_jrdd.cache()\n+        self._edge_jrdd.cache()\n+        return\n+\n+    def vertices(self):\n+        return self._vertex_jrdd\n+\n+    def edges(self):\n+        return self._edge_jrdd\n+\n+    def numEdges(self):\n+        return self._edge_jrdd.count()\n+\n+    def numVertices(self):\n+        return self._vertex_jrdd.count()\n+\n+    # TODO\n+    def partitionBy(self, partitionStrategy):",
    "line": 65
  }],
  "prId": 4205
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "What happens if this is false?\n",
    "commit": "d0a747901af273c5eb8578ec191cc7673f6efce5",
    "createdAt": "2015-01-26T19:24:51Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python bindings for Graph[VertexRDD, EdgeRDD] in GraphX\n+\"\"\"\n+\n+import itertools\n+from pyspark import PickleSerializer, RDD, StorageLevel, SparkContext\n+from pyspark.graphx import VertexRDD, EdgeRDD\n+\n+from pyspark.graphx.partitionstrategy import PartitionStrategy\n+from pyspark.rdd import PipelinedRDD\n+from pyspark.serializers import BatchedSerializer\n+\n+__all__ = [\"Graph\"]\n+\n+class Graph(object):\n+    def __init__(self, vertex_jrdd, edge_jrdd,\n+                 partition_strategy=PartitionStrategy.EdgePartition1D):\n+        self._vertex_jrdd = VertexRDD(vertex_jrdd, vertex_jrdd.context,\n+                                      BatchedSerializer(PickleSerializer()))\n+        self._edge_jrdd = EdgeRDD(edge_jrdd, edge_jrdd.context,\n+                                  BatchedSerializer(PickleSerializer()))\n+        self._partition_strategy = partition_strategy\n+        self._jsc = vertex_jrdd.context\n+\n+    def persist(self, storageLevel):\n+        self._vertex_jrdd.persist(storageLevel)\n+        self._edge_jrdd.persist(storageLevel)\n+        return\n+\n+    def cache(self):\n+        self._vertex_jrdd.cache()\n+        self._edge_jrdd.cache()\n+        return\n+\n+    def vertices(self):\n+        return self._vertex_jrdd\n+\n+    def edges(self):\n+        return self._edge_jrdd\n+\n+    def numEdges(self):\n+        return self._edge_jrdd.count()\n+\n+    def numVertices(self):\n+        return self._vertex_jrdd.count()\n+\n+    # TODO\n+    def partitionBy(self, partitionStrategy):\n+        return\n+\n+    # TODO\n+    def inDegrees(self):\n+        return\n+\n+    # TODO\n+    def outDegrees(self):\n+        return\n+\n+    # TODO\n+    def degrees(self):\n+        return\n+\n+    def triplets(self):\n+        if (isinstance(self._jsc, SparkContext)):",
    "line": 81
  }],
  "prId": 4205
}]