[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "\"the a\" --> \"a\"\n",
    "commit": "3a0b6e5fe8458b89cd5fb3fffc0536aa6c1b4b4d",
    "createdAt": "2014-11-03T22:58:26Z",
    "diffHunk": "@@ -408,6 +408,73 @@ def fromJson(cls, json):\n         return StructType([StructField.fromJson(f) for f in json[\"fields\"]])\n \n \n+class UserDefinedType(DataType):\n+    \"\"\"\n+    :: WARN: Spark Internal Use Only ::\n+    SQL User-Defined Type (UDT).\n+    \"\"\"\n+\n+    @classmethod\n+    def typeName(cls):\n+        return cls.__name__.lower()\n+\n+    @classmethod\n+    def sqlType(cls):\n+        \"\"\"\n+        Underlying SQL storage type for this UDT.\n+        \"\"\"\n+        raise NotImplementedError(\"UDT must implement sqlType().\")\n+\n+    @classmethod\n+    def module(cls):\n+        \"\"\"\n+        The Python module of the UDT.\n+        \"\"\"\n+        raise NotImplementedError(\"UDT must implement module().\")\n+\n+    @classmethod\n+    def scalaUDT(cls):\n+        \"\"\"\n+        The class name of the paired Scala UDT.\n+        \"\"\"\n+        raise NotImplementedError(\"UDT must have a paired Scala UDT.\")\n+\n+    def serialize(self, obj):\n+        \"\"\"\n+        Converts the a user-type object into a SQL datum."
  }],
  "prId": 3070
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Add comment:\n\n```\n>>> # User-Defined Type.\n```\n",
    "commit": "3a0b6e5fe8458b89cd5fb3fffc0536aa6c1b4b4d",
    "createdAt": "2014-11-03T22:58:28Z",
    "diffHunk": "@@ -460,6 +527,13 @@ def _parse_datatype_json_string(json_string):\n     ...                           complex_arraytype, False)\n     >>> check_datatype(complex_maptype)\n     True\n+    >>> from pyspark.tests import ExamplePointUDT"
  }],
  "prId": 3070
}]