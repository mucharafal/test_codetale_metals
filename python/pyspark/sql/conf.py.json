[{
  "comments": [{
    "author": {
      "login": "xuanyuanking"
    },
    "body": "@gatorsmile I moved all core configs using in pyspark into conf.py here. Please have a look when you have time.\r\nhttps://github.com/apache/spark/pull/21370#discussion_r194276735",
    "commit": "00ae164b535f5e4be6bfa2b496124760d0cdafdd",
    "createdAt": "2018-06-26T15:14:15Z",
    "diffHunk": "@@ -64,6 +64,96 @@ def _checkType(self, obj, identifier):\n                             (identifier, obj, type(obj).__name__))\n \n \n+class ConfigEntry(object):"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "Thank you for fixing this! Let us do it in a separate PR. ",
    "commit": "00ae164b535f5e4be6bfa2b496124760d0cdafdd",
    "createdAt": "2018-06-26T21:20:58Z",
    "diffHunk": "@@ -64,6 +64,96 @@ def _checkType(self, obj, identifier):\n                             (identifier, obj, type(obj).__name__))\n \n \n+class ConfigEntry(object):"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Yep, done in #21648 ",
    "commit": "00ae164b535f5e4be6bfa2b496124760d0cdafdd",
    "createdAt": "2018-06-27T05:45:59Z",
    "diffHunk": "@@ -64,6 +64,96 @@ def _checkType(self, obj, identifier):\n                             (identifier, obj, type(obj).__name__))\n \n \n+class ConfigEntry(object):"
  }],
  "prId": 21553
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "I think this PySpark SQLConf stuff should be done in a separate Jira/PR.",
    "commit": "00ae164b535f5e4be6bfa2b496124760d0cdafdd",
    "createdAt": "2018-06-27T01:15:51Z",
    "diffHunk": "@@ -64,6 +64,96 @@ def _checkType(self, obj, identifier):\n                             (identifier, obj, type(obj).__name__))\n \n \n+class ConfigEntry(object):\n+    \"\"\"An entry contains all meta information for a configuration\"\"\"\n+\n+    def __init__(self, confKey):\n+        \"\"\"Create a new ConfigEntry with config key\"\"\"\n+        self.confKey = confKey\n+        self.converter = None\n+        self.default = _NoValue\n+\n+    def boolConf(self):\n+        \"\"\"Designate current config entry is boolean config\"\"\"\n+        self.converter = lambda x: str(x).lower() == \"true\"\n+        return self\n+\n+    def intConf(self):\n+        \"\"\"Designate current config entry is integer config\"\"\"\n+        self.converter = lambda x: int(x)\n+        return self\n+\n+    def stringConf(self):\n+        \"\"\"Designate current config entry is string config\"\"\"\n+        self.converter = lambda x: str(x)\n+        return self\n+\n+    def withDefault(self, default):\n+        \"\"\"Give a default value for current config entry, the default value will be set\n+        to _NoValue when its absent\"\"\"\n+        self.default = default\n+        return self\n+\n+    def read(self, ctx):\n+        \"\"\"Read value from this config entry through sql context\"\"\"\n+        return self.converter(ctx.getConf(self.confKey, self.default))\n+\n+class SQLConf(object):"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Yea, it should be separate.",
    "commit": "00ae164b535f5e4be6bfa2b496124760d0cdafdd",
    "createdAt": "2018-06-27T01:17:46Z",
    "diffHunk": "@@ -64,6 +64,96 @@ def _checkType(self, obj, identifier):\n                             (identifier, obj, type(obj).__name__))\n \n \n+class ConfigEntry(object):\n+    \"\"\"An entry contains all meta information for a configuration\"\"\"\n+\n+    def __init__(self, confKey):\n+        \"\"\"Create a new ConfigEntry with config key\"\"\"\n+        self.confKey = confKey\n+        self.converter = None\n+        self.default = _NoValue\n+\n+    def boolConf(self):\n+        \"\"\"Designate current config entry is boolean config\"\"\"\n+        self.converter = lambda x: str(x).lower() == \"true\"\n+        return self\n+\n+    def intConf(self):\n+        \"\"\"Designate current config entry is integer config\"\"\"\n+        self.converter = lambda x: int(x)\n+        return self\n+\n+    def stringConf(self):\n+        \"\"\"Designate current config entry is string config\"\"\"\n+        self.converter = lambda x: str(x)\n+        return self\n+\n+    def withDefault(self, default):\n+        \"\"\"Give a default value for current config entry, the default value will be set\n+        to _NoValue when its absent\"\"\"\n+        self.default = default\n+        return self\n+\n+    def read(self, ctx):\n+        \"\"\"Read value from this config entry through sql context\"\"\"\n+        return self.converter(ctx.getConf(self.confKey, self.default))\n+\n+class SQLConf(object):"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Yeah, agree, done in #21648.",
    "commit": "00ae164b535f5e4be6bfa2b496124760d0cdafdd",
    "createdAt": "2018-06-27T05:46:26Z",
    "diffHunk": "@@ -64,6 +64,96 @@ def _checkType(self, obj, identifier):\n                             (identifier, obj, type(obj).__name__))\n \n \n+class ConfigEntry(object):\n+    \"\"\"An entry contains all meta information for a configuration\"\"\"\n+\n+    def __init__(self, confKey):\n+        \"\"\"Create a new ConfigEntry with config key\"\"\"\n+        self.confKey = confKey\n+        self.converter = None\n+        self.default = _NoValue\n+\n+    def boolConf(self):\n+        \"\"\"Designate current config entry is boolean config\"\"\"\n+        self.converter = lambda x: str(x).lower() == \"true\"\n+        return self\n+\n+    def intConf(self):\n+        \"\"\"Designate current config entry is integer config\"\"\"\n+        self.converter = lambda x: int(x)\n+        return self\n+\n+    def stringConf(self):\n+        \"\"\"Designate current config entry is string config\"\"\"\n+        self.converter = lambda x: str(x)\n+        return self\n+\n+    def withDefault(self, default):\n+        \"\"\"Give a default value for current config entry, the default value will be set\n+        to _NoValue when its absent\"\"\"\n+        self.default = default\n+        return self\n+\n+    def read(self, ctx):\n+        \"\"\"Read value from this config entry through sql context\"\"\"\n+        return self.converter(ctx.getConf(self.confKey, self.default))\n+\n+class SQLConf(object):"
  }],
  "prId": 21553
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "This duplicates the key. I think current way duplicates a lot of codes in Scala side.",
    "commit": "00ae164b535f5e4be6bfa2b496124760d0cdafdd",
    "createdAt": "2018-06-27T01:19:05Z",
    "diffHunk": "@@ -64,6 +64,96 @@ def _checkType(self, obj, identifier):\n                             (identifier, obj, type(obj).__name__))\n \n \n+class ConfigEntry(object):\n+    \"\"\"An entry contains all meta information for a configuration\"\"\"\n+\n+    def __init__(self, confKey):\n+        \"\"\"Create a new ConfigEntry with config key\"\"\"\n+        self.confKey = confKey\n+        self.converter = None\n+        self.default = _NoValue\n+\n+    def boolConf(self):\n+        \"\"\"Designate current config entry is boolean config\"\"\"\n+        self.converter = lambda x: str(x).lower() == \"true\"\n+        return self\n+\n+    def intConf(self):\n+        \"\"\"Designate current config entry is integer config\"\"\"\n+        self.converter = lambda x: int(x)\n+        return self\n+\n+    def stringConf(self):\n+        \"\"\"Designate current config entry is string config\"\"\"\n+        self.converter = lambda x: str(x)\n+        return self\n+\n+    def withDefault(self, default):\n+        \"\"\"Give a default value for current config entry, the default value will be set\n+        to _NoValue when its absent\"\"\"\n+        self.default = default\n+        return self\n+\n+    def read(self, ctx):\n+        \"\"\"Read value from this config entry through sql context\"\"\"\n+        return self.converter(ctx.getConf(self.confKey, self.default))\n+\n+class SQLConf(object):\n+    \"\"\"A class that enables the getting of SQL config parameters in pyspark\"\"\"\n+\n+    REPL_EAGER_EVAL_ENABLED = ConfigEntry(\"spark.sql.repl.eagerEval.enabled\")\\\n+        .boolConf()\\\n+        .withDefault(\"false\")\n+\n+    REPL_EAGER_EVAL_MAX_NUM_ROWS = ConfigEntry(\"spark.sql.repl.eagerEval.maxNumRows\")\\\n+        .intConf()\\\n+        .withDefault(\"20\")\n+\n+    REPL_EAGER_EVAL_TRUNCATE = ConfigEntry(\"spark.sql.repl.eagerEval.truncate\")\\\n+        .intConf()\\\n+        .withDefault(\"20\")\n+\n+    PANDAS_RESPECT_SESSION_LOCAL_TIMEZONE = \\\n+        ConfigEntry(\"spark.sql.execution.pandas.respectSessionTimeZone\")\\\n+        .boolConf()\n+\n+    SESSION_LOCAL_TIMEZONE = ConfigEntry(\"spark.sql.session.timeZone\")\\\n+        .stringConf()\n+\n+    ARROW_EXECUTION_ENABLED = ConfigEntry(\"spark.sql.execution.arrow.enabled\")\\"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Yep, I'm also puzzled by this, cause we also do the register in Scala side. How about just call buildConf on Scala side for theses keys which used only on PySpark? Lets discuss it in #21648 ",
    "commit": "00ae164b535f5e4be6bfa2b496124760d0cdafdd",
    "createdAt": "2018-06-27T05:49:07Z",
    "diffHunk": "@@ -64,6 +64,96 @@ def _checkType(self, obj, identifier):\n                             (identifier, obj, type(obj).__name__))\n \n \n+class ConfigEntry(object):\n+    \"\"\"An entry contains all meta information for a configuration\"\"\"\n+\n+    def __init__(self, confKey):\n+        \"\"\"Create a new ConfigEntry with config key\"\"\"\n+        self.confKey = confKey\n+        self.converter = None\n+        self.default = _NoValue\n+\n+    def boolConf(self):\n+        \"\"\"Designate current config entry is boolean config\"\"\"\n+        self.converter = lambda x: str(x).lower() == \"true\"\n+        return self\n+\n+    def intConf(self):\n+        \"\"\"Designate current config entry is integer config\"\"\"\n+        self.converter = lambda x: int(x)\n+        return self\n+\n+    def stringConf(self):\n+        \"\"\"Designate current config entry is string config\"\"\"\n+        self.converter = lambda x: str(x)\n+        return self\n+\n+    def withDefault(self, default):\n+        \"\"\"Give a default value for current config entry, the default value will be set\n+        to _NoValue when its absent\"\"\"\n+        self.default = default\n+        return self\n+\n+    def read(self, ctx):\n+        \"\"\"Read value from this config entry through sql context\"\"\"\n+        return self.converter(ctx.getConf(self.confKey, self.default))\n+\n+class SQLConf(object):\n+    \"\"\"A class that enables the getting of SQL config parameters in pyspark\"\"\"\n+\n+    REPL_EAGER_EVAL_ENABLED = ConfigEntry(\"spark.sql.repl.eagerEval.enabled\")\\\n+        .boolConf()\\\n+        .withDefault(\"false\")\n+\n+    REPL_EAGER_EVAL_MAX_NUM_ROWS = ConfigEntry(\"spark.sql.repl.eagerEval.maxNumRows\")\\\n+        .intConf()\\\n+        .withDefault(\"20\")\n+\n+    REPL_EAGER_EVAL_TRUNCATE = ConfigEntry(\"spark.sql.repl.eagerEval.truncate\")\\\n+        .intConf()\\\n+        .withDefault(\"20\")\n+\n+    PANDAS_RESPECT_SESSION_LOCAL_TIMEZONE = \\\n+        ConfigEntry(\"spark.sql.execution.pandas.respectSessionTimeZone\")\\\n+        .boolConf()\n+\n+    SESSION_LOCAL_TIMEZONE = ConfigEntry(\"spark.sql.session.timeZone\")\\\n+        .stringConf()\n+\n+    ARROW_EXECUTION_ENABLED = ConfigEntry(\"spark.sql.execution.arrow.enabled\")\\"
  }],
  "prId": 21553
}]