[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Can you use `with self.table(\"test_table\"):` too?",
    "commit": "9b167e10ce83df809af838e82bf6112595f65f17",
    "createdAt": "2019-07-17T00:41:28Z",
    "diffHunk": "@@ -141,6 +141,25 @@ def count_bucketed_cols(names, table=\"pyspark_bucket\"):\n                 .mode(\"overwrite\").saveAsTable(\"pyspark_bucket\"))\n             self.assertSetEqual(set(data), set(self.spark.table(\"pyspark_bucket\").collect()))\n \n+    def test_insert_into(self):\n+        df = self.spark.createDataFrame([(\"a\", 1), (\"b\", 2)], [\"C1\", \"C2\"])\n+        df.write.saveAsTable(\"test_table\")"
  }],
  "prId": 25175
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "seems a mistake.",
    "commit": "9b167e10ce83df809af838e82bf6112595f65f17",
    "createdAt": "2019-07-17T04:07:37Z",
    "diffHunk": "@@ -141,6 +141,26 @@ def count_bucketed_cols(names, table=\"pyspark_bucket\"):\n                 .mode(\"overwrite\").saveAsTable(\"pyspark_bucket\"))\n             self.assertSetEqual(set(data), set(self.spark.table(\"pyspark_bucket\").collect()))\n \n+    def test_insert_into(self):\n+        df = self.spark.createDataFrame([(\"a\", 1), (\"b\", 2)], [\"C1\", \"C2\"])\n+        with self.table(\"test_table\"):\n+            df.write.saveAsTable(\"test_table\")\n+            self.assertEqual(2, self.spark.sql(\"select * from test_table\").count())\n+\n+            df.write.insertInto(\"test_table\")\n+            self.assertEqual(4, self.spark.sql(\"select * from test_table\").count())\n+\n+            df.write.mode(\"overwrite\").insertInto(\"test_table\")\n+            self.assertEqual(2, self.spark.sql(\"select * from test_table\").count())\n+\n+            df.write.insertInto(\"test_table\", True)\n+            self.assertEqual(2, self.spark.sql(\"select * from test_table\").count())\n+\n+            df.write.insertInto(\"test_table\", False)\n+            self.assertEqual(4, self.spark.sql(\"select * from test_table\").count())\n+\n+            # self.spark.sql(\"drop table test_table\")"
  }],
  "prId": 25175
}]