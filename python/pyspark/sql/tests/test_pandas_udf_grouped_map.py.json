[{
  "comments": [{
    "author": {
      "login": "BryanCutler"
    },
    "body": "This was the only surprise, and it's because calling `DataFrame.apply` with kwargs infers the column names as str for Python 2, and causes DataFrame.columns.inferred_type to be 'mixed' and the assert to fail",
    "commit": "8dd720242d29fcd8cd2bb34c4fba663580577add",
    "createdAt": "2019-04-05T22:38:42Z",
    "diffHunk": "@@ -29,6 +29,25 @@\n     pandas_requirement_message, pyarrow_requirement_message\n from pyspark.testing.utils import QuietTest\n \n+if have_pandas:\n+    import pandas as pd\n+    from pandas.util.testing import assert_frame_equal as pd_assert_frame_equal\n+\n+if have_pyarrow:\n+    import pyarrow as pa\n+\n+\n+def assert_frame_equal(left, right):\n+    \"\"\"\n+    Wrap Pandas function because pd.DataFrame.assign will infer mixed types (unicode/str)\n+    w/ Python 2, so need to set check_column_type=False\n+    \"\"\"\n+    import sys\n+    if sys.version < '3':\n+        pd_assert_frame_equal(left, right, check_column_type=False)"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Should we let all tests using this wrapped version? I think it's better if we use a consistent version of `assert_frame_equal`.",
    "commit": "8dd720242d29fcd8cd2bb34c4fba663580577add",
    "createdAt": "2019-04-09T13:54:25Z",
    "diffHunk": "@@ -29,6 +29,25 @@\n     pandas_requirement_message, pyarrow_requirement_message\n from pyspark.testing.utils import QuietTest\n \n+if have_pandas:\n+    import pandas as pd\n+    from pandas.util.testing import assert_frame_equal as pd_assert_frame_equal\n+\n+if have_pyarrow:\n+    import pyarrow as pa\n+\n+\n+def assert_frame_equal(left, right):\n+    \"\"\"\n+    Wrap Pandas function because pd.DataFrame.assign will infer mixed types (unicode/str)\n+    w/ Python 2, so need to set check_column_type=False\n+    \"\"\"\n+    import sys\n+    if sys.version < '3':\n+        pd_assert_frame_equal(left, right, check_column_type=False)"
  }, {
    "author": {
      "login": "BryanCutler"
    },
    "body": "I don't know, the problem only comes up in these tests because of the way they call `assign`. How about I remove this function wrapping and just make the option conditional for Python version?",
    "commit": "8dd720242d29fcd8cd2bb34c4fba663580577add",
    "createdAt": "2019-04-09T16:49:12Z",
    "diffHunk": "@@ -29,6 +29,25 @@\n     pandas_requirement_message, pyarrow_requirement_message\n from pyspark.testing.utils import QuietTest\n \n+if have_pandas:\n+    import pandas as pd\n+    from pandas.util.testing import assert_frame_equal as pd_assert_frame_equal\n+\n+if have_pyarrow:\n+    import pyarrow as pa\n+\n+\n+def assert_frame_equal(left, right):\n+    \"\"\"\n+    Wrap Pandas function because pd.DataFrame.assign will infer mixed types (unicode/str)\n+    w/ Python 2, so need to set check_column_type=False\n+    \"\"\"\n+    import sys\n+    if sys.version < '3':\n+        pd_assert_frame_equal(left, right, check_column_type=False)"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Ok. Sounds good. Thanks.",
    "commit": "8dd720242d29fcd8cd2bb34c4fba663580577add",
    "createdAt": "2019-04-09T23:55:57Z",
    "diffHunk": "@@ -29,6 +29,25 @@\n     pandas_requirement_message, pyarrow_requirement_message\n from pyspark.testing.utils import QuietTest\n \n+if have_pandas:\n+    import pandas as pd\n+    from pandas.util.testing import assert_frame_equal as pd_assert_frame_equal\n+\n+if have_pyarrow:\n+    import pyarrow as pa\n+\n+\n+def assert_frame_equal(left, right):\n+    \"\"\"\n+    Wrap Pandas function because pd.DataFrame.assign will infer mixed types (unicode/str)\n+    w/ Python 2, so need to set check_column_type=False\n+    \"\"\"\n+    import sys\n+    if sys.version < '3':\n+        pd_assert_frame_equal(left, right, check_column_type=False)"
  }],
  "prId": 24306
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "This is more for my info, but what happens here if you dont' have pandas?  how can this method work?\r\nIf you do have pandas elsewhere, do the other imports shadow this definition?",
    "commit": "8dd720242d29fcd8cd2bb34c4fba663580577add",
    "createdAt": "2019-04-09T14:23:22Z",
    "diffHunk": "@@ -29,6 +29,25 @@\n     pandas_requirement_message, pyarrow_requirement_message\n from pyspark.testing.utils import QuietTest\n \n+if have_pandas:\n+    import pandas as pd\n+    from pandas.util.testing import assert_frame_equal as pd_assert_frame_equal\n+\n+if have_pyarrow:\n+    import pyarrow as pa\n+\n+\n+def assert_frame_equal(left, right):"
  }, {
    "author": {
      "login": "BryanCutler"
    },
    "body": "This would fail if you don't have pandas with an error that it doesn't know what `pd_assert_frame_equal` is, since it's only imported above, conditional on pandas being imported already. This is only seen by this file and wouldn't change anything elsewhere.\r\n\r\nI'm going to remove this though, and only define `check_column_type` here. That should make it clearer I think.",
    "commit": "8dd720242d29fcd8cd2bb34c4fba663580577add",
    "createdAt": "2019-04-09T16:53:46Z",
    "diffHunk": "@@ -29,6 +29,25 @@\n     pandas_requirement_message, pyarrow_requirement_message\n from pyspark.testing.utils import QuietTest\n \n+if have_pandas:\n+    import pandas as pd\n+    from pandas.util.testing import assert_frame_equal as pd_assert_frame_equal\n+\n+if have_pyarrow:\n+    import pyarrow as pa\n+\n+\n+def assert_frame_equal(left, right):"
  }],
  "prId": 24306
}]