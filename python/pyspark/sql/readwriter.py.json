[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Unlike the other things, there is some difference from the original semantics.\r\nAs an alternative approach, we can add the following if we need to keep the original `spark.read.load`.\r\n```python\r\nspark.conf.set(\"spark.sql.sources.default\", \"parquet\")\r\n```",
    "commit": "2975aff63a4a22ed60bded5011ee4ae8169cf987",
    "createdAt": "2018-03-01T23:46:21Z",
    "diffHunk": "@@ -147,8 +147,8 @@ def load(self, path=None, format=None, schema=None, **options):\n                        or a DDL-formatted string (For example ``col0 INT, col1 DOUBLE``).\n         :param options: all other string options\n \n-        >>> df = spark.read.load('python/test_support/sql/parquet_partitioned', opt1=True,\n-        ...     opt2=1, opt3='str')\n+        >>> df = spark.read.format(\"parquet\").load('python/test_support/sql/parquet_partitioned',\n+        ...     opt1=True, opt2=1, opt3='str')",
    "line": 7
  }],
  "prId": 20705
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "The built-in test data is `parquet`.",
    "commit": "2975aff63a4a22ed60bded5011ee4ae8169cf987",
    "createdAt": "2018-03-03T05:50:56Z",
    "diffHunk": "@@ -147,6 +147,7 @@ def load(self, path=None, format=None, schema=None, **options):\n                        or a DDL-formatted string (For example ``col0 INT, col1 DOUBLE``).\n         :param options: all other string options\n \n+        >>> spark.conf.set(\"spark.sql.sources.default\", \"parquet\")\n         >>> df = spark.read.load('python/test_support/sql/parquet_partitioned', opt1=True,"
  }],
  "prId": 20705
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Can we just call `format('parquet')` like the doctest for JSON below?",
    "commit": "2975aff63a4a22ed60bded5011ee4ae8169cf987",
    "createdAt": "2018-03-03T17:05:15Z",
    "diffHunk": "@@ -147,6 +147,7 @@ def load(self, path=None, format=None, schema=None, **options):\n                        or a DDL-formatted string (For example ``col0 INT, col1 DOUBLE``).\n         :param options: all other string options\n \n+        >>> spark.conf.set(\"spark.sql.sources.default\", \"parquet\")"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Yep. That was my first commit [here](https://github.com/apache/spark/pull/20705#discussion-diff-171729865R150). I'll rollback this.",
    "commit": "2975aff63a4a22ed60bded5011ee4ae8169cf987",
    "createdAt": "2018-03-03T18:06:02Z",
    "diffHunk": "@@ -147,6 +147,7 @@ def load(self, path=None, format=None, schema=None, **options):\n                        or a DDL-formatted string (For example ``col0 INT, col1 DOUBLE``).\n         :param options: all other string options\n \n+        >>> spark.conf.set(\"spark.sql.sources.default\", \"parquet\")"
  }],
  "prId": 20705
}]