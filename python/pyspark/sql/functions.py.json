[{
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "this would be a breaking API change I believe for python",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-08-31T05:09:20Z",
    "diffHunk": "@@ -1669,20 +1669,36 @@ def repeat(col, n):\n     return Column(sc._jvm.functions.repeat(_to_java_column(col), n))\n \n \n-@since(1.5)\n+@since(2.4)\n @ignore_unicode_prefix\n-def split(str, pattern):\n-    \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n-\n-    .. note:: pattern is a string represent the regular expression.\n-\n-    >>> df = spark.createDataFrame([('ab12cd',)], ['s',])\n-    >>> df.select(split(df.s, '[0-9]+').alias('s')).collect()\n-    [Row(s=[u'ab', u'cd'])]\n-    \"\"\"\n-    sc = SparkContext._active_spark_context\n-    return Column(sc._jvm.functions.split(_to_java_column(str), pattern))\n+def split(str, regex, limit=-1):"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Please change `regex ` back to `pattern`",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-08-31T05:16:45Z",
    "diffHunk": "@@ -1669,20 +1669,36 @@ def repeat(col, n):\n     return Column(sc._jvm.functions.repeat(_to_java_column(col), n))\n \n \n-@since(1.5)\n+@since(2.4)\n @ignore_unicode_prefix\n-def split(str, pattern):\n-    \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n-\n-    .. note:: pattern is a string represent the regular expression.\n-\n-    >>> df = spark.createDataFrame([('ab12cd',)], ['s',])\n-    >>> df.select(split(df.s, '[0-9]+').alias('s')).collect()\n-    [Row(s=[u'ab', u'cd'])]\n-    \"\"\"\n-    sc = SparkContext._active_spark_context\n-    return Column(sc._jvm.functions.split(_to_java_column(str), pattern))\n+def split(str, regex, limit=-1):"
  }, {
    "author": {
      "login": "phegstrom"
    },
    "body": "I'll change back to `pattern` here. And just curious, how is this an API break if it's an optional parameter? @felixcheung ",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-08-31T13:45:16Z",
    "diffHunk": "@@ -1669,20 +1669,36 @@ def repeat(col, n):\n     return Column(sc._jvm.functions.repeat(_to_java_column(col), n))\n \n \n-@since(1.5)\n+@since(2.4)\n @ignore_unicode_prefix\n-def split(str, pattern):\n-    \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n-\n-    .. note:: pattern is a string represent the regular expression.\n-\n-    >>> df = spark.createDataFrame([('ab12cd',)], ['s',])\n-    >>> df.select(split(df.s, '[0-9]+').alias('s')).collect()\n-    [Row(s=[u'ab', u'cd'])]\n-    \"\"\"\n-    sc = SparkContext._active_spark_context\n-    return Column(sc._jvm.functions.split(_to_java_column(str), pattern))\n+def split(str, regex, limit=-1):"
  }, {
    "author": {
      "login": "phegstrom"
    },
    "body": "@HyukjinKwon do you want `regex` -> `pattern` just here in python or every where in this PR?",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-08-31T13:46:02Z",
    "diffHunk": "@@ -1669,20 +1669,36 @@ def repeat(col, n):\n     return Column(sc._jvm.functions.repeat(_to_java_column(col), n))\n \n \n-@since(1.5)\n+@since(2.4)\n @ignore_unicode_prefix\n-def split(str, pattern):\n-    \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n-\n-    .. note:: pattern is a string represent the regular expression.\n-\n-    >>> df = spark.createDataFrame([('ab12cd',)], ['s',])\n-    >>> df.select(split(df.s, '[0-9]+').alias('s')).collect()\n-    [Row(s=[u'ab', u'cd'])]\n-    \"\"\"\n-    sc = SparkContext._active_spark_context\n-    return Column(sc._jvm.functions.split(_to_java_column(str), pattern))\n+def split(str, regex, limit=-1):"
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "yes, `regex` is the part breaking..",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-09-02T06:04:10Z",
    "diffHunk": "@@ -1669,20 +1669,36 @@ def repeat(col, n):\n     return Column(sc._jvm.functions.repeat(_to_java_column(col), n))\n \n \n-@since(1.5)\n+@since(2.4)\n @ignore_unicode_prefix\n-def split(str, pattern):\n-    \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n-\n-    .. note:: pattern is a string represent the regular expression.\n-\n-    >>> df = spark.createDataFrame([('ab12cd',)], ['s',])\n-    >>> df.select(split(df.s, '[0-9]+').alias('s')).collect()\n-    [Row(s=[u'ab', u'cd'])]\n-    \"\"\"\n-    sc = SparkContext._active_spark_context\n-    return Column(sc._jvm.functions.split(_to_java_column(str), pattern))\n+def split(str, regex, limit=-1):"
  }],
  "prId": 22227
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I wouldn't have this test since we now don't have a specific behaviour to 0.",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-09-03T01:34:47Z",
    "diffHunk": "@@ -1669,20 +1669,33 @@ def repeat(col, n):\n     return Column(sc._jvm.functions.repeat(_to_java_column(col), n))\n \n \n-@since(1.5)\n+@since(2.4)\n @ignore_unicode_prefix\n-def split(str, pattern):\n+def split(str, pattern, limit=-1):\n     \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n+    Splits str around matches of the given pattern.\n+\n+    :param str: a string expression to split\n+    :param pattern: a string representing a regular expression. The regex string should be\n+                  a Java regular expression.\n+    :param limit: an integer expression which controls the number of times the pattern is applied.\n \n-    .. note:: pattern is a string represent the regular expression.\n+            * ``limit > 0``: The resulting array's length will not be more than `limit`, and the\n+                             resulting array's last entry will contain all input beyond the last\n+                             matched pattern.\n+            * ``limit <= 0``: `pattern` will be applied as many times as possible, and the resulting\n+                              array can be of any size.\n \n-    >>> df = spark.createDataFrame([('ab12cd',)], ['s',])\n-    >>> df.select(split(df.s, '[0-9]+').alias('s')).collect()\n-    [Row(s=[u'ab', u'cd'])]\n+    >>> df = spark.createDataFrame([('oneAtwoBthreeC',)], ['s',])\n+    >>> df.select(split(df.s, '[ABC]', 2).alias('s')).collect()\n+    [Row(s=[u'one', u'twoBthreeC'])]\n+    >>> df.select(split(df.s, '[ABC]', -1).alias('s')).collect()\n+    [Row(s=[u'one', u'two', u'three', u''])]\n+    >>> df.select(split(df.s, '[ABC]', 0).alias('s')).collect()"
  }],
  "prId": 22227
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I wouldn't change `since`. You can describe the behaviour changed by, for instance:\r\n\r\n```python\r\n        .. versionchanged:: 2.4\r\n           The ``limit`` parameter blah blah..\r\n```",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-09-03T01:44:19Z",
    "diffHunk": "@@ -1669,20 +1669,33 @@ def repeat(col, n):\n     return Column(sc._jvm.functions.repeat(_to_java_column(col), n))\n \n \n-@since(1.5)\n+@since(2.4)"
  }],
  "prId": 22227
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Indentation:\r\n\r\n```diff\r\n-            * ``limit > 0``: The resulting array's length will not be more than `limit`, and the\r\n-                             resulting array's last entry will contain all input beyond the last\r\n-                             matched pattern.\r\n-            * ``limit <= 0``: `pattern` will be applied as many times as possible, and the resulting\r\n-                              array can be of any size.\r\n+        * ``limit > 0``: The resulting array's length will not be more than `limit`, and the\r\n+          resulting array's last entry will contain all input beyond the last\r\n+          matched pattern.\r\n+        * ``limit <= 0``: `pattern` will be applied as many times as possible, and the resulting\r\n+          array can be of any size.\r\n```\r\n\r\nDid you check the HTML output?",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-09-03T01:45:39Z",
    "diffHunk": "@@ -1669,20 +1669,33 @@ def repeat(col, n):\n     return Column(sc._jvm.functions.repeat(_to_java_column(col), n))\n \n \n-@since(1.5)\n+@since(2.4)\n @ignore_unicode_prefix\n-def split(str, pattern):\n+def split(str, pattern, limit=-1):\n     \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n+    Splits str around matches of the given pattern.\n+\n+    :param str: a string expression to split\n+    :param pattern: a string representing a regular expression. The regex string should be\n+                  a Java regular expression.\n+    :param limit: an integer expression which controls the number of times the pattern is applied.\n \n-    .. note:: pattern is a string represent the regular expression.\n+            * ``limit > 0``: The resulting array's length will not be more than `limit`, and the\n+                             resulting array's last entry will contain all input beyond the last\n+                             matched pattern.\n+            * ``limit <= 0``: `pattern` will be applied as many times as possible, and the resulting\n+                              array can be of any size."
  }, {
    "author": {
      "login": "phegstrom"
    },
    "body": "I did, see attached! Let me know what you think (unsure why initial description of limit starts on a new line):\r\n![screen shot 2018-09-06 at 4 18 48 pm](https://user-images.githubusercontent.com/5938022/45182990-ce86ac80-b1f0-11e8-8cae-721d9936526c.png)\r\n",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-09-06T20:21:08Z",
    "diffHunk": "@@ -1669,20 +1669,33 @@ def repeat(col, n):\n     return Column(sc._jvm.functions.repeat(_to_java_column(col), n))\n \n \n-@since(1.5)\n+@since(2.4)\n @ignore_unicode_prefix\n-def split(str, pattern):\n+def split(str, pattern, limit=-1):\n     \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n+    Splits str around matches of the given pattern.\n+\n+    :param str: a string expression to split\n+    :param pattern: a string representing a regular expression. The regex string should be\n+                  a Java regular expression.\n+    :param limit: an integer expression which controls the number of times the pattern is applied.\n \n-    .. note:: pattern is a string represent the regular expression.\n+            * ``limit > 0``: The resulting array's length will not be more than `limit`, and the\n+                             resulting array's last entry will contain all input beyond the last\n+                             matched pattern.\n+            * ``limit <= 0``: `pattern` will be applied as many times as possible, and the resulting\n+                              array can be of any size."
  }],
  "prId": 22227
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Let's target 3.0 since branch-2.4 is cut out.",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-09-10T02:33:29Z",
    "diffHunk": "@@ -1671,18 +1671,32 @@ def repeat(col, n):\n \n @since(1.5)\n @ignore_unicode_prefix\n-def split(str, pattern):\n+def split(str, pattern, limit=-1):\n     \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n+    Splits str around matches of the given pattern.\n \n-    .. note:: pattern is a string represent the regular expression.\n+    :param str: a string expression to split\n+    :param pattern: a string representing a regular expression. The regex string should be\n+                  a Java regular expression.\n+    :param limit: an integer which controls the number of times `pattern` is applied.\n \n-    >>> df = spark.createDataFrame([('ab12cd',)], ['s',])\n-    >>> df.select(split(df.s, '[0-9]+').alias('s')).collect()\n-    [Row(s=[u'ab', u'cd'])]\n+            * ``limit > 0``: The resulting array's length will not be more than `limit`, and the\n+                             resulting array's last entry will contain all input beyond the last\n+                             matched pattern.\n+            * ``limit <= 0``: `pattern` will be applied as many times as possible, and the resulting\n+                              array can be of any size.\n+\n+    .. versionchanged:: 2.4"
  }],
  "prId": 22227
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Shall we make it four-spaced.",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-09-13T23:24:06Z",
    "diffHunk": "@@ -1671,18 +1671,32 @@ def repeat(col, n):\n \n @since(1.5)\n @ignore_unicode_prefix\n-def split(str, pattern):\n+def split(str, pattern, limit=-1):\n     \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n+    Splits str around matches of the given pattern.\n \n-    .. note:: pattern is a string represent the regular expression.\n+    :param str: a string expression to split\n+    :param pattern: a string representing a regular expression. The regex string should be\n+                  a Java regular expression."
  }],
  "prId": 22227
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Let's make it 4 spaced too",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-09-13T23:25:31Z",
    "diffHunk": "@@ -1671,18 +1671,32 @@ def repeat(col, n):\n \n @since(1.5)\n @ignore_unicode_prefix\n-def split(str, pattern):\n+def split(str, pattern, limit=-1):\n     \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n+    Splits str around matches of the given pattern.\n \n-    .. note:: pattern is a string represent the regular expression.\n+    :param str: a string expression to split\n+    :param pattern: a string representing a regular expression. The regex string should be\n+                  a Java regular expression.\n+    :param limit: an integer which controls the number of times `pattern` is applied.\n \n-    >>> df = spark.createDataFrame([('ab12cd',)], ['s',])\n-    >>> df.select(split(df.s, '[0-9]+').alias('s')).collect()\n-    [Row(s=[u'ab', u'cd'])]\n+            * ``limit > 0``: The resulting array's length will not be more than `limit`, and the"
  }],
  "prId": 22227
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Let's turn into this an example without limit argument.",
    "commit": "34ba74f79aad2a0e2fe9e0d6f6110a10a51c8108",
    "createdAt": "2018-09-13T23:27:24Z",
    "diffHunk": "@@ -1671,18 +1671,32 @@ def repeat(col, n):\n \n @since(1.5)\n @ignore_unicode_prefix\n-def split(str, pattern):\n+def split(str, pattern, limit=-1):\n     \"\"\"\n-    Splits str around pattern (pattern is a regular expression).\n+    Splits str around matches of the given pattern.\n \n-    .. note:: pattern is a string represent the regular expression.\n+    :param str: a string expression to split\n+    :param pattern: a string representing a regular expression. The regex string should be\n+                  a Java regular expression.\n+    :param limit: an integer which controls the number of times `pattern` is applied.\n \n-    >>> df = spark.createDataFrame([('ab12cd',)], ['s',])\n-    >>> df.select(split(df.s, '[0-9]+').alias('s')).collect()\n-    [Row(s=[u'ab', u'cd'])]\n+            * ``limit > 0``: The resulting array's length will not be more than `limit`, and the\n+                             resulting array's last entry will contain all input beyond the last\n+                             matched pattern.\n+            * ``limit <= 0``: `pattern` will be applied as many times as possible, and the resulting\n+                              array can be of any size.\n+\n+    .. versionchanged:: 3.0\n+       `split` now takes an optional `limit` field. If not provided, default limit value is -1.\n+\n+    >>> df = spark.createDataFrame([('oneAtwoBthreeC',)], ['s',])\n+    >>> df.select(split(df.s, '[ABC]', 2).alias('s')).collect()\n+    [Row(s=[u'one', u'twoBthreeC'])]\n+    >>> df.select(split(df.s, '[ABC]', -1).alias('s')).collect()",
    "line": 31
  }],
  "prId": 22227
}]