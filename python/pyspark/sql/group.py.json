[{
  "comments": [{
    "author": {
      "login": "icexelloss"
    },
    "body": "This explains the general idea. I plan to improve the doc if people think this change is good.",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-09T21:06:44Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "It looks more reasonable to me to pass the grouping columns to UDF and let the UDF to decide if it wants to include the grouping columns or not.",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-10T02:00:18Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "+1 for ^ ",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-10T03:55:36Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "@cloud-fan That's what I thought too initially. Let's consider this use case,\r\n\r\n```\r\nimport statsmodels.api as sm\r\n# df has four columns: id, y, x1, x2\r\n\r\ngroup_column = 'id'\r\ny_column = 'y'\r\nx_columns = ['x1', 'x2']\r\nschema = df.select(group_column, *x_columns).schema\r\n\r\n@pandas_udf(schema, PandasUDFType.GROUP_MAP)\r\n# Input/output are both a pandas.DataFrame\r\ndef ols(pdf):\r\n    group_key = pdf[group_column].iloc[0]\r\n    y = pdf[y_column]\r\n    X = pdf[x_columns]\r\n      X = sm.add_constant(X)\r\n    model = sm.OLS(y, X).fit()\r\n\r\n    return pd.DataFrame([[group_key] + [model.params[i] for i in   x_columns]], columns=[group_column] + x_columns)\r\n\r\nbeta = df.groupby(group_column).apply(ols)\r\n```\r\nThis is a simple pandas UDF that does a linear regression. The issue is, although the UDF (linear regression) has nothing to do with the grouping column, the user needs to deal with grouping column in the UDF. In other words, the UDF is coupled with the grouping column.\r\n\r\nIf we make it such that grouping columns are prepend to UDF result, then the user can write something like this:\r\n\r\n```\r\nimport statsmodels.api as sm\r\n# df has four columns: id, y, x1, x2\r\n\r\ngroup_column = 'id'\r\ny_column = 'y'\r\nx_columns = ['x1', 'x2']\r\nschema = df.select(*x_columns).schema\r\n\r\n@pandas_udf(schema, PandasUDFType.GROUP_MAP)\r\n# Input/output are both a pandas.DataFrame\r\ndef ols(pdf):\r\n    y = pdf[y_column]\r\n    X = pdf[x_columns]\r\n      X = sm.add_constant(X)\r\n    model = sm.OLS(y, X).fit()\r\n\r\n    return pd.DataFrame([[model.params[i] for i in   x_columns]], columns=x_columns)\r\n\r\nbeta = df.groupby(group_column).apply(ols)\r\n```\r\n\r\nNow the UDF is cleaner because it only deals with columns that are relevant to the regression. It also make the UDF more reusable, as the user can now do something like:\r\n\r\n```\r\nbeta1 = df.groupby('a').apply(ols)\r\nbeta2 = df.groupby('a', 'b').apply(ols)\r\n```\r\nBecause the UDF is now decoupled with the grouping column, the user can reuse the same udf with different grouping, which is not possible with the current API.\r\n\r\n@cloud-fan @HyukjinKwon What do you think?",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-10T23:17:43Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Yup, I saw this usecase as described in the JIRA and I got that the specific case can be simplified; however, I am not sure if it's straightforward to the end users.\r\n\r\nFor example, if I use `pandas_udf` I think I would simply expect the return schema is matched as described in `returnType`. I think `pandas_udf` already need some background and I think we should make it simpler as possible as we can.\r\n\r\nIt might be convenient to make the guarantee on grouping columns in some cases vs this might be a kind of magic inside.\r\n\r\nI would prefer to let the UDF to specify the grouping columns to make this more straightforward more .. ",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-11T03:58:39Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Yeah. To be honest I don't think there is behavior that is both simple and works well with all use cases. It's probably a matter of leaning towards simpler behavior that doesn't work well in some cases or towards somewhat \"magic\" behavior. I don't think there is an obvious answer here.\r\n\r\nAnother option is to always prepend grouping columns, if users want to return grouping columns in the UDF output, they can do a `drop` after `groupby apply` \r\n\r\n```\r\npandas_udf('id int, v double', GROUP_MAP)\r\ndef foo(pdf):\r\n      return pdf.assign(v=pdf.v+1)\r\n\r\ndf.groupby('id').apply(foo).drop(df.id)\r\n```\r\n\r\nI don't think it's too annoying to add a drop after apply and it works well with the linear regression case. This is also a pretty straight forward non magical behavior. I like this a bit better because the UDF can still stay decoupled with the grouping column, and the caller decides whether he wants prepended grouping columns or not.\r\n\r\nWhat do you all think?\r\n",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-11T04:42:58Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "From a SQL background, I think we should add grouping keys to the input of UDF. Sometimes users do need to read the grouping keys when aggregating, and we should give users a way to do it. BTW this is also consistent with Dataset, see `KeyValueGroupedDataset.mapGroups`.",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-11T10:41:53Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "@cloud-fan Good point. I did some more research on `KeyValueGroupedDataset. flatMapGroups ` and also `gapply` in SparkR. These two seem to have consistent behavior:\r\n\r\n* Grouping key is passed as the first arg to the udf, the second arg is the actual data\r\n* No grouping key is prepend to the result, i.e., the output of the udf is the schema of the result Spark DataFrame.\r\n\r\nI think this could be a good option for `groupby apply` too for the following reason:\r\n* Consistent with similar API in Spark, i.e., `flatMapGroups` and `gapply`\r\n* Is flexible enough to implement the two use cases above:\r\n```\r\ndf = ... # id int, v double\r\npandas_udf('id int, v double', GROUP_MAP)\r\ndef foo(key, pdf):\r\n      # key is not used\r\n      return pdf.assign(v=pdf.v+1)\r\n\r\ndf.groupby('id').apply(foo)\r\n```\r\nand\r\n```\r\nimport statsmodels.api as sm\r\n# df has four columns: id, y, x1, x2\r\n\r\ngroup_column = 'id'\r\ny_column = 'y'\r\nx_columns = ['x1', 'x2']\r\nschema = df.select(group_column, *x_columns).schema\r\n\r\n@pandas_udf(schema, PandasUDFType.GROUP_MAP)\r\n# Input/output are both a pandas.DataFrame\r\ndef ols(key, pdf):\r\n    y = pdf[y_column]\r\n    X = pdf[x_columns]\r\n    X = sm.add_constant(X)\r\n    model = sm.OLS(y, X).fit()\r\n\r\n    return pd.DataFrame([key + [model.params[i] for i in x_columns]])\r\n\r\nbeta = df.groupby(group_column).apply(ols)\r\n```\r\nIn the second example here, output schema for the udf is still coupled with grouping key, but the function itself is decoupled.\r\n\r\nThe downside is it's now different from the pandas groupby apply API (the pandas one only takes one argument), but we cannot be consistent with everything...\r\n\r\nThoughts?",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-11T21:50:32Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "One thing is that I am a little confused by the doc of `gapply` here:\r\n\r\nhttps://github.com/apache/spark/blob/master/R/pkg/R/DataFrame.R#L1626\r\n\r\nIn the output, there is a \"Model\" column:\r\nhttps://github.com/apache/spark/blob/master/R/pkg/R/DataFrame.R#L1646\r\n\r\nbut it's not specified in the schema:\r\nhttps://github.com/apache/spark/blob/master/R/pkg/R/DataFrame.R#L1631\r\n\r\nLooks like it might be a mistake in the doc from the description of the function, but I am not sure.",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-11T21:54:16Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "@felixcheung, WDYT?\r\n\r\nTo cut the context short, it's a Pandas map group API like `gapply` (not Pandas scalar udf).\r\n\r\nIts current implementation is as follows\r\n\r\n```python\r\ndef foo(pdf):\r\n    pdf  # this is the Pandas DataFrame\r\n\r\npudf = pandas_udf(f=foo, returnType=\"id int, v double\", functionType=GROUP_MAP)\r\ndf.groupby(group_column).apply(pudf)\r\n```\r\n\r\n`returnType`, `'id int, v double'` describes the output schema and input `pdf` is the Pandas's DataFrame associated with the group.\r\n\r\nAs @icexelloss described above as a new proposal, looking at `gapply` in R at a glance again, seems making sense that we do:\r\n\r\n```python\r\ndef foo(key, pdf):\r\n    key  # this is a grouping key. \r\n    pdf  # this is the Pandas DataFrame\r\n\r\npudf = pandas_udf(f=foo, returnType=\"id int, v double\", functionType=GROUP_MAP)\r\ndf.groupby(group_column).apply(pudf)\r\n```\r\n",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-12T01:16:53Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "sounds to me like we could either stick with func(key, pdf) or whatever pandas does.\r\n\r\n(yes, for gapply, the returned data frame is expected to have key columns prepended; there was one SPARK-16258 proposing to eliminate that extra work)",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-13T07:48:36Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Up to my knowledge, the current implementation follows Pandas's default groupBy - apply when Pandas DataFrame -> Pandas DataFrame (correct me if I am wrong). So,(partly by this reason) I was thinking that we shouldn't start with prepending the grouping columns but we could alternatively consider an idea of `gapply` in somehow ..\r\n\r\nI think it's still feasible to have both ideas - If the given function takes single argument, we can give the input as pdf. If it takes two arguments, we can give key and pdf as input. I think we can support the `gapply`-like support optionally.\r\n\r\nIt's a rough idea but I think we can do this in theory as we know and can `inspect` the function ahead before computation.\r\n\r\nWDYT guys?",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-13T12:57:41Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "SGTM, one thing is how to define the type of `key`, a row?",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-15T08:34:11Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Sorry for the late reply. I agree with @HyukjinKwon, I think we can do support both `foo(pdf)` and `foo(key, pdf)` through inspection.\r\n\r\nI will try to put up a PR soon.\r\n\r\nAs to how to represent key, I think a tuple might be enough but I think a row also works. What do you guys think?",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-16T04:34:32Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "It's interesting to see the discussion in `SPARK-16258`. I think this is quite hard for the API to meet all cases...But the `foo(key, pdf)` is the best so far I think.",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-16T04:38:36Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "tuple sounds good, let's go with that.",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-16T08:41:47Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "@HyukjinKwon's proposal sounds good to me too.",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-16T09:13:52Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "ueshin"
    },
    "body": "I'd like to confirm what the result schema will be like finally.\r\nIf users want to include the keys, the udf should include the keys in its output and the keys will not be prepended automatically?",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-16T10:32:36Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "yup",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-16T14:03:42Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "ueshin"
    },
    "body": "I see, sounds good. Thanks!",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-16T14:07:49Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }, {
    "author": {
      "login": "icexelloss"
    },
    "body": "Thanks all for the discussion. I will update the Jira and open a new PR.",
    "commit": "46dc9e18f36dc14915e87ba206dd0614d0618dad",
    "createdAt": "2018-01-16T14:53:21Z",
    "diffHunk": "@@ -233,6 +233,27 @@ def apply(self, udf):\n         |  2| 1.1094003924504583|\n         +---+-------------------+\n \n+        Notes on grouping column:",
    "line": 4
  }],
  "prId": 20211
}]