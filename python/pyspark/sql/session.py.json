[{
  "comments": [{
    "author": {
      "login": "nchammas"
    },
    "body": "Technically not your change @andrewor14 (I see you just moved this line), but it's `samplingRatio` everywhere else in the code. See: [samplingRatio](https://github.com/apache/spark/search?utf8=%E2%9C%93&q=samplingratio&type=Code) vs. [sampleRatio](https://github.com/apache/spark/search?utf8=%E2%9C%93&q=sampleratio&type=Code)\n\nShould I open a PR to fix this?\n",
    "commit": "e61aa8a10c5cca0615dea5544f0060781c385f89",
    "createdAt": "2016-05-10T16:27:11Z",
    "diffHunk": "@@ -0,0 +1,525 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+import sys\n+import warnings\n+from functools import reduce\n+\n+if sys.version >= '3':\n+    basestring = unicode = str\n+else:\n+    from itertools import imap as map\n+\n+from pyspark import since\n+from pyspark.rdd import RDD, ignore_unicode_prefix\n+from pyspark.sql.dataframe import DataFrame\n+from pyspark.sql.functions import UserDefinedFunction\n+from pyspark.sql.readwriter import DataFrameReader\n+from pyspark.sql.types import Row, DataType, StringType, StructType, _verify_type, \\\n+    _infer_schema, _has_nulltype, _merge_type, _create_converter, _parse_datatype_string\n+from pyspark.sql.utils import install_exception_handler\n+\n+__all__ = [\"SparkSession\"]\n+\n+\n+def _monkey_patch_RDD(sparkSession):\n+    def toDF(self, schema=None, sampleRatio=None):",
    "line": 41
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "Please do.\n",
    "commit": "e61aa8a10c5cca0615dea5544f0060781c385f89",
    "createdAt": "2016-05-10T16:48:35Z",
    "diffHunk": "@@ -0,0 +1,525 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+import sys\n+import warnings\n+from functools import reduce\n+\n+if sys.version >= '3':\n+    basestring = unicode = str\n+else:\n+    from itertools import imap as map\n+\n+from pyspark import since\n+from pyspark.rdd import RDD, ignore_unicode_prefix\n+from pyspark.sql.dataframe import DataFrame\n+from pyspark.sql.functions import UserDefinedFunction\n+from pyspark.sql.readwriter import DataFrameReader\n+from pyspark.sql.types import Row, DataType, StringType, StructType, _verify_type, \\\n+    _infer_schema, _has_nulltype, _merge_type, _create_converter, _parse_datatype_string\n+from pyspark.sql.utils import install_exception_handler\n+\n+__all__ = [\"SparkSession\"]\n+\n+\n+def _monkey_patch_RDD(sparkSession):\n+    def toDF(self, schema=None, sampleRatio=None):",
    "line": 41
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "ah it would break APIs - maybe it's not worth it at this point.\n",
    "commit": "e61aa8a10c5cca0615dea5544f0060781c385f89",
    "createdAt": "2016-05-10T16:49:04Z",
    "diffHunk": "@@ -0,0 +1,525 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+import sys\n+import warnings\n+from functools import reduce\n+\n+if sys.version >= '3':\n+    basestring = unicode = str\n+else:\n+    from itertools import imap as map\n+\n+from pyspark import since\n+from pyspark.rdd import RDD, ignore_unicode_prefix\n+from pyspark.sql.dataframe import DataFrame\n+from pyspark.sql.functions import UserDefinedFunction\n+from pyspark.sql.readwriter import DataFrameReader\n+from pyspark.sql.types import Row, DataType, StringType, StructType, _verify_type, \\\n+    _infer_schema, _has_nulltype, _merge_type, _create_converter, _parse_datatype_string\n+from pyspark.sql.utils import install_exception_handler\n+\n+__all__ = [\"SparkSession\"]\n+\n+\n+def _monkey_patch_RDD(sparkSession):\n+    def toDF(self, schema=None, sampleRatio=None):",
    "line": 41
  }, {
    "author": {
      "login": "nchammas"
    },
    "body": "Oh, it looks like a \"non-public\" method (which is implied in Python by the leading underscore in `_monkey_patch_RDD`) so I thought it would be OK to change.\n\nAre you sure this counts as an API break? I did a search for `_monkey_patch_RDD` and, unless users are meant to use this directly, it looks like an internal-only method.\n",
    "commit": "e61aa8a10c5cca0615dea5544f0060781c385f89",
    "createdAt": "2016-05-10T16:57:01Z",
    "diffHunk": "@@ -0,0 +1,525 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+import sys\n+import warnings\n+from functools import reduce\n+\n+if sys.version >= '3':\n+    basestring = unicode = str\n+else:\n+    from itertools import imap as map\n+\n+from pyspark import since\n+from pyspark.rdd import RDD, ignore_unicode_prefix\n+from pyspark.sql.dataframe import DataFrame\n+from pyspark.sql.functions import UserDefinedFunction\n+from pyspark.sql.readwriter import DataFrameReader\n+from pyspark.sql.types import Row, DataType, StringType, StructType, _verify_type, \\\n+    _infer_schema, _has_nulltype, _merge_type, _create_converter, _parse_datatype_string\n+from pyspark.sql.utils import install_exception_handler\n+\n+__all__ = [\"SparkSession\"]\n+\n+\n+def _monkey_patch_RDD(sparkSession):\n+    def toDF(self, schema=None, sampleRatio=None):",
    "line": 41
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "monkey patch is not public, but the method being added via monkey patch becomes public (rdd.toDF)\n",
    "commit": "e61aa8a10c5cca0615dea5544f0060781c385f89",
    "createdAt": "2016-05-10T16:58:49Z",
    "diffHunk": "@@ -0,0 +1,525 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+import sys\n+import warnings\n+from functools import reduce\n+\n+if sys.version >= '3':\n+    basestring = unicode = str\n+else:\n+    from itertools import imap as map\n+\n+from pyspark import since\n+from pyspark.rdd import RDD, ignore_unicode_prefix\n+from pyspark.sql.dataframe import DataFrame\n+from pyspark.sql.functions import UserDefinedFunction\n+from pyspark.sql.readwriter import DataFrameReader\n+from pyspark.sql.types import Row, DataType, StringType, StructType, _verify_type, \\\n+    _infer_schema, _has_nulltype, _merge_type, _create_converter, _parse_datatype_string\n+from pyspark.sql.utils import install_exception_handler\n+\n+__all__ = [\"SparkSession\"]\n+\n+\n+def _monkey_patch_RDD(sparkSession):\n+    def toDF(self, schema=None, sampleRatio=None):",
    "line": 41
  }, {
    "author": {
      "login": "nchammas"
    },
    "body": "Either way I guess this is not a big deal really.\n",
    "commit": "e61aa8a10c5cca0615dea5544f0060781c385f89",
    "createdAt": "2016-05-10T16:59:21Z",
    "diffHunk": "@@ -0,0 +1,525 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+import sys\n+import warnings\n+from functools import reduce\n+\n+if sys.version >= '3':\n+    basestring = unicode = str\n+else:\n+    from itertools import imap as map\n+\n+from pyspark import since\n+from pyspark.rdd import RDD, ignore_unicode_prefix\n+from pyspark.sql.dataframe import DataFrame\n+from pyspark.sql.functions import UserDefinedFunction\n+from pyspark.sql.readwriter import DataFrameReader\n+from pyspark.sql.types import Row, DataType, StringType, StructType, _verify_type, \\\n+    _infer_schema, _has_nulltype, _merge_type, _create_converter, _parse_datatype_string\n+from pyspark.sql.utils import install_exception_handler\n+\n+__all__ = [\"SparkSession\"]\n+\n+\n+def _monkey_patch_RDD(sparkSession):\n+    def toDF(self, schema=None, sampleRatio=None):",
    "line": 41
  }, {
    "author": {
      "login": "nchammas"
    },
    "body": "Ahhhhh... OK I get it now.\n",
    "commit": "e61aa8a10c5cca0615dea5544f0060781c385f89",
    "createdAt": "2016-05-10T17:01:35Z",
    "diffHunk": "@@ -0,0 +1,525 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+import sys\n+import warnings\n+from functools import reduce\n+\n+if sys.version >= '3':\n+    basestring = unicode = str\n+else:\n+    from itertools import imap as map\n+\n+from pyspark import since\n+from pyspark.rdd import RDD, ignore_unicode_prefix\n+from pyspark.sql.dataframe import DataFrame\n+from pyspark.sql.functions import UserDefinedFunction\n+from pyspark.sql.readwriter import DataFrameReader\n+from pyspark.sql.types import Row, DataType, StringType, StructType, _verify_type, \\\n+    _infer_schema, _has_nulltype, _merge_type, _create_converter, _parse_datatype_string\n+from pyspark.sql.utils import install_exception_handler\n+\n+__all__ = [\"SparkSession\"]\n+\n+\n+def _monkey_patch_RDD(sparkSession):\n+    def toDF(self, schema=None, sampleRatio=None):",
    "line": 41
  }],
  "prId": 12746
}]