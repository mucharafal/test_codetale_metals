[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`copyto` needs numpy 1.7.\n",
    "commit": "d52e76305a4858d4d516141065e50d997e829c27",
    "createdAt": "2014-04-14T03:08:22Z",
    "diffHunk": "@@ -55,159 +103,222 @@ def _serialize_double_vector(v):\n     >>> array_equal(y, array([1.0, 2.0, 3.0]))\n     True\n     \"\"\"\n-    if type(v) != ndarray:\n-        raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    \"\"\"complex is only datatype that can't be converted to float64\"\"\"\n-    if issubdtype(v.dtype, complex):\n+    v = _convert_vector(v)\n+    if type(v) == ndarray:\n+        return _serialize_dense_vector(v)\n+    elif type(v) == SparseVector:\n+        return _serialize_sparse_vector(v)\n+    else:\n         raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    if v.dtype != float64:\n-        v = v.astype(float64)\n+                \"wanted ndarray or SparseVector\" % type(v))\n+\n+\n+def _serialize_dense_vector(v):\n+    \"\"\"Serialize a dense vector given as a NumPy array.\"\"\"\n     if v.ndim != 1:\n         raise TypeError(\"_serialize_double_vector called on a %ddarray; \"\n                 \"wanted a 1darray\" % v.ndim)\n+    if v.dtype != float64:\n+        if numpy.issubdtype(v.dtype, numpy.complex):\n+            raise TypeError(\"_serialize_double_vector called on an ndarray of %s; \"\n+                    \"wanted ndarray of float64\" % v.dtype)\n+        v = v.astype(float64)\n     length = v.shape[0]\n-    ba = bytearray(16 + 8*length)\n-    header = ndarray(shape=[2], buffer=ba, dtype=\"int64\")\n-    header[0] = 1\n-    header[1] = length\n-    copyto(ndarray(shape=[length], buffer=ba, offset=16,\n-            dtype=\"float64\"), v)\n+    ba = bytearray(5 + 8 * length)\n+    ba[0] = DENSE_VECTOR_MAGIC\n+    length_bytes = ndarray(shape=[1], buffer=ba, offset=1, dtype=int32)\n+    length_bytes[0] = length\n+    copyto(ndarray(shape=[length], buffer=ba, offset=5, dtype=float64), v)"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "We should implement `copyto` in `_common.py`.\n",
    "commit": "d52e76305a4858d4d516141065e50d997e829c27",
    "createdAt": "2014-04-14T03:08:56Z",
    "diffHunk": "@@ -55,159 +103,222 @@ def _serialize_double_vector(v):\n     >>> array_equal(y, array([1.0, 2.0, 3.0]))\n     True\n     \"\"\"\n-    if type(v) != ndarray:\n-        raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    \"\"\"complex is only datatype that can't be converted to float64\"\"\"\n-    if issubdtype(v.dtype, complex):\n+    v = _convert_vector(v)\n+    if type(v) == ndarray:\n+        return _serialize_dense_vector(v)\n+    elif type(v) == SparseVector:\n+        return _serialize_sparse_vector(v)\n+    else:\n         raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    if v.dtype != float64:\n-        v = v.astype(float64)\n+                \"wanted ndarray or SparseVector\" % type(v))\n+\n+\n+def _serialize_dense_vector(v):\n+    \"\"\"Serialize a dense vector given as a NumPy array.\"\"\"\n     if v.ndim != 1:\n         raise TypeError(\"_serialize_double_vector called on a %ddarray; \"\n                 \"wanted a 1darray\" % v.ndim)\n+    if v.dtype != float64:\n+        if numpy.issubdtype(v.dtype, numpy.complex):\n+            raise TypeError(\"_serialize_double_vector called on an ndarray of %s; \"\n+                    \"wanted ndarray of float64\" % v.dtype)\n+        v = v.astype(float64)\n     length = v.shape[0]\n-    ba = bytearray(16 + 8*length)\n-    header = ndarray(shape=[2], buffer=ba, dtype=\"int64\")\n-    header[0] = 1\n-    header[1] = length\n-    copyto(ndarray(shape=[length], buffer=ba, offset=16,\n-            dtype=\"float64\"), v)\n+    ba = bytearray(5 + 8 * length)\n+    ba[0] = DENSE_VECTOR_MAGIC\n+    length_bytes = ndarray(shape=[1], buffer=ba, offset=1, dtype=int32)\n+    length_bytes[0] = length\n+    copyto(ndarray(shape=[length], buffer=ba, offset=5, dtype=float64), v)"
  }],
  "prId": 341
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "ditto.\n",
    "commit": "d52e76305a4858d4d516141065e50d997e829c27",
    "createdAt": "2014-04-14T03:08:31Z",
    "diffHunk": "@@ -55,159 +103,222 @@ def _serialize_double_vector(v):\n     >>> array_equal(y, array([1.0, 2.0, 3.0]))\n     True\n     \"\"\"\n-    if type(v) != ndarray:\n-        raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    \"\"\"complex is only datatype that can't be converted to float64\"\"\"\n-    if issubdtype(v.dtype, complex):\n+    v = _convert_vector(v)\n+    if type(v) == ndarray:\n+        return _serialize_dense_vector(v)\n+    elif type(v) == SparseVector:\n+        return _serialize_sparse_vector(v)\n+    else:\n         raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    if v.dtype != float64:\n-        v = v.astype(float64)\n+                \"wanted ndarray or SparseVector\" % type(v))\n+\n+\n+def _serialize_dense_vector(v):\n+    \"\"\"Serialize a dense vector given as a NumPy array.\"\"\"\n     if v.ndim != 1:\n         raise TypeError(\"_serialize_double_vector called on a %ddarray; \"\n                 \"wanted a 1darray\" % v.ndim)\n+    if v.dtype != float64:\n+        if numpy.issubdtype(v.dtype, numpy.complex):\n+            raise TypeError(\"_serialize_double_vector called on an ndarray of %s; \"\n+                    \"wanted ndarray of float64\" % v.dtype)\n+        v = v.astype(float64)\n     length = v.shape[0]\n-    ba = bytearray(16 + 8*length)\n-    header = ndarray(shape=[2], buffer=ba, dtype=\"int64\")\n-    header[0] = 1\n-    header[1] = length\n-    copyto(ndarray(shape=[length], buffer=ba, offset=16,\n-            dtype=\"float64\"), v)\n+    ba = bytearray(5 + 8 * length)\n+    ba[0] = DENSE_VECTOR_MAGIC\n+    length_bytes = ndarray(shape=[1], buffer=ba, offset=1, dtype=int32)\n+    length_bytes[0] = length\n+    copyto(ndarray(shape=[length], buffer=ba, offset=5, dtype=float64), v)\n+    return ba\n+\n+\n+def _serialize_sparse_vector(v):\n+    \"\"\"Serialize a pyspark.mllib.linalg.SparseVector.\"\"\"\n+    nonzeros = len(v.indices)\n+    ba = bytearray(9 + 12 * nonzeros)\n+    ba[0] = SPARSE_VECTOR_MAGIC\n+    header = ndarray(shape=[2], buffer=ba, offset=1, dtype=int32)\n+    header[0] = v.size\n+    header[1] = nonzeros\n+    copyto(ndarray(shape=[nonzeros], buffer=ba, offset=9, dtype=int32), v.indices)\n+    values_offset = 9 + 4 * nonzeros\n+    copyto(ndarray(shape=[nonzeros], buffer=ba, offset=values_offset, dtype=float64), v.values)"
  }],
  "prId": 341
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "remove debug code?\n",
    "commit": "d52e76305a4858d4d516141065e50d997e829c27",
    "createdAt": "2014-04-14T03:10:50Z",
    "diffHunk": "@@ -55,159 +103,222 @@ def _serialize_double_vector(v):\n     >>> array_equal(y, array([1.0, 2.0, 3.0]))\n     True\n     \"\"\"\n-    if type(v) != ndarray:\n-        raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    \"\"\"complex is only datatype that can't be converted to float64\"\"\"\n-    if issubdtype(v.dtype, complex):\n+    v = _convert_vector(v)\n+    if type(v) == ndarray:\n+        return _serialize_dense_vector(v)\n+    elif type(v) == SparseVector:\n+        return _serialize_sparse_vector(v)\n+    else:\n         raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    if v.dtype != float64:\n-        v = v.astype(float64)\n+                \"wanted ndarray or SparseVector\" % type(v))\n+\n+\n+def _serialize_dense_vector(v):\n+    \"\"\"Serialize a dense vector given as a NumPy array.\"\"\"\n     if v.ndim != 1:\n         raise TypeError(\"_serialize_double_vector called on a %ddarray; \"\n                 \"wanted a 1darray\" % v.ndim)\n+    if v.dtype != float64:\n+        if numpy.issubdtype(v.dtype, numpy.complex):\n+            raise TypeError(\"_serialize_double_vector called on an ndarray of %s; \"\n+                    \"wanted ndarray of float64\" % v.dtype)\n+        v = v.astype(float64)\n     length = v.shape[0]\n-    ba = bytearray(16 + 8*length)\n-    header = ndarray(shape=[2], buffer=ba, dtype=\"int64\")\n-    header[0] = 1\n-    header[1] = length\n-    copyto(ndarray(shape=[length], buffer=ba, offset=16,\n-            dtype=\"float64\"), v)\n+    ba = bytearray(5 + 8 * length)\n+    ba[0] = DENSE_VECTOR_MAGIC\n+    length_bytes = ndarray(shape=[1], buffer=ba, offset=1, dtype=int32)\n+    length_bytes[0] = length\n+    copyto(ndarray(shape=[length], buffer=ba, offset=5, dtype=float64), v)\n+    return ba\n+\n+\n+def _serialize_sparse_vector(v):\n+    \"\"\"Serialize a pyspark.mllib.linalg.SparseVector.\"\"\"\n+    nonzeros = len(v.indices)\n+    ba = bytearray(9 + 12 * nonzeros)\n+    ba[0] = SPARSE_VECTOR_MAGIC\n+    header = ndarray(shape=[2], buffer=ba, offset=1, dtype=int32)\n+    header[0] = v.size\n+    header[1] = nonzeros\n+    copyto(ndarray(shape=[nonzeros], buffer=ba, offset=9, dtype=int32), v.indices)\n+    values_offset = 9 + 4 * nonzeros\n+    copyto(ndarray(shape=[nonzeros], buffer=ba, offset=values_offset, dtype=float64), v.values)\n     return ba\n \n+\n def _deserialize_double_vector(ba):\n     \"\"\"Deserialize a double vector from a mutually understood format.\n \n     >>> x = array([1.0, 2.0, 3.0, 4.0, -1.0, 0.0, -0.0])\n     >>> array_equal(x, _deserialize_double_vector(_serialize_double_vector(x)))\n     True\n+    >>> s = SparseVector(4, [1, 3], [3.0, 5.5])\n+    >>> s == _deserialize_double_vector(_serialize_double_vector(s))\n+    True\n     \"\"\"\n     if type(ba) != bytearray:\n         raise TypeError(\"_deserialize_double_vector called on a %s; \"\n                 \"wanted bytearray\" % type(ba))\n-    if len(ba) < 16:\n+    if len(ba) < 5:\n         raise TypeError(\"_deserialize_double_vector called on a %d-byte array, \"\n                 \"which is too short\" % len(ba))\n-    if (len(ba) & 7) != 0:\n-        raise TypeError(\"_deserialize_double_vector called on a %d-byte array, \"\n-                \"which is not a multiple of 8\" % len(ba))\n-    header = ndarray(shape=[2], buffer=ba, dtype=\"int64\")\n-    if header[0] != 1:\n+    if ba[0] == DENSE_VECTOR_MAGIC:\n+        return _deserialize_dense_vector(ba)\n+    elif ba[0] == SPARSE_VECTOR_MAGIC:\n+        return _deserialize_sparse_vector(ba)\n+    else:\n         raise TypeError(\"_deserialize_double_vector called on bytearray \"\n                         \"with wrong magic\")\n-    length = header[1]\n-    if len(ba) != 8*length + 16:\n-        raise TypeError(\"_deserialize_double_vector called on bytearray \"\n+\n+\n+def _deserialize_dense_vector(ba):\n+    \"\"\"Deserialize a dense vector into a numpy array.\"\"\"\n+    if len(ba) < 5:\n+        raise TypeError(\"_deserialize_dense_vector called on a %d-byte array, \"\n+                \"which is too short\" % len(ba))\n+    length = ndarray(shape=[1], buffer=ba, offset=1, dtype=int32)[0]\n+    if len(ba) != 8 * length + 5:\n+        raise TypeError(\"_deserialize_dense_vector called on bytearray \"\n+                        \"with wrong length\")\n+    return _deserialize_numpy_array([length], ba, 5)\n+\n+\n+def _deserialize_sparse_vector(ba):\n+    \"\"\"Deserialize a sparse vector into a MLlib SparseVector object.\"\"\"\n+    if len(ba) < 9:\n+        raise TypeError(\"_deserialize_sparse_vector called on a %d-byte array, \"\n+                \"which is too short\" % len(ba))\n+    header = ndarray(shape=[2], buffer=ba, offset=1, dtype=int32)\n+    size = header[0]\n+    nonzeros = header[1]\n+    if len(ba) != 9 + 12 * nonzeros:\n+        raise TypeError(\"_deserialize_sparse_vector called on bytearray \"\n                         \"with wrong length\")\n-    return _deserialize_byte_array([length], ba, 16)\n+    indices = _deserialize_numpy_array([nonzeros], ba, 9, dtype=int32)\n+    values = _deserialize_numpy_array([nonzeros], ba, 9 + 4 * nonzeros, dtype=float64)\n+    return SparseVector(int(size), indices, values)\n+\n \n def _serialize_double_matrix(m):\n     \"\"\"Serialize a double matrix into a mutually understood format.\"\"\"\n-    if (type(m) == ndarray and m.dtype == float64 and m.ndim == 2):\n+    if (type(m) == ndarray and m.ndim == 2):\n+        if m.dtype != float64:\n+            if numpy.issubdtype(m.dtype, numpy.complex):\n+                raise TypeError(\"_serialize_double_matrix called on an ndarray of %s; \"\n+                        \"wanted ndarray of float64\" % m.dtype)\n+            m = m.astype(float64)\n         rows = m.shape[0]\n         cols = m.shape[1]\n-        ba = bytearray(24 + 8 * rows * cols)\n-        header = ndarray(shape=[3], buffer=ba, dtype=\"int64\")\n-        header[0] = 2\n-        header[1] = rows\n-        header[2] = cols\n-        copyto(ndarray(shape=[rows, cols], buffer=ba, offset=24,\n-                       dtype=\"float64\", order='C'), m)\n+        ba = bytearray(9 + 8 * rows * cols)\n+        ba[0] = DENSE_MATRIX_MAGIC\n+        lengths = ndarray(shape=[3], buffer=ba, offset=1, dtype=int32)\n+        lengths[0] = rows\n+        lengths[1] = cols\n+        copyto(ndarray(shape=[rows, cols], buffer=ba, offset=9,\n+                       dtype=float64, order='C'), m)\n         return ba\n     else:\n         raise TypeError(\"_serialize_double_matrix called on a \"\n                         \"non-double-matrix\")\n \n+\n def _deserialize_double_matrix(ba):\n     \"\"\"Deserialize a double matrix from a mutually understood format.\"\"\"\n     if type(ba) != bytearray:\n         raise TypeError(\"_deserialize_double_matrix called on a %s; \"\n                 \"wanted bytearray\" % type(ba))\n-    if len(ba) < 24:\n+    if len(ba) < 9:\n         raise TypeError(\"_deserialize_double_matrix called on a %d-byte array, \"\n                 \"which is too short\" % len(ba))\n-    if (len(ba) & 7) != 0:\n-        raise TypeError(\"_deserialize_double_matrix called on a %d-byte array, \"\n-                \"which is not a multiple of 8\" % len(ba))\n-    header = ndarray(shape=[3], buffer=ba, dtype=\"int64\")\n-    if (header[0] != 2):\n+    if ba[0] != DENSE_MATRIX_MAGIC:\n         raise TypeError(\"_deserialize_double_matrix called on bytearray \"\n                         \"with wrong magic\")\n-    rows = header[1]\n-    cols = header[2]\n-    if (len(ba) != 8*rows*cols + 24):\n+    lengths = ndarray(shape=[2], buffer=ba, offset=1, dtype=int32)\n+    rows = lengths[0]\n+    cols = lengths[1]\n+    if (len(ba) != 8 * rows * cols + 9):\n         raise TypeError(\"_deserialize_double_matrix called on bytearray \"\n                         \"with wrong length\")\n-    return _deserialize_byte_array([rows, cols], ba, 24)\n+    return _deserialize_numpy_array([rows, cols], ba, 9)\n+\n+\n+def _serialize_labeled_point(p):\n+    \"\"\"Serialize a LabeledPoint with a features vector of any type.\"\"\"\n+    #from pyspark.mllib.regression import LabeledPoint\n+    #assert type(p) == LabeledPoint, \"Expected a LabeledPoint object\""
  }],
  "prId": 341
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Should use zeros instead of ones.\n",
    "commit": "d52e76305a4858d4d516141065e50d997e829c27",
    "createdAt": "2014-04-14T03:15:43Z",
    "diffHunk": "@@ -55,159 +103,222 @@ def _serialize_double_vector(v):\n     >>> array_equal(y, array([1.0, 2.0, 3.0]))\n     True\n     \"\"\"\n-    if type(v) != ndarray:\n-        raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    \"\"\"complex is only datatype that can't be converted to float64\"\"\"\n-    if issubdtype(v.dtype, complex):\n+    v = _convert_vector(v)\n+    if type(v) == ndarray:\n+        return _serialize_dense_vector(v)\n+    elif type(v) == SparseVector:\n+        return _serialize_sparse_vector(v)\n+    else:\n         raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    if v.dtype != float64:\n-        v = v.astype(float64)\n+                \"wanted ndarray or SparseVector\" % type(v))\n+\n+\n+def _serialize_dense_vector(v):\n+    \"\"\"Serialize a dense vector given as a NumPy array.\"\"\"\n     if v.ndim != 1:\n         raise TypeError(\"_serialize_double_vector called on a %ddarray; \"\n                 \"wanted a 1darray\" % v.ndim)\n+    if v.dtype != float64:\n+        if numpy.issubdtype(v.dtype, numpy.complex):\n+            raise TypeError(\"_serialize_double_vector called on an ndarray of %s; \"\n+                    \"wanted ndarray of float64\" % v.dtype)\n+        v = v.astype(float64)\n     length = v.shape[0]\n-    ba = bytearray(16 + 8*length)\n-    header = ndarray(shape=[2], buffer=ba, dtype=\"int64\")\n-    header[0] = 1\n-    header[1] = length\n-    copyto(ndarray(shape=[length], buffer=ba, offset=16,\n-            dtype=\"float64\"), v)\n+    ba = bytearray(5 + 8 * length)\n+    ba[0] = DENSE_VECTOR_MAGIC\n+    length_bytes = ndarray(shape=[1], buffer=ba, offset=1, dtype=int32)\n+    length_bytes[0] = length\n+    copyto(ndarray(shape=[length], buffer=ba, offset=5, dtype=float64), v)\n+    return ba\n+\n+\n+def _serialize_sparse_vector(v):\n+    \"\"\"Serialize a pyspark.mllib.linalg.SparseVector.\"\"\"\n+    nonzeros = len(v.indices)\n+    ba = bytearray(9 + 12 * nonzeros)\n+    ba[0] = SPARSE_VECTOR_MAGIC\n+    header = ndarray(shape=[2], buffer=ba, offset=1, dtype=int32)\n+    header[0] = v.size\n+    header[1] = nonzeros\n+    copyto(ndarray(shape=[nonzeros], buffer=ba, offset=9, dtype=int32), v.indices)\n+    values_offset = 9 + 4 * nonzeros\n+    copyto(ndarray(shape=[nonzeros], buffer=ba, offset=values_offset, dtype=float64), v.values)\n     return ba\n \n+\n def _deserialize_double_vector(ba):\n     \"\"\"Deserialize a double vector from a mutually understood format.\n \n     >>> x = array([1.0, 2.0, 3.0, 4.0, -1.0, 0.0, -0.0])\n     >>> array_equal(x, _deserialize_double_vector(_serialize_double_vector(x)))\n     True\n+    >>> s = SparseVector(4, [1, 3], [3.0, 5.5])\n+    >>> s == _deserialize_double_vector(_serialize_double_vector(s))\n+    True\n     \"\"\"\n     if type(ba) != bytearray:\n         raise TypeError(\"_deserialize_double_vector called on a %s; \"\n                 \"wanted bytearray\" % type(ba))\n-    if len(ba) < 16:\n+    if len(ba) < 5:\n         raise TypeError(\"_deserialize_double_vector called on a %d-byte array, \"\n                 \"which is too short\" % len(ba))\n-    if (len(ba) & 7) != 0:\n-        raise TypeError(\"_deserialize_double_vector called on a %d-byte array, \"\n-                \"which is not a multiple of 8\" % len(ba))\n-    header = ndarray(shape=[2], buffer=ba, dtype=\"int64\")\n-    if header[0] != 1:\n+    if ba[0] == DENSE_VECTOR_MAGIC:\n+        return _deserialize_dense_vector(ba)\n+    elif ba[0] == SPARSE_VECTOR_MAGIC:\n+        return _deserialize_sparse_vector(ba)\n+    else:\n         raise TypeError(\"_deserialize_double_vector called on bytearray \"\n                         \"with wrong magic\")\n-    length = header[1]\n-    if len(ba) != 8*length + 16:\n-        raise TypeError(\"_deserialize_double_vector called on bytearray \"\n+\n+\n+def _deserialize_dense_vector(ba):\n+    \"\"\"Deserialize a dense vector into a numpy array.\"\"\"\n+    if len(ba) < 5:\n+        raise TypeError(\"_deserialize_dense_vector called on a %d-byte array, \"\n+                \"which is too short\" % len(ba))\n+    length = ndarray(shape=[1], buffer=ba, offset=1, dtype=int32)[0]\n+    if len(ba) != 8 * length + 5:\n+        raise TypeError(\"_deserialize_dense_vector called on bytearray \"\n+                        \"with wrong length\")\n+    return _deserialize_numpy_array([length], ba, 5)\n+\n+\n+def _deserialize_sparse_vector(ba):\n+    \"\"\"Deserialize a sparse vector into a MLlib SparseVector object.\"\"\"\n+    if len(ba) < 9:\n+        raise TypeError(\"_deserialize_sparse_vector called on a %d-byte array, \"\n+                \"which is too short\" % len(ba))\n+    header = ndarray(shape=[2], buffer=ba, offset=1, dtype=int32)\n+    size = header[0]\n+    nonzeros = header[1]\n+    if len(ba) != 9 + 12 * nonzeros:\n+        raise TypeError(\"_deserialize_sparse_vector called on bytearray \"\n                         \"with wrong length\")\n-    return _deserialize_byte_array([length], ba, 16)\n+    indices = _deserialize_numpy_array([nonzeros], ba, 9, dtype=int32)\n+    values = _deserialize_numpy_array([nonzeros], ba, 9 + 4 * nonzeros, dtype=float64)\n+    return SparseVector(int(size), indices, values)\n+\n \n def _serialize_double_matrix(m):\n     \"\"\"Serialize a double matrix into a mutually understood format.\"\"\"\n-    if (type(m) == ndarray and m.dtype == float64 and m.ndim == 2):\n+    if (type(m) == ndarray and m.ndim == 2):\n+        if m.dtype != float64:\n+            if numpy.issubdtype(m.dtype, numpy.complex):\n+                raise TypeError(\"_serialize_double_matrix called on an ndarray of %s; \"\n+                        \"wanted ndarray of float64\" % m.dtype)\n+            m = m.astype(float64)\n         rows = m.shape[0]\n         cols = m.shape[1]\n-        ba = bytearray(24 + 8 * rows * cols)\n-        header = ndarray(shape=[3], buffer=ba, dtype=\"int64\")\n-        header[0] = 2\n-        header[1] = rows\n-        header[2] = cols\n-        copyto(ndarray(shape=[rows, cols], buffer=ba, offset=24,\n-                       dtype=\"float64\", order='C'), m)\n+        ba = bytearray(9 + 8 * rows * cols)\n+        ba[0] = DENSE_MATRIX_MAGIC\n+        lengths = ndarray(shape=[3], buffer=ba, offset=1, dtype=int32)\n+        lengths[0] = rows\n+        lengths[1] = cols\n+        copyto(ndarray(shape=[rows, cols], buffer=ba, offset=9,\n+                       dtype=float64, order='C'), m)\n         return ba\n     else:\n         raise TypeError(\"_serialize_double_matrix called on a \"\n                         \"non-double-matrix\")\n \n+\n def _deserialize_double_matrix(ba):\n     \"\"\"Deserialize a double matrix from a mutually understood format.\"\"\"\n     if type(ba) != bytearray:\n         raise TypeError(\"_deserialize_double_matrix called on a %s; \"\n                 \"wanted bytearray\" % type(ba))\n-    if len(ba) < 24:\n+    if len(ba) < 9:\n         raise TypeError(\"_deserialize_double_matrix called on a %d-byte array, \"\n                 \"which is too short\" % len(ba))\n-    if (len(ba) & 7) != 0:\n-        raise TypeError(\"_deserialize_double_matrix called on a %d-byte array, \"\n-                \"which is not a multiple of 8\" % len(ba))\n-    header = ndarray(shape=[3], buffer=ba, dtype=\"int64\")\n-    if (header[0] != 2):\n+    if ba[0] != DENSE_MATRIX_MAGIC:\n         raise TypeError(\"_deserialize_double_matrix called on bytearray \"\n                         \"with wrong magic\")\n-    rows = header[1]\n-    cols = header[2]\n-    if (len(ba) != 8*rows*cols + 24):\n+    lengths = ndarray(shape=[2], buffer=ba, offset=1, dtype=int32)\n+    rows = lengths[0]\n+    cols = lengths[1]\n+    if (len(ba) != 8 * rows * cols + 9):\n         raise TypeError(\"_deserialize_double_matrix called on bytearray \"\n                         \"with wrong length\")\n-    return _deserialize_byte_array([rows, cols], ba, 24)\n+    return _deserialize_numpy_array([rows, cols], ba, 9)\n+\n+\n+def _serialize_labeled_point(p):\n+    \"\"\"Serialize a LabeledPoint with a features vector of any type.\"\"\"\n+    #from pyspark.mllib.regression import LabeledPoint\n+    #assert type(p) == LabeledPoint, \"Expected a LabeledPoint object\"\n+    from pyspark.mllib.regression import LabeledPoint\n+    serialized_features = _serialize_double_vector(p.features)\n+    header = bytearray(9)\n+    header[0] = LABELED_POINT_MAGIC\n+    header_float = ndarray(shape=[1], buffer=header, offset=1, dtype=float64)\n+    header_float[0] = p.label\n+    return header + serialized_features\n \n-def _linear_predictor_typecheck(x, coeffs):\n-    \"\"\"Check that x is a one-dimensional vector of the right shape.\n-    This is a temporary hackaround until I actually implement bulk predict.\"\"\"\n-    if type(x) == ndarray:\n-        if x.ndim == 1:\n-            if x.shape == coeffs.shape:\n-                pass\n-            else:\n-                raise RuntimeError(\"Got array of %d elements; wanted %d\"\n-                        % (shape(x)[0], shape(coeffs)[0]))\n-        else:\n-            raise RuntimeError(\"Bulk predict not yet supported.\")\n-    elif (type(x) == RDD):\n-        raise RuntimeError(\"Bulk predict not yet supported.\")\n-    else:\n-        raise TypeError(\"Argument of type \" + type(x).__name__ + \" unsupported\")\n \n def _get_unmangled_rdd(data, serializer):\n     dataBytes = data.map(serializer)\n     dataBytes._bypass_serializer = True\n-    dataBytes.cache()\n+    dataBytes.cache() # TODO: users should unpersist() this later!\n     return dataBytes\n \n-# Map a pickled Python RDD of numpy double vectors to a Java RDD of\n+\n+# Map a pickled Python RDD of Python dense or sparse vectors to a Java RDD of\n # _serialized_double_vectors\n def _get_unmangled_double_vector_rdd(data):\n     return _get_unmangled_rdd(data, _serialize_double_vector)\n \n-class LinearModel(object):\n-    \"\"\"Something that has a vector of coefficients and an intercept.\"\"\"\n-    def __init__(self, coeff, intercept):\n-        self._coeff = coeff\n-        self._intercept = intercept\n \n-class LinearRegressionModelBase(LinearModel):\n-    \"\"\"A linear regression model.\n+# Map a pickled Python RDD of LabeledPoint to a Java RDD of _serialized_labeled_points\n+def _get_unmangled_labeled_point_rdd(data):\n+    return _get_unmangled_rdd(data, _serialize_labeled_point)\n \n-    >>> lrmb = LinearRegressionModelBase(array([1.0, 2.0]), 0.1)\n-    >>> abs(lrmb.predict(array([-1.03, 7.777])) - 14.624) < 1e-6\n-    True\n+\n+# Common functions for dealing with and training linear models\n+\n+def _linear_predictor_typecheck(x, coeffs):\n     \"\"\"\n-    def predict(self, x):\n-        \"\"\"Predict the value of the dependent variable given a vector x\"\"\"\n-        \"\"\"containing values for the independent variables.\"\"\"\n-        _linear_predictor_typecheck(x, self._coeff)\n-        return dot(self._coeff, x) + self._intercept\n+    Check that x is a one-dimensional vector of the right shape.\n+    This is a temporary hackaround until we actually implement bulk predict.\n+    \"\"\"\n+    x = _convert_vector(x)\n+    if type(x) == ndarray:\n+        if x.ndim == 1:\n+            if x.shape != coeffs.shape:\n+                raise RuntimeError(\"Got array of %d elements; wanted %d\"\n+                        % (numpy.shape(x)[0], coeffs.shape[0]))\n+        else:\n+            raise RuntimeError(\"Bulk predict not yet supported.\")\n+    elif type(x) == SparseVector:\n+        if x.size != coeffs.shape[0]:\n+           raise RuntimeError(\"Got sparse vector of size %d; wanted %d\"\n+                   % (x.size, coeffs.shape[0]))\n+    elif (type(x) == RDD):\n+        raise RuntimeError(\"Bulk predict not yet supported.\")\n+    else:\n+        raise TypeError(\"Argument of type \" + type(x).__name__ + \" unsupported\")\n+\n \n # If we weren't given initial weights, take a zero vector of the appropriate\n # length.\n def _get_initial_weights(initial_weights, data):\n     if initial_weights is None:\n-        initial_weights = data.first()\n-        if type(initial_weights) != ndarray:\n-            raise TypeError(\"At least one data element has type \"\n-                    + type(initial_weights).__name__ + \" which is not ndarray\")\n-        if initial_weights.ndim != 1:\n-            raise TypeError(\"At least one data element has \"\n-                    + initial_weights.ndim + \" dimensions, which is not 1\")\n-        initial_weights = ones([initial_weights.shape[0] - 1])\n+        initial_weights = _convert_vector(data.first().features)\n+        if type(initial_weights) == ndarray:\n+            if initial_weights.ndim != 1:\n+                raise TypeError(\"At least one data element has \"\n+                        + initial_weights.ndim + \" dimensions, which is not 1\")\n+            initial_weights = numpy.ones([initial_weights.shape[0]])"
  }],
  "prId": 341
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Ditto.\n",
    "commit": "d52e76305a4858d4d516141065e50d997e829c27",
    "createdAt": "2014-04-14T03:15:57Z",
    "diffHunk": "@@ -55,159 +103,222 @@ def _serialize_double_vector(v):\n     >>> array_equal(y, array([1.0, 2.0, 3.0]))\n     True\n     \"\"\"\n-    if type(v) != ndarray:\n-        raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    \"\"\"complex is only datatype that can't be converted to float64\"\"\"\n-    if issubdtype(v.dtype, complex):\n+    v = _convert_vector(v)\n+    if type(v) == ndarray:\n+        return _serialize_dense_vector(v)\n+    elif type(v) == SparseVector:\n+        return _serialize_sparse_vector(v)\n+    else:\n         raise TypeError(\"_serialize_double_vector called on a %s; \"\n-                \"wanted ndarray\" % type(v))\n-    if v.dtype != float64:\n-        v = v.astype(float64)\n+                \"wanted ndarray or SparseVector\" % type(v))\n+\n+\n+def _serialize_dense_vector(v):\n+    \"\"\"Serialize a dense vector given as a NumPy array.\"\"\"\n     if v.ndim != 1:\n         raise TypeError(\"_serialize_double_vector called on a %ddarray; \"\n                 \"wanted a 1darray\" % v.ndim)\n+    if v.dtype != float64:\n+        if numpy.issubdtype(v.dtype, numpy.complex):\n+            raise TypeError(\"_serialize_double_vector called on an ndarray of %s; \"\n+                    \"wanted ndarray of float64\" % v.dtype)\n+        v = v.astype(float64)\n     length = v.shape[0]\n-    ba = bytearray(16 + 8*length)\n-    header = ndarray(shape=[2], buffer=ba, dtype=\"int64\")\n-    header[0] = 1\n-    header[1] = length\n-    copyto(ndarray(shape=[length], buffer=ba, offset=16,\n-            dtype=\"float64\"), v)\n+    ba = bytearray(5 + 8 * length)\n+    ba[0] = DENSE_VECTOR_MAGIC\n+    length_bytes = ndarray(shape=[1], buffer=ba, offset=1, dtype=int32)\n+    length_bytes[0] = length\n+    copyto(ndarray(shape=[length], buffer=ba, offset=5, dtype=float64), v)\n+    return ba\n+\n+\n+def _serialize_sparse_vector(v):\n+    \"\"\"Serialize a pyspark.mllib.linalg.SparseVector.\"\"\"\n+    nonzeros = len(v.indices)\n+    ba = bytearray(9 + 12 * nonzeros)\n+    ba[0] = SPARSE_VECTOR_MAGIC\n+    header = ndarray(shape=[2], buffer=ba, offset=1, dtype=int32)\n+    header[0] = v.size\n+    header[1] = nonzeros\n+    copyto(ndarray(shape=[nonzeros], buffer=ba, offset=9, dtype=int32), v.indices)\n+    values_offset = 9 + 4 * nonzeros\n+    copyto(ndarray(shape=[nonzeros], buffer=ba, offset=values_offset, dtype=float64), v.values)\n     return ba\n \n+\n def _deserialize_double_vector(ba):\n     \"\"\"Deserialize a double vector from a mutually understood format.\n \n     >>> x = array([1.0, 2.0, 3.0, 4.0, -1.0, 0.0, -0.0])\n     >>> array_equal(x, _deserialize_double_vector(_serialize_double_vector(x)))\n     True\n+    >>> s = SparseVector(4, [1, 3], [3.0, 5.5])\n+    >>> s == _deserialize_double_vector(_serialize_double_vector(s))\n+    True\n     \"\"\"\n     if type(ba) != bytearray:\n         raise TypeError(\"_deserialize_double_vector called on a %s; \"\n                 \"wanted bytearray\" % type(ba))\n-    if len(ba) < 16:\n+    if len(ba) < 5:\n         raise TypeError(\"_deserialize_double_vector called on a %d-byte array, \"\n                 \"which is too short\" % len(ba))\n-    if (len(ba) & 7) != 0:\n-        raise TypeError(\"_deserialize_double_vector called on a %d-byte array, \"\n-                \"which is not a multiple of 8\" % len(ba))\n-    header = ndarray(shape=[2], buffer=ba, dtype=\"int64\")\n-    if header[0] != 1:\n+    if ba[0] == DENSE_VECTOR_MAGIC:\n+        return _deserialize_dense_vector(ba)\n+    elif ba[0] == SPARSE_VECTOR_MAGIC:\n+        return _deserialize_sparse_vector(ba)\n+    else:\n         raise TypeError(\"_deserialize_double_vector called on bytearray \"\n                         \"with wrong magic\")\n-    length = header[1]\n-    if len(ba) != 8*length + 16:\n-        raise TypeError(\"_deserialize_double_vector called on bytearray \"\n+\n+\n+def _deserialize_dense_vector(ba):\n+    \"\"\"Deserialize a dense vector into a numpy array.\"\"\"\n+    if len(ba) < 5:\n+        raise TypeError(\"_deserialize_dense_vector called on a %d-byte array, \"\n+                \"which is too short\" % len(ba))\n+    length = ndarray(shape=[1], buffer=ba, offset=1, dtype=int32)[0]\n+    if len(ba) != 8 * length + 5:\n+        raise TypeError(\"_deserialize_dense_vector called on bytearray \"\n+                        \"with wrong length\")\n+    return _deserialize_numpy_array([length], ba, 5)\n+\n+\n+def _deserialize_sparse_vector(ba):\n+    \"\"\"Deserialize a sparse vector into a MLlib SparseVector object.\"\"\"\n+    if len(ba) < 9:\n+        raise TypeError(\"_deserialize_sparse_vector called on a %d-byte array, \"\n+                \"which is too short\" % len(ba))\n+    header = ndarray(shape=[2], buffer=ba, offset=1, dtype=int32)\n+    size = header[0]\n+    nonzeros = header[1]\n+    if len(ba) != 9 + 12 * nonzeros:\n+        raise TypeError(\"_deserialize_sparse_vector called on bytearray \"\n                         \"with wrong length\")\n-    return _deserialize_byte_array([length], ba, 16)\n+    indices = _deserialize_numpy_array([nonzeros], ba, 9, dtype=int32)\n+    values = _deserialize_numpy_array([nonzeros], ba, 9 + 4 * nonzeros, dtype=float64)\n+    return SparseVector(int(size), indices, values)\n+\n \n def _serialize_double_matrix(m):\n     \"\"\"Serialize a double matrix into a mutually understood format.\"\"\"\n-    if (type(m) == ndarray and m.dtype == float64 and m.ndim == 2):\n+    if (type(m) == ndarray and m.ndim == 2):\n+        if m.dtype != float64:\n+            if numpy.issubdtype(m.dtype, numpy.complex):\n+                raise TypeError(\"_serialize_double_matrix called on an ndarray of %s; \"\n+                        \"wanted ndarray of float64\" % m.dtype)\n+            m = m.astype(float64)\n         rows = m.shape[0]\n         cols = m.shape[1]\n-        ba = bytearray(24 + 8 * rows * cols)\n-        header = ndarray(shape=[3], buffer=ba, dtype=\"int64\")\n-        header[0] = 2\n-        header[1] = rows\n-        header[2] = cols\n-        copyto(ndarray(shape=[rows, cols], buffer=ba, offset=24,\n-                       dtype=\"float64\", order='C'), m)\n+        ba = bytearray(9 + 8 * rows * cols)\n+        ba[0] = DENSE_MATRIX_MAGIC\n+        lengths = ndarray(shape=[3], buffer=ba, offset=1, dtype=int32)\n+        lengths[0] = rows\n+        lengths[1] = cols\n+        copyto(ndarray(shape=[rows, cols], buffer=ba, offset=9,\n+                       dtype=float64, order='C'), m)\n         return ba\n     else:\n         raise TypeError(\"_serialize_double_matrix called on a \"\n                         \"non-double-matrix\")\n \n+\n def _deserialize_double_matrix(ba):\n     \"\"\"Deserialize a double matrix from a mutually understood format.\"\"\"\n     if type(ba) != bytearray:\n         raise TypeError(\"_deserialize_double_matrix called on a %s; \"\n                 \"wanted bytearray\" % type(ba))\n-    if len(ba) < 24:\n+    if len(ba) < 9:\n         raise TypeError(\"_deserialize_double_matrix called on a %d-byte array, \"\n                 \"which is too short\" % len(ba))\n-    if (len(ba) & 7) != 0:\n-        raise TypeError(\"_deserialize_double_matrix called on a %d-byte array, \"\n-                \"which is not a multiple of 8\" % len(ba))\n-    header = ndarray(shape=[3], buffer=ba, dtype=\"int64\")\n-    if (header[0] != 2):\n+    if ba[0] != DENSE_MATRIX_MAGIC:\n         raise TypeError(\"_deserialize_double_matrix called on bytearray \"\n                         \"with wrong magic\")\n-    rows = header[1]\n-    cols = header[2]\n-    if (len(ba) != 8*rows*cols + 24):\n+    lengths = ndarray(shape=[2], buffer=ba, offset=1, dtype=int32)\n+    rows = lengths[0]\n+    cols = lengths[1]\n+    if (len(ba) != 8 * rows * cols + 9):\n         raise TypeError(\"_deserialize_double_matrix called on bytearray \"\n                         \"with wrong length\")\n-    return _deserialize_byte_array([rows, cols], ba, 24)\n+    return _deserialize_numpy_array([rows, cols], ba, 9)\n+\n+\n+def _serialize_labeled_point(p):\n+    \"\"\"Serialize a LabeledPoint with a features vector of any type.\"\"\"\n+    #from pyspark.mllib.regression import LabeledPoint\n+    #assert type(p) == LabeledPoint, \"Expected a LabeledPoint object\"\n+    from pyspark.mllib.regression import LabeledPoint\n+    serialized_features = _serialize_double_vector(p.features)\n+    header = bytearray(9)\n+    header[0] = LABELED_POINT_MAGIC\n+    header_float = ndarray(shape=[1], buffer=header, offset=1, dtype=float64)\n+    header_float[0] = p.label\n+    return header + serialized_features\n \n-def _linear_predictor_typecheck(x, coeffs):\n-    \"\"\"Check that x is a one-dimensional vector of the right shape.\n-    This is a temporary hackaround until I actually implement bulk predict.\"\"\"\n-    if type(x) == ndarray:\n-        if x.ndim == 1:\n-            if x.shape == coeffs.shape:\n-                pass\n-            else:\n-                raise RuntimeError(\"Got array of %d elements; wanted %d\"\n-                        % (shape(x)[0], shape(coeffs)[0]))\n-        else:\n-            raise RuntimeError(\"Bulk predict not yet supported.\")\n-    elif (type(x) == RDD):\n-        raise RuntimeError(\"Bulk predict not yet supported.\")\n-    else:\n-        raise TypeError(\"Argument of type \" + type(x).__name__ + \" unsupported\")\n \n def _get_unmangled_rdd(data, serializer):\n     dataBytes = data.map(serializer)\n     dataBytes._bypass_serializer = True\n-    dataBytes.cache()\n+    dataBytes.cache() # TODO: users should unpersist() this later!\n     return dataBytes\n \n-# Map a pickled Python RDD of numpy double vectors to a Java RDD of\n+\n+# Map a pickled Python RDD of Python dense or sparse vectors to a Java RDD of\n # _serialized_double_vectors\n def _get_unmangled_double_vector_rdd(data):\n     return _get_unmangled_rdd(data, _serialize_double_vector)\n \n-class LinearModel(object):\n-    \"\"\"Something that has a vector of coefficients and an intercept.\"\"\"\n-    def __init__(self, coeff, intercept):\n-        self._coeff = coeff\n-        self._intercept = intercept\n \n-class LinearRegressionModelBase(LinearModel):\n-    \"\"\"A linear regression model.\n+# Map a pickled Python RDD of LabeledPoint to a Java RDD of _serialized_labeled_points\n+def _get_unmangled_labeled_point_rdd(data):\n+    return _get_unmangled_rdd(data, _serialize_labeled_point)\n \n-    >>> lrmb = LinearRegressionModelBase(array([1.0, 2.0]), 0.1)\n-    >>> abs(lrmb.predict(array([-1.03, 7.777])) - 14.624) < 1e-6\n-    True\n+\n+# Common functions for dealing with and training linear models\n+\n+def _linear_predictor_typecheck(x, coeffs):\n     \"\"\"\n-    def predict(self, x):\n-        \"\"\"Predict the value of the dependent variable given a vector x\"\"\"\n-        \"\"\"containing values for the independent variables.\"\"\"\n-        _linear_predictor_typecheck(x, self._coeff)\n-        return dot(self._coeff, x) + self._intercept\n+    Check that x is a one-dimensional vector of the right shape.\n+    This is a temporary hackaround until we actually implement bulk predict.\n+    \"\"\"\n+    x = _convert_vector(x)\n+    if type(x) == ndarray:\n+        if x.ndim == 1:\n+            if x.shape != coeffs.shape:\n+                raise RuntimeError(\"Got array of %d elements; wanted %d\"\n+                        % (numpy.shape(x)[0], coeffs.shape[0]))\n+        else:\n+            raise RuntimeError(\"Bulk predict not yet supported.\")\n+    elif type(x) == SparseVector:\n+        if x.size != coeffs.shape[0]:\n+           raise RuntimeError(\"Got sparse vector of size %d; wanted %d\"\n+                   % (x.size, coeffs.shape[0]))\n+    elif (type(x) == RDD):\n+        raise RuntimeError(\"Bulk predict not yet supported.\")\n+    else:\n+        raise TypeError(\"Argument of type \" + type(x).__name__ + \" unsupported\")\n+\n \n # If we weren't given initial weights, take a zero vector of the appropriate\n # length.\n def _get_initial_weights(initial_weights, data):\n     if initial_weights is None:\n-        initial_weights = data.first()\n-        if type(initial_weights) != ndarray:\n-            raise TypeError(\"At least one data element has type \"\n-                    + type(initial_weights).__name__ + \" which is not ndarray\")\n-        if initial_weights.ndim != 1:\n-            raise TypeError(\"At least one data element has \"\n-                    + initial_weights.ndim + \" dimensions, which is not 1\")\n-        initial_weights = ones([initial_weights.shape[0] - 1])\n+        initial_weights = _convert_vector(data.first().features)\n+        if type(initial_weights) == ndarray:\n+            if initial_weights.ndim != 1:\n+                raise TypeError(\"At least one data element has \"\n+                        + initial_weights.ndim + \" dimensions, which is not 1\")\n+            initial_weights = numpy.ones([initial_weights.shape[0]])\n+        elif type(initial_weights) == SparseVector:\n+            initial_weights = numpy.ones([initial_weights.size])"
  }],
  "prId": 341
}]