[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Should the file name match Scala's?\n",
    "commit": "55c6de86369ea675db737bde480af2453c7da408",
    "createdAt": "2014-07-29T04:55:01Z",
    "diffHunk": "@@ -0,0 +1,213 @@\n+#"
  }],
  "prId": 1628
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "If this is only used in unit tests, let's move it inside doctest.\n",
    "commit": "55c6de86369ea675db737bde480af2453c7da408",
    "createdAt": "2014-07-29T04:55:10Z",
    "diffHunk": "@@ -0,0 +1,213 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from random import getrandbits\n+\n+from pyspark.rdd import RDD\n+from pyspark.mllib._common import _deserialize_double, _deserialize_double_vector\n+from pyspark.serializers import NoOpSerializer\n+from pyspark.statcounter import StatCounter"
  }],
  "prId": 1628
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`i.i.d` -> `i.i.d.`\n",
    "commit": "55c6de86369ea675db737bde480af2453c7da408",
    "createdAt": "2014-07-29T04:55:14Z",
    "diffHunk": "@@ -0,0 +1,213 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from random import getrandbits\n+\n+from pyspark.rdd import RDD\n+from pyspark.mllib._common import _deserialize_double, _deserialize_double_vector\n+from pyspark.serializers import NoOpSerializer\n+from pyspark.statcounter import StatCounter\n+\n+class RandomRDDGenerators:\n+    \"\"\"\n+    Generator methods for creating RDDs comprised of i.i.d samples from"
  }],
  "prId": 1628
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "ditto `a + (b - a) * v`\n",
    "commit": "55c6de86369ea675db737bde480af2453c7da408",
    "createdAt": "2014-07-29T04:55:16Z",
    "diffHunk": "@@ -0,0 +1,213 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from random import getrandbits\n+\n+from pyspark.rdd import RDD\n+from pyspark.mllib._common import _deserialize_double, _deserialize_double_vector\n+from pyspark.serializers import NoOpSerializer\n+from pyspark.statcounter import StatCounter\n+\n+class RandomRDDGenerators:\n+    \"\"\"\n+    Generator methods for creating RDDs comprised of i.i.d samples from\n+    some distribution.\n+    \"\"\"\n+\n+    @staticmethod\n+    def uniformRDD(sc, size, numPartitions=None, seed=None):\n+        \"\"\"\n+        Generates an RDD comprised of i.i.d samples from the\n+        uniform distribution on [0.0, 1.0].\n+\n+        To transform the distribution in the generated RDD from U[0.0, 1.0]\n+        to U[a, b], use\n+        C{RandomRDDGenerators.uniformRDD(sc, n, p, seed).map(lambda v: (b - a) * v)}"
  }],
  "prId": 1628
}]