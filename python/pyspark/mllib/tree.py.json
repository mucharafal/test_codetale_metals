[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "return an empty RDD instead?\n",
    "commit": "374448874de7a758658e0ac54cf1d578d09e347d",
    "createdAt": "2014-08-02T00:26:57Z",
    "diffHunk": "@@ -0,0 +1,219 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+\n+from pyspark import SparkContext, RDD\n+from pyspark.mllib._common import \\\n+    _get_unmangled_rdd, _get_unmangled_double_vector_rdd, _serialize_double_vector, \\\n+    _deserialize_labeled_point, _get_unmangled_labeled_point_rdd, \\\n+    _deserialize_double\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.serializers import NoOpSerializer\n+\n+class DecisionTreeModel(object):\n+    \"\"\"\n+    A decision tree model for classification or regression.\n+\n+    WARNING: This is an experimental API.  It will probably be modified for Spark v1.2.\n+    \"\"\"\n+\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def predict(self, x):\n+        \"\"\"\n+        Predict the label of one or more examples.\n+        NOTE: This currently does NOT support batch prediction.\n+\n+        :param x:  Data point: feature vector, or a LabeledPoint (whose label is ignored).\n+        \"\"\"\n+        pythonAPI = self._sc._jvm.PythonMLLibAPI()\n+        if isinstance(x, RDD):\n+            # Bulk prediction\n+            if x.count() == 0:\n+                raise RuntimeError(\"DecisionTreeModel.predict(x) given empty RDD x.\")"
  }],
  "prId": 1727
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We don't support `predict(RDD[LabeledPoint])` in Scala/Python. This adds extra complexity to the API.\n",
    "commit": "374448874de7a758658e0ac54cf1d578d09e347d",
    "createdAt": "2014-08-02T00:28:04Z",
    "diffHunk": "@@ -0,0 +1,219 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+\n+from pyspark import SparkContext, RDD\n+from pyspark.mllib._common import \\\n+    _get_unmangled_rdd, _get_unmangled_double_vector_rdd, _serialize_double_vector, \\\n+    _deserialize_labeled_point, _get_unmangled_labeled_point_rdd, \\\n+    _deserialize_double\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.serializers import NoOpSerializer\n+\n+class DecisionTreeModel(object):\n+    \"\"\"\n+    A decision tree model for classification or regression.\n+\n+    WARNING: This is an experimental API.  It will probably be modified for Spark v1.2.\n+    \"\"\"\n+\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def predict(self, x):\n+        \"\"\"\n+        Predict the label of one or more examples.\n+        NOTE: This currently does NOT support batch prediction.\n+\n+        :param x:  Data point: feature vector, or a LabeledPoint (whose label is ignored).\n+        \"\"\"\n+        pythonAPI = self._sc._jvm.PythonMLLibAPI()\n+        if isinstance(x, RDD):\n+            # Bulk prediction\n+            if x.count() == 0:\n+                raise RuntimeError(\"DecisionTreeModel.predict(x) given empty RDD x.\")\n+            elementType = type(x.take(1)[0])\n+            if elementType == LabeledPoint:"
  }],
  "prId": 1727
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We don't need to cache data for prediction because it only needs a single pass. If `_get_unmangled_double_vector_rdd` also does other special operations, we can add `cache=True` to its arguments.\n",
    "commit": "374448874de7a758658e0ac54cf1d578d09e347d",
    "createdAt": "2014-08-02T00:29:45Z",
    "diffHunk": "@@ -0,0 +1,219 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+\n+from pyspark import SparkContext, RDD\n+from pyspark.mllib._common import \\\n+    _get_unmangled_rdd, _get_unmangled_double_vector_rdd, _serialize_double_vector, \\\n+    _deserialize_labeled_point, _get_unmangled_labeled_point_rdd, \\\n+    _deserialize_double\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.serializers import NoOpSerializer\n+\n+class DecisionTreeModel(object):\n+    \"\"\"\n+    A decision tree model for classification or regression.\n+\n+    WARNING: This is an experimental API.  It will probably be modified for Spark v1.2.\n+    \"\"\"\n+\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def predict(self, x):\n+        \"\"\"\n+        Predict the label of one or more examples.\n+        NOTE: This currently does NOT support batch prediction.\n+\n+        :param x:  Data point: feature vector, or a LabeledPoint (whose label is ignored).\n+        \"\"\"\n+        pythonAPI = self._sc._jvm.PythonMLLibAPI()\n+        if isinstance(x, RDD):\n+            # Bulk prediction\n+            if x.count() == 0:\n+                raise RuntimeError(\"DecisionTreeModel.predict(x) given empty RDD x.\")\n+            elementType = type(x.take(1)[0])\n+            if elementType == LabeledPoint:\n+                x = x.map(lambda x: x.features)\n+            dataBytes = _get_unmangled_double_vector_rdd(x)"
  }],
  "prId": 1727
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "ditto: Maybe we should remove the support of predicting `LabeledPoint`.\n",
    "commit": "374448874de7a758658e0ac54cf1d578d09e347d",
    "createdAt": "2014-08-02T00:30:33Z",
    "diffHunk": "@@ -0,0 +1,219 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+\n+from pyspark import SparkContext, RDD\n+from pyspark.mllib._common import \\\n+    _get_unmangled_rdd, _get_unmangled_double_vector_rdd, _serialize_double_vector, \\\n+    _deserialize_labeled_point, _get_unmangled_labeled_point_rdd, \\\n+    _deserialize_double\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.serializers import NoOpSerializer\n+\n+class DecisionTreeModel(object):\n+    \"\"\"\n+    A decision tree model for classification or regression.\n+\n+    WARNING: This is an experimental API.  It will probably be modified for Spark v1.2.\n+    \"\"\"\n+\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def predict(self, x):\n+        \"\"\"\n+        Predict the label of one or more examples.\n+        NOTE: This currently does NOT support batch prediction.\n+\n+        :param x:  Data point: feature vector, or a LabeledPoint (whose label is ignored).\n+        \"\"\"\n+        pythonAPI = self._sc._jvm.PythonMLLibAPI()\n+        if isinstance(x, RDD):\n+            # Bulk prediction\n+            if x.count() == 0:\n+                raise RuntimeError(\"DecisionTreeModel.predict(x) given empty RDD x.\")\n+            elementType = type(x.take(1)[0])\n+            if elementType == LabeledPoint:\n+                x = x.map(lambda x: x.features)\n+            dataBytes = _get_unmangled_double_vector_rdd(x)\n+            jSerializedPreds = pythonAPI.predictDecisionTreeModel(self._java_model, dataBytes._jrdd)\n+            dataBytes.unpersist()\n+            serializedPreds = RDD(jSerializedPreds, self._sc, NoOpSerializer())\n+            return serializedPreds.map(lambda bytes: _deserialize_double(bytearray(bytes)))\n+        else:\n+            if type(x) == LabeledPoint:"
  }],
  "prId": 1727
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "a line in python doc should not have more than 80 (or 78 to be safe) chars. This is for people running python's help() under traditional terminals (80 x 24?)\n",
    "commit": "374448874de7a758658e0ac54cf1d578d09e347d",
    "createdAt": "2014-08-02T00:32:50Z",
    "diffHunk": "@@ -0,0 +1,219 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+\n+from pyspark import SparkContext, RDD\n+from pyspark.mllib._common import \\\n+    _get_unmangled_rdd, _get_unmangled_double_vector_rdd, _serialize_double_vector, \\\n+    _deserialize_labeled_point, _get_unmangled_labeled_point_rdd, \\\n+    _deserialize_double\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.serializers import NoOpSerializer\n+\n+class DecisionTreeModel(object):\n+    \"\"\"\n+    A decision tree model for classification or regression.\n+\n+    WARNING: This is an experimental API.  It will probably be modified for Spark v1.2.\n+    \"\"\"\n+\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def predict(self, x):\n+        \"\"\"\n+        Predict the label of one or more examples.\n+        NOTE: This currently does NOT support batch prediction.\n+\n+        :param x:  Data point: feature vector, or a LabeledPoint (whose label is ignored).\n+        \"\"\"\n+        pythonAPI = self._sc._jvm.PythonMLLibAPI()\n+        if isinstance(x, RDD):\n+            # Bulk prediction\n+            if x.count() == 0:\n+                raise RuntimeError(\"DecisionTreeModel.predict(x) given empty RDD x.\")\n+            elementType = type(x.take(1)[0])\n+            if elementType == LabeledPoint:\n+                x = x.map(lambda x: x.features)\n+            dataBytes = _get_unmangled_double_vector_rdd(x)\n+            jSerializedPreds = pythonAPI.predictDecisionTreeModel(self._java_model, dataBytes._jrdd)\n+            dataBytes.unpersist()\n+            serializedPreds = RDD(jSerializedPreds, self._sc, NoOpSerializer())\n+            return serializedPreds.map(lambda bytes: _deserialize_double(bytearray(bytes)))\n+        else:\n+            if type(x) == LabeledPoint:\n+                x_ = _serialize_double_vector(x.features)\n+            else:\n+                # Assume x is a single data point.\n+                x_ = _serialize_double_vector(x)\n+            return pythonAPI.predictDecisionTreeModel(self._java_model, x_)\n+\n+    def numNodes(self):\n+        return self._java_model.numNodes()\n+\n+    def depth(self):\n+        return self._java_model.depth()\n+\n+    def __str__(self):\n+        return self._java_model.toString()\n+\n+\n+class DecisionTree(object):\n+    \"\"\"\n+    Learning algorithm for a decision tree model for classification or regression.\n+\n+    WARNING: This is an experimental API.  It will probably be modified for Spark v1.2.\n+\n+    Example usage:\n+    >>> from numpy import array, ndarray\n+    >>> from pyspark.mllib.regression import LabeledPoint\n+    >>> from pyspark.mllib.tree import DecisionTree\n+    >>> from pyspark.mllib.linalg import SparseVector\n+    >>>\n+    >>> data = [\n+    ...     LabeledPoint(0.0, [0.0]),\n+    ...     LabeledPoint(1.0, [1.0]),\n+    ...     LabeledPoint(1.0, [2.0]),\n+    ...     LabeledPoint(1.0, [3.0])\n+    ... ]\n+    >>>\n+    >>> model = DecisionTree.trainClassifier(sc.parallelize(data), numClasses=2)\n+    >>> print(model)\n+    DecisionTreeModel classifier\n+      If (feature 0 <= 0.5)\n+       Predict: 0.0\n+      Else (feature 0 > 0.5)\n+       Predict: 1.0\n+\n+    >>> model.predict(array([1.0])) > 0\n+    True\n+    >>> model.predict(array([0.0])) == 0\n+    True\n+    >>> sparse_data = [\n+    ...     LabeledPoint(0.0, SparseVector(2, {0: 0.0})),\n+    ...     LabeledPoint(1.0, SparseVector(2, {1: 1.0})),\n+    ...     LabeledPoint(0.0, SparseVector(2, {0: 0.0})),\n+    ...     LabeledPoint(1.0, SparseVector(2, {1: 2.0}))\n+    ... ]\n+    >>>\n+    >>> model = DecisionTree.trainRegressor(sc.parallelize(sparse_data))\n+    >>> model.predict(array([0.0, 1.0])) == 1\n+    True\n+    >>> model.predict(array([0.0, 0.0])) == 0\n+    True\n+    >>> model.predict(SparseVector(2, {1: 1.0})) == 1\n+    True\n+    >>> model.predict(SparseVector(2, {1: 0.0})) == 0\n+    True\n+    \"\"\"\n+\n+    @staticmethod\n+    def trainClassifier(data, numClasses, categoricalFeaturesInfo={},\n+                        impurity=\"gini\", maxDepth=4, maxBins=100):\n+        \"\"\"\n+        Train a DecisionTreeModel for classification.\n+\n+        :param data: RDD of NumPy vectors, one per element, where the first\n+                     coordinate is the label and the rest is the feature vector.\n+                     Labels are integers {0,1,...,numClasses}.\n+        :param numClasses: Number of classes for classification.\n+        :param categoricalFeaturesInfo: Map from categorical feature index to number of categories."
  }],
  "prId": 1727
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "It batch prediction working?\n",
    "commit": "374448874de7a758658e0ac54cf1d578d09e347d",
    "createdAt": "2014-08-02T00:38:48Z",
    "diffHunk": "@@ -0,0 +1,219 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+\n+from pyspark import SparkContext, RDD\n+from pyspark.mllib._common import \\\n+    _get_unmangled_rdd, _get_unmangled_double_vector_rdd, _serialize_double_vector, \\\n+    _deserialize_labeled_point, _get_unmangled_labeled_point_rdd, \\\n+    _deserialize_double\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.serializers import NoOpSerializer\n+\n+class DecisionTreeModel(object):\n+    \"\"\"\n+    A decision tree model for classification or regression.\n+\n+    WARNING: This is an experimental API.  It will probably be modified for Spark v1.2.\n+    \"\"\"\n+\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def predict(self, x):\n+        \"\"\"\n+        Predict the label of one or more examples.\n+        NOTE: This currently does NOT support batch prediction."
  }],
  "prId": 1727
}]