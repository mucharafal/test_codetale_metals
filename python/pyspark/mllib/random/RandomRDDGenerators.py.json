[{
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "For these tests to run automatically, you also need to add this file into the `python/run-tests` script. Otherwise it won't automatically discover it, e.g. in Jenkins.\n",
    "commit": "55c6de86369ea675db737bde480af2453c7da408",
    "createdAt": "2014-07-30T02:05:48Z",
    "diffHunk": "@@ -0,0 +1,201 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from random import getrandbits\n+\n+from pyspark.rdd import RDD\n+from pyspark.mllib._common import _deserialize_double, _deserialize_double_vector\n+from pyspark.serializers import NoOpSerializer\n+\n+\n+def uniformRDD(sc, size, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of i.i.d. samples from the\n+    uniform distribution on [0.0, 1.0].\n+\n+    To transform the distribution in the generated RDD from U[0.0, 1.0]\n+    to U[a, b], use\n+    C{uniformRDD(sc, n, p, seed).map(lambda v: a + (b - a) * v)}\n+\n+    >>> x = uniformRDD(sc, 100).collect()\n+    >>> len(x)\n+    100\n+    >>> max(x) <= 1.0 and min(x) >= 0.0\n+    True\n+    >>> uniformRDD(sc, 100, 4).getNumPartitions()\n+    4\n+    >>> parts = uniformRDD(sc, 100, seed=4).getNumPartitions()\n+    >>> parts == sc.defaultParallelism\n+    True\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI().uniformRDD(sc._jsc, size, numPartitions, seed)\n+    uniform =  RDD(jrdd, sc, NoOpSerializer())\n+    return uniform.map(lambda bytes: _deserialize_double(bytearray(bytes)))\n+\n+def normalRDD(sc, size, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of i.i.d samples from the standard normal\n+    distribution.\n+\n+    To transform the distribution in the generated RDD from standard normal\n+    to some other normal N(mean, sigma), use\n+    C{normal(sc, n, p, seed).map(lambda v: mean + sigma * v)}\n+\n+    >>> x = normalRDD(sc, 1000, seed=1L).collect()\n+    >>> from pyspark.statcounter import StatCounter\n+    >>> stats = StatCounter(x)\n+    >>> stats.count()\n+    1000L\n+    >>> abs(stats.mean() - 0.0) < 0.1\n+    True\n+    >>> abs(stats.stdev() - 1.0) < 0.1\n+    True\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI().normalRDD(sc._jsc, size, numPartitions, seed)\n+    normal =  RDD(jrdd, sc, NoOpSerializer())\n+    return normal.map(lambda bytes: _deserialize_double(bytearray(bytes)))\n+\n+def poissonRDD(sc, mean, size, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of i.i.d samples from the Poisson\n+    distribution with the input mean.\n+\n+    >>> mean = 100.0\n+    >>> x = poissonRDD(sc, mean, 1000, seed=1L).collect()\n+    >>> from pyspark.statcounter import StatCounter\n+    >>> stats = StatCounter(x)\n+    >>> stats.count()\n+    1000L\n+    >>> abs(stats.mean() - mean) < 0.5\n+    True\n+    >>> from math import sqrt\n+    >>> abs(stats.stdev() - sqrt(mean)) < 0.5\n+    True\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI().poissonRDD(sc._jsc, mean, size, numPartitions, seed)\n+    poisson =  RDD(jrdd, sc, NoOpSerializer())\n+    return poisson.map(lambda bytes: _deserialize_double(bytearray(bytes)))\n+\n+def uniformVectorRDD(sc, numRows, numCols, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of vectors containing i.i.d samples drawn\n+    from the uniform distribution on [0.0 1.0].\n+\n+    >>> import numpy as np\n+    >>> mat = np.matrix(uniformVectorRDD(sc, 10, 10).collect())\n+    >>> mat.shape\n+    (10, 10)\n+    >>> mat.max() <= 1.0 and mat.min() >= 0.0\n+    True\n+    >>> uniformVectorRDD(sc, 10, 10, 4).getNumPartitions()\n+    4\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI()\\\n+        .uniformVectorRDD(sc._jsc, numRows, numCols, numPartitions, seed)\n+    uniform =  RDD(jrdd, sc, NoOpSerializer())\n+    return uniform.map(lambda bytes: _deserialize_double_vector(bytearray(bytes)))\n+\n+def normalVectorRDD(sc, numRows, numCols, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of vectors containing i.i.d samples drawn\n+    from the standard normal distribution.\n+\n+    >>> import numpy as np\n+    >>> mat = np.matrix(normalVectorRDD(sc, 100, 100, seed=1L).collect())\n+    >>> mat.shape\n+    (100, 100)\n+    >>> abs(mat.mean() - 0.0) < 0.1\n+    True\n+    >>> abs(mat.std() - 1.0) < 0.1\n+    True\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI() \\\n+        .normalVectorRDD(sc._jsc, numRows, numCols, numPartitions, seed)\n+    normal =  RDD(jrdd, sc, NoOpSerializer())\n+    return normal.map(lambda bytes: _deserialize_double_vector(bytearray(bytes)))\n+\n+def poissonVectorRDD(sc, mean, numRows, numCols, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of vectors containing i.i.d samples drawn\n+    from the Poisson distribution with the input mean.\n+\n+    >>> import numpy as np\n+    >>> mean = 100.0\n+    >>> rdd = poissonVectorRDD(sc, mean, 100, 100, seed=1L)\n+    >>> mat = np.mat(rdd.collect())\n+    >>> mat.shape\n+    (100, 100)\n+    >>> abs(mat.mean() - mean) < 0.5\n+    True\n+    >>> from math import sqrt\n+    >>> abs(mat.std() - sqrt(mean)) < 0.5\n+    True\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI() \\\n+        .poissonVectorRDD(sc._jsc, mean, numRows, numCols, numPartitions, seed)\n+    poisson =  RDD(jrdd, sc, NoOpSerializer())\n+    return poisson.map(lambda bytes: _deserialize_double_vector(bytearray(bytes)))\n+\n+def _getDefaultArgs(sc, numPartitions, seed):\n+    \"\"\"\n+    Use sc.defaultParallelism for numPartitions and\n+    a randomly generated long for seed if either has a value of C{None}\n+\n+    >>> _getDefaultArgs(sc, 3, 2)\n+    (3, 2)\n+    >>> _getDefaultArgs(sc, None, 2) == (sc.defaultParallelism, 2)\n+    True\n+    >>> from math import pow\n+    >>> _getDefaultArgs(sc, None, None)[1] < pow(2, 63)\n+    True\n+    \"\"\"\n+    if not numPartitions:\n+        numPartitions = sc.defaultParallelism\n+    if not seed:\n+        seed = _nextLong()\n+    return numPartitions, seed\n+\n+def _nextLong():\n+    \"\"\"\n+    Returns a random long to be used as RNG seed in the Java APIs.\n+\n+    Note: only 63 random bits are used here since Long.MAX_VALUE = 2 ^ 63 - 1\n+    \"\"\"\n+    return long(getrandbits(63))\n+\n+\n+def _test():"
  }, {
    "author": {
      "login": "dorx"
    },
    "body": "Yep caught that while looking inside run-tests. Thanks for the reminder.\n",
    "commit": "55c6de86369ea675db737bde480af2453c7da408",
    "createdAt": "2014-07-30T02:07:35Z",
    "diffHunk": "@@ -0,0 +1,201 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from random import getrandbits\n+\n+from pyspark.rdd import RDD\n+from pyspark.mllib._common import _deserialize_double, _deserialize_double_vector\n+from pyspark.serializers import NoOpSerializer\n+\n+\n+def uniformRDD(sc, size, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of i.i.d. samples from the\n+    uniform distribution on [0.0, 1.0].\n+\n+    To transform the distribution in the generated RDD from U[0.0, 1.0]\n+    to U[a, b], use\n+    C{uniformRDD(sc, n, p, seed).map(lambda v: a + (b - a) * v)}\n+\n+    >>> x = uniformRDD(sc, 100).collect()\n+    >>> len(x)\n+    100\n+    >>> max(x) <= 1.0 and min(x) >= 0.0\n+    True\n+    >>> uniformRDD(sc, 100, 4).getNumPartitions()\n+    4\n+    >>> parts = uniformRDD(sc, 100, seed=4).getNumPartitions()\n+    >>> parts == sc.defaultParallelism\n+    True\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI().uniformRDD(sc._jsc, size, numPartitions, seed)\n+    uniform =  RDD(jrdd, sc, NoOpSerializer())\n+    return uniform.map(lambda bytes: _deserialize_double(bytearray(bytes)))\n+\n+def normalRDD(sc, size, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of i.i.d samples from the standard normal\n+    distribution.\n+\n+    To transform the distribution in the generated RDD from standard normal\n+    to some other normal N(mean, sigma), use\n+    C{normal(sc, n, p, seed).map(lambda v: mean + sigma * v)}\n+\n+    >>> x = normalRDD(sc, 1000, seed=1L).collect()\n+    >>> from pyspark.statcounter import StatCounter\n+    >>> stats = StatCounter(x)\n+    >>> stats.count()\n+    1000L\n+    >>> abs(stats.mean() - 0.0) < 0.1\n+    True\n+    >>> abs(stats.stdev() - 1.0) < 0.1\n+    True\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI().normalRDD(sc._jsc, size, numPartitions, seed)\n+    normal =  RDD(jrdd, sc, NoOpSerializer())\n+    return normal.map(lambda bytes: _deserialize_double(bytearray(bytes)))\n+\n+def poissonRDD(sc, mean, size, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of i.i.d samples from the Poisson\n+    distribution with the input mean.\n+\n+    >>> mean = 100.0\n+    >>> x = poissonRDD(sc, mean, 1000, seed=1L).collect()\n+    >>> from pyspark.statcounter import StatCounter\n+    >>> stats = StatCounter(x)\n+    >>> stats.count()\n+    1000L\n+    >>> abs(stats.mean() - mean) < 0.5\n+    True\n+    >>> from math import sqrt\n+    >>> abs(stats.stdev() - sqrt(mean)) < 0.5\n+    True\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI().poissonRDD(sc._jsc, mean, size, numPartitions, seed)\n+    poisson =  RDD(jrdd, sc, NoOpSerializer())\n+    return poisson.map(lambda bytes: _deserialize_double(bytearray(bytes)))\n+\n+def uniformVectorRDD(sc, numRows, numCols, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of vectors containing i.i.d samples drawn\n+    from the uniform distribution on [0.0 1.0].\n+\n+    >>> import numpy as np\n+    >>> mat = np.matrix(uniformVectorRDD(sc, 10, 10).collect())\n+    >>> mat.shape\n+    (10, 10)\n+    >>> mat.max() <= 1.0 and mat.min() >= 0.0\n+    True\n+    >>> uniformVectorRDD(sc, 10, 10, 4).getNumPartitions()\n+    4\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI()\\\n+        .uniformVectorRDD(sc._jsc, numRows, numCols, numPartitions, seed)\n+    uniform =  RDD(jrdd, sc, NoOpSerializer())\n+    return uniform.map(lambda bytes: _deserialize_double_vector(bytearray(bytes)))\n+\n+def normalVectorRDD(sc, numRows, numCols, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of vectors containing i.i.d samples drawn\n+    from the standard normal distribution.\n+\n+    >>> import numpy as np\n+    >>> mat = np.matrix(normalVectorRDD(sc, 100, 100, seed=1L).collect())\n+    >>> mat.shape\n+    (100, 100)\n+    >>> abs(mat.mean() - 0.0) < 0.1\n+    True\n+    >>> abs(mat.std() - 1.0) < 0.1\n+    True\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI() \\\n+        .normalVectorRDD(sc._jsc, numRows, numCols, numPartitions, seed)\n+    normal =  RDD(jrdd, sc, NoOpSerializer())\n+    return normal.map(lambda bytes: _deserialize_double_vector(bytearray(bytes)))\n+\n+def poissonVectorRDD(sc, mean, numRows, numCols, numPartitions=None, seed=None):\n+    \"\"\"\n+    Generates an RDD comprised of vectors containing i.i.d samples drawn\n+    from the Poisson distribution with the input mean.\n+\n+    >>> import numpy as np\n+    >>> mean = 100.0\n+    >>> rdd = poissonVectorRDD(sc, mean, 100, 100, seed=1L)\n+    >>> mat = np.mat(rdd.collect())\n+    >>> mat.shape\n+    (100, 100)\n+    >>> abs(mat.mean() - mean) < 0.5\n+    True\n+    >>> from math import sqrt\n+    >>> abs(mat.std() - sqrt(mean)) < 0.5\n+    True\n+    \"\"\"\n+    numPartitions, seed = _getDefaultArgs(sc, numPartitions, seed)\n+    jrdd = sc._jvm.PythonMLLibAPI() \\\n+        .poissonVectorRDD(sc._jsc, mean, numRows, numCols, numPartitions, seed)\n+    poisson =  RDD(jrdd, sc, NoOpSerializer())\n+    return poisson.map(lambda bytes: _deserialize_double_vector(bytearray(bytes)))\n+\n+def _getDefaultArgs(sc, numPartitions, seed):\n+    \"\"\"\n+    Use sc.defaultParallelism for numPartitions and\n+    a randomly generated long for seed if either has a value of C{None}\n+\n+    >>> _getDefaultArgs(sc, 3, 2)\n+    (3, 2)\n+    >>> _getDefaultArgs(sc, None, 2) == (sc.defaultParallelism, 2)\n+    True\n+    >>> from math import pow\n+    >>> _getDefaultArgs(sc, None, None)[1] < pow(2, 63)\n+    True\n+    \"\"\"\n+    if not numPartitions:\n+        numPartitions = sc.defaultParallelism\n+    if not seed:\n+        seed = _nextLong()\n+    return numPartitions, seed\n+\n+def _nextLong():\n+    \"\"\"\n+    Returns a random long to be used as RNG seed in the Java APIs.\n+\n+    Note: only 63 random bits are used here since Long.MAX_VALUE = 2 ^ 63 - 1\n+    \"\"\"\n+    return long(getrandbits(63))\n+\n+\n+def _test():"
  }],
  "prId": 1628
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Add a doc comment to this package similar to the one on RandomRDDGenerators.scala\n",
    "commit": "55c6de86369ea675db737bde480af2453c7da408",
    "createdAt": "2014-07-30T02:07:03Z",
    "diffHunk": "@@ -0,0 +1,201 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from random import getrandbits\n+\n+from pyspark.rdd import RDD\n+from pyspark.mllib._common import _deserialize_double, _deserialize_double_vector\n+from pyspark.serializers import NoOpSerializer\n+"
  }],
  "prId": 1628
}]