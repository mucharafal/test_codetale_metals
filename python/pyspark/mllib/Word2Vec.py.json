[{
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "This is not used.\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-25T21:36:28Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+\n+from functools import wraps"
  }, {
    "author": {
      "login": "Ishiihara"
    },
    "body": "Done.\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-26T22:33:26Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+\n+from functools import wraps"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "need some simple test code\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-25T22:11:17Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+\n+from functools import wraps\n+\n+from pyspark import PickleSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        pythonAPI = self._sc._jvm.PythonMLLibAPI()\n+        result = pythonAPI.Word2VecModelTransform(self._java_model, word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        SerDe = self._sc._jvm.SerDe\n+        ser = PickleSerializer()\n+        pythonAPI = self._sc._jvm.PythonMLLibAPI()\n+        if type(x) == str:\n+            jlist = pythonAPI.Word2VecModelSynonyms(self._java_model, x, num)\n+        else:\n+            bytes = bytearray(ser.dumps(_convert_to_vector(x)))\n+            vec = self._sc._jvm.SerDe.loads(bytes)\n+            jlist = pythonAPI.Word2VecModelSynonyms(self._java_model, vec, num)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(jlist)))\n+\n+\n+class Word2Vec(object):\n+    \"\"\"\n+    Word2Vec creates vector representation of words in a text corpus.\n+    The algorithm first constructs a vocabulary from the corpus\n+    and then learns vector representation of words in the vocabulary.\n+    The vector representation can be used as features in\n+    natural language processing and machine learning algorithms.\n+\n+    We used skip-gram model in our implementation and hierarchical softmax\n+    method to train the model. The variable names in the implementation\n+    matches the original C implementation.\n+    For original C implementation, see https://code.google.com/p/word2vec/\n+    For research papers, see\n+    Efficient Estimation of Word Representations in Vector Space\n+    and\n+    Distributed Representations of Words and Phrases and their Compositionality.\n+    \"\"\"\n+    def __init__(self):\n+        self.vectorSize = 100\n+        self.startingAlpha = 0.025\n+        self.numPartitions = 1\n+        self.numIterations = 1\n+\n+    def setVectorSize(self, vectorSize):\n+        self.vectorSize = vectorSize\n+        return self\n+\n+    def setLearningRate(self, learningRate):\n+        self.startingAlpha = learningRate\n+        return self\n+\n+    def setNumPartitions(self, numPartitions):\n+        self.numPartitions = numPartitions\n+        return self\n+\n+    def setNumIterations(self, numIterations):\n+        self.numIterations = numIterations\n+        return self\n+\n+    def fit(self, data):\n+        \"\"\"\n+        :param data: Input RDD\n+        \"\"\""
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "parameters are not applied\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-25T22:11:20Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+\n+from functools import wraps\n+\n+from pyspark import PickleSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        pythonAPI = self._sc._jvm.PythonMLLibAPI()\n+        result = pythonAPI.Word2VecModelTransform(self._java_model, word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        SerDe = self._sc._jvm.SerDe\n+        ser = PickleSerializer()\n+        pythonAPI = self._sc._jvm.PythonMLLibAPI()\n+        if type(x) == str:\n+            jlist = pythonAPI.Word2VecModelSynonyms(self._java_model, x, num)\n+        else:\n+            bytes = bytearray(ser.dumps(_convert_to_vector(x)))\n+            vec = self._sc._jvm.SerDe.loads(bytes)\n+            jlist = pythonAPI.Word2VecModelSynonyms(self._java_model, vec, num)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(jlist)))\n+\n+\n+class Word2Vec(object):\n+    \"\"\"\n+    Word2Vec creates vector representation of words in a text corpus.\n+    The algorithm first constructs a vocabulary from the corpus\n+    and then learns vector representation of words in the vocabulary.\n+    The vector representation can be used as features in\n+    natural language processing and machine learning algorithms.\n+\n+    We used skip-gram model in our implementation and hierarchical softmax\n+    method to train the model. The variable names in the implementation\n+    matches the original C implementation.\n+    For original C implementation, see https://code.google.com/p/word2vec/\n+    For research papers, see\n+    Efficient Estimation of Word Representations in Vector Space\n+    and\n+    Distributed Representations of Words and Phrases and their Compositionality.\n+    \"\"\"\n+    def __init__(self):\n+        self.vectorSize = 100\n+        self.startingAlpha = 0.025\n+        self.numPartitions = 1\n+        self.numIterations = 1\n+\n+    def setVectorSize(self, vectorSize):\n+        self.vectorSize = vectorSize\n+        return self\n+\n+    def setLearningRate(self, learningRate):\n+        self.startingAlpha = learningRate\n+        return self\n+\n+    def setNumPartitions(self, numPartitions):\n+        self.numPartitions = numPartitions\n+        return self\n+\n+    def setNumIterations(self, numIterations):\n+        self.numIterations = numIterations\n+        return self\n+\n+    def fit(self, data):\n+        \"\"\"\n+        :param data: Input RDD\n+        \"\"\"\n+        sc = data.context\n+        model = sc._jvm.PythonMLLibAPI().trainWord2Vec(data._to_java_object_rdd())"
  }, {
    "author": {
      "login": "Ishiihara"
    },
    "body": "Can you elaborate? Thanks!\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-26T22:35:08Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+\n+from functools import wraps\n+\n+from pyspark import PickleSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        pythonAPI = self._sc._jvm.PythonMLLibAPI()\n+        result = pythonAPI.Word2VecModelTransform(self._java_model, word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        SerDe = self._sc._jvm.SerDe\n+        ser = PickleSerializer()\n+        pythonAPI = self._sc._jvm.PythonMLLibAPI()\n+        if type(x) == str:\n+            jlist = pythonAPI.Word2VecModelSynonyms(self._java_model, x, num)\n+        else:\n+            bytes = bytearray(ser.dumps(_convert_to_vector(x)))\n+            vec = self._sc._jvm.SerDe.loads(bytes)\n+            jlist = pythonAPI.Word2VecModelSynonyms(self._java_model, vec, num)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(jlist)))\n+\n+\n+class Word2Vec(object):\n+    \"\"\"\n+    Word2Vec creates vector representation of words in a text corpus.\n+    The algorithm first constructs a vocabulary from the corpus\n+    and then learns vector representation of words in the vocabulary.\n+    The vector representation can be used as features in\n+    natural language processing and machine learning algorithms.\n+\n+    We used skip-gram model in our implementation and hierarchical softmax\n+    method to train the model. The variable names in the implementation\n+    matches the original C implementation.\n+    For original C implementation, see https://code.google.com/p/word2vec/\n+    For research papers, see\n+    Efficient Estimation of Word Representations in Vector Space\n+    and\n+    Distributed Representations of Words and Phrases and their Compositionality.\n+    \"\"\"\n+    def __init__(self):\n+        self.vectorSize = 100\n+        self.startingAlpha = 0.025\n+        self.numPartitions = 1\n+        self.numIterations = 1\n+\n+    def setVectorSize(self, vectorSize):\n+        self.vectorSize = vectorSize\n+        return self\n+\n+    def setLearningRate(self, learningRate):\n+        self.startingAlpha = learningRate\n+        return self\n+\n+    def setNumPartitions(self, numPartitions):\n+        self.numPartitions = numPartitions\n+        return self\n+\n+    def setNumIterations(self, numIterations):\n+        self.numIterations = numIterations\n+        return self\n+\n+    def fit(self, data):\n+        \"\"\"\n+        :param data: Input RDD\n+        \"\"\"\n+        sc = data.context\n+        model = sc._jvm.PythonMLLibAPI().trainWord2Vec(data._to_java_object_rdd())"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "parameters are not sent to scala\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-27T04:08:14Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+\n+from pyspark import PickleSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        result = self._java_model.transform(word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        jlist = self._java_model.findSynonyms(x, num)\n+        words, similarity = PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(jlist)))\n+        return zip(words, similarity)\n+\n+\n+class Word2Vec(object):\n+    \"\"\"\n+    Word2Vec creates vector representation of words in a text corpus.\n+    The algorithm first constructs a vocabulary from the corpus\n+    and then learns vector representation of words in the vocabulary.\n+    The vector representation can be used as features in\n+    natural language processing and machine learning algorithms.\n+\n+    We used skip-gram model in our implementation and hierarchical softmax\n+    method to train the model. The variable names in the implementation\n+    matches the original C implementation.\n+    For original C implementation, see https://code.google.com/p/word2vec/\n+    For research papers, see\n+    Efficient Estimation of Word Representations in Vector Space\n+    and\n+    Distributed Representations of Words and Phrases and their Compositionality.\n+    >>> sentence = \"a b \" * 100 + \"a c \" * 10\n+    >>> localDoc = [sentence, sentence]\n+    >>> doc = sc.parallelize(localDoc).map(lambda line: line.split(\" \"))\n+    >>> model = Word2Vec().setVectorSize(10).setSeed(42L).fit(doc)\n+    >>> syms = model.findSynonyms(\"a\", 2)\n+    >>> str(syms[0][0])\n+    'b'\n+    >>> str(syms[1][0])\n+    'c'\n+    \"\"\"\n+    def __init__(self):\n+        self.vectorSize = 100\n+        self.startingAlpha = 0.025\n+        self.numPartitions = 1\n+        self.numIterations = 1\n+        self.seed = 42L\n+\n+    def setVectorSize(self, vectorSize):\n+        self.vectorSize = vectorSize\n+        return self\n+\n+    def setLearningRate(self, learningRate):\n+        self.startingAlpha = learningRate\n+        return self\n+\n+    def setNumPartitions(self, numPartitions):\n+        self.numPartitions = numPartitions\n+        return self\n+\n+    def setNumIterations(self, numIterations):\n+        self.numIterations = numIterations\n+        return self\n+\n+    def setSeed(self, seed):\n+        self.seed = seed\n+        return self\n+\n+    def fit(self, data):\n+        sc = data.context\n+        model = sc._jvm.PythonMLLibAPI().trainWord2Vec(data._to_java_object_rdd())"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "add doc and note this is local\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-27T04:10:51Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+\n+from pyspark import PickleSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):"
  }, {
    "author": {
      "login": "Ishiihara"
    },
    "body": "Done\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-27T08:25:21Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+\n+from pyspark import PickleSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Missing the main documentation. The doc only says \"local use only\" but not what this function does.\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-29T21:13:56Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+\n+from pyspark import PickleSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "Done\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-27T08:25:31Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+\n+from pyspark import PickleSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        result = self._java_model.transform(word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        jlist = self._java_model.findSynonyms(x, num)\n+        words, similarity = PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(jlist)))\n+        return zip(words, similarity)\n+\n+\n+class Word2Vec(object):\n+    \"\"\"\n+    Word2Vec creates vector representation of words in a text corpus.\n+    The algorithm first constructs a vocabulary from the corpus\n+    and then learns vector representation of words in the vocabulary.\n+    The vector representation can be used as features in\n+    natural language processing and machine learning algorithms.\n+\n+    We used skip-gram model in our implementation and hierarchical softmax\n+    method to train the model. The variable names in the implementation\n+    matches the original C implementation.\n+    For original C implementation, see https://code.google.com/p/word2vec/\n+    For research papers, see\n+    Efficient Estimation of Word Representations in Vector Space\n+    and\n+    Distributed Representations of Words and Phrases and their Compositionality."
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "organize imports:\n\n```\nfrom sys ...\n\nfrom numpy ...\n\nfrom pyspark.serializers ...\nfrom pyspark.mllib ...\n```\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-29T21:13:53Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+from numpy import random\n+\n+from sys import maxint"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "ditto. For python, it is important to describe the return type.\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-29T21:14:02Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+from numpy import random\n+\n+from sys import maxint\n+\n+from pyspark.serializers import PickleSerializer, AutoBatchedSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        \"\"\"\n+        local use only\n+        TODO: make transform usable in RDD operations from python side\n+        \"\"\"\n+        result = self._java_model.transform(word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        \"\"\"\n+        local use only"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "missing doc for all methods in `Word2Vec`\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-29T21:14:06Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+from numpy import random\n+\n+from sys import maxint\n+\n+from pyspark.serializers import PickleSerializer, AutoBatchedSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        \"\"\"\n+        local use only\n+        TODO: make transform usable in RDD operations from python side\n+        \"\"\"\n+        result = self._java_model.transform(word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        \"\"\"\n+        local use only\n+        TODO: make findSynonyms usable in RDD operations from python side\n+        \"\"\"\n+        jlist = self._java_model.findSynonyms(x, num)\n+        words, similarity = PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(jlist)))\n+        return zip(words, similarity)\n+\n+\n+class Word2Vec(object):\n+    \"\"\"\n+    Word2Vec creates vector representation of words in a text corpus.\n+    The algorithm first constructs a vocabulary from the corpus\n+    and then learns vector representation of words in the vocabulary.\n+    The vector representation can be used as features in\n+    natural language processing and machine learning algorithms.\n+\n+    We used skip-gram model in our implementation and hierarchical softmax\n+    method to train the model. The variable names in the implementation\n+    matches the original C implementation.\n+    For original C implementation, see https://code.google.com/p/word2vec/\n+    For research papers, see\n+    Efficient Estimation of Word Representations in Vector Space\n+    and\n+    Distributed Representations of Words and Phrases and their Compositionality.\n+\n+    >>> sentence = \"a b \" * 100 + \"a c \" * 10\n+    >>> localDoc = [sentence, sentence]\n+    >>> doc = sc.parallelize(localDoc).map(lambda line: line.split(\" \"))\n+    >>> model = Word2Vec().setVectorSize(10).setSeed(42L).fit(doc)\n+    >>> syms = model.findSynonyms(\"a\", 2)\n+    >>> str(syms[0][0])\n+    'b'\n+    >>> str(syms[1][0])\n+    'c'\n+    >>> len(syms)\n+    2\n+    >>> vec = model.transform(\"a\")\n+    >>> len(vec)\n+    10\n+    \"\"\"\n+    def __init__(self):"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "use `learningRate` instead\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-09-29T21:14:23Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+from numpy import random\n+\n+from sys import maxint\n+\n+from pyspark.serializers import PickleSerializer, AutoBatchedSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        \"\"\"\n+        local use only\n+        TODO: make transform usable in RDD operations from python side\n+        \"\"\"\n+        result = self._java_model.transform(word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        \"\"\"\n+        local use only\n+        TODO: make findSynonyms usable in RDD operations from python side\n+        \"\"\"\n+        jlist = self._java_model.findSynonyms(x, num)\n+        words, similarity = PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(jlist)))\n+        return zip(words, similarity)\n+\n+\n+class Word2Vec(object):\n+    \"\"\"\n+    Word2Vec creates vector representation of words in a text corpus.\n+    The algorithm first constructs a vocabulary from the corpus\n+    and then learns vector representation of words in the vocabulary.\n+    The vector representation can be used as features in\n+    natural language processing and machine learning algorithms.\n+\n+    We used skip-gram model in our implementation and hierarchical softmax\n+    method to train the model. The variable names in the implementation\n+    matches the original C implementation.\n+    For original C implementation, see https://code.google.com/p/word2vec/\n+    For research papers, see\n+    Efficient Estimation of Word Representations in Vector Space\n+    and\n+    Distributed Representations of Words and Phrases and their Compositionality.\n+\n+    >>> sentence = \"a b \" * 100 + \"a c \" * 10\n+    >>> localDoc = [sentence, sentence]\n+    >>> doc = sc.parallelize(localDoc).map(lambda line: line.split(\" \"))\n+    >>> model = Word2Vec().setVectorSize(10).setSeed(42L).fit(doc)\n+    >>> syms = model.findSynonyms(\"a\", 2)\n+    >>> str(syms[0][0])\n+    'b'\n+    >>> str(syms[1][0])\n+    'c'\n+    >>> len(syms)\n+    2\n+    >>> vec = model.transform(\"a\")\n+    >>> len(vec)\n+    10\n+    \"\"\"\n+    def __init__(self):\n+        self.vectorSize = 100\n+        self.startingAlpha = 0.025"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Please rename the file to `feature.py` to make `Word2Vec` live under `mllib.feature` package.\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-10-06T21:18:40Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+#"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "It is nice to put a simple sentence summarizing the method before parameters.\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-10-06T21:18:52Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+from pyspark.serializers import PickleSerializer, AutoBatchedSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        \"\"\"\n+        :param word: a word"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Let's move TODOs inside the implementation. Those are not for users.\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-10-06T21:18:54Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+from pyspark.serializers import PickleSerializer, AutoBatchedSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        \"\"\"\n+        :param word: a word\n+        :return: vector representation of word\n+\n+        Note: local use only\n+        TODO: make transform usable in RDD operations from python side"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "ditto: move TODO to implementation.\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-10-06T21:18:56Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+from pyspark.serializers import PickleSerializer, AutoBatchedSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        \"\"\"\n+        :param word: a word\n+        :return: vector representation of word\n+\n+        Note: local use only\n+        TODO: make transform usable in RDD operations from python side\n+        \"\"\"\n+        result = self._java_model.transform(word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        \"\"\"\n+        :param x: a word or a vector representation of word\n+        :param num: number of synonyms to find\n+        :return: array of (word, cosineSimilarity)\n+\n+        Note: local use only\n+        TODO: make findSynonyms usable in RDD operations from python side"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "need the type info on the input data\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-10-06T21:19:03Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+from pyspark.serializers import PickleSerializer, AutoBatchedSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        \"\"\"\n+        :param word: a word\n+        :return: vector representation of word\n+\n+        Note: local use only\n+        TODO: make transform usable in RDD operations from python side\n+        \"\"\"\n+        result = self._java_model.transform(word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        \"\"\"\n+        :param x: a word or a vector representation of word\n+        :param num: number of synonyms to find\n+        :return: array of (word, cosineSimilarity)\n+\n+        Note: local use only\n+        TODO: make findSynonyms usable in RDD operations from python side\n+        \"\"\"\n+        ser = PickleSerializer()\n+        if type(x) == str:\n+            jlist = self._java_model.findSynonyms(x, num)\n+        else:\n+            bytes = bytearray(ser.dumps(_convert_to_vector(x)))\n+            vec = self._sc._jvm.SerDe.loads(bytes)\n+            jlist = self._java_model.findSynonyms(vec, num)\n+        words, similarity = ser.loads(str(self._sc._jvm.SerDe.dumps(jlist)))\n+        return zip(words, similarity)\n+\n+\n+class Word2Vec(object):\n+    \"\"\"\n+    Word2Vec creates vector representation of words in a text corpus.\n+    The algorithm first constructs a vocabulary from the corpus\n+    and then learns vector representation of words in the vocabulary.\n+    The vector representation can be used as features in\n+    natural language processing and machine learning algorithms.\n+\n+    We used skip-gram model in our implementation and hierarchical softmax\n+    method to train the model. The variable names in the implementation\n+    matches the original C implementation.\n+    For original C implementation, see https://code.google.com/p/word2vec/\n+    For research papers, see\n+    Efficient Estimation of Word Representations in Vector Space\n+    and\n+    Distributed Representations of Words and Phrases and their Compositionality.\n+\n+    >>> sentence = \"a b \" * 100 + \"a c \" * 10\n+    >>> localDoc = [sentence, sentence]\n+    >>> doc = sc.parallelize(localDoc).map(lambda line: line.split(\" \"))\n+    >>> model = Word2Vec().setVectorSize(10).setSeed(42L).fit(doc)\n+    >>> syms = model.findSynonyms(\"a\", 2)\n+    >>> str(syms[0][0])\n+    'b'\n+    >>> str(syms[1][0])\n+    'c'\n+    >>> len(syms)\n+    2\n+    >>> vec = model.transform(\"a\")\n+    >>> len(vec)\n+    10\n+    >>> syms = model.findSynonyms(vec, 2)\n+    >>> str(syms[0][0])\n+    'b'\n+    >>> str(syms[1][0])\n+    'c'\n+    >>> len(syms)\n+    2\n+    \"\"\"\n+    def __init__(self):\n+        \"\"\"\n+        Construct Word2Vec instance\n+        \"\"\"\n+        self.vectorSize = 100\n+        self.learningRate = 0.025\n+        self.numPartitions = 1\n+        self.numIterations = 1\n+        self.seed = 42L\n+\n+    def setVectorSize(self, vectorSize):\n+        \"\"\"\n+        Sets vector size (default: 100).\n+        \"\"\"\n+        self.vectorSize = vectorSize\n+        return self\n+\n+    def setLearningRate(self, learningRate):\n+        \"\"\"\n+        Sets initial learning rate (default: 0.025).\n+        \"\"\"\n+        self.learningRate = learningRate\n+        return self\n+\n+    def setNumPartitions(self, numPartitions):\n+        \"\"\"\n+        Sets number of partitions (default: 1). Use a small number for accuracy.\n+        \"\"\"\n+        self.numPartitions = numPartitions\n+        return self\n+\n+    def setNumIterations(self, numIterations):\n+        \"\"\"\n+        Sets number of iterations (default: 1), which should be smaller than or equal to number of\n+        partitions.\n+        \"\"\"\n+        self.numIterations = numIterations\n+        return self\n+\n+    def setSeed(self, seed):\n+        \"\"\"\n+        Sets random seed (default: a random long integer).\n+        \"\"\"\n+        self.seed = seed\n+        return self\n+\n+    def fit(self, data):\n+        \"\"\"\n+        Computes the vector representation of each word in vocabulary.\n+\n+        :param data: training data."
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "remove unused code\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-10-06T21:19:16Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+from pyspark.serializers import PickleSerializer, AutoBatchedSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        \"\"\"\n+        :param word: a word\n+        :return: vector representation of word\n+\n+        Note: local use only\n+        TODO: make transform usable in RDD operations from python side\n+        \"\"\"\n+        result = self._java_model.transform(word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        \"\"\"\n+        :param x: a word or a vector representation of word\n+        :param num: number of synonyms to find\n+        :return: array of (word, cosineSimilarity)\n+\n+        Note: local use only\n+        TODO: make findSynonyms usable in RDD operations from python side\n+        \"\"\"\n+        ser = PickleSerializer()\n+        if type(x) == str:\n+            jlist = self._java_model.findSynonyms(x, num)\n+        else:\n+            bytes = bytearray(ser.dumps(_convert_to_vector(x)))\n+            vec = self._sc._jvm.SerDe.loads(bytes)\n+            jlist = self._java_model.findSynonyms(vec, num)\n+        words, similarity = ser.loads(str(self._sc._jvm.SerDe.dumps(jlist)))\n+        return zip(words, similarity)\n+\n+\n+class Word2Vec(object):\n+    \"\"\"\n+    Word2Vec creates vector representation of words in a text corpus.\n+    The algorithm first constructs a vocabulary from the corpus\n+    and then learns vector representation of words in the vocabulary.\n+    The vector representation can be used as features in\n+    natural language processing and machine learning algorithms.\n+\n+    We used skip-gram model in our implementation and hierarchical softmax\n+    method to train the model. The variable names in the implementation\n+    matches the original C implementation.\n+    For original C implementation, see https://code.google.com/p/word2vec/\n+    For research papers, see\n+    Efficient Estimation of Word Representations in Vector Space\n+    and\n+    Distributed Representations of Words and Phrases and their Compositionality.\n+\n+    >>> sentence = \"a b \" * 100 + \"a c \" * 10\n+    >>> localDoc = [sentence, sentence]\n+    >>> doc = sc.parallelize(localDoc).map(lambda line: line.split(\" \"))\n+    >>> model = Word2Vec().setVectorSize(10).setSeed(42L).fit(doc)\n+    >>> syms = model.findSynonyms(\"a\", 2)\n+    >>> str(syms[0][0])\n+    'b'\n+    >>> str(syms[1][0])\n+    'c'\n+    >>> len(syms)\n+    2\n+    >>> vec = model.transform(\"a\")\n+    >>> len(vec)\n+    10\n+    >>> syms = model.findSynonyms(vec, 2)\n+    >>> str(syms[0][0])\n+    'b'\n+    >>> str(syms[1][0])\n+    'c'\n+    >>> len(syms)\n+    2\n+    \"\"\"\n+    def __init__(self):\n+        \"\"\"\n+        Construct Word2Vec instance\n+        \"\"\"\n+        self.vectorSize = 100\n+        self.learningRate = 0.025\n+        self.numPartitions = 1\n+        self.numIterations = 1\n+        self.seed = 42L\n+\n+    def setVectorSize(self, vectorSize):\n+        \"\"\"\n+        Sets vector size (default: 100).\n+        \"\"\"\n+        self.vectorSize = vectorSize\n+        return self\n+\n+    def setLearningRate(self, learningRate):\n+        \"\"\"\n+        Sets initial learning rate (default: 0.025).\n+        \"\"\"\n+        self.learningRate = learningRate\n+        return self\n+\n+    def setNumPartitions(self, numPartitions):\n+        \"\"\"\n+        Sets number of partitions (default: 1). Use a small number for accuracy.\n+        \"\"\"\n+        self.numPartitions = numPartitions\n+        return self\n+\n+    def setNumIterations(self, numIterations):\n+        \"\"\"\n+        Sets number of iterations (default: 1), which should be smaller than or equal to number of\n+        partitions.\n+        \"\"\"\n+        self.numIterations = numIterations\n+        return self\n+\n+    def setSeed(self, seed):\n+        \"\"\"\n+        Sets random seed (default: a random long integer).\n+        \"\"\"\n+        self.seed = seed\n+        return self\n+\n+    def fit(self, data):\n+        \"\"\"\n+        Computes the vector representation of each word in vocabulary.\n+\n+        :param data: training data.\n+        :return: python Word2VecModel instance\n+        \"\"\"\n+        sc = data.context\n+        ser = PickleSerializer()\n+        vectorSize = self.vectorSize\n+        learningRate = self.learningRate\n+        numPartitions = self.numPartitions\n+        numIterations = self.numIterations\n+        seed = self.seed\n+\n+        # cached = data._reserialize(AutoBatchedSerializer(ser)).cache()"
  }],
  "prId": 2356
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "After we rename `Word2Vec.py` to `feature.py`, please add it to `python/run-tests.py` so it gets tested automatically.\n",
    "commit": "476ea34c9f576d425a05604f77cc3cab43fd5bae",
    "createdAt": "2014-10-06T21:20:58Z",
    "diffHunk": "@@ -0,0 +1,192 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Python package for Word2Vec in MLlib.\n+\"\"\"\n+from pyspark.serializers import PickleSerializer, AutoBatchedSerializer\n+\n+from pyspark.mllib.linalg import _convert_to_vector\n+\n+__all__ = ['Word2Vec', 'Word2VecModel']\n+\n+\n+class Word2VecModel(object):\n+    \"\"\"\n+    class for Word2Vec model\n+    \"\"\"\n+    def __init__(self, sc, java_model):\n+        \"\"\"\n+        :param sc:  Spark context\n+        :param java_model:  Handle to Java model object\n+        \"\"\"\n+        self._sc = sc\n+        self._java_model = java_model\n+\n+    def __del__(self):\n+        self._sc._gateway.detach(self._java_model)\n+\n+    def transform(self, word):\n+        \"\"\"\n+        :param word: a word\n+        :return: vector representation of word\n+\n+        Note: local use only\n+        TODO: make transform usable in RDD operations from python side\n+        \"\"\"\n+        result = self._java_model.transform(word)\n+        return PickleSerializer().loads(str(self._sc._jvm.SerDe.dumps(result)))\n+\n+    def findSynonyms(self, x, num):\n+        \"\"\"\n+        :param x: a word or a vector representation of word\n+        :param num: number of synonyms to find\n+        :return: array of (word, cosineSimilarity)\n+\n+        Note: local use only\n+        TODO: make findSynonyms usable in RDD operations from python side\n+        \"\"\"\n+        ser = PickleSerializer()\n+        if type(x) == str:\n+            jlist = self._java_model.findSynonyms(x, num)\n+        else:\n+            bytes = bytearray(ser.dumps(_convert_to_vector(x)))\n+            vec = self._sc._jvm.SerDe.loads(bytes)\n+            jlist = self._java_model.findSynonyms(vec, num)\n+        words, similarity = ser.loads(str(self._sc._jvm.SerDe.dumps(jlist)))\n+        return zip(words, similarity)\n+\n+\n+class Word2Vec(object):\n+    \"\"\"\n+    Word2Vec creates vector representation of words in a text corpus.\n+    The algorithm first constructs a vocabulary from the corpus\n+    and then learns vector representation of words in the vocabulary.\n+    The vector representation can be used as features in\n+    natural language processing and machine learning algorithms.\n+\n+    We used skip-gram model in our implementation and hierarchical softmax\n+    method to train the model. The variable names in the implementation\n+    matches the original C implementation.\n+    For original C implementation, see https://code.google.com/p/word2vec/\n+    For research papers, see\n+    Efficient Estimation of Word Representations in Vector Space\n+    and\n+    Distributed Representations of Words and Phrases and their Compositionality.\n+\n+    >>> sentence = \"a b \" * 100 + \"a c \" * 10\n+    >>> localDoc = [sentence, sentence]\n+    >>> doc = sc.parallelize(localDoc).map(lambda line: line.split(\" \"))\n+    >>> model = Word2Vec().setVectorSize(10).setSeed(42L).fit(doc)\n+    >>> syms = model.findSynonyms(\"a\", 2)\n+    >>> str(syms[0][0])\n+    'b'\n+    >>> str(syms[1][0])\n+    'c'\n+    >>> len(syms)\n+    2\n+    >>> vec = model.transform(\"a\")\n+    >>> len(vec)\n+    10\n+    >>> syms = model.findSynonyms(vec, 2)\n+    >>> str(syms[0][0])\n+    'b'\n+    >>> str(syms[1][0])\n+    'c'\n+    >>> len(syms)\n+    2\n+    \"\"\"\n+    def __init__(self):\n+        \"\"\"\n+        Construct Word2Vec instance\n+        \"\"\"\n+        self.vectorSize = 100\n+        self.learningRate = 0.025\n+        self.numPartitions = 1\n+        self.numIterations = 1\n+        self.seed = 42L\n+\n+    def setVectorSize(self, vectorSize):\n+        \"\"\"\n+        Sets vector size (default: 100).\n+        \"\"\"\n+        self.vectorSize = vectorSize\n+        return self\n+\n+    def setLearningRate(self, learningRate):\n+        \"\"\"\n+        Sets initial learning rate (default: 0.025).\n+        \"\"\"\n+        self.learningRate = learningRate\n+        return self\n+\n+    def setNumPartitions(self, numPartitions):\n+        \"\"\"\n+        Sets number of partitions (default: 1). Use a small number for accuracy.\n+        \"\"\"\n+        self.numPartitions = numPartitions\n+        return self\n+\n+    def setNumIterations(self, numIterations):\n+        \"\"\"\n+        Sets number of iterations (default: 1), which should be smaller than or equal to number of\n+        partitions.\n+        \"\"\"\n+        self.numIterations = numIterations\n+        return self\n+\n+    def setSeed(self, seed):\n+        \"\"\"\n+        Sets random seed (default: a random long integer).\n+        \"\"\"\n+        self.seed = seed\n+        return self\n+\n+    def fit(self, data):\n+        \"\"\"\n+        Computes the vector representation of each word in vocabulary.\n+\n+        :param data: training data.\n+        :return: python Word2VecModel instance\n+        \"\"\"\n+        sc = data.context\n+        ser = PickleSerializer()\n+        vectorSize = self.vectorSize\n+        learningRate = self.learningRate\n+        numPartitions = self.numPartitions\n+        numIterations = self.numIterations\n+        seed = self.seed\n+\n+        # cached = data._reserialize(AutoBatchedSerializer(ser)).cache()\n+        model = sc._jvm.PythonMLLibAPI().trainWord2Vec(\n+            data._to_java_object_rdd(), vectorSize,\n+            learningRate, numPartitions, numIterations, seed)\n+        return Word2VecModel(sc, model)\n+\n+\n+def _test():"
  }],
  "prId": 2356
}]