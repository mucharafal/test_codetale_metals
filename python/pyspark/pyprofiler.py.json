[{
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "These codes should be tested by doctest, do MyCustomProfiler should implemented here.\n",
    "commit": "0864b5d7edc420eff882dfb36f657cb8c286f358",
    "createdAt": "2014-11-13T21:42:05Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+PySpark supports custom profilers, this is to allow for different profilers to\n+be used as well as outputting to different formats than what is provided in the\n+BasicProfiler.\n+\n+The profiler class is chosen when creating L{SparkContext}:\n+NOTE: This has no effect if `spark.python.profile` is not set.\n+>>> from pyspark.context import SparkContext\n+>>> from pyspark.serializers import MarshalSerializer\n+>>> sc = SparkContext('local', 'test', profiler=MyCustomProfiler)"
  }],
  "prId": 3255
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "This class will become a public interface, could you add more doc for it?\n\nMaybe we could mark it as a developer API.\n",
    "commit": "0864b5d7edc420eff882dfb36f657cb8c286f358",
    "createdAt": "2014-11-13T21:43:41Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+PySpark supports custom profilers, this is to allow for different profilers to\n+be used as well as outputting to different formats than what is provided in the\n+BasicProfiler.\n+\n+The profiler class is chosen when creating L{SparkContext}:\n+NOTE: This has no effect if `spark.python.profile` is not set.\n+>>> from pyspark.context import SparkContext\n+>>> from pyspark.serializers import MarshalSerializer\n+>>> sc = SparkContext('local', 'test', profiler=MyCustomProfiler)\n+>>> sc.parallelize(list(range(1000))).map(lambda x: 2 * x).take(10)\n+[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n+>>> sc.show_profiles()\n+>>> sc.stop()\n+\n+\"\"\"\n+\n+\n+import cProfile\n+import pstats\n+import os\n+from pyspark.accumulators import PStatsParam\n+\n+\n+class BasicProfiler(object):"
  }],
  "prId": 3255
}]