[{
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "getClassByName is not used anywhere, please remove it.\n",
    "commit": "03f3e884d433eaa83c8573720d0b3262fadf36ae",
    "createdAt": "2015-01-27T20:02:47Z",
    "diffHunk": "@@ -0,0 +1,59 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+from py4j.java_gateway import java_import, Py4JError\n+\n+from pyspark.storagelevel import StorageLevel\n+from pyspark.serializers import PairDeserializer, NoOpSerializer\n+from pyspark.streaming import DStream\n+\n+__all__ = ['MQTTUtils']\n+\n+class MQTTUtils(object):\n+\n+    @staticmethod\n+    def createStream(ssc, topic, brokerUrl,\n+                     storageLevel=StorageLevel.MEMORY_AND_DISK_SER_2):\n+        \"\"\"\n+        Create an input stream that pulls messages from a Mqtt: Broker.\n+        :param ssc:  StreamingContext object\n+        :param brokerUrl:  Url of remote mqtt publisher\n+        :param topic:  topic name to subscribe to\n+        :param storageLevel:  RDD storage level.\n+        :return: A DStream object\n+        \"\"\"\n+        java_import(ssc._jvm, \"org.apache.spark.streaming.mqtt.MQTTUtils\")\n+\n+        jlevel = ssc._sc._getJavaStorageLevel(storageLevel)\n+\n+        def getClassByName(name):\n+            return ssc._jvm.org.apache.spark.util.Utils.classForName(name)"
  }],
  "prId": 4229
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "please keep the order of arguments as in Scala or docs\n",
    "commit": "03f3e884d433eaa83c8573720d0b3262fadf36ae",
    "createdAt": "2015-01-27T20:03:29Z",
    "diffHunk": "@@ -0,0 +1,59 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+from py4j.java_gateway import java_import, Py4JError\n+\n+from pyspark.storagelevel import StorageLevel\n+from pyspark.serializers import PairDeserializer, NoOpSerializer\n+from pyspark.streaming import DStream\n+\n+__all__ = ['MQTTUtils']\n+\n+class MQTTUtils(object):\n+\n+    @staticmethod\n+    def createStream(ssc, topic, brokerUrl,"
  }],
  "prId": 4229
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "So the DStream will be (str, str) in UTF-8? \n",
    "commit": "03f3e884d433eaa83c8573720d0b3262fadf36ae",
    "createdAt": "2015-02-04T18:25:03Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+from py4j.java_gateway import java_import, Py4JError\n+\n+from pyspark.storagelevel import StorageLevel\n+from pyspark.serializers import PairDeserializer, NoOpSerializer\n+from pyspark.streaming import DStream\n+\n+__all__ = ['MQTTUtils']\n+\n+\n+class MQTTUtils(object):\n+\n+    @staticmethod\n+    def createStream(ssc, brokerUrl, topic\n+                     storageLevel=StorageLevel.MEMORY_AND_DISK_SER_2):\n+        \"\"\"\n+        Create an input stream that pulls messages from a Mqtt Broker.\n+        :param ssc:  StreamingContext object\n+        :param brokerUrl:  Url of remote mqtt publisher\n+        :param topic:  topic name to subscribe to\n+        :param storageLevel:  RDD storage level.\n+        :return: A DStream object\n+        \"\"\"\n+        java_import(ssc._jvm, \"org.apache.spark.streaming.mqtt.MQTTUtils\")\n+\n+        jlevel = ssc._sc._getJavaStorageLevel(storageLevel)\n+\n+        try:\n+            jstream = ssc._jvm.MQTTUtils.createStream(ssc._jssc, brokerUrl, topic, jlevel)\n+\n+        except Py4JError, e:\n+            # TODO: use --jar once it also work on driver\n+            if not e.message or 'call a package' in e.message:\n+                print \"No Mqtt package, please put the assembly jar into classpath:\"\n+                print \" $ bin/spark-submit --driver-class-path external/mqtt-assembly/target/\" + \\\n+                      \"scala-*/spark-streaming-mqtt-assembly-*.jar\"\n+            raise e\n+        ser = PairDeserializer(NoOpSerializer(), NoOpSerializer())"
  }, {
    "author": {
      "login": "prabeesh"
    },
    "body": "(str) only\n",
    "commit": "03f3e884d433eaa83c8573720d0b3262fadf36ae",
    "createdAt": "2015-02-04T18:29:20Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+from py4j.java_gateway import java_import, Py4JError\n+\n+from pyspark.storagelevel import StorageLevel\n+from pyspark.serializers import PairDeserializer, NoOpSerializer\n+from pyspark.streaming import DStream\n+\n+__all__ = ['MQTTUtils']\n+\n+\n+class MQTTUtils(object):\n+\n+    @staticmethod\n+    def createStream(ssc, brokerUrl, topic\n+                     storageLevel=StorageLevel.MEMORY_AND_DISK_SER_2):\n+        \"\"\"\n+        Create an input stream that pulls messages from a Mqtt Broker.\n+        :param ssc:  StreamingContext object\n+        :param brokerUrl:  Url of remote mqtt publisher\n+        :param topic:  topic name to subscribe to\n+        :param storageLevel:  RDD storage level.\n+        :return: A DStream object\n+        \"\"\"\n+        java_import(ssc._jvm, \"org.apache.spark.streaming.mqtt.MQTTUtils\")\n+\n+        jlevel = ssc._sc._getJavaStorageLevel(storageLevel)\n+\n+        try:\n+            jstream = ssc._jvm.MQTTUtils.createStream(ssc._jssc, brokerUrl, topic, jlevel)\n+\n+        except Py4JError, e:\n+            # TODO: use --jar once it also work on driver\n+            if not e.message or 'call a package' in e.message:\n+                print \"No Mqtt package, please put the assembly jar into classpath:\"\n+                print \" $ bin/spark-submit --driver-class-path external/mqtt-assembly/target/\" + \\\n+                      \"scala-*/spark-streaming-mqtt-assembly-*.jar\"\n+            raise e\n+        ser = PairDeserializer(NoOpSerializer(), NoOpSerializer())"
  }, {
    "author": {
      "login": "davies"
    },
    "body": "Then the `ser` should be NoOpSerializer() or UTF8Deserializer(), not PairDeserializer()\n",
    "commit": "03f3e884d433eaa83c8573720d0b3262fadf36ae",
    "createdAt": "2015-02-04T18:36:02Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+from py4j.java_gateway import java_import, Py4JError\n+\n+from pyspark.storagelevel import StorageLevel\n+from pyspark.serializers import PairDeserializer, NoOpSerializer\n+from pyspark.streaming import DStream\n+\n+__all__ = ['MQTTUtils']\n+\n+\n+class MQTTUtils(object):\n+\n+    @staticmethod\n+    def createStream(ssc, brokerUrl, topic\n+                     storageLevel=StorageLevel.MEMORY_AND_DISK_SER_2):\n+        \"\"\"\n+        Create an input stream that pulls messages from a Mqtt Broker.\n+        :param ssc:  StreamingContext object\n+        :param brokerUrl:  Url of remote mqtt publisher\n+        :param topic:  topic name to subscribe to\n+        :param storageLevel:  RDD storage level.\n+        :return: A DStream object\n+        \"\"\"\n+        java_import(ssc._jvm, \"org.apache.spark.streaming.mqtt.MQTTUtils\")\n+\n+        jlevel = ssc._sc._getJavaStorageLevel(storageLevel)\n+\n+        try:\n+            jstream = ssc._jvm.MQTTUtils.createStream(ssc._jssc, brokerUrl, topic, jlevel)\n+\n+        except Py4JError, e:\n+            # TODO: use --jar once it also work on driver\n+            if not e.message or 'call a package' in e.message:\n+                print \"No Mqtt package, please put the assembly jar into classpath:\"\n+                print \" $ bin/spark-submit --driver-class-path external/mqtt-assembly/target/\" + \\\n+                      \"scala-*/spark-streaming-mqtt-assembly-*.jar\"\n+            raise e\n+        ser = PairDeserializer(NoOpSerializer(), NoOpSerializer())"
  }],
  "prId": 4229
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "nit: remove the extra empty line\n",
    "commit": "03f3e884d433eaa83c8573720d0b3262fadf36ae",
    "createdAt": "2015-06-22T10:26:49Z",
    "diffHunk": "@@ -0,0 +1,55 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+from py4j.java_gateway import java_import, Py4JError\n+\n+from pyspark.storagelevel import StorageLevel\n+from pyspark.serializers import UTF8Deserializer\n+from pyspark.streaming import DStream\n+\n+__all__ = ['MQTTUtils']\n+\n+\n+class MQTTUtils(object):\n+\n+    @staticmethod\n+    def createStream(ssc, brokerUrl, topic,\n+                     storageLevel=StorageLevel.MEMORY_AND_DISK_SER_2):\n+        \"\"\"\n+        Create an input stream that pulls messages from a Mqtt Broker.\n+        :param ssc:  StreamingContext object\n+        :param brokerUrl:  Url of remote mqtt publisher\n+        :param topic:  topic name to subscribe to\n+        :param storageLevel:  RDD storage level.\n+        :return: A DStream object\n+        \"\"\"\n+        java_import(ssc._jvm, \"org.apache.spark.streaming.mqtt.MQTTUtils\")\n+\n+        jlevel = ssc._sc._getJavaStorageLevel(storageLevel)\n+\n+        try:\n+            jstream = ssc._jvm.MQTTUtils.createStream(ssc._jssc, brokerUrl, topic, jlevel)\n+"
  }],
  "prId": 4229
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "It's incompatible with Python 3. Could you follow the latest `kafka.py` here: https://github.com/apache/spark/blob/1ecfac6e387b0934bfb5a9bbb4ad74b81ec210a4/python/pyspark/streaming/kafka.py#L168\n",
    "commit": "03f3e884d433eaa83c8573720d0b3262fadf36ae",
    "createdAt": "2015-06-22T10:46:21Z",
    "diffHunk": "@@ -0,0 +1,55 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from py4j.java_collections import MapConverter\n+from py4j.java_gateway import java_import, Py4JError\n+\n+from pyspark.storagelevel import StorageLevel\n+from pyspark.serializers import UTF8Deserializer\n+from pyspark.streaming import DStream\n+\n+__all__ = ['MQTTUtils']\n+\n+\n+class MQTTUtils(object):\n+\n+    @staticmethod\n+    def createStream(ssc, brokerUrl, topic,\n+                     storageLevel=StorageLevel.MEMORY_AND_DISK_SER_2):\n+        \"\"\"\n+        Create an input stream that pulls messages from a Mqtt Broker.\n+        :param ssc:  StreamingContext object\n+        :param brokerUrl:  Url of remote mqtt publisher\n+        :param topic:  topic name to subscribe to\n+        :param storageLevel:  RDD storage level.\n+        :return: A DStream object\n+        \"\"\"\n+        java_import(ssc._jvm, \"org.apache.spark.streaming.mqtt.MQTTUtils\")\n+\n+        jlevel = ssc._sc._getJavaStorageLevel(storageLevel)\n+\n+        try:\n+            jstream = ssc._jvm.MQTTUtils.createStream(ssc._jssc, brokerUrl, topic, jlevel)\n+\n+        except Py4JError, e:\n+            # TODO: use --jar once it also work on driver\n+            if not e.message or 'call a package' in e.message:\n+                print \"No Mqtt package, please put the assembly jar into classpath:\""
  }],
  "prId": 4229
}]