[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Otherwise, it prints out the exception too, for example:\r\n\r\n```\r\nWill test the following Python modules: ['pyspark-sql']\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nImportError: No module named foo\r\nPyArrow is not installed in Python executable 'python2.7', skipping related tests in 'pyspark-sql'.\r\n```",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-01T13:09:36Z",
    "diffHunk": "@@ -151,6 +151,38 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    if pyspark_sql in modules_to_test:\n+        # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+        # explicitly prints out. See SPARK-23300.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import pyarrow\"],\n+                stderr=open(os.devnull, 'w'))"
  }],
  "prId": 20473
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "How about we also explicitly mention that pyarrow/pandas related tests will run if they are installed?\r\n\r\n",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-01T18:26:08Z",
    "diffHunk": "@@ -151,6 +151,38 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    if pyspark_sql in modules_to_test:\n+        # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+        # explicitly prints out. See SPARK-23300.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import pyarrow\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:"
  }, {
    "author": {
      "login": "yhuai"
    },
    "body": "Actually, since we are here, is it possible to do the same thing as https://github.com/apache/spark/blob/ec63e2d0743a4f75e1cce21d0fe2b54407a86a4a/python/pyspark/sql/tests.py#L51-L63 and https://github.com/apache/spark/blob/ec63e2d0743a4f75e1cce21d0fe2b54407a86a4a/python/pyspark/sql/tests.py#L78-L84?\r\n\r\nIt will be nice to use the same logic. Otherwise, even we do not print the warning at here, tests may still get skipped because of the version issue.",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-01T18:28:45Z",
    "diffHunk": "@@ -151,6 +151,38 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    if pyspark_sql in modules_to_test:\n+        # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+        # explicitly prints out. See SPARK-23300.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import pyarrow\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Ah, hm. I believe we don't access to our main `pyspark` here. Let me check if I can address your concern today (or late tonight KST).",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-02T00:11:50Z",
    "diffHunk": "@@ -151,6 +151,38 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    if pyspark_sql in modules_to_test:\n+        # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+        # explicitly prints out. See SPARK-23300.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import pyarrow\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "https://github.com/apache/spark/pull/20473#discussion_r165445232 is easy but I think https://github.com/apache/spark/pull/20473#discussion_r165445947 makes things complicated.\r\n\r\nLet me try it to show how it looks like.",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-02T04:12:37Z",
    "diffHunk": "@@ -151,6 +151,38 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    if pyspark_sql in modules_to_test:\n+        # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+        # explicitly prints out. See SPARK-23300.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import pyarrow\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:"
  }, {
    "author": {
      "login": "yhuai"
    },
    "body": "Thank you. Appreciate it.",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-02T04:16:27Z",
    "diffHunk": "@@ -151,6 +151,38 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    if pyspark_sql in modules_to_test:\n+        # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+        # explicitly prints out. See SPARK-23300.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import pyarrow\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:"
  }],
  "prId": 20473
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I think I can't easily reuse `require_minimum_pandas_version` or `require_minimum_pyarrow_version` since it looks it's not guaranteed to access to our main `pyspark` here. I tries to address the comments at my best. Also updated PR description. Please check the logs above.",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-02T05:31:59Z",
    "diffHunk": "@@ -151,6 +152,61 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    if pyspark_sql in modules_to_test:\n+        # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+        # explicitly prints out. See SPARK-23300.\n+        try:\n+            pyarrow_version = subprocess_check_output(\n+                [python_exec, \"-c\", \"import pyarrow; print(pyarrow.__version__)\"],\n+                universal_newlines=True,\n+                stderr=open(os.devnull, 'w')).strip()\n+            if LooseVersion(pyarrow_version) >= LooseVersion('0.8.0'):"
  }],
  "prId": 20473
}, {
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "Let's have `0.8.0` as a variable in this file, or hopefully somewhere global if possible.",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-02T05:45:11Z",
    "diffHunk": "@@ -151,6 +152,61 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    if pyspark_sql in modules_to_test:\n+        # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+        # explicitly prints out. See SPARK-23300.\n+        try:\n+            pyarrow_version = subprocess_check_output(\n+                [python_exec, \"-c\", \"import pyarrow; print(pyarrow.__version__)\"],\n+                universal_newlines=True,\n+                stderr=open(os.devnull, 'w')).strip()\n+            if LooseVersion(pyarrow_version) >= LooseVersion('0.8.0'):"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "yup.",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-02T06:17:35Z",
    "diffHunk": "@@ -151,6 +152,61 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    if pyspark_sql in modules_to_test:\n+        # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+        # explicitly prints out. See SPARK-23300.\n+        try:\n+            pyarrow_version = subprocess_check_output(\n+                [python_exec, \"-c\", \"import pyarrow; print(pyarrow.__version__)\"],\n+                universal_newlines=True,\n+                stderr=open(os.devnull, 'w')).strip()\n+            if LooseVersion(pyarrow_version) >= LooseVersion('0.8.0'):"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Ah, hm .. I think I am not sure of a good place to put them as globals .. let me just make a variable here. Let me leave a comment there too.",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-02T06:36:22Z",
    "diffHunk": "@@ -151,6 +152,61 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    if pyspark_sql in modules_to_test:\n+        # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+        # explicitly prints out. See SPARK-23300.\n+        try:\n+            pyarrow_version = subprocess_check_output(\n+                [python_exec, \"-c\", \"import pyarrow; print(pyarrow.__version__)\"],\n+                universal_newlines=True,\n+                stderr=open(os.devnull, 'w')).strip()\n+            if LooseVersion(pyarrow_version) >= LooseVersion('0.8.0'):"
  }],
  "prId": 20473
}, {
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "ditto.",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-02T05:45:23Z",
    "diffHunk": "@@ -151,6 +152,61 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    if pyspark_sql in modules_to_test:\n+        # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+        # explicitly prints out. See SPARK-23300.\n+        try:\n+            pyarrow_version = subprocess_check_output(\n+                [python_exec, \"-c\", \"import pyarrow; print(pyarrow.__version__)\"],\n+                universal_newlines=True,\n+                stderr=open(os.devnull, 'w')).strip()\n+            if LooseVersion(pyarrow_version) >= LooseVersion('0.8.0'):\n+                LOGGER.info(\"Will test PyArrow related features against Python executable \"\n+                            \"'%s' in '%s' module.\" % (python_exec, pyspark_sql.name))\n+            else:\n+                LOGGER.warning(\n+                    \"Will skip PyArrow related features against Python executable \"\n+                    \"'%s' in '%s' module. PyArrow >= 0.8.0 is required; however, PyArrow \"\n+                    \"%s was found.\" % (python_exec, pyspark_sql.name, pyarrow_version))\n+        except:\n+            LOGGER.warning(\n+                \"Will skip PyArrow related features against Python executable \"\n+                \"'%s' in '%s' module. PyArrow >= 0.8.0 is required; however, PyArrow \"\n+                \"was not found.\" % (python_exec, pyspark_sql.name))\n+\n+        try:\n+            pandas_version = subprocess_check_output(\n+                [python_exec, \"-c\", \"import pandas; print(pandas.__version__)\"],\n+                universal_newlines=True,\n+                stderr=open(os.devnull, 'w')).strip()\n+            if LooseVersion(pandas_version) >= LooseVersion('0.19.2'):"
  }],
  "prId": 20473
}, {
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "that, I'd agree...",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-02T07:21:06Z",
    "diffHunk": "@@ -151,6 +152,68 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+    # explicitly prints out. See SPARK-23300.\n+    if pyspark_sql in modules_to_test:\n+        # Hyukjin: I think here is not the best place to leave versions for extra dependencies."
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "could we grep this https://github.com/apache/spark/blob/master/python/setup.py#L204",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-02T07:22:29Z",
    "diffHunk": "@@ -151,6 +152,68 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+    # explicitly prints out. See SPARK-23300.\n+    if pyspark_sql in modules_to_test:\n+        # Hyukjin: I think here is not the best place to leave versions for extra dependencies."
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Not sure .. I was thinking of putting this in `./dev/sparktestsupport/modules.py` too but .. I believe this should be done separately. We should replace these too:\r\n\r\nhttps://github.com/apache/spark/blob/12d20dd75b1620da362dbb5345bed58e47ddacb9/python/pyspark/sql/utils.py#L120\r\n\r\nhttps://github.com/apache/spark/blob/12d20dd75b1620da362dbb5345bed58e47ddacb9/python/pyspark/sql/utils.py#L130\r\n",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-02T07:26:46Z",
    "diffHunk": "@@ -151,6 +152,68 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+    # explicitly prints out. See SPARK-23300.\n+    if pyspark_sql in modules_to_test:\n+        # Hyukjin: I think here is not the best place to leave versions for extra dependencies."
  }],
  "prId": 20473
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "In the last commit,\r\n\r\n- I only replaced `minimal_pyarrow_version` -> `minimum_pyarrow_version` and `minimal_pandas_version` -> `minimum_pandas_version`\r\n\r\n- Replaced the comment to `# TODO(HyukjinKwon): Relocate and deduplicate these version specifications.`, to match it to https://github.com/apache/spark/pull/20487.",
    "commit": "78f5879a75c085ec558f26ba83d7334542623418",
    "createdAt": "2018-02-05T02:05:27Z",
    "diffHunk": "@@ -151,6 +152,67 @@ def parse_opts():\n     return opts\n \n \n+def _check_dependencies(python_exec, modules_to_test):\n+    if \"COVERAGE_PROCESS_START\" in os.environ:\n+        # Make sure if coverage is installed.\n+        try:\n+            subprocess_check_output(\n+                [python_exec, \"-c\", \"import coverage\"],\n+                stderr=open(os.devnull, 'w'))\n+        except:\n+            print_red(\"Coverage is not installed in Python executable '%s' \"\n+                      \"but 'COVERAGE_PROCESS_START' environment variable is set, \"\n+                      \"exiting.\" % python_exec)\n+            sys.exit(-1)\n+\n+    # If we should test 'pyspark-sql', it checks if PyArrow and Pandas are installed and\n+    # explicitly prints out. See SPARK-23300.\n+    if pyspark_sql in modules_to_test:\n+        # TODO(HyukjinKwon): Relocate and deduplicate these version specifications.\n+        minimum_pyarrow_version = '0.8.0'\n+        minimum_pandas_version = '0.19.2'",
    "line": 41
  }],
  "prId": 20473
}]