[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "From a design perspective, I think it makes more sense to move these conditionals out of the `run_*_tests` functions and into the `tests/default` script.\n",
    "commit": "e08f602c5f510132b313505fc4b7e704c901a8a8",
    "createdAt": "2015-06-18T21:24:26Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+# -*- coding: utf-8 -*-\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+function run_test() {\n+    echo -en \"Running test: $1 ... \" | tee -a $LOG_FILE\n+    start=$(date +\"%s\")\n+    SPARK_TESTING=1 time \"$FWDIR\"/bin/pyspark $1 > $LOG_FILE 2>&1\n+\n+    FAILED=$((PIPESTATUS[0]||$FAILED))\n+\n+    # Fail and exit on the first test failure.\n+    if [[ $FAILED != 0 ]]; then\n+        cat $LOG_FILE | grep -v \"^[0-9][0-9]*\" # filter all lines starting with a number.\n+        echo -en \"\\033[31m\"  # Red\n+        echo \"Had test failures; see logs.\"\n+        echo -en \"\\033[0m\"  # No color\n+        exit -1\n+    else\n+        now=$(date +\"%s\")\n+        echo \"ok ($(($now - $start))s)\"\n+    fi\n+}\n+\n+function run_core_tests() {\n+    if [ $DO_CORE_TESTS == 0 ]; then\n+        return 0\n+    fi\n+\n+    echo \"Run core tests ...\"\n+    run_test \"pyspark.rdd\"\n+    run_test \"pyspark.context\"\n+    run_test \"pyspark.conf\"\n+    run_test \"pyspark.broadcast\"\n+    run_test \"pyspark.accumulators\"\n+    run_test \"pyspark.serializers\"\n+    run_test \"pyspark.profiler\"\n+    run_test \"pyspark.shuffle\"\n+    run_test \"pyspark.tests\"\n+}\n+\n+function run_sql_tests() {\n+    if [ $DO_SQL_TESTS == 0 ]; then\n+        return 0\n+    fi\n+\n+    echo \"Run sql tests ...\"\n+    run_test \"pyspark.sql.types\"\n+    run_test \"pyspark.sql.context\"\n+    run_test \"pyspark.sql.column\"\n+    run_test \"pyspark.sql.dataframe\"\n+    run_test \"pyspark.sql.group\"\n+    run_test \"pyspark.sql.functions\"\n+    run_test \"pyspark.sql.readwriter\"\n+    run_test \"pyspark.sql.window\"\n+    run_test \"pyspark.sql.tests\"\n+}\n+\n+function run_mllib_tests() {\n+    if [ $DO_MLLIB_TESTS == 0 ]; then",
    "line": 73
  }, {
    "author": {
      "login": "potix2"
    },
    "body": "I think it is not good, because if we remove these conditions from here, we must put them into the `tests/default`, `tests/pypy.sh` and another runner script for a particular python version. @davies pointed out that.\n",
    "commit": "e08f602c5f510132b313505fc4b7e704c901a8a8",
    "createdAt": "2015-06-19T01:15:11Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+# -*- coding: utf-8 -*-\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+function run_test() {\n+    echo -en \"Running test: $1 ... \" | tee -a $LOG_FILE\n+    start=$(date +\"%s\")\n+    SPARK_TESTING=1 time \"$FWDIR\"/bin/pyspark $1 > $LOG_FILE 2>&1\n+\n+    FAILED=$((PIPESTATUS[0]||$FAILED))\n+\n+    # Fail and exit on the first test failure.\n+    if [[ $FAILED != 0 ]]; then\n+        cat $LOG_FILE | grep -v \"^[0-9][0-9]*\" # filter all lines starting with a number.\n+        echo -en \"\\033[31m\"  # Red\n+        echo \"Had test failures; see logs.\"\n+        echo -en \"\\033[0m\"  # No color\n+        exit -1\n+    else\n+        now=$(date +\"%s\")\n+        echo \"ok ($(($now - $start))s)\"\n+    fi\n+}\n+\n+function run_core_tests() {\n+    if [ $DO_CORE_TESTS == 0 ]; then\n+        return 0\n+    fi\n+\n+    echo \"Run core tests ...\"\n+    run_test \"pyspark.rdd\"\n+    run_test \"pyspark.context\"\n+    run_test \"pyspark.conf\"\n+    run_test \"pyspark.broadcast\"\n+    run_test \"pyspark.accumulators\"\n+    run_test \"pyspark.serializers\"\n+    run_test \"pyspark.profiler\"\n+    run_test \"pyspark.shuffle\"\n+    run_test \"pyspark.tests\"\n+}\n+\n+function run_sql_tests() {\n+    if [ $DO_SQL_TESTS == 0 ]; then\n+        return 0\n+    fi\n+\n+    echo \"Run sql tests ...\"\n+    run_test \"pyspark.sql.types\"\n+    run_test \"pyspark.sql.context\"\n+    run_test \"pyspark.sql.column\"\n+    run_test \"pyspark.sql.dataframe\"\n+    run_test \"pyspark.sql.group\"\n+    run_test \"pyspark.sql.functions\"\n+    run_test \"pyspark.sql.readwriter\"\n+    run_test \"pyspark.sql.window\"\n+    run_test \"pyspark.sql.tests\"\n+}\n+\n+function run_mllib_tests() {\n+    if [ $DO_MLLIB_TESTS == 0 ]; then",
    "line": 73
  }],
  "prId": 4269
}]