[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Can this also include a \"loss\" or \"compute\" method?  That would allow tracking the actual objective in boosting (instead of just MSE as is done now).\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-17T23:40:20Z",
    "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.loss\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+\n+/**\n+ * Trait for adding \"pluggable\" loss functions for the gradient boosting algorithm\n+ */\n+trait Loss extends Serializable {"
  }],
  "prId": 2607
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Can we name this \"gradient\"?  (Calling Loss.lossGradient seems redundant)\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-17T23:40:22Z",
    "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.loss\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+\n+/**\n+ * Trait for adding \"pluggable\" loss functions for the gradient boosting algorithm\n+ */\n+trait Loss extends Serializable {\n+\n+  /**\n+   * Method to calculate the loss gradients for the gradient boosting calculation\n+   * @param model Model of the weak learner\n+   * @param point Instance of the training dataset\n+   * @param learningRate Learning rate parameter for regularization\n+   * @return Loss gradient\n+   */\n+  @DeveloperApi\n+  def lossGradient("
  }, {
    "author": {
      "login": "manishamde"
    },
    "body": "negativeGradient might be better. What do you think?\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-20T02:11:44Z",
    "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.loss\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+\n+/**\n+ * Trait for adding \"pluggable\" loss functions for the gradient boosting algorithm\n+ */\n+trait Loss extends Serializable {\n+\n+  /**\n+   * Method to calculate the loss gradients for the gradient boosting calculation\n+   * @param model Model of the weak learner\n+   * @param point Instance of the training dataset\n+   * @param learningRate Learning rate parameter for regularization\n+   * @return Loss gradient\n+   */\n+  @DeveloperApi\n+  def lossGradient("
  }],
  "prId": 2607
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Could this please be renamed to \"gradient\" so it is less repetitive to call loss.lossGradient?\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-28T19:01:34Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.loss\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.RDD\n+\n+/**\n+ * Trait for adding \"pluggable\" loss functions for the gradient boosting algorithm.\n+ */\n+trait Loss extends Serializable {\n+\n+  /**\n+   * Method to calculate the loss gradients for the gradient boosting calculation.\n+   * @param model Model of the weak learner.\n+   * @param point Instance of the training dataset.\n+   * @param learningRate Learning rate parameter for regularization.\n+   * @return Loss gradient.\n+   */\n+  @DeveloperApi\n+  def lossGradient("
  }, {
    "author": {
      "login": "manishamde"
    },
    "body": "Technically negative of the gradient. I can rename it to gradient but it might be confusing.\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-28T19:21:52Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.loss\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.RDD\n+\n+/**\n+ * Trait for adding \"pluggable\" loss functions for the gradient boosting algorithm.\n+ */\n+trait Loss extends Serializable {\n+\n+  /**\n+   * Method to calculate the loss gradients for the gradient boosting calculation.\n+   * @param model Model of the weak learner.\n+   * @param point Instance of the training dataset.\n+   * @param learningRate Learning rate parameter for regularization.\n+   * @return Loss gradient.\n+   */\n+  @DeveloperApi\n+  def lossGradient("
  }],
  "prId": 2607
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Rename to \"compute\" or \"loss\"\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-28T19:01:41Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.loss\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.RDD\n+\n+/**\n+ * Trait for adding \"pluggable\" loss functions for the gradient boosting algorithm.\n+ */\n+trait Loss extends Serializable {\n+\n+  /**\n+   * Method to calculate the loss gradients for the gradient boosting calculation.\n+   * @param model Model of the weak learner.\n+   * @param point Instance of the training dataset.\n+   * @param learningRate Learning rate parameter for regularization.\n+   * @return Loss gradient.\n+   */\n+  @DeveloperApi\n+  def lossGradient(\n+      model: DecisionTreeModel,\n+      point: LabeledPoint,\n+      learningRate: Double): Double\n+\n+  /**\n+   * Method to calculate error of the base learner for the gradient boosting calculation.\n+   * Note: This method is not used by the gradient boosting algorithm but is useful for debugging\n+   * purposes.\n+   * @param model Model of the weak learner.\n+   * @param data Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @return\n+   */\n+  @DeveloperApi\n+  def computeError(model: DecisionTreeModel, data: RDD[LabeledPoint]): Double"
  }],
  "prId": 2607
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Since this is called gradient, could it please return the gradient instead of the negated gradient?  (And boosting can be updated accordingly.)\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-28T19:48:57Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.loss\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.RDD\n+\n+/**\n+ * Trait for adding \"pluggable\" loss functions for the gradient boosting algorithm.\n+ */\n+trait Loss extends Serializable {\n+\n+  /**\n+   * Method to calculate the loss gradients for the gradient boosting calculation.\n+   * @param model Model of the weak learner.\n+   * @param point Instance of the training dataset.\n+   * @param learningRate Learning rate parameter for regularization.\n+   * @return Loss gradient."
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "(just saw your other note; I vote for renaming to gradient, and making it actually return the gradient)\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-28T19:58:22Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.loss\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.RDD\n+\n+/**\n+ * Trait for adding \"pluggable\" loss functions for the gradient boosting algorithm.\n+ */\n+trait Loss extends Serializable {\n+\n+  /**\n+   * Method to calculate the loss gradients for the gradient boosting calculation.\n+   * @param model Model of the weak learner.\n+   * @param point Instance of the training dataset.\n+   * @param learningRate Learning rate parameter for regularization.\n+   * @return Loss gradient."
  }, {
    "author": {
      "login": "manishamde"
    },
    "body": "Sounds good. Agree.\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-28T20:04:22Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.loss\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.RDD\n+\n+/**\n+ * Trait for adding \"pluggable\" loss functions for the gradient boosting algorithm.\n+ */\n+trait Loss extends Serializable {\n+\n+  /**\n+   * Method to calculate the loss gradients for the gradient boosting calculation.\n+   * @param model Model of the weak learner.\n+   * @param point Instance of the training dataset.\n+   * @param learningRate Learning rate parameter for regularization.\n+   * @return Loss gradient."
  }],
  "prId": 2607
}]