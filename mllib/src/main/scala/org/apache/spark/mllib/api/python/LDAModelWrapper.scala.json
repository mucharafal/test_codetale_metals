[{
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "Serialize a DataFrame will trigger a Spark job, we could still use Pickle to serialize them without DataFrame, via `PythomMLLibAPI.dumps()`\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-02T17:50:18Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.api.java.JavaSparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(jsc: JavaSparkContext): DataFrame = describeTopics(this.model.vocabSize, jsc)\n+\n+  def describeTopics(maxTermsPerTopic: Int, jsc: JavaSparkContext): DataFrame = {\n+    // Since the return value of `describeTopics` is a little complicated,\n+    // it is converted into `Row` to take advantage of DataFrame serialization.\n+    val sqlContext = new SQLContext(jsc.sc)\n+    val topics = model.describeTopics(maxTermsPerTopic)\n+    sqlContext.createDataFrame(topics).toDF(\"terms\", \"termWeights\")"
  }, {
    "author": {
      "login": "yu-iskw"
    },
    "body": "@davies thanks for the comment. Should we rather `PythonMLlibAPI.dmups()` than Java Any types like below?\nhttps://github.com/yu-iskw/spark/commit/e1c66d050f7c4edbe1bf4e3b57b145cc62c23630#diff-71f42172be0b5fc14827b7bb31f4e80bR34\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-02T17:57:16Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.api.java.JavaSparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(jsc: JavaSparkContext): DataFrame = describeTopics(this.model.vocabSize, jsc)\n+\n+  def describeTopics(maxTermsPerTopic: Int, jsc: JavaSparkContext): DataFrame = {\n+    // Since the return value of `describeTopics` is a little complicated,\n+    // it is converted into `Row` to take advantage of DataFrame serialization.\n+    val sqlContext = new SQLContext(jsc.sc)\n+    val topics = model.describeTopics(maxTermsPerTopic)\n+    sqlContext.createDataFrame(topics).toDF(\"terms\", \"termWeights\")"
  }],
  "prId": 8643
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "nit: this line could be `Array[Any](terms, termWeights)`\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-03T06:52:38Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights"
  }],
  "prId": 8643
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "If the result is large, each element in the list will need an RPC call to get the data into Python, I'd prefer serialize the entire list in JVM first, then return Array[Byte], deserialize in Python.\n\nCould you benchmark the difference for larger `k`?\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-03T07:08:08Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights\n+      }.toSeq\n+    JavaConverters.seqAsJavaListConverter(seq).asJava"
  }, {
    "author": {
      "login": "yu-iskw"
    },
    "body": "@davies thank you for tha comment. Could you please give me more information about the type conversion?\n\nHow do we deserialize the return value in Python? Especially, I don't know how to deserialize `scala.Tuple2` in Python. I tried to serialize the entire list with `SerDe.dumps()` at `LDAModelWrapper.describeTopics()`, and then confirm the return value in Python. \nhttps://github.com/yu-iskw/spark/commit/54e5fda86ac3f3bac76b165615a0231d88a717aa\n\nThe testing result is as follow:\n\n```\n**********************************************************************\nFailed example:\n    model.describeTopics()\nExpected:\n    [([1, 0], [0.5..., 0.49...]), ([0, 1], [0.5..., 0.49...])]\nGot:\n    ({u'__class__': u'scala.Tuple2'}, {u'__class__': u'scala.Tuple2'})\n```\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-03T07:48:51Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights\n+      }.toSeq\n+    JavaConverters.seqAsJavaListConverter(seq).asJava"
  }, {
    "author": {
      "login": "davies"
    },
    "body": "Before call `SerDe.dumps()`, you still need to convert the Tuple2 into `Array[Any]()`\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-03T08:03:53Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights\n+      }.toSeq\n+    JavaConverters.seqAsJavaListConverter(seq).asJava"
  }, {
    "author": {
      "login": "yu-iskw"
    },
    "body": "Got it. I'll give it a try. Thanks!\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-03T08:19:58Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights\n+      }.toSeq\n+    JavaConverters.seqAsJavaListConverter(seq).asJava"
  }, {
    "author": {
      "login": "yu-iskw"
    },
    "body": "@davies could you give me a little bit help? I tried to serialize the entire list after converting into `Array[Any](...)`. And then, when deserializing it in Python, there was something wrong with pickle : `TypeError: must be a unicode character, not bytes`.\n- My patch\n  https://github.com/yu-iskw/spark/compare/SPARK-8467-2...yu-iskw:SPARK-8467-2.trial\n- unit testing errors\n  https://gist.github.com/yu-iskw/60e0db67b1e222fc7fd4\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-03T23:37:06Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights\n+      }.toSeq\n+    JavaConverters.seqAsJavaListConverter(seq).asJava"
  }, {
    "author": {
      "login": "yu-iskw"
    },
    "body": "ping @davies \n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-06T17:35:43Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights\n+      }.toSeq\n+    JavaConverters.seqAsJavaListConverter(seq).asJava"
  }, {
    "author": {
      "login": "yu-iskw"
    },
    "body": "I tried to test deserialization directly. It worked well. Why do we failed to deserialize the `describeTopics`'s return value...?\nhttps://gist.github.com/yu-iskw/22fb83895024a29ea048\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-06T18:16:55Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights\n+      }.toSeq\n+    JavaConverters.seqAsJavaListConverter(seq).asJava"
  }, {
    "author": {
      "login": "davies"
    },
    "body": "I think it failed in Python 3, you may need to specify the encoding:\n\n```\nr = PickleSerializer().loads(bytes(r), encoding=encoding)\n```\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-06T18:20:15Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights\n+      }.toSeq\n+    JavaConverters.seqAsJavaListConverter(seq).asJava"
  }, {
    "author": {
      "login": "yu-iskw"
    },
    "body": "Thanks! Let me think about it. Because python's mllib `call` doesn't have `encoding` option.\n\nSorry, one more thing, what is the difference between the two cases in this gist? When comparing the return value with `1`, It seems to be going well. However, when comparing with the expected value, it failed.\nhttps://gist.github.com/yu-iskw/59c66bb90d9311c0b408\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-06T18:42:22Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights\n+      }.toSeq\n+    JavaConverters.seqAsJavaListConverter(seq).asJava"
  }, {
    "author": {
      "login": "davies"
    },
    "body": "you could return this in Java :  \n\n```\nList<Array[Any](List<Int>, List<Double>))\n```\n\nThis could help to avoid the issue about deserialize array in Python 3\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-06T18:47:36Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights\n+      }.toSeq\n+    JavaConverters.seqAsJavaListConverter(seq).asJava"
  }, {
    "author": {
      "login": "yu-iskw"
    },
    "body": "Thanks! I did it!!\n",
    "commit": "e91c65aef57ae870b0ceb0970068cefcc1231198",
    "createdAt": "2015-11-06T20:41:54Z",
    "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.api.python\n+\n+import scala.collection.JavaConverters\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.mllib.clustering.LDAModel\n+import org.apache.spark.mllib.linalg.Matrix\n+\n+/**\n+ * Wrapper around LDAModel to provide helper methods in Python\n+ */\n+private[python] class LDAModelWrapper(model: LDAModel) {\n+\n+  def topicsMatrix(): Matrix = model.topicsMatrix\n+\n+  def vocabSize(): Int = model.vocabSize\n+\n+  def describeTopics(): java.util.List[Array[Any]] = describeTopics(this.model.vocabSize)\n+\n+  def describeTopics(maxTermsPerTopic: Int): java.util.List[Array[Any]] = {\n+\n+    val seq = model.describeTopics(maxTermsPerTopic).map { case (terms, termWeights) =>\n+        Array.empty[Any] ++ terms ++ termWeights\n+      }.toSeq\n+    JavaConverters.seqAsJavaListConverter(seq).asJava"
  }],
  "prId": 8643
}]