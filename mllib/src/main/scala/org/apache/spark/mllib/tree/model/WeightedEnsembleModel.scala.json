[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Please switch from \"learner\" to \"hypothesis\" since these are hypotheses produced by the learner.  I'd recommend:\n- baseLearners -> weakHypotheses\n- baseLearnerWeights -> weakHypothesisWeights\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-28T19:01:46Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.model\n+\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.configuration.Algo._\n+import org.apache.spark.mllib.tree.configuration.EnsembleCombiningStrategy._\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable\n+\n+@Experimental\n+class WeightedEnsembleModel(\n+    val baseLearners: Array[DecisionTreeModel],"
  }, {
    "author": {
      "login": "manishamde"
    },
    "body": "Sure. Will do.\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-28T19:20:20Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.model\n+\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.configuration.Algo._\n+import org.apache.spark.mllib.tree.configuration.EnsembleCombiningStrategy._\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable\n+\n+@Experimental\n+class WeightedEnsembleModel(\n+    val baseLearners: Array[DecisionTreeModel],"
  }],
  "prId": 2607
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Remember to remove (since you moved it to predictRaw)\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-28T19:01:49Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.model\n+\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.configuration.Algo._\n+import org.apache.spark.mllib.tree.configuration.EnsembleCombiningStrategy._\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable\n+\n+@Experimental\n+class WeightedEnsembleModel(\n+    val baseLearners: Array[DecisionTreeModel],\n+    val baseLearnerWeights: Array[Double],\n+    val algo: Algo,\n+    val combiningStrategy: EnsembleCombiningStrategy) extends Serializable {\n+\n+  require(numTrees > 0, s\"WeightedEnsembleModel cannot be created without base learners. Number \" +\n+    s\"of baselearners = $baseLearners\")\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictRaw(features: Vector): Double = {\n+    val treePredictions = baseLearners.map(learner => learner.predict(features))\n+    if (numTrees == 1){\n+      treePredictions(0)\n+    } else {\n+      var prediction = treePredictions(0)\n+      var index = 1\n+      while (index < numTrees) {\n+        prediction += baseLearnerWeights(index) * treePredictions(index)\n+        index += 1\n+      }\n+      prediction\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictBySumming(features: Vector): Double = {\n+    val treePredictions = baseLearners.map(learner => learner.predict(features))\n+    val rawPrediction = {"
  }],
  "prId": 2607
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Rename to numWeakHypotheses and keep?\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-28T19:01:51Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.model\n+\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.configuration.Algo._\n+import org.apache.spark.mllib.tree.configuration.EnsembleCombiningStrategy._\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable\n+\n+@Experimental\n+class WeightedEnsembleModel(\n+    val baseLearners: Array[DecisionTreeModel],\n+    val baseLearnerWeights: Array[Double],\n+    val algo: Algo,\n+    val combiningStrategy: EnsembleCombiningStrategy) extends Serializable {\n+\n+  require(numTrees > 0, s\"WeightedEnsembleModel cannot be created without base learners. Number \" +\n+    s\"of baselearners = $baseLearners\")\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictRaw(features: Vector): Double = {\n+    val treePredictions = baseLearners.map(learner => learner.predict(features))\n+    if (numTrees == 1){\n+      treePredictions(0)\n+    } else {\n+      var prediction = treePredictions(0)\n+      var index = 1\n+      while (index < numTrees) {\n+        prediction += baseLearnerWeights(index) * treePredictions(index)\n+        index += 1\n+      }\n+      prediction\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictBySumming(features: Vector): Double = {\n+    val treePredictions = baseLearners.map(learner => learner.predict(features))\n+    val rawPrediction = {\n+      if (numTrees == 1) {\n+        treePredictions(0)\n+      } else {\n+        var prediction = treePredictions(0)\n+        var index = 1\n+        while (index < numTrees) {\n+          prediction += baseLearnerWeights(index) * treePredictions(index)\n+          index += 1\n+        }\n+        prediction\n+      }\n+    }\n+    algo match {\n+      case Regression => predictRaw(features)\n+      case Classification => {\n+        // TODO: predicted labels are +1 or -1 for GBT. Need a better way to store this info.\n+        if (predictRaw(features) > 0 ) 1.0 else 0.0\n+      }\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown algo parameter: $algo.\")\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point.\n+   *\n+   * @param features array representing a single data point\n+   * @return Double prediction from the trained model\n+   */\n+  def predictByAveraging(features: Vector): Double = {\n+    algo match {\n+      case Classification =>\n+        val predictionToCount = new mutable.HashMap[Int, Int]()\n+        baseLearners.foreach { learner =>\n+          val prediction = learner.predict(features).toInt\n+          predictionToCount(prediction) = predictionToCount.getOrElse(prediction, 0) + 1\n+        }\n+        predictionToCount.maxBy(_._2)._1\n+      case Regression =>\n+        baseLearners.map(_.predict(features)).sum / baseLearners.size\n+    }\n+  }\n+\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  def predict(features: Vector): Double = {\n+    combiningStrategy match {\n+      case Sum => predictBySumming(features)\n+      case Average => predictByAveraging(features)\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown combining parameter: $combiningStrategy.\")\n+    }\n+  }\n+\n+  /**\n+   * Predict values for the given data set.\n+   *\n+   * @param features RDD representing data points to be predicted\n+   * @return RDD[Double] where each entry contains the corresponding prediction\n+   */\n+  def predict(features: RDD[Vector]): RDD[Double] = features.map(x => predict(x))\n+\n+  /**\n+   * Print full model.\n+   */\n+  override def toString: String = {\n+    val header = algo match {\n+      case Classification =>\n+        s\"WeightedEnsembleModel classifier with $numTrees trees\\n\"\n+      case Regression =>\n+        s\"WeightedEnsembleModel regressor with $numTrees trees\\n\"\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown algo parameter: $algo.\")\n+    }\n+    header + baseLearners.zipWithIndex.map { case (learner, treeIndex) =>\n+      s\"  Tree $treeIndex:\\n\" + learner.topNode.subtreeToString(4)\n+    }.fold(\"\")(_ + _)\n+  }\n+\n+  /**\n+   * Print the full model to a string.\n+   */\n+  def toDebugString: String = {\n+    val header = toString + \"\\n\"\n+    header + baseLearners.zipWithIndex.map { case (tree, treeIndex) =>\n+      s\"  Tree $treeIndex:\\n\" + tree.topNode.subtreeToString(4)\n+    }.fold(\"\")(_ + _)\n+  }\n+\n+\n+  // TODO: Remove these helpers methods once class is generalized to support any base learning\n+  // algorithms.\n+\n+  /**\n+   * Get number of trees in forest.\n+   */\n+  def numTrees: Int = baseLearners.size"
  }, {
    "author": {
      "login": "manishamde"
    },
    "body": "Agree.\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-28T19:17:19Z",
    "diffHunk": "@@ -0,0 +1,177 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.model\n+\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.configuration.Algo._\n+import org.apache.spark.mllib.tree.configuration.EnsembleCombiningStrategy._\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable\n+\n+@Experimental\n+class WeightedEnsembleModel(\n+    val baseLearners: Array[DecisionTreeModel],\n+    val baseLearnerWeights: Array[Double],\n+    val algo: Algo,\n+    val combiningStrategy: EnsembleCombiningStrategy) extends Serializable {\n+\n+  require(numTrees > 0, s\"WeightedEnsembleModel cannot be created without base learners. Number \" +\n+    s\"of baselearners = $baseLearners\")\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictRaw(features: Vector): Double = {\n+    val treePredictions = baseLearners.map(learner => learner.predict(features))\n+    if (numTrees == 1){\n+      treePredictions(0)\n+    } else {\n+      var prediction = treePredictions(0)\n+      var index = 1\n+      while (index < numTrees) {\n+        prediction += baseLearnerWeights(index) * treePredictions(index)\n+        index += 1\n+      }\n+      prediction\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictBySumming(features: Vector): Double = {\n+    val treePredictions = baseLearners.map(learner => learner.predict(features))\n+    val rawPrediction = {\n+      if (numTrees == 1) {\n+        treePredictions(0)\n+      } else {\n+        var prediction = treePredictions(0)\n+        var index = 1\n+        while (index < numTrees) {\n+          prediction += baseLearnerWeights(index) * treePredictions(index)\n+          index += 1\n+        }\n+        prediction\n+      }\n+    }\n+    algo match {\n+      case Regression => predictRaw(features)\n+      case Classification => {\n+        // TODO: predicted labels are +1 or -1 for GBT. Need a better way to store this info.\n+        if (predictRaw(features) > 0 ) 1.0 else 0.0\n+      }\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown algo parameter: $algo.\")\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point.\n+   *\n+   * @param features array representing a single data point\n+   * @return Double prediction from the trained model\n+   */\n+  def predictByAveraging(features: Vector): Double = {\n+    algo match {\n+      case Classification =>\n+        val predictionToCount = new mutable.HashMap[Int, Int]()\n+        baseLearners.foreach { learner =>\n+          val prediction = learner.predict(features).toInt\n+          predictionToCount(prediction) = predictionToCount.getOrElse(prediction, 0) + 1\n+        }\n+        predictionToCount.maxBy(_._2)._1\n+      case Regression =>\n+        baseLearners.map(_.predict(features)).sum / baseLearners.size\n+    }\n+  }\n+\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  def predict(features: Vector): Double = {\n+    combiningStrategy match {\n+      case Sum => predictBySumming(features)\n+      case Average => predictByAveraging(features)\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown combining parameter: $combiningStrategy.\")\n+    }\n+  }\n+\n+  /**\n+   * Predict values for the given data set.\n+   *\n+   * @param features RDD representing data points to be predicted\n+   * @return RDD[Double] where each entry contains the corresponding prediction\n+   */\n+  def predict(features: RDD[Vector]): RDD[Double] = features.map(x => predict(x))\n+\n+  /**\n+   * Print full model.\n+   */\n+  override def toString: String = {\n+    val header = algo match {\n+      case Classification =>\n+        s\"WeightedEnsembleModel classifier with $numTrees trees\\n\"\n+      case Regression =>\n+        s\"WeightedEnsembleModel regressor with $numTrees trees\\n\"\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown algo parameter: $algo.\")\n+    }\n+    header + baseLearners.zipWithIndex.map { case (learner, treeIndex) =>\n+      s\"  Tree $treeIndex:\\n\" + learner.topNode.subtreeToString(4)\n+    }.fold(\"\")(_ + _)\n+  }\n+\n+  /**\n+   * Print the full model to a string.\n+   */\n+  def toDebugString: String = {\n+    val header = toString + \"\\n\"\n+    header + baseLearners.zipWithIndex.map { case (tree, treeIndex) =>\n+      s\"  Tree $treeIndex:\\n\" + tree.topNode.subtreeToString(4)\n+    }.fold(\"\")(_ + _)\n+  }\n+\n+\n+  // TODO: Remove these helpers methods once class is generalized to support any base learning\n+  // algorithms.\n+\n+  /**\n+   * Get number of trees in forest.\n+   */\n+  def numTrees: Int = baseLearners.size"
  }],
  "prId": 2607
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "I don't think toString() should print the full model.  toString should be concise, and toDebugString should print the full model.\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-30T21:23:32Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.model\n+\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.configuration.Algo._\n+import org.apache.spark.mllib.tree.configuration.EnsembleCombiningStrategy._\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable\n+\n+@Experimental\n+class WeightedEnsembleModel(\n+    val weakHypotheses: Array[DecisionTreeModel],\n+    val weakHypothesisWeights: Array[Double],\n+    val algo: Algo,\n+    val combiningStrategy: EnsembleCombiningStrategy) extends Serializable {\n+\n+  require(numWeakHypotheses > 0, s\"WeightedEnsembleModel cannot be created without weakHypotheses\" +\n+    s\". Number of weakHypotheses = $weakHypotheses\")\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictRaw(features: Vector): Double = {\n+    val treePredictions = weakHypotheses.map(learner => learner.predict(features))\n+    if (numWeakHypotheses == 1){\n+      treePredictions(0)\n+    } else {\n+      var prediction = treePredictions(0)\n+      var index = 1\n+      while (index < numWeakHypotheses) {\n+        prediction += weakHypothesisWeights(index) * treePredictions(index)\n+        index += 1\n+      }\n+      prediction\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictBySumming(features: Vector): Double = {\n+    algo match {\n+      case Regression => predictRaw(features)\n+      case Classification => {\n+        // TODO: predicted labels are +1 or -1 for GBT. Need a better way to store this info.\n+        if (predictRaw(features) > 0 ) 1.0 else 0.0\n+      }\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown algo parameter: $algo.\")\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point.\n+   *\n+   * @param features array representing a single data point\n+   * @return Double prediction from the trained model\n+   */\n+  def predictByAveraging(features: Vector): Double = {\n+    algo match {\n+      case Classification =>\n+        val predictionToCount = new mutable.HashMap[Int, Int]()\n+        weakHypotheses.foreach { learner =>\n+          val prediction = learner.predict(features).toInt\n+          predictionToCount(prediction) = predictionToCount.getOrElse(prediction, 0) + 1\n+        }\n+        predictionToCount.maxBy(_._2)._1\n+      case Regression =>\n+        weakHypotheses.map(_.predict(features)).sum / weakHypotheses.size\n+    }\n+  }\n+\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  def predict(features: Vector): Double = {\n+    combiningStrategy match {\n+      case Sum => predictBySumming(features)\n+      case Average => predictByAveraging(features)\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown combining parameter: $combiningStrategy.\")\n+    }\n+  }\n+\n+  /**\n+   * Predict values for the given data set.\n+   *\n+   * @param features RDD representing data points to be predicted\n+   * @return RDD[Double] where each entry contains the corresponding prediction\n+   */\n+  def predict(features: RDD[Vector]): RDD[Double] = features.map(x => predict(x))\n+\n+  /**\n+   * Print full model.\n+   */\n+  override def toString: String = {\n+    val header = algo match {\n+      case Classification =>\n+        s\"WeightedEnsembleModel classifier with $numWeakHypotheses trees\\n\"\n+      case Regression =>\n+        s\"WeightedEnsembleModel regressor with $numWeakHypotheses trees\\n\"\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown algo parameter: $algo.\")\n+    }\n+    header + weakHypotheses.zipWithIndex.map { case (learner, treeIndex) =>"
  }, {
    "author": {
      "login": "manishamde"
    },
    "body": "Will do.\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-30T21:48:36Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.model\n+\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.configuration.Algo._\n+import org.apache.spark.mllib.tree.configuration.EnsembleCombiningStrategy._\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable\n+\n+@Experimental\n+class WeightedEnsembleModel(\n+    val weakHypotheses: Array[DecisionTreeModel],\n+    val weakHypothesisWeights: Array[Double],\n+    val algo: Algo,\n+    val combiningStrategy: EnsembleCombiningStrategy) extends Serializable {\n+\n+  require(numWeakHypotheses > 0, s\"WeightedEnsembleModel cannot be created without weakHypotheses\" +\n+    s\". Number of weakHypotheses = $weakHypotheses\")\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictRaw(features: Vector): Double = {\n+    val treePredictions = weakHypotheses.map(learner => learner.predict(features))\n+    if (numWeakHypotheses == 1){\n+      treePredictions(0)\n+    } else {\n+      var prediction = treePredictions(0)\n+      var index = 1\n+      while (index < numWeakHypotheses) {\n+        prediction += weakHypothesisWeights(index) * treePredictions(index)\n+        index += 1\n+      }\n+      prediction\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictBySumming(features: Vector): Double = {\n+    algo match {\n+      case Regression => predictRaw(features)\n+      case Classification => {\n+        // TODO: predicted labels are +1 or -1 for GBT. Need a better way to store this info.\n+        if (predictRaw(features) > 0 ) 1.0 else 0.0\n+      }\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown algo parameter: $algo.\")\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point.\n+   *\n+   * @param features array representing a single data point\n+   * @return Double prediction from the trained model\n+   */\n+  def predictByAveraging(features: Vector): Double = {\n+    algo match {\n+      case Classification =>\n+        val predictionToCount = new mutable.HashMap[Int, Int]()\n+        weakHypotheses.foreach { learner =>\n+          val prediction = learner.predict(features).toInt\n+          predictionToCount(prediction) = predictionToCount.getOrElse(prediction, 0) + 1\n+        }\n+        predictionToCount.maxBy(_._2)._1\n+      case Regression =>\n+        weakHypotheses.map(_.predict(features)).sum / weakHypotheses.size\n+    }\n+  }\n+\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  def predict(features: Vector): Double = {\n+    combiningStrategy match {\n+      case Sum => predictBySumming(features)\n+      case Average => predictByAveraging(features)\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown combining parameter: $combiningStrategy.\")\n+    }\n+  }\n+\n+  /**\n+   * Predict values for the given data set.\n+   *\n+   * @param features RDD representing data points to be predicted\n+   * @return RDD[Double] where each entry contains the corresponding prediction\n+   */\n+  def predict(features: RDD[Vector]): RDD[Double] = features.map(x => predict(x))\n+\n+  /**\n+   * Print full model.\n+   */\n+  override def toString: String = {\n+    val header = algo match {\n+      case Classification =>\n+        s\"WeightedEnsembleModel classifier with $numWeakHypotheses trees\\n\"\n+      case Regression =>\n+        s\"WeightedEnsembleModel regressor with $numWeakHypotheses trees\\n\"\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown algo parameter: $algo.\")\n+    }\n+    header + weakHypotheses.zipWithIndex.map { case (learner, treeIndex) =>"
  }],
  "prId": 2607
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "private\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-30T21:24:15Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.model\n+\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.configuration.Algo._\n+import org.apache.spark.mllib.tree.configuration.EnsembleCombiningStrategy._\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable\n+\n+@Experimental\n+class WeightedEnsembleModel(\n+    val weakHypotheses: Array[DecisionTreeModel],\n+    val weakHypothesisWeights: Array[Double],\n+    val algo: Algo,\n+    val combiningStrategy: EnsembleCombiningStrategy) extends Serializable {\n+\n+  require(numWeakHypotheses > 0, s\"WeightedEnsembleModel cannot be created without weakHypotheses\" +\n+    s\". Number of weakHypotheses = $weakHypotheses\")\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictRaw(features: Vector): Double = {\n+    val treePredictions = weakHypotheses.map(learner => learner.predict(features))\n+    if (numWeakHypotheses == 1){\n+      treePredictions(0)\n+    } else {\n+      var prediction = treePredictions(0)\n+      var index = 1\n+      while (index < numWeakHypotheses) {\n+        prediction += weakHypothesisWeights(index) * treePredictions(index)\n+        index += 1\n+      }\n+      prediction\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictBySumming(features: Vector): Double = {\n+    algo match {\n+      case Regression => predictRaw(features)\n+      case Classification => {\n+        // TODO: predicted labels are +1 or -1 for GBT. Need a better way to store this info.\n+        if (predictRaw(features) > 0 ) 1.0 else 0.0\n+      }\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown algo parameter: $algo.\")\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point.\n+   *\n+   * @param features array representing a single data point\n+   * @return Double prediction from the trained model\n+   */\n+  def predictByAveraging(features: Vector): Double = {"
  }, {
    "author": {
      "login": "manishamde"
    },
    "body": "will do.\n",
    "commit": "991c7b58f4648693e7b01ef756d032cc51980eec",
    "createdAt": "2014-10-30T21:48:44Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.model\n+\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.configuration.Algo._\n+import org.apache.spark.mllib.tree.configuration.EnsembleCombiningStrategy._\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable\n+\n+@Experimental\n+class WeightedEnsembleModel(\n+    val weakHypotheses: Array[DecisionTreeModel],\n+    val weakHypothesisWeights: Array[Double],\n+    val algo: Algo,\n+    val combiningStrategy: EnsembleCombiningStrategy) extends Serializable {\n+\n+  require(numWeakHypotheses > 0, s\"WeightedEnsembleModel cannot be created without weakHypotheses\" +\n+    s\". Number of weakHypotheses = $weakHypotheses\")\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictRaw(features: Vector): Double = {\n+    val treePredictions = weakHypotheses.map(learner => learner.predict(features))\n+    if (numWeakHypotheses == 1){\n+      treePredictions(0)\n+    } else {\n+      var prediction = treePredictions(0)\n+      var index = 1\n+      while (index < numWeakHypotheses) {\n+        prediction += weakHypothesisWeights(index) * treePredictions(index)\n+        index += 1\n+      }\n+      prediction\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point using the model trained.\n+   *\n+   * @param features array representing a single data point\n+   * @return predicted category from the trained model\n+   */\n+  private def predictBySumming(features: Vector): Double = {\n+    algo match {\n+      case Regression => predictRaw(features)\n+      case Classification => {\n+        // TODO: predicted labels are +1 or -1 for GBT. Need a better way to store this info.\n+        if (predictRaw(features) > 0 ) 1.0 else 0.0\n+      }\n+      case _ => throw new IllegalArgumentException(\n+        s\"WeightedEnsembleModel given unknown algo parameter: $algo.\")\n+    }\n+  }\n+\n+  /**\n+   * Predict values for a single data point.\n+   *\n+   * @param features array representing a single data point\n+   * @return Double prediction from the trained model\n+   */\n+  def predictByAveraging(features: Vector): Double = {"
  }],
  "prId": 2607
}]