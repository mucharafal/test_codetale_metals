[{
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "Why do we need F-bounded polymorphism here? Does the code not work when you replace `T` with `self.type`?\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-25T01:12:59Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+\n+trait StreamingDecay {\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+private[mllib] trait StreamingDecaySetter[T <: StreamingDecaySetter[T]] extends Logging {"
  }, {
    "author": {
      "login": "rotationsymmetry"
    },
    "body": "\"Does the code not work when you replace T with self.type?\"\n\nI guess not? For example, \n\n``` scala\ntrait Setter { def set: this.type = this}\nclass Apple extends Setter\nval a = new Apple()\na.set\n```\n\nThe return type of `a.set` is `a.type`, not `Apple`. Do I answer your question?\n\n\"Why do we need F-bounded polymorphism here?\"\nI agree with you that this is not needed here. Originally I included this as an extra level of type checking. But since I have `self: T=>` in the next line, I don't think we need it any more. I will remove it in the next push to the PR.\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-26T17:13:32Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+\n+trait StreamingDecay {\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+private[mllib] trait StreamingDecaySetter[T <: StreamingDecaySetter[T]] extends Logging {"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "Provide full scaladoc with `@params` for all public APIs\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-25T01:14:37Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+\n+trait StreamingDecay {\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+private[mllib] trait StreamingDecaySetter[T <: StreamingDecaySetter[T]] extends Logging {\n+  self: T =>\n+  var decayFactor: Double = 0\n+  var timeUnit: String = StreamingDecay.BATCHES\n+\n+  /** Set the decay factor directly (for forgetful algorithms). */\n+  def setDecayFactor(a: Double): T = {\n+    this.decayFactor = a\n+    this\n+  }\n+\n+  /** Set the half life and time unit (\"batches\" or \"points\") for forgetful algorithms. */"
  }, {
    "author": {
      "login": "rotationsymmetry"
    },
    "body": "Thanks! Will do. \n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-25T16:33:41Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+\n+trait StreamingDecay {\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+private[mllib] trait StreamingDecaySetter[T <: StreamingDecaySetter[T]] extends Logging {\n+  self: T =>\n+  var decayFactor: Double = 0\n+  var timeUnit: String = StreamingDecay.BATCHES\n+\n+  /** Set the decay factor directly (for forgetful algorithms). */\n+  def setDecayFactor(a: Double): T = {\n+    this.decayFactor = a\n+    this\n+  }\n+\n+  /** Set the half life and time unit (\"batches\" or \"points\") for forgetful algorithms. */"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "Scaladocs for public APIs\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-25T01:15:14Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+\n+trait StreamingDecay {\n+  def getDiscount(numNewDataPoints: Long): Double"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "Can these be private?\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-25T01:16:30Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+\n+trait StreamingDecay {\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+private[mllib] trait StreamingDecaySetter[T <: StreamingDecaySetter[T]] extends Logging {\n+  self: T =>\n+  var decayFactor: Double = 0\n+  var timeUnit: String = StreamingDecay.BATCHES"
  }, {
    "author": {
      "login": "rotationsymmetry"
    },
    "body": "I agree that the `StreamingDecay` trait can be `private[mllib]`. Will update this. \n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-25T16:34:57Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+\n+trait StreamingDecay {\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+private[mllib] trait StreamingDecaySetter[T <: StreamingDecaySetter[T]] extends Logging {\n+  self: T =>\n+  var decayFactor: Double = 0\n+  var timeUnit: String = StreamingDecay.BATCHES"
  }, {
    "author": {
      "login": "feynmanliang"
    },
    "body": "Oh didn't see that on L22, yeah I agree (thanks for catching :+1:)!\n\nWhat I meant here is that since you provide getters and setters for `decayFactor` and `timeUnit` in the trait, perhaps we could make the actual `var`s -> `private var`s to force users to use the getters / setters (and provide an additional level of indirection separating interface from implementation)\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-25T17:17:31Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+\n+trait StreamingDecay {\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+private[mllib] trait StreamingDecaySetter[T <: StreamingDecaySetter[T]] extends Logging {\n+  self: T =>\n+  var decayFactor: Double = 0\n+  var timeUnit: String = StreamingDecay.BATCHES"
  }, {
    "author": {
      "login": "rotationsymmetry"
    },
    "body": "Got it. That is a good point. I will make them private in my next push to the PR.\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-26T17:14:13Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+\n+trait StreamingDecay {\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+private[mllib] trait StreamingDecaySetter[T <: StreamingDecaySetter[T]] extends Logging {\n+  self: T =>\n+  var decayFactor: Double = 0\n+  var timeUnit: String = StreamingDecay.BATCHES"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "The formula for calculating `decayFactor` needs to be documented, as well as the behavior `decayFactor = 0` => online (i.e. only use current batch for weights) and `decayFactor -> \\infty` => model weights are fixed\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-25T01:17:34Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+\n+trait StreamingDecay {\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+private[mllib] trait StreamingDecaySetter[T <: StreamingDecaySetter[T]] extends Logging {\n+  self: T =>\n+  var decayFactor: Double = 0\n+  var timeUnit: String = StreamingDecay.BATCHES\n+\n+  /** Set the decay factor directly (for forgetful algorithms). */\n+  def setDecayFactor(a: Double): T = {\n+    this.decayFactor = a\n+    this\n+  }\n+\n+  /** Set the half life and time unit (\"batches\" or \"points\") for forgetful algorithms. */\n+  def setHalfLife(halfLife: Double, timeUnit: String): T = {\n+    if (timeUnit != StreamingDecay.BATCHES && timeUnit != StreamingDecay.POINTS) {\n+      throw new IllegalArgumentException(\"Invalid time unit for decay: \" + timeUnit)\n+    }\n+    this.decayFactor = math.exp(math.log(0.5) / halfLife)"
  }, {
    "author": {
      "login": "rotationsymmetry"
    },
    "body": "will include this in the ScalaDoc. Thanks!\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-25T16:36:03Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+\n+trait StreamingDecay {\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+private[mllib] trait StreamingDecaySetter[T <: StreamingDecaySetter[T]] extends Logging {\n+  self: T =>\n+  var decayFactor: Double = 0\n+  var timeUnit: String = StreamingDecay.BATCHES\n+\n+  /** Set the decay factor directly (for forgetful algorithms). */\n+  def setDecayFactor(a: Double): T = {\n+    this.decayFactor = a\n+    this\n+  }\n+\n+  /** Set the half life and time unit (\"batches\" or \"points\") for forgetful algorithms. */\n+  def setHalfLife(halfLife: Double, timeUnit: String): T = {\n+    if (timeUnit != StreamingDecay.BATCHES && timeUnit != StreamingDecay.POINTS) {\n+      throw new IllegalArgumentException(\"Invalid time unit for decay: \" + timeUnit)\n+    }\n+    this.decayFactor = math.exp(math.log(0.5) / halfLife)"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "\"[[StreamingDecaySetter]]\"\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-27T21:41:00Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T]."
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "`private[mllib]` (we can always relax to `private[spark]` if we need this trait in `ml` but not vice versa)\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-27T21:41:45Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T].\n+ */\n+@Experimental\n+trait StreamingDecay {"
  }, {
    "author": {
      "login": "feynmanliang"
    },
    "body": "Actually, do we plan on adding more `StreamingDecay` implementations soon? If not, I would suggest denormalizing and just having a single trait rather than this hierarchy\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-27T21:47:42Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T].\n+ */\n+@Experimental\n+trait StreamingDecay {"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "If `StreamingDecaySetter` implements `StreamingDecay` like L27 says, then this should be `trait StreamingDecaySetter[T] extends StreamingDecay with Logging`\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-27T21:43:29Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T].\n+ */\n+@Experimental\n+trait StreamingDecay {\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * StreamingDecaySetter provides the concrete implementation\n+ * of getDiscount in StreamingDecay and setters for decay factor\n+ * and half-life.\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecaySetter[T] extends Logging {"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "keep self type annotation on L47\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-27T21:43:41Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T].\n+ */\n+@Experimental\n+trait StreamingDecay {\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * StreamingDecaySetter provides the concrete implementation\n+ * of getDiscount in StreamingDecay and setters for decay factor\n+ * and half-life.\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecaySetter[T] extends Logging {\n+  self: T =>"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "I don't think we need to add reference to companion object since it doesn't add any information (plus, I want to make the companion package private)\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-27T21:45:14Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T].\n+ */\n+@Experimental\n+trait StreamingDecay {\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * StreamingDecaySetter provides the concrete implementation\n+ * of getDiscount in StreamingDecay and setters for decay factor\n+ * and half-life.\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecaySetter[T] extends Logging {\n+  self: T =>\n+  private var decayFactor: Double = 0\n+  private var timeUnit: String = StreamingDecay.BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): T = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+\n+\n+  /**\n+   * Set the half life and time unit (\"batches\" or \"points\") for the forgetful algorithm.\n+   * The half life along with the time unit provides an alternative way to specify decay factor.\n+   * The decay factor is calculated such that, for data acquired at time t,\n+   * its contribution by time t + halfLife will have dropped to 0.5.\n+   * The unit of time can be specified either as batches or points;\n+   * see StreamingDecay companion object."
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "Can this be `private[mllib]`?\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-27T21:45:28Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T].\n+ */\n+@Experimental\n+trait StreamingDecay {\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * StreamingDecaySetter provides the concrete implementation\n+ * of getDiscount in StreamingDecay and setters for decay factor\n+ * and half-life.\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecaySetter[T] extends Logging {\n+  self: T =>\n+  private var decayFactor: Double = 0\n+  private var timeUnit: String = StreamingDecay.BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): T = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+\n+\n+  /**\n+   * Set the half life and time unit (\"batches\" or \"points\") for the forgetful algorithm.\n+   * The half life along with the time unit provides an alternative way to specify decay factor.\n+   * The decay factor is calculated such that, for data acquired at time t,\n+   * its contribution by time t + halfLife will have dropped to 0.5.\n+   * The unit of time can be specified either as batches or points;\n+   * see StreamingDecay companion object.\n+   *\n+   * @param halfLife the half life\n+   * @param timeUnit the time unit\n+   */\n+  def setHalfLife(halfLife: Double, timeUnit: String): T = {\n+    if (timeUnit != StreamingDecay.BATCHES && timeUnit != StreamingDecay.POINTS) {\n+      throw new IllegalArgumentException(\"Invalid time unit for decay: \" + timeUnit)\n+    }\n+    this.decayFactor = math.exp(math.log(0.5) / halfLife)\n+    logInfo(\"Setting decay factor to: %g \".format (this.decayFactor))\n+    this.timeUnit = timeUnit\n+    this\n+  }\n+\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double = timeUnit match {\n+    case StreamingDecay.BATCHES => decayFactor\n+    case StreamingDecay.POINTS => math.pow(decayFactor, numNewDataPoints)\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Provides the String constants for allowed time unit in the forgetful algorithm.\n+ */\n+@Experimental\n+object StreamingDecay {"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "nit: \"dropped to 0.5\" -> \"dropped by 0.5\"\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-27T21:46:16Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T].\n+ */\n+@Experimental\n+trait StreamingDecay {\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * StreamingDecaySetter provides the concrete implementation\n+ * of getDiscount in StreamingDecay and setters for decay factor\n+ * and half-life.\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecaySetter[T] extends Logging {\n+  self: T =>\n+  private var decayFactor: Double = 0\n+  private var timeUnit: String = StreamingDecay.BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): T = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+\n+\n+  /**\n+   * Set the half life and time unit (\"batches\" or \"points\") for the forgetful algorithm.\n+   * The half life along with the time unit provides an alternative way to specify decay factor.\n+   * The decay factor is calculated such that, for data acquired at time t,\n+   * its contribution by time t + halfLife will have dropped to 0.5."
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "Looks like you're trying to get an enum-like thing here using strings? I would tend to favor case objects in this case, something like\n\n``` scala\nobject StreamingDecay {\n  sealed trait TimeUnit\n  case object BATCHES extends TimeUnit\n  case object POINTS extends TimeUnit\n}\n```\n\nand then use `StreamingDecay.TimeUnit` instead of `String` for the type\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-27T21:51:32Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T].\n+ */\n+@Experimental\n+trait StreamingDecay {\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * StreamingDecaySetter provides the concrete implementation\n+ * of getDiscount in StreamingDecay and setters for decay factor\n+ * and half-life.\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecaySetter[T] extends Logging {\n+  self: T =>\n+  private var decayFactor: Double = 0\n+  private var timeUnit: String = StreamingDecay.BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): T = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+\n+\n+  /**\n+   * Set the half life and time unit (\"batches\" or \"points\") for the forgetful algorithm.\n+   * The half life along with the time unit provides an alternative way to specify decay factor.\n+   * The decay factor is calculated such that, for data acquired at time t,\n+   * its contribution by time t + halfLife will have dropped to 0.5.\n+   * The unit of time can be specified either as batches or points;\n+   * see StreamingDecay companion object.\n+   *\n+   * @param halfLife the half life\n+   * @param timeUnit the time unit\n+   */\n+  def setHalfLife(halfLife: Double, timeUnit: String): T = {\n+    if (timeUnit != StreamingDecay.BATCHES && timeUnit != StreamingDecay.POINTS) {\n+      throw new IllegalArgumentException(\"Invalid time unit for decay: \" + timeUnit)\n+    }\n+    this.decayFactor = math.exp(math.log(0.5) / halfLife)\n+    logInfo(\"Setting decay factor to: %g \".format (this.decayFactor))\n+    this.timeUnit = timeUnit\n+    this\n+  }\n+\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double = timeUnit match {\n+    case StreamingDecay.BATCHES => decayFactor\n+    case StreamingDecay.POINTS => math.pow(decayFactor, numNewDataPoints)\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Provides the String constants for allowed time unit in the forgetful algorithm.\n+ */\n+@Experimental\n+object StreamingDecay {\n+  /**\n+   * Each RDD in the DStream will be treated as 1 time unit.\n+   *\n+   */\n+  final val BATCHES = \"batches\""
  }, {
    "author": {
      "login": "rotationsymmetry"
    },
    "body": "I am all for this approach because if offers much higher type safety and the IDE goodies. \n\nThe reason I have the `String` implementation is to follow [StreamingKMeans](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.StreamingKMeans). \n\nShall we consolidate StreamingKMeans to use case object? If so, I will open a JIRA for that.\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-28T00:51:03Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T].\n+ */\n+@Experimental\n+trait StreamingDecay {\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * StreamingDecaySetter provides the concrete implementation\n+ * of getDiscount in StreamingDecay and setters for decay factor\n+ * and half-life.\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecaySetter[T] extends Logging {\n+  self: T =>\n+  private var decayFactor: Double = 0\n+  private var timeUnit: String = StreamingDecay.BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): T = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+\n+\n+  /**\n+   * Set the half life and time unit (\"batches\" or \"points\") for the forgetful algorithm.\n+   * The half life along with the time unit provides an alternative way to specify decay factor.\n+   * The decay factor is calculated such that, for data acquired at time t,\n+   * its contribution by time t + halfLife will have dropped to 0.5.\n+   * The unit of time can be specified either as batches or points;\n+   * see StreamingDecay companion object.\n+   *\n+   * @param halfLife the half life\n+   * @param timeUnit the time unit\n+   */\n+  def setHalfLife(halfLife: Double, timeUnit: String): T = {\n+    if (timeUnit != StreamingDecay.BATCHES && timeUnit != StreamingDecay.POINTS) {\n+      throw new IllegalArgumentException(\"Invalid time unit for decay: \" + timeUnit)\n+    }\n+    this.decayFactor = math.exp(math.log(0.5) / halfLife)\n+    logInfo(\"Setting decay factor to: %g \".format (this.decayFactor))\n+    this.timeUnit = timeUnit\n+    this\n+  }\n+\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double = timeUnit match {\n+    case StreamingDecay.BATCHES => decayFactor\n+    case StreamingDecay.POINTS => math.pow(decayFactor, numNewDataPoints)\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Provides the String constants for allowed time unit in the forgetful algorithm.\n+ */\n+@Experimental\n+object StreamingDecay {\n+  /**\n+   * Each RDD in the DStream will be treated as 1 time unit.\n+   *\n+   */\n+  final val BATCHES = \"batches\""
  }, {
    "author": {
      "login": "feynmanliang"
    },
    "body": "I think that would be much better but it might be useful to ping whoever implemented the StreamingKMeans API first just to check if they did that for some particular reason that I am unaware of.\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-28T20:51:02Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T].\n+ */\n+@Experimental\n+trait StreamingDecay {\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * StreamingDecaySetter provides the concrete implementation\n+ * of getDiscount in StreamingDecay and setters for decay factor\n+ * and half-life.\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecaySetter[T] extends Logging {\n+  self: T =>\n+  private var decayFactor: Double = 0\n+  private var timeUnit: String = StreamingDecay.BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): T = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+\n+\n+  /**\n+   * Set the half life and time unit (\"batches\" or \"points\") for the forgetful algorithm.\n+   * The half life along with the time unit provides an alternative way to specify decay factor.\n+   * The decay factor is calculated such that, for data acquired at time t,\n+   * its contribution by time t + halfLife will have dropped to 0.5.\n+   * The unit of time can be specified either as batches or points;\n+   * see StreamingDecay companion object.\n+   *\n+   * @param halfLife the half life\n+   * @param timeUnit the time unit\n+   */\n+  def setHalfLife(halfLife: Double, timeUnit: String): T = {\n+    if (timeUnit != StreamingDecay.BATCHES && timeUnit != StreamingDecay.POINTS) {\n+      throw new IllegalArgumentException(\"Invalid time unit for decay: \" + timeUnit)\n+    }\n+    this.decayFactor = math.exp(math.log(0.5) / halfLife)\n+    logInfo(\"Setting decay factor to: %g \".format (this.decayFactor))\n+    this.timeUnit = timeUnit\n+    this\n+  }\n+\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double = timeUnit match {\n+    case StreamingDecay.BATCHES => decayFactor\n+    case StreamingDecay.POINTS => math.pow(decayFactor, numNewDataPoints)\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Provides the String constants for allowed time unit in the forgetful algorithm.\n+ */\n+@Experimental\n+object StreamingDecay {\n+  /**\n+   * Each RDD in the DStream will be treated as 1 time unit.\n+   *\n+   */\n+  final val BATCHES = \"batches\""
  }, {
    "author": {
      "login": "rotationsymmetry"
    },
    "body": "@freeman-lab : \n\n@feynmanliang and I are working on adding forgetful algorithm with decay factors to the streaming regressions. We would propose to implement case object for the time unit of half life in streaming algorithms. The case object approach will enhance type safety and readability. Currently `StreamingKMeans` uses `String` constant (\"BATCHES\", \"POINTS\") for the time unit.  Check if this proposal is OK with you? \n\nProposed case objects:\n\n``` scala\n  sealed trait TimeUnit\n  case object BATCHES extends TimeUnit\n  case object POINTS extends TimeUnit\n```\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-08-31T17:43:03Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+\n+/**\n+ * :: Experimental ::\n+ * Supplies an interface for the discount value in\n+ * the forgetful update rule in StreamingLinearAlgorithm.\n+ * Actual implementation is provided in StreamingDecaySetter[T].\n+ */\n+@Experimental\n+trait StreamingDecay {\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * StreamingDecaySetter provides the concrete implementation\n+ * of getDiscount in StreamingDecay and setters for decay factor\n+ * and half-life.\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecaySetter[T] extends Logging {\n+  self: T =>\n+  private var decayFactor: Double = 0\n+  private var timeUnit: String = StreamingDecay.BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): T = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+\n+\n+  /**\n+   * Set the half life and time unit (\"batches\" or \"points\") for the forgetful algorithm.\n+   * The half life along with the time unit provides an alternative way to specify decay factor.\n+   * The decay factor is calculated such that, for data acquired at time t,\n+   * its contribution by time t + halfLife will have dropped to 0.5.\n+   * The unit of time can be specified either as batches or points;\n+   * see StreamingDecay companion object.\n+   *\n+   * @param halfLife the half life\n+   * @param timeUnit the time unit\n+   */\n+  def setHalfLife(halfLife: Double, timeUnit: String): T = {\n+    if (timeUnit != StreamingDecay.BATCHES && timeUnit != StreamingDecay.POINTS) {\n+      throw new IllegalArgumentException(\"Invalid time unit for decay: \" + timeUnit)\n+    }\n+    this.decayFactor = math.exp(math.log(0.5) / halfLife)\n+    logInfo(\"Setting decay factor to: %g \".format (this.decayFactor))\n+    this.timeUnit = timeUnit\n+    this\n+  }\n+\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  def getDiscount(numNewDataPoints: Long): Double = timeUnit match {\n+    case StreamingDecay.BATCHES => decayFactor\n+    case StreamingDecay.POINTS => math.pow(decayFactor, numNewDataPoints)\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Provides the String constants for allowed time unit in the forgetful algorithm.\n+ */\n+@Experimental\n+object StreamingDecay {\n+  /**\n+   * Each RDD in the DStream will be treated as 1 time unit.\n+   *\n+   */\n+  final val BATCHES = \"batches\""
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "Extra newline\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-09-03T17:47:28Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.regression.StreamingDecay.{TimeUnit, BATCHES, POINTS}\n+\n+/**\n+ * :: Experimental ::\n+ * Supply the discount value for the\n+ * forgetful update rule in [[StreamingLinearAlgorithm]];\n+ * The degree of forgetfulness can be specified by the decay factor\n+ * or the half life.\n+ *\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecay extends Logging{\n+\n+  private[this] var decayFactor: Double = 0\n+  private[this] var timeUnit: TimeUnit = BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): this.type = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+",
    "line": 52
  }, {
    "author": {
      "login": "rotationsymmetry"
    },
    "body": "fixed.\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-09-04T02:41:38Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.regression.StreamingDecay.{TimeUnit, BATCHES, POINTS}\n+\n+/**\n+ * :: Experimental ::\n+ * Supply the discount value for the\n+ * forgetful update rule in [[StreamingLinearAlgorithm]];\n+ * The degree of forgetfulness can be specified by the decay factor\n+ * or the half life.\n+ *\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecay extends Logging{\n+\n+  private[this] var decayFactor: Double = 0\n+  private[this] var timeUnit: TimeUnit = BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): this.type = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+",
    "line": 52
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "Since these are part of public API, please add `@Since` annotations\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-09-03T17:49:00Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.regression.StreamingDecay.{TimeUnit, BATCHES, POINTS}\n+\n+/**\n+ * :: Experimental ::\n+ * Supply the discount value for the\n+ * forgetful update rule in [[StreamingLinearAlgorithm]];\n+ * The degree of forgetfulness can be specified by the decay factor\n+ * or the half life.\n+ *\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecay extends Logging{\n+\n+  private[this] var decayFactor: Double = 0\n+  private[this] var timeUnit: TimeUnit = BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): this.type = {"
  }, {
    "author": {
      "login": "feynmanliang"
    },
    "body": "We should also document default values for `decayFactor` and `timeUnit`\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-09-03T17:53:33Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.regression.StreamingDecay.{TimeUnit, BATCHES, POINTS}\n+\n+/**\n+ * :: Experimental ::\n+ * Supply the discount value for the\n+ * forgetful update rule in [[StreamingLinearAlgorithm]];\n+ * The degree of forgetfulness can be specified by the decay factor\n+ * or the half life.\n+ *\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecay extends Logging{\n+\n+  private[this] var decayFactor: Double = 0\n+  private[this] var timeUnit: TimeUnit = BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): this.type = {"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "This is only true if `TimeUnit = BATCHES`\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-09-03T17:59:10Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.regression.StreamingDecay.{TimeUnit, BATCHES, POINTS}\n+\n+/**\n+ * :: Experimental ::\n+ * Supply the discount value for the\n+ * forgetful update rule in [[StreamingLinearAlgorithm]];\n+ * The degree of forgetfulness can be specified by the decay factor\n+ * or the half life.\n+ *\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecay extends Logging{\n+\n+  private[this] var decayFactor: Double = 0\n+  private[this] var timeUnit: TimeUnit = BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used."
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "Since `timeUnit` affects the behavior `decayFactor` as well, what do you think about either:\n1. adding a `timeUnit` param to `decayFactor`\n2. removing the `timeUnit` param from `setHalfLife` and introducing a `setTimeUnit`\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-09-03T18:00:46Z",
    "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.regression.StreamingDecay.{TimeUnit, BATCHES, POINTS}\n+\n+/**\n+ * :: Experimental ::\n+ * Supply the discount value for the\n+ * forgetful update rule in [[StreamingLinearAlgorithm]];\n+ * The degree of forgetfulness can be specified by the decay factor\n+ * or the half life.\n+ *\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecay extends Logging{\n+\n+  private[this] var decayFactor: Double = 0\n+  private[this] var timeUnit: TimeUnit = BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor should be between 0 and 1, inclusive.\n+   * decayFactor = 0: only the data from the most recent RDD will be used.\n+   * decayFactor = 1: all data since the beginning of the DStream will be used.\n+   * decayFactor is default to zero.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  def setDecayFactor(decayFactor: Double): this.type = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+\n+\n+  /**\n+   * Set the half life and time unit (\"batches\" or \"points\") for the forgetful algorithm.\n+   * The half life along with the time unit provides an alternative way to specify decay factor.\n+   * The decay factor is calculated such that, for data acquired at time t,\n+   * its contribution by time t + halfLife will have dropped by 0.5.\n+   * The unit of time can be specified either as batches or points.\n+   *\n+   * @param halfLife the half life\n+   * @param timeUnit the time unit\n+   */\n+  def setHalfLife(halfLife: Double, timeUnit: TimeUnit): this.type = {\n+    this.decayFactor = math.exp(math.log(0.5) / halfLife)\n+    logInfo(\"Setting decay factor to: %g \".format (this.decayFactor))\n+    this.timeUnit = timeUnit\n+    this\n+  }\n+\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  private[mllib] def getDiscount(numNewDataPoints: Long): Double = timeUnit match {\n+    case BATCHES => decayFactor",
    "line": 90
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "just `private` is fine\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-09-05T03:03:41Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.{Since, Experimental}\n+import org.apache.spark.mllib.regression.StreamingDecay.{TimeUnit, BATCHES, POINTS}\n+\n+/**\n+ * :: Experimental ::\n+ * Supply the discount value for the\n+ * forgetful update rule in [[StreamingLinearAlgorithm]];\n+ * The degree of forgetfulness can be specified by the decay factor\n+ * or the half life.\n+ *\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecay extends Logging{\n+  private[this] var decayFactor: Double = 0"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "extra newline\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-09-05T03:05:11Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.{Since, Experimental}\n+import org.apache.spark.mllib.regression.StreamingDecay.{TimeUnit, BATCHES, POINTS}\n+\n+/**\n+ * :: Experimental ::\n+ * Supply the discount value for the\n+ * forgetful update rule in [[StreamingLinearAlgorithm]];\n+ * The degree of forgetfulness can be specified by the decay factor\n+ * or the half life.\n+ *\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecay extends Logging{\n+  private[this] var decayFactor: Double = 0\n+  private[this] var timeUnit: TimeUnit = BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor specifies the decay of\n+   * the contribution of data from time t-1 to time t.\n+   * Valid decayFactor ranges from 0 to 1, inclusive.\n+   * decayFactor = 0: previous data have no contribution to the model at the next time unit.\n+   * decayFactor = 1: previous data have equal contribution to the model as the data arriving\n+   * at the next time unit.\n+   * decayFactor is default to 0.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  @Since(\"1.6.0\")\n+  def setDecayFactor(decayFactor: Double): this.type = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+\n+  /**\n+   * Set the half life for the forgetful algorithm.\n+   * The half life provides an alternative way to specify decay factor.\n+   * The decay factor is calculated such that, for data acquired at time t,\n+   * its contribution by time t + halfLife will have dropped by 0.5.\n+   * Half life > 0 is considered as valid.\n+   *\n+   * @param halfLife the half life\n+   */\n+  @Since(\"1.6.0\")\n+  def setHalfLife(halfLife: Double): this.type = {\n+    this.decayFactor = math.exp(math.log(0.5) / halfLife)\n+    logInfo(\"Setting decay factor to: %g \".format (this.decayFactor))\n+    this\n+  }\n+\n+  /**\n+   * Set the time unit for the forgetful algorithm.\n+   * BATCHES: Each RDD in the DStream will be treated as 1 time unit.\n+   * POINTS: Each data point will be treated as 1 time unit.\n+   * timeUnit is default to BATCHES.\n+   *\n+   * @param timeUnit the time unit\n+   */\n+  @Since(\"1.6.0\")\n+  def setTimeUnit(timeUnit: TimeUnit): this.type = {\n+    this.timeUnit = timeUnit\n+    this\n+  }\n+\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  private[mllib] def getDiscount(numNewDataPoints: Long): Double = timeUnit match {\n+    case BATCHES => decayFactor\n+    case POINTS => math.pow(decayFactor, numNewDataPoints)\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Provides the String constants for allowed time unit in the forgetful algorithm.\n+ */\n+@Experimental\n+@Since(\"1.6.0\")\n+object StreamingDecay {\n+  private[mllib] sealed trait TimeUnit\n+  /**\n+   * Each RDD in the DStream will be treated as 1 time unit.\n+   *"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "Extra newline\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-09-05T03:05:16Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.{Since, Experimental}\n+import org.apache.spark.mllib.regression.StreamingDecay.{TimeUnit, BATCHES, POINTS}\n+\n+/**\n+ * :: Experimental ::\n+ * Supply the discount value for the\n+ * forgetful update rule in [[StreamingLinearAlgorithm]];\n+ * The degree of forgetfulness can be specified by the decay factor\n+ * or the half life.\n+ *\n+ */\n+@Experimental\n+private[mllib] trait StreamingDecay extends Logging{\n+  private[this] var decayFactor: Double = 0\n+  private[this] var timeUnit: TimeUnit = BATCHES\n+\n+  /**\n+   * Set the decay factor for the forgetful algorithms.\n+   * The decay factor specifies the decay of\n+   * the contribution of data from time t-1 to time t.\n+   * Valid decayFactor ranges from 0 to 1, inclusive.\n+   * decayFactor = 0: previous data have no contribution to the model at the next time unit.\n+   * decayFactor = 1: previous data have equal contribution to the model as the data arriving\n+   * at the next time unit.\n+   * decayFactor is default to 0.\n+   *\n+   * @param decayFactor the decay factor\n+   */\n+  @Since(\"1.6.0\")\n+  def setDecayFactor(decayFactor: Double): this.type = {\n+    this.decayFactor = decayFactor\n+    this\n+  }\n+\n+  /**\n+   * Set the half life for the forgetful algorithm.\n+   * The half life provides an alternative way to specify decay factor.\n+   * The decay factor is calculated such that, for data acquired at time t,\n+   * its contribution by time t + halfLife will have dropped by 0.5.\n+   * Half life > 0 is considered as valid.\n+   *\n+   * @param halfLife the half life\n+   */\n+  @Since(\"1.6.0\")\n+  def setHalfLife(halfLife: Double): this.type = {\n+    this.decayFactor = math.exp(math.log(0.5) / halfLife)\n+    logInfo(\"Setting decay factor to: %g \".format (this.decayFactor))\n+    this\n+  }\n+\n+  /**\n+   * Set the time unit for the forgetful algorithm.\n+   * BATCHES: Each RDD in the DStream will be treated as 1 time unit.\n+   * POINTS: Each data point will be treated as 1 time unit.\n+   * timeUnit is default to BATCHES.\n+   *\n+   * @param timeUnit the time unit\n+   */\n+  @Since(\"1.6.0\")\n+  def setTimeUnit(timeUnit: TimeUnit): this.type = {\n+    this.timeUnit = timeUnit\n+    this\n+  }\n+\n+  /**\n+   * Derive the discount factor.\n+   *\n+   * @param numNewDataPoints number of data points for the RDD arriving at time t.\n+   * @return Discount factor\n+   */\n+  private[mllib] def getDiscount(numNewDataPoints: Long): Double = timeUnit match {\n+    case BATCHES => decayFactor\n+    case POINTS => math.pow(decayFactor, numNewDataPoints)\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Provides the String constants for allowed time unit in the forgetful algorithm.\n+ */\n+@Experimental\n+@Since(\"1.6.0\")\n+object StreamingDecay {\n+  private[mllib] sealed trait TimeUnit\n+  /**\n+   * Each RDD in the DStream will be treated as 1 time unit.\n+   *\n+   */\n+  @Since(\"1.6.0\")\n+  case object BATCHES extends TimeUnit\n+  /**\n+   * Each data point will be treated as 1 time unit.\n+   *"
  }],
  "prId": 8022
}, {
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "Extra newline\n",
    "commit": "0072400825c0c4a871467a92799d12752fe96402",
    "createdAt": "2015-09-05T03:05:28Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.{Since, Experimental}\n+import org.apache.spark.mllib.regression.StreamingDecay.{TimeUnit, BATCHES, POINTS}\n+\n+/**\n+ * :: Experimental ::\n+ * Supply the discount value for the\n+ * forgetful update rule in [[StreamingLinearAlgorithm]];\n+ * The degree of forgetfulness can be specified by the decay factor\n+ * or the half life.\n+ *"
  }],
  "prId": 8022
}]