[{
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "First import  SparkContext, then you can use \ninput.map(l => l.label).mean()\ndirectly\n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T18:28:21Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(\n+       input : RDD[LabeledPoint],\n+       leaningRate : Double,\n+       countOfTrees : Int,\n+       samplingSizeRatio : Double,\n+       strategy: Strategy): StochasticGradientBoostingModel = {\n+\n+    val featureDimension = input.count()\n+    val mean = new DoubleRDDFunctions(input.map(l => l.label)).mean()",
    "line": 44
  }],
  "prId": 2394
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "DoubleRDDFunctions is not needed here\n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T18:28:45Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}",
    "line": 9
  }],
  "prId": 2394
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "How about TreeCount? \n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T18:29:35Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(\n+       input : RDD[LabeledPoint],\n+       leaningRate : Double,\n+       countOfTrees : Int,",
    "line": 39
  }],
  "prId": 2394
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "return this\n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T18:41:42Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(\n+       input : RDD[LabeledPoint],\n+       leaningRate : Double,\n+       countOfTrees : Int,\n+       samplingSizeRatio : Double,\n+       strategy: Strategy): StochasticGradientBoostingModel = {\n+\n+    val featureDimension = input.count()\n+    val mean = new DoubleRDDFunctions(input.map(l => l.label)).mean()\n+    val boostingModel = new StochasticGradientBoostingModel(countOfTrees, mean, leaningRate)\n+\n+    for (i <- 0 to countOfTrees - 1) {\n+      val gradient = input.map(l => l.label - boostingModel.computeValue(l.features))\n+\n+      val newInput: RDD[LabeledPoint] = input\n+        .zip(gradient)\n+        .map{case(inputVal, gradientVal) => new LabeledPoint(gradientVal, inputVal.features)}\n+\n+      val randomSample = newInput.sample(\n+        false,\n+        (samplingSizeRatio * featureDimension).asInstanceOf[Int],\n+        Random.nextInt()\n+      )\n+\n+      val model = DecisionTree.train(randomSample, strategy)\n+      boostingModel.addTree(model)\n+    }\n+    boostingModel\n+  }\n+}\n+\n+/**\n+ * Model that can be used for prediction.\n+ *\n+ * @param countOfTrees Number of trees.\n+ * @param initValue Initialize model with this value.\n+ * @param learningRate Learning rate.\n+ */\n+class StochasticGradientBoostingModel (\n+    private val countOfTrees: Int,\n+    private var initValue: Double,\n+    private val learningRate: Double) extends Serializable with RegressionModel {\n+\n+  val trees: Array[DecisionTreeModel] = new Array[DecisionTreeModel](countOfTrees)\n+  var index: Int = 0\n+\n+  def this(countOfTrees:Int, learning_rate: Double) = {\n+    this(countOfTrees, 0, learning_rate)\n+  }\n+\n+  def computeValue(feature_x: Vector): Double = {\n+    var re_res = initValue\n+\n+    if (index == 0) {\n+      return re_res\n+    }\n+    for (i <- 0 to index - 1) {\n+      re_res += learningRate * trees(i).predict(feature_x)\n+    }\n+    re_res\n+  }\n+\n+  def addTree(tree : DecisionTreeModel) = {\n+    trees(index) = tree\n+    index += 1\n+  }\n+\n+  def setInitValue (value : Double) = {\n+    initValue = value\n+  }",
    "line": 105
  }],
  "prId": 2394
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "Check whether index is out of bound\n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T18:42:18Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(\n+       input : RDD[LabeledPoint],\n+       leaningRate : Double,\n+       countOfTrees : Int,\n+       samplingSizeRatio : Double,\n+       strategy: Strategy): StochasticGradientBoostingModel = {\n+\n+    val featureDimension = input.count()\n+    val mean = new DoubleRDDFunctions(input.map(l => l.label)).mean()\n+    val boostingModel = new StochasticGradientBoostingModel(countOfTrees, mean, leaningRate)\n+\n+    for (i <- 0 to countOfTrees - 1) {\n+      val gradient = input.map(l => l.label - boostingModel.computeValue(l.features))\n+\n+      val newInput: RDD[LabeledPoint] = input\n+        .zip(gradient)\n+        .map{case(inputVal, gradientVal) => new LabeledPoint(gradientVal, inputVal.features)}\n+\n+      val randomSample = newInput.sample(\n+        false,\n+        (samplingSizeRatio * featureDimension).asInstanceOf[Int],\n+        Random.nextInt()\n+      )\n+\n+      val model = DecisionTree.train(randomSample, strategy)\n+      boostingModel.addTree(model)\n+    }\n+    boostingModel\n+  }\n+}\n+\n+/**\n+ * Model that can be used for prediction.\n+ *\n+ * @param countOfTrees Number of trees.\n+ * @param initValue Initialize model with this value.\n+ * @param learningRate Learning rate.\n+ */\n+class StochasticGradientBoostingModel (\n+    private val countOfTrees: Int,\n+    private var initValue: Double,\n+    private val learningRate: Double) extends Serializable with RegressionModel {\n+\n+  val trees: Array[DecisionTreeModel] = new Array[DecisionTreeModel](countOfTrees)\n+  var index: Int = 0\n+\n+  def this(countOfTrees:Int, learning_rate: Double) = {\n+    this(countOfTrees, 0, learning_rate)\n+  }\n+\n+  def computeValue(feature_x: Vector): Double = {\n+    var re_res = initValue\n+\n+    if (index == 0) {\n+      return re_res\n+    }\n+    for (i <- 0 to index - 1) {\n+      re_res += learningRate * trees(i).predict(feature_x)\n+    }\n+    re_res\n+  }\n+\n+  def addTree(tree : DecisionTreeModel) = {",
    "line": 98
  }],
  "prId": 2394
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "use while instead of for. while is faster in scala\n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T18:43:44Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(\n+       input : RDD[LabeledPoint],\n+       leaningRate : Double,\n+       countOfTrees : Int,\n+       samplingSizeRatio : Double,\n+       strategy: Strategy): StochasticGradientBoostingModel = {\n+\n+    val featureDimension = input.count()\n+    val mean = new DoubleRDDFunctions(input.map(l => l.label)).mean()\n+    val boostingModel = new StochasticGradientBoostingModel(countOfTrees, mean, leaningRate)\n+\n+    for (i <- 0 to countOfTrees - 1) {",
    "line": 47
  }],
  "prId": 2394
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "@mengxr Would it be better if cache input explicitly as it is used many times inside this function? \n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T18:46:39Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(\n+       input : RDD[LabeledPoint],\n+       leaningRate : Double,\n+       countOfTrees : Int,\n+       samplingSizeRatio : Double,\n+       strategy: Strategy): StochasticGradientBoostingModel = {\n+\n+    val featureDimension = input.count()\n+    val mean = new DoubleRDDFunctions(input.map(l => l.label)).mean()\n+    val boostingModel = new StochasticGradientBoostingModel(countOfTrees, mean, leaningRate)\n+\n+    for (i <- 0 to countOfTrees - 1) {\n+      val gradient = input.map(l => l.label - boostingModel.computeValue(l.features))",
    "line": 48
  }],
  "prId": 2394
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "change asInstanceOf[Int] to toInt\n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T18:47:42Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(\n+       input : RDD[LabeledPoint],\n+       leaningRate : Double,\n+       countOfTrees : Int,\n+       samplingSizeRatio : Double,\n+       strategy: Strategy): StochasticGradientBoostingModel = {\n+\n+    val featureDimension = input.count()\n+    val mean = new DoubleRDDFunctions(input.map(l => l.label)).mean()\n+    val boostingModel = new StochasticGradientBoostingModel(countOfTrees, mean, leaningRate)\n+\n+    for (i <- 0 to countOfTrees - 1) {\n+      val gradient = input.map(l => l.label - boostingModel.computeValue(l.features))\n+\n+      val newInput: RDD[LabeledPoint] = input\n+        .zip(gradient)\n+        .map{case(inputVal, gradientVal) => new LabeledPoint(gradientVal, inputVal.features)}\n+\n+      val randomSample = newInput.sample(\n+        false,\n+        (samplingSizeRatio * featureDimension).asInstanceOf[Int],",
    "line": 56
  }, {
    "author": {
      "login": "Ishiihara"
    },
    "body": "featureDimension is the number of instance? Probably we need a better name for it.  \n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T18:58:11Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(\n+       input : RDD[LabeledPoint],\n+       leaningRate : Double,\n+       countOfTrees : Int,\n+       samplingSizeRatio : Double,\n+       strategy: Strategy): StochasticGradientBoostingModel = {\n+\n+    val featureDimension = input.count()\n+    val mean = new DoubleRDDFunctions(input.map(l => l.label)).mean()\n+    val boostingModel = new StochasticGradientBoostingModel(countOfTrees, mean, leaningRate)\n+\n+    for (i <- 0 to countOfTrees - 1) {\n+      val gradient = input.map(l => l.label - boostingModel.computeValue(l.features))\n+\n+      val newInput: RDD[LabeledPoint] = input\n+        .zip(gradient)\n+        .map{case(inputVal, gradientVal) => new LabeledPoint(gradientVal, inputVal.features)}\n+\n+      val randomSample = newInput.sample(\n+        false,\n+        (samplingSizeRatio * featureDimension).asInstanceOf[Int],",
    "line": 56
  }],
  "prId": 2394
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "may be put run method under object StochasticGradientBoosting, the StochasticGradientBoosting class does not have any state in it.\n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T18:49:30Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(",
    "line": 36
  }],
  "prId": 2394
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "This is not feature dimension, rather, input.count() is the number of LabeledPoint in your RDD. if you would like to compute feature dimension, please use\ninput.take(1).features.length\n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T18:56:37Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(\n+       input : RDD[LabeledPoint],\n+       leaningRate : Double,\n+       countOfTrees : Int,\n+       samplingSizeRatio : Double,\n+       strategy: Strategy): StochasticGradientBoostingModel = {\n+\n+    val featureDimension = input.count()",
    "line": 43
  }],
  "prId": 2394
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "private \n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T19:01:44Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(\n+       input : RDD[LabeledPoint],\n+       leaningRate : Double,\n+       countOfTrees : Int,\n+       samplingSizeRatio : Double,\n+       strategy: Strategy): StochasticGradientBoostingModel = {\n+\n+    val featureDimension = input.count()\n+    val mean = new DoubleRDDFunctions(input.map(l => l.label)).mean()\n+    val boostingModel = new StochasticGradientBoostingModel(countOfTrees, mean, leaningRate)\n+\n+    for (i <- 0 to countOfTrees - 1) {\n+      val gradient = input.map(l => l.label - boostingModel.computeValue(l.features))\n+\n+      val newInput: RDD[LabeledPoint] = input\n+        .zip(gradient)\n+        .map{case(inputVal, gradientVal) => new LabeledPoint(gradientVal, inputVal.features)}\n+\n+      val randomSample = newInput.sample(\n+        false,\n+        (samplingSizeRatio * featureDimension).asInstanceOf[Int],\n+        Random.nextInt()\n+      )\n+\n+      val model = DecisionTree.train(randomSample, strategy)\n+      boostingModel.addTree(model)\n+    }\n+    boostingModel\n+  }\n+}\n+\n+/**\n+ * Model that can be used for prediction.\n+ *\n+ * @param countOfTrees Number of trees.\n+ * @param initValue Initialize model with this value.\n+ * @param learningRate Learning rate.\n+ */\n+class StochasticGradientBoostingModel (\n+    private val countOfTrees: Int,\n+    private var initValue: Double,\n+    private val learningRate: Double) extends Serializable with RegressionModel {\n+\n+  val trees: Array[DecisionTreeModel] = new Array[DecisionTreeModel](countOfTrees)",
    "line": 79
  }],
  "prId": 2394
}, {
  "comments": [{
    "author": {
      "login": "Ishiihara"
    },
    "body": "private\n",
    "commit": "4d90b46ca4515b93c46bc80f24bc63aa7d98810d",
    "createdAt": "2014-09-26T19:01:54Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.mllib.linalg.Vector\n+import org.apache.spark.mllib.tree.DecisionTree\n+import org.apache.spark.mllib.tree.configuration.Algo.Algo\n+import org.apache.spark.mllib.tree.configuration.Strategy\n+import org.apache.spark.mllib.tree.impurity.Impurity\n+import org.apache.spark.mllib.tree.model.DecisionTreeModel\n+import org.apache.spark.rdd.{DoubleRDDFunctions, RDD}\n+import scala.util.Random\n+\n+/**\n+ *\n+ * Read about the algorithm \"Gradient boosting\" here:\n+ * http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2007/GWD07/geurts-icml2007.pdf\n+ *\n+ * Libraries that implement the algorithm \"Gradient boosting\" similar way\n+ * https://code.google.com/p/jforests/\n+ * https://code.google.com/p/jsgbm/\n+ *\n+ */\n+class StochasticGradientBoosting {\n+\n+  /**\n+   * Train a Gradient Boosting model given an RDD of (label, features) pairs.\n+   *\n+   * @param input Training dataset: RDD of [[org.apache.spark.mllib.regression.LabeledPoint]].\n+   * @param leaningRate Learning rate\n+   * @param countOfTrees Number of trees.\n+   * @param samplingSizeRatio Size of random sample, percent of ${input} size.\n+   * @param strategy The configuration parameters for the tree algorithm which specify the type\n+   *                 of algorithm (classification, regression, etc.), feature type (continuous,\n+   *                 categorical), depth of the tree, quantile calculation strategy, etc.\n+   * @return StochasticGradientBoostingModel that can be used for prediction\n+   */\n+  def run(\n+       input : RDD[LabeledPoint],\n+       leaningRate : Double,\n+       countOfTrees : Int,\n+       samplingSizeRatio : Double,\n+       strategy: Strategy): StochasticGradientBoostingModel = {\n+\n+    val featureDimension = input.count()\n+    val mean = new DoubleRDDFunctions(input.map(l => l.label)).mean()\n+    val boostingModel = new StochasticGradientBoostingModel(countOfTrees, mean, leaningRate)\n+\n+    for (i <- 0 to countOfTrees - 1) {\n+      val gradient = input.map(l => l.label - boostingModel.computeValue(l.features))\n+\n+      val newInput: RDD[LabeledPoint] = input\n+        .zip(gradient)\n+        .map{case(inputVal, gradientVal) => new LabeledPoint(gradientVal, inputVal.features)}\n+\n+      val randomSample = newInput.sample(\n+        false,\n+        (samplingSizeRatio * featureDimension).asInstanceOf[Int],\n+        Random.nextInt()\n+      )\n+\n+      val model = DecisionTree.train(randomSample, strategy)\n+      boostingModel.addTree(model)\n+    }\n+    boostingModel\n+  }\n+}\n+\n+/**\n+ * Model that can be used for prediction.\n+ *\n+ * @param countOfTrees Number of trees.\n+ * @param initValue Initialize model with this value.\n+ * @param learningRate Learning rate.\n+ */\n+class StochasticGradientBoostingModel (\n+    private val countOfTrees: Int,\n+    private var initValue: Double,\n+    private val learningRate: Double) extends Serializable with RegressionModel {\n+\n+  val trees: Array[DecisionTreeModel] = new Array[DecisionTreeModel](countOfTrees)\n+  var index: Int = 0",
    "line": 80
  }],
  "prId": 2394
}]