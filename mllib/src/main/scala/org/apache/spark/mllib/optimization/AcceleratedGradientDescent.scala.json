[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "It is quite hard to choose a proper `stepSize` in practice, because it depends on the Lipschitz constant, which is usually unknown. It may be better if we can implement a line search method.\n",
    "commit": "a121bd0f6e5f2387bd502976940c08f6a4a2e4b1",
    "createdAt": "2015-03-06T22:57:29Z",
    "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import breeze.linalg.{DenseVector => BDV, norm}\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.rdd.RDD\n+\n+/**\n+ * :: DeveloperApi ::\n+ * This class optimizes a vector of weights via accelerated (proximal) gradient descent.\n+ * The implementation is based on TFOCS [[http://cvxr.com/tfocs]], described in Becker, Candes, and\n+ * Grant 2010.\n+ * @param gradient Delegate that computes the loss function value and gradient for a vector of\n+ *                 weights.\n+ * @param updater Delegate that updates weights in the direction of a gradient.\n+ */\n+@DeveloperApi\n+class AcceleratedGradientDescent (private var gradient: Gradient, private var updater: Updater)\n+  extends Optimizer {\n+\n+  private var stepSize: Double = 1.0\n+  private var convergenceTol: Double = 1e-4\n+  private var numIterations: Int = 100\n+  private var regParam: Double = 0.0\n+\n+  /**\n+   * Set the initial step size, used for the first step. Default 1.0.\n+   * On subsequent steps, the step size will be adjusted by the acceleration algorithm.\n+   */\n+  def setStepSize(step: Double): this.type = {",
    "line": 51
  }, {
    "author": {
      "login": "staple"
    },
    "body": "@mengxr Thanks for taking a look. I was advised by Reza Zadeh to implement a version without line search, at least for the initial implementation.\n\nPlease see discussion here: https://issues.apache.org/jira/browse/SPARK-1503?focusedCommentId=14225295, and in the following comments. I also attached some optimization benchmarks to the jira, which include performance of both backtracking line search and non line search implementations. Per your suggestion that it's hard to choose a proper stepSize I can attest that, anecdotally, acceleration seems somewhat more sensitive to diverging with nominal stepSize than the existing gradient descent.\n",
    "commit": "a121bd0f6e5f2387bd502976940c08f6a4a2e4b1",
    "createdAt": "2015-03-06T23:23:14Z",
    "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import breeze.linalg.{DenseVector => BDV, norm}\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.rdd.RDD\n+\n+/**\n+ * :: DeveloperApi ::\n+ * This class optimizes a vector of weights via accelerated (proximal) gradient descent.\n+ * The implementation is based on TFOCS [[http://cvxr.com/tfocs]], described in Becker, Candes, and\n+ * Grant 2010.\n+ * @param gradient Delegate that computes the loss function value and gradient for a vector of\n+ *                 weights.\n+ * @param updater Delegate that updates weights in the direction of a gradient.\n+ */\n+@DeveloperApi\n+class AcceleratedGradientDescent (private var gradient: Gradient, private var updater: Updater)\n+  extends Optimizer {\n+\n+  private var stepSize: Double = 1.0\n+  private var convergenceTol: Double = 1e-4\n+  private var numIterations: Int = 100\n+  private var regParam: Double = 0.0\n+\n+  /**\n+   * Set the initial step size, used for the first step. Default 1.0.\n+   * On subsequent steps, the step size will be adjusted by the acceleration algorithm.\n+   */\n+  def setStepSize(step: Double): this.type = {",
    "line": 51
  }],
  "prId": 4934
}, {
  "comments": [{
    "author": {
      "login": "staple"
    },
    "body": "Oops looks like a typo: 'avaialble'\n",
    "commit": "a121bd0f6e5f2387bd502976940c08f6a4a2e4b1",
    "createdAt": "2015-03-11T03:10:30Z",
    "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import breeze.linalg.{DenseVector => BDV, norm}\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.rdd.RDD\n+\n+/**\n+ * :: DeveloperApi ::\n+ * This class optimizes a vector of weights via accelerated (proximal) gradient descent.\n+ * The implementation is based on TFOCS [[http://cvxr.com/tfocs]], described in Becker, Candes, and\n+ * Grant 2010.\n+ * @param gradient Delegate that computes the loss function value and gradient for a vector of\n+ *                 weights.\n+ * @param updater Delegate that updates weights in the direction of a gradient.\n+ */\n+@DeveloperApi\n+class AcceleratedGradientDescent (private var gradient: Gradient, private var updater: Updater)\n+  extends Optimizer {\n+\n+  private var stepSize: Double = 1.0\n+  private var convergenceTol: Double = 1e-4\n+  private var numIterations: Int = 100\n+  private var regParam: Double = 0.0\n+\n+  /**\n+   * Set the initial step size, used for the first step. Default 1.0.\n+   * On subsequent steps, the step size will be adjusted by the acceleration algorithm.\n+   */\n+  def setStepSize(step: Double): this.type = {\n+    this.stepSize = step\n+    this\n+  }\n+\n+  /**\n+   * Set the optimization convergence tolerance. Default 1e-4.\n+   * Smaller values will increase accuracy but require additional iterations.\n+   */\n+  def setConvergenceTol(tol: Double): this.type = {\n+    this.convergenceTol = tol\n+    this\n+  }\n+\n+  /**\n+   * Set the maximum number of iterations. Default 100.\n+   */\n+  def setNumIterations(iters: Int): this.type = {\n+    this.numIterations = iters\n+    this\n+  }\n+\n+  /**\n+   * Set the regularization parameter. Default 0.0.\n+   */\n+  def setRegParam(regParam: Double): this.type = {\n+    this.regParam = regParam\n+    this\n+  }\n+\n+  /**\n+   * Set a Gradient delegate for computing the loss function value and gradient.\n+   */\n+  def setGradient(gradient: Gradient): this.type = {\n+    this.gradient = gradient\n+    this\n+  }\n+\n+  /**\n+   * Set an Updater delegate for updating weights in the direction of a gradient.\n+   * If regularization is used, the Updater will implement the regularization term's proximity\n+   * operator. Thus the type of regularization penalty is configured by providing a corresponding\n+   * Updater implementation.\n+   */\n+  def setUpdater(updater: Updater): this.type = {\n+    this.updater = updater\n+    this\n+  }\n+\n+  /**\n+   * Run accelerated gradient descent on the provided training data.\n+   * @param data training data\n+   * @param initialWeights initial weights\n+   * @return solution vector\n+   */\n+  def optimize(data: RDD[(Double, Vector)], initialWeights: Vector): Vector = {\n+    val (weights, _) = AcceleratedGradientDescent.run(\n+      data,\n+      gradient,\n+      updater,\n+      stepSize,\n+      convergenceTol,\n+      numIterations,\n+      regParam,\n+      initialWeights)\n+    weights\n+  }\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Top-level method to run accelerated (proximal) gradient descent.\n+ */\n+@DeveloperApi\n+object AcceleratedGradientDescent extends Logging {\n+  /**\n+   * Run accelerated proximal gradient descent.\n+   * The implementation is based on TFOCS [[http://cvxr.com/tfocs]], described in Becker, Candes,\n+   * and Grant 2010. A limited but useful subset of the TFOCS feature set is implemented, including\n+   * support for composite loss functions, the Auslender and Teboulle acceleration method, and\n+   * automatic restart using the gradient test. A global Lipschitz bound is supported in preference\n+   * to local Lipschitz estimation via backtracking. On each iteration, the loss function and\n+   * gradient are caclculated from the full training dataset, requiring one Spark map reduce.\n+   *\n+   * @param data Input data. RDD containing data examples of the form (label, [feature values]).\n+   * @param gradient Delegate that computes the loss function value and gradient for a vector of\n+                     weights (for one single data example).\n+   * @param updater Delegate that updates weights in the direction of a gradient.\n+   * @param stepSize Initial step size for the first step.\n+   * @param convergenceTol Tolerance for convergence of the optimization algorithm. When the norm of\n+   *                       the change in weight vectors between successive iterations falls below\n+   *                       this relative tolerance, optimization is complete.\n+   * @param numIterations Maximum number of iterations to run the algorithm.\n+   * @param regParam The regularization parameter.\n+   * @param initialWeights The initial weight values.\n+   *\n+   * @return A tuple containing two elements. The first element is a Vector containing the optimized\n+   *         weight for each feature, and the second element is an array containing the approximate\n+   *         loss computed on each iteration.\n+   */\n+  def run(\n+      data: RDD[(Double, Vector)],\n+      gradient: Gradient,\n+      updater: Updater,\n+      stepSize: Double,\n+      convergenceTol: Double,\n+      numIterations: Int,\n+      regParam: Double,\n+      initialWeights: Vector): (Vector, Array[Double]) = {\n+\n+    /** Returns the loss function and gradient for the provided weights 'x'. */\n+    def applySmooth(x: BDV[Double]): (Double, BDV[Double]) = {\n+      val bcX = data.context.broadcast(Vectors.fromBreeze(x))\n+\n+      // Sum the loss function and gradient computed for each training example.\n+      val (loss, grad, count) = data.treeAggregate((0.0, BDV.zeros[Double](x.size), 0L))(\n+        seqOp = (c, v) => (c, v) match { case ((loss, grad, count), (label, features)) =>\n+          val l = gradient.compute(features, label, bcX.value, Vectors.fromBreeze(grad))\n+          (loss + l, grad, count + 1)\n+        },\n+        combOp = (c1, c2) => (c1, c2) match {\n+          case ((loss1, grad1, count1), (loss2, grad2, count2)) =>\n+            (loss1 + loss2, grad1 += grad2, count1 + count2)\n+        })\n+\n+      // Divide the summed loss and gradient by the number of training examples.\n+      (loss / count, grad / (count: Double))\n+    }\n+\n+    /**\n+     * Returns the regularization loss and updates weights according to the gradient and the\n+     * proximity operator.\n+     */\n+    def applyProjector(x: BDV[Double], g: BDV[Double], step: Double): (Double, BDV[Double]) = {\n+      val (weights, regularization) = updater.compute(Vectors.fromBreeze(x),\n+                                                      Vectors.fromBreeze(g),\n+                                                      step,\n+                                                      iter = 1, // Passing 1 avoids step size\n+                                                                // rescaling within the updater.\n+                                                      regParam)\n+      (regularization, BDV[Double](weights.toArray))\n+    }\n+\n+    var x = BDV[Double](initialWeights.toArray)\n+    var z = x\n+    val L = 1.0 / stepSize // Infer a (global) Lipshitz bound from the provided stepSize.\n+    var theta = Double.PositiveInfinity\n+    var hasConverged = false\n+    val lossHistory = new ArrayBuffer[Double](numIterations)\n+\n+    for (i <- 1 to numIterations if !hasConverged) {\n+\n+      // Auslender and Teboulle's accelerated method.\n+      val (x_old, z_old) = (x, z)\n+      theta = 2.0 / (1.0 + math.sqrt(1.0 + 4.0 / (theta * theta)))\n+      val y = x_old * (1.0 - theta) + z_old * theta\n+      val (f_y, g_y) = applySmooth(y)\n+      val step = 1.0 / (theta * L)\n+      z = applyProjector(z_old, g_y, step)._2\n+      x = x_old * (1.0 - theta) + z * theta\n+      val d_x = x - x_old\n+\n+      // Track loss history using the loss function at y, since f_y is already avaialble and",
    "line": 213
  }],
  "prId": 4934
}]