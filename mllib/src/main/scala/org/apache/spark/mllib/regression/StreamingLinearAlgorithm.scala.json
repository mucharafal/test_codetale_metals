[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Somewhere it needs to be documented that ordering relationship of trainOn() and predictOn(). Should one be called before other? Can one be called after others?  Can any of them be called multiple times? What are the implications? If one is to be called only after another, then we will have to think about restricting it in the aPI itself (throw, error is ordering is wrong)?\n",
    "commit": "775ea29e53a7067ff6e143b455b49ddbb8553d94",
    "createdAt": "2014-08-01T17:39:39Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.dstream.DStream\n+\n+/**\n+ * :: DeveloperApi ::",
    "line": 25
  }, {
    "author": {
      "login": "freeman-lab"
    },
    "body": "I've been testing this and it seems fairly robust, agreed we should clarify in the documentation. \n\nWhat I've tried:\n- If train and predict are called on the same stream (or on two streams with data arriving simultaneously), order matters. If trainOn is first, the prediction will always use the subsequently updated model. If predictOn is first, it will use the model from the previous update. In practice, over multiple updates, either behavior seems reasonable, but maybe there should be a helpful warning if the user calls predictOn before trainOn?\n- If they are called on different streams and the data arrive sequentially, order doesn't matter. For example, if data arrive in the predictOn stream before the trainOn stream, the prediction uses the intial weights (as it should) to predict, regardless of the order of the calls.\n- It's ok, and maybe useful, to call predictOn repeatedly on different streams. For example, training on one stream, and predicting on it and another, behaves correctly (modolu the ordering issues described above).\n- If you call trainOn repeatedly on different streams, it will do an update when data arrive in either stream, which seems fine. Could be used to update using multiple input sources.\n",
    "commit": "775ea29e53a7067ff6e143b455b49ddbb8553d94",
    "createdAt": "2014-08-01T20:51:53Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.dstream.DStream\n+\n+/**\n+ * :: DeveloperApi ::",
    "line": 25
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Whoa this is quite a lot to grasp. \nI am not sure how in the second case the order doesnt matter. Gotta think about it.\n",
    "commit": "775ea29e53a7067ff6e143b455b49ddbb8553d94",
    "createdAt": "2014-08-01T20:58:50Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.dstream.DStream\n+\n+/**\n+ * :: DeveloperApi ::",
    "line": 25
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "@freeman-lab It would be really nice to put your findings inside the implementation. That can help us to understand the behavior.\n",
    "commit": "775ea29e53a7067ff6e143b455b49ddbb8553d94",
    "createdAt": "2014-08-01T21:09:41Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.dstream.DStream\n+\n+/**\n+ * :: DeveloperApi ::",
    "line": 25
  }],
  "prId": 1361
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "If the number of features is greater than 100, we should output `, ...` instead of `]`\n",
    "commit": "775ea29e53a7067ff6e143b455b49ddbb8553d94",
    "createdAt": "2014-08-02T00:01:40Z",
    "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.dstream.DStream\n+\n+/**\n+ * :: DeveloperApi ::\n+ * StreamingLinearAlgorithm implements methods for continuously\n+ * training a generalized linear model model on streaming data,\n+ * and using it for prediction on (possibly different) streaming data.\n+ *\n+ * This class takes as type parameters a GeneralizedLinearModel,\n+ * and a GeneralizedLinearAlgorithm, making it easy to extend to construct\n+ * streaming versions of any analyses using GLMs. Only weights will be updated,\n+ * not an intercept. If the model needs an intercept, it should be manually appended\n+ * to the input data.\n+ *\n+ * For example usage, see `StreamingLinearRegressionWithSGD`.\n+ *\n+ * NOTE(Freeman): In some use cases, the order in which trainOn and predictOn\n+ * are called in an application will affect the results. When called on\n+ * the same DStream, if trainOn is called before predictOn, when new data\n+ * arrive the model will update and the prediction will be based on the new\n+ * model. Whereas if predictOn is called first, the prediction will use the model\n+ * from the previous update.\n+ *\n+ * NOTE(Freeman): It is ok to call predictOn repeatedly on multiple streams; this\n+ * will generate predictions for each one all using the current model.\n+ * It is also ok to call trainOn on different streams; this will update\n+ * the model using each of the different sources, in sequence.\n+ *\n+ */\n+@DeveloperApi\n+abstract class StreamingLinearAlgorithm[\n+    M <: GeneralizedLinearModel,\n+    A <: GeneralizedLinearAlgorithm[M]] extends Logging {\n+\n+  /** The model to be updated and used for prediction. */\n+  protected var model: M\n+\n+  /** The algorithm to use for updating. */\n+  protected val algorithm: A\n+\n+  /** Return the latest model. */\n+  def latestModel(): M = {\n+    model\n+  }\n+\n+  /**\n+   * Update the model by training on batches of data from a DStream.\n+   * This operation registers a DStream for training the model,\n+   * and updates the model based on every subsequent\n+   * batch of data from the stream.\n+   *\n+   * @param data DStream containing labeled data\n+   */\n+  def trainOn(data: DStream[LabeledPoint]) {\n+    data.foreachRDD { (rdd, time) =>\n+        model = algorithm.run(rdd, model.weights)\n+        logInfo(\"Model updated at time %s\".format(time.toString))\n+        logInfo(\"Current model: weights, %s\".format(\n+          model.weights.toArray.take(100).mkString(\"[\", \",\", \"]\")))"
  }, {
    "author": {
      "login": "freeman-lab"
    },
    "body": "Good catch!\n",
    "commit": "775ea29e53a7067ff6e143b455b49ddbb8553d94",
    "createdAt": "2014-08-02T00:57:50Z",
    "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.regression\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.Logging\n+import org.apache.spark.streaming.dstream.DStream\n+\n+/**\n+ * :: DeveloperApi ::\n+ * StreamingLinearAlgorithm implements methods for continuously\n+ * training a generalized linear model model on streaming data,\n+ * and using it for prediction on (possibly different) streaming data.\n+ *\n+ * This class takes as type parameters a GeneralizedLinearModel,\n+ * and a GeneralizedLinearAlgorithm, making it easy to extend to construct\n+ * streaming versions of any analyses using GLMs. Only weights will be updated,\n+ * not an intercept. If the model needs an intercept, it should be manually appended\n+ * to the input data.\n+ *\n+ * For example usage, see `StreamingLinearRegressionWithSGD`.\n+ *\n+ * NOTE(Freeman): In some use cases, the order in which trainOn and predictOn\n+ * are called in an application will affect the results. When called on\n+ * the same DStream, if trainOn is called before predictOn, when new data\n+ * arrive the model will update and the prediction will be based on the new\n+ * model. Whereas if predictOn is called first, the prediction will use the model\n+ * from the previous update.\n+ *\n+ * NOTE(Freeman): It is ok to call predictOn repeatedly on multiple streams; this\n+ * will generate predictions for each one all using the current model.\n+ * It is also ok to call trainOn on different streams; this will update\n+ * the model using each of the different sources, in sequence.\n+ *\n+ */\n+@DeveloperApi\n+abstract class StreamingLinearAlgorithm[\n+    M <: GeneralizedLinearModel,\n+    A <: GeneralizedLinearAlgorithm[M]] extends Logging {\n+\n+  /** The model to be updated and used for prediction. */\n+  protected var model: M\n+\n+  /** The algorithm to use for updating. */\n+  protected val algorithm: A\n+\n+  /** Return the latest model. */\n+  def latestModel(): M = {\n+    model\n+  }\n+\n+  /**\n+   * Update the model by training on batches of data from a DStream.\n+   * This operation registers a DStream for training the model,\n+   * and updates the model based on every subsequent\n+   * batch of data from the stream.\n+   *\n+   * @param data DStream containing labeled data\n+   */\n+  def trainOn(data: DStream[LabeledPoint]) {\n+    data.foreachRDD { (rdd, time) =>\n+        model = algorithm.run(rdd, model.weights)\n+        logInfo(\"Model updated at time %s\".format(time.toString))\n+        logInfo(\"Current model: weights, %s\".format(\n+          model.weights.toArray.take(100).mkString(\"[\", \",\", \"]\")))"
  }],
  "prId": 1361
}]