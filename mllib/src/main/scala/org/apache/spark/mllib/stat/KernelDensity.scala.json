[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Is this a candidate for Experimental? in the sense that it might evolve into a fuller density estimation something-or-other later?\n",
    "commit": "5f06b3388fec4c230fbdd8e2b1f7cf94f3966606",
    "createdAt": "2014-06-16T07:55:14Z",
    "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.stat\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.commons.math3.util.FastMath\n+\n+object KernelDensity {"
  }],
  "prId": 1093
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I'd give a reference to the formulas your implementing, if only to say \"this is the log of the Gaussian pdf\" or something\n",
    "commit": "5f06b3388fec4c230fbdd8e2b1f7cf94f3966606",
    "createdAt": "2014-06-16T07:55:49Z",
    "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.stat\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.commons.math3.util.FastMath\n+\n+object KernelDensity {\n+  /**\n+   * Given a set of samples form a distribution, estimates its density at the set of given points.\n+   * Uses a Gaussian kernel with the given standard deviation.\n+   */\n+  def estimate(samples: RDD[Double], standardDeviation: Double,\n+      evaluationPoints: Array[Double]): Array[Double] = {\n+    val logStandardDeviationPlusHalfLog2Pi ="
  }],
  "prId": 1093
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Traversing arrays this way is to avoid copying?\n",
    "commit": "5f06b3388fec4c230fbdd8e2b1f7cf94f3966606",
    "createdAt": "2014-06-16T07:59:15Z",
    "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.stat\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.commons.math3.util.FastMath\n+\n+object KernelDensity {\n+  /**\n+   * Given a set of samples form a distribution, estimates its density at the set of given points.\n+   * Uses a Gaussian kernel with the given standard deviation.\n+   */\n+  def estimate(samples: RDD[Double], standardDeviation: Double,\n+      evaluationPoints: Array[Double]): Array[Double] = {\n+    val logStandardDeviationPlusHalfLog2Pi =\n+      FastMath.log(standardDeviation) + 0.5 * FastMath.log(2 * FastMath.PI)\n+\n+    val (points, count) = samples.aggregate((new Array[Double](evaluationPoints.length), 0))(\n+      (x, y) => {\n+        var i = 0\n+        while (i < evaluationPoints.length) {",
    "line": 40
  }, {
    "author": {
      "login": "sryza"
    },
    "body": "Right.  There might be a prettier way to do this that still avoids copying, but I've been advised against using Scala fanciness in performance-critical loops, because it has non-negligible overhead.\n",
    "commit": "5f06b3388fec4c230fbdd8e2b1f7cf94f3966606",
    "createdAt": "2014-06-16T18:13:35Z",
    "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.stat\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.commons.math3.util.FastMath\n+\n+object KernelDensity {\n+  /**\n+   * Given a set of samples form a distribution, estimates its density at the set of given points.\n+   * Uses a Gaussian kernel with the given standard deviation.\n+   */\n+  def estimate(samples: RDD[Double], standardDeviation: Double,\n+      evaluationPoints: Array[Double]): Array[Double] = {\n+    val logStandardDeviationPlusHalfLog2Pi =\n+      FastMath.log(standardDeviation) + 0.5 * FastMath.log(2 * FastMath.PI)\n+\n+    val (points, count) = samples.aggregate((new Array[Double](evaluationPoints.length), 0))(\n+      (x, y) => {\n+        var i = 0\n+        while (i < evaluationPoints.length) {",
    "line": 40
  }],
  "prId": 1093
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Taking the log of the normalizing constant and then exponentiating again feels like it could introduce tiny inaccuracies when it is avoidable. Sure, cache sqrt(2pi) as a constant but the exp can just be divided by that and stdev eh?\n",
    "commit": "5f06b3388fec4c230fbdd8e2b1f7cf94f3966606",
    "createdAt": "2014-06-16T08:04:30Z",
    "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.stat\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.commons.math3.util.FastMath\n+\n+object KernelDensity {\n+  /**\n+   * Given a set of samples form a distribution, estimates its density at the set of given points.\n+   * Uses a Gaussian kernel with the given standard deviation.\n+   */\n+  def estimate(samples: RDD[Double], standardDeviation: Double,\n+      evaluationPoints: Array[Double]): Array[Double] = {\n+    val logStandardDeviationPlusHalfLog2Pi =\n+      FastMath.log(standardDeviation) + 0.5 * FastMath.log(2 * FastMath.PI)\n+\n+    val (points, count) = samples.aggregate((new Array[Double](evaluationPoints.length), 0))(\n+      (x, y) => {\n+        var i = 0\n+        while (i < evaluationPoints.length) {\n+          x._1(i) += normPdf(y, standardDeviation, logStandardDeviationPlusHalfLog2Pi,\n+            evaluationPoints(i))\n+          i += 1\n+        }\n+        (x._1, i)\n+      },\n+      (x, y) => {\n+        var i = 0\n+        while (i < evaluationPoints.length) {\n+          x._1(i) += y._1(i)\n+          i += 1\n+        }\n+        (x._1, x._2 + y._2)\n+      })\n+\n+    var i = 0\n+    while (i < points.length) {\n+      points(i) /= count\n+      i += 1\n+    }\n+    points\n+  }\n+\n+  private def normPdf(mean: Double, standardDeviation: Double,\n+      logStandardDeviationPlusHalfLog2Pi: Double, x: Double): Double = {\n+    val x0 = x - mean\n+    val x1 = x0 / standardDeviation\n+    FastMath.exp(-0.5 * x1 * x1 - logStandardDeviationPlusHalfLog2Pi)"
  }, {
    "author": {
      "login": "sryza"
    },
    "body": "I stole this calculation from commons math - https://github.com/apache/commons-math/blob/trunk/src/main/java/org/apache/commons/math3/distribution/NormalDistribution.java.\n\nI'm a total novice on numerical stability, but maybe they have some reason?  We get to avoid a floating point division.\n",
    "commit": "5f06b3388fec4c230fbdd8e2b1f7cf94f3966606",
    "createdAt": "2014-06-16T20:36:09Z",
    "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.stat\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.commons.math3.util.FastMath\n+\n+object KernelDensity {\n+  /**\n+   * Given a set of samples form a distribution, estimates its density at the set of given points.\n+   * Uses a Gaussian kernel with the given standard deviation.\n+   */\n+  def estimate(samples: RDD[Double], standardDeviation: Double,\n+      evaluationPoints: Array[Double]): Array[Double] = {\n+    val logStandardDeviationPlusHalfLog2Pi =\n+      FastMath.log(standardDeviation) + 0.5 * FastMath.log(2 * FastMath.PI)\n+\n+    val (points, count) = samples.aggregate((new Array[Double](evaluationPoints.length), 0))(\n+      (x, y) => {\n+        var i = 0\n+        while (i < evaluationPoints.length) {\n+          x._1(i) += normPdf(y, standardDeviation, logStandardDeviationPlusHalfLog2Pi,\n+            evaluationPoints(i))\n+          i += 1\n+        }\n+        (x._1, i)\n+      },\n+      (x, y) => {\n+        var i = 0\n+        while (i < evaluationPoints.length) {\n+          x._1(i) += y._1(i)\n+          i += 1\n+        }\n+        (x._1, x._2 + y._2)\n+      })\n+\n+    var i = 0\n+    while (i < points.length) {\n+      points(i) /= count\n+      i += 1\n+    }\n+    points\n+  }\n+\n+  private def normPdf(mean: Double, standardDeviation: Double,\n+      logStandardDeviationPlusHalfLog2Pi: Double, x: Double): Double = {\n+    val x0 = x - mean\n+    val x1 = x0 / standardDeviation\n+    FastMath.exp(-0.5 * x1 * x1 - logStandardDeviationPlusHalfLog2Pi)"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Yeah it's doing this part in log space, but I don't see why these values are expected to be exceptionally large or small. It looks like the original code exposes a density and logDensity method, so one's written in terms of the other to avoid duplication -- not sure it is necessarily because it's better in that form. Anyone else have ideas?\n",
    "commit": "5f06b3388fec4c230fbdd8e2b1f7cf94f3966606",
    "createdAt": "2014-06-16T20:50:53Z",
    "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.stat\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.commons.math3.util.FastMath\n+\n+object KernelDensity {\n+  /**\n+   * Given a set of samples form a distribution, estimates its density at the set of given points.\n+   * Uses a Gaussian kernel with the given standard deviation.\n+   */\n+  def estimate(samples: RDD[Double], standardDeviation: Double,\n+      evaluationPoints: Array[Double]): Array[Double] = {\n+    val logStandardDeviationPlusHalfLog2Pi =\n+      FastMath.log(standardDeviation) + 0.5 * FastMath.log(2 * FastMath.PI)\n+\n+    val (points, count) = samples.aggregate((new Array[Double](evaluationPoints.length), 0))(\n+      (x, y) => {\n+        var i = 0\n+        while (i < evaluationPoints.length) {\n+          x._1(i) += normPdf(y, standardDeviation, logStandardDeviationPlusHalfLog2Pi,\n+            evaluationPoints(i))\n+          i += 1\n+        }\n+        (x._1, i)\n+      },\n+      (x, y) => {\n+        var i = 0\n+        while (i < evaluationPoints.length) {\n+          x._1(i) += y._1(i)\n+          i += 1\n+        }\n+        (x._1, x._2 + y._2)\n+      })\n+\n+    var i = 0\n+    while (i < points.length) {\n+      points(i) /= count\n+      i += 1\n+    }\n+    points\n+  }\n+\n+  private def normPdf(mean: Double, standardDeviation: Double,\n+      logStandardDeviationPlusHalfLog2Pi: Double, x: Double): Double = {\n+    val x0 = x - mean\n+    val x1 = x0 / standardDeviation\n+    FastMath.exp(-0.5 * x1 * x1 - logStandardDeviationPlusHalfLog2Pi)"
  }],
  "prId": 1093
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Might check the arg standardDeviation to make sure it's positive\n",
    "commit": "5f06b3388fec4c230fbdd8e2b1f7cf94f3966606",
    "createdAt": "2014-06-16T08:05:02Z",
    "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.stat\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.commons.math3.util.FastMath\n+\n+object KernelDensity {\n+  /**\n+   * Given a set of samples form a distribution, estimates its density at the set of given points.\n+   * Uses a Gaussian kernel with the given standard deviation.\n+   */\n+  def estimate(samples: RDD[Double], standardDeviation: Double,"
  }],
  "prId": 1093
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "If some of this is copied from Commons Math I'd suggest a note about its origin. I like FastMath; I think they show it is faster than Java's version. For consistency in the past I either used all FastMath or all Math. I don't know how much it matters here, using FastMath vs Java Math vs Scala Math from a consistency standpoint?\n",
    "commit": "5f06b3388fec4c230fbdd8e2b1f7cf94f3966606",
    "createdAt": "2014-06-16T20:53:35Z",
    "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.stat\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.commons.math3.util.FastMath\n+import org.apache.spark.annotation.Experimental\n+\n+@Experimental\n+object KernelDensity {\n+  /**\n+   * Given a set of samples form a distribution, estimates its density at the set of given points.\n+   * Uses a Gaussian kernel with the given standard deviation.\n+   */\n+  def estimate(samples: RDD[Double], standardDeviation: Double,\n+      evaluationPoints: Array[Double]): Array[Double] = {\n+    if (standardDeviation <= 0.0) {\n+      throw new IllegalArgumentException(\"Standard deviation must be positive\")\n+    }\n+\n+    // This gets used in each Gaussian PDF computation, so compute it up front\n+    val logStandardDeviationPlusHalfLog2Pi =",
    "line": 34
  }],
  "prId": 1093
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`Math` is being deprecated. Please replace it with `math` instead.\n",
    "commit": "5f06b3388fec4c230fbdd8e2b1f7cf94f3966606",
    "createdAt": "2015-02-09T18:22:58Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.stat\n+\n+import org.apache.spark.rdd.RDD\n+\n+private[stat] object KernelDensity {\n+  /**\n+   * Given a set of samples from a distribution, estimates its density at the set of given points.\n+   * Uses a Gaussian kernel with the given standard deviation.\n+   */\n+  def estimate(samples: RDD[Double], standardDeviation: Double,\n+      evaluationPoints: Array[Double]): Array[Double] = {\n+    if (standardDeviation <= 0.0) {\n+      throw new IllegalArgumentException(\"Standard deviation must be positive\")\n+    }\n+\n+    // This gets used in each Gaussian PDF computation, so compute it up front\n+    val logStandardDeviationPlusHalfLog2Pi =\n+      Math.log(standardDeviation) + 0.5 * Math.log(2 * Math.PI)",
    "line": 35
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Ah, yeah I thought of that before I merged, but saw a load of usages of `Math` in the code. Shall I make a PR to change all of them in one go?\n",
    "commit": "5f06b3388fec4c230fbdd8e2b1f7cf94f3966606",
    "createdAt": "2015-02-09T18:24:03Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.stat\n+\n+import org.apache.spark.rdd.RDD\n+\n+private[stat] object KernelDensity {\n+  /**\n+   * Given a set of samples from a distribution, estimates its density at the set of given points.\n+   * Uses a Gaussian kernel with the given standard deviation.\n+   */\n+  def estimate(samples: RDD[Double], standardDeviation: Double,\n+      evaluationPoints: Array[Double]): Array[Double] = {\n+    if (standardDeviation <= 0.0) {\n+      throw new IllegalArgumentException(\"Standard deviation must be positive\")\n+    }\n+\n+    // This gets used in each Gaussian PDF computation, so compute it up front\n+    val logStandardDeviationPlusHalfLog2Pi =\n+      Math.log(standardDeviation) + 0.5 * Math.log(2 * Math.PI)",
    "line": 35
  }],
  "prId": 1093
}]