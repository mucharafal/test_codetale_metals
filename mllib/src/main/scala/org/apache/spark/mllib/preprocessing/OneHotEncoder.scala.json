[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "you can wrap code around using \n\n```\n{{{\n\n}}}\n```\n\nso they get properly formatted in scaladoc\n",
    "commit": "8e0efba08ab88306ac66706b7ac3b4f84f93d134",
    "createdAt": "2014-04-02T21:29:10Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.preprocessing\n+\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable.HashSet\n+import scala.collection.mutable.Set\n+\n+/**\n+ * A utility for encoding categorical variables to numeric variables. The resulting vectors\n+ * contain a component for each value that the variable can take. The component corresponding\n+ * to the value that the variable takes is set to 1 and the components corresponding to all other\n+ * categories are set to 0.\n+ *\n+ * The utility handles input vectors with mixed categorical and numeric variables by accepting a\n+ * list of feature indices that are categorical and only transforming those.\n+ *\n+ * An example usage is:\n+ *\n+ *  val categoricalFields = Array(0, 7, 21)"
  }],
  "prId": 304
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Put scala import before spark imports. Also, better import `scala.collection.mutable` and in the code use `mutable.HashSet` and `mutable.Set`.\n",
    "commit": "8e0efba08ab88306ac66706b7ac3b4f84f93d134",
    "createdAt": "2014-04-09T21:43:58Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.preprocessing\n+\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable.HashSet"
  }],
  "prId": 304
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Maybe add some doc about the \"One-Hot\" name or provide a link to the wikipedia page.\n",
    "commit": "8e0efba08ab88306ac66706b7ac3b4f84f93d134",
    "createdAt": "2014-04-09T21:48:35Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.preprocessing\n+\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable.HashSet\n+import scala.collection.mutable.Set\n+\n+/**\n+ * A utility for encoding categorical variables as numeric variables. The resulting vectors\n+ * contain a component for each value that the variable can take. The component corresponding\n+ * to the value that the variable takes is set to 1 and the components corresponding to all other\n+ * categories are set to 0.\n+ *\n+ * The utility handles input vectors with mixed categorical and numeric variables by accepting a\n+ * list of feature indices that are categorical and only transforming those.\n+ *\n+ * An example usage is:\n+ *\n+ * {{{\n+ *  val categoricalFields = Array(0, 7, 21)\n+ *  val categories = OneHotEncoder.categories(rdd, categoricalFields)\n+ *  val encoded = OneHotEncoder.encode(rdd, categories)\n+ * }}}\n+ */\n+object OneHotEncoder {",
    "line": 56
  }],
  "prId": 304
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "The doc is not very clear to me, at least not as clear as sklean's doc. A concrete example would be super helpful.\n",
    "commit": "8e0efba08ab88306ac66706b7ac3b4f84f93d134",
    "createdAt": "2014-04-09T21:52:48Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.preprocessing\n+\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable.HashSet\n+import scala.collection.mutable.Set\n+\n+/**\n+ * A utility for encoding categorical variables as numeric variables. The resulting vectors\n+ * contain a component for each value that the variable can take. The component corresponding\n+ * to the value that the variable takes is set to 1 and the components corresponding to all other\n+ * categories are set to 0."
  }],
  "prId": 304
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Could we use a generic type here? So if a user input `Array[Double]`, it will return `Array[Map[Double, Int]]`.\n",
    "commit": "8e0efba08ab88306ac66706b7ac3b4f84f93d134",
    "createdAt": "2014-04-09T21:55:44Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.preprocessing\n+\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable.HashSet\n+import scala.collection.mutable.Set\n+\n+/**\n+ * A utility for encoding categorical variables as numeric variables. The resulting vectors\n+ * contain a component for each value that the variable can take. The component corresponding\n+ * to the value that the variable takes is set to 1 and the components corresponding to all other\n+ * categories are set to 0.\n+ *\n+ * The utility handles input vectors with mixed categorical and numeric variables by accepting a\n+ * list of feature indices that are categorical and only transforming those.\n+ *\n+ * An example usage is:\n+ *\n+ * {{{\n+ *  val categoricalFields = Array(0, 7, 21)\n+ *  val categories = OneHotEncoder.categories(rdd, categoricalFields)\n+ *  val encoded = OneHotEncoder.encode(rdd, categories)\n+ * }}}\n+ */\n+object OneHotEncoder {\n+\n+  /**\n+   * Given a dataset and the set of columns which are categorical variables, returns a structure\n+   * that, for each field, describes the values that are present for in the dataset. The structure\n+   * is meant to be used as input to encode.\n+   */\n+  def categories(rdd: RDD[Array[Any]], categoricalFields: Seq[Int]): Array[Map[Any, Int]] = {"
  }],
  "prId": 304
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Instead of map/reduce, using aggregate to avoid creating temporary objects.\n",
    "commit": "8e0efba08ab88306ac66706b7ac3b4f84f93d134",
    "createdAt": "2014-04-09T22:17:46Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.preprocessing\n+\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable.HashSet\n+import scala.collection.mutable.Set\n+\n+/**\n+ * A utility for encoding categorical variables as numeric variables. The resulting vectors\n+ * contain a component for each value that the variable can take. The component corresponding\n+ * to the value that the variable takes is set to 1 and the components corresponding to all other\n+ * categories are set to 0.\n+ *\n+ * The utility handles input vectors with mixed categorical and numeric variables by accepting a\n+ * list of feature indices that are categorical and only transforming those.\n+ *\n+ * An example usage is:\n+ *\n+ * {{{\n+ *  val categoricalFields = Array(0, 7, 21)\n+ *  val categories = OneHotEncoder.categories(rdd, categoricalFields)\n+ *  val encoded = OneHotEncoder.encode(rdd, categories)\n+ * }}}\n+ */\n+object OneHotEncoder {\n+\n+  /**\n+   * Given a dataset and the set of columns which are categorical variables, returns a structure\n+   * that, for each field, describes the values that are present for in the dataset. The structure\n+   * is meant to be used as input to encode.\n+   */\n+  def categories(rdd: RDD[Array[Any]], categoricalFields: Seq[Int]): Array[Map[Any, Int]] = {\n+    val categories = rdd.map(categoricals(_, categoricalFields)).reduce(uniqueCats)"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Basically, you start with an `Array[mutable.HashSet]` and then merge vectors one by one.\n",
    "commit": "8e0efba08ab88306ac66706b7ac3b4f84f93d134",
    "createdAt": "2014-04-09T22:23:36Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.preprocessing\n+\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable.HashSet\n+import scala.collection.mutable.Set\n+\n+/**\n+ * A utility for encoding categorical variables as numeric variables. The resulting vectors\n+ * contain a component for each value that the variable can take. The component corresponding\n+ * to the value that the variable takes is set to 1 and the components corresponding to all other\n+ * categories are set to 0.\n+ *\n+ * The utility handles input vectors with mixed categorical and numeric variables by accepting a\n+ * list of feature indices that are categorical and only transforming those.\n+ *\n+ * An example usage is:\n+ *\n+ * {{{\n+ *  val categoricalFields = Array(0, 7, 21)\n+ *  val categories = OneHotEncoder.categories(rdd, categoricalFields)\n+ *  val encoded = OneHotEncoder.encode(rdd, categories)\n+ * }}}\n+ */\n+object OneHotEncoder {\n+\n+  /**\n+   * Given a dataset and the set of columns which are categorical variables, returns a structure\n+   * that, for each field, describes the values that are present for in the dataset. The structure\n+   * is meant to be used as input to encode.\n+   */\n+  def categories(rdd: RDD[Array[Any]], categoricalFields: Seq[Int]): Array[Map[Any, Int]] = {\n+    val categories = rdd.map(categoricals(_, categoricalFields)).reduce(uniqueCats)"
  }],
  "prId": 304
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`catMaps` should have the same size as `categoricalFields` to save space. The worst case is when the dimension is huge but number of categorical features is small. \n",
    "commit": "8e0efba08ab88306ac66706b7ac3b4f84f93d134",
    "createdAt": "2014-04-09T22:21:09Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.preprocessing\n+\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable.HashSet\n+import scala.collection.mutable.Set\n+\n+/**\n+ * A utility for encoding categorical variables as numeric variables. The resulting vectors\n+ * contain a component for each value that the variable can take. The component corresponding\n+ * to the value that the variable takes is set to 1 and the components corresponding to all other\n+ * categories are set to 0.\n+ *\n+ * The utility handles input vectors with mixed categorical and numeric variables by accepting a\n+ * list of feature indices that are categorical and only transforming those.\n+ *\n+ * An example usage is:\n+ *\n+ * {{{\n+ *  val categoricalFields = Array(0, 7, 21)\n+ *  val categories = OneHotEncoder.categories(rdd, categoricalFields)\n+ *  val encoded = OneHotEncoder.encode(rdd, categories)\n+ * }}}\n+ */\n+object OneHotEncoder {\n+\n+  /**\n+   * Given a dataset and the set of columns which are categorical variables, returns a structure\n+   * that, for each field, describes the values that are present for in the dataset. The structure\n+   * is meant to be used as input to encode.\n+   */\n+  def categories(rdd: RDD[Array[Any]], categoricalFields: Seq[Int]): Array[Map[Any, Int]] = {\n+    val categories = rdd.map(categoricals(_, categoricalFields)).reduce(uniqueCats)\n+\n+    val catMaps = new Array[Map[Any, Int]](rdd.first().length)"
  }],
  "prId": 304
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Do not use `for` in an inner loop. `while` and `foreach` give better performance.\n",
    "commit": "8e0efba08ab88306ac66706b7ac3b4f84f93d134",
    "createdAt": "2014-04-09T22:25:30Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.preprocessing\n+\n+import org.apache.spark.rdd.RDD\n+\n+import scala.collection.mutable.HashSet\n+import scala.collection.mutable.Set\n+\n+/**\n+ * A utility for encoding categorical variables as numeric variables. The resulting vectors\n+ * contain a component for each value that the variable can take. The component corresponding\n+ * to the value that the variable takes is set to 1 and the components corresponding to all other\n+ * categories are set to 0.\n+ *\n+ * The utility handles input vectors with mixed categorical and numeric variables by accepting a\n+ * list of feature indices that are categorical and only transforming those.\n+ *\n+ * An example usage is:\n+ *\n+ * {{{\n+ *  val categoricalFields = Array(0, 7, 21)\n+ *  val categories = OneHotEncoder.categories(rdd, categoricalFields)\n+ *  val encoded = OneHotEncoder.encode(rdd, categories)\n+ * }}}\n+ */\n+object OneHotEncoder {\n+\n+  /**\n+   * Given a dataset and the set of columns which are categorical variables, returns a structure\n+   * that, for each field, describes the values that are present for in the dataset. The structure\n+   * is meant to be used as input to encode.\n+   */\n+  def categories(rdd: RDD[Array[Any]], categoricalFields: Seq[Int]): Array[Map[Any, Int]] = {\n+    val categories = rdd.map(categoricals(_, categoricalFields)).reduce(uniqueCats)\n+\n+    val catMaps = new Array[Map[Any, Int]](rdd.first().length)\n+    for (i <- 0 until categoricalFields.length) {\n+      catMaps(categoricalFields(i)) = categories(i).zipWithIndex.toMap\n+    }\n+\n+    catMaps\n+  }\n+\n+  /**\n+   * Accepts a vector and set of feature indices that are categorical variables.  Outputs an array\n+   * whose size is the number of categorical fields and each element is a Set of size one\n+   * containing a categorical value from the input vec\n+   */\n+  private def categoricals(tokens: Array[Any], catFields: Seq[Int]): Array[Set[Any]] = {\n+    val categoriesArr = new Array[Set[Any]](catFields.length)\n+    for (i <- 0 until catFields.length) {\n+      categoriesArr(i) = new HashSet[Any]()\n+      categoriesArr(i) += tokens(catFields(i))\n+    }\n+    categoriesArr\n+  }\n+\n+  private def uniqueCats(a: Array[Set[Any]], b: Array[Set[Any]]): Array[Set[Any]] = {\n+    for (i <- 0 until a.length) {\n+      a(i) ++= b(i)\n+    }\n+    a\n+  }\n+\n+  /**\n+   * OneHot encodes the given RDD.\n+   */\n+  def encode(rdd: RDD[Array[Any]], featureCategories: Array[Map[Any, Int]]):\n+      RDD[Array[Any]] = {\n+    var outArrLen = 0\n+    for (catMap <- featureCategories) {\n+      outArrLen += (if (catMap == null) 1 else catMap.size)\n+    }\n+    rdd.map(encodeVec(_, featureCategories, outArrLen))\n+  }\n+\n+  private def encodeVec(vec: Array[Any], featureCategories: Array[Map[Any, Int]],\n+      outArrLen: Int): Array[Any] = {\n+    var outArrIndex = 0\n+    val outVec = new Array[Any](outArrLen)\n+    for (i <- 0 until vec.length) {"
  }],
  "prId": 304
}]