[{
  "comments": [{
    "author": {
      "login": "karlhigley"
    },
    "body": "The name of the third return value here should be `background`.  This appears to change the background in the global parameters returned by this method.\n",
    "commit": "e0fcc6fa6af1121973d1d61afefb2e37b9494e3c",
    "createdAt": "2014-10-01T22:19:36Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.clustering.topicmodeling.topicmodels\n+\n+\n+import java.util.Random\n+\n+import org.apache.spark.broadcast.Broadcast\n+import org.apache.spark.mllib.clustering.topicmodeling.documents.Document\n+import org.apache.spark.mllib.clustering.topicmodeling.topicmodels.regulaizers.{DocumentOverTopicDistributionRegularizer, TopicsRegularizer, UniformDocumentOverTopicRegularizer, UniformTopicRegularizer}\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.{Logging, SparkContext}\n+\n+\n+/**\n+ * distributed topic modeling via RobustPLSA (Hofmann (1999), Vorontsov, Potapenko (2014) )\n+ *\n+ * @param sc  spark context\n+ * @param numberOfTopics number of topics\n+ * @param numberOfIterations number of iterations\n+ * @param random java.util.Random need for initialisation\n+ * @param documentOverTopicDistributionRegularizer\n+ * @param topicRegularizer\n+ * @param computePpx boolean. If true, model computes perplexity and prints it puts in the log at\n+ *                   INFO level. it takes some time and memory\n+ * @param gamma weight of background\n+ * @param eps   weight of noise\n+ */\n+class RobustPLSA(@transient protected val sc: SparkContext,\n+                 protected val numberOfTopics: Int,\n+                 protected val numberOfIterations: Int,\n+                 protected val random: Random,\n+                 private val documentOverTopicDistributionRegularizer:\n+                  DocumentOverTopicDistributionRegularizer =\n+                          new UniformDocumentOverTopicRegularizer,\n+                 @transient protected val topicRegularizer: TopicsRegularizer =\n+                                                        new UniformTopicRegularizer,\n+                 private val computePpx: Boolean = true,\n+                 private val gamma: Float = 0.3f,\n+                 private val eps: Float = 0.01f)\n+  extends AbstractPLSA[RobustDocumentParameters, RobustGlobalParameters, RobustGlobalCounters]\n+  with Logging\n+  with Serializable {\n+\n+\n+  /**\n+   *\n+   * @param documents  -- document collection\n+   * @return a pair of rdd of document parameters global parameters\n+   */\n+  override def infer(documents: RDD[Document])\n+      : (RDD[RobustDocumentParameters], RobustGlobalParameters) = {\n+    val alphabetSize = getAlphabetSize(documents)\n+    EM(documents, getInitialTopics(alphabetSize), alphabetSize, foldingIn = false)\n+  }\n+\n+\n+  /**\n+   *\n+   * @param documents  docs to be folded in\n+   * @param globalParams global parameters that were produced by infer method (stores topics)\n+   * @return\n+   */\n+  override def foldIn(documents: RDD[Document],\n+                      globalParams: RobustGlobalParameters): RDD[RobustDocumentParameters] = {\n+    EM(documents, sc.broadcast(globalParams.phi), globalParams.alphabetSize, foldingIn = true)._1\n+  }\n+\n+  private def EM(documents: RDD[Document],\n+                 topicBC: Broadcast[Array[Array[Float]]],\n+                 alphabetSize : Int,\n+                 foldingIn : Boolean) :(RDD[RobustDocumentParameters], RobustGlobalParameters) = {\n+    val collectionLength = getCollectionLength(documents)\n+\n+    val parameters = documents.map(doc => RobustDocumentParameters(doc,\n+                                                  numberOfTopics,\n+                                                  gamma,\n+                                                  eps,\n+                                                  documentOverTopicDistributionRegularizer))\n+\n+    val background = Array.fill(alphabetSize)(1f / alphabetSize)\n+\n+    val (result, topics, backgound) = newIteration(parameters,"
  }, {
    "author": {
      "login": "akopich"
    },
    "body": "Thank you very much for reading the code. You are right. \nFixed. \n",
    "commit": "e0fcc6fa6af1121973d1d61afefb2e37b9494e3c",
    "createdAt": "2014-10-02T11:17:26Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.clustering.topicmodeling.topicmodels\n+\n+\n+import java.util.Random\n+\n+import org.apache.spark.broadcast.Broadcast\n+import org.apache.spark.mllib.clustering.topicmodeling.documents.Document\n+import org.apache.spark.mllib.clustering.topicmodeling.topicmodels.regulaizers.{DocumentOverTopicDistributionRegularizer, TopicsRegularizer, UniformDocumentOverTopicRegularizer, UniformTopicRegularizer}\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.{Logging, SparkContext}\n+\n+\n+/**\n+ * distributed topic modeling via RobustPLSA (Hofmann (1999), Vorontsov, Potapenko (2014) )\n+ *\n+ * @param sc  spark context\n+ * @param numberOfTopics number of topics\n+ * @param numberOfIterations number of iterations\n+ * @param random java.util.Random need for initialisation\n+ * @param documentOverTopicDistributionRegularizer\n+ * @param topicRegularizer\n+ * @param computePpx boolean. If true, model computes perplexity and prints it puts in the log at\n+ *                   INFO level. it takes some time and memory\n+ * @param gamma weight of background\n+ * @param eps   weight of noise\n+ */\n+class RobustPLSA(@transient protected val sc: SparkContext,\n+                 protected val numberOfTopics: Int,\n+                 protected val numberOfIterations: Int,\n+                 protected val random: Random,\n+                 private val documentOverTopicDistributionRegularizer:\n+                  DocumentOverTopicDistributionRegularizer =\n+                          new UniformDocumentOverTopicRegularizer,\n+                 @transient protected val topicRegularizer: TopicsRegularizer =\n+                                                        new UniformTopicRegularizer,\n+                 private val computePpx: Boolean = true,\n+                 private val gamma: Float = 0.3f,\n+                 private val eps: Float = 0.01f)\n+  extends AbstractPLSA[RobustDocumentParameters, RobustGlobalParameters, RobustGlobalCounters]\n+  with Logging\n+  with Serializable {\n+\n+\n+  /**\n+   *\n+   * @param documents  -- document collection\n+   * @return a pair of rdd of document parameters global parameters\n+   */\n+  override def infer(documents: RDD[Document])\n+      : (RDD[RobustDocumentParameters], RobustGlobalParameters) = {\n+    val alphabetSize = getAlphabetSize(documents)\n+    EM(documents, getInitialTopics(alphabetSize), alphabetSize, foldingIn = false)\n+  }\n+\n+\n+  /**\n+   *\n+   * @param documents  docs to be folded in\n+   * @param globalParams global parameters that were produced by infer method (stores topics)\n+   * @return\n+   */\n+  override def foldIn(documents: RDD[Document],\n+                      globalParams: RobustGlobalParameters): RDD[RobustDocumentParameters] = {\n+    EM(documents, sc.broadcast(globalParams.phi), globalParams.alphabetSize, foldingIn = true)._1\n+  }\n+\n+  private def EM(documents: RDD[Document],\n+                 topicBC: Broadcast[Array[Array[Float]]],\n+                 alphabetSize : Int,\n+                 foldingIn : Boolean) :(RDD[RobustDocumentParameters], RobustGlobalParameters) = {\n+    val collectionLength = getCollectionLength(documents)\n+\n+    val parameters = documents.map(doc => RobustDocumentParameters(doc,\n+                                                  numberOfTopics,\n+                                                  gamma,\n+                                                  eps,\n+                                                  documentOverTopicDistributionRegularizer))\n+\n+    val background = Array.fill(alphabetSize)(1f / alphabetSize)\n+\n+    val (result, topics, backgound) = newIteration(parameters,"
  }, {
    "author": {
      "login": "karlhigley"
    },
    "body": "I'm actually trying to run it! :)\n",
    "commit": "e0fcc6fa6af1121973d1d61afefb2e37b9494e3c",
    "createdAt": "2014-10-02T12:52:17Z",
    "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.clustering.topicmodeling.topicmodels\n+\n+\n+import java.util.Random\n+\n+import org.apache.spark.broadcast.Broadcast\n+import org.apache.spark.mllib.clustering.topicmodeling.documents.Document\n+import org.apache.spark.mllib.clustering.topicmodeling.topicmodels.regulaizers.{DocumentOverTopicDistributionRegularizer, TopicsRegularizer, UniformDocumentOverTopicRegularizer, UniformTopicRegularizer}\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.{Logging, SparkContext}\n+\n+\n+/**\n+ * distributed topic modeling via RobustPLSA (Hofmann (1999), Vorontsov, Potapenko (2014) )\n+ *\n+ * @param sc  spark context\n+ * @param numberOfTopics number of topics\n+ * @param numberOfIterations number of iterations\n+ * @param random java.util.Random need for initialisation\n+ * @param documentOverTopicDistributionRegularizer\n+ * @param topicRegularizer\n+ * @param computePpx boolean. If true, model computes perplexity and prints it puts in the log at\n+ *                   INFO level. it takes some time and memory\n+ * @param gamma weight of background\n+ * @param eps   weight of noise\n+ */\n+class RobustPLSA(@transient protected val sc: SparkContext,\n+                 protected val numberOfTopics: Int,\n+                 protected val numberOfIterations: Int,\n+                 protected val random: Random,\n+                 private val documentOverTopicDistributionRegularizer:\n+                  DocumentOverTopicDistributionRegularizer =\n+                          new UniformDocumentOverTopicRegularizer,\n+                 @transient protected val topicRegularizer: TopicsRegularizer =\n+                                                        new UniformTopicRegularizer,\n+                 private val computePpx: Boolean = true,\n+                 private val gamma: Float = 0.3f,\n+                 private val eps: Float = 0.01f)\n+  extends AbstractPLSA[RobustDocumentParameters, RobustGlobalParameters, RobustGlobalCounters]\n+  with Logging\n+  with Serializable {\n+\n+\n+  /**\n+   *\n+   * @param documents  -- document collection\n+   * @return a pair of rdd of document parameters global parameters\n+   */\n+  override def infer(documents: RDD[Document])\n+      : (RDD[RobustDocumentParameters], RobustGlobalParameters) = {\n+    val alphabetSize = getAlphabetSize(documents)\n+    EM(documents, getInitialTopics(alphabetSize), alphabetSize, foldingIn = false)\n+  }\n+\n+\n+  /**\n+   *\n+   * @param documents  docs to be folded in\n+   * @param globalParams global parameters that were produced by infer method (stores topics)\n+   * @return\n+   */\n+  override def foldIn(documents: RDD[Document],\n+                      globalParams: RobustGlobalParameters): RDD[RobustDocumentParameters] = {\n+    EM(documents, sc.broadcast(globalParams.phi), globalParams.alphabetSize, foldingIn = true)._1\n+  }\n+\n+  private def EM(documents: RDD[Document],\n+                 topicBC: Broadcast[Array[Array[Float]]],\n+                 alphabetSize : Int,\n+                 foldingIn : Boolean) :(RDD[RobustDocumentParameters], RobustGlobalParameters) = {\n+    val collectionLength = getCollectionLength(documents)\n+\n+    val parameters = documents.map(doc => RobustDocumentParameters(doc,\n+                                                  numberOfTopics,\n+                                                  gamma,\n+                                                  eps,\n+                                                  documentOverTopicDistributionRegularizer))\n+\n+    val background = Array.fill(alphabetSize)(1f / alphabetSize)\n+\n+    val (result, topics, backgound) = newIteration(parameters,"
  }],
  "prId": 1269
}]