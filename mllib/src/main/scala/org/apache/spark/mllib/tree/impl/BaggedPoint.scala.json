[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "insert an empty line to separate imports\n",
    "commit": "c6941748b58f5b77a480cfbc85cdece9ce8dec5a",
    "createdAt": "2014-09-23T22:21:14Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.impl\n+\n+import cern.jet.random.Poisson\n+import cern.jet.random.engine.DRand\n+import org.apache.spark.rdd.RDD"
  }],
  "prId": 2435
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "remove `{ }`\n",
    "commit": "c6941748b58f5b77a480cfbc85cdece9ce8dec5a",
    "createdAt": "2014-09-23T22:21:17Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.impl\n+\n+import cern.jet.random.Poisson\n+import cern.jet.random.engine.DRand\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Internal representation of a datapoint which belongs to several subsamples of the same dataset,\n+ * particularly for bagging (e.g., for random forests).\n+ *\n+ * This holds one instance, as well as an array of weights which represent the (weighted)\n+ * number of times which this instance appears in each subsample.\n+ * E.g., (datum, [1, 0, 4]) indicates that there are 3 subsamples of the dataset and that\n+ * this datum has 1 copy, 0 copies, and 4 copies in the 3 subsamples, respectively.\n+ *\n+ * @param datum  Data instance\n+ * @param subsampleWeights  Weight of this instance in each subsampled dataset.\n+ *\n+ * TODO: This does not currently support (Double) weighted instances.  Once MLlib has weighted\n+ *       dataset support, update.  (We store subsampleWeights as Double for this future extension.)\n+ */\n+private[tree] class BaggedPoint[Datum](val datum: Datum, val subsampleWeights: Array[Double])\n+  extends Serializable {\n+}"
  }],
  "prId": 2435
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "use `Long` for random seed\n",
    "commit": "c6941748b58f5b77a480cfbc85cdece9ce8dec5a",
    "createdAt": "2014-09-23T22:21:20Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.impl\n+\n+import cern.jet.random.Poisson\n+import cern.jet.random.engine.DRand\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Internal representation of a datapoint which belongs to several subsamples of the same dataset,\n+ * particularly for bagging (e.g., for random forests).\n+ *\n+ * This holds one instance, as well as an array of weights which represent the (weighted)\n+ * number of times which this instance appears in each subsample.\n+ * E.g., (datum, [1, 0, 4]) indicates that there are 3 subsamples of the dataset and that\n+ * this datum has 1 copy, 0 copies, and 4 copies in the 3 subsamples, respectively.\n+ *\n+ * @param datum  Data instance\n+ * @param subsampleWeights  Weight of this instance in each subsampled dataset.\n+ *\n+ * TODO: This does not currently support (Double) weighted instances.  Once MLlib has weighted\n+ *       dataset support, update.  (We store subsampleWeights as Double for this future extension.)\n+ */\n+private[tree] class BaggedPoint[Datum](val datum: Datum, val subsampleWeights: Array[Double])\n+  extends Serializable {\n+}\n+\n+private[tree] object BaggedPoint {\n+\n+  /**\n+   * Convert an input dataset into its BaggedPoint representation,\n+   * choosing subsample counts for each instance.\n+   * Each subsample has the same number of instances as the original dataset,\n+   * and is created by subsampling with replacement.\n+   * @param input     Input dataset.\n+   * @param numSubsamples  Number of subsamples of this RDD to take.\n+   * @param seed   Random seed.\n+   * @return  BaggedPoint dataset representation\n+   */\n+  def convertToBaggedRDD[Datum](\n+      input: RDD[Datum],\n+      numSubsamples: Int,\n+      seed: Int = Utils.random.nextInt()): RDD[BaggedPoint[Datum]] = {",
    "line": 59
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "I used DRand, copying SampledRDD, and DRand takes an Int, not a Long.  Should I use a different random number generator?\n",
    "commit": "c6941748b58f5b77a480cfbc85cdece9ce8dec5a",
    "createdAt": "2014-09-24T23:57:01Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.impl\n+\n+import cern.jet.random.Poisson\n+import cern.jet.random.engine.DRand\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Internal representation of a datapoint which belongs to several subsamples of the same dataset,\n+ * particularly for bagging (e.g., for random forests).\n+ *\n+ * This holds one instance, as well as an array of weights which represent the (weighted)\n+ * number of times which this instance appears in each subsample.\n+ * E.g., (datum, [1, 0, 4]) indicates that there are 3 subsamples of the dataset and that\n+ * this datum has 1 copy, 0 copies, and 4 copies in the 3 subsamples, respectively.\n+ *\n+ * @param datum  Data instance\n+ * @param subsampleWeights  Weight of this instance in each subsampled dataset.\n+ *\n+ * TODO: This does not currently support (Double) weighted instances.  Once MLlib has weighted\n+ *       dataset support, update.  (We store subsampleWeights as Double for this future extension.)\n+ */\n+private[tree] class BaggedPoint[Datum](val datum: Datum, val subsampleWeights: Array[Double])\n+  extends Serializable {\n+}\n+\n+private[tree] object BaggedPoint {\n+\n+  /**\n+   * Convert an input dataset into its BaggedPoint representation,\n+   * choosing subsample counts for each instance.\n+   * Each subsample has the same number of instances as the original dataset,\n+   * and is created by subsampling with replacement.\n+   * @param input     Input dataset.\n+   * @param numSubsamples  Number of subsamples of this RDD to take.\n+   * @param seed   Random seed.\n+   * @return  BaggedPoint dataset representation\n+   */\n+  def convertToBaggedRDD[Datum](\n+      input: RDD[Datum],\n+      numSubsamples: Int,\n+      seed: Int = Utils.random.nextInt()): RDD[BaggedPoint[Datum]] = {",
    "line": 59
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Use `seed.toInt` for `DRand`.\n",
    "commit": "c6941748b58f5b77a480cfbc85cdece9ce8dec5a",
    "createdAt": "2014-09-25T07:49:26Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.impl\n+\n+import cern.jet.random.Poisson\n+import cern.jet.random.engine.DRand\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Internal representation of a datapoint which belongs to several subsamples of the same dataset,\n+ * particularly for bagging (e.g., for random forests).\n+ *\n+ * This holds one instance, as well as an array of weights which represent the (weighted)\n+ * number of times which this instance appears in each subsample.\n+ * E.g., (datum, [1, 0, 4]) indicates that there are 3 subsamples of the dataset and that\n+ * this datum has 1 copy, 0 copies, and 4 copies in the 3 subsamples, respectively.\n+ *\n+ * @param datum  Data instance\n+ * @param subsampleWeights  Weight of this instance in each subsampled dataset.\n+ *\n+ * TODO: This does not currently support (Double) weighted instances.  Once MLlib has weighted\n+ *       dataset support, update.  (We store subsampleWeights as Double for this future extension.)\n+ */\n+private[tree] class BaggedPoint[Datum](val datum: Datum, val subsampleWeights: Array[Double])\n+  extends Serializable {\n+}\n+\n+private[tree] object BaggedPoint {\n+\n+  /**\n+   * Convert an input dataset into its BaggedPoint representation,\n+   * choosing subsample counts for each instance.\n+   * Each subsample has the same number of instances as the original dataset,\n+   * and is created by subsampling with replacement.\n+   * @param input     Input dataset.\n+   * @param numSubsamples  Number of subsamples of this RDD to take.\n+   * @param seed   Random seed.\n+   * @return  BaggedPoint dataset representation\n+   */\n+  def convertToBaggedRDD[Datum](\n+      input: RDD[Datum],\n+      numSubsamples: Int,\n+      seed: Int = Utils.random.nextInt()): RDD[BaggedPoint[Datum]] = {",
    "line": 59
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "OK, but that seems a little deceptive in terms of API.\n",
    "commit": "c6941748b58f5b77a480cfbc85cdece9ce8dec5a",
    "createdAt": "2014-09-25T19:15:05Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.impl\n+\n+import cern.jet.random.Poisson\n+import cern.jet.random.engine.DRand\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Internal representation of a datapoint which belongs to several subsamples of the same dataset,\n+ * particularly for bagging (e.g., for random forests).\n+ *\n+ * This holds one instance, as well as an array of weights which represent the (weighted)\n+ * number of times which this instance appears in each subsample.\n+ * E.g., (datum, [1, 0, 4]) indicates that there are 3 subsamples of the dataset and that\n+ * this datum has 1 copy, 0 copies, and 4 copies in the 3 subsamples, respectively.\n+ *\n+ * @param datum  Data instance\n+ * @param subsampleWeights  Weight of this instance in each subsampled dataset.\n+ *\n+ * TODO: This does not currently support (Double) weighted instances.  Once MLlib has weighted\n+ *       dataset support, update.  (We store subsampleWeights as Double for this future extension.)\n+ */\n+private[tree] class BaggedPoint[Datum](val datum: Datum, val subsampleWeights: Array[Double])\n+  extends Serializable {\n+}\n+\n+private[tree] object BaggedPoint {\n+\n+  /**\n+   * Convert an input dataset into its BaggedPoint representation,\n+   * choosing subsample counts for each instance.\n+   * Each subsample has the same number of instances as the original dataset,\n+   * and is created by subsampling with replacement.\n+   * @param input     Input dataset.\n+   * @param numSubsamples  Number of subsamples of this RDD to take.\n+   * @param seed   Random seed.\n+   * @return  BaggedPoint dataset representation\n+   */\n+  def convertToBaggedRDD[Datum](\n+      input: RDD[Datum],\n+      numSubsamples: Int,\n+      seed: Int = Utils.random.nextInt()): RDD[BaggedPoint[Datum]] = {",
    "line": 59
  }],
  "prId": 2435
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "space before `{`\n",
    "commit": "c6941748b58f5b77a480cfbc85cdece9ce8dec5a",
    "createdAt": "2014-09-23T22:21:22Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.impl\n+\n+import cern.jet.random.Poisson\n+import cern.jet.random.engine.DRand\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Internal representation of a datapoint which belongs to several subsamples of the same dataset,\n+ * particularly for bagging (e.g., for random forests).\n+ *\n+ * This holds one instance, as well as an array of weights which represent the (weighted)\n+ * number of times which this instance appears in each subsample.\n+ * E.g., (datum, [1, 0, 4]) indicates that there are 3 subsamples of the dataset and that\n+ * this datum has 1 copy, 0 copies, and 4 copies in the 3 subsamples, respectively.\n+ *\n+ * @param datum  Data instance\n+ * @param subsampleWeights  Weight of this instance in each subsampled dataset.\n+ *\n+ * TODO: This does not currently support (Double) weighted instances.  Once MLlib has weighted\n+ *       dataset support, update.  (We store subsampleWeights as Double for this future extension.)\n+ */\n+private[tree] class BaggedPoint[Datum](val datum: Datum, val subsampleWeights: Array[Double])\n+  extends Serializable {\n+}\n+\n+private[tree] object BaggedPoint {\n+\n+  /**\n+   * Convert an input dataset into its BaggedPoint representation,\n+   * choosing subsample counts for each instance.\n+   * Each subsample has the same number of instances as the original dataset,\n+   * and is created by subsampling with replacement.\n+   * @param input     Input dataset.\n+   * @param numSubsamples  Number of subsamples of this RDD to take.\n+   * @param seed   Random seed.\n+   * @return  BaggedPoint dataset representation\n+   */\n+  def convertToBaggedRDD[Datum](\n+      input: RDD[Datum],\n+      numSubsamples: Int,\n+      seed: Int = Utils.random.nextInt()): RDD[BaggedPoint[Datum]] = {\n+    input.mapPartitionsWithIndex{ (partitionIndex, instances) =>"
  }],
  "prId": 2435
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "space before `{`\n",
    "commit": "c6941748b58f5b77a480cfbc85cdece9ce8dec5a",
    "createdAt": "2014-09-23T22:21:24Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.tree.impl\n+\n+import cern.jet.random.Poisson\n+import cern.jet.random.engine.DRand\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Internal representation of a datapoint which belongs to several subsamples of the same dataset,\n+ * particularly for bagging (e.g., for random forests).\n+ *\n+ * This holds one instance, as well as an array of weights which represent the (weighted)\n+ * number of times which this instance appears in each subsample.\n+ * E.g., (datum, [1, 0, 4]) indicates that there are 3 subsamples of the dataset and that\n+ * this datum has 1 copy, 0 copies, and 4 copies in the 3 subsamples, respectively.\n+ *\n+ * @param datum  Data instance\n+ * @param subsampleWeights  Weight of this instance in each subsampled dataset.\n+ *\n+ * TODO: This does not currently support (Double) weighted instances.  Once MLlib has weighted\n+ *       dataset support, update.  (We store subsampleWeights as Double for this future extension.)\n+ */\n+private[tree] class BaggedPoint[Datum](val datum: Datum, val subsampleWeights: Array[Double])\n+  extends Serializable {\n+}\n+\n+private[tree] object BaggedPoint {\n+\n+  /**\n+   * Convert an input dataset into its BaggedPoint representation,\n+   * choosing subsample counts for each instance.\n+   * Each subsample has the same number of instances as the original dataset,\n+   * and is created by subsampling with replacement.\n+   * @param input     Input dataset.\n+   * @param numSubsamples  Number of subsamples of this RDD to take.\n+   * @param seed   Random seed.\n+   * @return  BaggedPoint dataset representation\n+   */\n+  def convertToBaggedRDD[Datum](\n+      input: RDD[Datum],\n+      numSubsamples: Int,\n+      seed: Int = Utils.random.nextInt()): RDD[BaggedPoint[Datum]] = {\n+    input.mapPartitionsWithIndex{ (partitionIndex, instances) =>\n+      // TODO: Support different sampling rates, and sampling without replacement.\n+      // Use random seed = seed + partitionIndex + 1 to make generation reproducible.\n+      val poisson = new Poisson(1.0, new DRand(seed + partitionIndex + 1))\n+      instances.map{ instance =>"
  }],
  "prId": 2435
}]