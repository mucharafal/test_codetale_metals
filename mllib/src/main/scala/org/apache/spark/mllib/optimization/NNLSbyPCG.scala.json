[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Add an empty line to separate spark imports from 3rd-party ones.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T04:56:46Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Mark it `private[mllib]`.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T04:57:09Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+object NNLSbyPCG {"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Could you add more comments about the exact problem you are solving? It can help understand the code.\n\n```\nminimize 1/2 * x^T (AtA) x - (Atb)^T x\nsubject to x >= 0.\n```\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T05:06:14Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+object NNLSbyPCG {\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b."
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Btw, if there is a reference for the implementation, please provide the reference. Otherwise, please add more comments about the difference here from a standard projected gradient/CG method.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T05:12:38Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+object NNLSbyPCG {\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b."
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Since the class name is `NNLS`, we expect `nonnegative = true`. The unconstrained case should be handled by direct solvers.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T05:10:14Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+object NNLSbyPCG {\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean): Array[Double] = {"
  }, {
    "author": {
      "login": "tmyklebu"
    },
    "body": "@mengxr Should be handled that way, but I prefer this since it lets me check that CG is kicking in.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T16:21:40Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+object NNLSbyPCG {\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean): Array[Double] = {"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Use camelCase: `lastDir`\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T05:15:49Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+object NNLSbyPCG {\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean): Array[Double] = {\n+    val n = atb.rows\n+    val scratch = new DoubleMatrix(n, 1)\n+\n+    // find the optimal unconstrained step\n+    def steplen(dir: DoubleMatrix, resid: DoubleMatrix): Double = {\n+      val top = SimpleBlas.dot(dir, resid)\n+      SimpleBlas.gemv(1.0, ata, dir, 0.0, scratch)\n+      // Push the denominator upward very slightly to avoid infinities and silliness\n+      top / (SimpleBlas.dot(scratch, dir) + 1e-20)\n+    }\n+\n+    // stopping condition\n+    def stop(step: Double, ndir: Double, nx: Double): Boolean = {\n+        ((step != step) // NaN\n+      || (step < 1e-6) // too small or negative\n+      || (step > 1e40) // too small; almost certainly numerical problems\n+      || (ndir < 1e-12 * nx) // gradient relatively too small\n+      || (ndir < 1e-32) // gradient absolutely too small; numerical issues may lurk\n+      )\n+    }\n+\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastdir = new DoubleMatrix(n, 1)"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`lastNorm`\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T05:15:58Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+object NNLSbyPCG {\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean): Array[Double] = {\n+    val n = atb.rows\n+    val scratch = new DoubleMatrix(n, 1)\n+\n+    // find the optimal unconstrained step\n+    def steplen(dir: DoubleMatrix, resid: DoubleMatrix): Double = {\n+      val top = SimpleBlas.dot(dir, resid)\n+      SimpleBlas.gemv(1.0, ata, dir, 0.0, scratch)\n+      // Push the denominator upward very slightly to avoid infinities and silliness\n+      top / (SimpleBlas.dot(scratch, dir) + 1e-20)\n+    }\n+\n+    // stopping condition\n+    def stop(step: Double, ndir: Double, nx: Double): Boolean = {\n+        ((step != step) // NaN\n+      || (step < 1e-6) // too small or negative\n+      || (step > 1e40) // too small; almost certainly numerical problems\n+      || (ndir < 1e-12 * nx) // gradient relatively too small\n+      || (ndir < 1e-32) // gradient absolutely too small; numerical issues may lurk\n+      )\n+    }\n+\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastdir = new DoubleMatrix(n, 1)\n+    val resid = new DoubleMatrix(n, 1)\n+    var lastnorm = 0.0"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "rename to `lastWall` and also add comment about this variable\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T05:16:30Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+object NNLSbyPCG {\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean): Array[Double] = {\n+    val n = atb.rows\n+    val scratch = new DoubleMatrix(n, 1)\n+\n+    // find the optimal unconstrained step\n+    def steplen(dir: DoubleMatrix, resid: DoubleMatrix): Double = {\n+      val top = SimpleBlas.dot(dir, resid)\n+      SimpleBlas.gemv(1.0, ata, dir, 0.0, scratch)\n+      // Push the denominator upward very slightly to avoid infinities and silliness\n+      top / (SimpleBlas.dot(scratch, dir) + 1e-20)\n+    }\n+\n+    // stopping condition\n+    def stop(step: Double, ndir: Double, nx: Double): Boolean = {\n+        ((step != step) // NaN\n+      || (step < 1e-6) // too small or negative\n+      || (step > 1e40) // too small; almost certainly numerical problems\n+      || (ndir < 1e-12 * nx) // gradient relatively too small\n+      || (ndir < 1e-32) // gradient absolutely too small; numerical issues may lurk\n+      )\n+    }\n+\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastdir = new DoubleMatrix(n, 1)\n+    val resid = new DoubleMatrix(n, 1)\n+    var lastnorm = 0.0\n+    var iterno = 0\n+    var lastwall = 0"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`resid` is not a common acronym for residual. Use either `res` or `residual`.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T05:41:17Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+object NNLSbyPCG {\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean): Array[Double] = {\n+    val n = atb.rows\n+    val scratch = new DoubleMatrix(n, 1)\n+\n+    // find the optimal unconstrained step\n+    def steplen(dir: DoubleMatrix, resid: DoubleMatrix): Double = {\n+      val top = SimpleBlas.dot(dir, resid)\n+      SimpleBlas.gemv(1.0, ata, dir, 0.0, scratch)\n+      // Push the denominator upward very slightly to avoid infinities and silliness\n+      top / (SimpleBlas.dot(scratch, dir) + 1e-20)\n+    }\n+\n+    // stopping condition\n+    def stop(step: Double, ndir: Double, nx: Double): Boolean = {\n+        ((step != step) // NaN\n+      || (step < 1e-6) // too small or negative\n+      || (step > 1e40) // too small; almost certainly numerical problems\n+      || (ndir < 1e-12 * nx) // gradient relatively too small\n+      || (ndir < 1e-32) // gradient absolutely too small; numerical issues may lurk\n+      )\n+    }\n+\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastdir = new DoubleMatrix(n, 1)\n+    val resid = new DoubleMatrix(n, 1)"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`stepSize` or `stepLength`?\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T05:42:42Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+object NNLSbyPCG {\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean): Array[Double] = {\n+    val n = atb.rows\n+    val scratch = new DoubleMatrix(n, 1)\n+\n+    // find the optimal unconstrained step\n+    def steplen(dir: DoubleMatrix, resid: DoubleMatrix): Double = {"
  }, {
    "author": {
      "login": "tmyklebu"
    },
    "body": "Traditional name for this is \"alpha.\"  I'll go with stepLength.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-21T16:19:44Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+object NNLSbyPCG {\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean): Array[Double] = {\n+    val n = atb.rows\n+    val scratch = new DoubleMatrix(n, 1)\n+\n+    // find the optimal unconstrained step\n+    def steplen(dir: DoubleMatrix, resid: DoubleMatrix): Double = {"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Remove extra empty lines.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T06:39:02Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+"
  }, {
    "author": {
      "login": "tmyklebu"
    },
    "body": "I removed Line 24 here.  Seems like your coding style has two newlines after the package statement and two newlines between external imports and Spark imports.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T16:57:54Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Since this is already package private, we don't need the annotation.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T06:44:31Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Do you think `NNLS` a better name? Then we can have `solveByPCG` as the method name (and possibly add other methods in the future). We can keep the default `solve` and link it to `solveByPCG`.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T06:46:00Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+private[mllib] object NNLSbyPCG {"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Use `DoubleMatrix#fill(0.0)`.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T06:47:10Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+private[mllib] object NNLSbyPCG {\n+  class Workspace(val n: Int) {\n+    val scratch = new DoubleMatrix(n, 1)\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastDir = new DoubleMatrix(n, 1)\n+    val res = new DoubleMatrix(n, 1)\n+\n+    def wipe() {\n+      var i: Int = 0\n+      while (i < n) {\n+        scratch.data(i) = 0.0"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Do we need to mention `lambda I` somewhere? It is actually `AtA + \\lambda I`. \n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T06:48:29Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+private[mllib] object NNLSbyPCG {\n+  class Workspace(val n: Int) {\n+    val scratch = new DoubleMatrix(n, 1)\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastDir = new DoubleMatrix(n, 1)\n+    val res = new DoubleMatrix(n, 1)\n+\n+    def wipe() {\n+      var i: Int = 0\n+      while (i < n) {\n+        scratch.data(i) = 0.0\n+        grad.data(i) = 0.0\n+        x.data(i) = 0.0\n+        dir.data(i) = 0.0\n+        lastDir.data(i) = 0.0\n+        res.data(i) = 0.0\n+        i = i + 1\n+      }\n+    }\n+  }\n+\n+  def createWorkspace(n: Int): Workspace = {\n+    new Workspace(n)\n+  }\n+\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   *\n+   * We solve the problem\n+   *   min_x      1/2 x^T ata x^T - x^T atb"
  }, {
    "author": {
      "login": "tmyklebu"
    },
    "body": "@mengxr I don't think so.  Regularisation is equivalent to tossing a new block of constraints that just say \"lambda x = 0\" in this context.  So it's already rolled into ata and atb before it makes it to the NNLS solver.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T16:59:17Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+private[mllib] object NNLSbyPCG {\n+  class Workspace(val n: Int) {\n+    val scratch = new DoubleMatrix(n, 1)\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastDir = new DoubleMatrix(n, 1)\n+    val res = new DoubleMatrix(n, 1)\n+\n+    def wipe() {\n+      var i: Int = 0\n+      while (i < n) {\n+        scratch.data(i) = 0.0\n+        grad.data(i) = 0.0\n+        x.data(i) = 0.0\n+        dir.data(i) = 0.0\n+        lastDir.data(i) = 0.0\n+        res.data(i) = 0.0\n+        i = i + 1\n+      }\n+    }\n+  }\n+\n+  def createWorkspace(n: Int): Workspace = {\n+    new Workspace(n)\n+  }\n+\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   *\n+   * We solve the problem\n+   *   min_x      1/2 x^T ata x^T - x^T atb"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "The `nonnegative` is not necessary. It can solve unconstrained LS iteratively, but we have better algorithms for that, like LSQR and QR/SVD. Also, the object name is `NNLS`.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T06:52:37Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+private[mllib] object NNLSbyPCG {\n+  class Workspace(val n: Int) {\n+    val scratch = new DoubleMatrix(n, 1)\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastDir = new DoubleMatrix(n, 1)\n+    val res = new DoubleMatrix(n, 1)\n+\n+    def wipe() {\n+      var i: Int = 0\n+      while (i < n) {\n+        scratch.data(i) = 0.0\n+        grad.data(i) = 0.0\n+        x.data(i) = 0.0\n+        dir.data(i) = 0.0\n+        lastDir.data(i) = 0.0\n+        res.data(i) = 0.0\n+        i = i + 1\n+      }\n+    }\n+  }\n+\n+  def createWorkspace(n: Int): Workspace = {\n+    new Workspace(n)\n+  }\n+\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   *\n+   * We solve the problem\n+   *   min_x      1/2 x^T ata x^T - x^T atb\n+   *   subject to x >= 0 (if nonnegative == true)\n+   *\n+   * The method used is similar to one described by Polyak (B. T. Polyak, The conjugate gradient\n+   * method in extremal problems, Zh. Vychisl. Mat. Mat. Fiz. 9(4)(1969), pp. 94-112) for bound-\n+   * constrained nonlinear programming.  Polyak unconditionally uses a conjugate gradient\n+   * direction, however, while this method only uses a conjugate gradient direction if the last\n+   * iteration did not cause a previously-inactive constraint to become active.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean,"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Scala has `Double#isNaN`\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T06:55:00Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+private[mllib] object NNLSbyPCG {\n+  class Workspace(val n: Int) {\n+    val scratch = new DoubleMatrix(n, 1)\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastDir = new DoubleMatrix(n, 1)\n+    val res = new DoubleMatrix(n, 1)\n+\n+    def wipe() {\n+      var i: Int = 0\n+      while (i < n) {\n+        scratch.data(i) = 0.0\n+        grad.data(i) = 0.0\n+        x.data(i) = 0.0\n+        dir.data(i) = 0.0\n+        lastDir.data(i) = 0.0\n+        res.data(i) = 0.0\n+        i = i + 1\n+      }\n+    }\n+  }\n+\n+  def createWorkspace(n: Int): Workspace = {\n+    new Workspace(n)\n+  }\n+\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   *\n+   * We solve the problem\n+   *   min_x      1/2 x^T ata x^T - x^T atb\n+   *   subject to x >= 0 (if nonnegative == true)\n+   *\n+   * The method used is similar to one described by Polyak (B. T. Polyak, The conjugate gradient\n+   * method in extremal problems, Zh. Vychisl. Mat. Mat. Fiz. 9(4)(1969), pp. 94-112) for bound-\n+   * constrained nonlinear programming.  Polyak unconditionally uses a conjugate gradient\n+   * direction, however, while this method only uses a conjugate gradient direction if the last\n+   * iteration did not cause a previously-inactive constraint to become active.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean,\n+      ws: Workspace): Array[Double] = {\n+    ws.wipe()\n+\n+    val n = atb.rows\n+    val scratch = ws.scratch\n+\n+    // find the optimal unconstrained step\n+    def steplen(dir: DoubleMatrix, res: DoubleMatrix): Double = {\n+      val top = SimpleBlas.dot(dir, res)\n+      SimpleBlas.gemv(1.0, ata, dir, 0.0, scratch)\n+      // Push the denominator upward very slightly to avoid infinities and silliness\n+      top / (SimpleBlas.dot(scratch, dir) + 1e-20)\n+    }\n+\n+    // stopping condition\n+    def stop(step: Double, ndir: Double, nx: Double): Boolean = {\n+        ((step != step) // NaN"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`unconstrained step` -> `unconstrained CG step`? Both gradient descent and CG are used.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T07:01:13Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+private[mllib] object NNLSbyPCG {\n+  class Workspace(val n: Int) {\n+    val scratch = new DoubleMatrix(n, 1)\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastDir = new DoubleMatrix(n, 1)\n+    val res = new DoubleMatrix(n, 1)\n+\n+    def wipe() {\n+      var i: Int = 0\n+      while (i < n) {\n+        scratch.data(i) = 0.0\n+        grad.data(i) = 0.0\n+        x.data(i) = 0.0\n+        dir.data(i) = 0.0\n+        lastDir.data(i) = 0.0\n+        res.data(i) = 0.0\n+        i = i + 1\n+      }\n+    }\n+  }\n+\n+  def createWorkspace(n: Int): Workspace = {\n+    new Workspace(n)\n+  }\n+\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   *\n+   * We solve the problem\n+   *   min_x      1/2 x^T ata x^T - x^T atb\n+   *   subject to x >= 0 (if nonnegative == true)\n+   *\n+   * The method used is similar to one described by Polyak (B. T. Polyak, The conjugate gradient\n+   * method in extremal problems, Zh. Vychisl. Mat. Mat. Fiz. 9(4)(1969), pp. 94-112) for bound-\n+   * constrained nonlinear programming.  Polyak unconditionally uses a conjugate gradient\n+   * direction, however, while this method only uses a conjugate gradient direction if the last\n+   * iteration did not cause a previously-inactive constraint to become active.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean,\n+      ws: Workspace): Array[Double] = {\n+    ws.wipe()\n+\n+    val n = atb.rows\n+    val scratch = ws.scratch\n+\n+    // find the optimal unconstrained step"
  }, {
    "author": {
      "login": "tmyklebu"
    },
    "body": "@mengxr We have a search direction and a quadratic objective function.  This finds the minimum value of the quadratic along the given line, ignoring nonnegativity constraints.  Works whether you have a CG or a steepest descent direction (and it's used for both).\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T17:01:05Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+private[mllib] object NNLSbyPCG {\n+  class Workspace(val n: Int) {\n+    val scratch = new DoubleMatrix(n, 1)\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastDir = new DoubleMatrix(n, 1)\n+    val res = new DoubleMatrix(n, 1)\n+\n+    def wipe() {\n+      var i: Int = 0\n+      while (i < n) {\n+        scratch.data(i) = 0.0\n+        grad.data(i) = 0.0\n+        x.data(i) = 0.0\n+        dir.data(i) = 0.0\n+        lastDir.data(i) = 0.0\n+        res.data(i) = 0.0\n+        i = i + 1\n+      }\n+    }\n+  }\n+\n+  def createWorkspace(n: Int): Workspace = {\n+    new Workspace(n)\n+  }\n+\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   *\n+   * We solve the problem\n+   *   min_x      1/2 x^T ata x^T - x^T atb\n+   *   subject to x >= 0 (if nonnegative == true)\n+   *\n+   * The method used is similar to one described by Polyak (B. T. Polyak, The conjugate gradient\n+   * method in extremal problems, Zh. Vychisl. Mat. Mat. Fiz. 9(4)(1969), pp. 94-112) for bound-\n+   * constrained nonlinear programming.  Polyak unconditionally uses a conjugate gradient\n+   * direction, however, while this method only uses a conjugate gradient direction if the last\n+   * iteration did not cause a previously-inactive constraint to become active.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean,\n+      ws: Workspace): Array[Double] = {\n+    ws.wipe()\n+\n+    val n = atb.rows\n+    val scratch = ws.scratch\n+\n+    // find the optimal unconstrained step"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`step = x.data(i) / dir.data(i)`.\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T07:07:21Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+private[mllib] object NNLSbyPCG {\n+  class Workspace(val n: Int) {\n+    val scratch = new DoubleMatrix(n, 1)\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastDir = new DoubleMatrix(n, 1)\n+    val res = new DoubleMatrix(n, 1)\n+\n+    def wipe() {\n+      var i: Int = 0\n+      while (i < n) {\n+        scratch.data(i) = 0.0\n+        grad.data(i) = 0.0\n+        x.data(i) = 0.0\n+        dir.data(i) = 0.0\n+        lastDir.data(i) = 0.0\n+        res.data(i) = 0.0\n+        i = i + 1\n+      }\n+    }\n+  }\n+\n+  def createWorkspace(n: Int): Workspace = {\n+    new Workspace(n)\n+  }\n+\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   *\n+   * We solve the problem\n+   *   min_x      1/2 x^T ata x^T - x^T atb\n+   *   subject to x >= 0 (if nonnegative == true)\n+   *\n+   * The method used is similar to one described by Polyak (B. T. Polyak, The conjugate gradient\n+   * method in extremal problems, Zh. Vychisl. Mat. Mat. Fiz. 9(4)(1969), pp. 94-112) for bound-\n+   * constrained nonlinear programming.  Polyak unconditionally uses a conjugate gradient\n+   * direction, however, while this method only uses a conjugate gradient direction if the last\n+   * iteration did not cause a previously-inactive constraint to become active.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean,\n+      ws: Workspace): Array[Double] = {\n+    ws.wipe()\n+\n+    val n = atb.rows\n+    val scratch = ws.scratch\n+\n+    // find the optimal unconstrained step\n+    def steplen(dir: DoubleMatrix, res: DoubleMatrix): Double = {\n+      val top = SimpleBlas.dot(dir, res)\n+      SimpleBlas.gemv(1.0, ata, dir, 0.0, scratch)\n+      // Push the denominator upward very slightly to avoid infinities and silliness\n+      top / (SimpleBlas.dot(scratch, dir) + 1e-20)\n+    }\n+\n+    // stopping condition\n+    def stop(step: Double, ndir: Double, nx: Double): Boolean = {\n+        ((step != step) // NaN\n+      || (step < 1e-6) // too small or negative\n+      || (step > 1e40) // too small; almost certainly numerical problems\n+      || (ndir < 1e-12 * nx) // gradient relatively too small\n+      || (ndir < 1e-32) // gradient absolutely too small; numerical issues may lurk\n+      )\n+    }\n+\n+    val grad = ws.grad\n+    val x = ws.x\n+    val dir = ws.dir\n+    val lastDir = ws.lastDir\n+    val res = ws.res\n+    val iterMax = Math.max(400, 20 * n)\n+    var lastNorm = 0.0\n+    var iterno = 0\n+    var lastWall = 0 // Last iteration when we hit a bound constraint.\n+    var i = 0\n+    while (iterno < iterMax) {\n+      // find the residual\n+      SimpleBlas.gemv(1.0, ata, x, 0.0, res)\n+      SimpleBlas.axpy(-1.0, atb, res)\n+      SimpleBlas.copy(res, grad)\n+\n+      // project the gradient\n+      if (nonnegative) {\n+        i = 0\n+        while (i < n) {\n+          if (grad.data(i) > 0.0 && x.data(i) == 0.0) {\n+            grad.data(i) = 0.0\n+          }\n+          i = i + 1\n+        }\n+      }\n+      val ngrad = SimpleBlas.dot(grad, grad)\n+\n+      SimpleBlas.copy(grad, dir)\n+\n+      // use a CG direction under certain conditions\n+      var step = steplen(grad, res)\n+      var ndir = 0.0\n+      val nx = SimpleBlas.dot(x, x)\n+      if (iterno > lastWall + 1) {\n+        val alpha = ngrad / lastNorm\n+        SimpleBlas.axpy(alpha, lastDir, dir)\n+        val dstep = steplen(dir, res)\n+        ndir = SimpleBlas.dot(dir, dir)\n+        if (stop(dstep, ndir, nx)) {\n+          // reject the CG step if it could lead to premature termination\n+          SimpleBlas.copy(grad, dir)\n+          ndir = SimpleBlas.dot(dir, dir)\n+        } else {\n+          step = dstep\n+        }\n+      } else {\n+        ndir = SimpleBlas.dot(dir, dir)\n+      }\n+\n+      // terminate?\n+      if (stop(step, ndir, nx)) {\n+        return x.data.clone\n+      }\n+\n+      // don't run through the walls\n+      if (nonnegative) {\n+        i = 0\n+        while (i < n) {\n+          if (step * dir.data(i) > x.data(i)) {\n+            step = Math.min(step, x.data(i) / dir.data(i))"
  }],
  "prId": 460
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "```\n} else {\n  x.data(i) -= step * dir.data(i)\n}\n```\n",
    "commit": "79bc4b5650ba91ccd76a4e07c5b4b9e6adbf3d7b",
    "createdAt": "2014-04-25T07:09:10Z",
    "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.optimization\n+\n+import org.jblas.{DoubleMatrix, SimpleBlas}\n+\n+import org.apache.spark.annotation.DeveloperApi\n+\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Object used to solve nonnegative least squares problems using a modified\n+ * projected gradient method.\n+ */\n+@DeveloperApi\n+private[mllib] object NNLSbyPCG {\n+  class Workspace(val n: Int) {\n+    val scratch = new DoubleMatrix(n, 1)\n+    val grad = new DoubleMatrix(n, 1)\n+    val x = new DoubleMatrix(n, 1)\n+    val dir = new DoubleMatrix(n, 1)\n+    val lastDir = new DoubleMatrix(n, 1)\n+    val res = new DoubleMatrix(n, 1)\n+\n+    def wipe() {\n+      var i: Int = 0\n+      while (i < n) {\n+        scratch.data(i) = 0.0\n+        grad.data(i) = 0.0\n+        x.data(i) = 0.0\n+        dir.data(i) = 0.0\n+        lastDir.data(i) = 0.0\n+        res.data(i) = 0.0\n+        i = i + 1\n+      }\n+    }\n+  }\n+\n+  def createWorkspace(n: Int): Workspace = {\n+    new Workspace(n)\n+  }\n+\n+  /**\n+   * Solve a least squares problem, possibly with nonnegativity constraints, by a modified\n+   * projected gradient method.  That is, find x minimising ||Ax - b||_2 given A^T A and A^T b.\n+   *\n+   * We solve the problem\n+   *   min_x      1/2 x^T ata x^T - x^T atb\n+   *   subject to x >= 0 (if nonnegative == true)\n+   *\n+   * The method used is similar to one described by Polyak (B. T. Polyak, The conjugate gradient\n+   * method in extremal problems, Zh. Vychisl. Mat. Mat. Fiz. 9(4)(1969), pp. 94-112) for bound-\n+   * constrained nonlinear programming.  Polyak unconditionally uses a conjugate gradient\n+   * direction, however, while this method only uses a conjugate gradient direction if the last\n+   * iteration did not cause a previously-inactive constraint to become active.\n+   */\n+  def solve(ata: DoubleMatrix, atb: DoubleMatrix, nonnegative: Boolean,\n+      ws: Workspace): Array[Double] = {\n+    ws.wipe()\n+\n+    val n = atb.rows\n+    val scratch = ws.scratch\n+\n+    // find the optimal unconstrained step\n+    def steplen(dir: DoubleMatrix, res: DoubleMatrix): Double = {\n+      val top = SimpleBlas.dot(dir, res)\n+      SimpleBlas.gemv(1.0, ata, dir, 0.0, scratch)\n+      // Push the denominator upward very slightly to avoid infinities and silliness\n+      top / (SimpleBlas.dot(scratch, dir) + 1e-20)\n+    }\n+\n+    // stopping condition\n+    def stop(step: Double, ndir: Double, nx: Double): Boolean = {\n+        ((step != step) // NaN\n+      || (step < 1e-6) // too small or negative\n+      || (step > 1e40) // too small; almost certainly numerical problems\n+      || (ndir < 1e-12 * nx) // gradient relatively too small\n+      || (ndir < 1e-32) // gradient absolutely too small; numerical issues may lurk\n+      )\n+    }\n+\n+    val grad = ws.grad\n+    val x = ws.x\n+    val dir = ws.dir\n+    val lastDir = ws.lastDir\n+    val res = ws.res\n+    val iterMax = Math.max(400, 20 * n)\n+    var lastNorm = 0.0\n+    var iterno = 0\n+    var lastWall = 0 // Last iteration when we hit a bound constraint.\n+    var i = 0\n+    while (iterno < iterMax) {\n+      // find the residual\n+      SimpleBlas.gemv(1.0, ata, x, 0.0, res)\n+      SimpleBlas.axpy(-1.0, atb, res)\n+      SimpleBlas.copy(res, grad)\n+\n+      // project the gradient\n+      if (nonnegative) {\n+        i = 0\n+        while (i < n) {\n+          if (grad.data(i) > 0.0 && x.data(i) == 0.0) {\n+            grad.data(i) = 0.0\n+          }\n+          i = i + 1\n+        }\n+      }\n+      val ngrad = SimpleBlas.dot(grad, grad)\n+\n+      SimpleBlas.copy(grad, dir)\n+\n+      // use a CG direction under certain conditions\n+      var step = steplen(grad, res)\n+      var ndir = 0.0\n+      val nx = SimpleBlas.dot(x, x)\n+      if (iterno > lastWall + 1) {\n+        val alpha = ngrad / lastNorm\n+        SimpleBlas.axpy(alpha, lastDir, dir)\n+        val dstep = steplen(dir, res)\n+        ndir = SimpleBlas.dot(dir, dir)\n+        if (stop(dstep, ndir, nx)) {\n+          // reject the CG step if it could lead to premature termination\n+          SimpleBlas.copy(grad, dir)\n+          ndir = SimpleBlas.dot(dir, dir)\n+        } else {\n+          step = dstep\n+        }\n+      } else {\n+        ndir = SimpleBlas.dot(dir, dir)\n+      }\n+\n+      // terminate?\n+      if (stop(step, ndir, nx)) {\n+        return x.data.clone\n+      }\n+\n+      // don't run through the walls\n+      if (nonnegative) {\n+        i = 0\n+        while (i < n) {\n+          if (step * dir.data(i) > x.data(i)) {\n+            step = Math.min(step, x.data(i) / dir.data(i))\n+          }\n+          i = i + 1\n+        }\n+      }\n+\n+      // take the step\n+      i = 0\n+      while (i < n) {\n+        if (nonnegative) {\n+          if (step * dir.data(i) > x.data(i) * (1 - 1e-14)) {\n+            x.data(i) = 0\n+            lastWall = iterno\n+          } else x.data(i) -= step * dir.data(i)"
  }],
  "prId": 460
}]