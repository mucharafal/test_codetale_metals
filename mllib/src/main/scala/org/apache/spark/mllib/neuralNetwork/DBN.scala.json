[{
  "comments": [{
    "author": {
      "login": "witgo"
    },
    "body": " The last layer should be also trained?\n",
    "commit": "de47aafc5f721167d64ebc7b987b43375ef26798",
    "createdAt": "2014-11-16T16:08:59Z",
    "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.neuralNetwork\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.mllib.linalg.{Vector => SV}\n+import org.apache.spark.rdd.RDD\n+\n+class DBN(val stackedRBM: StackedRBM, val nn: NN)\n+  extends Logging with Serializable {\n+}\n+\n+object DBN extends Logging {\n+  def train(\n+    data: RDD[(SV, SV)],\n+    batchSize: Int,\n+    numIteration: Int,\n+    topology: Array[Int],\n+    fraction: Double,\n+    momentum: Double,\n+    weightCost: Double,\n+    learningRate: Double): DBN = {\n+    val dbn = initializeDBN(topology)\n+    pretrain(data, batchSize, numIteration, dbn,\n+      fraction, momentum, weightCost, learningRate)\n+    NN.train(data, batchSize, numIteration, dbn.nn,\n+      fraction, momentum, weightCost, learningRate)\n+    dbn\n+  }\n+\n+  private[mllib] def pretrain(\n+    data: RDD[(SV, SV)],\n+    batchSize: Int,\n+    numIteration: Int,\n+    dbn: DBN,\n+    fraction: Double,\n+    momentum: Double,\n+    weightCost: Double,\n+    learningRate: Double): DBN = {\n+    StackedRBM.train(data.map(_._1), batchSize, numIteration, dbn.stackedRBM,\n+      fraction, momentum, weightCost, learningRate, dbn.stackedRBM.numLayer - 1)"
  }, {
    "author": {
      "login": "Lewuathe"
    },
    "body": "I think it all depends on the problem. Last layer usually is changeable when it comes to classification or regression problems etc. It might not be necessary to be trained on `pretrain` only if trained on `finetune`\n",
    "commit": "de47aafc5f721167d64ebc7b987b43375ef26798",
    "createdAt": "2014-11-19T11:37:39Z",
    "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.neuralNetwork\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.mllib.linalg.{Vector => SV}\n+import org.apache.spark.rdd.RDD\n+\n+class DBN(val stackedRBM: StackedRBM, val nn: NN)\n+  extends Logging with Serializable {\n+}\n+\n+object DBN extends Logging {\n+  def train(\n+    data: RDD[(SV, SV)],\n+    batchSize: Int,\n+    numIteration: Int,\n+    topology: Array[Int],\n+    fraction: Double,\n+    momentum: Double,\n+    weightCost: Double,\n+    learningRate: Double): DBN = {\n+    val dbn = initializeDBN(topology)\n+    pretrain(data, batchSize, numIteration, dbn,\n+      fraction, momentum, weightCost, learningRate)\n+    NN.train(data, batchSize, numIteration, dbn.nn,\n+      fraction, momentum, weightCost, learningRate)\n+    dbn\n+  }\n+\n+  private[mllib] def pretrain(\n+    data: RDD[(SV, SV)],\n+    batchSize: Int,\n+    numIteration: Int,\n+    dbn: DBN,\n+    fraction: Double,\n+    momentum: Double,\n+    weightCost: Double,\n+    learningRate: Double): DBN = {\n+    StackedRBM.train(data.map(_._1), batchSize, numIteration, dbn.stackedRBM,\n+      fraction, momentum, weightCost, learningRate, dbn.stackedRBM.numLayer - 1)"
  }, {
    "author": {
      "login": "witgo"
    },
    "body": "I see, Thanks.\n",
    "commit": "de47aafc5f721167d64ebc7b987b43375ef26798",
    "createdAt": "2014-11-19T13:50:18Z",
    "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.neuralNetwork\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.mllib.linalg.{Vector => SV}\n+import org.apache.spark.rdd.RDD\n+\n+class DBN(val stackedRBM: StackedRBM, val nn: NN)\n+  extends Logging with Serializable {\n+}\n+\n+object DBN extends Logging {\n+  def train(\n+    data: RDD[(SV, SV)],\n+    batchSize: Int,\n+    numIteration: Int,\n+    topology: Array[Int],\n+    fraction: Double,\n+    momentum: Double,\n+    weightCost: Double,\n+    learningRate: Double): DBN = {\n+    val dbn = initializeDBN(topology)\n+    pretrain(data, batchSize, numIteration, dbn,\n+      fraction, momentum, weightCost, learningRate)\n+    NN.train(data, batchSize, numIteration, dbn.nn,\n+      fraction, momentum, weightCost, learningRate)\n+    dbn\n+  }\n+\n+  private[mllib] def pretrain(\n+    data: RDD[(SV, SV)],\n+    batchSize: Int,\n+    numIteration: Int,\n+    dbn: DBN,\n+    fraction: Double,\n+    momentum: Double,\n+    weightCost: Double,\n+    learningRate: Double): DBN = {\n+    StackedRBM.train(data.map(_._1), batchSize, numIteration, dbn.stackedRBM,\n+      fraction, momentum, weightCost, learningRate, dbn.stackedRBM.numLayer - 1)"
  }],
  "prId": 3222
}]