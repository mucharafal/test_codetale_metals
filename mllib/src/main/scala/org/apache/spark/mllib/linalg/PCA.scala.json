[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "For better performance, we should use while instead of for, or cast both to DoubleMatrix and use addi from jblas.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-17T07:25:42Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: DenseMatrix): DenseMatrix = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * All input and output is expected in DenseMatrix format\n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: DenseMatrix, k: Int): DenseMatrix = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    val v = computePCA(matrix.rows.map(_.data), k)\n+    val retV = DenseMatrix(sc.makeRDD(Array.tabulate(n)(i => MatrixRow(i, v(i)))), n, k)   \n+    retV\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(new Array[Double](n)){\n+      (a, b) => for(i <- 0 until n) {"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "used inplace doublematrix for better native performance\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T06:56:10Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: DenseMatrix): DenseMatrix = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * All input and output is expected in DenseMatrix format\n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: DenseMatrix, k: Int): DenseMatrix = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    val v = computePCA(matrix.rows.map(_.data), k)\n+    val retV = DenseMatrix(sc.makeRDD(Array.tabulate(n)(i => MatrixRow(i, v(i)))), n, k)   \n+    retV\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(new Array[Double](n)){\n+      (a, b) => for(i <- 0 until n) {"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`colSums(i) / m` can be pre-computed. The corner case `n <= 1` should be handled somewhere.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-17T07:27:18Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: DenseMatrix): DenseMatrix = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * All input and output is expected in DenseMatrix format\n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: DenseMatrix, k: Int): DenseMatrix = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    val v = computePCA(matrix.rows.map(_.data), k)\n+    val retV = DenseMatrix(sc.makeRDD(Array.tabulate(n)(i => MatrixRow(i, v(i)))), n, k)   \n+    retV\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(new Array[Double](n)){\n+      (a, b) => for(i <- 0 until n) {\n+                  a(i) += b(i)\n+                }\n+      a\n+    }).value\n+    \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = (x(i) - colSums(i) / m) / Math.sqrt(n - 1)"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "did the /m just once before broadcasting. also handled n<=1 by removing it, since the normalization is not needed for returning V\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T06:56:48Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: DenseMatrix): DenseMatrix = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * All input and output is expected in DenseMatrix format\n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: DenseMatrix, k: Int): DenseMatrix = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    val v = computePCA(matrix.rows.map(_.data), k)\n+    val retV = DenseMatrix(sc.makeRDD(Array.tabulate(n)(i => MatrixRow(i, v(i)))), n, k)   \n+    retV\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(new Array[Double](n)){\n+      (a, b) => for(i <- 0 until n) {\n+                  a(i) += b(i)\n+                }\n+      a\n+    }).value\n+    \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = (x(i) - colSums(i) / m) / Math.sqrt(n - 1)"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "It is rare to have tall-and-skinny data stored in COO format. Also, text format is not general for matrix data. We should think about how to extend it in the future. If we change the name to TallAndSkinnyQR, the default input format should be one line for each row.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-17T07:37:14Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: DenseMatrix): DenseMatrix = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * All input and output is expected in DenseMatrix format\n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: DenseMatrix, k: Int): DenseMatrix = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    val v = computePCA(matrix.rows.map(_.data), k)\n+    val retV = DenseMatrix(sc.makeRDD(Array.tabulate(n)(i => MatrixRow(i, v(i)))), n, k)   \n+    retV\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(new Array[Double](n)){\n+      (a, b) => for(i <- 0 until n) {\n+                  a(i) += b(i)\n+                }\n+      a\n+    }).value\n+    \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = (x(i) - colSums(i) / m) / Math.sqrt(n - 1)\n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are DenseMatrix format\n+ */\n+object PCA {\n+  def main(args: Array[String]) {\n+    if (args.length < 6) {\n+      println(\"Usage: PCA <master> <matrix_file> <m> <n> \" +\n+              \"<k> <output_coefficient_file>\")\n+      System.exit(1)\n+    }\n+\n+    val (master, inputFile, m, n, k, output_u) = \n+      (args(0), args(1), args(2).toInt, args(3).toInt,\n+      args(4).toInt, args(5))\n+    \n+    val sc = new SparkContext(master, \"PCA\")\n+    \n+    val rawData = sc.textFile(inputFile)\n+    val data = rawData.map { line =>\n+      val parts = line.split(',')\n+      MatrixEntry(parts(0).toInt, parts(1).toInt, parts(2).toDouble)"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "Changed interfaces to be as lean and specialized as possible to allow for future generalizations to all matrices without breaking\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T06:57:25Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: DenseMatrix): DenseMatrix = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * All input and output is expected in DenseMatrix format\n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: DenseMatrix, k: Int): DenseMatrix = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    val v = computePCA(matrix.rows.map(_.data), k)\n+    val retV = DenseMatrix(sc.makeRDD(Array.tabulate(n)(i => MatrixRow(i, v(i)))), n, k)   \n+    retV\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(new Array[Double](n)){\n+      (a, b) => for(i <- 0 until n) {\n+                  a(i) += b(i)\n+                }\n+      a\n+    }).value\n+    \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = (x(i) - colSums(i) / m) / Math.sqrt(n - 1)\n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are DenseMatrix format\n+ */\n+object PCA {\n+  def main(args: Array[String]) {\n+    if (args.length < 6) {\n+      println(\"Usage: PCA <master> <matrix_file> <m> <n> \" +\n+              \"<k> <output_coefficient_file>\")\n+      System.exit(1)\n+    }\n+\n+    val (master, inputFile, m, n, k, output_u) = \n+      (args(0), args(1), args(2).toInt, args(3).toInt,\n+      args(4).toInt, args(5))\n+    \n+    val sc = new SparkContext(master, \"PCA\")\n+    \n+    val rawData = sc.textFile(inputFile)\n+    val data = rawData.map { line =>\n+      val parts = line.split(',')\n+      MatrixEntry(parts(0).toInt, parts(1).toInt, parts(2).toDouble)"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Worth mentioning whether the result is row based or column based.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T20:45:43Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "done\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T23:57:32Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "forgot to push the changes?\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T06:45:46Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "This is an oudated diff, I changed it to\n\"  \\* @return An nxk matrix with principal components in columns\"\nCan see it in \"files\" section of PR\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:01:00Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "I refreshed the page but didn't see it ...\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:15:51Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Need more doc here.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T20:54:49Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "added pointer to more docs\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T00:11:47Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Remove extra empty line.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T20:55:18Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "done\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T00:12:25Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Worthing putting the values of `m` and `n` in the message.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T20:55:46Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "done\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T00:13:35Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "It is confusing to have a private `k` and let the argument `k` overwrite the private `k`. We can put this into the companion object.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T20:57:53Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "What's confusing about this? It's pretty clear. Done this way to allow adding extra parameters later on.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T00:19:23Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "We already used builder pattern for setting parameters. With this method, user can say `pca.setK(10).computePCA(data, 20)`, which is confusing.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T00:34:31Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "OK, made private, so that confusing case is not possible\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T01:36:57Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We don't need a separate job to get `m`. We can get `m` via an accumulator while computing the column sums. \n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T20:59:48Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "I thought .count was smarter than running a job - it's not? OK, replaced this with accumulator\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T01:36:48Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Make an extra space between `)` and `{`\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T21:01:04Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "`broadcast` doesn't have any positive effect here.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T21:05:30Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "done, and removed broadcast\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T01:45:41Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "append this line to the one above\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T21:01:29Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => "
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "done\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T01:45:59Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => "
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Same style issue as above.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T21:01:55Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "done\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T01:47:08Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Should not use `for` loop here.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T21:03:03Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "Replaced with while. Oh, Scala.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T01:48:06Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "wrong indentation\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T21:06:47Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = x(i) - colSums(i) \n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are TallSkinnyDenseMatrix format\n+ */\n+object PCA {\n+  def main(args: Array[String]) {\n+    if (args.length < 6) {\n+      println(\"Usage: PCA <master> <matrix_file> <m> <n> \" +\n+              \"<k> <output_coefficient_file>\")"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "This actually fits in 100 chars so we can just use a single line, ie\n\n``` scala\nprintln(\"Usage: PCA <master> <matrix_file> <m> <n> <k> <output_coefficient_file>\")\n```\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T00:26:40Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = x(i) - colSums(i) \n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are TallSkinnyDenseMatrix format\n+ */\n+object PCA {\n+  def main(args: Array[String]) {\n+    if (args.length < 6) {\n+      println(\"Usage: PCA <master> <matrix_file> <m> <n> \" +\n+              \"<k> <output_coefficient_file>\")"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "Fixed\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T01:48:18Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = x(i) - colSums(i) \n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are TallSkinnyDenseMatrix format\n+ */\n+object PCA {\n+  def main(args: Array[String]) {\n+    if (args.length < 6) {\n+      println(\"Usage: PCA <master> <matrix_file> <m> <n> \" +\n+              \"<k> <output_coefficient_file>\")"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "this line can be appended to the one above.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T21:07:09Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = x(i) - colSums(i) \n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are TallSkinnyDenseMatrix format\n+ */\n+object PCA {\n+  def main(args: Array[String]) {\n+    if (args.length < 6) {\n+      println(\"Usage: PCA <master> <matrix_file> <m> <n> \" +\n+              \"<k> <output_coefficient_file>\")\n+      System.exit(1)\n+    }\n+\n+    val (master, inputFile, m, n, k, output_u) = \n+      (args(0), args(1), args(2).toInt, args(3).toInt,\n+      args(4).toInt, args(5))"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "In the code, it still reads coo format data.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T21:07:38Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = x(i) - colSums(i) \n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are TallSkinnyDenseMatrix format"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "Removed this since it's not useful for PCA.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T01:58:15Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = x(i) - colSums(i) \n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are TallSkinnyDenseMatrix format"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "call `sc.stop()` before exit.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T21:09:09Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = x(i) - colSums(i) \n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are TallSkinnyDenseMatrix format\n+ */\n+object PCA {\n+  def main(args: Array[String]) {\n+    if (args.length < 6) {\n+      println(\"Usage: PCA <master> <matrix_file> <m> <n> \" +\n+              \"<k> <output_coefficient_file>\")\n+      System.exit(1)\n+    }\n+\n+    val (master, inputFile, m, n, k, output_u) = \n+      (args(0), args(1), args(2).toInt, args(3).toInt,\n+      args(4).toInt, args(5))\n+    \n+    val sc = new SparkContext(master, \"PCA\")\n+    \n+    val rawData = sc.textFile(inputFile)\n+    val data = rawData.map { line =>\n+      val parts = line.split(',')\n+      MatrixEntry(parts(0).toInt, parts(1).toInt, parts(2).toDouble)\n+    }\n+\n+    val u = new PCA().computePCA(LAUtils.spToDense(SparseMatrix(data, m, n)), k)\n+    \n+    println(\"Computed \" + k + \" principal vectors\")\n+    System.exit(0)"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "Removed.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T01:59:07Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = x(i) - colSums(i) \n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are TallSkinnyDenseMatrix format\n+ */\n+object PCA {\n+  def main(args: Array[String]) {\n+    if (args.length < 6) {\n+      println(\"Usage: PCA <master> <matrix_file> <m> <n> \" +\n+              \"<k> <output_coefficient_file>\")\n+      System.exit(1)\n+    }\n+\n+    val (master, inputFile, m, n, k, output_u) = \n+      (args(0), args(1), args(2).toInt, args(3).toInt,\n+      args(4).toInt, args(5))\n+    \n+    val sc = new SparkContext(master, \"PCA\")\n+    \n+    val rawData = sc.textFile(inputFile)\n+    val data = rawData.map { line =>\n+      val parts = line.split(',')\n+      MatrixEntry(parts(0).toInt, parts(1).toInt, parts(2).toDouble)\n+    }\n+\n+    val u = new PCA().computePCA(LAUtils.spToDense(SparseMatrix(data, m, n)), k)\n+    \n+    println(\"Computed \" + k + \" principal vectors\")\n+    System.exit(0)"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "remove extra lines\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-18T21:09:18Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = x(i) - colSums(i) \n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are TallSkinnyDenseMatrix format\n+ */\n+object PCA {\n+  def main(args: Array[String]) {\n+    if (args.length < 6) {\n+      println(\"Usage: PCA <master> <matrix_file> <m> <n> \" +\n+              \"<k> <output_coefficient_file>\")\n+      System.exit(1)\n+    }\n+\n+    val (master, inputFile, m, n, k, output_u) = \n+      (args(0), args(1), args(2).toInt, args(3).toInt,\n+      args(4).toInt, args(5))\n+    \n+    val sc = new SparkContext(master, \"PCA\")\n+    \n+    val rawData = sc.textFile(inputFile)\n+    val data = rawData.map { line =>\n+      val parts = line.split(',')\n+      MatrixEntry(parts(0).toInt, parts(1).toInt, parts(2).toDouble)\n+    }\n+\n+    val u = new PCA().computePCA(LAUtils.spToDense(SparseMatrix(data, m, n)), k)\n+    \n+    println(\"Computed \" + k + \" principal vectors\")\n+    System.exit(0)\n+  }\n+}\n+\n+"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "Removed.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T01:59:15Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+   * Compute PCA using the current set parameters\n+   */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+  * Compute PCA using the current set parameters\n+  */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\"Expecting a well-formed matrix\")\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+    val m = matrix.count\n+\n+    // compute column sums and normalize matrix\n+    val colSums = sc.broadcast(matrix.fold(Array.ofDim[Double](n)){\n+      (a, b) => \n+      val am = new DoubleMatrix(a)\n+      val bm = new DoubleMatrix(b)\n+      am.addi(bm)\n+      a\n+    }.map(x => x / m)).value\n+   \n+    val data = matrix.map{\n+      x => \n+        val row = Array.ofDim[Double](n)\n+        for(i <- 0 until n) {\n+          row(i) = x(i) - colSums(i) \n+        }\n+        row\n+    }           \n+   \n+    val (u, s, v) = SVD.denseSVD(data, k)\n+    v\n+  }\n+}\n+\n+\n+/**\n+ * Top-level methods for calling Principal Component Analysis\n+ * NOTE: All matrices are TallSkinnyDenseMatrix format\n+ */\n+object PCA {\n+  def main(args: Array[String]) {\n+    if (args.length < 6) {\n+      println(\"Usage: PCA <master> <matrix_file> <m> <n> \" +\n+              \"<k> <output_coefficient_file>\")\n+      System.exit(1)\n+    }\n+\n+    val (master, inputFile, m, n, k, output_u) = \n+      (args(0), args(1), args(2).toInt, args(3).toInt,\n+      args(4).toInt, args(5))\n+    \n+    val sc = new SparkContext(master, \"PCA\")\n+    \n+    val rawData = sc.textFile(inputFile)\n+    val data = rawData.map { line =>\n+      val parts = line.split(',')\n+      MatrixEntry(parts(0).toInt, parts(1).toInt, parts(2).toDouble)\n+    }\n+\n+    val u = new PCA().computePCA(LAUtils.spToDense(SparseMatrix(data, m, n)), k)\n+    \n+    println(\"Computed \" + k + \" principal vectors\")\n+    System.exit(0)\n+  }\n+}\n+\n+"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Wrong indentation.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T06:59:19Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "Man, I wish we had a tool for these. Thank you. Fixed.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:03:57Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Which editor are you using? I use idea and it handles code style properly with little extra manual effort.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:34:28Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`k` is already a member. It is not necessary to put it back as an argument.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:02:28Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "Removed\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:11:34Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "The return type is `Array[Array[Double]]`. It is nice to document whether this is row-major or column-major.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:04:51Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "Added note that columns are inner arrays. This is pretty standard, so that matrix(i)(j) is standard m_ij math notation\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:18:04Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Both row-major and column-major are standards. The doc is still ambiguous to me. `in columns` could mean:\n1. The matrix is row-based while the principal components are its columns.\n2. The result is an array of principal components.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:38:22Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "You can remove `k` and make this public.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:06:55Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\n+                \"Expecting a well-formed matrix: m=\" + m + \" n=\" + n)\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  private def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "It's already public via\ndef compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\nBetter not have two identical methods doing the same thing with different names.\nk removed though.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:19:54Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\n+                \"Expecting a well-formed matrix: m=\" + m + \" n=\" + n)\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  private def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "a nitpick: you don't need the Int here since it is obvious this is an integer.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:08:30Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "I'd rather be explicit and consistent with what's inside SVD.scala\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:21:05Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "perhaps change that as well? throughout spark codebase (and almost every other scala project) we rely on type inference when the type is very obvious. \n\nThe exception to this rule is when it's a public method (as specified by the scala style guide).\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:38:19Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "I really like this returning PCA itself to enable chaining!\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:08:43Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {",
    "line": 35
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "It was @mateiz 's idea :)\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:21:31Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {",
    "line": 35
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "Instead of making this a private method and having the 2nd argument here, why don't you just remove the 2nd argument, and make this public? (You can then remove the other compute method). This also applies to the computePCA version that takes RDD.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:09:39Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "It's already public via\n  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\nBetter not have two identical methods doing the same thing with different names.\nk removed though.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:22:15Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "why don't we just remove that method? you really only need one\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:38:50Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "You can fit this in one line (still under 100 chars) and use string comprehension to slightly improve readability\n\n``` scala\n      throw new IllegalArgumentException(s\"Expecting a well-formed matrix: m=$m n=$n\")\n```\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:10:26Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException("
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "Cool didn't know about string comprehension, done.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:24:15Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException("
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "capitalize PCA here. \n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:11:26Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\n+                \"Expecting a well-formed matrix: m=\" + m + \" n=\" + n)\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "done\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:25:01Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\n+                \"Expecting a well-formed matrix: m=\" + m + \" n=\" + n)\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "This line is probably redundant (the first sentence should start with a verb - I think the 2nd sentence is perfectly fine as the starting sentence).\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:12:15Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\n+                \"Expecting a well-formed matrix: m=\" + m + \" n=\" + n)\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+  /**\n+  * Principal Component Analysis."
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "OK done\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:26:25Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\n+                \"Expecting a well-formed matrix: m=\" + m + \" n=\" + n)\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+  /**\n+  * Principal Component Analysis."
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "The way this code block is indented is a bit hard to read. You can move the fold to the same line as the map to improve readability slightly\n\n``` scala\n    // Compute column sums and normalize matrix\n    val colSumsTemp = matrix.map(x => (x, 1)).fold((Array.ofDim[Double](n), 0)) { (a, b) => \n      val am = new DoubleMatrix(a._1)\n      val bm = new DoubleMatrix(b._1)\n      am.addi(bm)\n      (a._1, a._2 + b._2)\n    }\n```\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:14:15Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\n+                \"Expecting a well-formed matrix: m=\" + m + \" n=\" + n)\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  private def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+\n+    // compute column sums and normalize matrix\n+    val colSumsTemp = matrix.map(x => (x, 1))"
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "done\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:28:40Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\n+                \"Expecting a well-formed matrix: m=\" + m + \" n=\" + n)\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  private def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+\n+    // compute column sums and normalize matrix\n+    val colSumsTemp = matrix.map(x => (x, 1))"
  }],
  "prId": 88
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "add a space before {, and only indent 2 spaces for the body of the map; also make sure you add a space after \"while\". e.g.\n\n``` scala\n    val data = matrix.map { x => \n      val row = Array.ofDim[Double](n)\n      var i = 0\n      while (i < n) {\n        row(i) = x(i) - colSums(i)\n        i += 1 \n      }\n      row\n    }           \n```\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:15:51Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\n+                \"Expecting a well-formed matrix: m=\" + m + \" n=\" + n)\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  private def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+\n+    // compute column sums and normalize matrix\n+    val colSumsTemp = matrix.map(x => (x, 1))\n+          .fold((Array.ofDim[Double](n), 0)) { (a, b) => \n+      val am = new DoubleMatrix(a._1)\n+      val bm = new DoubleMatrix(b._1)\n+      am.addi(bm)\n+      (a._1, a._2 + b._2)\n+    }\n+\n+    val m = colSumsTemp._2 \n+    val colSums = colSumsTemp._1.map(x => x / m)\n+\n+    val data = matrix.map{ x => "
  }, {
    "author": {
      "login": "rezazadeh"
    },
    "body": "Done. Really wish we had a tool for these.\n",
    "commit": "e298700a69316d9d32bcd1ce3157f22acc4bb585",
    "createdAt": "2014-03-19T07:30:14Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.rdd.RDD\n+\n+import org.apache.spark.mllib.util._\n+\n+import org.jblas.{DoubleMatrix, Singular, MatrixFunctions}\n+\n+\n+/**\n+ * Class used to obtain principal components\n+ */\n+class PCA {\n+  private var k: Int = 1\n+\n+  /**\n+   * Set the number of top-k principle components to return\n+   */\n+  def setK(k: Int): PCA = {\n+    this.k = k\n+    this\n+  }\n+\n+   /**\n+    * Compute PCA using the current set parameters\n+    */\n+  def compute(matrix: TallSkinnyDenseMatrix): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+  /**\n+   * Compute PCA using the parameters currently set\n+   * See computePCA() for more details\n+   */\n+  def compute(matrix: RDD[Array[Double]]): Array[Array[Double]] = {\n+    computePCA(matrix, k)\n+  }\n+\n+ /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix with principal components in columns\n+  */\n+  private def computePCA(matrix: TallSkinnyDenseMatrix, k: Int): Array[Array[Double]] = {\n+    val m = matrix.m\n+    val n = matrix.n\n+    val sc = matrix.rows.sparkContext\n+\n+    if (m <= 0 || n <= 0) {\n+      throw new IllegalArgumentException(\n+                \"Expecting a well-formed matrix: m=\" + m + \" n=\" + n)\n+    }\n+\n+    computePCA(matrix.rows.map(_.data), k)\n+  }\n+\n+  /**\n+  * Principal Component Analysis.\n+  * Computes the top k principal component coefficients for the m-by-n data matrix X.\n+  * Rows of X correspond to observations and columns correspond to variables. \n+  * The coefficient matrix is n-by-k. Each column of coeff contains coefficients\n+  * for one principal component, and the columns are in descending \n+  * order of component variance.\n+  * This function centers the data and uses the \n+  * singular value decomposition (SVD) algorithm. \n+  *\n+  * @param matrix dense matrix to perform pca on\n+  * @param k Recover k principal components\n+  * @return An nxk matrix of principal components\n+  */\n+  private def computePCA(matrix: RDD[Array[Double]], k: Int): Array[Array[Double]] = {\n+    val n = matrix.first.size\n+    val sc = matrix.sparkContext\n+\n+    // compute column sums and normalize matrix\n+    val colSumsTemp = matrix.map(x => (x, 1))\n+          .fold((Array.ofDim[Double](n), 0)) { (a, b) => \n+      val am = new DoubleMatrix(a._1)\n+      val bm = new DoubleMatrix(b._1)\n+      am.addi(bm)\n+      (a._1, a._2 + b._2)\n+    }\n+\n+    val m = colSumsTemp._2 \n+    val colSums = colSumsTemp._1.map(x => x / m)\n+\n+    val data = matrix.map{ x => "
  }],
  "prId": 88
}]