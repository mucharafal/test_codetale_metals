[{
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "Call this `unionedData`\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T01:17:37Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))"
  }, {
    "author": {
      "login": "josepablocam"
    },
    "body": "changed\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T02:25:28Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Would it be clearer to write `true` and `false` instead of `isSample1` and `!isSample1`? I don't have a strong opinion.\nCan the `map` functions be like `.map((_, isSample1))` for tidiness or does that syntax not work here?\nFinally I wonder if `.union` is clearer than `++` here? I don't have a strong opinion either, just am somehow used to method invocations on RDDs and `++`-like syntax for Scala collections.\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T07:12:10Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "\"and the third is\"\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T01:19:45Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "Place this comment on the line above\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T01:21:04Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double)\n+    : Iterator[(Double, Double, Double)] = {\n+    // fold accumulator: local minimum, local maximum, index for sample 1, index for sample2\n+    case class KS2Acc(min: Double, max: Double, ix1: Int, ix2: Int)\n+    val initAcc = KS2Acc(Double.MaxValue, Double.MinValue, 0, 0)\n+    // traverse the data in partition and calculate distances and counts\n+    val pResults = partData.foldLeft(initAcc) { case (acc: KS2Acc, (v, isSample1)) =>\n+      val (add1, add2) = if (isSample1) (1, 0) else (0, 1)\n+      val cdf1 = (acc.ix1 + add1) / n1\n+      val cdf2 = (acc.ix2 + add2) / n2\n+      val dist = cdf1 - cdf2\n+      KS2Acc(math.min(acc.min, dist), math.max(acc.max, dist), acc.ix1 + add1, acc.ix2 + add2)\n+    }\n+    val results = if (pResults == initAcc) {\n+      Array[(Double, Double, Double)]()\n+    } else {\n+      Array((pResults.min, pResults.max, (pResults.ix1 + 1) * n2  -  (pResults.ix2 + 1) * n1))\n+    }\n+    results.iterator\n+  }\n+\n+  /**\n+   * Adjust candidate extremes by the appropriate constant. The resulting maximum corresponds to\n+   * the two-sample, two-sided Kolmogorov-Smirnov test\n+   * @param localData `Array[(Double, Double, Double)]` contains the candidate extremes from each\n+   *                 partition, along with the numerator for the necessary constant adjustments\n+   * @param n `Double` The denominator in the constant adjustment (i.e. (size of sample 1 ) * (size\n+   *         of sample 2))\n+   * @return The two-sample, two-sided Kolmogorov-Smirnov statistic\n+   */\n+  private def searchTwoSampleStatistic(localData: Array[(Double, Double, Double)], n: Double)\n+    : Double = {\n+    val initAcc = (Double.MinValue, 0.0) // maximum distance and numerator for constant adjustment"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "Indent this (and the contents of the block) back a step\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T01:21:29Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double)\n+    : Iterator[(Double, Double, Double)] = {\n+    // fold accumulator: local minimum, local maximum, index for sample 1, index for sample2\n+    case class KS2Acc(min: Double, max: Double, ix1: Int, ix2: Int)\n+    val initAcc = KS2Acc(Double.MaxValue, Double.MinValue, 0, 0)\n+    // traverse the data in partition and calculate distances and counts\n+    val pResults = partData.foldLeft(initAcc) { case (acc: KS2Acc, (v, isSample1)) =>\n+      val (add1, add2) = if (isSample1) (1, 0) else (0, 1)\n+      val cdf1 = (acc.ix1 + add1) / n1\n+      val cdf2 = (acc.ix2 + add2) / n2\n+      val dist = cdf1 - cdf2\n+      KS2Acc(math.min(acc.min, dist), math.max(acc.max, dist), acc.ix1 + add1, acc.ix2 + add2)\n+    }\n+    val results = if (pResults == initAcc) {\n+      Array[(Double, Double, Double)]()\n+    } else {\n+      Array((pResults.min, pResults.max, (pResults.ix1 + 1) * n2  -  (pResults.ix2 + 1) * n1))\n+    }\n+    results.iterator\n+  }\n+\n+  /**\n+   * Adjust candidate extremes by the appropriate constant. The resulting maximum corresponds to\n+   * the two-sample, two-sided Kolmogorov-Smirnov test\n+   * @param localData `Array[(Double, Double, Double)]` contains the candidate extremes from each\n+   *                 partition, along with the numerator for the necessary constant adjustments\n+   * @param n `Double` The denominator in the constant adjustment (i.e. (size of sample 1 ) * (size\n+   *         of sample 2))\n+   * @return The two-sample, two-sided Kolmogorov-Smirnov statistic\n+   */\n+  private def searchTwoSampleStatistic(localData: Array[(Double, Double, Double)], n: Double)\n+    : Double = {\n+    val initAcc = (Double.MinValue, 0.0) // maximum distance and numerator for constant adjustment\n+    // adjust differences based on the number of elements preceding it, which should provide\n+    // the correct distance between the 2 empirical CDFs\n+    val results = localData.foldLeft(initAcc) { case ((prevMax, prevCt), (minCand, maxCand, ct)) =>\n+        val adjConst = prevCt / n\n+        val dist1 = math.abs(minCand + adjConst)\n+        val dist2 = math.abs(maxCand + adjConst)\n+        val maxVal = Array(prevMax, dist1, dist2).max\n+        (maxVal, prevCt + ct)\n+      }"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "This can go on the line above\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T01:22:25Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double)\n+    : Iterator[(Double, Double, Double)] = {"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "KS2Acc is a little cryptic.  Maybe `ExtremaPositions`?\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T01:23:53Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double)\n+    : Iterator[(Double, Double, Double)] = {\n+    // fold accumulator: local minimum, local maximum, index for sample 1, index for sample2\n+    case class KS2Acc(min: Double, max: Double, ix1: Int, ix2: Int)"
  }, {
    "author": {
      "login": "josepablocam"
    },
    "body": "How about ExtremaAndRunningIndices? The indices aren't the positions of the extrema themselves, but rather than running indices that we use for the position of element i in sample 1 and sample 2, to then calculate the empirical CDF values associated with that element. \n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T02:34:02Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double)\n+    : Iterator[(Double, Double, Double)] = {\n+    // fold accumulator: local minimum, local maximum, index for sample 1, index for sample2\n+    case class KS2Acc(min: Double, max: Double, ix1: Int, ix2: Int)"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "extra space before comma\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T01:24:32Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "Looks like there are a couple spots with two consecutive spaces in here\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T01:25:57Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double)\n+    : Iterator[(Double, Double, Double)] = {\n+    // fold accumulator: local minimum, local maximum, index for sample 1, index for sample2\n+    case class KS2Acc(min: Double, max: Double, ix1: Int, ix2: Int)\n+    val initAcc = KS2Acc(Double.MaxValue, Double.MinValue, 0, 0)\n+    // traverse the data in partition and calculate distances and counts\n+    val pResults = partData.foldLeft(initAcc) { case (acc: KS2Acc, (v, isSample1)) =>\n+      val (add1, add2) = if (isSample1) (1, 0) else (0, 1)\n+      val cdf1 = (acc.ix1 + add1) / n1\n+      val cdf2 = (acc.ix2 + add2) / n2\n+      val dist = cdf1 - cdf2\n+      KS2Acc(math.min(acc.min, dist), math.max(acc.max, dist), acc.ix1 + add1, acc.ix2 + add2)\n+    }\n+    val results = if (pResults == initAcc) {\n+      Array[(Double, Double, Double)]()\n+    } else {\n+      Array((pResults.min, pResults.max, (pResults.ix1 + 1) * n2  -  (pResults.ix2 + 1) * n1))"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "nit: \"in _the_ partition\"\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T01:26:35Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double)\n+    : Iterator[(Double, Double, Double)] = {\n+    // fold accumulator: local minimum, local maximum, index for sample 1, index for sample2\n+    case class KS2Acc(min: Double, max: Double, ix1: Int, ix2: Int)\n+    val initAcc = KS2Acc(Double.MaxValue, Double.MinValue, 0, 0)\n+    // traverse the data in partition and calculate distances and counts"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "Do things go bad if we don't special case here?  Or it's just less efficient?\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T01:28:08Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double)\n+    : Iterator[(Double, Double, Double)] = {\n+    // fold accumulator: local minimum, local maximum, index for sample 1, index for sample2\n+    case class KS2Acc(min: Double, max: Double, ix1: Int, ix2: Int)\n+    val initAcc = KS2Acc(Double.MaxValue, Double.MinValue, 0, 0)\n+    // traverse the data in partition and calculate distances and counts\n+    val pResults = partData.foldLeft(initAcc) { case (acc: KS2Acc, (v, isSample1)) =>\n+      val (add1, add2) = if (isSample1) (1, 0) else (0, 1)\n+      val cdf1 = (acc.ix1 + add1) / n1\n+      val cdf2 = (acc.ix2 + add2) / n2\n+      val dist = cdf1 - cdf2\n+      KS2Acc(math.min(acc.min, dist), math.max(acc.max, dist), acc.ix1 + add1, acc.ix2 + add2)\n+    }\n+    val results = if (pResults == initAcc) {"
  }, {
    "author": {
      "login": "josepablocam"
    },
    "body": "Things go bad. The accumulator for the fold  has Double.MaxValue and Double.MinValue, to allow proper accumulator of minimums and maximums, respectively. If the partition is empty, the foldLeft still returns the accumulator. So if we don't check and replace with an empty array (on line 247), then the statistic is ruined by the max double.\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T02:37:14Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double)\n+    : Iterator[(Double, Double, Double)] = {\n+    // fold accumulator: local minimum, local maximum, index for sample 1, index for sample2\n+    case class KS2Acc(min: Double, max: Double, ix1: Int, ix2: Int)\n+    val initAcc = KS2Acc(Double.MaxValue, Double.MinValue, 0, 0)\n+    // traverse the data in partition and calculate distances and counts\n+    val pResults = partData.foldLeft(initAcc) { case (acc: KS2Acc, (v, isSample1)) =>\n+      val (add1, add2) = if (isSample1) (1, 0) else (0, 1)\n+      val cdf1 = (acc.ix1 + add1) / n1\n+      val cdf2 = (acc.ix2 + add2) / n2\n+      val dist = cdf1 - cdf2\n+      KS2Acc(math.min(acc.min, dist), math.max(acc.max, dist), acc.ix1 + add1, acc.ix2 + add2)\n+    }\n+    val results = if (pResults == initAcc) {"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "Can we describe in a little more detail what the mentioned count is a count of?  Or if it's described somewhere else in the code, reference it?\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T01:29:41Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this"
  }, {
    "author": {
      "login": "josepablocam"
    },
    "body": "done, added. Let me know if this is clearer now. I will push the change in a bit, after fixing rest.\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T02:52:48Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "`.sortByKey`? I think the `mapPartitions` doesn't need braces, just parens, but that's tiny.\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T07:13:25Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Does `acc` need a type here?\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-07-31T07:14:51Z",
    "diffHunk": "@@ -190,5 +191,93 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new KolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    val isSample1 = true // identifier for sample 1, needed after co-sort\n+    // combine identified samples\n+    val joinedData = data1.map(x => (x, isSample1)) ++ data2.map(x => (x, !isSample1))\n+    // co-sort and operate on each partition\n+    val localData = joinedData.sortBy { case (v, id) => v }.mapPartitions { part =>\n+      searchTwoSampleCandidates(part, n1, n2) // local extrema\n+    }.collect()\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2) // result: global extreme\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts from each sample within one partition for\n+   * the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance , the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and a\n+   *        count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double)\n+    : Iterator[(Double, Double, Double)] = {\n+    // fold accumulator: local minimum, local maximum, index for sample 1, index for sample2\n+    case class KS2Acc(min: Double, max: Double, ix1: Int, ix2: Int)\n+    val initAcc = KS2Acc(Double.MaxValue, Double.MinValue, 0, 0)\n+    // traverse the data in partition and calculate distances and counts\n+    val pResults = partData.foldLeft(initAcc) { case (acc: KS2Acc, (v, isSample1)) =>"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "Nit: I'd make the above one \"Sample follows _the_ theoretical distribution\" or make the bottom one \"Both samples follow same distribution\".\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-08-03T20:08:54Z",
    "diffHunk": "@@ -53,6 +53,7 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n   object NullHypothesis extends Enumeration {\n     type NullHypothesis = Value\n     val OneSampleTwoSided = Value(\"Sample follows theoretical distribution\")\n+    val TwoSampleTwoSided = Value(\"Both samples follow the same distribution\")"
  }, {
    "author": {
      "login": "josepablocam"
    },
    "body": "fixed. Modified the first. Thanks\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-08-04T00:44:05Z",
    "diffHunk": "@@ -53,6 +53,7 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n   object NullHypothesis extends Enumeration {\n     type NullHypothesis = Value\n     val OneSampleTwoSided = Value(\"Sample follows theoretical distribution\")\n+    val TwoSampleTwoSided = Value(\"Both samples follow the same distribution\")"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "Can you provide a comment on what situations we would expect to hit this case in?\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-08-03T20:13:35Z",
    "diffHunk": "@@ -190,5 +191,104 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new CommonMathKolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    // identifier for sample 1, needed after co-sort\n+    val isSample1 = true\n+    // combine identified samples\n+    val unionedData = data1.map((_, isSample1)).union(data2.map((_, !isSample1)))\n+    // co-sort and operate on each partition, returning local extrema to the driver\n+    val localData = unionedData.sortByKey().mapPartitions(\n+      searchTwoSampleCandidates(_, n1, n2)\n+    ).collect()\n+    // result: global extreme\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2)\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts of elements from each sample within one\n+   * partition for the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance, the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and the third is\n+   *        a count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition. This last value, the numerator of the adjustment constant, is calculated as\n+   *        |sample 2| * |sample 1 in partition| - |sample 1| * |sample 2 in partition|. This comes\n+   *        from the fact that when we adjust for prior partitions, what we are doing is\n+   *        adding the difference of the fractions (|prior elements in sample 1| / |sample 1| -\n+   *        |prior elements in sample 2| / |sample 2|). We simply keep track of the numerator\n+   *        portion that is attributable to each partition so that following partitions can\n+   *        use it to cumulatively adjust their values.\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double): Iterator[(Double, Double, Double)] = {\n+    // fold accumulator: local minimum, local maximum, index for sample 1, index for sample2\n+    case class ExtremaAndIndices(min: Double, max: Double, ix1: Int, ix2: Int)\n+    val initAcc = ExtremaAndIndices(Double.MaxValue, Double.MinValue, 0, 0)\n+    // traverse the data in the partition and calculate distances and counts\n+    val pResults = partData.foldLeft(initAcc) { case (acc, (v, isSample1)) =>\n+      val (add1, add2) = if (isSample1) (1, 0) else (0, 1)\n+      val cdf1 = (acc.ix1 + add1) / n1\n+      val cdf2 = (acc.ix2 + add2) / n2\n+      val dist = cdf1 - cdf2\n+      ExtremaAndIndices(\n+        math.min(acc.min, dist),\n+        math.max(acc.max, dist),\n+        acc.ix1 + add1, acc.ix2 + add2)\n+    }\n+    val results = if (pResults == initAcc) {"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "Indent this back two spaces\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-08-03T20:14:03Z",
    "diffHunk": "@@ -190,5 +191,104 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new CommonMathKolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    // identifier for sample 1, needed after co-sort\n+    val isSample1 = true\n+    // combine identified samples\n+    val unionedData = data1.map((_, isSample1)).union(data2.map((_, !isSample1)))\n+    // co-sort and operate on each partition, returning local extrema to the driver\n+    val localData = unionedData.sortByKey().mapPartitions(\n+      searchTwoSampleCandidates(_, n1, n2)\n+    ).collect()\n+    // result: global extreme\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2)\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts of elements from each sample within one\n+   * partition for the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance, the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and the third is\n+   *        a count corresponding to the numerator of the adjustment constant coming from this\n+   *        partition. This last value, the numerator of the adjustment constant, is calculated as\n+   *        |sample 2| * |sample 1 in partition| - |sample 1| * |sample 2 in partition|. This comes\n+   *        from the fact that when we adjust for prior partitions, what we are doing is\n+   *        adding the difference of the fractions (|prior elements in sample 1| / |sample 1| -\n+   *        |prior elements in sample 2| / |sample 2|). We simply keep track of the numerator\n+   *        portion that is attributable to each partition so that following partitions can\n+   *        use it to cumulatively adjust their values.\n+   */\n+  private def searchTwoSampleCandidates(\n+      partData: Iterator[(Double, Boolean)],\n+      n1: Double,\n+      n2: Double): Iterator[(Double, Double, Double)] = {\n+    // fold accumulator: local minimum, local maximum, index for sample 1, index for sample2\n+    case class ExtremaAndIndices(min: Double, max: Double, ix1: Int, ix2: Int)\n+    val initAcc = ExtremaAndIndices(Double.MaxValue, Double.MinValue, 0, 0)\n+    // traverse the data in the partition and calculate distances and counts\n+    val pResults = partData.foldLeft(initAcc) { case (acc, (v, isSample1)) =>\n+      val (add1, add2) = if (isSample1) (1, 0) else (0, 1)\n+      val cdf1 = (acc.ix1 + add1) / n1\n+      val cdf2 = (acc.ix2 + add2) / n2\n+      val dist = cdf1 - cdf2\n+      ExtremaAndIndices(\n+        math.min(acc.min, dist),\n+        math.max(acc.max, dist),\n+        acc.ix1 + add1, acc.ix2 + add2)\n+    }\n+    val results = if (pResults == initAcc) {\n+      Array[(Double, Double, Double)]()\n+    } else {\n+      Array((pResults.min, pResults.max, (pResults.ix1 + 1) * n2 - (pResults.ix2 + 1) * n1))\n+    }\n+    results.iterator\n+  }\n+\n+  /**\n+   * Adjust candidate extremes by the appropriate constant. The resulting maximum corresponds to\n+   * the two-sample, two-sided Kolmogorov-Smirnov test\n+   * @param localData `Array[(Double, Double, Double)]` contains the candidate extremes from each\n+   *                 partition, along with the numerator for the necessary constant adjustments\n+   * @param n `Double` The denominator in the constant adjustment (i.e. (size of sample 1 ) * (size\n+   *         of sample 2))\n+   * @return The two-sample, two-sided Kolmogorov-Smirnov statistic\n+   */\n+  private def searchTwoSampleStatistic(localData: Array[(Double, Double, Double)], n: Double)\n+    : Double = {\n+    // maximum distance and numerator for constant adjustment\n+    val initAcc = (Double.MinValue, 0.0)\n+    // adjust differences based on the number of elements preceding it, which should provide\n+    // the correct distance between the 2 empirical CDFs\n+    val results = localData.foldLeft(initAcc) { case ((prevMax, prevCt), (minCand, maxCand, ct)) =>\n+      val adjConst = prevCt / n\n+      val dist1 = math.abs(minCand + adjConst)\n+      val dist2 = math.abs(maxCand + adjConst)\n+      val maxVal = Array(prevMax, dist1, dist2).max\n+      (maxVal, prevCt + ct)\n+      }"
  }],
  "prId": 7075
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "Can you add a little clarification in the top level documentation for the class on the approach.  I.e. so users can understand what the adjustment constant is, as well as what the denominator is that will be put under the numerator calculated here.\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-08-03T20:17:48Z",
    "diffHunk": "@@ -190,5 +191,104 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new CommonMathKolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    // identifier for sample 1, needed after co-sort\n+    val isSample1 = true\n+    // combine identified samples\n+    val unionedData = data1.map((_, isSample1)).union(data2.map((_, !isSample1)))\n+    // co-sort and operate on each partition, returning local extrema to the driver\n+    val localData = unionedData.sortByKey().mapPartitions(\n+      searchTwoSampleCandidates(_, n1, n2)\n+    ).collect()\n+    // result: global extreme\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2)\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts of elements from each sample within one\n+   * partition for the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance, the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and the third is\n+   *        a count corresponding to the numerator of the adjustment constant coming from this",
    "line": 67
  }, {
    "author": {
      "login": "josepablocam"
    },
    "body": "done, thanks for feedback\n",
    "commit": "feacda09b38be41b3daacde5cbcd6b7452fc0b8b",
    "createdAt": "2015-08-04T00:56:34Z",
    "diffHunk": "@@ -190,5 +191,104 @@ private[stat] object KolmogorovSmirnovTest extends Logging {\n     val pval = 1 - new CommonMathKolmogorovSmirnovTest().cdf(ksStat, n.toInt)\n     new KolmogorovSmirnovTestResult(pval, ksStat, NullHypothesis.OneSampleTwoSided.toString)\n   }\n+\n+  /**\n+   * Implements a two-sample, two-sided Kolmogorov-Smirnov test, which tests if the 2 samples\n+   * come from the same distribution\n+   * @param data1 `RDD[Double]` first sample of data\n+   * @param data2 `RDD[Double]` second sample of data\n+   * @return [[org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult]] with the test\n+   *        statistic, p-value, and appropriate null hypothesis\n+   */\n+  def testTwoSamples(data1: RDD[Double], data2: RDD[Double]): KolmogorovSmirnovTestResult = {\n+    val n1 = data1.count().toDouble\n+    val n2 = data2.count().toDouble\n+    // identifier for sample 1, needed after co-sort\n+    val isSample1 = true\n+    // combine identified samples\n+    val unionedData = data1.map((_, isSample1)).union(data2.map((_, !isSample1)))\n+    // co-sort and operate on each partition, returning local extrema to the driver\n+    val localData = unionedData.sortByKey().mapPartitions(\n+      searchTwoSampleCandidates(_, n1, n2)\n+    ).collect()\n+    // result: global extreme\n+    val ksStat = searchTwoSampleStatistic(localData, n1 * n2)\n+    evalTwoSampleP(ksStat, n1.toInt, n2.toInt)\n+  }\n+\n+  /**\n+   * Calculates maximum distance candidates and counts of elements from each sample within one\n+   * partition for the two-sample, two-sided Kolmogorov-Smirnov test implementation\n+   * @param partData `Iterator[(Double, Boolean)]` the data in 1 partition of the co-sorted RDDs,\n+   *                each element is additionally tagged with a boolean flag for sample 1 membership\n+   * @param n1 `Double` sample 1 size\n+   * @param n2 `Double` sample 2 size\n+   * @return `Iterator[(Double, Double, Double)]` where the first element is an unadjusted minimum\n+   *        distance, the second is an unadjusted maximum distance (both of which will later\n+   *        be adjusted by a constant to account for elements in prior partitions), and the third is\n+   *        a count corresponding to the numerator of the adjustment constant coming from this",
    "line": 67
  }],
  "prId": 7075
}]