[{
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Does this really need to be in the rdd package? I guess it's okay but it just makes the package names longer\n",
    "commit": "24d829460e3ddcfe6c5515d7c197477356c5df0f",
    "createdAt": "2014-04-07T20:32:35Z",
    "diffHunk": "@@ -0,0 +1,327 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg.rdd"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Renamed to `distributed` (even longer ...).\n",
    "commit": "24d829460e3ddcfe6c5515d7c197477356c5df0f",
    "createdAt": "2014-04-07T22:54:03Z",
    "diffHunk": "@@ -0,0 +1,327 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg.rdd"
  }],
  "prId": 296
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Should m and n be called numRows and numColumns?\n",
    "commit": "24d829460e3ddcfe6c5515d7c197477356c5df0f",
    "createdAt": "2014-04-07T20:33:06Z",
    "diffHunk": "@@ -0,0 +1,327 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg.rdd\n+\n+import java.util\n+\n+import scala.util.control.Breaks._\n+\n+import breeze.linalg.{DenseMatrix => BDM, DenseVector => BDV, svd => brzSvd}\n+import breeze.numerics.{sqrt => brzSqrt}\n+import com.github.fommil.netlib.BLAS.{getInstance => blas}\n+\n+import org.apache.spark.mllib.linalg._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.Logging\n+\n+/**\n+ * Represents a row-oriented RDDMatrix with no meaningful row indices.\n+ *\n+ * @param rows rows stored as an RDD[Vector]\n+ * @param m number of rows\n+ * @param n number of columns\n+ */\n+class RowRDDMatrix(\n+    val rows: RDD[Vector],\n+    m: Long = -1L,\n+    n: Long = -1) extends RDDMatrix with Logging {"
  }, {
    "author": {
      "login": "mateiz"
    },
    "body": "Actually I see, they're just to let the user specify these. In that case they should be documented as such and maybe just called \"rows\" and \"columns\". Also, this constructor is not Java-friendly; you should make these arguments not have defaults and then add alternative constructors in the body of the class that pass -1 for them.\n",
    "commit": "24d829460e3ddcfe6c5515d7c197477356c5df0f",
    "createdAt": "2014-04-07T20:34:29Z",
    "diffHunk": "@@ -0,0 +1,327 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg.rdd\n+\n+import java.util\n+\n+import scala.util.control.Breaks._\n+\n+import breeze.linalg.{DenseMatrix => BDM, DenseVector => BDV, svd => brzSvd}\n+import breeze.numerics.{sqrt => brzSqrt}\n+import com.github.fommil.netlib.BLAS.{getInstance => blas}\n+\n+import org.apache.spark.mllib.linalg._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.Logging\n+\n+/**\n+ * Represents a row-oriented RDDMatrix with no meaningful row indices.\n+ *\n+ * @param rows rows stored as an RDD[Vector]\n+ * @param m number of rows\n+ * @param n number of columns\n+ */\n+class RowRDDMatrix(\n+    val rows: RDD[Vector],\n+    m: Long = -1L,\n+    n: Long = -1) extends RDDMatrix with Logging {"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Done.\n",
    "commit": "24d829460e3ddcfe6c5515d7c197477356c5df0f",
    "createdAt": "2014-04-07T22:54:16Z",
    "diffHunk": "@@ -0,0 +1,327 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg.rdd\n+\n+import java.util\n+\n+import scala.util.control.Breaks._\n+\n+import breeze.linalg.{DenseMatrix => BDM, DenseVector => BDV, svd => brzSvd}\n+import breeze.numerics.{sqrt => brzSqrt}\n+import com.github.fommil.netlib.BLAS.{getInstance => blas}\n+\n+import org.apache.spark.mllib.linalg._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.Logging\n+\n+/**\n+ * Represents a row-oriented RDDMatrix with no meaningful row indices.\n+ *\n+ * @param rows rows stored as an RDD[Vector]\n+ * @param m number of rows\n+ * @param n number of columns\n+ */\n+class RowRDDMatrix(\n+    val rows: RDD[Vector],\n+    m: Long = -1L,\n+    n: Long = -1) extends RDDMatrix with Logging {"
  }],
  "prId": 296
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "There may also be no first row, I guess that would kind of suck but maybe return 0 then. You can use rows.take(1) to get an empty list if no row exists.\n",
    "commit": "24d829460e3ddcfe6c5515d7c197477356c5df0f",
    "createdAt": "2014-04-07T20:35:01Z",
    "diffHunk": "@@ -0,0 +1,327 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg.rdd\n+\n+import java.util\n+\n+import scala.util.control.Breaks._\n+\n+import breeze.linalg.{DenseMatrix => BDM, DenseVector => BDV, svd => brzSvd}\n+import breeze.numerics.{sqrt => brzSqrt}\n+import com.github.fommil.netlib.BLAS.{getInstance => blas}\n+\n+import org.apache.spark.mllib.linalg._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.Logging\n+\n+/**\n+ * Represents a row-oriented RDDMatrix with no meaningful row indices.\n+ *\n+ * @param rows rows stored as an RDD[Vector]\n+ * @param m number of rows\n+ * @param n number of columns\n+ */\n+class RowRDDMatrix(\n+    val rows: RDD[Vector],\n+    m: Long = -1L,\n+    n: Long = -1) extends RDDMatrix with Logging {\n+\n+  private var _m = m\n+  private var _n = n\n+\n+  /** Gets or computes the number of columns. */\n+  override def numCols(): Long = {\n+    if (_n < 0) {\n+      _n = rows.first().size"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "`first()` will throw an exception if the RDD is empty. I don't think we should allow a distributed matrix with a zero size.\n",
    "commit": "24d829460e3ddcfe6c5515d7c197477356c5df0f",
    "createdAt": "2014-04-07T22:23:10Z",
    "diffHunk": "@@ -0,0 +1,327 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg.rdd\n+\n+import java.util\n+\n+import scala.util.control.Breaks._\n+\n+import breeze.linalg.{DenseMatrix => BDM, DenseVector => BDV, svd => brzSvd}\n+import breeze.numerics.{sqrt => brzSqrt}\n+import com.github.fommil.netlib.BLAS.{getInstance => blas}\n+\n+import org.apache.spark.mllib.linalg._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.Logging\n+\n+/**\n+ * Represents a row-oriented RDDMatrix with no meaningful row indices.\n+ *\n+ * @param rows rows stored as an RDD[Vector]\n+ * @param m number of rows\n+ * @param n number of columns\n+ */\n+class RowRDDMatrix(\n+    val rows: RDD[Vector],\n+    m: Long = -1L,\n+    n: Long = -1) extends RDDMatrix with Logging {\n+\n+  private var _m = m\n+  private var _n = n\n+\n+  /** Gets or computes the number of columns. */\n+  override def numCols(): Long = {\n+    if (_n < 0) {\n+      _n = rows.first().size"
  }],
  "prId": 296
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "I know this code is copied, but `breakable` and `break` are kind of weird to use and expensive. It would be better to just add a flag for shouldStop and do `while (i < k && !shouldStop)`.\n",
    "commit": "24d829460e3ddcfe6c5515d7c197477356c5df0f",
    "createdAt": "2014-04-07T20:36:06Z",
    "diffHunk": "@@ -0,0 +1,327 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg.rdd\n+\n+import java.util\n+\n+import scala.util.control.Breaks._\n+\n+import breeze.linalg.{DenseMatrix => BDM, DenseVector => BDV, svd => brzSvd}\n+import breeze.numerics.{sqrt => brzSqrt}\n+import com.github.fommil.netlib.BLAS.{getInstance => blas}\n+\n+import org.apache.spark.mllib.linalg._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.Logging\n+\n+/**\n+ * Represents a row-oriented RDDMatrix with no meaningful row indices.\n+ *\n+ * @param rows rows stored as an RDD[Vector]\n+ * @param m number of rows\n+ * @param n number of columns\n+ */\n+class RowRDDMatrix(\n+    val rows: RDD[Vector],\n+    m: Long = -1L,\n+    n: Long = -1) extends RDDMatrix with Logging {\n+\n+  private var _m = m\n+  private var _n = n\n+\n+  /** Gets or computes the number of columns. */\n+  override def numCols(): Long = {\n+    if (_n < 0) {\n+      _n = rows.first().size\n+    }\n+    _n\n+  }\n+\n+  /** Gets or computes the number of rows. */\n+  override def numRows(): Long = {\n+    if (_m < 0) {\n+      _m = rows.count()\n+    }\n+    _m\n+  }\n+\n+  /**\n+   * Computes the Gramian matrix `A^T A`.\n+   */\n+  def computeGramianMatrix(): Matrix = {\n+    val n = numCols().toInt\n+    val nt: Int = n * (n + 1) / 2\n+\n+    // Compute the upper triangular part of the gram matrix.\n+    val GU = rows.aggregate(new BDV[Double](new Array[Double](nt)))(\n+      seqOp = (U, v) => {\n+        RowRDDMatrix.dspr(1.0, v, U.data)\n+        U\n+      },\n+      combOp = (U1, U2) => U1 += U2\n+    )\n+\n+    RowRDDMatrix.triuToFull(n, GU.data)\n+  }\n+\n+  /**\n+   * Computes the singular value decomposition of this matrix.\n+   * Denote this matrix by A (m x n), this will compute matrices U, S, V such that A = U * S * V'.\n+   *\n+   * There is no restriction on m, but we require `n^2` doubles to fit in memory.\n+   * Further, n should be less than m.\n+\n+   * The decomposition is computed by first computing A'A = V S^2 V',\n+   * computing svd locally on that (since n x n is small), from which we recover S and V.\n+   * Then we compute U via easy matrix multiplication as U =  A * (V * S^-1).\n+   * Note that this approach requires `O(n^3)` time on the master node.\n+   *\n+   * At most k largest non-zero singular values and associated vectors are returned.\n+   * If there are k such values, then the dimensions of the return will be:\n+   *\n+   * U is a RowRDDMatrix of size m x k that satisfies U'U = eye(k),\n+   * s is a Vector of size k, holding the singular values in descending order,\n+   * and V is a Matrix of size n x k that satisfies V'V = eye(k).\n+   *\n+   * @param k number of singular values to keep. We might return less than k if there are\n+   *          numerically zero singular values. See rCond.\n+   * @param computeU whether to compute U\n+   * @param rCond the reciprocal condition number. All singular values smaller than rCond * sigma(0)\n+   *              are treated as zero, where sigma(0) is the largest singular value.\n+   * @return SingularValueDecomposition(U, s, V)\n+   */\n+  def computeSVD(\n+      k: Int,\n+      computeU: Boolean = false,\n+      rCond: Double = 1e-9): SingularValueDecomposition[RowRDDMatrix, Matrix] = {\n+\n+    val n = numCols().toInt\n+\n+    require(k > 0 && k <= n, s\"Request up to n singular values k=$k n=$n.\")\n+\n+    val G = computeGramianMatrix()\n+\n+    // TODO: Use sparse SVD instead.\n+    val (u: BDM[Double], sigmaSquares: BDV[Double], v: BDM[Double]) =\n+      brzSvd(G.toBreeze.asInstanceOf[BDM[Double]])\n+    val sigmas: BDV[Double] = brzSqrt(sigmaSquares)\n+\n+    // Determine effective rank.\n+    val sigma0 = sigmas(0)\n+    val threshold = rCond * sigma0\n+    var i = 0\n+    breakable {\n+      while (i < k) {\n+        if (sigmas(i) < threshold) {\n+          break()\n+        }\n+        i += 1\n+      }\n+    }"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Done.\n",
    "commit": "24d829460e3ddcfe6c5515d7c197477356c5df0f",
    "createdAt": "2014-04-07T22:46:44Z",
    "diffHunk": "@@ -0,0 +1,327 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg.rdd\n+\n+import java.util\n+\n+import scala.util.control.Breaks._\n+\n+import breeze.linalg.{DenseMatrix => BDM, DenseVector => BDV, svd => brzSvd}\n+import breeze.numerics.{sqrt => brzSqrt}\n+import com.github.fommil.netlib.BLAS.{getInstance => blas}\n+\n+import org.apache.spark.mllib.linalg._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.Logging\n+\n+/**\n+ * Represents a row-oriented RDDMatrix with no meaningful row indices.\n+ *\n+ * @param rows rows stored as an RDD[Vector]\n+ * @param m number of rows\n+ * @param n number of columns\n+ */\n+class RowRDDMatrix(\n+    val rows: RDD[Vector],\n+    m: Long = -1L,\n+    n: Long = -1) extends RDDMatrix with Logging {\n+\n+  private var _m = m\n+  private var _n = n\n+\n+  /** Gets or computes the number of columns. */\n+  override def numCols(): Long = {\n+    if (_n < 0) {\n+      _n = rows.first().size\n+    }\n+    _n\n+  }\n+\n+  /** Gets or computes the number of rows. */\n+  override def numRows(): Long = {\n+    if (_m < 0) {\n+      _m = rows.count()\n+    }\n+    _m\n+  }\n+\n+  /**\n+   * Computes the Gramian matrix `A^T A`.\n+   */\n+  def computeGramianMatrix(): Matrix = {\n+    val n = numCols().toInt\n+    val nt: Int = n * (n + 1) / 2\n+\n+    // Compute the upper triangular part of the gram matrix.\n+    val GU = rows.aggregate(new BDV[Double](new Array[Double](nt)))(\n+      seqOp = (U, v) => {\n+        RowRDDMatrix.dspr(1.0, v, U.data)\n+        U\n+      },\n+      combOp = (U1, U2) => U1 += U2\n+    )\n+\n+    RowRDDMatrix.triuToFull(n, GU.data)\n+  }\n+\n+  /**\n+   * Computes the singular value decomposition of this matrix.\n+   * Denote this matrix by A (m x n), this will compute matrices U, S, V such that A = U * S * V'.\n+   *\n+   * There is no restriction on m, but we require `n^2` doubles to fit in memory.\n+   * Further, n should be less than m.\n+\n+   * The decomposition is computed by first computing A'A = V S^2 V',\n+   * computing svd locally on that (since n x n is small), from which we recover S and V.\n+   * Then we compute U via easy matrix multiplication as U =  A * (V * S^-1).\n+   * Note that this approach requires `O(n^3)` time on the master node.\n+   *\n+   * At most k largest non-zero singular values and associated vectors are returned.\n+   * If there are k such values, then the dimensions of the return will be:\n+   *\n+   * U is a RowRDDMatrix of size m x k that satisfies U'U = eye(k),\n+   * s is a Vector of size k, holding the singular values in descending order,\n+   * and V is a Matrix of size n x k that satisfies V'V = eye(k).\n+   *\n+   * @param k number of singular values to keep. We might return less than k if there are\n+   *          numerically zero singular values. See rCond.\n+   * @param computeU whether to compute U\n+   * @param rCond the reciprocal condition number. All singular values smaller than rCond * sigma(0)\n+   *              are treated as zero, where sigma(0) is the largest singular value.\n+   * @return SingularValueDecomposition(U, s, V)\n+   */\n+  def computeSVD(\n+      k: Int,\n+      computeU: Boolean = false,\n+      rCond: Double = 1e-9): SingularValueDecomposition[RowRDDMatrix, Matrix] = {\n+\n+    val n = numCols().toInt\n+\n+    require(k > 0 && k <= n, s\"Request up to n singular values k=$k n=$n.\")\n+\n+    val G = computeGramianMatrix()\n+\n+    // TODO: Use sparse SVD instead.\n+    val (u: BDM[Double], sigmaSquares: BDV[Double], v: BDM[Double]) =\n+      brzSvd(G.toBreeze.asInstanceOf[BDM[Double]])\n+    val sigmas: BDV[Double] = brzSqrt(sigmaSquares)\n+\n+    // Determine effective rank.\n+    val sigma0 = sigmas(0)\n+    val threshold = rCond * sigma0\n+    var i = 0\n+    breakable {\n+      while (i < k) {\n+        if (sigmas(i) < threshold) {\n+          break()\n+        }\n+        i += 1\n+      }\n+    }"
  }],
  "prId": 296
}]