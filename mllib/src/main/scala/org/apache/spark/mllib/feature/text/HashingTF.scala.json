[{
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Can you add a Java-friendly version of these tool? This looks like `scala.Iterable`. For the Java one you will probably have to make it take `JavaRDD` since we can't have methods that differ on the element type of RDD.\n\nOnce you add it, please add a Java test that uses it as well so we make sure it compiles in Java with no surprises.\n",
    "commit": "7d6588822f2a2bc988596b003ad02b682da82562",
    "createdAt": "2014-07-30T23:10:15Z",
    "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature.text\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * :: Experimental ::\n+ * Maps a sequence of terms to their term frequencies using the hashing trick.\n+ *\n+ * @param numFeatures number of features (default: 1000000)\n+ */\n+@Experimental\n+class HashingTF(val numFeatures: Int) extends Serializable {\n+\n+  def this() = this(1000000)\n+\n+  /**\n+   * Returns the index of the input term.\n+   */\n+  def indexOf(term: Any): Int = Utils.nonNegativeMod(term.##, numFeatures)\n+\n+  /**\n+   * Transforms the input document into a sparse term frequency vector.\n+   */\n+  def transform(document: Iterable[_]): Vector = {\n+    val termFrequencies = mutable.HashMap.empty[Int, Double]\n+    document.foreach { term =>\n+      val i = indexOf(term)\n+      termFrequencies.put(i, termFrequencies.getOrElse(i, 0.0) + 1.0)\n+    }\n+    Vectors.sparse(numFeatures, termFrequencies.toSeq)\n+  }\n+\n+  /**\n+   * Transforms the input document to term frequency vectors.\n+   */\n+  def transform[D <: Iterable[_]](dataset: RDD[D]): RDD[Vector] = {\n+    dataset.map(this.transform)\n+  }"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Sure.\n",
    "commit": "7d6588822f2a2bc988596b003ad02b682da82562",
    "createdAt": "2014-07-30T23:22:18Z",
    "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature.text\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * :: Experimental ::\n+ * Maps a sequence of terms to their term frequencies using the hashing trick.\n+ *\n+ * @param numFeatures number of features (default: 1000000)\n+ */\n+@Experimental\n+class HashingTF(val numFeatures: Int) extends Serializable {\n+\n+  def this() = this(1000000)\n+\n+  /**\n+   * Returns the index of the input term.\n+   */\n+  def indexOf(term: Any): Int = Utils.nonNegativeMod(term.##, numFeatures)\n+\n+  /**\n+   * Transforms the input document into a sparse term frequency vector.\n+   */\n+  def transform(document: Iterable[_]): Vector = {\n+    val termFrequencies = mutable.HashMap.empty[Int, Double]\n+    document.foreach { term =>\n+      val i = indexOf(term)\n+      termFrequencies.put(i, termFrequencies.getOrElse(i, 0.0) + 1.0)\n+    }\n+    Vectors.sparse(numFeatures, termFrequencies.toSeq)\n+  }\n+\n+  /**\n+   * Transforms the input document to term frequency vectors.\n+   */\n+  def transform[D <: Iterable[_]](dataset: RDD[D]): RDD[Vector] = {\n+    dataset.map(this.transform)\n+  }"
  }],
  "prId": 1671
}]