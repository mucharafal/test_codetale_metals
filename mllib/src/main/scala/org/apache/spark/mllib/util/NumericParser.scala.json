[{
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Using a match statement here might be slow, check the generated code with `javap`. It would be safer to do `if (c == '(')` and such.\n",
    "commit": "2d1116a4076c822d828f99206195a0a709b94ca9",
    "createdAt": "2014-05-10T05:02:02Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+import scala.collection.mutable.{ArrayBuffer, ListBuffer}\n+\n+private[mllib] object NumericTokenizer {\n+  val NUMBER = -1\n+  val END = -2\n+}\n+\n+import NumericTokenizer._\n+\n+/**\n+ * Simple tokenizer for a numeric structure consisting of three types:\n+ *\n+ *  - number: a double in Java's floating number format\n+ *  - array: an array of numbers stored as `[v0,v1,...,vn]`\n+ *  - tuple: a list of numbers, arrays, or tuples stored as `(...)`\n+ *\n+ * @param s input string\n+ * @param start start index\n+ * @param end end index\n+ */\n+private[mllib] class NumericTokenizer(s: String, start: Int, end: Int) {\n+\n+  /**\n+   * Creates a tokenizer for the entire input string.\n+   */\n+  def this(s: String) = this(s, 0, s.length)\n+\n+  private var cur = start\n+  private var allowComma = false\n+  private var _value = Double.NaN\n+\n+  /**\n+   * Returns the most recent parsed number.\n+   */\n+  def value: Double = _value\n+\n+  /**\n+   * Returns the next token, which could be any of the following:\n+   *  - '[', ']', '(', or ')'.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#NUMBER]], call value() to get its value.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#END]].\n+   */\n+  def next(): Int = {\n+    if (cur < end) {\n+      val c = s(cur)\n+      c match {"
  }],
  "prId": 685
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Don't use `sys.error`\n",
    "commit": "2d1116a4076c822d828f99206195a0a709b94ca9",
    "createdAt": "2014-05-10T05:04:03Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+import scala.collection.mutable.{ArrayBuffer, ListBuffer}\n+\n+private[mllib] object NumericTokenizer {\n+  val NUMBER = -1\n+  val END = -2\n+}\n+\n+import NumericTokenizer._\n+\n+/**\n+ * Simple tokenizer for a numeric structure consisting of three types:\n+ *\n+ *  - number: a double in Java's floating number format\n+ *  - array: an array of numbers stored as `[v0,v1,...,vn]`\n+ *  - tuple: a list of numbers, arrays, or tuples stored as `(...)`\n+ *\n+ * @param s input string\n+ * @param start start index\n+ * @param end end index\n+ */\n+private[mllib] class NumericTokenizer(s: String, start: Int, end: Int) {\n+\n+  /**\n+   * Creates a tokenizer for the entire input string.\n+   */\n+  def this(s: String) = this(s, 0, s.length)\n+\n+  private var cur = start\n+  private var allowComma = false\n+  private var _value = Double.NaN\n+\n+  /**\n+   * Returns the most recent parsed number.\n+   */\n+  def value: Double = _value\n+\n+  /**\n+   * Returns the next token, which could be any of the following:\n+   *  - '[', ']', '(', or ')'.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#NUMBER]], call value() to get its value.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#END]].\n+   */\n+  def next(): Int = {\n+    if (cur < end) {\n+      val c = s(cur)\n+      c match {\n+        case '(' | '[' =>\n+          allowComma = false\n+          cur += 1\n+          c\n+        case ')' | ']' =>\n+          allowComma = true\n+          cur += 1\n+          c\n+        case ',' =>\n+          if (allowComma) {\n+            cur += 1\n+            allowComma = false\n+            next()\n+          } else {\n+            sys.error(\"Found a ',' at a wrong location.\")"
  }],
  "prId": 685
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Use `s.charAt(cur)` instead to avoid some temp objects from implicit conversion\n",
    "commit": "2d1116a4076c822d828f99206195a0a709b94ca9",
    "createdAt": "2014-05-10T05:04:59Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+import scala.collection.mutable.{ArrayBuffer, ListBuffer}\n+\n+private[mllib] object NumericTokenizer {\n+  val NUMBER = -1\n+  val END = -2\n+}\n+\n+import NumericTokenizer._\n+\n+/**\n+ * Simple tokenizer for a numeric structure consisting of three types:\n+ *\n+ *  - number: a double in Java's floating number format\n+ *  - array: an array of numbers stored as `[v0,v1,...,vn]`\n+ *  - tuple: a list of numbers, arrays, or tuples stored as `(...)`\n+ *\n+ * @param s input string\n+ * @param start start index\n+ * @param end end index\n+ */\n+private[mllib] class NumericTokenizer(s: String, start: Int, end: Int) {\n+\n+  /**\n+   * Creates a tokenizer for the entire input string.\n+   */\n+  def this(s: String) = this(s, 0, s.length)\n+\n+  private var cur = start\n+  private var allowComma = false\n+  private var _value = Double.NaN\n+\n+  /**\n+   * Returns the most recent parsed number.\n+   */\n+  def value: Double = _value\n+\n+  /**\n+   * Returns the next token, which could be any of the following:\n+   *  - '[', ']', '(', or ')'.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#NUMBER]], call value() to get its value.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#END]].\n+   */\n+  def next(): Int = {\n+    if (cur < end) {\n+      val c = s(cur)"
  }],
  "prId": 685
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "No need to do a StringBuilder, you can use `s.substring(start, end)` to get a new String that points into the same `char[]` and thus avoids copying data and allocating memory\n",
    "commit": "2d1116a4076c822d828f99206195a0a709b94ca9",
    "createdAt": "2014-05-10T05:05:33Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+import scala.collection.mutable.{ArrayBuffer, ListBuffer}\n+\n+private[mllib] object NumericTokenizer {\n+  val NUMBER = -1\n+  val END = -2\n+}\n+\n+import NumericTokenizer._\n+\n+/**\n+ * Simple tokenizer for a numeric structure consisting of three types:\n+ *\n+ *  - number: a double in Java's floating number format\n+ *  - array: an array of numbers stored as `[v0,v1,...,vn]`\n+ *  - tuple: a list of numbers, arrays, or tuples stored as `(...)`\n+ *\n+ * @param s input string\n+ * @param start start index\n+ * @param end end index\n+ */\n+private[mllib] class NumericTokenizer(s: String, start: Int, end: Int) {\n+\n+  /**\n+   * Creates a tokenizer for the entire input string.\n+   */\n+  def this(s: String) = this(s, 0, s.length)\n+\n+  private var cur = start\n+  private var allowComma = false\n+  private var _value = Double.NaN\n+\n+  /**\n+   * Returns the most recent parsed number.\n+   */\n+  def value: Double = _value\n+\n+  /**\n+   * Returns the next token, which could be any of the following:\n+   *  - '[', ']', '(', or ')'.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#NUMBER]], call value() to get its value.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#END]].\n+   */\n+  def next(): Int = {\n+    if (cur < end) {\n+      val c = s(cur)\n+      c match {\n+        case '(' | '[' =>\n+          allowComma = false\n+          cur += 1\n+          c\n+        case ')' | ']' =>\n+          allowComma = true\n+          cur += 1\n+          c\n+        case ',' =>\n+          if (allowComma) {\n+            cur += 1\n+            allowComma = false\n+            next()\n+          } else {\n+            sys.error(\"Found a ',' at a wrong location.\")\n+          }\n+        case other => // expecting a number\n+          var inNumber = true\n+          val sb = new StringBuilder()"
  }],
  "prId": 685
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "charAt\n",
    "commit": "2d1116a4076c822d828f99206195a0a709b94ca9",
    "createdAt": "2014-05-10T05:05:39Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+import scala.collection.mutable.{ArrayBuffer, ListBuffer}\n+\n+private[mllib] object NumericTokenizer {\n+  val NUMBER = -1\n+  val END = -2\n+}\n+\n+import NumericTokenizer._\n+\n+/**\n+ * Simple tokenizer for a numeric structure consisting of three types:\n+ *\n+ *  - number: a double in Java's floating number format\n+ *  - array: an array of numbers stored as `[v0,v1,...,vn]`\n+ *  - tuple: a list of numbers, arrays, or tuples stored as `(...)`\n+ *\n+ * @param s input string\n+ * @param start start index\n+ * @param end end index\n+ */\n+private[mllib] class NumericTokenizer(s: String, start: Int, end: Int) {\n+\n+  /**\n+   * Creates a tokenizer for the entire input string.\n+   */\n+  def this(s: String) = this(s, 0, s.length)\n+\n+  private var cur = start\n+  private var allowComma = false\n+  private var _value = Double.NaN\n+\n+  /**\n+   * Returns the most recent parsed number.\n+   */\n+  def value: Double = _value\n+\n+  /**\n+   * Returns the next token, which could be any of the following:\n+   *  - '[', ']', '(', or ')'.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#NUMBER]], call value() to get its value.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#END]].\n+   */\n+  def next(): Int = {\n+    if (cur < end) {\n+      val c = s(cur)\n+      c match {\n+        case '(' | '[' =>\n+          allowComma = false\n+          cur += 1\n+          c\n+        case ')' | ']' =>\n+          allowComma = true\n+          cur += 1\n+          c\n+        case ',' =>\n+          if (allowComma) {\n+            cur += 1\n+            allowComma = false\n+            next()\n+          } else {\n+            sys.error(\"Found a ',' at a wrong location.\")\n+          }\n+        case other => // expecting a number\n+          var inNumber = true\n+          val sb = new StringBuilder()\n+          while (cur < end && inNumber) {\n+            val d = s(cur)"
  }],
  "prId": 685
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "We could make a nicer method to check for here. `require` will throw an \"IllegalArgumentException: requirement failed\", which looks kind of weird. We could throw one that says \"expected ] at end of input\" or similar.\n",
    "commit": "2d1116a4076c822d828f99206195a0a709b94ca9",
    "createdAt": "2014-05-10T05:08:02Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+import scala.collection.mutable.{ArrayBuffer, ListBuffer}\n+\n+private[mllib] object NumericTokenizer {\n+  val NUMBER = -1\n+  val END = -2\n+}\n+\n+import NumericTokenizer._\n+\n+/**\n+ * Simple tokenizer for a numeric structure consisting of three types:\n+ *\n+ *  - number: a double in Java's floating number format\n+ *  - array: an array of numbers stored as `[v0,v1,...,vn]`\n+ *  - tuple: a list of numbers, arrays, or tuples stored as `(...)`\n+ *\n+ * @param s input string\n+ * @param start start index\n+ * @param end end index\n+ */\n+private[mllib] class NumericTokenizer(s: String, start: Int, end: Int) {\n+\n+  /**\n+   * Creates a tokenizer for the entire input string.\n+   */\n+  def this(s: String) = this(s, 0, s.length)\n+\n+  private var cur = start\n+  private var allowComma = false\n+  private var _value = Double.NaN\n+\n+  /**\n+   * Returns the most recent parsed number.\n+   */\n+  def value: Double = _value\n+\n+  /**\n+   * Returns the next token, which could be any of the following:\n+   *  - '[', ']', '(', or ')'.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#NUMBER]], call value() to get its value.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#END]].\n+   */\n+  def next(): Int = {\n+    if (cur < end) {\n+      val c = s(cur)\n+      c match {\n+        case '(' | '[' =>\n+          allowComma = false\n+          cur += 1\n+          c\n+        case ')' | ']' =>\n+          allowComma = true\n+          cur += 1\n+          c\n+        case ',' =>\n+          if (allowComma) {\n+            cur += 1\n+            allowComma = false\n+            next()\n+          } else {\n+            sys.error(\"Found a ',' at a wrong location.\")\n+          }\n+        case other => // expecting a number\n+          var inNumber = true\n+          val sb = new StringBuilder()\n+          while (cur < end && inNumber) {\n+            val d = s(cur)\n+            if (d == ')' || d == ']' || d == ',') {\n+              inNumber = false\n+            } else {\n+              sb.append(d)\n+              cur += 1\n+            }\n+          }\n+          _value = sb.toString().toDouble\n+          allowComma = true\n+          NUMBER\n+      }\n+    } else {\n+      END\n+    }\n+  }\n+}\n+\n+/**\n+ * Simple parser for tokens from [[org.apache.spark.mllib.util.NumericTokenizer]].\n+ */\n+private[mllib] object NumericParser {\n+\n+  /** Parses a string into a Double, an Array[Double], or a Seq[Any]. */\n+  def parse(s: String): Any = parse(new NumericTokenizer(s))\n+\n+  private def parse(tokenizer: NumericTokenizer): Any = {\n+    tokenizer.next() match {\n+      case '(' =>\n+        parseTuple(tokenizer)\n+      case '[' =>\n+        parseArray(tokenizer)\n+      case NUMBER =>\n+        tokenizer.value\n+      case END =>\n+        null\n+    }\n+  }\n+\n+  private def parseArray(tokenizer: NumericTokenizer): Array[Double] = {\n+    val values = ArrayBuffer.empty[Double]\n+    var token = tokenizer.next()\n+    while (token == NUMBER) {\n+      values.append(tokenizer.value)\n+      token = tokenizer.next()\n+    }\n+    require(token == ']')"
  }],
  "prId": 685
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Double.parseDouble is probably more efficient\n",
    "commit": "2d1116a4076c822d828f99206195a0a709b94ca9",
    "createdAt": "2014-05-10T05:11:42Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+import scala.collection.mutable.{ArrayBuffer, ListBuffer}\n+\n+private[mllib] object NumericTokenizer {\n+  val NUMBER = -1\n+  val END = -2\n+}\n+\n+import NumericTokenizer._\n+\n+/**\n+ * Simple tokenizer for a numeric structure consisting of three types:\n+ *\n+ *  - number: a double in Java's floating number format\n+ *  - array: an array of numbers stored as `[v0,v1,...,vn]`\n+ *  - tuple: a list of numbers, arrays, or tuples stored as `(...)`\n+ *\n+ * @param s input string\n+ * @param start start index\n+ * @param end end index\n+ */\n+private[mllib] class NumericTokenizer(s: String, start: Int, end: Int) {\n+\n+  /**\n+   * Creates a tokenizer for the entire input string.\n+   */\n+  def this(s: String) = this(s, 0, s.length)\n+\n+  private var cur = start\n+  private var allowComma = false\n+  private var _value = Double.NaN\n+\n+  /**\n+   * Returns the most recent parsed number.\n+   */\n+  def value: Double = _value\n+\n+  /**\n+   * Returns the next token, which could be any of the following:\n+   *  - '[', ']', '(', or ')'.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#NUMBER]], call value() to get its value.\n+   *  - [[org.apache.spark.mllib.util.NumericTokenizer#END]].\n+   */\n+  def next(): Int = {\n+    if (cur < end) {\n+      val c = s(cur)\n+      c match {\n+        case '(' | '[' =>\n+          allowComma = false\n+          cur += 1\n+          c\n+        case ')' | ']' =>\n+          allowComma = true\n+          cur += 1\n+          c\n+        case ',' =>\n+          if (allowComma) {\n+            cur += 1\n+            allowComma = false\n+            next()\n+          } else {\n+            sys.error(\"Found a ',' at a wrong location.\")\n+          }\n+        case other => // expecting a number\n+          var inNumber = true\n+          val sb = new StringBuilder()\n+          while (cur < end && inNumber) {\n+            val d = s(cur)\n+            if (d == ')' || d == ']' || d == ',') {\n+              inNumber = false\n+            } else {\n+              sb.append(d)\n+              cur += 1\n+            }\n+          }\n+          _value = sb.toString().toDouble"
  }],
  "prId": 685
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Much of the logic here could perhaps be replaced by `new StringTokenizer(s.substring(start, end), \"[](),\" true)`. StringTokenizer can be configured to return the tokens (namely '[', ',', etc) so it should be enough for parsing these data types.\n",
    "commit": "2d1116a4076c822d828f99206195a0a709b94ca9",
    "createdAt": "2014-05-10T05:13:14Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+import scala.collection.mutable.{ArrayBuffer, ListBuffer}\n+\n+private[mllib] object NumericTokenizer {\n+  val NUMBER = -1\n+  val END = -2\n+}\n+\n+import NumericTokenizer._\n+\n+/**\n+ * Simple tokenizer for a numeric structure consisting of three types:\n+ *\n+ *  - number: a double in Java's floating number format\n+ *  - array: an array of numbers stored as `[v0,v1,...,vn]`\n+ *  - tuple: a list of numbers, arrays, or tuples stored as `(...)`\n+ *\n+ * @param s input string\n+ * @param start start index\n+ * @param end end index\n+ */\n+private[mllib] class NumericTokenizer(s: String, start: Int, end: Int) {"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Tiny comment - `StringTokenizer` is considered just about deprecated (http://docs.oracle.com/javase/7/docs/api/java/util/StringTokenizer.html). Guava's `Splitter` does a better job and can return delimiters, and is already available in the project.\n",
    "commit": "2d1116a4076c822d828f99206195a0a709b94ca9",
    "createdAt": "2014-05-10T08:48:26Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+import scala.collection.mutable.{ArrayBuffer, ListBuffer}\n+\n+private[mllib] object NumericTokenizer {\n+  val NUMBER = -1\n+  val END = -2\n+}\n+\n+import NumericTokenizer._\n+\n+/**\n+ * Simple tokenizer for a numeric structure consisting of three types:\n+ *\n+ *  - number: a double in Java's floating number format\n+ *  - array: an array of numbers stored as `[v0,v1,...,vn]`\n+ *  - tuple: a list of numbers, arrays, or tuples stored as `(...)`\n+ *\n+ * @param s input string\n+ * @param start start index\n+ * @param end end index\n+ */\n+private[mllib] class NumericTokenizer(s: String, start: Int, end: Int) {"
  }],
  "prId": 685
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Is this conversion necessary? ListBuffer is likely also a Seq\n",
    "commit": "2d1116a4076c822d828f99206195a0a709b94ca9",
    "createdAt": "2014-05-29T07:01:58Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+import java.util.StringTokenizer\n+\n+import scala.collection.mutable.{ArrayBuffer, ListBuffer}\n+\n+import org.apache.spark.SparkException\n+\n+/**\n+ * Simple parser for a numeric structure consisting of three types:\n+ *\n+ *  - number: a double in Java's floating number format\n+ *  - array: an array of numbers stored as `[v0,v1,...,vn]`\n+ *  - tuple: a list of numbers, arrays, or tuples stored as `(...)`\n+ */\n+private[mllib] object NumericParser {\n+\n+  /** Parses a string into a Double, an Array[Double], or a Seq[Any]. */\n+  def parse(s: String): Any = {\n+    val tokenizer = new StringTokenizer(s, \"()[],\", true)\n+    if (tokenizer.hasMoreTokens()) {\n+      val token = tokenizer.nextToken()\n+      if (token == \"(\") {\n+        parseTuple(tokenizer)\n+      } else if (token == \"[\") {\n+        parseArray(tokenizer)\n+      } else {\n+        // expecting a number\n+        parseDouble(token)\n+      }\n+    } else {\n+      throw new SparkException(s\"Cannot find any token from the input string.\")\n+    }\n+  }\n+\n+  private def parseArray(tokenizer: StringTokenizer): Array[Double] = {\n+    val values = ArrayBuffer.empty[Double]\n+    var parsing = true\n+    var allowComma = false\n+    var token: String = null\n+    while (parsing && tokenizer.hasMoreTokens()) {\n+      token = tokenizer.nextToken()\n+      if (token == \"]\") {\n+        parsing = false\n+      } else if (token == \",\") {\n+        if (allowComma) {\n+          allowComma = false\n+        } else {\n+          throw new SparkException(\"Found a ',' at a wrong position.\")\n+        }\n+      } else {\n+        // expecting a number\n+        values.append(parseDouble(token))\n+        allowComma = true\n+      }\n+    }\n+    if (parsing) {\n+      throw new SparkException(s\"An array must end with ']'.\")\n+    }\n+    values.toArray\n+  }\n+\n+  private def parseTuple(tokenizer: StringTokenizer): Seq[_] = {\n+    val items = ListBuffer.empty[Any]\n+    var parsing = true\n+    var allowComma = false\n+    var token: String = null\n+    while (parsing && tokenizer.hasMoreTokens()) {\n+      token = tokenizer.nextToken()\n+      if (token == \"(\") {\n+        items.append(parseTuple(tokenizer))\n+        allowComma = true\n+      } else if (token == \"[\") {\n+        items.append(parseArray(tokenizer))\n+        allowComma = true\n+      } else if (token == \",\") {\n+        if (allowComma) {\n+          allowComma = false\n+        } else {\n+          throw new SparkException(\"Found a ',' at a wrong position.\")\n+        }\n+      } else if (token == \")\") {\n+        parsing = false\n+      } else {\n+        // expecting a number\n+        items.append(parseDouble(token))\n+        allowComma = true\n+      }\n+    }\n+    if (parsing) {\n+      throw new SparkException(s\"A tuple must end with ')'.\")\n+    }\n+    items.toSeq"
  }],
  "prId": 685
}]