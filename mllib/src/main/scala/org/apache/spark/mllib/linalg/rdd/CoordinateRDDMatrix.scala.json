[{
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Ditto on the default args\n",
    "commit": "24d829460e3ddcfe6c5515d7c197477356c5df0f",
    "createdAt": "2014-04-07T20:37:55Z",
    "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg.rdd\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.mllib.linalg.Vectors\n+\n+/**\n+ * Represents a matrix in coordinate list format.\n+ *\n+ * @param entries matrix entries\n+ * @param m number of rows (default: -1L, which means unknown)\n+ * @param n number of column (default: -1L, which means unknown)\n+ */\n+class CoordinateRDDMatrix(\n+    val entries: RDD[RDDMatrixEntry],\n+    m: Long = -1L,\n+    n: Long = -1L) extends RDDMatrix {"
  }],
  "prId": 296
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "This should also have a toRowMatrix.\n",
    "commit": "24d829460e3ddcfe6c5515d7c197477356c5df0f",
    "createdAt": "2014-04-07T21:18:05Z",
    "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg.rdd\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.mllib.linalg.Vectors\n+\n+/**\n+ * Represents a matrix in coordinate list format.\n+ *\n+ * @param entries matrix entries\n+ * @param m number of rows (default: -1L, which means unknown)\n+ * @param n number of column (default: -1L, which means unknown)\n+ */\n+class CoordinateRDDMatrix(\n+    val entries: RDD[RDDMatrixEntry],\n+    m: Long = -1L,\n+    n: Long = -1L) extends RDDMatrix {\n+\n+  private var _m = m\n+  private var _n = n\n+\n+  /** Gets or computes the number of columns. */\n+  override def numCols(): Long = {\n+    if (_n < 0) {\n+      computeSize()\n+    }\n+    _n\n+  }\n+\n+  /** Gets or computes the number of rows. */\n+  override def numRows(): Long = {\n+    if (_m < 0) {\n+      computeSize()\n+    }\n+    _m\n+  }\n+\n+  private def computeSize() {\n+    val (m1, n1) = entries.map(entry => (entry.i, entry.j)).reduce { case ((i1, j1), (i2, j2)) =>\n+      (math.max(i1, i2), math.max(j1, j2))\n+    }\n+    // There may be empty columns at the very right and empty rows at the very bottom.\n+    _m = math.max(_m, m1 + 1L)\n+    _n = math.max(_n, n1 + 1L)\n+  }\n+\n+  def toIndexedRowRDDMatrix(): IndexedRowRDDMatrix = {\n+    val n = numCols().toInt\n+    val indexedRows = entries.map(entry => (entry.i, (entry.j.toInt, entry.value)))\n+      .groupByKey()\n+      .map { case (i, vectorEntries) =>\n+      IndexedRDDMatrixRow(i, Vectors.sparse(n, vectorEntries))\n+    }\n+    new IndexedRowRDDMatrix(indexedRows, numRows(), numCols())\n+  }"
  }],
  "prId": 296
}]