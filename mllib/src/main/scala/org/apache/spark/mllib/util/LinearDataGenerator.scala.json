[{
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "extra line.\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-22T00:55:12Z",
    "diffHunk": "@@ -125,6 +125,59 @@ object LinearDataGenerator {\n   }\n \n   /**\n+   *"
  }],
  "prId": 9180
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "How about consolidate with `LinearDataGenerator`, and add `sparsity = 1.0` as param to control if it's sparse feature?\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-23T23:07:47Z",
    "diffHunk": "@@ -125,6 +124,58 @@ object LinearDataGenerator {\n   }\n \n   /**\n+   * @param intercept Data intercept\n+   * @param weights  Weights to be applied.\n+   * @param xMean the mean of the generated features. Lots of time, if the features are not properly\n+   *              standardized, the algorithm with poor implementation will have difficulty\n+   *              to converge.\n+   * @param xVariance the variance of the generated features.\n+   * @param nPoints Number of points in sample.\n+   * @param seed Random seed\n+   * @param eps Epsilon scaling factor.\n+   * @return Seq of LabeledPoint includes sparse vectors..\n+   */"
  }, {
    "author": {
      "login": "Lewuathe"
    },
    "body": "Yes, I also thought it is good idea. But `LinearDataGenerator` is used as static object, then we have to pass `sparsity` as parameter to `generateLinearInput`. This method seems to be used a lot of suites. It is necessary to change a lot of method reference. \nTherefore it might be better to do in separate JIRA. What do you thing about?\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-24T01:03:37Z",
    "diffHunk": "@@ -125,6 +124,58 @@ object LinearDataGenerator {\n   }\n \n   /**\n+   * @param intercept Data intercept\n+   * @param weights  Weights to be applied.\n+   * @param xMean the mean of the generated features. Lots of time, if the features are not properly\n+   *              standardized, the algorithm with poor implementation will have difficulty\n+   *              to converge.\n+   * @param xVariance the variance of the generated features.\n+   * @param nPoints Number of points in sample.\n+   * @param seed Random seed\n+   * @param eps Epsilon scaling factor.\n+   * @return Seq of LabeledPoint includes sparse vectors..\n+   */"
  }, {
    "author": {
      "login": "dbtsai"
    },
    "body": "Let's modify the JIRA and do it here. Basically, you can create a `LinearDataGenerator` with old signature calling new API for compatibility issue.\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-24T05:58:24Z",
    "diffHunk": "@@ -125,6 +124,58 @@ object LinearDataGenerator {\n   }\n \n   /**\n+   * @param intercept Data intercept\n+   * @param weights  Weights to be applied.\n+   * @param xMean the mean of the generated features. Lots of time, if the features are not properly\n+   *              standardized, the algorithm with poor implementation will have difficulty\n+   *              to converge.\n+   * @param xVariance the variance of the generated features.\n+   * @param nPoints Number of points in sample.\n+   * @param seed Random seed\n+   * @param eps Epsilon scaling factor.\n+   * @return Seq of LabeledPoint includes sparse vectors..\n+   */"
  }],
  "prId": 9180
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "Once you have `sparsity`, randomly choose `n = numFeatures * (1 - sparsity)` as non-zero features, and zero the rest out.\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-23T23:10:45Z",
    "diffHunk": "@@ -125,6 +124,58 @@ object LinearDataGenerator {\n   }\n \n   /**\n+   * @param intercept Data intercept\n+   * @param weights  Weights to be applied.\n+   * @param xMean the mean of the generated features. Lots of time, if the features are not properly\n+   *              standardized, the algorithm with poor implementation will have difficulty\n+   *              to converge.\n+   * @param xVariance the variance of the generated features.\n+   * @param nPoints Number of points in sample.\n+   * @param seed Random seed\n+   * @param eps Epsilon scaling factor.\n+   * @return Seq of LabeledPoint includes sparse vectors..\n+   */\n+  @Since(\"1.6.0\")\n+  def generateLinearSparseInput(\n+      intercept: Double,\n+      weights: Array[Double],\n+      xMean: Array[Double],\n+      xVariance: Array[Double],\n+      nPoints: Int,\n+      seed: Int,\n+      eps: Double): Seq[LabeledPoint] = {\n+    val rnd = new Random(seed)\n+    val x = Array.fill[Array[Double]](nPoints)(\n+      Array.fill[Double](weights.length)(rnd.nextDouble()))\n+\n+    x.foreach { v =>"
  }, {
    "author": {
      "login": "dbtsai"
    },
    "body": "You can also add the variance of sparsity such that the num of non zeros will not be constant. \n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-23T23:11:38Z",
    "diffHunk": "@@ -125,6 +124,58 @@ object LinearDataGenerator {\n   }\n \n   /**\n+   * @param intercept Data intercept\n+   * @param weights  Weights to be applied.\n+   * @param xMean the mean of the generated features. Lots of time, if the features are not properly\n+   *              standardized, the algorithm with poor implementation will have difficulty\n+   *              to converge.\n+   * @param xVariance the variance of the generated features.\n+   * @param nPoints Number of points in sample.\n+   * @param seed Random seed\n+   * @param eps Epsilon scaling factor.\n+   * @return Seq of LabeledPoint includes sparse vectors..\n+   */\n+  @Since(\"1.6.0\")\n+  def generateLinearSparseInput(\n+      intercept: Double,\n+      weights: Array[Double],\n+      xMean: Array[Double],\n+      xVariance: Array[Double],\n+      nPoints: Int,\n+      seed: Int,\n+      eps: Double): Seq[LabeledPoint] = {\n+    val rnd = new Random(seed)\n+    val x = Array.fill[Array[Double]](nPoints)(\n+      Array.fill[Double](weights.length)(rnd.nextDouble()))\n+\n+    x.foreach { v =>"
  }],
  "prId": 9180
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "The formatting in pervious method\n\n``` scala\n  def generateLinearInput(\n      intercept: Double,\n      weights: Array[Double],\n      nPoints: Int,\n      seed: Int,\n      eps: Double = 0.1): Seq[LabeledPoint] = {\n    generateLinearInput(intercept, weights,\n      Array.fill[Double](weights.length)(0.0),\n      Array.fill[Double](weights.length)(1.0 / 3.0),\n      nPoints, seed, eps)}\n```\n\nlooks weird for me. Can you fix in this PR? Thanks.\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-29T17:28:28Z",
    "diffHunk": "@@ -83,7 +83,6 @@ object LinearDataGenerator {\n       nPoints, seed, eps)}"
  }],
  "prId": 9180
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "Just call it `generateLinearInput` without `Internal`.\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-29T17:29:09Z",
    "diffHunk": "@@ -104,7 +103,35 @@ object LinearDataGenerator {\n       nPoints: Int,\n       seed: Int,\n       eps: Double): Seq[LabeledPoint] = {\n+    generateLinearInputInternal(intercept, weights, xMean, xVariance, nPoints, seed, eps, 0.0)\n+  }\n \n+\n+  /**\n+   * @param intercept Data intercept\n+   * @param weights  Weights to be applied.\n+   * @param xMean the mean of the generated features. Lots of time, if the features are not properly\n+   *              standardized, the algorithm with poor implementation will have difficulty\n+   *              to converge.\n+   * @param xVariance the variance of the generated features.\n+   * @param nPoints Number of points in sample.\n+   * @param seed Random seed\n+   * @param eps Epsilon scaling factor.\n+   * @param sparcity The ratio of zero elements. If it is 0.0, LabeledPoints with\n+   *                 DenseVector is returned.\n+   * @return Seq of input.\n+   */\n+  @Since(\"1.6.0\")\n+  def generateLinearInputInternal("
  }],
  "prId": 9180
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "Typo: `sparsity`\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-29T17:33:47Z",
    "diffHunk": "@@ -104,7 +103,35 @@ object LinearDataGenerator {\n       nPoints: Int,\n       seed: Int,\n       eps: Double): Seq[LabeledPoint] = {\n+    generateLinearInputInternal(intercept, weights, xMean, xVariance, nPoints, seed, eps, 0.0)\n+  }\n \n+\n+  /**\n+   * @param intercept Data intercept\n+   * @param weights  Weights to be applied.\n+   * @param xMean the mean of the generated features. Lots of time, if the features are not properly\n+   *              standardized, the algorithm with poor implementation will have difficulty\n+   *              to converge.\n+   * @param xVariance the variance of the generated features.\n+   * @param nPoints Number of points in sample.\n+   * @param seed Random seed\n+   * @param eps Epsilon scaling factor.\n+   * @param sparcity The ratio of zero elements. If it is 0.0, LabeledPoints with"
  }],
  "prId": 9180
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "ditto. typo.\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-29T17:34:15Z",
    "diffHunk": "@@ -104,7 +103,35 @@ object LinearDataGenerator {\n       nPoints: Int,\n       seed: Int,\n       eps: Double): Seq[LabeledPoint] = {\n+    generateLinearInputInternal(intercept, weights, xMean, xVariance, nPoints, seed, eps, 0.0)\n+  }\n \n+\n+  /**\n+   * @param intercept Data intercept\n+   * @param weights  Weights to be applied.\n+   * @param xMean the mean of the generated features. Lots of time, if the features are not properly\n+   *              standardized, the algorithm with poor implementation will have difficulty\n+   *              to converge.\n+   * @param xVariance the variance of the generated features.\n+   * @param nPoints Number of points in sample.\n+   * @param seed Random seed\n+   * @param eps Epsilon scaling factor.\n+   * @param sparcity The ratio of zero elements. If it is 0.0, LabeledPoints with\n+   *                 DenseVector is returned.\n+   * @return Seq of input.\n+   */\n+  @Since(\"1.6.0\")\n+  def generateLinearInputInternal(\n+      intercept: Double,\n+      weights: Array[Double],\n+      xMean: Array[Double],\n+      xVariance: Array[Double],\n+      nPoints: Int,\n+      seed: Int,\n+      eps: Double,\n+      sparcity: Double): Seq[LabeledPoint] = {"
  }],
  "prId": 9180
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "Since you seed `rnd` and `sparceRnd` with the same seed, both of them will generate the same sequence of random numbers which is not what you want. You should be able to use the same random number generator which will give you uncorrelated random numbers in both creating the features and choice which columns to zero out.\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-29T17:44:04Z",
    "diffHunk": "@@ -112,8 +139,13 @@ object LinearDataGenerator {\n     x.foreach { v =>\n       var i = 0\n       val len = v.length\n+      val sparceRnd = new Random(seed)"
  }, {
    "author": {
      "login": "Lewuathe"
    },
    "body": "If we use same random generator for both creating features and choice which columns to zero, x is  different from current ones. This cause unit test failures. Can we change the assertion tolerance or target written in `LinearRegressionSuite`?\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-30T06:11:26Z",
    "diffHunk": "@@ -112,8 +139,13 @@ object LinearDataGenerator {\n     x.foreach { v =>\n       var i = 0\n       val len = v.length\n+      val sparceRnd = new Random(seed)"
  }],
  "prId": 9180
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "Okay, I think it's okay to have sparsity == 1.0. Just have everything zeros.\n\n`require(0.0 <= sparsity && sparsity <= 1.0)`\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-29T18:04:57Z",
    "diffHunk": "@@ -104,7 +103,35 @@ object LinearDataGenerator {\n       nPoints: Int,\n       seed: Int,\n       eps: Double): Seq[LabeledPoint] = {\n+    generateLinearInputInternal(intercept, weights, xMean, xVariance, nPoints, seed, eps, 0.0)\n+  }\n \n+\n+  /**\n+   * @param intercept Data intercept\n+   * @param weights  Weights to be applied.\n+   * @param xMean the mean of the generated features. Lots of time, if the features are not properly\n+   *              standardized, the algorithm with poor implementation will have difficulty\n+   *              to converge.\n+   * @param xVariance the variance of the generated features.\n+   * @param nPoints Number of points in sample.\n+   * @param seed Random seed\n+   * @param eps Epsilon scaling factor.\n+   * @param sparcity The ratio of zero elements. If it is 0.0, LabeledPoints with\n+   *                 DenseVector is returned.\n+   * @return Seq of input.\n+   */\n+  @Since(\"1.6.0\")\n+  def generateLinearInputInternal(\n+      intercept: Double,\n+      weights: Array[Double],\n+      xMean: Array[Double],\n+      xVariance: Array[Double],\n+      nPoints: Int,\n+      seed: Int,\n+      eps: Double,\n+      sparcity: Double): Seq[LabeledPoint] = {\n+    require(sparcity <= 1.0)"
  }],
  "prId": 9180
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "To simplify the following code, do\n\n``` scala\ny.zip(x).map { p => \n  if (sparsity == 0.0) {\n    LabeledPoint(p._1, Vectors.dense(p._2))\n  } else {\n    LabeledPoint(p._1, Vectors.dense(p._2).toSparse)\n  }\n}\n```\n",
    "commit": "241ec7293607d670c93293b5872b21ed0c9f411a",
    "createdAt": "2015-10-29T18:09:41Z",
    "diffHunk": "@@ -121,7 +153,21 @@ object LinearDataGenerator {\n     val y = x.map { xi =>\n       blas.ddot(weights.length, xi, 1, weights, 1) + intercept + eps * rnd.nextGaussian()\n     }\n-    y.zip(x).map(p => LabeledPoint(p._1, Vectors.dense(p._2)))\n+",
    "line": 73
  }],
  "prId": 9180
}]