[{
  "comments": [{
    "author": {
      "login": "petro-rudenko"
    },
    "body": "Maybe call it FeatureUnion to keep the same semantic with [sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html)\n",
    "commit": "a52b10162a4d1cca9cb86d726771b481844499c9",
    "createdAt": "2015-04-02T10:21:08Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import scala.collection.mutable.ArrayBuilder\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.param.{HasInputCols, HasOutputCol, ParamMap}\n+import org.apache.spark.mllib.linalg.{Vector, VectorUDT, Vectors}\n+import org.apache.spark.sql.{Column, DataFrame, Row}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute\n+import org.apache.spark.sql.catalyst.expressions.CreateStruct\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * :: AlphaComponent ::\n+ * A feature transformer than merge multiple columns into a vector column.\n+ */\n+@AlphaComponent\n+class VectorAssembler extends Transformer with HasInputCols with HasOutputCol {",
    "line": 38
  }, {
    "author": {
      "login": "oefirouz"
    },
    "body": "+1. I like the idea of trying to keep naming and architecture as similar to sklearn as possible.\n",
    "commit": "a52b10162a4d1cca9cb86d726771b481844499c9",
    "createdAt": "2015-04-02T18:38:45Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import scala.collection.mutable.ArrayBuilder\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.param.{HasInputCols, HasOutputCol, ParamMap}\n+import org.apache.spark.mllib.linalg.{Vector, VectorUDT, Vectors}\n+import org.apache.spark.sql.{Column, DataFrame, Row}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute\n+import org.apache.spark.sql.catalyst.expressions.CreateStruct\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * :: AlphaComponent ::\n+ * A feature transformer than merge multiple columns into a vector column.\n+ */\n+@AlphaComponent\n+class VectorAssembler extends Transformer with HasInputCols with HasOutputCol {",
    "line": 38
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "This is not exactly sklearn's FeatureUnion that takes transformers. `VectorAssembler` merges arbitrary columns. I'm a little worried that if we use the same name people would expect the same behavior.\n",
    "commit": "a52b10162a4d1cca9cb86d726771b481844499c9",
    "createdAt": "2015-04-07T22:21:47Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import scala.collection.mutable.ArrayBuilder\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.param.{HasInputCols, HasOutputCol, ParamMap}\n+import org.apache.spark.mllib.linalg.{Vector, VectorUDT, Vectors}\n+import org.apache.spark.sql.{Column, DataFrame, Row}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute\n+import org.apache.spark.sql.catalyst.expressions.CreateStruct\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * :: AlphaComponent ::\n+ * A feature transformer than merge multiple columns into a vector column.\n+ */\n+@AlphaComponent\n+class VectorAssembler extends Transformer with HasInputCols with HasOutputCol {",
    "line": 38
  }],
  "prId": 5196
}, {
  "comments": [{
    "author": {
      "login": "petro-rudenko"
    },
    "body": "Would be good to support Integers also and just convert them to double.\n",
    "commit": "a52b10162a4d1cca9cb86d726771b481844499c9",
    "createdAt": "2015-04-03T16:48:13Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import scala.collection.mutable.ArrayBuilder\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.param.{HasInputCols, HasOutputCol, ParamMap}\n+import org.apache.spark.mllib.linalg.{Vector, VectorUDT, Vectors}\n+import org.apache.spark.sql.{Column, DataFrame, Row}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute\n+import org.apache.spark.sql.catalyst.expressions.CreateStruct\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * :: AlphaComponent ::\n+ * A feature transformer than merge multiple columns into a vector column.\n+ */\n+@AlphaComponent\n+class VectorAssembler extends Transformer with HasInputCols with HasOutputCol {\n+\n+  /** @group setParam */\n+  def setInputCols(value: Array[String]): this.type = set(inputCols, value)\n+\n+  /** @group setParam */\n+  def setOutputCol(value: String): this.type = set(outputCol, value)\n+\n+  override def transform(dataset: DataFrame, paramMap: ParamMap): DataFrame = {\n+    val map = this.paramMap ++ paramMap\n+    val assembleFunc = udf { r: Row =>\n+      VectorAssembler.assemble(r.toSeq: _*)\n+    }\n+    val args = map(inputCols).map(c => UnresolvedAttribute(c))\n+    dataset.select(col(\"*\"), assembleFunc(new Column(CreateStruct(args))).as(map(outputCol)))\n+  }\n+\n+  override def transformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    val map = this.paramMap ++ paramMap\n+    val inputColNames = map(inputCols)\n+    val outputColName = map(outputCol)\n+    val inputDataTypes = inputColNames.map(name => schema(name).dataType)\n+    for (dataType <- inputDataTypes) {\n+      if (!(dataType == DoubleType || dataType.isInstanceOf[VectorUDT])) {\n+        throw new IllegalArgumentException(s\"Data type $dataType is not supported.\")\n+      }\n+    }\n+    if (schema.fieldNames.contains(outputColName)) {\n+      throw new IllegalArgumentException(s\"Output column $outputColName already exists.\")\n+    }\n+    StructType(schema.fields :+ new StructField(outputColName, new VectorUDT, false))\n+  }\n+}\n+\n+@AlphaComponent\n+object VectorAssembler {\n+\n+  private[feature] def assemble(vv: Any*): Vector = {\n+    val indices = ArrayBuilder.make[Int]\n+    val values = ArrayBuilder.make[Double]\n+    var cur = 0\n+    vv.foreach {\n+      case v: Double =>",
    "line": 89
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Done with casting.\n",
    "commit": "a52b10162a4d1cca9cb86d726771b481844499c9",
    "createdAt": "2015-04-10T07:24:59Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import scala.collection.mutable.ArrayBuilder\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.param.{HasInputCols, HasOutputCol, ParamMap}\n+import org.apache.spark.mllib.linalg.{Vector, VectorUDT, Vectors}\n+import org.apache.spark.sql.{Column, DataFrame, Row}\n+import org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute\n+import org.apache.spark.sql.catalyst.expressions.CreateStruct\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * :: AlphaComponent ::\n+ * A feature transformer than merge multiple columns into a vector column.\n+ */\n+@AlphaComponent\n+class VectorAssembler extends Transformer with HasInputCols with HasOutputCol {\n+\n+  /** @group setParam */\n+  def setInputCols(value: Array[String]): this.type = set(inputCols, value)\n+\n+  /** @group setParam */\n+  def setOutputCol(value: String): this.type = set(outputCol, value)\n+\n+  override def transform(dataset: DataFrame, paramMap: ParamMap): DataFrame = {\n+    val map = this.paramMap ++ paramMap\n+    val assembleFunc = udf { r: Row =>\n+      VectorAssembler.assemble(r.toSeq: _*)\n+    }\n+    val args = map(inputCols).map(c => UnresolvedAttribute(c))\n+    dataset.select(col(\"*\"), assembleFunc(new Column(CreateStruct(args))).as(map(outputCol)))\n+  }\n+\n+  override def transformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    val map = this.paramMap ++ paramMap\n+    val inputColNames = map(inputCols)\n+    val outputColName = map(outputCol)\n+    val inputDataTypes = inputColNames.map(name => schema(name).dataType)\n+    for (dataType <- inputDataTypes) {\n+      if (!(dataType == DoubleType || dataType.isInstanceOf[VectorUDT])) {\n+        throw new IllegalArgumentException(s\"Data type $dataType is not supported.\")\n+      }\n+    }\n+    if (schema.fieldNames.contains(outputColName)) {\n+      throw new IllegalArgumentException(s\"Output column $outputColName already exists.\")\n+    }\n+    StructType(schema.fields :+ new StructField(outputColName, new VectorUDT, false))\n+  }\n+}\n+\n+@AlphaComponent\n+object VectorAssembler {\n+\n+  private[feature] def assemble(vv: Any*): Vector = {\n+    val indices = ArrayBuilder.make[Int]\n+    val values = ArrayBuilder.make[Double]\n+    var cur = 0\n+    vv.foreach {\n+      case v: Double =>",
    "line": 89
  }],
  "prId": 5196
}]