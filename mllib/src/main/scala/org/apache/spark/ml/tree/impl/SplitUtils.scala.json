[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Remove this (If there's any chance of this, then we should find ways to test it.)",
    "commit": "d86dd18e47451c2e4463c68db441f92a898ac765",
    "createdAt": "2017-11-10T05:57:41Z",
    "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impl\n+\n+import org.apache.spark.ml.tree.{CategoricalSplit, Split}\n+import org.apache.spark.mllib.tree.impurity.ImpurityCalculator\n+import org.apache.spark.mllib.tree.model.ImpurityStats\n+\n+/** Utility methods for choosing splits during local & distributed tree training. */\n+private[impl] object SplitUtils {\n+\n+  /** Sorts ordered feature categories by label centroid, returning an ordered list of categories */\n+  private def sortByCentroid(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int): List[Int] = {\n+    /* Each bin is one category (feature value).\n+     * The bins are ordered based on centroidForCategories, and this ordering determines which\n+     * splits are considered.  (With K categories, we consider K - 1 possible splits.)\n+     *\n+     * centroidForCategories is a list: (category, centroid)\n+     */\n+    val numCategories = binAggregates.metadata.numBins(featureIndex)\n+    val nodeFeatureOffset = binAggregates.getFeatureOffset(featureIndexIdx)\n+\n+    val centroidForCategories = Range(0, numCategories).map { featureValue =>\n+      val categoryStats =\n+        binAggregates.getImpurityCalculator(nodeFeatureOffset, featureValue)\n+      val centroid = ImpurityUtils.getCentroid(binAggregates.metadata, categoryStats)\n+      (featureValue, centroid)\n+    }\n+    // TODO(smurching): How to handle logging statements like these?\n+    // logDebug(\"Centroids for categorical variable: \" + centroidForCategories.mkString(\",\"))\n+    // bins sorted by centroids\n+    val categoriesSortedByCentroid = centroidForCategories.toList.sortBy(_._2).map(_._1)\n+    // logDebug(\"Sorted centroids for categorical variable = \" +\n+    //   categoriesSortedByCentroid.mkString(\",\"))\n+    categoriesSortedByCentroid\n+  }\n+\n+  /**\n+   * Find the best split for an unordered categorical feature at a single node.\n+   *\n+   * Algorithm:\n+   *  - Considers all possible subsets (exponentially many)\n+   *\n+   * @param featureIndex  Global index of feature being split.\n+   * @param featureIndexIdx Index of feature being split within subset of features for current node.\n+   * @param featureSplits Array of splits for the current feature\n+   * @param parentCalculator Optional: ImpurityCalculator containing impurity stats for current node\n+   * @return  (best split, statistics for split)  If no valid split was found, the returned\n+   *          ImpurityStats instance will be invalid (have member valid = false).\n+   */\n+  private[impl] def chooseUnorderedCategoricalSplit(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int,\n+      featureSplits: Array[Split],\n+      parentCalculator: Option[ImpurityCalculator] = None): (Split, ImpurityStats) = {\n+    // Unordered categorical feature\n+    val nodeFeatureOffset = binAggregates.getFeatureOffset(featureIndexIdx)\n+    val numSplits = binAggregates.metadata.numSplits(featureIndex)\n+    var parentCalc = parentCalculator\n+    val (bestFeatureSplitIndex, bestFeatureGainStats) =\n+      Range(0, numSplits).map { splitIndex =>\n+        val leftChildStats = binAggregates.getImpurityCalculator(nodeFeatureOffset, splitIndex)\n+        val rightChildStats = binAggregates.getParentImpurityCalculator()\n+          .subtract(leftChildStats)\n+        val gainAndImpurityStats = ImpurityUtils.calculateImpurityStats(parentCalc,\n+          leftChildStats, rightChildStats, binAggregates.metadata)\n+        // Compute parent stats once, when considering first split for current feature\n+        if (parentCalc.isEmpty) {\n+          parentCalc = Some(gainAndImpurityStats.impurityCalculator)\n+        }\n+        (splitIndex, gainAndImpurityStats)\n+      }.maxBy(_._2.gain)\n+    (featureSplits(bestFeatureSplitIndex), bestFeatureGainStats)\n+\n+  }\n+\n+  /**\n+   * Choose splitting rule: feature value <= threshold\n+   *\n+   * @return  (best split, statistics for split)  If the best split actually puts all instances\n+   *          in one leaf node, then it will be set to None.  If no valid split was found, the\n+   *          returned ImpurityStats instance will be invalid (have member valid = false)\n+   */\n+  private[impl] def chooseContinuousSplit(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int,\n+      featureSplits: Array[Split],\n+      parentCalculator: Option[ImpurityCalculator] = None): (Split, ImpurityStats) = {\n+    // For a continuous feature, bins are already sorted for splitting\n+    // Number of \"categories\" = number of bins\n+    val sortedCategories = Range(0, binAggregates.metadata.numBins(featureIndex)).toList\n+    // Get & return best split info\n+    val (bestFeatureSplitIndex, bestFeatureGainStats) = orderedSplitHelper(binAggregates,\n+      featureIndex, featureIndexIdx, sortedCategories, parentCalculator)\n+    (featureSplits(bestFeatureSplitIndex), bestFeatureGainStats)\n+  }\n+\n+  /**\n+   * Computes the index of the best split for an ordered feature.\n+   * @param parentCalculator Optional: ImpurityCalculator containing impurity stats for current node\n+   */\n+  private def orderedSplitHelper(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int,\n+      categoriesSortedByCentroid: List[Int],\n+      parentCalculator: Option[ImpurityCalculator]): (Int, ImpurityStats) = {\n+    // Cumulative sum (scanLeft) of bin statistics.\n+    // Afterwards, binAggregates for a bin is the sum of aggregates for\n+    // that bin + all preceding bins.\n+    assert(!binAggregates.metadata.isUnordered(featureIndex))"
  }],
  "prId": 19433
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "This line can be moved outside of the map.  Actually, this is the parentCalc, right?  So if it's not available, parentCalc can be computed beforehand outside of the map.",
    "commit": "d86dd18e47451c2e4463c68db441f92a898ac765",
    "createdAt": "2017-11-10T06:02:03Z",
    "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impl\n+\n+import org.apache.spark.ml.tree.{CategoricalSplit, Split}\n+import org.apache.spark.mllib.tree.impurity.ImpurityCalculator\n+import org.apache.spark.mllib.tree.model.ImpurityStats\n+\n+/** Utility methods for choosing splits during local & distributed tree training. */\n+private[impl] object SplitUtils {\n+\n+  /** Sorts ordered feature categories by label centroid, returning an ordered list of categories */\n+  private def sortByCentroid(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int): List[Int] = {\n+    /* Each bin is one category (feature value).\n+     * The bins are ordered based on centroidForCategories, and this ordering determines which\n+     * splits are considered.  (With K categories, we consider K - 1 possible splits.)\n+     *\n+     * centroidForCategories is a list: (category, centroid)\n+     */\n+    val numCategories = binAggregates.metadata.numBins(featureIndex)\n+    val nodeFeatureOffset = binAggregates.getFeatureOffset(featureIndexIdx)\n+\n+    val centroidForCategories = Range(0, numCategories).map { featureValue =>\n+      val categoryStats =\n+        binAggregates.getImpurityCalculator(nodeFeatureOffset, featureValue)\n+      val centroid = ImpurityUtils.getCentroid(binAggregates.metadata, categoryStats)\n+      (featureValue, centroid)\n+    }\n+    // TODO(smurching): How to handle logging statements like these?\n+    // logDebug(\"Centroids for categorical variable: \" + centroidForCategories.mkString(\",\"))\n+    // bins sorted by centroids\n+    val categoriesSortedByCentroid = centroidForCategories.toList.sortBy(_._2).map(_._1)\n+    // logDebug(\"Sorted centroids for categorical variable = \" +\n+    //   categoriesSortedByCentroid.mkString(\",\"))\n+    categoriesSortedByCentroid\n+  }\n+\n+  /**\n+   * Find the best split for an unordered categorical feature at a single node.\n+   *\n+   * Algorithm:\n+   *  - Considers all possible subsets (exponentially many)\n+   *\n+   * @param featureIndex  Global index of feature being split.\n+   * @param featureIndexIdx Index of feature being split within subset of features for current node.\n+   * @param featureSplits Array of splits for the current feature\n+   * @param parentCalculator Optional: ImpurityCalculator containing impurity stats for current node\n+   * @return  (best split, statistics for split)  If no valid split was found, the returned\n+   *          ImpurityStats instance will be invalid (have member valid = false).\n+   */\n+  private[impl] def chooseUnorderedCategoricalSplit(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int,\n+      featureSplits: Array[Split],\n+      parentCalculator: Option[ImpurityCalculator] = None): (Split, ImpurityStats) = {\n+    // Unordered categorical feature\n+    val nodeFeatureOffset = binAggregates.getFeatureOffset(featureIndexIdx)\n+    val numSplits = binAggregates.metadata.numSplits(featureIndex)\n+    var parentCalc = parentCalculator\n+    val (bestFeatureSplitIndex, bestFeatureGainStats) =\n+      Range(0, numSplits).map { splitIndex =>\n+        val leftChildStats = binAggregates.getImpurityCalculator(nodeFeatureOffset, splitIndex)\n+        val rightChildStats = binAggregates.getParentImpurityCalculator()\n+          .subtract(leftChildStats)\n+        val gainAndImpurityStats = ImpurityUtils.calculateImpurityStats(parentCalc,\n+          leftChildStats, rightChildStats, binAggregates.metadata)\n+        // Compute parent stats once, when considering first split for current feature\n+        if (parentCalc.isEmpty) {\n+          parentCalc = Some(gainAndImpurityStats.impurityCalculator)\n+        }\n+        (splitIndex, gainAndImpurityStats)\n+      }.maxBy(_._2.gain)\n+    (featureSplits(bestFeatureSplitIndex), bestFeatureGainStats)\n+\n+  }\n+\n+  /**\n+   * Choose splitting rule: feature value <= threshold\n+   *\n+   * @return  (best split, statistics for split)  If the best split actually puts all instances\n+   *          in one leaf node, then it will be set to None.  If no valid split was found, the\n+   *          returned ImpurityStats instance will be invalid (have member valid = false)\n+   */\n+  private[impl] def chooseContinuousSplit(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int,\n+      featureSplits: Array[Split],\n+      parentCalculator: Option[ImpurityCalculator] = None): (Split, ImpurityStats) = {\n+    // For a continuous feature, bins are already sorted for splitting\n+    // Number of \"categories\" = number of bins\n+    val sortedCategories = Range(0, binAggregates.metadata.numBins(featureIndex)).toList\n+    // Get & return best split info\n+    val (bestFeatureSplitIndex, bestFeatureGainStats) = orderedSplitHelper(binAggregates,\n+      featureIndex, featureIndexIdx, sortedCategories, parentCalculator)\n+    (featureSplits(bestFeatureSplitIndex), bestFeatureGainStats)\n+  }\n+\n+  /**\n+   * Computes the index of the best split for an ordered feature.\n+   * @param parentCalculator Optional: ImpurityCalculator containing impurity stats for current node\n+   */\n+  private def orderedSplitHelper(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int,\n+      categoriesSortedByCentroid: List[Int],\n+      parentCalculator: Option[ImpurityCalculator]): (Int, ImpurityStats) = {\n+    // Cumulative sum (scanLeft) of bin statistics.\n+    // Afterwards, binAggregates for a bin is the sum of aggregates for\n+    // that bin + all preceding bins.\n+    assert(!binAggregates.metadata.isUnordered(featureIndex))\n+    val numSplits = binAggregates.metadata.numSplits(featureIndex)\n+    val nodeFeatureOffset = binAggregates.getFeatureOffset(featureIndexIdx)\n+    var splitIndex = 0\n+    while (splitIndex < numSplits) {\n+      val currentCategory = categoriesSortedByCentroid(splitIndex)\n+      val nextCategory = categoriesSortedByCentroid(splitIndex + 1)\n+      binAggregates.mergeForFeature(nodeFeatureOffset, nextCategory, currentCategory)\n+      splitIndex += 1\n+    }\n+    // lastCategory = index of bin with total aggregates for this (node, feature)\n+    val lastCategory = categoriesSortedByCentroid.last\n+\n+    // Find best split.\n+    var parentCalc = parentCalculator\n+    Range(0, numSplits).map { splitIndex =>\n+      val featureValue = categoriesSortedByCentroid(splitIndex)\n+      val leftChildStats =\n+        binAggregates.getImpurityCalculator(nodeFeatureOffset, featureValue)\n+      val rightChildStats =",
    "line": 145
  }, {
    "author": {
      "login": "smurching"
    },
    "body": "Exactly, it's the parentCalc minus the left child stats. Since `ImpurityCalculator.subtract()` updates the impurity calculator in place, we call `binAggregates.getParentImpurityCalculator()` to get a copy of the parent impurity calculator, then subtract the left child stats.",
    "commit": "d86dd18e47451c2e4463c68db441f92a898ac765",
    "createdAt": "2017-11-15T02:03:01Z",
    "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impl\n+\n+import org.apache.spark.ml.tree.{CategoricalSplit, Split}\n+import org.apache.spark.mllib.tree.impurity.ImpurityCalculator\n+import org.apache.spark.mllib.tree.model.ImpurityStats\n+\n+/** Utility methods for choosing splits during local & distributed tree training. */\n+private[impl] object SplitUtils {\n+\n+  /** Sorts ordered feature categories by label centroid, returning an ordered list of categories */\n+  private def sortByCentroid(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int): List[Int] = {\n+    /* Each bin is one category (feature value).\n+     * The bins are ordered based on centroidForCategories, and this ordering determines which\n+     * splits are considered.  (With K categories, we consider K - 1 possible splits.)\n+     *\n+     * centroidForCategories is a list: (category, centroid)\n+     */\n+    val numCategories = binAggregates.metadata.numBins(featureIndex)\n+    val nodeFeatureOffset = binAggregates.getFeatureOffset(featureIndexIdx)\n+\n+    val centroidForCategories = Range(0, numCategories).map { featureValue =>\n+      val categoryStats =\n+        binAggregates.getImpurityCalculator(nodeFeatureOffset, featureValue)\n+      val centroid = ImpurityUtils.getCentroid(binAggregates.metadata, categoryStats)\n+      (featureValue, centroid)\n+    }\n+    // TODO(smurching): How to handle logging statements like these?\n+    // logDebug(\"Centroids for categorical variable: \" + centroidForCategories.mkString(\",\"))\n+    // bins sorted by centroids\n+    val categoriesSortedByCentroid = centroidForCategories.toList.sortBy(_._2).map(_._1)\n+    // logDebug(\"Sorted centroids for categorical variable = \" +\n+    //   categoriesSortedByCentroid.mkString(\",\"))\n+    categoriesSortedByCentroid\n+  }\n+\n+  /**\n+   * Find the best split for an unordered categorical feature at a single node.\n+   *\n+   * Algorithm:\n+   *  - Considers all possible subsets (exponentially many)\n+   *\n+   * @param featureIndex  Global index of feature being split.\n+   * @param featureIndexIdx Index of feature being split within subset of features for current node.\n+   * @param featureSplits Array of splits for the current feature\n+   * @param parentCalculator Optional: ImpurityCalculator containing impurity stats for current node\n+   * @return  (best split, statistics for split)  If no valid split was found, the returned\n+   *          ImpurityStats instance will be invalid (have member valid = false).\n+   */\n+  private[impl] def chooseUnorderedCategoricalSplit(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int,\n+      featureSplits: Array[Split],\n+      parentCalculator: Option[ImpurityCalculator] = None): (Split, ImpurityStats) = {\n+    // Unordered categorical feature\n+    val nodeFeatureOffset = binAggregates.getFeatureOffset(featureIndexIdx)\n+    val numSplits = binAggregates.metadata.numSplits(featureIndex)\n+    var parentCalc = parentCalculator\n+    val (bestFeatureSplitIndex, bestFeatureGainStats) =\n+      Range(0, numSplits).map { splitIndex =>\n+        val leftChildStats = binAggregates.getImpurityCalculator(nodeFeatureOffset, splitIndex)\n+        val rightChildStats = binAggregates.getParentImpurityCalculator()\n+          .subtract(leftChildStats)\n+        val gainAndImpurityStats = ImpurityUtils.calculateImpurityStats(parentCalc,\n+          leftChildStats, rightChildStats, binAggregates.metadata)\n+        // Compute parent stats once, when considering first split for current feature\n+        if (parentCalc.isEmpty) {\n+          parentCalc = Some(gainAndImpurityStats.impurityCalculator)\n+        }\n+        (splitIndex, gainAndImpurityStats)\n+      }.maxBy(_._2.gain)\n+    (featureSplits(bestFeatureSplitIndex), bestFeatureGainStats)\n+\n+  }\n+\n+  /**\n+   * Choose splitting rule: feature value <= threshold\n+   *\n+   * @return  (best split, statistics for split)  If the best split actually puts all instances\n+   *          in one leaf node, then it will be set to None.  If no valid split was found, the\n+   *          returned ImpurityStats instance will be invalid (have member valid = false)\n+   */\n+  private[impl] def chooseContinuousSplit(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int,\n+      featureSplits: Array[Split],\n+      parentCalculator: Option[ImpurityCalculator] = None): (Split, ImpurityStats) = {\n+    // For a continuous feature, bins are already sorted for splitting\n+    // Number of \"categories\" = number of bins\n+    val sortedCategories = Range(0, binAggregates.metadata.numBins(featureIndex)).toList\n+    // Get & return best split info\n+    val (bestFeatureSplitIndex, bestFeatureGainStats) = orderedSplitHelper(binAggregates,\n+      featureIndex, featureIndexIdx, sortedCategories, parentCalculator)\n+    (featureSplits(bestFeatureSplitIndex), bestFeatureGainStats)\n+  }\n+\n+  /**\n+   * Computes the index of the best split for an ordered feature.\n+   * @param parentCalculator Optional: ImpurityCalculator containing impurity stats for current node\n+   */\n+  private def orderedSplitHelper(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int,\n+      categoriesSortedByCentroid: List[Int],\n+      parentCalculator: Option[ImpurityCalculator]): (Int, ImpurityStats) = {\n+    // Cumulative sum (scanLeft) of bin statistics.\n+    // Afterwards, binAggregates for a bin is the sum of aggregates for\n+    // that bin + all preceding bins.\n+    assert(!binAggregates.metadata.isUnordered(featureIndex))\n+    val numSplits = binAggregates.metadata.numSplits(featureIndex)\n+    val nodeFeatureOffset = binAggregates.getFeatureOffset(featureIndexIdx)\n+    var splitIndex = 0\n+    while (splitIndex < numSplits) {\n+      val currentCategory = categoriesSortedByCentroid(splitIndex)\n+      val nextCategory = categoriesSortedByCentroid(splitIndex + 1)\n+      binAggregates.mergeForFeature(nodeFeatureOffset, nextCategory, currentCategory)\n+      splitIndex += 1\n+    }\n+    // lastCategory = index of bin with total aggregates for this (node, feature)\n+    val lastCategory = categoriesSortedByCentroid.last\n+\n+    // Find best split.\n+    var parentCalc = parentCalculator\n+    Range(0, numSplits).map { splitIndex =>\n+      val featureValue = categoriesSortedByCentroid(splitIndex)\n+      val leftChildStats =\n+        binAggregates.getImpurityCalculator(nodeFeatureOffset, featureValue)\n+      val rightChildStats =",
    "line": 145
  }],
  "prId": 19433
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "It'd be nice to calculate the parentCalc right away here, if needed.  That seems possible just by taking the first candidate split.  Then we could simplify calculateImpurityStats by not passing in parentCalc as an option.",
    "commit": "d86dd18e47451c2e4463c68db441f92a898ac765",
    "createdAt": "2017-11-10T06:10:58Z",
    "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impl\n+\n+import org.apache.spark.ml.tree.{CategoricalSplit, Split}\n+import org.apache.spark.mllib.tree.impurity.ImpurityCalculator\n+import org.apache.spark.mllib.tree.model.ImpurityStats\n+\n+/** Utility methods for choosing splits during local & distributed tree training. */\n+private[impl] object SplitUtils {\n+\n+  /** Sorts ordered feature categories by label centroid, returning an ordered list of categories */\n+  private def sortByCentroid(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int): List[Int] = {\n+    /* Each bin is one category (feature value).\n+     * The bins are ordered based on centroidForCategories, and this ordering determines which\n+     * splits are considered.  (With K categories, we consider K - 1 possible splits.)\n+     *\n+     * centroidForCategories is a list: (category, centroid)\n+     */\n+    val numCategories = binAggregates.metadata.numBins(featureIndex)\n+    val nodeFeatureOffset = binAggregates.getFeatureOffset(featureIndexIdx)\n+\n+    val centroidForCategories = Range(0, numCategories).map { featureValue =>\n+      val categoryStats =\n+        binAggregates.getImpurityCalculator(nodeFeatureOffset, featureValue)\n+      val centroid = ImpurityUtils.getCentroid(binAggregates.metadata, categoryStats)\n+      (featureValue, centroid)\n+    }\n+    // TODO(smurching): How to handle logging statements like these?\n+    // logDebug(\"Centroids for categorical variable: \" + centroidForCategories.mkString(\",\"))\n+    // bins sorted by centroids\n+    val categoriesSortedByCentroid = centroidForCategories.toList.sortBy(_._2).map(_._1)\n+    // logDebug(\"Sorted centroids for categorical variable = \" +\n+    //   categoriesSortedByCentroid.mkString(\",\"))\n+    categoriesSortedByCentroid\n+  }\n+\n+  /**\n+   * Find the best split for an unordered categorical feature at a single node.\n+   *\n+   * Algorithm:\n+   *  - Considers all possible subsets (exponentially many)\n+   *\n+   * @param featureIndex  Global index of feature being split.\n+   * @param featureIndexIdx Index of feature being split within subset of features for current node.\n+   * @param featureSplits Array of splits for the current feature\n+   * @param parentCalculator Optional: ImpurityCalculator containing impurity stats for current node\n+   * @return  (best split, statistics for split)  If no valid split was found, the returned\n+   *          ImpurityStats instance will be invalid (have member valid = false).\n+   */\n+  private[impl] def chooseUnorderedCategoricalSplit(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int,\n+      featureSplits: Array[Split],\n+      parentCalculator: Option[ImpurityCalculator] = None): (Split, ImpurityStats) = {\n+    // Unordered categorical feature\n+    val nodeFeatureOffset = binAggregates.getFeatureOffset(featureIndexIdx)\n+    val numSplits = binAggregates.metadata.numSplits(featureIndex)\n+    var parentCalc = parentCalculator"
  }],
  "prId": 19433
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "What's the issue?  You should be able to call logDebug if this object inherits from org.apache.spark.internal.Logging",
    "commit": "d86dd18e47451c2e4463c68db441f92a898ac765",
    "createdAt": "2017-11-10T18:45:53Z",
    "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impl\n+\n+import org.apache.spark.ml.tree.{CategoricalSplit, Split}\n+import org.apache.spark.mllib.tree.impurity.ImpurityCalculator\n+import org.apache.spark.mllib.tree.model.ImpurityStats\n+\n+/** Utility methods for choosing splits during local & distributed tree training. */\n+private[impl] object SplitUtils {\n+\n+  /** Sorts ordered feature categories by label centroid, returning an ordered list of categories */\n+  private def sortByCentroid(\n+      binAggregates: DTStatsAggregator,\n+      featureIndex: Int,\n+      featureIndexIdx: Int): List[Int] = {\n+    /* Each bin is one category (feature value).\n+     * The bins are ordered based on centroidForCategories, and this ordering determines which\n+     * splits are considered.  (With K categories, we consider K - 1 possible splits.)\n+     *\n+     * centroidForCategories is a list: (category, centroid)\n+     */\n+    val numCategories = binAggregates.metadata.numBins(featureIndex)\n+    val nodeFeatureOffset = binAggregates.getFeatureOffset(featureIndexIdx)\n+\n+    val centroidForCategories = Range(0, numCategories).map { featureValue =>\n+      val categoryStats =\n+        binAggregates.getImpurityCalculator(nodeFeatureOffset, featureValue)\n+      val centroid = ImpurityUtils.getCentroid(binAggregates.metadata, categoryStats)\n+      (featureValue, centroid)\n+    }\n+    // TODO(smurching): How to handle logging statements like these?"
  }],
  "prId": 19433
}]