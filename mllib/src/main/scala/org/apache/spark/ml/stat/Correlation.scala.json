[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Say \"pearson\" here explicitly.",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-23T16:34:01Z",
    "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for correlation functions in MLlib, compatible with Dataframes and Datasets.\n+ *\n+ * The functions in this package generalize the functions in [[org.apache.spark.sql.Dataset.stat]]\n+ * to spark.ml's Vector types.\n+ */\n+@Since(\"2.2.0\")\n+@Experimental\n+object Correlation {\n+\n+  /**\n+   * :: Experimental ::\n+   * Compute the correlation matrix for the input RDD of Vectors using the specified method.\n+   * Methods currently supported: `pearson` (default), `spearman`.\n+   *\n+   * @param dataset A dataset or a dataframe\n+   * @param column The name of the column of vectors for which the correlation coefficient needs\n+   *               to be computed. This must be a column of the dataset, and it must contain\n+   *               Vector objects.\n+   * @param method String specifying the method to use for computing correlation.\n+   *               Supported: `pearson` (default), `spearman`\n+   * @return A dataframe that contains the correlation matrix of the column of vectors. This\n+   *         dataframe contains a single row and a single column of name\n+   *         '$METHODNAME($COLUMN)'.\n+   * @throws IllegalArgumentException if the column is not a valid column in the dataset, or if\n+   *                                  the content of this column is not of type Vector.\n+   *\n+   *  Here is how to access the correlation coefficient:\n+   *  {{{\n+   *    val data: Dataset[Vector] = ...\n+   *    val Row(coeff: Matrix) = Statistics.corr(data, \"value\").head\n+   *    // coeff now contains the Pearson correlation matrix.\n+   *  }}}\n+   *\n+   * @note For Spearman, a rank correlation, we need to create an RDD[Double] for each column\n+   * and sort it in order to retrieve the ranks and then join the columns back into an RDD[Vector],\n+   * which is fairly costly. Cache the input RDD before calling corr with `method = \"spearman\"` to\n+   * avoid recomputing the common lineage.\n+   */\n+  @Since(\"2.2.0\")\n+  def corr(dataset: Dataset[_], column: String, method: String): DataFrame = {\n+    val rdd = dataset.select(column).rdd.map {\n+      case Row(v: Vector) => OldVectors.fromML(v)\n+    }\n+    val oldM = OldStatistics.corr(rdd, method)\n+    val name = s\"$method($column)\"\n+    val schema = StructType(Array(StructField(name, SQLDataTypes.MatrixType, nullable = false)))\n+    dataset.sparkSession.createDataFrame(Seq(Row(oldM.asML)).asJava, schema)\n+  }\n+\n+  /**\n+   * Compute the correlation matrix for the input Dataset of Vectors."
  }],
  "prId": 17108
}]