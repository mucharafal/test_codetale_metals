[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Don't add Since annotations to private APIs.  They can get Since annotations when they are made public.",
    "commit": "c4e1a51551993008d7b082b112d2296cbc4eb97b",
    "createdAt": "2018-04-23T22:29:22Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.util\n+\n+import org.apache.spark.annotation.Since\n+import org.apache.spark.ml.linalg.{Vectors, VectorUDT}\n+import org.apache.spark.sql.{Column, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.{ArrayType, DoubleType, FloatType}\n+\n+\n+private[spark] object DatasetUtils {\n+\n+  /**\n+   * preprocessing the input feature column to Vector\n+   * @param dataset DataFrame with columns for features\n+   * @param colName column name for features\n+   * @return Vector feature column\n+   */\n+  @Since(\"2.4.0\")"
  }],
  "prId": 21081
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "This is a bit unclear.  How about: \"Cast a column in a Dataset to a Vector type.\"\r\nAlso, this isn't specific to features, so please clarify that below.\r\nFinally, the key thing to document is the list of supported input types, so I'd add that.",
    "commit": "c4e1a51551993008d7b082b112d2296cbc4eb97b",
    "createdAt": "2018-04-23T22:31:34Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.util\n+\n+import org.apache.spark.annotation.Since\n+import org.apache.spark.ml.linalg.{Vectors, VectorUDT}\n+import org.apache.spark.sql.{Column, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.{ArrayType, DoubleType, FloatType}\n+\n+\n+private[spark] object DatasetUtils {\n+\n+  /**\n+   * preprocessing the input feature column to Vector"
  }],
  "prId": 21081
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Add a note that this returned Column does not have Metadata",
    "commit": "c4e1a51551993008d7b082b112d2296cbc4eb97b",
    "createdAt": "2018-04-23T22:35:45Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.util\n+\n+import org.apache.spark.annotation.Since\n+import org.apache.spark.ml.linalg.{Vectors, VectorUDT}\n+import org.apache.spark.sql.{Column, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.{ArrayType, DoubleType, FloatType}\n+\n+\n+private[spark] object DatasetUtils {\n+\n+  /**\n+   * preprocessing the input feature column to Vector\n+   * @param dataset DataFrame with columns for features\n+   * @param colName column name for features\n+   * @return Vector feature column"
  }],
  "prId": 21081
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Thanks!  I forgot about this since this was generalized.",
    "commit": "c4e1a51551993008d7b082b112d2296cbc4eb97b",
    "createdAt": "2018-04-24T16:23:48Z",
    "diffHunk": "@@ -27,28 +26,38 @@ import org.apache.spark.sql.types.{ArrayType, DoubleType, FloatType}\n private[spark] object DatasetUtils {\n \n   /**\n-   * preprocessing the input feature column to Vector\n-   * @param dataset DataFrame with columns for features\n-   * @param colName column name for features\n-   * @return Vector feature column\n+   * Cast a column in a Dataset to Vector type.\n+   *\n+   * The supported data types of the input column are\n+   * - Vector\n+   * - float/double type Array.\n+   *\n+   * Note: The returned column does not have Metadata.\n+   *\n+   * @param dataset input DataFrame\n+   * @param colName column name.\n+   * @return Vector column\n    */\n-  @Since(\"2.4.0\")\n   def columnToVector(dataset: Dataset[_], colName: String): Column = {\n-    val featuresDataType = dataset.schema(colName).dataType\n-    featuresDataType match {\n+    val columnDataType = dataset.schema(colName).dataType\n+    columnDataType match {\n       case _: VectorUDT => col(colName)\n       case fdt: ArrayType =>\n         val transferUDF = fdt.elementType match {\n           case _: FloatType => udf(f = (vector: Seq[Float]) => {\n-            val featureArray = Array.fill[Double](vector.size)(0.0)\n-            vector.indices.foreach(idx => featureArray(idx) = vector(idx).toDouble)\n-            Vectors.dense(featureArray)\n+            val inputArray = Array.fill[Double](vector.size)(0.0)\n+            vector.indices.foreach(idx => inputArray(idx) = vector(idx).toDouble)\n+            Vectors.dense(inputArray)\n           })\n           case _: DoubleType => udf((vector: Seq[Double]) => {\n             Vectors.dense(vector.toArray)\n           })\n+          case other =>"
  }],
  "prId": 21081
}]