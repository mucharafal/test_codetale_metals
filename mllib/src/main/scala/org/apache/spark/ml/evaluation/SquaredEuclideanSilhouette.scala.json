[{
  "comments": [{
    "author": {
      "login": "yanboliang"
    },
    "body": "Aggregate function performance is not ideal for column of non-primitive type(like here is vector type). So we would still use RDD-based aggregate. You can factor this part of code following [```NaiveBayes```](https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/classification/NaiveBayes.scala#L161) like:\r\n```\r\n    import org.apache.spark.ml.linalg.{BLAS, DenseVector, Vectors}\r\n    import org.apache.spark.sql.functions._\r\n    \r\n    val numFeatures = ...\r\n    val squaredNorm = udf { features: Vector => math.pow(Vectors.norm(features, 2.0), 2.0) }\r\n\r\n    df.select(col(predictionCol), col(featuresCol))\r\n      .withColumn(\"squaredNorm\", squaredNorm(col(featuresCol)))\r\n      .rdd\r\n      .map { row => (row.getDouble(0), (row.getAs[Vector](1), row.getDouble(2))) }\r\n      .aggregateByKey[(DenseVector, Double)]((Vectors.zeros(numFeatures).toDense, 0.0))(\r\n      seqOp = {\r\n        case ((featureSum: DenseVector, squaredNormSum: Double), (features, squaredNorm)) =>\r\n          BLAS.axpy(1.0, features, featureSum)\r\n          (featureSum, squaredNormSum + squaredNorm)\r\n      },\r\n      combOp = {\r\n        case ((featureSum1, squaredNormSum1), (featureSum2, squaredNormSum2)) =>\r\n          BLAS.axpy(1.0, featureSum2, featureSum1)\r\n          (featureSum1, squaredNormSum1 + squaredNormSum2)\r\n      }).collect()\r\n```\r\nIn my suggestion, you can compute ```csi``` and ```y``` in a single data pass, which should be more efficient.",
    "commit": "a7c14818283467276a8f7eaa30b074a0f25237dc",
    "createdAt": "2017-08-08T11:45:52Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.evaluation\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.broadcast.Broadcast\n+import org.apache.spark.ml.linalg.{Vector, VectorElementWiseSum}\n+import org.apache.spark.sql.DataFrame\n+import org.apache.spark.sql.functions.{col, count, sum}\n+\n+private[evaluation] object SquaredEuclideanSilhouette {\n+\n+  private[this] var kryoRegistrationPerformed: Boolean = false\n+\n+  /**\n+   * This method registers the class\n+   * [[org.apache.spark.ml.evaluation.SquaredEuclideanSilhouette.ClusterStats]]\n+   * for kryo serialization.\n+   *\n+   * @param sc `SparkContext` to be used\n+   */\n+  def registerKryoClasses(sc: SparkContext): Unit = {\n+    if (! kryoRegistrationPerformed) {\n+      sc.getConf.registerKryoClasses(\n+        Array(\n+          classOf[SquaredEuclideanSilhouette.ClusterStats]\n+        )\n+      )\n+      kryoRegistrationPerformed = true\n+    }\n+  }\n+\n+  case class ClusterStats(Y: Vector, psi: Double, count: Long)\n+\n+  def computeCsi(vector: Vector): Double = {\n+    var sumOfSquares = 0.0\n+    vector.foreachActive((_, v) => {\n+      sumOfSquares += v * v\n+    })\n+    sumOfSquares\n+  }\n+\n+  def computeYVectorPsiAndCount(\n+      df: DataFrame,\n+      predictionCol: String,\n+      featuresCol: String): DataFrame = {\n+    val Yudaf = new VectorElementWiseSum()\n+    df.groupBy(predictionCol)\n+      .agg(\n+        count(\"*\").alias(\"count\"),\n+        sum(\"csi\").alias(\"psi\"),\n+        Yudaf(col(featuresCol)).alias(\"y\")\n+      )"
  }],
  "prId": 18538
}, {
  "comments": [{
    "author": {
      "login": "yanboliang"
    },
    "body": "Can we use ```Vectors.norm(vector, 2.0)```? It should be more efficient for both dense and sparse vector. Actually we can remove this function if you refactor code as my suggested below.",
    "commit": "a7c14818283467276a8f7eaa30b074a0f25237dc",
    "createdAt": "2017-08-08T11:48:28Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.evaluation\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.broadcast.Broadcast\n+import org.apache.spark.ml.linalg.{Vector, VectorElementWiseSum}\n+import org.apache.spark.sql.DataFrame\n+import org.apache.spark.sql.functions.{col, count, sum}\n+\n+private[evaluation] object SquaredEuclideanSilhouette {\n+\n+  private[this] var kryoRegistrationPerformed: Boolean = false\n+\n+  /**\n+   * This method registers the class\n+   * [[org.apache.spark.ml.evaluation.SquaredEuclideanSilhouette.ClusterStats]]\n+   * for kryo serialization.\n+   *\n+   * @param sc `SparkContext` to be used\n+   */\n+  def registerKryoClasses(sc: SparkContext): Unit = {\n+    if (! kryoRegistrationPerformed) {\n+      sc.getConf.registerKryoClasses(\n+        Array(\n+          classOf[SquaredEuclideanSilhouette.ClusterStats]\n+        )\n+      )\n+      kryoRegistrationPerformed = true\n+    }\n+  }\n+\n+  case class ClusterStats(Y: Vector, psi: Double, count: Long)\n+\n+  def computeCsi(vector: Vector): Double = {"
  }],
  "prId": 18538
}, {
  "comments": [{
    "author": {
      "login": "yanboliang"
    },
    "body": "Please rename ```csi``` to ```squaredNorm```, ```psi``` to ```squaredNormSum```, ```y``` to ```featureSum``` if I don't have misunderstand. We should use more descriptive name.",
    "commit": "a7c14818283467276a8f7eaa30b074a0f25237dc",
    "createdAt": "2017-08-08T11:52:49Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.evaluation\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.broadcast.Broadcast\n+import org.apache.spark.ml.linalg.{Vector, VectorElementWiseSum}\n+import org.apache.spark.sql.DataFrame\n+import org.apache.spark.sql.functions.{col, count, sum}\n+\n+private[evaluation] object SquaredEuclideanSilhouette {\n+\n+  private[this] var kryoRegistrationPerformed: Boolean = false\n+\n+  /**\n+   * This method registers the class\n+   * [[org.apache.spark.ml.evaluation.SquaredEuclideanSilhouette.ClusterStats]]\n+   * for kryo serialization.\n+   *\n+   * @param sc `SparkContext` to be used\n+   */\n+  def registerKryoClasses(sc: SparkContext): Unit = {\n+    if (! kryoRegistrationPerformed) {\n+      sc.getConf.registerKryoClasses(\n+        Array(\n+          classOf[SquaredEuclideanSilhouette.ClusterStats]\n+        )\n+      )\n+      kryoRegistrationPerformed = true\n+    }\n+  }\n+\n+  case class ClusterStats(Y: Vector, psi: Double, count: Long)\n+\n+  def computeCsi(vector: Vector): Double = {\n+    var sumOfSquares = 0.0\n+    vector.foreachActive((_, v) => {\n+      sumOfSquares += v * v\n+    })\n+    sumOfSquares\n+  }\n+\n+  def computeYVectorPsiAndCount(\n+      df: DataFrame,\n+      predictionCol: String,\n+      featuresCol: String): DataFrame = {\n+    val Yudaf = new VectorElementWiseSum()\n+    df.groupBy(predictionCol)\n+      .agg(\n+        count(\"*\").alias(\"count\"),\n+        sum(\"csi\").alias(\"psi\"),\n+        Yudaf(col(featuresCol)).alias(\"y\")"
  }],
  "prId": 18538
}, {
  "comments": [{
    "author": {
      "login": "yanboliang"
    },
    "body": "Let's move this to file ```ClusteringEvaluator```.",
    "commit": "a7c14818283467276a8f7eaa30b074a0f25237dc",
    "createdAt": "2017-08-08T11:58:52Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.evaluation\n+\n+import org.apache.spark.SparkContext\n+import org.apache.spark.broadcast.Broadcast\n+import org.apache.spark.ml.linalg.{Vector, VectorElementWiseSum}\n+import org.apache.spark.sql.DataFrame\n+import org.apache.spark.sql.functions.{col, count, sum}\n+\n+private[evaluation] object SquaredEuclideanSilhouette {"
  }],
  "prId": 18538
}]