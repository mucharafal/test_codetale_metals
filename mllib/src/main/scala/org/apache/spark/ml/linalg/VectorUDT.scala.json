[{
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "ditto\n",
    "commit": "1c230ae23e17905af9ea9655cbcfb5a948e627a9",
    "createdAt": "2016-04-19T08:28:53Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.linalg.udt\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.linalg.{DenseVector, SparseVector, Vector}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.GenericMutableRow\n+import org.apache.spark.sql.catalyst.util.GenericArrayData\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * :: AlphaComponent ::\n+ *\n+ * User-defined type for [[Vector]] in [[mllib-local]] which allows easy interaction with SQL\n+ * via [[org.apache.spark.sql.Dataset]].\n+ */\n+@AlphaComponent\n+private[ml] class VectorUDT extends UserDefinedType[Vector] {\n+\n+  override def sqlType: StructType = {\n+    // type: 0 = sparse, 1 = dense\n+    // We only use \"values\" for dense vectors, and \"size\", \"indices\", and \"values\" for sparse\n+    // vectors. The \"values\" field is nullable because we might want to add binary vectors later,\n+    // which uses \"size\" and \"indices\", but not \"values\".\n+    StructType(Seq(\n+      StructField(\"type\", ByteType, nullable = false),\n+      StructField(\"size\", IntegerType, nullable = true),\n+      StructField(\"indices\", ArrayType(IntegerType, containsNull = false), nullable = true),\n+      StructField(\"values\", ArrayType(DoubleType, containsNull = false), nullable = true)))\n+  }\n+\n+  override def serialize(obj: Vector): InternalRow = {\n+    obj match {\n+      case SparseVector(size, indices, values) =>\n+        val row = new GenericMutableRow(4)\n+        row.setByte(0, 0)\n+        row.setInt(1, size)\n+        row.update(2, new GenericArrayData(indices.map(_.asInstanceOf[Any])))\n+        row.update(3, new GenericArrayData(values.map(_.asInstanceOf[Any])))\n+        row\n+      case DenseVector(values) =>\n+        val row = new GenericMutableRow(4)\n+        row.setByte(0, 1)\n+        row.setNullAt(1)\n+        row.setNullAt(2)\n+        row.update(3, new GenericArrayData(values.map(_.asInstanceOf[Any])))\n+        row\n+    }\n+  }\n+\n+  override def deserialize(datum: Any): Vector = {\n+    datum match {\n+      case row: InternalRow =>\n+        require(row.numFields == 4,\n+          s\"VectorUDT.deserialize given row with length ${row.numFields} but requires length == 4\")\n+        val tpe = row.getByte(0)\n+        tpe match {\n+          case 0 =>\n+            val size = row.getInt(1)\n+            val indices = row.getArray(2).toIntArray()\n+            val values = row.getArray(3).toDoubleArray()\n+            new SparseVector(size, indices, values)\n+          case 1 =>\n+            val values = row.getArray(3).toDoubleArray()\n+            new DenseVector(values)\n+        }\n+    }\n+  }\n+\n+  override def pyUDT: String = \"pyspark.mllib.linalg.VectorUDT\""
  }],
  "prId": 12259
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "ditto. remove `udt` from package name.\n",
    "commit": "1c230ae23e17905af9ea9655cbcfb5a948e627a9",
    "createdAt": "2016-04-22T17:39:02Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.linalg.udt"
  }],
  "prId": 12259
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We don't need annotation for package private classes.\n",
    "commit": "1c230ae23e17905af9ea9655cbcfb5a948e627a9",
    "createdAt": "2016-04-22T18:36:23Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.linalg.udt\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.linalg.{DenseVector, SparseVector, Vector}\n+import org.apache.spark.sql.catalyst.InternalRow\n+import org.apache.spark.sql.catalyst.expressions.GenericMutableRow\n+import org.apache.spark.sql.catalyst.util.GenericArrayData\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * :: AlphaComponent ::\n+ *\n+ * User-defined type for [[Vector]] in [[mllib-local]] which allows easy interaction with SQL\n+ * via [[org.apache.spark.sql.Dataset]].\n+ */\n+@AlphaComponent"
  }],
  "prId": 12259
}]