[{
  "comments": [{
    "author": {
      "login": "wangmiao1981"
    },
    "body": "Add `Instrumentation`? Or I can add it in a separate PR.",
    "commit": "375e150e2f317e8bfc46992c13f60ca74ed04c00",
    "createdAt": "2018-04-17T21:56:53Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.clustering\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util._\n+import org.apache.spark.mllib.clustering.{PowerIterationClustering => MLlibPowerIterationClustering}\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.functions.col\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Common params for PowerIterationClustering\n+ */\n+private[clustering] trait PowerIterationClusteringParams extends Params with HasMaxIter\n+  with HasPredictionCol {\n+\n+  /**\n+   * The number of clusters to create (k). Must be &gt; 1. Default: 2.\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  final val k = new IntParam(this, \"k\", \"The number of clusters to create. \" +\n+    \"Must be > 1.\", ParamValidators.gt(1))\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getK: Int = $(k)\n+\n+  /**\n+   * Param for the initialization algorithm. This can be either \"random\" to use a random vector\n+   * as vertex properties, or \"degree\" to use a normalized sum of similarities with other vertices.\n+   * Default: random.\n+   * @group expertParam\n+   */\n+  @Since(\"2.4.0\")\n+  final val initMode = {\n+    val allowedParams = ParamValidators.inArray(Array(\"random\", \"degree\"))\n+    new Param[String](this, \"initMode\", \"The initialization algorithm. This can be either \" +\n+      \"'random' to use a random vector as vertex properties, or 'degree' to use a normalized sum \" +\n+      \"of similarities with other vertices.  Supported options: 'random' and 'degree'.\",\n+      allowedParams)\n+  }\n+\n+  /** @group expertGetParam */\n+  @Since(\"2.4.0\")\n+  def getInitMode: String = $(initMode)\n+\n+  /**\n+   * Param for the name of the input column for vertex IDs.\n+   * Default: \"id\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val idCol = new Param[String](this, \"idCol\", \"Name of the input column for vertex IDs.\",\n+    (value: String) => value.nonEmpty)\n+\n+  setDefault(idCol, \"id\")\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getIdCol: String = getOrDefault(idCol)\n+\n+  /**\n+   * Param for the name of the input column for neighbors in the adjacency list representation.\n+   * Default: \"neighbors\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val neighborsCol = new Param[String](this, \"neighborsCol\",\n+    \"Name of the input column for neighbors in the adjacency list representation.\",\n+    (value: String) => value.nonEmpty)\n+\n+  setDefault(neighborsCol, \"neighbors\")\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getNeighborsCol: String = $(neighborsCol)\n+\n+  /**\n+   * Param for the name of the input column for neighbors in the adjacency list representation.\n+   * Default: \"similarities\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val similaritiesCol = new Param[String](this, \"similaritiesCol\",\n+    \"Name of the input column for neighbors in the adjacency list representation.\",\n+    (value: String) => value.nonEmpty)\n+\n+  setDefault(similaritiesCol, \"similarities\")\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getSimilaritiesCol: String = $(similaritiesCol)\n+\n+  protected def validateAndTransformSchema(schema: StructType): StructType = {\n+    SchemaUtils.checkColumnTypes(schema, $(idCol), Seq(IntegerType, LongType))\n+    SchemaUtils.checkColumnTypes(schema, $(neighborsCol),\n+      Seq(ArrayType(IntegerType, containsNull = false),\n+        ArrayType(LongType, containsNull = false)))\n+    SchemaUtils.checkColumnTypes(schema, $(similaritiesCol),\n+      Seq(ArrayType(FloatType, containsNull = false),\n+        ArrayType(DoubleType, containsNull = false)))\n+    SchemaUtils.appendColumn(schema, $(predictionCol), IntegerType)\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Power Iteration Clustering (PIC), a scalable graph clustering algorithm developed by\n+ * <a href=http://www.icml2010.org/papers/387.pdf>Lin and Cohen</a>. From the abstract:\n+ * PIC finds a very low-dimensional embedding of a dataset using truncated power\n+ * iteration on a normalized pair-wise similarity matrix of the data.\n+ *\n+ * PIC takes an affinity matrix between items (or vertices) as input.  An affinity matrix\n+ * is a symmetric matrix whose entries are non-negative similarities between items.\n+ * PIC takes this matrix (or graph) as an adjacency matrix.  Specifically, each input row includes:\n+ *  - `idCol`: vertex ID\n+ *  - `neighborsCol`: neighbors of vertex in `idCol`\n+ *  - `similaritiesCol`: non-negative weights (similarities) of edges between the vertex\n+ *                       in `idCol` and each neighbor in `neighborsCol`\n+ * PIC returns a cluster assignment for each input vertex.  It appends a new column `predictionCol`\n+ * containing the cluster assignment in `[0,k)` for each row (vertex).\n+ *\n+ * Notes:\n+ *  - [[PowerIterationClustering]] is a transformer with an expensive [[transform]] operation.\n+ *    Transform runs the iterative PIC algorithm to cluster the whole input dataset.\n+ *  - Input validation: This validates that similarities are non-negative but does NOT validate\n+ *    that the input matrix is symmetric.\n+ *\n+ * @see <a href=http://en.wikipedia.org/wiki/Spectral_clustering>\n+ * Spectral clustering (Wikipedia)</a>\n+ */\n+@Since(\"2.4.0\")\n+@Experimental\n+class PowerIterationClustering private[clustering] (\n+    @Since(\"2.4.0\") override val uid: String)\n+  extends Transformer with PowerIterationClusteringParams with DefaultParamsWritable {\n+\n+  setDefault(\n+    k -> 2,\n+    maxIter -> 20,\n+    initMode -> \"random\")\n+\n+  @Since(\"2.4.0\")\n+  def this() = this(Identifiable.randomUID(\"PowerIterationClustering\"))\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setPredictionCol(value: String): this.type = set(predictionCol, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setK(value: Int): this.type = set(k, value)\n+\n+  /** @group expertSetParam */\n+  @Since(\"2.4.0\")\n+  def setInitMode(value: String): this.type = set(initMode, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setMaxIter(value: Int): this.type = set(maxIter, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setIdCol(value: String): this.type = set(idCol, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setNeighborsCol(value: String): this.type = set(neighborsCol, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setSimilaritiesCol(value: String): this.type = set(similaritiesCol, value)\n+\n+  @Since(\"2.4.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    transformSchema(dataset.schema, logging = true)\n+\n+    val sparkSession = dataset.sparkSession\n+    val idColValue = $(idCol)\n+    val rdd: RDD[(Long, Long, Double)] =\n+      dataset.select(\n+        col($(idCol)).cast(LongType),\n+        col($(neighborsCol)).cast(ArrayType(LongType, containsNull = false)),\n+        col($(similaritiesCol)).cast(ArrayType(DoubleType, containsNull = false))\n+      ).rdd.flatMap {\n+        case Row(id: Long, nbrs: Seq[_], sims: Seq[_]) =>\n+          require(nbrs.size == sims.size, s\"The length of the neighbor ID list must be \" +\n+            s\"equal to the the length of the neighbor similarity list.  Row for ID \" +\n+            s\"$idColValue=$id has neighbor ID list of length ${nbrs.length} but similarity list \" +\n+            s\"of length ${sims.length}.\")\n+          nbrs.asInstanceOf[Seq[Long]].zip(sims.asInstanceOf[Seq[Double]]).map {\n+            case (nbr, similarity) => (id, nbr, similarity)\n+          }\n+      }",
    "line": 215
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "Actually, we don't have any precedent for using Instrumentation in Models or Transformers, only Estimators.  I'll hold off on this for now.",
    "commit": "375e150e2f317e8bfc46992c13f60ca74ed04c00",
    "createdAt": "2018-04-19T00:30:24Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.clustering\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util._\n+import org.apache.spark.mllib.clustering.{PowerIterationClustering => MLlibPowerIterationClustering}\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.functions.col\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Common params for PowerIterationClustering\n+ */\n+private[clustering] trait PowerIterationClusteringParams extends Params with HasMaxIter\n+  with HasPredictionCol {\n+\n+  /**\n+   * The number of clusters to create (k). Must be &gt; 1. Default: 2.\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  final val k = new IntParam(this, \"k\", \"The number of clusters to create. \" +\n+    \"Must be > 1.\", ParamValidators.gt(1))\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getK: Int = $(k)\n+\n+  /**\n+   * Param for the initialization algorithm. This can be either \"random\" to use a random vector\n+   * as vertex properties, or \"degree\" to use a normalized sum of similarities with other vertices.\n+   * Default: random.\n+   * @group expertParam\n+   */\n+  @Since(\"2.4.0\")\n+  final val initMode = {\n+    val allowedParams = ParamValidators.inArray(Array(\"random\", \"degree\"))\n+    new Param[String](this, \"initMode\", \"The initialization algorithm. This can be either \" +\n+      \"'random' to use a random vector as vertex properties, or 'degree' to use a normalized sum \" +\n+      \"of similarities with other vertices.  Supported options: 'random' and 'degree'.\",\n+      allowedParams)\n+  }\n+\n+  /** @group expertGetParam */\n+  @Since(\"2.4.0\")\n+  def getInitMode: String = $(initMode)\n+\n+  /**\n+   * Param for the name of the input column for vertex IDs.\n+   * Default: \"id\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val idCol = new Param[String](this, \"idCol\", \"Name of the input column for vertex IDs.\",\n+    (value: String) => value.nonEmpty)\n+\n+  setDefault(idCol, \"id\")\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getIdCol: String = getOrDefault(idCol)\n+\n+  /**\n+   * Param for the name of the input column for neighbors in the adjacency list representation.\n+   * Default: \"neighbors\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val neighborsCol = new Param[String](this, \"neighborsCol\",\n+    \"Name of the input column for neighbors in the adjacency list representation.\",\n+    (value: String) => value.nonEmpty)\n+\n+  setDefault(neighborsCol, \"neighbors\")\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getNeighborsCol: String = $(neighborsCol)\n+\n+  /**\n+   * Param for the name of the input column for neighbors in the adjacency list representation.\n+   * Default: \"similarities\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val similaritiesCol = new Param[String](this, \"similaritiesCol\",\n+    \"Name of the input column for neighbors in the adjacency list representation.\",\n+    (value: String) => value.nonEmpty)\n+\n+  setDefault(similaritiesCol, \"similarities\")\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getSimilaritiesCol: String = $(similaritiesCol)\n+\n+  protected def validateAndTransformSchema(schema: StructType): StructType = {\n+    SchemaUtils.checkColumnTypes(schema, $(idCol), Seq(IntegerType, LongType))\n+    SchemaUtils.checkColumnTypes(schema, $(neighborsCol),\n+      Seq(ArrayType(IntegerType, containsNull = false),\n+        ArrayType(LongType, containsNull = false)))\n+    SchemaUtils.checkColumnTypes(schema, $(similaritiesCol),\n+      Seq(ArrayType(FloatType, containsNull = false),\n+        ArrayType(DoubleType, containsNull = false)))\n+    SchemaUtils.appendColumn(schema, $(predictionCol), IntegerType)\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Power Iteration Clustering (PIC), a scalable graph clustering algorithm developed by\n+ * <a href=http://www.icml2010.org/papers/387.pdf>Lin and Cohen</a>. From the abstract:\n+ * PIC finds a very low-dimensional embedding of a dataset using truncated power\n+ * iteration on a normalized pair-wise similarity matrix of the data.\n+ *\n+ * PIC takes an affinity matrix between items (or vertices) as input.  An affinity matrix\n+ * is a symmetric matrix whose entries are non-negative similarities between items.\n+ * PIC takes this matrix (or graph) as an adjacency matrix.  Specifically, each input row includes:\n+ *  - `idCol`: vertex ID\n+ *  - `neighborsCol`: neighbors of vertex in `idCol`\n+ *  - `similaritiesCol`: non-negative weights (similarities) of edges between the vertex\n+ *                       in `idCol` and each neighbor in `neighborsCol`\n+ * PIC returns a cluster assignment for each input vertex.  It appends a new column `predictionCol`\n+ * containing the cluster assignment in `[0,k)` for each row (vertex).\n+ *\n+ * Notes:\n+ *  - [[PowerIterationClustering]] is a transformer with an expensive [[transform]] operation.\n+ *    Transform runs the iterative PIC algorithm to cluster the whole input dataset.\n+ *  - Input validation: This validates that similarities are non-negative but does NOT validate\n+ *    that the input matrix is symmetric.\n+ *\n+ * @see <a href=http://en.wikipedia.org/wiki/Spectral_clustering>\n+ * Spectral clustering (Wikipedia)</a>\n+ */\n+@Since(\"2.4.0\")\n+@Experimental\n+class PowerIterationClustering private[clustering] (\n+    @Since(\"2.4.0\") override val uid: String)\n+  extends Transformer with PowerIterationClusteringParams with DefaultParamsWritable {\n+\n+  setDefault(\n+    k -> 2,\n+    maxIter -> 20,\n+    initMode -> \"random\")\n+\n+  @Since(\"2.4.0\")\n+  def this() = this(Identifiable.randomUID(\"PowerIterationClustering\"))\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setPredictionCol(value: String): this.type = set(predictionCol, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setK(value: Int): this.type = set(k, value)\n+\n+  /** @group expertSetParam */\n+  @Since(\"2.4.0\")\n+  def setInitMode(value: String): this.type = set(initMode, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setMaxIter(value: Int): this.type = set(maxIter, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setIdCol(value: String): this.type = set(idCol, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setNeighborsCol(value: String): this.type = set(neighborsCol, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.4.0\")\n+  def setSimilaritiesCol(value: String): this.type = set(similaritiesCol, value)\n+\n+  @Since(\"2.4.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    transformSchema(dataset.schema, logging = true)\n+\n+    val sparkSession = dataset.sparkSession\n+    val idColValue = $(idCol)\n+    val rdd: RDD[(Long, Long, Double)] =\n+      dataset.select(\n+        col($(idCol)).cast(LongType),\n+        col($(neighborsCol)).cast(ArrayType(LongType, containsNull = false)),\n+        col($(similaritiesCol)).cast(ArrayType(DoubleType, containsNull = false))\n+      ).rdd.flatMap {\n+        case Row(id: Long, nbrs: Seq[_], sims: Seq[_]) =>\n+          require(nbrs.size == sims.size, s\"The length of the neighbor ID list must be \" +\n+            s\"equal to the the length of the neighbor similarity list.  Row for ID \" +\n+            s\"$idColValue=$id has neighbor ID list of length ${nbrs.length} but similarity list \" +\n+            s\"of length ${sims.length}.\")\n+          nbrs.asInstanceOf[Seq[Long]].zip(sims.asInstanceOf[Seq[Double]]).map {\n+            case (nbr, similarity) => (id, nbr, similarity)\n+          }\n+      }",
    "line": 215
  }],
  "prId": 21090
}, {
  "comments": [{
    "author": {
      "login": "huaxingao"
    },
    "body": "Seems similaritiesCol is exactly the same as neighborsCol. Is this right?",
    "commit": "375e150e2f317e8bfc46992c13f60ca74ed04c00",
    "createdAt": "2018-04-20T02:22:54Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.clustering\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util._\n+import org.apache.spark.mllib.clustering.{PowerIterationClustering => MLlibPowerIterationClustering}\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.functions.col\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Common params for PowerIterationClustering\n+ */\n+private[clustering] trait PowerIterationClusteringParams extends Params with HasMaxIter\n+  with HasPredictionCol {\n+\n+  /**\n+   * The number of clusters to create (k). Must be &gt; 1. Default: 2.\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  final val k = new IntParam(this, \"k\", \"The number of clusters to create. \" +\n+    \"Must be > 1.\", ParamValidators.gt(1))\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getK: Int = $(k)\n+\n+  /**\n+   * Param for the initialization algorithm. This can be either \"random\" to use a random vector\n+   * as vertex properties, or \"degree\" to use a normalized sum of similarities with other vertices.\n+   * Default: random.\n+   * @group expertParam\n+   */\n+  @Since(\"2.4.0\")\n+  final val initMode = {\n+    val allowedParams = ParamValidators.inArray(Array(\"random\", \"degree\"))\n+    new Param[String](this, \"initMode\", \"The initialization algorithm. This can be either \" +\n+      \"'random' to use a random vector as vertex properties, or 'degree' to use a normalized sum \" +\n+      \"of similarities with other vertices.  Supported options: 'random' and 'degree'.\",\n+      allowedParams)\n+  }\n+\n+  /** @group expertGetParam */\n+  @Since(\"2.4.0\")\n+  def getInitMode: String = $(initMode)\n+\n+  /**\n+   * Param for the name of the input column for vertex IDs.\n+   * Default: \"id\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val idCol = new Param[String](this, \"idCol\", \"Name of the input column for vertex IDs.\",\n+    (value: String) => value.nonEmpty)\n+\n+  setDefault(idCol, \"id\")\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getIdCol: String = getOrDefault(idCol)\n+\n+  /**\n+   * Param for the name of the input column for neighbors in the adjacency list representation.\n+   * Default: \"neighbors\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val neighborsCol = new Param[String](this, \"neighborsCol\",\n+    \"Name of the input column for neighbors in the adjacency list representation.\",\n+    (value: String) => value.nonEmpty)\n+\n+  setDefault(neighborsCol, \"neighbors\")\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getNeighborsCol: String = $(neighborsCol)\n+\n+  /**\n+   * Param for the name of the input column for neighbors in the adjacency list representation.\n+   * Default: \"similarities\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val similaritiesCol = new Param[String](this, \"similaritiesCol\",\n+    \"Name of the input column for neighbors in the adjacency list representation.\",\n+    (value: String) => value.nonEmpty)\n+",
    "line": 108
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "No, it's meant to be an adjacency list representation of the graph: neighborsCol has the set of neighbor vertex IDs, and similaritiesCol has the corresponding set of edge weights.",
    "commit": "375e150e2f317e8bfc46992c13f60ca74ed04c00",
    "createdAt": "2018-05-17T01:00:45Z",
    "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.clustering\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util._\n+import org.apache.spark.mllib.clustering.{PowerIterationClustering => MLlibPowerIterationClustering}\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.functions.col\n+import org.apache.spark.sql.types._\n+\n+/**\n+ * Common params for PowerIterationClustering\n+ */\n+private[clustering] trait PowerIterationClusteringParams extends Params with HasMaxIter\n+  with HasPredictionCol {\n+\n+  /**\n+   * The number of clusters to create (k). Must be &gt; 1. Default: 2.\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  final val k = new IntParam(this, \"k\", \"The number of clusters to create. \" +\n+    \"Must be > 1.\", ParamValidators.gt(1))\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getK: Int = $(k)\n+\n+  /**\n+   * Param for the initialization algorithm. This can be either \"random\" to use a random vector\n+   * as vertex properties, or \"degree\" to use a normalized sum of similarities with other vertices.\n+   * Default: random.\n+   * @group expertParam\n+   */\n+  @Since(\"2.4.0\")\n+  final val initMode = {\n+    val allowedParams = ParamValidators.inArray(Array(\"random\", \"degree\"))\n+    new Param[String](this, \"initMode\", \"The initialization algorithm. This can be either \" +\n+      \"'random' to use a random vector as vertex properties, or 'degree' to use a normalized sum \" +\n+      \"of similarities with other vertices.  Supported options: 'random' and 'degree'.\",\n+      allowedParams)\n+  }\n+\n+  /** @group expertGetParam */\n+  @Since(\"2.4.0\")\n+  def getInitMode: String = $(initMode)\n+\n+  /**\n+   * Param for the name of the input column for vertex IDs.\n+   * Default: \"id\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val idCol = new Param[String](this, \"idCol\", \"Name of the input column for vertex IDs.\",\n+    (value: String) => value.nonEmpty)\n+\n+  setDefault(idCol, \"id\")\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getIdCol: String = getOrDefault(idCol)\n+\n+  /**\n+   * Param for the name of the input column for neighbors in the adjacency list representation.\n+   * Default: \"neighbors\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val neighborsCol = new Param[String](this, \"neighborsCol\",\n+    \"Name of the input column for neighbors in the adjacency list representation.\",\n+    (value: String) => value.nonEmpty)\n+\n+  setDefault(neighborsCol, \"neighbors\")\n+\n+  /** @group getParam */\n+  @Since(\"2.4.0\")\n+  def getNeighborsCol: String = $(neighborsCol)\n+\n+  /**\n+   * Param for the name of the input column for neighbors in the adjacency list representation.\n+   * Default: \"similarities\"\n+   * @group param\n+   */\n+  @Since(\"2.4.0\")\n+  val similaritiesCol = new Param[String](this, \"similaritiesCol\",\n+    \"Name of the input column for neighbors in the adjacency list representation.\",\n+    (value: String) => value.nonEmpty)\n+",
    "line": 108
  }],
  "prId": 21090
}]