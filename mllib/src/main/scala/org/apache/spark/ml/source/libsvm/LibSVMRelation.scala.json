[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "add an `assert`?\n",
    "commit": "931a29fe0c128e5b2708f8280150e98aa9d7b9e6",
    "createdAt": "2016-03-31T14:55:53Z",
    "diffHunk": "@@ -176,4 +203,49 @@ class DefaultSource extends FileFormat with DataSourceRegister {\n       externalRows.map(converter.toRow)\n     }\n   }\n+\n+  override def buildReader(\n+      sqlContext: SQLContext,\n+      dataSchema: StructType,\n+      partitionSchema: StructType,\n+      requiredSchema: StructType,\n+      filters: Seq[Filter],\n+      options: Map[String, String]): (PartitionedFile) => Iterator[InternalRow] = {\n+    val numFeatures = options(\"numFeatures\").toInt",
    "line": 98
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "Thanks, added.\n",
    "commit": "931a29fe0c128e5b2708f8280150e98aa9d7b9e6",
    "createdAt": "2016-03-31T15:28:48Z",
    "diffHunk": "@@ -176,4 +203,49 @@ class DefaultSource extends FileFormat with DataSourceRegister {\n       externalRows.map(converter.toRow)\n     }\n   }\n+\n+  override def buildReader(\n+      sqlContext: SQLContext,\n+      dataSchema: StructType,\n+      partitionSchema: StructType,\n+      requiredSchema: StructType,\n+      filters: Seq[Filter],\n+      options: Map[String, String]): (PartitionedFile) => Iterator[InternalRow] = {\n+    val numFeatures = options(\"numFeatures\").toInt",
    "line": 98
  }],
  "prId": 12088
}, {
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "Why do we define a function here and only call it once?\n",
    "commit": "931a29fe0c128e5b2708f8280150e98aa9d7b9e6",
    "createdAt": "2016-03-31T14:56:57Z",
    "diffHunk": "@@ -127,6 +135,25 @@ class DefaultSource extends FileFormat with DataSourceRegister {\n         StructField(\"features\", new VectorUDT(), nullable = false) :: Nil))\n   }\n \n+  override def prepareRead(\n+      sqlContext: SQLContext,\n+      options: Map[String, String],\n+      files: Seq[FileStatus]): Map[String, String] = {\n+    def computeNumFeatures(): Int = {",
    "line": 52
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "Because it's not always called. It's only called when `numFeatures` is absent or non-positive in `options`.\n",
    "commit": "931a29fe0c128e5b2708f8280150e98aa9d7b9e6",
    "createdAt": "2016-03-31T15:25:51Z",
    "diffHunk": "@@ -127,6 +135,25 @@ class DefaultSource extends FileFormat with DataSourceRegister {\n         StructField(\"features\", new VectorUDT(), nullable = false) :: Nil))\n   }\n \n+  override def prepareRead(\n+      sqlContext: SQLContext,\n+      options: Map[String, String],\n+      files: Seq[FileStatus]): Map[String, String] = {\n+    def computeNumFeatures(): Int = {",
    "line": 52
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "How about just put the method body into the getOrElse block?\n",
    "commit": "931a29fe0c128e5b2708f8280150e98aa9d7b9e6",
    "createdAt": "2016-04-01T00:06:07Z",
    "diffHunk": "@@ -127,6 +135,25 @@ class DefaultSource extends FileFormat with DataSourceRegister {\n         StructField(\"features\", new VectorUDT(), nullable = false) :: Nil))\n   }\n \n+  override def prepareRead(\n+      sqlContext: SQLContext,\n+      options: Map[String, String],\n+      files: Seq[FileStatus]): Map[String, String] = {\n+    def computeNumFeatures(): Int = {",
    "line": 52
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "+1 it is really weird to have a function here\n",
    "commit": "931a29fe0c128e5b2708f8280150e98aa9d7b9e6",
    "createdAt": "2016-06-15T23:16:23Z",
    "diffHunk": "@@ -127,6 +135,25 @@ class DefaultSource extends FileFormat with DataSourceRegister {\n         StructField(\"features\", new VectorUDT(), nullable = false) :: Nil))\n   }\n \n+  override def prepareRead(\n+      sqlContext: SQLContext,\n+      options: Map[String, String],\n+      files: Seq[FileStatus]): Map[String, String] = {\n+    def computeNumFeatures(): Int = {",
    "line": 52
  }],
  "prId": 12088
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "indent\n",
    "commit": "931a29fe0c128e5b2708f8280150e98aa9d7b9e6",
    "createdAt": "2016-03-31T16:18:07Z",
    "diffHunk": "@@ -127,6 +135,25 @@ class DefaultSource extends FileFormat with DataSourceRegister {\n         StructField(\"features\", new VectorUDT(), nullable = false) :: Nil))\n   }\n \n+  override def prepareRead(\n+      sqlContext: SQLContext,\n+      options: Map[String, String],\n+      files: Seq[FileStatus]): Map[String, String] = {\n+    def computeNumFeatures(): Int = {\n+      val dataFiles = files.filterNot(_.getPath.getName startsWith \"_\")\n+      val path = if (dataFiles.length == 1) dataFiles.head.getPath.toUri.toString\n+      else if (dataFiles.isEmpty) throw new IOException(\"No input path specified for libsvm data\")"
  }],
  "prId": 12088
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "indent\n",
    "commit": "931a29fe0c128e5b2708f8280150e98aa9d7b9e6",
    "createdAt": "2016-03-31T16:18:08Z",
    "diffHunk": "@@ -127,6 +135,25 @@ class DefaultSource extends FileFormat with DataSourceRegister {\n         StructField(\"features\", new VectorUDT(), nullable = false) :: Nil))\n   }\n \n+  override def prepareRead(\n+      sqlContext: SQLContext,\n+      options: Map[String, String],\n+      files: Seq[FileStatus]): Map[String, String] = {\n+    def computeNumFeatures(): Int = {\n+      val dataFiles = files.filterNot(_.getPath.getName startsWith \"_\")\n+      val path = if (dataFiles.length == 1) dataFiles.head.getPath.toUri.toString\n+      else if (dataFiles.isEmpty) throw new IOException(\"No input path specified for libsvm data\")\n+      else throw new IOException(\"Multiple input paths are not supported for libsvm data.\")"
  }],
  "prId": 12088
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`numFeatures` could be nonpositive. See L102.\n",
    "commit": "931a29fe0c128e5b2708f8280150e98aa9d7b9e6",
    "createdAt": "2016-03-31T16:18:10Z",
    "diffHunk": "@@ -127,6 +135,25 @@ class DefaultSource extends FileFormat with DataSourceRegister {\n         StructField(\"features\", new VectorUDT(), nullable = false) :: Nil))\n   }\n \n+  override def prepareRead(\n+      sqlContext: SQLContext,\n+      options: Map[String, String],\n+      files: Seq[FileStatus]): Map[String, String] = {\n+    def computeNumFeatures(): Int = {\n+      val dataFiles = files.filterNot(_.getPath.getName startsWith \"_\")\n+      val path = if (dataFiles.length == 1) dataFiles.head.getPath.toUri.toString\n+      else if (dataFiles.isEmpty) throw new IOException(\"No input path specified for libsvm data\")\n+      else throw new IOException(\"Multiple input paths are not supported for libsvm data.\")\n+\n+      val sc = sqlContext.sparkContext\n+      val parsed = MLUtils.parseLibSVMFile(sc, path, sc.defaultParallelism)\n+      MLUtils.computeNumFeatures(parsed)\n+    }\n+\n+    val numFeatures = options.getOrElse(\"numFeatures\", computeNumFeatures().toString)"
  }],
  "prId": 12088
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Note that unlike what we do in `MLUtils`, we don't cache `parsed` RDD here since it's constructed using different partitioning strategies as the final `FileScanRDD`. This is a potential performance regression.\n",
    "commit": "931a29fe0c128e5b2708f8280150e98aa9d7b9e6",
    "createdAt": "2016-03-31T17:46:01Z",
    "diffHunk": "@@ -127,6 +135,32 @@ class DefaultSource extends FileFormat with DataSourceRegister {\n         StructField(\"features\", new VectorUDT(), nullable = false) :: Nil))\n   }\n \n+  override def prepareRead(\n+      sqlContext: SQLContext,\n+      options: Map[String, String],\n+      files: Seq[FileStatus]): Map[String, String] = {\n+    def computeNumFeatures(): Int = {\n+      val dataFiles = files.filterNot(_.getPath.getName startsWith \"_\")\n+      val path = if (dataFiles.length == 1) {\n+        dataFiles.head.getPath.toUri.toString\n+      } else if (dataFiles.isEmpty) {\n+        throw new IOException(\"No input path specified for libsvm data\")\n+      } else {\n+        throw new IOException(\"Multiple input paths are not supported for libsvm data.\")\n+      }\n+\n+      val sc = sqlContext.sparkContext\n+      val parsed = MLUtils.parseLibSVMFile(sc, path, sc.defaultParallelism)\n+      MLUtils.computeNumFeatures(parsed)",
    "line": 64
  }],
  "prId": 12088
}]